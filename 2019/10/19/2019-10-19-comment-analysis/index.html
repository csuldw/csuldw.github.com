<!doctype html>
<html class="theme-next use-motion ">
<head><meta name="generator" content="Hexo 3.9.0">
  

<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">








  <link rel="stylesheet" type="text/css" href="/others/fancybox/source/jquery.fancybox.css?v=2.1.5">



  
    <link href="//fonts.googleapis.com/css?family=Lato:300,400,700,400italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  


<link rel="stylesheet" type="text/css" href="/others/font-awesome/css/font-awesome.min.css?v=4.4.0">

<link rel="stylesheet" type="text/css" href="/css/main.css?v=0.4.5.2">


    <meta name="description" content="中南大学硕士，关注机器学习、深度学习、自然语言处理与人工智能领域.">



  <meta name="keywords" content="豆瓣影评,情感分析,评论,">



  <link rel="alternate" href="/atom.xml" title="机器学习算法技术分享" type="application/atom+xml">



  <link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico?v=0.4.5.2">


<meta name="description" content="倒腾豆瓣电影短评情感分析也有一阵时间了，一直抓着这个不放也不是个事，得赶紧腾出时间去总结下KG。本文算是笔者对情感分析的进阶篇，也是关于情感分类模型覆盖最全的文章。首先，从传统的特征提取方面对比了BOW、TF-IDF、N-Gram技术，并使用不同的机器学习算法构建了不同的子模型，然后又采用了Stacking模型融合技术对短评情感进行了进一步的探索，最后进阶到深度学习，构建神经网络模型进行文本分类。">
<meta name="keywords" content="豆瓣影评,情感分析,评论">
<meta property="og:type" content="article">
<meta property="og:title" content="电影短评情感分析：各大模型江湖再见">
<meta property="og:url" content="https://www.csuldw.com/2019/10/19/2019-10-19-comment-analysis/index.html">
<meta property="og:site_name" content="机器学习算法技术分享">
<meta property="og:description" content="倒腾豆瓣电影短评情感分析也有一阵时间了，一直抓着这个不放也不是个事，得赶紧腾出时间去总结下KG。本文算是笔者对情感分析的进阶篇，也是关于情感分类模型覆盖最全的文章。首先，从传统的特征提取方面对比了BOW、TF-IDF、N-Gram技术，并使用不同的机器学习算法构建了不同的子模型，然后又采用了Stacking模型融合技术对短评情感进行了进一步的探索，最后进阶到深度学习，构建神经网络模型进行文本分类。">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://www.csuldw.com/assets/articleImg/2019/stacking-framework.png">
<meta property="og:image" content="https://www.csuldw.com/assets/articleImg/2019/simple-model-framework.png">
<meta property="og:image" content="https://www.csuldw.com/assets/articleImg/2019/rnn-lstm-gru.png">
<meta property="og:updated_time" content="2019-10-20T04:31:43.009Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="电影短评情感分析：各大模型江湖再见">
<meta name="twitter:description" content="倒腾豆瓣电影短评情感分析也有一阵时间了，一直抓着这个不放也不是个事，得赶紧腾出时间去总结下KG。本文算是笔者对情感分析的进阶篇，也是关于情感分类模型覆盖最全的文章。首先，从传统的特征提取方面对比了BOW、TF-IDF、N-Gram技术，并使用不同的机器学习算法构建了不同的子模型，然后又采用了Stacking模型融合技术对短评情感进行了进一步的探索，最后进阶到深度学习，构建神经网络模型进行文本分类。">
<meta name="twitter:image" content="https://www.csuldw.com/assets/articleImg/2019/stacking-framework.png">


<script type="text/javascript" id="hexo.configuration">
  var CONFIG = {
    scheme: '',
    sidebar: 'post'
  };
</script>



  <title> 电影短评情感分析：各大模型江湖再见 | 机器学习算法技术分享 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  <!--[if lte IE 8]>
  <div style=' clear: both; height: 59px; padding:0 0 0 15px; position: relative;margin:0 auto;'>
    <a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode">
      <img src="http://7u2nvr.com1.z0.glb.clouddn.com/picouterie.jpg" border="0" height="42" width="820"
           alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today or use other browser ,like chrome firefox safari."
           style='margin-left:auto;margin-right:auto;display: block;'/>
    </a>
  </div>
<![endif]-->
  






  <div id="container" class="container one-column page-post-detail">

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  
  
    <ul id="menu" class="menu ">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-user"></i> <br>
            
            About
          </a>
        </li>
      

      
      
	  	<span style="font-size:14px;float:right;padding:39px 40px 0 0;">——悄悄是别离的笙箫，沉默是今晚的康桥.</span>
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">

        	<div id="content" class="content"> 

  <div id="posts" class="posts-expand">
    

  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                电影短评情感分析：各大模型江湖再见
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            Posted on
            <time itemprop="dateCreated" datetime="2019-10-19T19:10:00+08:00" content="2019-10-19">
              2019-10-19 19:10
            </time>
          </span>

          
            <span class="post-category">
              &nbsp; | &nbsp; In
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2019/10/19/2019-10-19-comment-analysis/#comments" itemprop="discussionUrl">
                <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/10/19/2019-10-19-comment-analysis/" itemprop="commentsCount"></span>
              </a>
            </span>
            
          

          

          
            <span id="/2019/10/19/2019-10-19-comment-analysis/" class="leancloud_visitors" data-flag-title="电影短评情感分析：各大模型江湖再见">
            &nbsp; | &nbsp;   
            views
            </span>
          
        </div>
      </header>
    


    <div class="post-body">

      
      

      
        <span itemprop="articleBody"><p>倒腾豆瓣电影短评情感分析也有一阵时间了，一直抓着这个不放也不是个事，得赶紧腾出时间去总结下KG。本文算是笔者对情感分析的进阶篇，也是关于情感分类模型覆盖最全的文章。首先，从传统的特征提取方面对比了BOW、TF-IDF、N-Gram技术，并使用不同的机器学习算法构建了不同的子模型，然后又采用了Stacking模型融合技术对短评情感进行了进一步的探索，最后进阶到深度学习，构建神经网络模型进行文本分类。全文各个模型并不是参数最优，但也有一定的参考价值，因为针对不同的数据集，模型的预测结果都是不尽相同的。言归正传，下面一起来看看电影短评情感分析的结果吧！</p>
<a id="more"></a>

<h2 id="往期回顾"><a href="#往期回顾" class="headerlink" title="往期回顾"></a>往期回顾</h2><p>首先介绍下笔者先前写的几篇关于电影短评的文章：第一篇文章介绍的是如何构建高质量的情感分析数据集，第二篇是采用MNB做的一个baseline模型，第三篇是数据集的原始来源。本文使用的数据集来自文章[1]，整个训练集正负样本各220000条，测试集正负样本各24912条。</p>
<ol>
<li><a href="http://www.csuldw.com/2019/10/11/2019-10-11-rebuild-sa-dataset/">浅谈影评情感分析数据集的构建</a></li>
<li><a href="http://www.csuldw.com/2019/09/28/2019-09-28-comment-sentiment-analysis/">豆瓣电影短评数据情感分析Baseline</a></li>
<li><a href="http://www.csuldw.com/2019/09/08/2019-09-08-moviedata-10m/">14万电影800万影评数据集介绍</a></li>
</ol>
<p>这三篇文章主要是情感分析初始篇，模型层面的东西基本上没有涉及。本篇则是从模型出发分析短评情感。在文章内容篇幅上，笔者将从以下几个大方向构建电影短评情感分析模型：</p>
<ul>
<li>基于Bag-Of-Words特征的文本分类模型</li>
<li>基于TF-IDF特征的文本分类模型</li>
<li>基于Stacking模型融合的情感分析</li>
<li>基于深度学习的短评情感分析</li>
</ul>
<h2 id="基于Bag-Of-Words特征的文本分类模型"><a href="#基于Bag-Of-Words特征的文本分类模型" class="headerlink" title="基于Bag-Of-Words特征的文本分类模型"></a>基于Bag-Of-Words特征的文本分类模型</h2><p>笔者首先对短评数据进行了分词，然后算出每个短评的bow特征，并在此基础上训练了LR、MMB、RF、GBDT四个模型，当然各个模型都没有进行很深程度的调优。从Table 1可以看出，bow-LR模型整体上预测结果最好，AUC达到了0.9399，其他预测指标也达到了0.87。</p>
<center>Table 1 测试集预测结果对比(BoW)</center>

<!-- MORE -->
<table>
<thead>
<tr>
<th>模型名称</th>
<th>Accuracy</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>AUC</th>
</tr>
</thead>
<tbody><tr>
<td><strong>bow-LR</strong></td>
<td><strong>0.868</strong></td>
<td><strong>0.87</strong></td>
<td><strong>0.87</strong></td>
<td><strong>0.87</strong></td>
<td><strong>0.9399</strong></td>
</tr>
<tr>
<td>bow-MNB</td>
<td>0.865</td>
<td>0.86</td>
<td>0.86</td>
<td>0.86</td>
<td>0.9342</td>
</tr>
<tr>
<td>bow-RF</td>
<td>0.818</td>
<td>0.82</td>
<td>0.82</td>
<td>0.82</td>
<td>0.8902</td>
</tr>
<tr>
<td>bow-GBDT</td>
<td>0.7557</td>
<td>0.76</td>
<td>0.76</td>
<td>0.76</td>
<td>0.8535</td>
</tr>
</tbody></table>
<p>核心代码如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">transformer = CountVectorizer(analyzer=process.process_line)</span><br><span class="line">transformer.fit(X)X = transformer.transform(X)</span><br></pre></td></tr></tbody></table></figure>

<h2 id="基于TF-IDF特征的文本分类"><a href="#基于TF-IDF特征的文本分类" class="headerlink" title="基于TF-IDF特征的文本分类"></a>基于TF-IDF特征的文本分类</h2><p>TF-IDF在文本处理中经常用到，至少在我的工作中是用到的较多，比如计算文本相似度的时候，比较简单而且常用的做法就是，先将句子的TF-IDF值算出来，然后根据欧式距离计算相似度。TF-IDF（词频-逆文档频率）技术，是文本向量化的常用做法，从文本中提取特征以供后续的算法使用。</p>
<p>在这一小节里，特征方面最开始尝试了基于word的tfidf，然后又尝试了word-ngram-tfidf，后来将word-level替换成char-level，基于char构建n-gram。当然，关于ngram的n究竟该怎么取，也是一个值得考量的因子，读者如有兴趣，可以尝试下3-gram to 6-gram。针对不同的特征，笔者对比了LR、RF、MNB、GBDT四个算法，四个模型除了RF和GBDT是基于tree的，其他的都是不同类型的，以示区分。共训练了12个模型，各个模型的结果如Table 2所示。</p>
<center>Table 2 测试集预测结果对比(TF-IDF)</center>

<!-- MORE -->

<table>
<thead>
<tr>
<th>模型名称</th>
<th>Accuracy</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>AUC</th>
</tr>
</thead>
<tbody><tr>
<td>word-level-tfidf-LR</td>
<td>0.872</td>
<td>0.87</td>
<td>0.87</td>
<td>0.87</td>
<td>0.9438</td>
</tr>
<tr>
<td>word-level-tfidf-MNB</td>
<td>0.862</td>
<td>0.86</td>
<td>0.86</td>
<td>0.86</td>
<td>0.9394</td>
</tr>
<tr>
<td>word-level-tfidf-RF</td>
<td>0.8219</td>
<td>0.82</td>
<td>0.82</td>
<td>0.82</td>
<td>0.8930</td>
</tr>
<tr>
<td>word-level-tfidf-GBDT</td>
<td>0.723</td>
<td>0.72</td>
<td>0.72</td>
<td>0.71</td>
<td>0.8183</td>
</tr>
<tr>
<td>word-ngram-tfidf-LR</td>
<td>0.8724</td>
<td>0.87</td>
<td>0.87</td>
<td>0.87</td>
<td>0.9439</td>
</tr>
<tr>
<td>word-ngram-tfidf-MNB</td>
<td>0.8642</td>
<td>0.86</td>
<td>0.86</td>
<td>0.86</td>
<td>0.9399</td>
</tr>
<tr>
<td>word-ngram-tfidf-RF</td>
<td>0.8212</td>
<td>0.82</td>
<td>0.82</td>
<td>0.82</td>
<td>0.8925</td>
</tr>
<tr>
<td>word-ngram-tfidf-GBDT</td>
<td>0.7630</td>
<td>0.77</td>
<td>0.76</td>
<td>0.76</td>
<td>0.8588</td>
</tr>
<tr>
<td><strong>char-ngram-tfidf-LR</strong></td>
<td><strong>0.8866</strong></td>
<td><strong>0.89</strong></td>
<td><strong>0.89</strong></td>
<td><strong>0.89</strong></td>
<td><strong>0.9552</strong></td>
</tr>
<tr>
<td>char-ngram-tfidf-MNB</td>
<td>0.8657</td>
<td>0.87</td>
<td>0.87</td>
<td>0.87</td>
<td>0.9410</td>
</tr>
<tr>
<td>char-ngram-tfidf-RF</td>
<td>0.8276</td>
<td>0.83</td>
<td>0.83</td>
<td>0.83</td>
<td>0.9009</td>
</tr>
<tr>
<td>char-ngram-tfidf-GBDT</td>
<td>0.7686</td>
<td>0.78</td>
<td>0.77</td>
<td>0.77</td>
<td>0.8613</td>
</tr>
</tbody></table>
<div class="caption"></div>


<p>让笔者比较意外的是，GBDT和RF的结果居然比LR还要差，不过稍微想了下也感觉正常，主要是没有经过细致的调参。在上述12个模型中，基于char的ngram特征结合LR，测试集的预测结果，不管是precision还是recall、F1，都达到了0.89，AUC也高达0.9552，相对其他的模型，确实要高出一筹。说明一下，上述模型中基于word的ngram取得是[1,2,3]-gram，基于char的ngram是[2,3]-gram。</p>
<p>在算法上，笔者没有尝试SVM、xgboost、LightGBM等大众算法，一方面是SVM训练的速度过慢；另一方面是后面还会构建其他算法模型，传统的仅做参考吧。不过，虽然现在很多企业都转向了做深度学习模型，但传统的特征提取构建模型的方式还是值得学习一下的，毕竟知识掌握了就是自己的，缕清之后也就多了一份自信，没掌握的存放在电脑上的，那都是资料！！</p>
<h2 id="基于Stacking模型融合的情感分类模型"><a href="#基于Stacking模型融合的情感分类模型" class="headerlink" title="基于Stacking模型融合的情感分类模型"></a>基于Stacking模型融合的情感分类模型</h2><p>关于stacking融合技术，整个过程如Fig 1所示。首先将数据集划分为训练集和测试集，训练集主要用于sub-Model训练，训练方式有两种，一种基于cross-validation，一种是单纯的训练。两种方式具体的过程如下：</p>
<ul>
<li>Stacking-CV-Model：将训练集分成k份，在使用算法A进行交叉验证过程中，分别将每份作为测试集其余4分作为训练集训练分类模型，最后得到5个模型和5个测试集的预测结果，我们将算法A交叉验证得到的Out-Of-Fold结果作为一个特征集。如果有5个算法，每个算法得到的oof结果都是一个特征集，最后将其合并作为新的训练集（Meta Feature）。</li>
<li>Stacking-Model：将训练集分成k份，假设有5个算法用于stacking子模型中，那么算法1采用第5份作为测试集，其余4份作为训练集，依此论推，算法2采用采用第4份作为测试机，算法3采用第3份作为测试集，算法4采用第2份作为测试集，算法1采用第5份作为测试机，其余作为训练集，最后将每个算法预测的测试集的结果合并，作为新的特征，即新的训练集（Meta Feature）。</li>
</ul>
<p>如果有新的数据需要预测，那么都需要按照上述过程预测出新的特征，然后使用Meta algorithm预测出最终的结果。Stacking融合模型的代码已上传至github，仅供参考：<a href="https://github.com/csuldw/MachineLearning/blob/master/stacking/stacking.py" target="_blank" rel="noopener">https://github.com/csuldw/MachineLearning/blob/master/stacking/stacking.py</a></p>
<p><img src="/assets/articleImg/2019/stacking-framework.png" alt></p>
<div class="caption">Fig 1. stacking策略模型（分为两个阶段，第一阶段是model 1-model 5，用于训练出新的特征，第二阶段是Meta Algorithm，训练最终的分类模型）</div>

<p>在短评情感分类中，关于stacking模型，笔者尝试了几个，如Table 3所示。从数据上可以看出，在特征都为bag-of-words的情况下，bow（lr+MNB+RF）+xgboost 融合的结果的确比Table 1的各个子模型预测的结果好。单独从Table 3来看，xgboost作为layer 2的Meta算法比LR作为meta Algorithm 要稍微好一些。而针对不同的特征，基于char的ngram仍然要高出bow和word-tfidf特征，其AUC达到了0.9592。</p>
<center>Table 3 测试集模型预测结果对比(Stacking模型融合)</center>

<table>
<thead>
<tr>
<th>子模型</th>
<th>Meta_Classifier</th>
<th>Accuracy</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>AUC</th>
</tr>
</thead>
<tbody><tr>
<td>char-ngram-tfidf（lr+MNB+RF）</td>
<td>LR</td>
<td>0.8830</td>
<td>0.88</td>
<td>0.88</td>
<td>0.88</td>
<td>0.9539</td>
</tr>
<tr>
<td><strong>char-ngram-tfidf（lr+MNB+RF）</strong></td>
<td><strong>xgboost</strong></td>
<td><strong>0.8934</strong></td>
<td><strong>0.89</strong></td>
<td><strong>0.89</strong></td>
<td><strong>0.89</strong></td>
<td><strong>0.9592</strong></td>
</tr>
<tr>
<td>bow（lr+MNB+RF）</td>
<td>xgboost</td>
<td>0.8751</td>
<td>0.89</td>
<td>0.88</td>
<td>0.88</td>
<td>0.9444</td>
</tr>
<tr>
<td>word-tfidf（lr+MNB+RF）</td>
<td>xgboost</td>
<td>0.8739</td>
<td>0.87</td>
<td>0.87</td>
<td>0.87</td>
<td>0.9465</td>
</tr>
</tbody></table>
<h2 id="基于深度学习的情感分析"><a href="#基于深度学习的情感分析" class="headerlink" title="基于深度学习的情感分析"></a>基于深度学习的情感分析</h2><p>上面采用了传统机器学习方法构建了文本分类模型，接下来将使用深度学习技术进行文本分类。至于两者到底谁更好，我们大可不必太过较真。记得去年公司内部的多语言情感分类比赛，第一名是将BERT、fastText与传统机器学习算法进行融合而构建的stacking模型，第二名则是采用纯粹的传统机器学习方法进行融合。比赛当中，对数据的处理真的比算法更重要，有时候看起不起眼的算法，只要特征工程做的好，结果都是出乎意料的。说这些并不是指深度学习不行，只是想让大家以客观的心态去看待它，不要将其神话了。对于文本分类，之前使用比较多的深度学习算法还属RNN，比如LSTM、GRU等。在BERT出来之后，对文本分类的精度又提升了一个level。笔者在做情感分析的时候，并没有尝试去使用BERT算法，仅仅是将深度学习模型框架搭建了起来，后续要使用的话，直接调用就行了!关于深度学习模型的调参，笔者也没有花太多的时间，主要是在Mac上训练一个网络速度太慢了，一个LSTM，跑几十万的训练数据，一个epoch差不多20多分钟，整个模型训练下来也要好几个小时，真的是耗不起！基于LSTM的模型框架Fig 2所示：</p>
<!-- ![](/assets/articleImg/2019/simple-model-framework.png) -->
<img src="/assets/articleImg/2019/simple-model-framework.png" width="70%">
<div class="caption">Fig 2. LSTM深度学习文本分类模型框架</div>

<p>下面是笔者采用训练LSTM的核心代码(人生苦短，我用keras, v2.2.5)，注意一下，这里采用了多分类的方式来做二分类，所以调用的是<code>categorical_crossentropy</code>.</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span><span class="params">(X_train, y_train, X_test, y_test, n_words, batch_size, n_class=<span class="number">2</span>)</span>:</span></span><br><span class="line">    embedding_layer = Embedding(n_words + <span class="number">1</span>, EMBEDDING_DIM,</span><br><span class="line">                            <span class="comment"># weights=[embedding_matrix],</span></span><br><span class="line">                            input_length=MAX_SEQUENCE_LENGTH, dropout=<span class="number">0.2</span>)</span><br><span class="line">    print(<span class="string">'Build model...'</span>)</span><br><span class="line">    model = Sequential()</span><br><span class="line">    model.add(embedding_layer)</span><br><span class="line">    model.add(SpatialDropout1D(<span class="number">0.4</span>))</span><br><span class="line">    model.add(LSTM(<span class="number">64</span>, dropout=<span class="number">0.2</span>, recurrent_dropout=<span class="number">0.2</span>))  <span class="comment"># try using a GRU </span></span><br><span class="line">    model.add(Dense(n_class, activation=<span class="string">'softmax'</span>))</span><br><span class="line">    <span class="comment"># try using different parameters</span></span><br><span class="line">    model.compile(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">    print(model.summary())</span><br><span class="line">    model.fit(X_train, y_train, batch_size=batch_size, epochs=<span class="number">5</span>, validation_data=(X_test, y_test))</span><br><span class="line">    score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)</span><br><span class="line">    print(<span class="string">'Test score:{}, accuracy:{}'</span>.format(score, acc))</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></tbody></table></figure>

<p>LSTM Model结构与参数数量如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Model: <span class="string">"sequential_1"</span></span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param <span class="comment">#   </span></span><br><span class="line">=================================================================</span><br><span class="line">embedding_1 (Embedding)      (<span class="literal">None</span>, <span class="number">50</span>, <span class="number">128</span>)           <span class="number">12800128</span>  </span><br><span class="line">_________________________________________________________________</span><br><span class="line">spatial_dropout1d_1 (Spatial (<span class="literal">None</span>, <span class="number">50</span>, <span class="number">128</span>)           <span class="number">0</span>         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">lstm_1 (LSTM)                (<span class="literal">None</span>, <span class="number">64</span>)                <span class="number">49408</span>     </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense)              (<span class="literal">None</span>, <span class="number">2</span>)                 <span class="number">130</span>       </span><br><span class="line">=================================================================</span><br><span class="line">Total params: <span class="number">12</span>,<span class="number">849</span>,<span class="number">666</span></span><br><span class="line">Trainable params: <span class="number">12</span>,<span class="number">849</span>,<span class="number">666</span></span><br><span class="line">Non-trainable params: <span class="number">0</span></span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></tbody></table></figure>

<p>关于LSTM算法，这里不扩展了，感兴趣的童鞋可以参考下这篇文章<a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">Understanding LSTM Networks
</a>。其内部结构如Fig 3 (中)所示，：</p>
<!-- ![](/assets/articleImg/2019/rnn-lstm-gru.png) -->
<img src="/assets/articleImg/2019/rnn-lstm-gru.png" width="70%">
<div class="caption">Fig 3. RNN-vs-LSTM-vs-GRU 内部结构
</div>


<p>最终的模型预测结果如Table 4所示，在没有细致的调参情况下，LSTM模型的预测能力与上述传统的机器学习模型相差不大，GRU则与LSTM几乎持平：</p>
<center>Table 4. 测试集模型预测结果对比(深度学习)</center>

<table>
<thead>
<tr>
<th>模型名称</th>
<th>Accuracy</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>AUC</th>
</tr>
</thead>
<tbody><tr>
<td>LSTM-Model</td>
<td>0.8685</td>
<td>0.87</td>
<td>0.87</td>
<td>0.87</td>
<td>0.9392</td>
</tr>
<tr>
<td>GRU-Model</td>
<td>0.8685</td>
<td>0.87</td>
<td>0.88</td>
<td>0.87</td>
<td>0.9404</td>
</tr>
<tr>
<td>BiLSTM-Model</td>
<td>0.8660</td>
<td>0.87</td>
<td>0.87</td>
<td>0.87</td>
<td>0.9380</td>
</tr>
</tbody></table>
<div class="caption"></div>

<p>上面只是简单的采用了LSTM和GRU来构建深度学习模型，针对分类任务，还有很多的方法可以实施。比如基于BERT预训练模型构建分类模型，或是CNN、fastText等，亦或是不同的深度网络结构，都可以用来优化模型的最终预测性能。另外，我们还可以将深度学习模型与传统的机器学习模型进行融合，构建基于深度学习和机器学习的stacking模型等等等等。当然，只追求模型的种类是绝对不行的，要深入到一个模型里面，将参数调制最优，才是学习之根本。比如深度学习模型，模型何时会收敛，如何尽量避免过拟合等等，都是一大学问。读者如有相关的问题，可以关注笔者的公众号[斗码小院]，在后台或是文章中留言都可以。</p>
<h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>本文针对豆瓣电影短评数据集，构建了四大分类模型：基于BOW特征的分类模型、基于TF-IDF特征的分类模型、基于Stacking模型融合技术的情感分类模型、基于深度学习的短评情感分析模型，共训练了20+个文本分类模型，其中传统的基于char-level-ngram-tfidf特征构建的模型，在相同的算法下，不亚于其他的word-level特征。在深度学习模型上，由于一个模型训练的时间过长，笔者并未花费太多的时间去优化。后续如果有新的进展，也会第一时间在本文的留言栏中说明。OK，关于情感分析，就到此为止吧，感谢各位读者的捧场！<strong>需要数据集的童鞋可关注[<span style="color:blue">斗码小院</span>]公众号，回复”情感分析数据集”即可</strong>。</p>
<p>本文的所有代码已上传至GitHub：<a href="https://github.com/csuldw/comment-sentiment-analysis" target="_blank" rel="noopener">https://github.com/csuldw/comment-sentiment-analysis</a>，代码如有错误，还望读者指出，多谢！</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol>
<li><a href="http://www.csuldw.com">http://www.csuldw.com</a></li>
<li><a href="https://scikit-learn.org" target="_blank" rel="noopener">https://scikit-learn.org</a></li>
<li><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></li>
<li><a href="https://www.kaggle.com/ngyptr/lstm-sentiment-analysis-keras" target="_blank" rel="noopener">https://www.kaggle.com/ngyptr/lstm-sentiment-analysis-keras</a></li>
<li><a href="http://dprogrammer.org/rnn-lstm-gru" target="_blank" rel="noopener">http://dprogrammer.org/rnn-lstm-gru</a></li>
</ol>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script></span>
      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/豆瓣影评/" rel="tag">#豆瓣影评</a>
          
            <a href="/tags/情感分析/" rel="tag">#情感分析</a>
          
            <a href="/tags/评论/" rel="tag">#评论</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/10/20/2019-10-20-nl2sql-introduction/" rel="prev">
                <i class="fa fa-chevron-left"></i> NL2SQL概述：一文了解NL2SQL
              </a>
            
          </div>

          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/10/11/2019-10-11-rebuild-sa-dataset/" rel="next">
                浅谈影评情感分析数据集的构建 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>

 </div>

        

        
          <div class="comments" id="comments">
            
              <div id="disqus_thread">
                <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
              </div>
            
          </div>
        
      

        
          
  
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">
      
      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table Of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview" sidebar-panel>
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" src="/images/default_avatar.jpg" alt="刘帝伟" itemprop="image">
          <p class="site-author-name" itemprop="name">刘帝伟</p>
        </div>
        <p class="site-description motion-element" itemprop="description">中南大学硕士，关注机器学习、深度学习、自然语言处理与人工智能领域.</p>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">110</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          <div class="site-state-item site-state-categories">
            <a href="/categories">
              <span class="site-state-item-count">16</span>
              <span class="site-state-item-name">categories</span>
              </a>
          </div>

          <div class="site-state-item site-state-tags">
            <a href="/tags">
              <span class="site-state-item-count">186</span>
              <span class="site-state-item-name">tags</span>
              </a>
          </div>

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="menu-item-icon icon-next-feed"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/csuldw" target="_blank">
                  <i class="fa fa-github"></i> GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/liudiwei210" target="_blank">
                  <i class="fa fa-weibo"></i> WeiBo
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://blog.csdn.net/dream_angel_z" target="_blank">
                  <i class="fa fa-csdn"></i> CSDN
                </a>
              </span>
            
          
        </div>

        
        

        <div class="links-of-author motion-element">
          
        </div>

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel-active">
          <div class="post-toc-indicator-top post-toc-indicator"></div>
          <div class="post-toc">
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#往期回顾"><span class="nav-number">1.</span> <span class="nav-text">往期回顾</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于Bag-Of-Words特征的文本分类模型"><span class="nav-number">2.</span> <span class="nav-text">基于Bag-Of-Words特征的文本分类模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于TF-IDF特征的文本分类"><span class="nav-number">3.</span> <span class="nav-text">基于TF-IDF特征的文本分类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于Stacking模型融合的情感分类模型"><span class="nav-number">4.</span> <span class="nav-text">基于Stacking模型融合的情感分类模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于深度学习的情感分析"><span class="nav-number">5.</span> <span class="nav-text">基于深度学习的情感分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#结束语"><span class="nav-number">6.</span> <span class="nav-text">结束语</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考文献"><span class="nav-number">7.</span> <span class="nav-text">参考文献</span></a></li></ol></div>
            
          </div>
          <div class="post-toc-indicator-bottom post-toc-indicator"></div>
        </section>
      

    </div>
  </aside>


        
	  </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner"> <div class="copyright">
  
  &copy;  2014 - 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="icon-next-heart fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">刘帝伟</span>
</div>
<div class="powered-by">
  Powered by <a class="theme-link" href="http://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="#">
    FreeSky
  </a>(Reserved)

  
  <span id="busuanzi_container_site_uv">
     &nbsp; | &nbsp;  用户量: <span id="busuanzi_value_site_uv"></span>
  </span>
  <span id="busuanzi_container_site_pv">
    &nbsp; | &nbsp;  总访问量: <span id="busuanzi_value_site_pv"></span>
  </span>

</div>
      <div style="width:800px;margin:0 auto; padding:0px 0; font-size: 1em">
        <span><a href="https://beian.miit.gov.cn" target="_blank">粤ICP备19116962号</a></span>
        <a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=44030702002575" style="display:inline-block;text-decoration:none;height:18px;line-height:20px;">
        <img src="/images/beian.png" style="float:left;"><p style="float:left;height:17px;line-height:20px;margin: 0px 0px 0px 4px; color:#939393;">粤公网安备 44030702002575号</p></a>
      </div>


<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
 </div>
    </footer>

    <div class="back-to-top"></div>
  </div>

  <script type="text/javascript" src="/others/jquery/index.js?v=2.1.3"></script>

  
  
  
    
    

  

    <script type="text/javascript">
      var disqus_shortname = 'csuldw';
      var disqus_identifier = '2019/10/19/2019-10-19-comment-analysis/';
      var disqus_title = '电影短评情感分析：各大模型江湖再见';
      var disqus_url = 'https://www.csuldw.com/2019/10/19/2019-10-19-comment-analysis/';

      function run_disqus_script(disqus_script){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      }

      run_disqus_script('count.js');
      
        run_disqus_script('embed.js');
      
    </script>
  


  
  
  <script type="text/javascript" src="/others/fancybox/source/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/fancy-box.js?v=0.4.5.2"></script>


  <script type="text/javascript" src="/js/helpers.js?v=0.4.5.2"></script>
  

  <script type="text/javascript" src="/others/velocity/velocity.min.js"></script>
  <script type="text/javascript" src="/others/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/js/motion_global.js?v=0.4.5.2" id="motion.global"></script>




  <script type="text/javascript" src="/js/nav-toggle.js?v=0.4.5.2"></script>
  <script type="text/javascript" src="/others/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  
<script type="text/javascript" src="/js/bootstrap.scrollspy.js?v=0.4.5.2" id="bootstrap.scrollspy.custom"></script>


<script type="text/javascript" id="sidebar.toc.highlight">
  $(document).ready(function () {
    var tocSelector = '.post-toc';
    var $tocSelector = $(tocSelector);
    var activeCurrentSelector = '.active-current';

    $tocSelector
      .on('activate.bs.scrollspy', function () {
        var $currentActiveElement = $(tocSelector + ' .active').last();

        removeCurrentActiveClass();
        $currentActiveElement.addClass('active-current');

        $tocSelector[0].scrollTop = $currentActiveElement.position().top;
      })
      .on('clear.bs.scrollspy', function () {
        removeCurrentActiveClass();
      });

    function removeCurrentActiveClass () {
      $(tocSelector + ' ' + activeCurrentSelector)
        .removeClass(activeCurrentSelector.substring(1));
    }

    function processTOC () {
      getTOCMaxHeight();
      toggleTOCOverflowIndicators();
    }

    function getTOCMaxHeight () {
      var height = $('.sidebar').height() -
                   $tocSelector.position().top -
                   $('.post-toc-indicator-bottom').height();

      $tocSelector.css('height', height);

      return height;
    }

    function toggleTOCOverflowIndicators () {
      tocOverflowIndicator(
        '.post-toc-indicator-top',
        $tocSelector.scrollTop() > 0 ? 'show' : 'hide'
      );

      tocOverflowIndicator(
        '.post-toc-indicator-bottom',
        $tocSelector.scrollTop() >= $tocSelector.find('ol').height() - $tocSelector.height() ? 'hide' : 'show'
      )
    }

    $(document).on('sidebar.motion.complete', function () {
      processTOC();
    });

    $('body').scrollspy({ target: tocSelector });
    $(window).on('resize', function () {
      if ( $('.sidebar').hasClass('sidebar-active') ) {
        processTOC();
      }
    });

    onScroll($tocSelector);

    function onScroll (element) {
      element.on('mousewheel DOMMouseScroll', function (event) {
          var oe = event.originalEvent;
          var delta = oe.wheelDelta || -oe.detail;

          this.scrollTop += ( delta < 0 ? 1 : -1 ) * 30;
          event.preventDefault();

          toggleTOCOverflowIndicators();
      });
    }

    function tocOverflowIndicator (indicator, action) {
      var $indicator = $(indicator);
      var opacity = action === 'show' ? 0.4 : 0;
      $indicator.velocity ?
        $indicator.velocity('stop').velocity({
          opacity: opacity
        }, { duration: 100 }) :
        $indicator.stop().animate({
          opacity: opacity
        }, 100);
    }

  });
</script>

<script type="text/javascript" id="sidebar.nav">
  $(document).ready(function () {
    var html = $('html');
    var TAB_ANIMATE_DURATION = 200;
    var hasVelocity = $.isFunction(html.velocity);

    $('.sidebar-nav li').on('click', function () {
      var item = $(this);
      var activeTabClassName = 'sidebar-nav-active';
      var activePanelClassName = 'sidebar-panel-active';
      if (item.hasClass(activeTabClassName)) {
        return;
      }

      var currentTarget = $('.' + activePanelClassName);
      var target = $('.' + item.data('target'));

      hasVelocity ?
        currentTarget.velocity('transition.slideUpOut', TAB_ANIMATE_DURATION, function () {
          target
            .velocity('stop')
            .velocity('transition.slideDownIn', TAB_ANIMATE_DURATION)
            .addClass(activePanelClassName);
        }) :
        currentTarget.animate({ opacity: 0 }, TAB_ANIMATE_DURATION, function () {
          currentTarget.hide();
          target
            .stop()
            .css({'opacity': 0, 'display': 'block'})
            .animate({ opacity: 1 }, TAB_ANIMATE_DURATION, function () {
              currentTarget.removeClass(activePanelClassName);
              target.addClass(activePanelClassName);
            });
        });

      item.siblings().removeClass(activeTabClassName);
      item.addClass(activeTabClassName);
    });

    $('.post-toc a').on('click', function (e) {
      e.preventDefault();
      var targetSelector = escapeSelector(this.getAttribute('href'));
      var offset = $(targetSelector).offset().top;
      hasVelocity ?
        html.velocity('stop').velocity('scroll', {
          offset: offset  + 'px',
          mobileHA: false
        }) :
        $('html, body').stop().animate({
          scrollTop: offset
        }, 500);
    });

    // Expand sidebar on post detail page by default, when post has a toc.
    var $tocContent = $('.post-toc-content');
    var $aboutContent = $('#posts-about');
    if (isDesktop() && CONFIG.sidebar === 'post') {
      if ($tocContent.length > 0 && $tocContent.html().trim().length > 0 && $aboutContent.length === 0) {
        displaySidebar();
      }
    }
  });
</script>



  <script type="text/javascript">
    $(document).ready(function () {
      if (CONFIG.sidebar === 'always') {
        displaySidebar();
      }
      if (isMobile()) {
        FastClick.attach(document.body);
      }

      motionIntegrator.bootstrap();
    });
  </script>

  
  
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>



  
  

<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"1","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"16"},"slide":{"type":"slide","bdImg":"3","bdPos":"left","bdTop":"250"}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>



  
  <script type="text/javascript" src="/js/lazyload.js"></script>
  <script type="text/javascript">
    $(function () {
      $("#posts").find('img').lazyload({
        placeholder: "/images/loading.gif",
        effect: "fadeIn"
      });
    });
  </script>
  
     <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
<script>AV.initialize("VmAcWiBwF1SdavvjD8vkHJLn-gzGzoHsz", "cmuscA82gXyC9N1tgjH1m8bK");</script>
<script>
function showTime(Counter) {
  var query = new AV.Query(Counter);
  $(".leancloud_visitors").each(function() {
    var url = $(this).attr("id").trim();
    query.equalTo("url", url);
    query.find({
      success: function(results) {
        if (results.length == 0) {
          var content = $(document.getElementById(url)).text() + ': 0';
          $(document.getElementById(url)).text(content);
          return;
        }
        for (var i = 0; i < results.length; i++) {
          var object = results[i];
          var content = $(document.getElementById(url)).text() + ': ' + object.get('time');
          $(document.getElementById(url)).text(content);
        }
      },
      error: function(object, error) {
        console.log("Error: " + error.code + " " + error.message);
      }
    });

  });
}

function addCount(Counter) {
  var Counter = AV.Object.extend("Counter");
  url = $(".leancloud_visitors").attr('id').trim();
  title = $(".leancloud_visitors").attr('data-flag-title').trim();
  var query = new AV.Query(Counter);
  query.equalTo("url", url);
  query.find({
    success: function(results) {
      if (results.length > 0) {
        var counter = results[0];
        counter.fetchWhenSave(true);
        counter.increment("time");
        counter.save(null, {
          success: function(counter) {
            var content = $(document.getElementById(url)).text() + ': ' + counter.get('time');
            $(document.getElementById(url)).text(content);
          },
          error: function(counter, error) {
            console.log('Failed to save Visitor num, with error message: ' + error.message);
          }
        });
      } else {
        var newcounter = new Counter();
        newcounter.set("title", title);
        newcounter.set("url", url);
        newcounter.set("time", 1);
        newcounter.save(null, {
          success: function(newcounter) {
              console.log("newcounter.get('time')="+newcounter.get('time'));
            var content = $(document.getElementById(url)).text() + ': ' + newcounter.get('time');
            $(document.getElementById(url)).text(content);
          },
          error: function(newcounter, error) {
            console.log('Failed to create');
          }
        });
      }
    },
    error: function(error) {
      console.log('Error:' + error.code + " " + error.message);
    }
  });
}
$(function() {
  var Counter = AV.Object.extend("Counter");
  if ($('.leancloud_visitors').length == 1) {
    addCount(Counter);
  } else if ($('.post-title-link').length > 1) {
    showTime(Counter);
  }
}); 
</script>
  
</body>
</html>
