{"meta":{"version":1,"warehouse":"1.0.2"},"models":{"Asset":[{"_id":"themes/freesky/source/vendors/velocity/velocity.ui.min.js","path":"vendors/velocity/velocity.ui.min.js","modified":0},{"_id":"themes/freesky/source/vendors/velocity/velocity.ui.js","path":"vendors/velocity/velocity.ui.js","modified":0},{"_id":"themes/freesky/source/vendors/velocity/velocity.min.js","path":"vendors/velocity/velocity.min.js","modified":0},{"_id":"themes/freesky/source/vendors/velocity/velocity.js","path":"vendors/velocity/velocity.js","modified":0},{"_id":"themes/freesky/source/vendors/velocity/bower.json","path":"vendors/velocity/bower.json","modified":0},{"_id":"themes/freesky/source/vendors/jquery/index.js","path":"vendors/jquery/index.js","modified":0},{"_id":"themes/freesky/source/vendors/font-awesome/fonts/fontawesome-webfont.woff2","path":"vendors/font-awesome/fonts/fontawesome-webfont.woff2","modified":0},{"_id":"themes/freesky/source/vendors/font-awesome/fonts/fontawesome-webfont.woff","path":"vendors/font-awesome/fonts/fontawesome-webfont.woff","modified":0},{"_id":"themes/freesky/source/vendors/font-awesome/fonts/fontawesome-webfont.ttf","path":"vendors/font-awesome/fonts/fontawesome-webfont.ttf","modified":0},{"_id":"themes/freesky/source/vendors/font-awesome/fonts/fontawesome-webfont.svg","path":"vendors/font-awesome/fonts/fontawesome-webfont.svg","modified":0},{"_id":"themes/freesky/source/vendors/font-awesome/fonts/fontawesome-webfont.eot","path":"vendors/font-awesome/fonts/fontawesome-webfont.eot","modified":0},{"_id":"themes/freesky/source/vendors/font-awesome/fonts/FontAwesome.otf","path":"vendors/font-awesome/fonts/FontAwesome.otf","modified":0},{"_id":"themes/freesky/source/vendors/font-awesome/css/font-awesome.min.css","path":"vendors/font-awesome/css/font-awesome.min.css","modified":0},{"_id":"themes/freesky/source/vendors/font-awesome/css/font-awesome.css.map","path":"vendors/font-awesome/css/font-awesome.css.map","modified":0},{"_id":"themes/freesky/source/vendors/font-awesome/css/font-awesome.css","path":"vendors/font-awesome/css/font-awesome.css","modified":0},{"_id":"themes/freesky/source/vendors/font-awesome/bower.json","path":"vendors/font-awesome/bower.json","modified":0},{"_id":"themes/freesky/source/vendors/font-awesome/HELP-US-OUT.txt","path":"vendors/font-awesome/HELP-US-OUT.txt","modified":0},{"_id":"themes/freesky/source/vendors/fastclick/lib/fastclick.min.js","path":"vendors/fastclick/lib/fastclick.min.js","modified":0},{"_id":"themes/freesky/source/vendors/fastclick/lib/fastclick.js","path":"vendors/fastclick/lib/fastclick.js","modified":0},{"_id":"themes/freesky/source/vendors/fastclick/bower.json","path":"vendors/fastclick/bower.json","modified":0},{"_id":"themes/freesky/source/vendors/fastclick/README.md","path":"vendors/fastclick/README.md","modified":0},{"_id":"themes/freesky/source/vendors/fastclick/LICENSE","path":"vendors/fastclick/LICENSE","modified":0},{"_id":"themes/freesky/source/vendors/fancybox/source/jquery.fancybox.pack.js","path":"vendors/fancybox/source/jquery.fancybox.pack.js","modified":0},{"_id":"themes/freesky/source/vendors/fancybox/source/jquery.fancybox.js","path":"vendors/fancybox/source/jquery.fancybox.js","modified":0},{"_id":"themes/freesky/source/vendors/fancybox/source/jquery.fancybox.css","path":"vendors/fancybox/source/jquery.fancybox.css","modified":0},{"_id":"themes/freesky/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0},{"_id":"themes/freesky/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0},{"_id":"themes/freesky/source/vendors/fancybox/source/helpers/jquery.fancybox-media.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-media.js","modified":0},{"_id":"themes/freesky/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0},{"_id":"themes/freesky/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0},{"_id":"themes/freesky/source/vendors/fancybox/source/helpers/fancybox_buttons.png","path":"vendors/fancybox/source/helpers/fancybox_buttons.png","modified":0},{"_id":"themes/freesky/source/vendors/fancybox/source/fancybox_sprite@2x.png","path":"vendors/fancybox/source/fancybox_sprite@2x.png","modified":0},{"_id":"themes/freesky/source/vendors/fancybox/source/fancybox_sprite.png","path":"vendors/fancybox/source/fancybox_sprite.png","modified":0},{"_id":"themes/freesky/source/vendors/fancybox/source/fancybox_overlay.png","path":"vendors/fancybox/source/fancybox_overlay.png","modified":0},{"_id":"themes/freesky/source/vendors/fancybox/source/fancybox_loading@2x.gif","path":"vendors/fancybox/source/fancybox_loading@2x.gif","modified":0},{"_id":"themes/freesky/source/vendors/fancybox/source/fancybox_loading.gif","path":"vendors/fancybox/source/fancybox_loading.gif","modified":0},{"_id":"themes/freesky/source/vendors/fancybox/source/blank.gif","path":"vendors/fancybox/source/blank.gif","modified":0},{"_id":"themes/freesky/source/js/ua-parser.min.js","path":"js/ua-parser.min.js","modified":0},{"_id":"themes/freesky/source/js/nav-toggle.js","path":"js/nav-toggle.js","modified":0},{"_id":"themes/freesky/source/js/motion_global.js","path":"js/motion_global.js","modified":0},{"_id":"themes/freesky/source/js/motion_fallback.js","path":"js/motion_fallback.js","modified":0},{"_id":"themes/freesky/source/js/lazyload.js","path":"js/lazyload.js","modified":0},{"_id":"themes/freesky/source/js/hook-duoshuo.js","path":"js/hook-duoshuo.js","modified":0},{"_id":"themes/freesky/source/js/helpers.js","path":"js/helpers.js","modified":0},{"_id":"themes/freesky/source/js/fancy-box.js","path":"js/fancy-box.js","modified":0},{"_id":"themes/freesky/source/js/bootstrap.scrollspy.js","path":"js/bootstrap.scrollspy.js","modified":0},{"_id":"themes/freesky/source/images/searchicon.png","path":"images/searchicon.png","modified":0},{"_id":"themes/freesky/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0},{"_id":"themes/freesky/source/images/loading.gif","path":"images/loading.gif","modified":0},{"_id":"themes/freesky/source/images/favicon.ico","path":"images/favicon.ico","modified":0},{"_id":"themes/freesky/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0},{"_id":"themes/freesky/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0},{"_id":"themes/freesky/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0},{"_id":"themes/freesky/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0},{"_id":"themes/freesky/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0},{"_id":"themes/freesky/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0},{"_id":"themes/freesky/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0},{"_id":"themes/freesky/source/images/bkdefault_avatar.jpg","path":"images/bkdefault_avatar.jpg","modified":0},{"_id":"themes/freesky/source/images/bg.png","path":"images/bg.png","modified":0},{"_id":"themes/freesky/source/fonts/icon-linecons/selection.json","path":"fonts/icon-linecons/selection.json","modified":0},{"_id":"themes/freesky/source/fonts/icon-linecons/icomoon.woff","path":"fonts/icon-linecons/icomoon.woff","modified":0},{"_id":"themes/freesky/source/fonts/icon-linecons/icomoon.ttf","path":"fonts/icon-linecons/icomoon.ttf","modified":0},{"_id":"themes/freesky/source/fonts/icon-linecons/icomoon.svg","path":"fonts/icon-linecons/icomoon.svg","modified":0},{"_id":"themes/freesky/source/fonts/icon-linecons/icomoon.eot","path":"fonts/icon-linecons/icomoon.eot","modified":0},{"_id":"themes/freesky/source/fonts/icon-icomoon/icomoon.woff","path":"fonts/icon-icomoon/icomoon.woff","modified":0},{"_id":"themes/freesky/source/fonts/icon-icomoon/icomoon.ttf","path":"fonts/icon-icomoon/icomoon.ttf","modified":0},{"_id":"themes/freesky/source/fonts/icon-icomoon/icomoon.svg","path":"fonts/icon-icomoon/icomoon.svg","modified":0},{"_id":"themes/freesky/source/fonts/icon-icomoon/icomoon.eot","path":"fonts/icon-icomoon/icomoon.eot","modified":0},{"_id":"themes/freesky/source/fonts/icon-fifty-shades/selection.json","path":"fonts/icon-fifty-shades/selection.json","modified":0},{"_id":"themes/freesky/source/fonts/icon-fifty-shades/icomoon.woff","path":"fonts/icon-fifty-shades/icomoon.woff","modified":0},{"_id":"themes/freesky/source/fonts/icon-fifty-shades/icomoon.ttf","path":"fonts/icon-fifty-shades/icomoon.ttf","modified":0},{"_id":"themes/freesky/source/fonts/icon-fifty-shades/icomoon.svg","path":"fonts/icon-fifty-shades/icomoon.svg","modified":0},{"_id":"themes/freesky/source/fonts/icon-fifty-shades/icomoon.eot","path":"fonts/icon-fifty-shades/icomoon.eot","modified":0},{"_id":"themes/freesky/source/fonts/icon-feather/selection.json","path":"fonts/icon-feather/selection.json","modified":0},{"_id":"themes/freesky/source/fonts/icon-feather/icomoon.woff","path":"fonts/icon-feather/icomoon.woff","modified":0},{"_id":"themes/freesky/source/fonts/icon-feather/icomoon.ttf","path":"fonts/icon-feather/icomoon.ttf","modified":0},{"_id":"themes/freesky/source/fonts/icon-feather/icomoon.svg","path":"fonts/icon-feather/icomoon.svg","modified":0},{"_id":"themes/freesky/source/fonts/icon-feather/icomoon.eot","path":"fonts/icon-feather/icomoon.eot","modified":0},{"_id":"themes/freesky/source/fonts/icon-default/selection.json","path":"fonts/icon-default/selection.json","modified":0},{"_id":"themes/freesky/source/fonts/icon-default/icomoon.woff","path":"fonts/icon-default/icomoon.woff","modified":0},{"_id":"themes/freesky/source/fonts/icon-default/icomoon.ttf","path":"fonts/icon-default/icomoon.ttf","modified":0},{"_id":"themes/freesky/source/fonts/icon-default/icomoon.svg","path":"fonts/icon-default/icomoon.svg","modified":0},{"_id":"themes/freesky/source/fonts/icon-default/icomoon.eot","path":"fonts/icon-default/icomoon.eot","modified":0},{"_id":"themes/freesky/source/css/main.styl","path":"css/main.styl","modified":0},{"_id":"source/CNAME","path":"CNAME","modified":0},{"_id":"source/resume/resume.pdf","path":"resume/resume.pdf","modified":0},{"_id":"source/resume/resume-pdf.pdf","path":"resume/resume-pdf.pdf","modified":0},{"_id":"source/images/favicon2.ico","path":"images/favicon2.ico","modified":0},{"_id":"source/images/favicon1.ico","path":"images/favicon1.ico","modified":0},{"_id":"source/images/favicon.ico","path":"images/favicon.ico","modified":0},{"_id":"source/images/default_avatar.jpg","path":"images/default_avatar.jpg","modified":0},{"_id":"source/images/bg.png","path":"images/bg.png","modified":0},{"_id":"source/assets/svg/feature engineering.svg","path":"assets/svg/feature engineering.svg","modified":0},{"_id":"source/assets/pdf/Slope One.pdf","path":"assets/pdf/Slope One.pdf","modified":0},{"_id":"source/assets/pdf/How to Select a Good Training-data Subset for Transcriptionsubmodular active selection from sequences.pdf","path":"assets/pdf/How to Select a Good Training-data Subset for Transcriptionsubmodular active selection from sequences.pdf","modified":0},{"_id":"source/assets/pdf/Full-CheatSheet-on-Machine-Learning-Algorithms(Python-and-R-Codes).pdf","path":"assets/pdf/Full-CheatSheet-on-Machine-Learning-Algorithms(Python-and-R-Codes).pdf","modified":0},{"_id":"source/assets/pdf/A Few Useful Things to Know about Machine Learning.pdf","path":"assets/pdf/A Few Useful Things to Know about Machine Learning.pdf","modified":0},{"_id":"source/assets/pdf/2009- Learning from Imbalanced Data.pdf","path":"assets/pdf/2009- Learning from Imbalanced Data.pdf","modified":0},{"_id":"source/assets/images/zhifubao_denote.jpg","path":"assets/images/zhifubao_denote.jpg","modified":0},{"_id":"source/assets/images/weixin_denote.jpg","path":"assets/images/weixin_denote.jpg","modified":0},{"_id":"source/assets/images/submolarity.png","path":"assets/images/submolarity.png","modified":0},{"_id":"source/assets/images/pca.png","path":"assets/images/pca.png","modified":0},{"_id":"source/assets/images/navigate1.png","path":"assets/images/navigate1.png","modified":0},{"_id":"source/assets/images/navigate0.png","path":"assets/images/navigate0.png","modified":0},{"_id":"source/assets/images/navigate.png","path":"assets/images/navigate.png","modified":0},{"_id":"source/assets/images/feature selection.png","path":"assets/images/feature selection.png","modified":0},{"_id":"source/assets/images/feature engineering.tif","path":"assets/images/feature engineering.tif","modified":0},{"_id":"source/assets/images/feature engineering.png","path":"assets/images/feature engineering.png","modified":0},{"_id":"source/assets/images/face.jpg","path":"assets/images/face.jpg","modified":0},{"_id":"source/assets/images/face-h200.jpg","path":"assets/images/face-h200.jpg","modified":0},{"_id":"source/assets/images/denote.xcf","path":"assets/images/denote.xcf","modified":0},{"_id":"source/assets/images/denote.jpg","path":"assets/images/denote.jpg","modified":0},{"_id":"source/assets/images/2015111502.png","path":"assets/images/2015111502.png","modified":0},{"_id":"source/assets/images/2015111501.png","path":"assets/images/2015111501.png","modified":0},{"_id":"source/assets/images/20151029183224.png","path":"assets/images/20151029183224.png","modified":0},{"_id":"source/assets/images/20151029094653.png","path":"assets/images/20151029094653.png","modified":0},{"_id":"source/assets/docs/Merge-sort.docx","path":"assets/docs/Merge-sort.docx","modified":0},{"_id":"source/assets/blogImg/face.png","path":"assets/blogImg/face.png","modified":0},{"_id":"source/assets/blogImg/devin.png","path":"assets/blogImg/devin.png","modified":0},{"_id":"source/assets/articleImg/roc_plot.gif","path":"assets/articleImg/roc_plot.gif","modified":0},{"_id":"source/assets/articleImg/pca_ica.png","path":"assets/articleImg/pca_ica.png","modified":0},{"_id":"source/assets/articleImg/logit_sgd.png","path":"assets/articleImg/logit_sgd.png","modified":0},{"_id":"source/assets/articleImg/k_clusters4.png","path":"assets/articleImg/k_clusters4.png","modified":0},{"_id":"source/assets/articleImg/hinge.png","path":"assets/articleImg/hinge.png","modified":0},{"_id":"source/assets/articleImg/hinge.jpg","path":"assets/articleImg/hinge.jpg","modified":0},{"_id":"source/assets/articleImg/bias_variance.png","path":"assets/articleImg/bias_variance.png","modified":0},{"_id":"source/assets/articleImg/area_under_curve.png","path":"assets/articleImg/area_under_curve.png","modified":0},{"_id":"source/assets/articleImg/Newton_optimization_vs_grad_descent.svg","path":"assets/articleImg/Newton_optimization_vs_grad_descent.svg","modified":0},{"_id":"source/assets/articleImg/Max_paraboloid.svg","path":"assets/articleImg/Max_paraboloid.svg","modified":0},{"_id":"source/assets/articleImg/4DFDU.png","path":"assets/articleImg/4DFDU.png","modified":0},{"_id":"source/assets/articleImg/2016-01-01-img5.png","path":"assets/articleImg/2016-01-01-img5.png","modified":0},{"_id":"source/assets/articleImg/2016-01-01-img4.png","path":"assets/articleImg/2016-01-01-img4.png","modified":0},{"_id":"source/assets/articleImg/2016-01-01-img3.png","path":"assets/articleImg/2016-01-01-img3.png","modified":0},{"_id":"source/assets/articleImg/2016-01-01-img2.png","path":"assets/articleImg/2016-01-01-img2.png","modified":0},{"_id":"source/assets/articleImg/2016-01-01-img1.png","path":"assets/articleImg/2016-01-01-img1.png","modified":0},{"_id":"source/assets/articleImg/2015-12-31-tiedao1.jpg","path":"assets/articleImg/2015-12-31-tiedao1.jpg","modified":0},{"_id":"source/assets/articleImg/2015-12-31-movie_all1.jpg","path":"assets/articleImg/2015-12-31-movie_all1.jpg","modified":0},{"_id":"source/assets/articleImg/2015-12-31-lab-morning.jpg","path":"assets/articleImg/2015-12-31-lab-morning.jpg","modified":0},{"_id":"source/assets/articleImg/2015-12-31-huatian.jpg","path":"assets/articleImg/2015-12-31-huatian.jpg","modified":0},{"_id":"source/assets/articleImg/2015-12-31-desktop.jpg","path":"assets/articleImg/2015-12-31-desktop.jpg","modified":0},{"_id":"source/assets/articleImg/2015-12-31-bagong.jpg","path":"assets/articleImg/2015-12-31-bagong.jpg","modified":0},{"_id":"source/assets/articleImg/2015-12-21-machine-learning-algorithms_2.jpg","path":"assets/articleImg/2015-12-21-machine-learning-algorithms_2.jpg","modified":0},{"_id":"source/assets/articleImg/2015-12-21-machine-learning-algorithms_1.jpg","path":"assets/articleImg/2015-12-21-machine-learning-algorithms_1.jpg","modified":0},{"_id":"source/assets/articleImg/2015-12-12-leetcode.png","path":"assets/articleImg/2015-12-12-leetcode.png","modified":0},{"_id":"source/assets/articleImg/2015-12-02-p3.png","path":"assets/articleImg/2015-12-02-p3.png","modified":0},{"_id":"source/assets/articleImg/2015-12-02-p2.png","path":"assets/articleImg/2015-12-02-p2.png","modified":0},{"_id":"source/assets/articleImg/2015-12-02-gs9.png","path":"assets/articleImg/2015-12-02-gs9.png","modified":0},{"_id":"source/assets/articleImg/2015-12-02-gs8.png","path":"assets/articleImg/2015-12-02-gs8.png","modified":0},{"_id":"source/assets/articleImg/2015-12-02-gs7.png","path":"assets/articleImg/2015-12-02-gs7.png","modified":0},{"_id":"source/assets/articleImg/2015-12-02-gs6.png","path":"assets/articleImg/2015-12-02-gs6.png","modified":0},{"_id":"source/assets/articleImg/2015-12-02-gs5.png","path":"assets/articleImg/2015-12-02-gs5.png","modified":0},{"_id":"source/assets/articleImg/2015-12-02-gs4.png","path":"assets/articleImg/2015-12-02-gs4.png","modified":0},{"_id":"source/assets/articleImg/2015-12-02-gs3.png","path":"assets/articleImg/2015-12-02-gs3.png","modified":0},{"_id":"source/assets/articleImg/2015-12-02-gs2.png","path":"assets/articleImg/2015-12-02-gs2.png","modified":0},{"_id":"source/assets/articleImg/2015-12-02-gs11.png","path":"assets/articleImg/2015-12-02-gs11.png","modified":0},{"_id":"source/assets/articleImg/2015-12-02-gs10.png","path":"assets/articleImg/2015-12-02-gs10.png","modified":0},{"_id":"source/assets/articleImg/2015-12-02-gs1.png","path":"assets/articleImg/2015-12-02-gs1.png","modified":0},{"_id":"source/assets/articleImg/2015-12-02-Jensen-inequality.png","path":"assets/articleImg/2015-12-02-Jensen-inequality.png","modified":0},{"_id":"source/assets/articleImg/2015-12-02-EM_Clustering_of_Old_Faithful_data.gif","path":"assets/articleImg/2015-12-02-EM_Clustering_of_Old_Faithful_data.gif","modified":0},{"_id":"source/assets/articleImg/2015-11-25-data-scientist-work-diagram.png","path":"assets/articleImg/2015-11-25-data-scientist-work-diagram.png","modified":0},{"_id":"source/assets/articleImg/2015-07-21 randomForest分类器的方法png.png","path":"assets/articleImg/2015-07-21 randomForest分类器的方法png.png","modified":0},{"_id":"source/assets/articleImg/2014-12-21-performances-of-sort-algs.png","path":"assets/articleImg/2014-12-21-performances-of-sort-algs.png","modified":0},{"_id":"source/assets/articleImg/2014-12-21-mergeSort-2.png","path":"assets/articleImg/2014-12-21-mergeSort-2.png","modified":0},{"_id":"source/assets/articleImg/2014-12-21-mergeSort-1.png","path":"assets/articleImg/2014-12-21-mergeSort-1.png","modified":0},{"_id":"source/assets/articleImg/2014-12-21-insert-sort.png","path":"assets/articleImg/2014-12-21-insert-sort.png","modified":0},{"_id":"source/README","path":"README","modified":0},{"_id":"source/assets/articleImg/2016-04-02-1.jpg","path":"assets/articleImg/2016-04-02-1.jpg","modified":0},{"_id":"source/assets/articleImg/2016-04-02-2.jpg","path":"assets/articleImg/2016-04-02-2.jpg","modified":0},{"_id":"source/assets/articleImg/2016-04-02-0.jpg","path":"assets/articleImg/2016-04-02-0.jpg","modified":0},{"_id":"source/assets/articleImg/2016-04-02-3.jpg","path":"assets/articleImg/2016-04-02-3.jpg","modified":0},{"_id":"source/README.txt","path":"README.txt","modified":0},{"_id":"source/assets/articleImg/170.jpg","path":"assets/articleImg/170.jpg","modified":0}],"Cache":[{"_id":"themes/freesky/source/css/_common/_page/home.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1446648948000},{"_id":"themes/freesky/source/css/_mixins/Mist.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1446648949000},{"_id":"themes/freesky/source/css/_mixins/custom.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1446648949000},{"_id":"themes/freesky/source/css/_mixins/default.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1446648949000},{"_id":"themes/freesky/source/css/_variables/custom.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1446648949000},{"_id":"themes/freesky/source/css/_variables/default.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1446648949000},{"_id":"themes/freesky/README.md","shasum":"5a4d639cab24e85a51752a0d0509655c1200f1e8","modified":1446648938000},{"_id":"themes/freesky/bower.json","shasum":"f1e262dea42567b2df0d1d0476eac58d7614dcad","modified":1446648938000},{"_id":"themes/freesky/languages/de.yml","shasum":"3af67eda28640a99e17d06eec0c664e54e95fb2d","modified":1446648947000},{"_id":"themes/freesky/languages/default.yml","shasum":"513c22371c3085224c466c10c6b1dd2735877f04","modified":1446648947000},{"_id":"themes/freesky/languages/en.yml","shasum":"513c22371c3085224c466c10c6b1dd2735877f04","modified":1446648947000},{"_id":"themes/freesky/languages/pt.yml","shasum":"18735138d4bf19e31c65276f9d7d25f49732a9cf","modified":1446648947000},{"_id":"themes/freesky/languages/ru.yml","shasum":"be6821b00c20dfe15717415fca3b1a5d719f4014","modified":1446648947000},{"_id":"themes/freesky/languages/zh-Hans.yml","shasum":"b7d8ec1129f9843b546c64284684a3d08378757f","modified":1446648947000},{"_id":"themes/freesky/languages/fr-FR.yml","shasum":"694980cca651eca633fec7f63da6e69070a28669","modified":1446648947000},{"_id":"themes/freesky/languages/zh-tw.yml","shasum":"9fd6f672e503c50d6cc004df178387fc10be62db","modified":1446648947000},{"_id":"themes/freesky/layout/_macro/about.swig","shasum":"924ce2a21ffd5c888411d3846cb1df9cee59e8c1","modified":1446648947000},{"_id":"themes/freesky/languages/zh-hk.yml","shasum":"a36d81d609bb0fbfb1ca5f264c6e1c0d95fb9fae","modified":1446648947000},{"_id":"themes/freesky/layout/_macro/post.swig","shasum":"3cb1614524ce5f9904a20bd1b6ef511411e25517","modified":1459562655907},{"_id":"themes/freesky/layout/_layout.swig","shasum":"daf79383debd8d086cd3ec5d6ba2c0f37e8af3da","modified":1458284375286},{"_id":"themes/freesky/layout/_macro/sidebar.swig","shasum":"83536fac60881b2b415fe3c095aba6facc4b2d5e","modified":1446648947000},{"_id":"themes/freesky/_config.yml","shasum":"2febf3b2f586b90d658428e8b6875bb1081cbde7","modified":1456189353020},{"_id":"themes/freesky/layout/_macro/post-collapse.swig","shasum":"60766ca0cf5ba834d445c3304695d1a7ce0e1a36","modified":1446648947000},{"_id":"themes/freesky/layout/_macro/archive-collapse.swig","shasum":"2e5a0b699a7ac58b49d487a5dcda10c1a76bc8df","modified":1446648947000},{"_id":"themes/freesky/layout/_partials/pagination.swig","shasum":"1634fb887842698e01ff6e632597fe03c75d2d01","modified":1457849397250},{"_id":"themes/freesky/layout/_partials/search/swiftype.swig","shasum":"73e8294939bbbb46755798215c605ebe5af5918f","modified":1446648947000},{"_id":"themes/freesky/layout/_partials/search/tinysou.swig","shasum":"b25002a83cbd2ca0c4a5df87ad5bff26477c0457","modified":1446648947000},{"_id":"themes/freesky/layout/_partials/footer.swig","shasum":"e3176b33213bb7cd04124022b4f13b6684c55a5b","modified":1459912254898},{"_id":"themes/freesky/layout/_partials/search.swig","shasum":"1b86eb85017599392071d1230171e900045f8e69","modified":1446648947000},{"_id":"themes/freesky/layout/_partials/header.swig","shasum":"9229665949fe164f3de17a9ce98ada7bb9979299","modified":1458011212197},{"_id":"themes/freesky/layout/_partials/head.swig","shasum":"0e7a3b7e91051198e871ef5628a91d621c04928f","modified":1458284379917},{"_id":"themes/freesky/layout/_scripts/analytics/baidu-analytics.swig","shasum":"ae5b8597603d4e42ee66ed121544e7b1c644767e","modified":1446648948000},{"_id":"themes/freesky/layout/_scripts/analytics/google-analytics.swig","shasum":"1b6af02fd0ba3f729675cd95429a0cea4aebf358","modified":1446648948000},{"_id":"themes/freesky/layout/_scripts/analytics.swig","shasum":"5e1b2b547a8f07ea0e3ab2a97dac9cc7d1e13c9a","modified":1446648947000},{"_id":"themes/freesky/layout/_scripts/analytics/facebook-sdk.swig","shasum":"61347b9cf5c42a02f28cda4b6d920d6d17099d44","modified":1446648948000},{"_id":"themes/freesky/layout/_scripts/bootstrap.scrollspy.swig","shasum":"0aad8d447567b683108b274c841c536b2daa176d","modified":1446648947000},{"_id":"themes/freesky/layout/_partials/share/jiathis.swig","shasum":"12684840de632eb16e53ffa863166306a756fd4f","modified":1446648947000},{"_id":"themes/freesky/layout/_scripts/baidushare.swig","shasum":"640d4dda003f54a0dffa4508fba4d91ac0dcfa6e","modified":1446648947000},{"_id":"themes/freesky/layout/_partials/share/duoshuo_share.swig","shasum":"d4fbffd7fa8f2090eb32a871872665d90a885fac","modified":1446648947000},{"_id":"themes/freesky/layout/_scripts/helpers.swig","shasum":"4d2cbfca0aaf546a2b5813288073e824c1498fdf","modified":1446648947000},{"_id":"themes/freesky/layout/_scripts/comments/duoshuo.swig","shasum":"c5643f07b121051460331489ab399137d2feb4b7","modified":1446648948000},{"_id":"themes/freesky/layout/_scripts/motion.swig","shasum":"40439a4d4c8e8c2218da84ee1e586e11db9837be","modified":1446648947000},{"_id":"themes/freesky/layout/_scripts/comments/disqus.swig","shasum":"c1186e609d4810ebfb3e675e9045b023a557d1db","modified":1446648948000},{"_id":"themes/freesky/layout/_partials/old-browsers.swig","shasum":"3c4d930d34c234725065173780a23673e1c574f5","modified":1446648947000},{"_id":"themes/freesky/layout/_scripts/fancy-box.swig","shasum":"701dfc53d750635de2f08f08d072d6ceb83b636c","modified":1446648947000},{"_id":"themes/freesky/layout/_scripts/pages/post-details.swig","shasum":"3ac70198258ab3c2bceca452864b68cc14a9debf","modified":1446648948000},{"_id":"themes/freesky/layout/_scripts/tinysou.swig","shasum":"fe95dd3d166634c466e19aa756e65ad6e8254d3e","modified":1446648947000},{"_id":"themes/freesky/layout/_scripts/mathjax.swig","shasum":"e113e497075ac8681c665a7831657901cfa4fb68","modified":1446648947000},{"_id":"themes/freesky/layout/category.swig","shasum":"a995b082f2fd9fcac604068c4558bdeafa5ba731","modified":1446648947000},{"_id":"themes/freesky/layout/index.swig","shasum":"836631665db2b37639028fbc3aaa0b96f059e45c","modified":1447603712492},{"_id":"themes/freesky/layout/about.swig","shasum":"463ae664816472351bf64e43de321a5a7b7fc75d","modified":1446648947000},{"_id":"themes/freesky/layout/post.swig","shasum":"e67a6aabe4d71cbcf01a4cace652424bd49acc9b","modified":1446648947000},{"_id":"themes/freesky/scripts/merge-configs.js","shasum":"2a47a2eb10c4491beffa8c5dd2a04cdb493ee80c","modified":1446648948000},{"_id":"themes/freesky/scripts/tags/center-quote.js","shasum":"99b66949f18398689b904907af23c013be1b978f","modified":1446648948000},{"_id":"themes/freesky/scripts/tags/full-image.js","shasum":"d44c660d4d6f61a17d5a19e195efa2241ee53c83","modified":1446648948000},{"_id":"themes/freesky/scripts/tags/group-pictures.js","shasum":"ac681b0d0d8d39ba3817336c0270c6787c2b6b70","modified":1446648948000},{"_id":"themes/freesky/source/css/_common/_component/back-to-top.styl","shasum":"b283ea4852d332336dc05fa2ad9f70f010207fe8","modified":1457873116023},{"_id":"themes/freesky/source/css/_common/_component/buttons.styl","shasum":"cda511bbc13b1f54019a40d02089705d8945eccd","modified":1446648948000},{"_id":"themes/freesky/layout/page.swig","shasum":"a91e3fd7aef26e8a02e339e3372801c517f400cf","modified":1446648947000},{"_id":"themes/freesky/source/css/_common/_component/comments.styl","shasum":"ff4489cd582f518bba6909a301ac1292a38b4e96","modified":1446648948000},{"_id":"themes/freesky/layout/archive.swig","shasum":"38af820daba7b9fd76050acdde4ba0ca5ac45d91","modified":1457856248805},{"_id":"themes/freesky/source/css/_common/_component/gallery.styl","shasum":"cd9e214e502697f2f2db84eb721bac57a49b0fce","modified":1446648948000},{"_id":"themes/freesky/source/css/_common/_component/jiathis.styl","shasum":"15975ba7456b96916b1dbac448a1a0d2c38b8f3d","modified":1446648948000},{"_id":"themes/freesky/source/css/_common/_component/group-pictures.styl","shasum":"2a268e0b667c923b95cb562c904dca094cd3707b","modified":1446648948000},{"_id":"themes/freesky/source/css/_common/_component/duoshuo.styl","shasum":"76e8e6f5200e5e6063be6643c1cf340a51af6619","modified":1446648948000},{"_id":"themes/freesky/source/css/_common/_component/posts-type.styl","shasum":"f28f00b2acb0df0343e77400bcc8246b40ac046c","modified":1446648948000},{"_id":"themes/freesky/source/css/_common/_component/posts-expand.styl","shasum":"e7c3deb3cbb2a483501749baba53160a88de9f31","modified":1457832192375},{"_id":"themes/freesky/source/css/_common/_component/tag-cloud.styl","shasum":"3e552a58bd61804c6a443bb6c7ff597163a34da5","modified":1457830292251},{"_id":"themes/freesky/source/css/_common/_component/posts.styl","shasum":"abe394c5fbdd77e58df10c00d8a7dea7eeae8b30","modified":1446648948000},{"_id":"themes/freesky/layout/tag.swig","shasum":"0b0a089f84e4e80433283e7772de95ce0d22f5e8","modified":1446648947000},{"_id":"themes/freesky/source/css/_common/_component/posts-collapse.styl","shasum":"9df61e9f7d4ed30bfea5bc60ab79fe05d18e4415","modified":1446731252137},{"_id":"themes/freesky/source/css/_common/_core/helpers.styl","shasum":"a03ae3bab457bf4ee0771e9326468ace5f959c2f","modified":1446648948000},{"_id":"themes/freesky/source/css/_common/_core/base.styl","shasum":"3a35f6576b9b9652232df65a54e0754df6fea7ba","modified":1451560137840},{"_id":"themes/freesky/source/css/_common/_core/scaffolding.styl","shasum":"83a8dee9ef7e9d4b4b48107f07816157bc7da2fe","modified":1457830184343},{"_id":"themes/freesky/source/css/_common/_core/normalize.styl","shasum":"3f40e8a9fe8e7bd5cfc4cf4cbbbcb9539462e973","modified":1446648948000},{"_id":"themes/freesky/source/css/_common/_component/pagination.styl","shasum":"9844b7aea0da6527136417c51aa8dea7af377b0c","modified":1457831122287},{"_id":"themes/freesky/source/css/_common/_fonts/icon-feather.styl","shasum":"7bdc92a55f2eee20b6b546e93e4566696b459b9d","modified":1446648948000},{"_id":"themes/freesky/source/css/_common/_fonts/icon-default.styl","shasum":"c46d16429b85570347373fd11db8c222f6ff914e","modified":1446648948000},{"_id":"themes/freesky/source/css/_common/_core/tables.styl","shasum":"16a98866f5025c050c56e52312228355a16d00d9","modified":1446648948000},{"_id":"themes/freesky/source/css/_common/_page/archive.styl","shasum":"c324a9eff22b4e81e0280ba0aa5757e1f47e2f2f","modified":1446648948000},{"_id":"themes/freesky/source/css/_common/_fonts/icon-fifty-shades.styl","shasum":"dbb0843ea5aa7c2ac2755a2d1ce60fa662f1b939","modified":1446648948000},{"_id":"themes/freesky/source/css/_common/_page/post-detail.styl","shasum":"70464ceb64c4239af590f99ef319747d3d1f100b","modified":1457831649809},{"_id":"themes/freesky/source/css/_common/_fonts/icon-linecons.styl","shasum":"a9f5260198225801eb5c16345a69a7e3cab904fe","modified":1446648948000},{"_id":"themes/freesky/source/css/_common/_section/body.styl","shasum":"6eaa5d9cb08ecfb2d377a475e541e41fbfe4c1b6","modified":1446648948000},{"_id":"themes/freesky/source/css/_common/_fonts/icon-font.styl","shasum":"692c01dcdc612c3e1e245cf93d0ace0a4e2aaf3f","modified":1446648948000},{"_id":"themes/freesky/source/css/_common/_section/footer.styl","shasum":"12b794975ab057be78abef8b0428e5060f75ca69","modified":1457831053082},{"_id":"themes/freesky/source/css/_common/_section/media.styl","shasum":"f2f57f73aaa92058b5a8727c22445fda4b27f709","modified":1449057752982},{"_id":"themes/freesky/source/css/_common/_page/categories.styl","shasum":"926123c3305faddc385a1cc73e7a5fd463fadc18","modified":1457831559050},{"_id":"themes/freesky/source/css/_common/_section/header.styl","shasum":"7b6f5ad7df202858e9aaed35067f5a8f0fb20859","modified":1457866738370},{"_id":"themes/freesky/source/css/_common/_vendor/highlight/highlight.styl","shasum":"5297dfee4728b736f175c3a159699ceb93342cad","modified":1449210958058},{"_id":"themes/freesky/source/css/_custom/custom.styl","shasum":"3403fdd8efde1a0afd11ae8a5a97673f5903087f","modified":1446648949000},{"_id":"themes/freesky/source/css/_common/_vendor/highlight/theme.styl","shasum":"9f0606d4d94ffa6bd77f91628507bba19133cf36","modified":1446648949000},{"_id":"themes/freesky/source/css/_common/_section/layout.styl","shasum":"a22541947ffcf7cd35da9332036641fe2f8ddbb1","modified":1446648948000},{"_id":"themes/freesky/source/css/_schemes/Mist/_logo.styl","shasum":"b1025c421406d2c24cc92a02ae28c1915b01e240","modified":1446648949000},{"_id":"themes/freesky/source/css/_mixins/base.styl","shasum":"10ca6744a8594c1a085b50120f4ed0a1ef433f40","modified":1446648949000},{"_id":"themes/freesky/source/css/_schemes/Mist/_header.styl","shasum":"b023ed45e11107befe023c4cf0efb9eb966050c3","modified":1446648949000},{"_id":"themes/freesky/source/css/_schemes/Mist/_menu.styl","shasum":"490805fe7022ceb708d2b81078d024b58c1edea9","modified":1446648949000},{"_id":"themes/freesky/source/css/_schemes/Mist/_base.styl","shasum":"e4b5b56e1a035c99ebd50d00e93d89e2e8d0b735","modified":1446648949000},{"_id":"themes/freesky/source/css/_schemes/Mist/_posts-expanded.styl","shasum":"003b28a25eb53c1c06809de7a92870cc6d9a6cf9","modified":1446648949000},{"_id":"themes/freesky/source/css/_schemes/default/_menu.styl","shasum":"dd667be3f5f24cebdc15d0262c7d397f23d751c5","modified":1446648949000},{"_id":"themes/freesky/source/css/_schemes/default/index.styl","shasum":"ecd76494cea5fbf592cc13ba1e4ccdfedbc5bf1b","modified":1446648949000},{"_id":"themes/freesky/source/css/_schemes/default/_logo.styl","shasum":"748dbfbf9c08e719ddc775958003c64b00d39dab","modified":1446648949000},{"_id":"themes/freesky/source/css/_variables/base.styl","shasum":"056e704b4ebb08d938da1fbe9484ae47ac0658d7","modified":1457831827651},{"_id":"themes/freesky/source/css/main.styl","shasum":"0424a4e51413da2366acbd26b54da55a3c650891","modified":1446648948000},{"_id":"themes/freesky/source/fonts/icon-default/icomoon.eot","shasum":"90763e97be18be78e65749075225cceeddc6fa8a","modified":1446648949000},{"_id":"themes/freesky/source/css/_variables/Mist.styl","shasum":"306149f2f2afe2a7c0277ee3f5116603c6eb8863","modified":1446648949000},{"_id":"themes/freesky/source/css/_schemes/Mist/index.styl","shasum":"f10be4b0c642104a6f533b94ac09e22019aa640e","modified":1446648949000},{"_id":"themes/freesky/source/css/_schemes/default/_search.styl","shasum":"e315ee6f604c2bcc44a5ef9078f5ce420c153a4b","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-default/icomoon.woff","shasum":"dbe0368f2a65d87b13234cfea29d9783892fc7a8","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-default/icomoon.ttf","shasum":"c093408e6030221cafc1f79d897f1fb5283c1178","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-default/icomoon.svg","shasum":"a2682f9b0a2647ec5cc35201ba37b0aceba86bcf","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-default/selection.json","shasum":"f05d514de60469cb8b77ab6dd68335d3de980377","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-feather/icomoon.eot","shasum":"11554b9e9d5b9f535ba96cbb27d45d8c8f1689fd","modified":1446648949000},{"_id":"themes/freesky/source/css/_common/_section/sidebar.styl","shasum":"473534c02ab0fcf050ea3e4939768863426c35a1","modified":1457874336123},{"_id":"themes/freesky/source/fonts/icon-feather/icomoon.woff","shasum":"2ea1c59c17422798e64ee6f4e9ce1f7aff1a06a5","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-feather/icomoon.ttf","shasum":"b2bbae4b613403cf61ad25037913378da1c07b8f","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-feather/selection.json","shasum":"9a69a90c394f690f96758e0b012d0f85fdbb5d31","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-fifty-shades/icomoon.eot","shasum":"da86ba5df72d1288de9e9633e5f528062dd427d5","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-fifty-shades/icomoon.ttf","shasum":"72fe82e1f3db52414eed706952d385af241cb196","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-fifty-shades/icomoon.svg","shasum":"021bab3a7cb80aaaead0aceeb23a324256470b22","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-icomoon/icomoon.svg","shasum":"51ca86690d0294529bb9a736984e7fa718d15933","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-feather/icomoon.svg","shasum":"a701877262c33bd521204de4eaf842294a294ca7","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-icomoon/icomoon.eot","shasum":"301fcf00c24750dddf1c529f944ca62c7f1a217d","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-icomoon/icomoon.ttf","shasum":"f399713d1c9400d4d3373e38991a7e362a754a94","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-icomoon/icomoon.woff","shasum":"05f1ec0bd307da5e731a86eb4961589a6042aebb","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-linecons/icomoon.eot","shasum":"e2d7f040428a632f3c50bfa94083b759936effc2","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-fifty-shades/selection.json","shasum":"bc7767511444b4bc79c7e986ccd8b0a38dcd1541","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-linecons/icomoon.svg","shasum":"85371b5563515a4f3eed0690653a0c35ee0b9d99","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-fifty-shades/icomoon.woff","shasum":"4de6a74f523dee33d95dde61caae5809f9a5d448","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-linecons/icomoon.ttf","shasum":"078068206684e4f185b0187ad3cee16f54a287d7","modified":1446648949000},{"_id":"themes/freesky/source/fonts/icon-linecons/selection.json","shasum":"8fb52012770b4745b18b43850737585d24a689cf","modified":1446648950000},{"_id":"themes/freesky/source/fonts/icon-linecons/icomoon.woff","shasum":"0b07ee6ceda3b1bceb40c1e7379b3aa48dcc15a8","modified":1446648950000},{"_id":"themes/freesky/source/images/cc-by-nc-nd.svg","shasum":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1446648950000},{"_id":"themes/freesky/source/images/cc-by-nc.svg","shasum":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1446648950000},{"_id":"themes/freesky/source/images/cc-by-nd.svg","shasum":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1446648950000},{"_id":"themes/freesky/source/images/bkdefault_avatar.jpg","shasum":"b687bb4bfbe35a32b592c24d652ba80cfdc770fc","modified":1446648950000},{"_id":"themes/freesky/source/images/cc-by-sa.svg","shasum":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1446648950000},{"_id":"themes/freesky/source/images/loading.gif","shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1446648950000},{"_id":"themes/freesky/source/images/placeholder.gif","shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1446648950000},{"_id":"themes/freesky/source/images/favicon.ico","shasum":"5c713499ccd8054767a01337f6ff9b86168f30cf","modified":1446648950000},{"_id":"themes/freesky/source/images/cc-by-nc-sa.svg","shasum":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1446648950000},{"_id":"themes/freesky/source/js/bootstrap.scrollspy.js","shasum":"97640be11a524b203781c1a03f623ef0b9195a02","modified":1446648950000},{"_id":"themes/freesky/source/images/cc-zero.svg","shasum":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1446648950000},{"_id":"themes/freesky/source/js/fancy-box.js","shasum":"b980c3f972d190fa17d25b1cb11459b47f92d9c5","modified":1446648950000},{"_id":"themes/freesky/source/js/hook-duoshuo.js","shasum":"ea30e91c6b7fdaa6dce4a848f25cdf90436b072a","modified":1446648950000},{"_id":"themes/freesky/source/js/helpers.js","shasum":"092d54b791af7c4a11b1496294dd3259259058b6","modified":1446648950000},{"_id":"themes/freesky/source/images/cc-by.svg","shasum":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1446648950000},{"_id":"themes/freesky/source/js/motion_global.js","shasum":"e52aa9067bbd28a1f9d1f5a9503e734ec3cfdd91","modified":1455769006892},{"_id":"themes/freesky/source/js/nav-toggle.js","shasum":"43c86778408a2c0c97c2f34838687d3dcb018ad4","modified":1446648950000},{"_id":"themes/freesky/source/js/motion_fallback.js","shasum":"bff3d62933345bb9bba962332b8c3d31f7b01579","modified":1446648950000},{"_id":"themes/freesky/source/vendors/fancybox/source/blank.gif","shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1446648950000},{"_id":"themes/freesky/source/js/lazyload.js","shasum":"dd94f7e88df11a1d760ca9994e21a58c07974fb2","modified":1446648950000},{"_id":"themes/freesky/source/vendors/fancybox/source/fancybox_loading@2x.gif","shasum":"273b123496a42ba45c3416adb027cd99745058b0","modified":1446648950000},{"_id":"themes/freesky/source/images/searchicon.png","shasum":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1446648950000},{"_id":"themes/freesky/source/vendors/fancybox/source/fancybox_sprite@2x.png","shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1446648950000},{"_id":"themes/freesky/source/js/ua-parser.min.js","shasum":"acf0ee6a47ffb7231472b56e43996e3f947c258a","modified":1446648950000},{"_id":"themes/freesky/source/vendors/fancybox/source/fancybox_loading.gif","shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1446648950000},{"_id":"themes/freesky/source/vendors/fancybox/source/fancybox_sprite.png","shasum":"17df19f97628e77be09c352bf27425faea248251","modified":1446648950000},{"_id":"themes/freesky/source/vendors/fancybox/source/helpers/jquery.fancybox-media.js","shasum":"51139a4c79573d372a347ef01a493222a1eaf10a","modified":1446648950000},{"_id":"themes/freesky/source/vendors/fancybox/source/fancybox_overlay.png","shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1446648950000},{"_id":"themes/freesky/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","shasum":"6394c48092085788a8c0ef72670b0652006231a1","modified":1446648950000},{"_id":"themes/freesky/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","shasum":"ee948b4489aedeb548a77c9e45d8c7c5732fd62d","modified":1446648950000},{"_id":"themes/freesky/source/vendors/fancybox/source/jquery.fancybox.css","shasum":"82f33ad0842aa9c154d029e0dada2497d4eb1d57","modified":1446648950000},{"_id":"themes/freesky/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","shasum":"d22b1629cb23a6181bebb70d0cf653ffe4b835c8","modified":1446648950000},{"_id":"themes/freesky/source/vendors/fastclick/LICENSE","shasum":"6f474ea75c42442da7bbcf2e9143ce98258efd8d","modified":1446648950000},{"_id":"themes/freesky/source/vendors/fastclick/README.md","shasum":"68a9b9d53126405b0fa5f3324f1fb96dbcc547aa","modified":1446648950000},{"_id":"themes/freesky/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","shasum":"b88b589f5f1aa1b3d87cc7eef34c281ff749b1ae","modified":1446648950000},{"_id":"themes/freesky/source/vendors/fastclick/bower.json","shasum":"a9b3ee1e4db71a0e4ea6d5bed292d176dd68b261","modified":1446648950000},{"_id":"themes/freesky/source/vendors/fancybox/source/jquery.fancybox.js","shasum":"d71602cbca33b9ecdb7ab291b7f86a49530f3601","modified":1446648950000},{"_id":"themes/freesky/source/vendors/fancybox/source/helpers/fancybox_buttons.png","shasum":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1446648950000},{"_id":"themes/freesky/source/vendors/font-awesome/HELP-US-OUT.txt","shasum":"ed80b43dbc7e3009b2f436741b9796df8eb3be02","modified":1446648951000},{"_id":"themes/freesky/source/vendors/font-awesome/bower.json","shasum":"71e7183634dc1b9449f590f15ebd7201add22ca7","modified":1446648950000},{"_id":"themes/freesky/source/vendors/font-awesome/css/font-awesome.css","shasum":"811432ad1e2d6c1f6da9a63fd919bf2a02b71dd9","modified":1446648951000},{"_id":"themes/freesky/source/vendors/fancybox/source/jquery.fancybox.pack.js","shasum":"ae6318aeb62ad4ce7a7e9a4cdacd93ffb004f0fb","modified":1446648950000},{"_id":"themes/freesky/source/vendors/font-awesome/css/font-awesome.min.css","shasum":"4c2c5f5f6cc86d775a44b944661e038b7be98149","modified":1446648951000},{"_id":"themes/freesky/source/vendors/fastclick/lib/fastclick.min.js","shasum":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1446648950000},{"_id":"themes/freesky/source/vendors/font-awesome/fonts/fontawesome-webfont.woff2","shasum":"574ea2698c03ae9477db2ea3baf460ee32f1a7ea","modified":1446648951000},{"_id":"themes/freesky/source/vendors/fastclick/lib/fastclick.js","shasum":"1d6aeda0480d0e4cb6198edf7719d601d4ae2ccc","modified":1446648950000},{"_id":"themes/freesky/source/vendors/font-awesome/css/font-awesome.css.map","shasum":"1573904b82807abbb32c97a3632c6c6808eaac50","modified":1446648951000},{"_id":"themes/freesky/source/vendors/velocity/bower.json","shasum":"92d92860418c4216aa59eb4cb4a556290a7ad9c3","modified":1446648951000},{"_id":"themes/freesky/source/vendors/velocity/velocity.ui.js","shasum":"dbbfb50f6502f6b81dcc9fee7b31f1e812da3464","modified":1446648951000},{"_id":"themes/freesky/test/helpers.js","shasum":"f25e7f3265eb5a6e1ccbb5e5012fa9bebf134105","modified":1446648951000},{"_id":"themes/freesky/test/intern.js","shasum":"db90b1063356727d72be0d77054fdc32fa882a66","modified":1446648951000},{"_id":"themes/freesky/source/vendors/font-awesome/fonts/FontAwesome.otf","shasum":"0112e96f327d413938d37c1693806f468ffdbace","modified":1446648951000},{"_id":"themes/freesky/source/vendors/font-awesome/fonts/fontawesome-webfont.eot","shasum":"b3c2f08e73320135b69c23a3908b87a12053a2f6","modified":1446648951000},{"_id":"themes/freesky/source/vendors/font-awesome/fonts/fontawesome-webfont.woff","shasum":"507970402e328b2baeb05bde73bf9ded4e2c3a2d","modified":1446648951000},{"_id":"themes/freesky/source/vendors/jquery/index.js","shasum":"17a740d68a1c330876c198b6a4d9319f379f3af2","modified":1446648951000},{"_id":"themes/freesky/source/vendors/velocity/velocity.ui.min.js","shasum":"dde584994ac13dc601836e86f4cf490e418d9723","modified":1446648951000},{"_id":"themes/freesky/source/vendors/velocity/velocity.min.js","shasum":"bf172816a9c57f9040e3d19c24e181a142daf92b","modified":1446648951000},{"_id":"themes/freesky/source/vendors/font-awesome/fonts/fontawesome-webfont.ttf","shasum":"27cf1f2ec59aece6938c7bb2feb0e287ea778ff9","modified":1446648951000},{"_id":"source/README","shasum":"92449a25c7d01ee7bab1a01c5eb5255851030987","modified":1452510230811},{"_id":"source/CNAME","shasum":"f892e9aacb3418889e5aff6ed301a5a7f381ecf7","modified":1452503408439},{"_id":"source/_draft/2016-01-12-git-commands.md","shasum":"dad2bdd4ec25dc6c9622225b3b7cabcc9fbedf0b","modified":1463194390311},{"_id":"source/_draft/2016-02-16-spark-quick-start.md","shasum":"2abf9559f480a61e8bf286cc8bc303826404dd05","modified":1455591382032},{"_id":"source/_draft/2015-03-16-supervised-learning-and-unsepervised-learning.md","shasum":"904a0756220c9cd50572617cef066a7745466df7","modified":1455605277212},{"_id":"source/_draft/2015-03-10-HMM.md","shasum":"1b9ace0dd8bfec8ff5a78f66c7c622ae9e0d8091","modified":1457611854032},{"_id":"source/_draft/2016-02-21-ML-Study.md","shasum":"2a44c3f173396c30db218d1968dfb5345adf7bc7","modified":1456550949882},{"_id":"source/_draft/2015-08-29 Summary.md","shasum":"8ffc3acd9cdd944714b788d8a3f671dfe1b23486","modified":1465437079590},{"_id":"source/_draft/2016-03-09-svm.md","shasum":"8e9db2802c2693e0f469965944cf09bcbd07ba38","modified":1457658731742},{"_id":"source/_draft/2016-02-28-LDA-and-PCA.md","shasum":"37fc0666052057e23017e30566f42b5db6eee570","modified":1457309784909},{"_id":"source/_draft/2016-03-06-the-introduction-of-optimization.md","shasum":"629033c8f4c49805f9f461976afea67d715ea64c","modified":1457245742460},{"_id":"source/_posts/2014-11-19-linux-tree-command.md","shasum":"2e92769f93ade39c5763d37631680b689b18561d","modified":1457426679758},{"_id":"source/_draft/2016-03-10-one-hot-encoding.md","shasum":"711216b0bde2bfea79ff67fbe1d6d75ef1d9c859","modified":1457568501341},{"_id":"source/_posts/2014-12-22-choiceSort.md","shasum":"83e00fe6288fb69eb50f863175c24f7af5509011","modified":1458961810671},{"_id":"source/_posts/2014-12-21-InsertSort.md","shasum":"df8afc8b4297e2d343cf5e4c695b57d9238ded1b","modified":1458960779019},{"_id":"source/_posts/2014-12-25-exchangeSort.md","shasum":"7edaf81bac54c21b20c22b41cd806d0b1d0b96d8","modified":1458961806016},{"_id":"source/_posts/2014-12-26-MergeSort.md","shasum":"cd9e9dd60b036ace95441d3e0ee46d6b61ac0ee1","modified":1458961786295},{"_id":"source/_posts/2014-12-19-The-difference-of-list-and-tupple.md","shasum":"27e2da74d0e734dc9b55520789d54ff39feabf62","modified":1457848929663},{"_id":"source/_posts/2015-03-26-sublimeLinter.md","shasum":"4fa15cd7e0a4ed95d71b3e726cfa2a4526e56953","modified":1457427717155},{"_id":"source/_posts/2015-02-14-string-match.md","shasum":"bdf0bc1fe3e5d427202f1289f1396624c582f156","modified":1457426775136},{"_id":"source/_posts/2015-05-08-decision tree.md","shasum":"b42b996248a265207134781a6ade5e994d5e00d8","modified":1462896033820},{"_id":"source/_posts/2015-04-12-Syncing-a-fork.md","shasum":"5cbc7ffdae030db32dfaf6329019a20348db86ab","modified":1457426816581},{"_id":"source/_posts/2015-03-18-machine-learning-top10-algorithms.md","shasum":"3546e6ad632bfc089b53ddab914a8552ca2c6c6c","modified":1457848879923},{"_id":"source/_posts/2015-05-31 scikit-learn training model's save and reused.md","shasum":"83cc6e2e8f45354898e0e70f335314d333bcd690","modified":1457426887491},{"_id":"source/_posts/2015-06-03-ml-algorithm-K-means.md","shasum":"8ee7a0f4e69fbded101ea5ac2f1fe2cf0f1515eb","modified":1458952502921},{"_id":"source/_posts/2015-05-21-KNN.md","shasum":"329d9c1cca0cbc115685e32e29e3a0cce0c6275d","modified":1457848840457},{"_id":"source/_posts/2015-06-10 Python-simulate-command.md","shasum":"15e1be2077e1e9a13204f9929c2df7ad4b1bd4a2","modified":1457851274831},{"_id":"source/_posts/2015-05-28-NB.md","shasum":"3392ec09beb24a1feab51a7388aaecef0a50025d","modified":1457427703043},{"_id":"source/_draft/2016-03-18-AlphaGO.md","shasum":"dcde1d345d00428592f0591f1fe6bd686f3a3b1b","modified":1458362449189},{"_id":"source/_posts/2015-07-13-10 keys to successful machine learning for developers.md","shasum":"2549240f84bcea8235b7261907146e57049f8d24","modified":1457848738804},{"_id":"source/_posts/2015-07-05-ML-algorithm-Adaboost.md","shasum":"42ed0b8c1cbe2539fe03ff97060212f64f8d4b79","modified":1457848768639},{"_id":"source/_posts/2015-07-16 Python timer.md","shasum":"6d6a36b77e267fda8dbb0bb3992e0b9049d8760b","modified":1457848725846},{"_id":"source/_posts/2015-07-21-An-introduction-to-machine-learning-with-scikit-learn.md","shasum":"2f608e9b8eb85c94b4e91aca6df3a7644b394dc3","modified":1457427469910},{"_id":"source/_posts/2015-07-07-PDB.md","shasum":"6ba084d5cbefe2520aebdc60ecc595a2a566bdad","modified":1457426937705},{"_id":"source/_posts/2015-06-04-Apriori.md","shasum":"591d8a27beab57cfa400e202d1c49368bca0bc89","modified":1457848788624},{"_id":"source/_posts/2015-07-18-a precision-and-recall.md","shasum":"c46238c5cfa828a7c23f19ed0bdd20918761b84c","modified":1457426663384},{"_id":"source/_posts/2015-07-28 crossvalidation.md","shasum":"a814fc733887754227ec4f84725aacd59cd55e54","modified":1457864537928},{"_id":"source/_posts/2015-07-23 machine learning tips.md","shasum":"bdda054c5179782481d33d6161d263c244cd16a6","modified":1457864584957},{"_id":"source/_posts/2015-08-12-theano-to-lasagne.md","shasum":"5e5975ceb1636d8599cd5397cf423303edea00e2","modified":1457864525428},{"_id":"source/_posts/2015-07-22  ensemble.md","shasum":"0725466542736a65e91cf26bf1b255e371dc06a5","modified":1457848710693},{"_id":"source/_posts/2015-08-19 GBDT.md","shasum":"b1c9f904122fd579ef128856f8a5fafa72322880","modified":1457849099915},{"_id":"source/_posts/2015-10-21 Windows git push no password.md","shasum":"83951b6c5059579b31567a2e71654be5a5fd569a","modified":1465439824132},{"_id":"source/_posts/2015-10-25 scikit-learn preprocessing.md","shasum":"4a6db17b1ec758107bedc5ffff086b66b55caa3f","modified":1457848540918},{"_id":"source/_posts/2015-10-29 Python RegEx.md","shasum":"7fda6c18afb74f070cbfac6ad6b9b67df67b3850","modified":1458735949452},{"_id":"source/_posts/2015-10-24 feature engineering.md","shasum":"a1d6613d19390397d42a6e9245beb7ff0c75c06e","modified":1457848550418},{"_id":"source/_posts/2015-11-16 Download PDB file with wget command.md","shasum":"6f05c66460efd7abfde5f9662ab286c0f4eec781","modified":1457427254739},{"_id":"source/_posts/2015-11-03 Add header and footer to some file.md","shasum":"8767499c14e4072df8d07e5e37fb0c2ee3656669","modified":1457848499446},{"_id":"source/_posts/2015-11-17 B=U-A.md","shasum":"ab269c4f6dba53b0bb64afc35e046b4e7e1db045","modified":1448169147232},{"_id":"source/_posts/2015-11-18 ExpNotes[1]-Extract protein sequences from a fasta file.md","shasum":"d8745c445d233bcdcd4f41f3419334481c8ca5c2","modified":1457427278237},{"_id":"source/_posts/2015-11-21-machine-learning-algorithms.md","shasum":"442caecfec484c7e8fd7cee706ddb59889a089f3","modified":1457848470243},{"_id":"source/_posts/2015-11-25-Reading-Today.md","shasum":"eda887024b14c049e6581610d17b8990f29b571a","modified":1457427895617},{"_id":"source/_posts/2015-12-04-Python-Round.md","shasum":"c1ef13896061c485aade8122ed656d5d3852d30e","modified":1457427757645},{"_id":"source/_posts/2015-12-02-EM-algorithms.md","shasum":"8fce4a0b2987b4555101f8495107beb391b0de18","modified":1457941234143},{"_id":"source/_posts/2015-12-12-LeetCode-ans.md","shasum":"2aab6b91fab885b3b5f2bc65ed7ac11714985878","modified":1458788693331},{"_id":"source/_posts/2015-09-23 Machine learning materials.md","shasum":"2e40b09b08f4eea57decee7ca8938e221dd64e86","modified":1457848578860},{"_id":"source/_posts/2015-12-25-25-Java-Machine-Learning-Tools-&-Libraries.md","shasum":"c05b5916d3ca522fef6bd2c6d1d8e84dc196a3fe","modified":1457427866439},{"_id":"source/_posts/2015-11-15 normalization.md","shasum":"6d256906b1b37c5de35d197df81127d3b91835dd","modified":1457427239832},{"_id":"source/_posts/2015-12-04-Python-two-list-add-item-add-item.md","shasum":"a5c3e13c946e4314c8ccf0092707f8550a363298","modified":1457848446975},{"_id":"source/_posts/2016-01-02-extracte-data-from-web-server-in-python.md","shasum":"fde2726a5394f3187ee8225392092b0548c84be2","modified":1457851811811},{"_id":"source/_posts/2015-12-31-annual-summary.md","shasum":"5e86c516becc9128ecd65de275d2b2c8228c0115","modified":1457781845933},{"_id":"source/_posts/2016-02-23-Python-coding-standards.md","shasum":"f552d4db419d8202a006edc7d4e26576e056d5fd","modified":1465439646571},{"_id":"source/_posts/2016-01-21-Python-notes.md","shasum":"2974526aba14d81a3f4c554f1d78a5071705aee4","modified":1465439747500},{"_id":"source/_posts/2016-02-25-machine-learning-MNIST-dataset.md","shasum":"8ac4aeb67ff333ebdb105951e970062b134cafe3","modified":1457427810616},{"_id":"source/_posts/2016-02-28-pca.md","shasum":"b258cc28a28047a25c60b22bc6b65f9ba307c0a2","modified":1462897048968},{"_id":"source/_posts/2016-01-01-csdn-cloud-column-translation.md","shasum":"c95f0bceaf95bc79fccd20583a2e75a2aa6236e4","modified":1458802687138},{"_id":"source/_posts/2016-01-12-Newton-Method.md","shasum":"52aa2716be58f5c95221d115187f7becb757e175","modified":1457963000336},{"_id":"source/about/index.md","shasum":"e736c22df3dc80e564e8d84f0d0d82366ba750d9","modified":1465438966737},{"_id":"source/_posts/2016-03-12-performance-evaluation.md","shasum":"1ad939efe459dcce5f7f5695ee518e7b68b7f7d1","modified":1465439197644},{"_id":"source/_posts/2016-03-26-loss-function.md","shasum":"451220beca52e8640379ceca79cfa80d701c0216","modified":1465437790723},{"_id":"source/assets/articleImg/2014-12-21-insert-sort.png","shasum":"24370eb131156791759d44db9e8c75a011b8273a","modified":1448169147241},{"_id":"source/assets/articleImg/2015-07-21 randomForest分类器的方法png.png","shasum":"630e283bda6b0e2f6876ffd8dc7d88b14915e139","modified":1448169147249},{"_id":"source/assets/articleImg/2015-12-02-gs1.png","shasum":"875ea1629d1775c705fd403668c1b38042fb14a6","modified":1449056781302},{"_id":"source/assets/articleImg/2015-12-02-gs10.png","shasum":"07fe100f967b333a622e822c98eaeb3dc3d57186","modified":1449063101284},{"_id":"source/assets/articleImg/2015-12-02-Jensen-inequality.png","shasum":"4439c99f0eca19396314a5bdb117dbc47f96c18d","modified":1449055138820},{"_id":"source/assets/articleImg/2015-12-02-gs2.png","shasum":"1e340330137e7a0342f728db213a7a2855aacec1","modified":1449060221729},{"_id":"source/assets/articleImg/2015-12-02-gs11.png","shasum":"649f2ded34b7b754b6108026943fb727f57d91f5","modified":1449063222731},{"_id":"source/assets/articleImg/2015-12-02-gs3.png","shasum":"42547026784d89499a53a65caefb65a12f3cd4d9","modified":1449061772893},{"_id":"source/assets/articleImg/2015-12-02-gs5.png","shasum":"561f5fb11de28a4aa93a604df6ed1c4f6ce7d63b","modified":1449062207517},{"_id":"source/assets/articleImg/2015-12-02-gs7.png","shasum":"77fab8c904fefee00338a2574a18e1a8d78738a0","modified":1449062776207},{"_id":"source/assets/articleImg/2015-12-02-gs6.png","shasum":"da7bca4be4e93d79fb7e44733bbadd316fc03e03","modified":1449062591306},{"_id":"source/assets/articleImg/2015-12-02-gs4.png","shasum":"7011eb1479c7fa6b6ae7ace869639bede0b9494e","modified":1449061902851},{"_id":"source/assets/articleImg/2015-12-02-gs9.png","shasum":"ad3cf080698c94ad3f969ebc182bb683ea5e8d3e","modified":1449063052565},{"_id":"source/assets/articleImg/2015-12-02-p2.png","shasum":"a5dbd668d0c618f57f34eef01e5c310344209dfa","modified":1449061183235},{"_id":"source/assets/articleImg/2015-12-02-gs8.png","shasum":"c90d3c842ce8abc71cadb865c1eca60ccb7c1910","modified":1449062806877},{"_id":"source/assets/articleImg/2016-01-01-img3.png","shasum":"9eb30159068b128b734f769036b2dd9ef9ad80bb","modified":1451623051852},{"_id":"source/assets/articleImg/4DFDU.png","shasum":"2b160d7859c0433086fb14404165ee6db04ea68c","modified":1458828211887},{"_id":"source/_posts/2016-02-26-choosing-a-machine-learning-classifier.md","shasum":"ae810715601d33f4299e08cd7aa506d6ea0d7921","modified":1462897023091},{"_id":"source/assets/articleImg/Newton_optimization_vs_grad_descent.svg","shasum":"deaf597ee787ec35c853281d48bd10d45f7ca130","modified":1457319747491},{"_id":"source/assets/articleImg/area_under_curve.png","shasum":"44f03b36dbdadd6257d4f5672980884e35d59f69","modified":1457790196933},{"_id":"source/assets/articleImg/hinge.jpg","shasum":"163d44524fc191c212ac24082915f093224a4105","modified":1458866109089},{"_id":"source/assets/articleImg/logit_sgd.png","shasum":"3948c4eca7eac3399fa5b26fee0d8c471e15560d","modified":1457490220161},{"_id":"source/assets/articleImg/bias_variance.png","shasum":"ea377f9c28c6629857458c4b68c52e864e35e676","modified":1457226387641},{"_id":"source/assets/articleImg/hinge.png","shasum":"85a8d77e51197e3ad9ace886908e5966b90af39f","modified":1457180193740},{"_id":"source/assets/articleImg/k_clusters4.png","shasum":"c10346ffee0d68e450592ea6702148f238fccfea","modified":1458908017075},{"_id":"source/assets/blogImg/face.png","shasum":"5becca466c4cfc4ec0e960d6c0c8fa38ff4b1b21","modified":1448169147280},{"_id":"source/assets/images/20151029094653.png","shasum":"ff5e58b2f30fc5c86e240e54b5536f2165e5efea","modified":1448169147282},{"_id":"source/assets/images/20151029183224.png","shasum":"b2623009f05331ace037ee91ac30865c8b676d33","modified":1448169147282},{"_id":"source/assets/docs/Merge-sort.docx","shasum":"0aec7f80e29dc6f6dbcc9de673e14ed16c29f9fa","modified":1448169147281},{"_id":"source/assets/images/2015111501.png","shasum":"7123eb25c051675c0c4cd2dde18692feeb05ee77","modified":1448169147283},{"_id":"source/assets/articleImg/pca_ica.png","shasum":"515156bd65606f842488736af69c3422f12b3585","modified":1457314113596},{"_id":"source/assets/images/face-h200.jpg","shasum":"f381cba4d44396afba110b82264a4bab5c797a0a","modified":1448169147296},{"_id":"source/assets/images/navigate.png","shasum":"15f88035457c248f3a28858cfeba6b6b41e85149","modified":1448169147330},{"_id":"source/assets/images/navigate0.png","shasum":"36fe69c672eb66b0ddabefe82ae4984273483622","modified":1448169147330},{"_id":"source/assets/images/feature selection.png","shasum":"a02f4f12afeb0cb36377fcb5473ebc72691da71b","modified":1448169147329},{"_id":"source/assets/images/navigate1.png","shasum":"27a994ac225d7ed2f21835641166207e547f73e4","modified":1448169147331},{"_id":"source/assets/images/pca.png","shasum":"6a18ec79211e6164962f9010f5ee299d58b76e2e","modified":1456638870645},{"_id":"source/assets/images/2015111502.png","shasum":"948c97a5a53caf5e060852ae2494f054fa485b4d","modified":1448169147286},{"_id":"source/categories/index.md","shasum":"6285e6f5c09dff3c29cde7bb00baf0df33c94f3e","modified":1448169147365},{"_id":"source/donation/index.md","shasum":"8ab067ba4ac074cc84bdcfee06a59db873284b99","modified":1448191132003},{"_id":"source/assets/svg/feature engineering.svg","shasum":"3c3dcee389a26b0294d056a9be9a4f35a83f2920","modified":1448169147365},{"_id":"source/images/default_avatar.jpg","shasum":"5becca466c4cfc4ec0e960d6c0c8fa38ff4b1b21","modified":1448169147372},{"_id":"source/images/favicon1.ico","shasum":"e954e61d2178e559c72acc85c701a4b8cc66585d","modified":1448169147373},{"_id":"source/images/favicon.ico","shasum":"aef77afa442d35d233ba17306fba28f115781d29","modified":1448169147372},{"_id":"source/instagram/index.ejs","shasum":"6c1fda4881fe03d0304a20dcbd3d55def72d5c90","modified":1448169147374},{"_id":"source/images/favicon2.ico","shasum":"5c713499ccd8054767a01337f6ff9b86168f30cf","modified":1448169147373},{"_id":"source/leetcode/LeetCode[155]-Min Stack.md","shasum":"8e35699bd798e0731741a50c25fee19dfd8f286c","modified":1458743582419},{"_id":"source/leetcode/Leetcode[100]-Same Tree.md","shasum":"c5af33296e3925cc79e8183c1f01f94f01408aea","modified":1458743582269},{"_id":"source/leetcode/Leetcode[101]-Symmetric Tree.md","shasum":"a29547f40d22547b216bae36b5fb95ff5f177a7e","modified":1458743582278},{"_id":"source/instagram/ins2.json","shasum":"1cef31a539a5f23d009fd5abd331ff71a1dc08c1","modified":1448169147377},{"_id":"source/leetcode/Leetcode[102]-Binary Tree Level Order Traversal.md","shasum":"915ac09eafbb9576bbb44031b04c9aa7d239f09f","modified":1458980530005},{"_id":"source/instagram/ins1.json","shasum":"43e6ff8d41b62fb926d98b72eb2ba475ee915ad1","modified":1448169147376},{"_id":"source/leetcode/Leetcode[103]-Binary Tree Zigzag Level Order Traversal.md","shasum":"115c786d44e606e8d0d42224da9032a321c5321d","modified":1458743582283},{"_id":"source/leetcode/Leetcode[107]-Binary Tree Level Order Traversal II.md","shasum":"7d48211dd39d0393679de9e6debbb5ddf3a23bbe","modified":1458743582294},{"_id":"source/leetcode/Leetcode[111]-Minimum Depth of Binary Tree.md","shasum":"3f768034fc193d3ad33f3389f23fb557beee7a2f","modified":1458743582303},{"_id":"source/leetcode/Leetcode[104]-Maximum Depth of Binary Tree.md","shasum":"13a68db7256513bfd04cb10ed39f7246d817fae3","modified":1458743582291},{"_id":"source/leetcode/Leetcode[110]-Balanced Binary Tree.md","shasum":"8f08114111f04e005203f7af4abff2ba928b58a2","modified":1458743582302},{"_id":"source/leetcode/Leetcode[118]-Pascal's Triangle.md","shasum":"c4fdb121c737d0283cf822a928cd34f197256d8c","modified":1458743582311},{"_id":"source/leetcode/Leetcode[114]-Flatten Binary Tree to Linked List.md","shasum":"b7ad21d3b4f26c81e9c83379f0d63e3ae958bd1c","modified":1458743582308},{"_id":"source/leetcode/Leetcode[119]-Pascal's Triangle II.md","shasum":"f584944091e028e4535e4c1637c925ce9c5e499c","modified":1458743582313},{"_id":"source/leetcode/Leetcode[125]-Valid Palindrome.md","shasum":"3a6d2e25e022dd6044553a795e4e863b78b6c937","modified":1458743582318},{"_id":"source/leetcode/Leetcode[128]-Longest Consecutive Sequence.md","shasum":"2432afaf81ca8cbe676a6332b4e3bd5bdfb00a52","modified":1458743582330},{"_id":"source/leetcode/Leetcode[113]-Path Sum II.md","shasum":"a5b222e98f11bfee0cf75ca5a7c787ad3c33f260","modified":1458743582307},{"_id":"source/leetcode/Leetcode[129]-Sum Root to Leaf Numbers.md","shasum":"1b13b158fdc8c7d23c39d431ef355c7531d18a6c","modified":1458743582337},{"_id":"source/leetcode/Leetcode[136]-Single Number.md","shasum":"6ecbb62b33a43333beec102e6330f52d9ff91883","modified":1458743582357},{"_id":"source/leetcode/Leetcode[141]-Linked List Cycle.md","shasum":"fb681e6ef7c8f85e9ba81802c2e8331cfc7bed64","modified":1458743582392},{"_id":"source/leetcode/Leetcode[137]-Single Number II.md","shasum":"2ee34915c7f98810a01405295abe1154f83c39f9","modified":1458743582364},{"_id":"source/leetcode/Leetcode[12]-Integer to Roman+++.md","shasum":"273fc417b1b4bda6196b71357fa0b9c48570b1b2","modified":1458743582342},{"_id":"source/leetcode/Leetcode[13]-Roman to Integer+++.md","shasum":"6b1e8e51050d9f91028592e6385c4fae01efe6c3","modified":1458743582380},{"_id":"source/leetcode/Leetcode[145]-Binary Tree Postorder Traversal.md","shasum":"1868b14cd291550a5f7765eba178b1b40d273ca1","modified":1458743582409},{"_id":"source/leetcode/Leetcode[143]-Reorder List.md","shasum":"fe716d93f40be513e27d7c4038b0b27b51dd0060","modified":1458743582393},{"_id":"source/leetcode/Leetcode[144]-Binary Tree Preorder Traversal.md","shasum":"8f13e7fbc625b1594ccc673ab61f911ebb788393","modified":1458743582399},{"_id":"source/leetcode/Leetcode[154]-Find Minimum in Rotated Sorted Array II.md","shasum":"2c1b3c9bb886a2c7d8e94fe7290b7345aabace6c","modified":1458743582418},{"_id":"source/leetcode/Leetcode[147]-Insertion Sort List.md","shasum":"60f6d1fef191684b21b33a41dd34535f653ea65b","modified":1458743582411},{"_id":"source/leetcode/Leetcode[153]-Find Minimum in Rotated Sorted Array.md","shasum":"29f83e7a3add2afc9385aa69d62bc55d00c90963","modified":1458743582417},{"_id":"source/leetcode/Leetcode[148]-Sort List.md","shasum":"922be7ddc01e46afb34ef2dced2d779c45cd1050","modified":1458743582416},{"_id":"source/leetcode/Leetcode[162]-Find Peak Element.md","shasum":"3e762631573eb1089526d506e95868886359abbc","modified":1458743582421},{"_id":"source/leetcode/Leetcode[189]-Rotate Array.md","shasum":"17d1942fb9b21b13417ab5742b14e59b194a66b8","modified":1458743582424},{"_id":"source/leetcode/Leetcode[191]-Number of Bits.md","shasum":"10925b87c81507d324fe2d6cc635f5d57b1fc32f","modified":1458743582433},{"_id":"source/leetcode/Leetcode[18]-4Sum.md","shasum":"fc1910f7e6da8a50dc917fb3d95a700789003992","modified":1458743582432},{"_id":"source/leetcode/Leetcode[19]-Remove Nth Node From End of List.md","shasum":"e10bd484a111016f35d1c38266e8d18325d0ea39","modified":1458743582445},{"_id":"source/leetcode/Leetcode[15]-3Sum.md","shasum":"da73807726a0c4c9d264b670a9f0d4acf0553351","modified":1458743582420},{"_id":"source/leetcode/Leetcode[202]-Happy Number.md","shasum":"7e1bcfcfbe03403f7449c68b9e2cef74e9225c12","modified":1458743582461},{"_id":"source/leetcode/Leetcode[198]-House Robber.md","shasum":"d21255979a063409ea83830dbbbaaba1f0efc038","modified":1458743582435},{"_id":"source/leetcode/Leetcode[173]-Binary Search Tree Iterator.md","shasum":"d5eaa06f19f96a684d8e7724aa25738d47bf0de8","modified":1458743582423},{"_id":"source/leetcode/Leetcode[1]-Two Sum.md","shasum":"fa48ff446e37213567c4534854c921cf21c37566","modified":1458743582446},{"_id":"source/leetcode/Leetcode[169]-Majority Element.md","shasum":"257f31d29c46bb0f3efc97077408aa9bf9b1b80a","modified":1458743582422},{"_id":"source/leetcode/Leetcode[20]-Valid Parentheses.md","shasum":"2a58dc3bbefeb5593c5cb7c0d39a6bba8147e75e","modified":1458743582619},{"_id":"source/leetcode/Leetcode[203]-Remove Linked List Elements.md","shasum":"26388b4dad76d852d4d5ad18a92ace1a11e15701","modified":1458743582590},{"_id":"source/leetcode/Leetcode[206]-Reverse Linked List.md","shasum":"604b3037000bc818858183fcc5188c75a794635b","modified":1458743582604},{"_id":"source/leetcode/Leetcode[215]-Kth Largest Element in an Array.md","shasum":"7131f10c44a0544364ca1ea67c742e74b17c4691","modified":1458743582622},{"_id":"source/leetcode/Leetcode[217]-Contains Duplicate.md","shasum":"4e106ae760042026d68a9b495925aaa74f5a365e","modified":1458743582637},{"_id":"source/leetcode/Leetcode[231]-Power of Two.md","shasum":"fc4d90f319917f042d3280ed9457dbe8560123f4","modified":1458743582683},{"_id":"source/leetcode/Leetcode[219]-Contains Duplicate II.md","shasum":"baee0d121e5d66b33637c4502401c83b8ff4f140","modified":1458743582642},{"_id":"source/leetcode/Leetcode[222]-Count Complete Tree Nodes.md","shasum":"43162ce05218d72a0992dfbe69ef2cff6a96c8cd","modified":1458743582665},{"_id":"source/leetcode/Leetcode[226]-Invert Binary Tree.md","shasum":"39d759ead12f3bb87f461c50969d777d4d1beb5b","modified":1458743582678},{"_id":"source/leetcode/Leetcode[242]-Valid Anagram.md","shasum":"ca142d244565bef7e88c85bbc16385c4ba38a1eb","modified":1458743582701},{"_id":"source/leetcode/Leetcode[237]-Delete Node in a Linked List.md","shasum":"1a59b4f852be134e187e4a29fb0a61e2be753176","modified":1458743582693},{"_id":"source/leetcode/Leetcode[258]-Add Digits.md","shasum":"3c3e6296f89e562325637ea4c7393568f8ec2ff7","modified":1458743582717},{"_id":"source/leetcode/Leetcode[260]-Single Number III.md","shasum":"cda6fb0454eb745093909de6e2113300a21d10fc","modified":1458743582725},{"_id":"source/leetcode/Leetcode[21]-Merge Two Sorted Lists.md","shasum":"99206ca76a0fe04fac627a169c083ce7de7b5ba4","modified":1458743582663},{"_id":"source/leetcode/Leetcode[26]-Remove Duplicates from Sorted Array.md","shasum":"a780236a8ec8d2e1b1de48046318a6648724a0be","modified":1458743582735},{"_id":"source/leetcode/Leetcode[27]-Remove Element.md","shasum":"a68409be965b265b99fc8cc939a83c5423371296","modified":1458743582736},{"_id":"source/leetcode/Leetcode[292]-Nim Game.md","shasum":"a63e59d53ae600a3110f5b39dc1bb2f9841c6adb","modified":1458743582762},{"_id":"source/leetcode/Leetcode[283]-Move Zeroes.md","shasum":"a392cd48a91e70487387f37f908edc8c445c834f","modified":1458743582747},{"_id":"source/leetcode/Leetcode[300]-Longest Increasing Subsequence.md","shasum":"30679a011b6ac280dc359c03024816daa177ed30","modified":1458743582771},{"_id":"source/leetcode/Leetcode[33]-Search in Rotated Sorted Array.md","shasum":"fe0120a6753d0b4d4e5fb24f9e327a668824da14","modified":1458743582803},{"_id":"source/leetcode/Leetcode[36]-Valid Sudoku.md","shasum":"a7203953bdcca1145d3f0c2380878e6f38735fd5","modified":1458743582855},{"_id":"source/leetcode/Leetcode[53]-Maximum Subarray.md","shasum":"023a2731f7e5fead460b913d2744d9a1d642a93a","modified":1458743582872},{"_id":"source/leetcode/Leetcode[263]-Ugly Number++.md","shasum":"f734ec5f83909ad7fb6c36715cad33638752df8b","modified":1458743582734},{"_id":"source/leetcode/Leetcode[62]-Unique Paths.md","shasum":"872545fb8cd7a54e4b652bb7317ca4de83f94f21","modified":1458743582888},{"_id":"source/leetcode/Leetcode[63]-Unique Paths II.md","shasum":"10c21d24657144600bde0099cfe4296fe731dcf7","modified":1458743582889},{"_id":"source/leetcode/Leetcode[66]-Plus One.md","shasum":"29f670c0d4f4dba39a141f9aa3be3007ea566de5","modified":1458743582891},{"_id":"source/leetcode/Leetcode[70]-Climbing Stairs.md","shasum":"e92390677159a4282f50969b5967746ea314f734","modified":1458743582893},{"_id":"source/leetcode/Leetcode[74]-Search a 2D Matrix.md","shasum":"8ed9691567db690ffcdea6e52f52ef4e47452a54","modified":1458743582894},{"_id":"source/leetcode/Leetcode[81]-Search for a Range.md","shasum":"443b0bb25b87391496947373e751f8060ac41e84","modified":1458743582919},{"_id":"source/leetcode/Leetcode[82]-Remove Duplicates from Sorted List II.md","shasum":"11c9a5bba088e871db9dd64bb9cdf0d4483f4ff6","modified":1458743582931},{"_id":"source/leetcode/Leetcode[86]-Partition List.md","shasum":"4b7545b771860d38df201adbbee00f6e8a763e51","modified":1458743582952},{"_id":"source/leetcode/Leetcode[83]-Remove Duplicates from Sorted List.md","shasum":"f2797fccffebeb0727aca55aef085cfa80949535","modified":1458743582942},{"_id":"source/leetcode/Leetcode[88]-Merge Sorted Array.md","shasum":"fbb3e69574ea574b11a543e38d2cc11f38aae82c","modified":1458743582957},{"_id":"source/leetcode/Leetcode[7]-Reverse Integer.md","shasum":"77e141d681067c7b507f140ffc8a7ee5d950dce8","modified":1458743582905},{"_id":"source/leetcode/Leetcode[35]-Search Insert Position.md","shasum":"53b4c586a8e9c6c96289fb54fd95e38f0c887789","modified":1458743582832},{"_id":"source/leetcode/Leetcode[92]-Reverse Linked List II.md","shasum":"08abeff6faea4faa38930514ce14250ee3863b8b","modified":1458743582959},{"_id":"source/leetcode/Leetcode[98]-Validate Binary Search Tree.md","shasum":"2c932efcb22f5f71fbfe256d70520c1153dbefb1","modified":1458743582977},{"_id":"source/leetcode/Leetcode[96]-Unique Binary Search Trees.md","shasum":"0d6457c5441fbc16142e26aeb8b73bb56986b148","modified":1458743582964},{"_id":"source/leetcode/Leetcode[94]-Binary Tree Inorder Traversal.md","shasum":"b4c670246104aafc7bc69a694bc04c95d8d40934","modified":1458743582960},{"_id":"source/leetcode/Leetcode[9]-Palindrome Number.md","shasum":"a84a3510c8d24f5efb7a60b66620948adce9f4a6","modified":1458743582978},{"_id":"source/resume/index.md","shasum":"74a0196abdb360d024de573b738c8cc37c48c89b","modified":1448169147377},{"_id":"source/leetcode/Leetcode[4]-Median of Two Sorted Arrays.md","shasum":"5a76d61883c79148950cd8c0456a1b55730084cb","modified":1458743582865},{"_id":"source/tags/index.md","shasum":"2c31155ef43066ad82482079983cb5290e0ad658","modified":1448169147382},{"_id":"source/resume/resume-pdf.md","shasum":"3d075d77e0e434c1fda319ad35ace3d8d2d90d70","modified":1448169147378},{"_id":"themes/freesky/source/vendors/velocity/velocity.js","shasum":"e63dc7cea055ca60a95d286f32349d88b10c5a4d","modified":1446648951000},{"_id":"source/assets/articleImg/2014-12-21-performances-of-sort-algs.png","shasum":"16108a096336b79d5bca6cd4f43758e383cd39db","modified":1448169147248},{"_id":"source/assets/articleImg/2015-12-02-EM_Clustering_of_Old_Faithful_data.gif","shasum":"ad8e9b45e3d01deef10f0cc07ec22144c3c631b3","modified":1449057481912},{"_id":"source/assets/articleImg/2015-11-25-data-scientist-work-diagram.png","shasum":"85d41312806c05fa986ef4a756d6383b42efbbdf","modified":1448457703664},{"_id":"source/assets/articleImg/2015-12-12-leetcode.png","shasum":"12dd7204588189ef56e102dd605094c9ff587746","modified":1458742201291},{"_id":"source/assets/articleImg/2015-12-31-huatian.jpg","shasum":"cb3eb50345cec253326bd32c0cf45631e30addd0","modified":1451524351970},{"_id":"source/assets/articleImg/2016-01-01-img1.png","shasum":"ae52381dc4d245c68f05acb7ed3d2b5035186432","modified":1451622879409},{"_id":"source/assets/articleImg/2015-12-02-p3.png","shasum":"6c3016d2d55130cf3570c9a158a5d30f91f4198a","modified":1449062121894},{"_id":"source/assets/articleImg/2016-01-01-img4.png","shasum":"6959aa87c4dfaa5da3f34022236bfa69613bda54","modified":1451623257016},{"_id":"source/assets/articleImg/2016-01-01-img5.png","shasum":"bda93d9f38c1a21a5b85f498ac9c358dfd14c724","modified":1451623770396},{"_id":"source/assets/articleImg/2016-01-01-img2.png","shasum":"86598ded65e6409252486ddb8cf72faa55fab900","modified":1451622939466},{"_id":"source/assets/images/zhifubao_denote.jpg","shasum":"1172d8a13eee6dadb1785a7d5f592e29c83ed854","modified":1448169147335},{"_id":"source/assets/images/submolarity.png","shasum":"5396d8785bb68c5f7831284614bce9dbd2e50c47","modified":1448169147332},{"_id":"source/assets/pdf/Slope One.pdf","shasum":"2d38f623c7c904ecc4022443e1c22f379e89d653","modified":1448169147363},{"_id":"source/resume/resume.md","shasum":"5d1c2cb7c693afe42570a556a211361a6502744d","modified":1448169147380},{"_id":"source/instagram/ins0.json","shasum":"1d0ccefbe2d41a61ff3df771e83830c95fa34bfc","modified":1448169147375},{"_id":"source/assets/images/weixin_denote.jpg","shasum":"23674bb7ce8e042d50a92bbf2bec01c722bc8960","modified":1448169147334},{"_id":"themes/freesky/source/images/bg.png","shasum":"26b2ff0a42335d3b0ab3d5bcc6402b8afd8c9abc","modified":1446648950000},{"_id":"source/assets/articleImg/2015-12-31-tiedao1.jpg","shasum":"299f1b7bf8ecf6646b287444c8ce4c4af1022507","modified":1451375021634},{"_id":"source/assets/pdf/A Few Useful Things to Know about Machine Learning.pdf","shasum":"98e43925cff9857667a7cb085cc029fc48623cc0","modified":1448169147354},{"_id":"themes/freesky/source/vendors/font-awesome/fonts/fontawesome-webfont.svg","shasum":"f346b8b3df147e4059e1a7d66c52c9a6e1cec3e8","modified":1446648951000},{"_id":"source/assets/articleImg/2014-12-21-mergeSort-1.png","shasum":"fd8b15bb2dcfa32d2f1131a508e567f2c97046e6","modified":1448169147244},{"_id":"source/assets/articleImg/2014-12-21-mergeSort-2.png","shasum":"372e93e25efa88b02a0132bc0d27f8a61fe45591","modified":1448169147247},{"_id":"source/assets/blogImg/devin.png","shasum":"9c7922e5995a47a1264f37d462fd4d0679a7fc79","modified":1448169147279},{"_id":"source/assets/articleImg/roc_plot.gif","shasum":"6aa137ccf577a9689570505ad4fa5eac52a784c0","modified":1457789560310},{"_id":"source/assets/images/denote.jpg","shasum":"c954bb995905cc8a09c04990164a9f4930577589","modified":1448169147289},{"_id":"source/assets/images/face.jpg","shasum":"9c7922e5995a47a1264f37d462fd4d0679a7fc79","modified":1448169147299},{"_id":"source/resume/resume.pdf","shasum":"4bd6ba146f079555dfef2dff6e11b33702c48e32","modified":1448169147381},{"_id":"source/assets/articleImg/2015-12-21-machine-learning-algorithms_1.jpg","shasum":"93cf7dfd762e2844efc08f52740afff3914f7e1e","modified":1448169147252},{"_id":"source/assets/articleImg/Max_paraboloid.svg","shasum":"7efb043b67294b18c6348c8c2935333c5e91b1e2","modified":1457319702904},{"_id":"source/assets/articleImg/2015-12-31-bagong.jpg","shasum":"cd5a424e972cf02b574412f28f7b89a4d626cefb","modified":1451564762965},{"_id":"source/assets/pdf/Full-CheatSheet-on-Machine-Learning-Algorithms(Python-and-R-Codes).pdf","shasum":"4065131ecd59de6a54556a122969d5fb28e76bd2","modified":1448169147356},{"_id":"source/resume/resume-pdf.pdf","shasum":"e822ed94a3168846d196addb9619ce4074472d4c","modified":1448169147379},{"_id":"source/images/bg.png","shasum":"26b2ff0a42335d3b0ab3d5bcc6402b8afd8c9abc","modified":1448169147371},{"_id":"source/assets/images/feature engineering.png","shasum":"4a26e5889bc0f02de146a601d263c113ba446caa","modified":1448169147304},{"_id":"source/assets/articleImg/2015-12-31-desktop.jpg","shasum":"277ad9577289c4195d87ac8a1c8c5f487a0bdfb3","modified":1451482278135},{"_id":"source/assets/pdf/How to Select a Good Training-data Subset for Transcriptionsubmodular active selection from sequences.pdf","shasum":"9719ad883a20297df798b02ba6b27a138920717b","modified":1448169147362},{"_id":"source/assets/images/denote.xcf","shasum":"8d8791d47b07d3e8c2c58ca24cf00cd81e1ada04","modified":1448169147296},{"_id":"source/assets/articleImg/2015-12-31-movie_all1.jpg","shasum":"cc0d8b1bf840954c224b70f805b9f333b4233998","modified":1451530298591},{"_id":"source/assets/articleImg/2015-12-31-lab-morning.jpg","shasum":"b80692d1563d818a8912f833866c78bc56b2bcab","modified":1451524447568},{"_id":"source/assets/articleImg/2015-12-21-machine-learning-algorithms_2.jpg","shasum":"411406772118eb7c5438050fbbe1913a6b818fbf","modified":1448169147276},{"_id":"source/assets/pdf/2009- Learning from Imbalanced Data.pdf","shasum":"bfc2537a96c4f8a57f1823719e24042a8ee5af2f","modified":1448169147352},{"_id":"source/assets/images/feature engineering.tif","shasum":"420b6a1f42cf3ca5dde241b72424e3e9ff12ed70","modified":1448169147328},{"_id":"public/tags/index.html","modified":1465437137644,"shasum":"a060d15a95a4834781d32dde5fbf7ac2adfcfaf5"},{"_id":"public/resume/resume.html","modified":1465437137722,"shasum":"bb847d356c9db5591c0dde72401f7f22180b2918"},{"_id":"public/resume/index.html","modified":1465437137800,"shasum":"13bf0d97d66f9baa925dfd574fb293e22606d034"},{"_id":"public/leetcode/Leetcode[9]-Palindrome Number.html","modified":1465437137847,"shasum":"a3eeda147f6dd898e12ce90300f9b676a0abc23b"},{"_id":"public/leetcode/Leetcode[98]-Validate Binary Search Tree.html","modified":1465437137910,"shasum":"3d264c8d9d095c8a5ac77caf4f5434fa4f4a34e0"},{"_id":"public/leetcode/Leetcode[96]-Unique Binary Search Trees.html","modified":1465437137956,"shasum":"f447e7f1ebe678beabc5fa1f253d524173967944"},{"_id":"public/leetcode/Leetcode[94]-Binary Tree Inorder Traversal.html","modified":1465437138013,"shasum":"5aadf7681d88da7cfa372d201a539846d2085e3d"},{"_id":"public/leetcode/Leetcode[92]-Reverse Linked List II.html","modified":1465437138074,"shasum":"05525d63a5f98278791e3ba3a8bf58f8d48f0739"},{"_id":"public/leetcode/Leetcode[88]-Merge Sorted Array.html","modified":1465437138125,"shasum":"61992835cbbf8455a7633fe6422979a0f10f20b0"},{"_id":"public/leetcode/Leetcode[86]-Partition List.html","modified":1465437138182,"shasum":"5a3a288b2421d1741e41738f334dc54895bcf9ff"},{"_id":"public/leetcode/Leetcode[83]-Remove Duplicates from Sorted List.html","modified":1465437138281,"shasum":"213a4b48bd35ff692c5bfb87c111ca46bf7de922"},{"_id":"public/leetcode/Leetcode[82]-Remove Duplicates from Sorted List II.html","modified":1465437138331,"shasum":"ab79b8bc907204b1b997a6de7e916a194f2c626d"},{"_id":"public/leetcode/Leetcode[81]-Search for a Range.html","modified":1465437138389,"shasum":"40bdade51f045d08426679ba58ff716bd8a7a571"},{"_id":"public/leetcode/Leetcode[7]-Reverse Integer.html","modified":1465437138436,"shasum":"946b172847bf1a8020f0c29e3a34bdb3940626af"},{"_id":"public/leetcode/Leetcode[74]-Search a 2D Matrix.html","modified":1465437138480,"shasum":"6c4eb39d7167fc93dbb6ad4b95681811a2cdae83"},{"_id":"public/leetcode/Leetcode[70]-Climbing Stairs.html","modified":1465437138535,"shasum":"97197e009abc0650f16a3de94016171454281a1e"},{"_id":"public/leetcode/Leetcode[66]-Plus One.html","modified":1465437138576,"shasum":"5c77a8a8d6637af049fa4bcc0c2bcade2bba3812"},{"_id":"public/leetcode/Leetcode[63]-Unique Paths II.html","modified":1465437138622,"shasum":"12154fb77f4a7b57ab0164a877ace7ab7096f17e"},{"_id":"public/leetcode/Leetcode[62]-Unique Paths.html","modified":1465437138676,"shasum":"ffbd382a3144b34a31edd1ea9e5c5759f6e44591"},{"_id":"public/leetcode/Leetcode[53]-Maximum Subarray.html","modified":1465437138726,"shasum":"34f9513fe6b7046af3643bc4a25109492e89ff89"},{"_id":"public/leetcode/Leetcode[4]-Median of Two Sorted Arrays.html","modified":1465437138776,"shasum":"446925da8a8e83e8f8478c9d3ac0649d0b3f1a41"},{"_id":"public/leetcode/Leetcode[36]-Valid Sudoku.html","modified":1465437138833,"shasum":"6829886287e0c53693d9005c835c23019407eaad"},{"_id":"public/leetcode/Leetcode[35]-Search Insert Position.html","modified":1465437138879,"shasum":"06fd5c47873764b8b731680ebdbb3b92d87b7b15"},{"_id":"public/leetcode/Leetcode[33]-Search in Rotated Sorted Array.html","modified":1465437138936,"shasum":"7269a3fc5befdaf808a705891988198da6d0f01a"},{"_id":"public/leetcode/Leetcode[300]-Longest Increasing Subsequence.html","modified":1465437138979,"shasum":"1d3ed8e68013674e933ab52ad73622d9eaec5fce"},{"_id":"public/leetcode/Leetcode[292]-Nim Game.html","modified":1465437139013,"shasum":"cfb59aa2a1de9a6b63b0ac696bbd26ff767615b7"},{"_id":"public/leetcode/Leetcode[283]-Move Zeroes.html","modified":1465437139060,"shasum":"82641097c0876dc7bce96ebd8223d5049cdfd5ce"},{"_id":"public/leetcode/Leetcode[27]-Remove Element.html","modified":1465437139091,"shasum":"cc3571eb6340307e87074959b6bfb6b9ebc9be2e"},{"_id":"public/leetcode/Leetcode[26]-Remove Duplicates from Sorted Array.html","modified":1465437139138,"shasum":"5dc96747a235cc51d32246b9580b710d5ea1f314"},{"_id":"public/leetcode/Leetcode[263]-Ugly Number++.html","modified":1465437139244,"shasum":"704701f05ae21ea236f7e04ebdd33e4170f11fd7"},{"_id":"public/leetcode/Leetcode[260]-Single Number III.html","modified":1465437139316,"shasum":"446ee4be684bff5b2005df8d67607613ff631ee5"},{"_id":"public/leetcode/Leetcode[258]-Add Digits.html","modified":1465437139377,"shasum":"dbc3ba5ed1b4e3c04b7f5d3dc05d6baae5494a92"},{"_id":"public/leetcode/Leetcode[242]-Valid Anagram.html","modified":1465437139435,"shasum":"904da7857bc337b39c05c69e9e1cc8f17e00b726"},{"_id":"public/leetcode/Leetcode[237]-Delete Node in a Linked List.html","modified":1465437139478,"shasum":"586549209921a68860d6c18c8bb3cf9dedebd209"},{"_id":"public/leetcode/Leetcode[231]-Power of Two.html","modified":1465437139536,"shasum":"1d36f4d0a8387891b9973194ed6ef6bcf0327a0f"},{"_id":"public/leetcode/Leetcode[226]-Invert Binary Tree.html","modified":1465437139581,"shasum":"c7473b0146eb2983ad5f51c32e2c107798dcf496"},{"_id":"public/leetcode/Leetcode[222]-Count Complete Tree Nodes.html","modified":1465437139643,"shasum":"33cc391c825ec2ce82b0de8d7bb3aea34361ebd2"},{"_id":"public/leetcode/Leetcode[21]-Merge Two Sorted Lists.html","modified":1465437139705,"shasum":"bc73d140af68dda74064bcbe0e15359c564e3447"},{"_id":"public/leetcode/Leetcode[219]-Contains Duplicate II.html","modified":1465437139752,"shasum":"d5b68954e1d3b59d270204e9ae244a8567f0eb47"},{"_id":"public/leetcode/Leetcode[217]-Contains Duplicate.html","modified":1465437139815,"shasum":"905ad486c6a43840467130be0870747412c050c3"},{"_id":"public/leetcode/Leetcode[215]-Kth Largest Element in an Array.html","modified":1465437139879,"shasum":"f383ca91a34389c4aa059ad3f5c2592f3317f758"},{"_id":"public/leetcode/Leetcode[20]-Valid Parentheses.html","modified":1465437139928,"shasum":"85b2dbf981c35461f1ddea99fc196c779e01207b"},{"_id":"public/leetcode/Leetcode[206]-Reverse Linked List.html","modified":1465437139992,"shasum":"07fbabf1dcf59d1bf7a67f0cdda5576385a435cc"},{"_id":"public/leetcode/Leetcode[203]-Remove Linked List Elements.html","modified":1465437140039,"shasum":"7815336e1779e16d8ba41710d3bdf4ddfc254565"},{"_id":"public/leetcode/Leetcode[202]-Happy Number.html","modified":1465437140101,"shasum":"c3949e5f1a05b271cb4043ef5c731539359c2447"},{"_id":"public/leetcode/Leetcode[1]-Two Sum.html","modified":1465437140195,"shasum":"54c6e4eb7b6ec11aa0f39922a7c742a0925239b5"},{"_id":"public/leetcode/Leetcode[19]-Remove Nth Node From End of List.html","modified":1465437140300,"shasum":"856e06157a9318b0d4bab0fb14bf434e0dad7ffb"},{"_id":"public/leetcode/Leetcode[198]-House Robber.html","modified":1465437140383,"shasum":"573ccebba3d4df6920c5ceec5313c2b0fdeaa43a"},{"_id":"public/leetcode/Leetcode[191]-Number of Bits.html","modified":1465437140448,"shasum":"399353782c4f82d4efed293d9186dfb6eb3e1e91"},{"_id":"public/leetcode/Leetcode[18]-4Sum.html","modified":1465437140542,"shasum":"03d33f2d5c720ed9e43768ad6b66b3aea97a9d57"},{"_id":"public/leetcode/Leetcode[189]-Rotate Array.html","modified":1465437140588,"shasum":"832bf23af1229d59484f816baee08057f18a7f73"},{"_id":"public/leetcode/Leetcode[173]-Binary Search Tree Iterator.html","modified":1465437140635,"shasum":"f952014b5a6888559143cd7c20e3b0ca8cc285f6"},{"_id":"public/leetcode/Leetcode[169]-Majority Element.html","modified":1465437140713,"shasum":"caf4b2012afbb8ac6fb47f01dfe816f126d1c85f"},{"_id":"public/leetcode/Leetcode[162]-Find Peak Element.html","modified":1465437140761,"shasum":"723325a526947dd8137b89f4df31ab9f55a7ddb1"},{"_id":"public/leetcode/Leetcode[15]-3Sum.html","modified":1465437140803,"shasum":"e2f49a5bb858cbf167f75035566ae4e588797bfb"},{"_id":"public/leetcode/Leetcode[154]-Find Minimum in Rotated Sorted Array II.html","modified":1465437140852,"shasum":"4cd4a735786aee50929759b6747fb5468053568f"},{"_id":"public/leetcode/Leetcode[153]-Find Minimum in Rotated Sorted Array.html","modified":1465437140896,"shasum":"48f5b2fc21d617f2a21e08c221c2d5f47e2134b2"},{"_id":"public/leetcode/Leetcode[148]-Sort List.html","modified":1465437140934,"shasum":"6a8859d9b0f62451b2724d6734c2b8896e83df53"},{"_id":"public/leetcode/Leetcode[147]-Insertion Sort List.html","modified":1465437140981,"shasum":"c1f0cb456149e9efaa4cbdbeeb2fbd0358c93517"},{"_id":"public/leetcode/Leetcode[145]-Binary Tree Postorder Traversal.html","modified":1465437141012,"shasum":"e29fe5f81c9720cad22dd41986b01bcbe359d348"},{"_id":"public/leetcode/Leetcode[144]-Binary Tree Preorder Traversal.html","modified":1465437141059,"shasum":"97017a3b6a97cbe856aeed02ec0ffba9238e627a"},{"_id":"public/leetcode/Leetcode[143]-Reorder List.html","modified":1465437141105,"shasum":"c9bd21ad1150356c47dc31a7a778d88f94101055"},{"_id":"public/leetcode/Leetcode[141]-Linked List Cycle.html","modified":1465437141152,"shasum":"5770497b25bdee9bcf36a743092eac726ab11d3d"},{"_id":"public/leetcode/Leetcode[13]-Roman to Integer+++.html","modified":1465437141183,"shasum":"d9f71bbdcdcd6215c692533b1cd9b77d609fbe1f"},{"_id":"public/leetcode/Leetcode[137]-Single Number II.html","modified":1465437141225,"shasum":"ded540a733ff02c20cdd933e59d398967bf4cec0"},{"_id":"public/leetcode/Leetcode[136]-Single Number.html","modified":1465437141290,"shasum":"e7f260a709727d62ad63283ea07d1f0a73d8664e"},{"_id":"public/leetcode/Leetcode[12]-Integer to Roman+++.html","modified":1465437141341,"shasum":"c65bf15bac4801030026157bc9d3df06d72ff84e"},{"_id":"public/leetcode/Leetcode[129]-Sum Root to Leaf Numbers.html","modified":1465437141404,"shasum":"64da78e6b640219d076fb265e84dd0231583b700"},{"_id":"public/leetcode/Leetcode[128]-Longest Consecutive Sequence.html","modified":1465437141451,"shasum":"a887b070462b92d312fd0e1e5f7b2c0623b117fa"},{"_id":"public/leetcode/Leetcode[125]-Valid Palindrome.html","modified":1465437141498,"shasum":"2901311ad0cf1cf80c0876ed8eadff597d3ecdcc"},{"_id":"public/leetcode/Leetcode[119]-Pascal's Triangle II.html","modified":1465437141545,"shasum":"1c45fc2a55cd63b1982961e5a1a78c42eb387920"},{"_id":"public/leetcode/Leetcode[118]-Pascal's Triangle.html","modified":1465437141576,"shasum":"8e92bedd8fe9b3864d876d588a7da936091fcc15"},{"_id":"public/leetcode/Leetcode[114]-Flatten Binary Tree to Linked List.html","modified":1465437141623,"shasum":"be823ec802c67b25f9ce6ffcffef5b29311eec83"},{"_id":"public/leetcode/Leetcode[113]-Path Sum II.html","modified":1465437141669,"shasum":"2bba7938fac22022c3d07f3e0826171a7c342e5a"},{"_id":"public/leetcode/Leetcode[111]-Minimum Depth of Binary Tree.html","modified":1465437141716,"shasum":"b1e76f072d8c00cd09fbc4b3b667083cf724a89f"},{"_id":"public/leetcode/Leetcode[110]-Balanced Binary Tree.html","modified":1465437141747,"shasum":"7fd74f47290660e5234eff19d64f8f5e1d10df74"},{"_id":"public/leetcode/Leetcode[107]-Binary Tree Level Order Traversal II.html","modified":1465437141794,"shasum":"e58c382b7ccf3ac8908bcd947050bb62a7ea3aa9"},{"_id":"public/leetcode/Leetcode[104]-Maximum Depth of Binary Tree.html","modified":1465437141841,"shasum":"c67adad0e9f408df8cce12df82f397e511de8ebf"},{"_id":"public/leetcode/Leetcode[103]-Binary Tree Zigzag Level Order Traversal.html","modified":1465437141872,"shasum":"ac841aac5ceb45e67bf5551be1f545e36b1218dc"},{"_id":"public/leetcode/Leetcode[102]-Binary Tree Level Order Traversal.html","modified":1465437141919,"shasum":"f64358847833abf03133b0df28fb42a1199052dd"},{"_id":"public/leetcode/Leetcode[101]-Symmetric Tree.html","modified":1465437141966,"shasum":"355ea135b7aa51c90660aa080bb86328ddd3a5b1"},{"_id":"public/leetcode/Leetcode[100]-Same Tree.html","modified":1465437142013,"shasum":"b9b62d43631f571679932bf154f7d88a8e8d6eed"},{"_id":"public/leetcode/LeetCode[155]-Min Stack.html","modified":1465437142044,"shasum":"77e6f21722728c229a2398de8353511aca47462b"},{"_id":"public/instagram/ins2.json","modified":1459562779711,"shasum":"586ec18d863f9e3e3bc58dbdcb59f72d8fb0e45d"},{"_id":"public/instagram/ins1.json","modified":1459562779714,"shasum":"0358ccadc1a2f76923bef7835e7965efe4282d71"},{"_id":"public/instagram/ins0.json","modified":1459562779717,"shasum":"f61865df33126db2c58c8e8ddc02dd01a35a20d4"},{"_id":"public/instagram/index.html","modified":1465437142137,"shasum":"30eb7cb6747394b606f88261a266fb40db3f6eef"},{"_id":"public/donation/index.html","modified":1465437142184,"shasum":"b6d9e4f6c7ffb72b61bdd06a37afb77648907282"},{"_id":"public/categories/index.html","modified":1465437142231,"shasum":"a674f83444d7e218e956b038178dfb2be2c175b1"},{"_id":"public/about/index.html","modified":1465439223543,"shasum":"6ee7f0d3d8aa76dd2ff6efc7290b1fe7b4871e78"},{"_id":"public/2016/03/26/2016-03-26-loss-function/index.html","modified":1465437830053,"shasum":"124b020af6a4f6d3b68fb30dc66019a428d65741"},{"_id":"public/2016/03/12/2016-03-12-performance-evaluation/index.html","modified":1465439223918,"shasum":"de5024d5538a8e4a58eedc32185a33cfdaae8369"},{"_id":"public/2016/02/28/2016-02-28-pca/index.html","modified":1465437142725,"shasum":"2c626744d15d67777f37e5367a77c781459e1416"},{"_id":"public/2016/02/26/2016-02-26-choosing-a-machine-learning-classifier/index.html","modified":1465437142787,"shasum":"a277aee3ee266c797dbecc257d3695a6036c55f3"},{"_id":"public/2016/02/25/2016-02-25-machine-learning-MNIST-dataset/index.html","modified":1465437142881,"shasum":"11901b288f51da3fac1a000566c72f2491ab391c"},{"_id":"public/2016/02/23/2016-02-23-Python-coding-standards/index.html","modified":1465439774388,"shasum":"a74ee3793cd91468879153c7a16b07e69144ac17"},{"_id":"public/2016/01/22/2016-01-21-Python-notes/index.html","modified":1465439774482,"shasum":"6e01fe4dbabd39002b924bfba3d8fd304eebcff0"},{"_id":"public/2016/01/12/2016-01-12-Newton-Method/index.html","modified":1465439774559,"shasum":"875c3d76ae3a0885e7be408be112c827982346e1"},{"_id":"public/2016/01/02/2016-01-02-extracte-data-from-web-server-in-python/index.html","modified":1465437143193,"shasum":"d32d6ad884ed9f9b8056798ac115fe3d5f0a3101"},{"_id":"public/2016/01/01/2016-01-01-csdn-cloud-column-translation/index.html","modified":1465437143255,"shasum":"0a783e96726aba4196a3feef6f750e6f4301c683"},{"_id":"public/2015/12/31/2015-12-31-annual-summary/index.html","modified":1465437143333,"shasum":"13680a2c6cdb23f850ba934a96b3b808de76d136"},{"_id":"public/2015/12/25/2015-12-25-25-Java-Machine-Learning-Tools-&-Libraries/index.html","modified":1465437143411,"shasum":"26ec27d303ce4caa99cb9143a20483735143a727"},{"_id":"public/2015/12/12/2015-12-12-LeetCode-ans/index.html","modified":1465437143474,"shasum":"693117da1736403d2ace1774e787b6ca66861137"},{"_id":"public/2015/12/04/2015-12-04-Python-Round/index.html","modified":1465437143536,"shasum":"fef47e3d4041562caf9507d50106b4d703c510c9"},{"_id":"public/2015/12/04/2015-12-04-Python-two-list-add-item-add-item/index.html","modified":1465437143614,"shasum":"06ebfa4e17e3a4add65e0179d6f2d738bfffc3b3"},{"_id":"public/2015/12/02/2015-12-02-EM-algorithms/index.html","modified":1465437143676,"shasum":"2f8f22548ff8ae773de32c90f11d035e15c3df61"},{"_id":"public/2015/11/25/2015-11-25-Reading-Today/index.html","modified":1465437143739,"shasum":"592debf0dddb589b4f036c9f32086aae4ae11a6f"},{"_id":"public/2015/11/21/2015-11-21-machine-learning-algorithms/index.html","modified":1465437143817,"shasum":"eaab1625b5d473afb1b6cd2eaf40ffbebfeef810"},{"_id":"public/2015/11/18/2015-11-18 ExpNotes[1]-Extract protein sequences from a fasta file/index.html","modified":1465437143893,"shasum":"bfa3726a1996c5af25bf2f2325ef9182f70500d5"},{"_id":"public/2015/11/17/2015-11-17 B=U-A/index.html","modified":1465437143971,"shasum":"4312af97d4ce4240535f90edb5b1ec4dbacc4936"},{"_id":"public/2015/11/16/2015-11-16 Download PDB file with wget command/index.html","modified":1465437144079,"shasum":"f66e2fbd536221b3e2007dc837c35575101d7818"},{"_id":"public/2015/11/15/2015-11-15 normalization/index.html","modified":1465437144157,"shasum":"9438aba940144fc45aa39391ca71645601d2bc25"},{"_id":"public/2015/11/03/2015-11-03 Add header and footer to some file/index.html","modified":1465437144235,"shasum":"e5c6a71cdd8273dee4c4a323fa6b576cee7dec4f"},{"_id":"public/2015/10/29/2015-10-29 Python RegEx/index.html","modified":1465437144313,"shasum":"2d804cdb10ea49bc6ebd5fc3bc3b4b060e935e10"},{"_id":"public/2015/10/25/2015-10-25 scikit-learn preprocessing/index.html","modified":1465437144406,"shasum":"1facaae8c8068107f1ae18fa54068c1540e4ab82"},{"_id":"public/2015/10/24/2015-10-24 feature engineering/index.html","modified":1465437144475,"shasum":"42f69e8b020801ed8a052eef3ed2f3da413e2a0f"},{"_id":"public/2015/10/21/2015-10-21 Windows git push no password/index.html","modified":1465439850996,"shasum":"379520a4ac10a907571e77a31743bf500f429a08"},{"_id":"public/2015/09/23/2015-09-23 Machine learning materials/index.html","modified":1465437144619,"shasum":"1956c41eacd068df5576e86a2387c08b63f27279"},{"_id":"public/2015/08/19/2015-08-19 GBDT/index.html","modified":1465437144681,"shasum":"df5b7b36039dd7c2be2e80fc684cd3903404489d"},{"_id":"public/2015/08/12/2015-08-12-theano-to-lasagne/index.html","modified":1465437144759,"shasum":"942f6b7d932a42dd72229184c8a6beb07e3309b1"},{"_id":"public/2015/07/28/2015-07-28 crossvalidation/index.html","modified":1465437144854,"shasum":"2866f0123dafa0c9de13f0423385747bae9314c0"},{"_id":"public/2015/07/23/2015-07-23 machine learning tips/index.html","modified":1465437144942,"shasum":"6636cc55a2943a0015b9b44f155dbbd832894f62"},{"_id":"public/2015/07/22/2015-07-22  ensemble/index.html","modified":1465437145038,"shasum":"7ec74cc29f175d617f356a7aa18bfba5598b2712"},{"_id":"public/2015/07/21/2015-07-21-An-introduction-to-machine-learning-with-scikit-learn/index.html","modified":1465437145120,"shasum":"ee794cffa050994880e01ecc040e58ccbffd0dda"},{"_id":"public/2015/07/18/2015-07-18-a precision-and-recall/index.html","modified":1465437145183,"shasum":"ec2985756bf5e2b0e5491321ed9ea1ece0852935"},{"_id":"public/2015/07/16/2015-07-16 Python timer/index.html","modified":1465437145245,"shasum":"792aac0530f10ebf9e136f4b81e918104eaa2588"},{"_id":"public/2015/07/13/2015-07-13-10 keys to successful machine learning for developers/index.html","modified":1465437145323,"shasum":"c7f95622f34fefe686c1f0693b1c3e31a9eac5f0"},{"_id":"public/2015/07/07/2015-07-07-PDB/index.html","modified":1465437145385,"shasum":"eb29e866acf6199a84df5163ae59dde37fcacd91"},{"_id":"public/2015/07/05/2015-07-05-ML-algorithm-Adaboost/index.html","modified":1465437145479,"shasum":"fc7ed569a96e882753188c370433867e7f62f8bd"},{"_id":"public/2015/06/10/2015-06-10 Python-simulate-command/index.html","modified":1465437145541,"shasum":"5604867d11cabdedeab79de8cbdd216583a01a13"},{"_id":"public/2015/06/04/2015-06-04-Apriori/index.html","modified":1465437145619,"shasum":"e96cd92c44fafcceb565ac1087109e6037bfa3e4"},{"_id":"public/2015/06/03/2015-06-03-ml-algorithm-K-means/index.html","modified":1465437145697,"shasum":"e73bc80f3d1853f91c56327e596ad376ed71b95b"},{"_id":"public/2015/05/31/2015-05-31 scikit-learn training model's save and reused/index.html","modified":1465437145775,"shasum":"37fac5ea5b011d084d6d9a69bc16c456f125e67d"},{"_id":"public/2015/05/28/2015-05-28-NB/index.html","modified":1465437145853,"shasum":"c4795dd1241e71f41b4d252fc2986d27d231dd46"},{"_id":"public/2015/05/21/2015-05-21-KNN/index.html","modified":1465437145931,"shasum":"a29a283e7fef75c604b929aaa3b3cd3a09e6292c"},{"_id":"public/2015/05/08/2015-05-08-decision tree/index.html","modified":1465437145994,"shasum":"43f59e6e90610b3b82fffa284879f539f45c342d"},{"_id":"public/2015/04/15/2015-04-12-Syncing-a-fork/index.html","modified":1465437146056,"shasum":"d654d4ab0eddfd0efb2dbd391d9bc098007a7ef7"},{"_id":"public/2015/03/26/2015-03-26-sublimeLinter/index.html","modified":1465437146134,"shasum":"56ad63690835ec98d313b33f7a0a158fa6b2f449"},{"_id":"public/2015/03/18/2015-03-18-machine-learning-top10-algorithms/index.html","modified":1465437146197,"shasum":"7805ad224c1220e9f3950ac4bd5c754d4f4b8f25"},{"_id":"public/2015/02/14/2015-02-14-string-match/index.html","modified":1465437146275,"shasum":"1ddc9ef6cef70ede08ee80db0861d9fa861eaeb1"},{"_id":"public/2014/12/26/2014-12-26-MergeSort/index.html","modified":1465437146337,"shasum":"dac6a224ef76ce78afe9486b407d635584ae29fe"},{"_id":"public/2014/12/25/2014-12-25-exchangeSort/index.html","modified":1465437146415,"shasum":"abc292370cf75956b7dbd86ccb46a3afccd0dfed"},{"_id":"public/2014/12/22/2014-12-22-choiceSort/index.html","modified":1465437146493,"shasum":"6da53c0ee2331fb3c4579b3d146c2f1c3754b7a5"},{"_id":"public/2014/12/21/2014-12-21-InsertSort/index.html","modified":1465437146649,"shasum":"989bfa15a35e30785a4c3ed4ec458cbdf8e0dc60"},{"_id":"public/2014/12/19/2014-12-19-The-difference-of-list-and-tupple/index.html","modified":1465437146758,"shasum":"f5d8fc9a68e4090858abe7ed98088785d1ea23b2"},{"_id":"public/2014/11/19/2014-11-19-linux-tree-command/index.html","modified":1465437146836,"shasum":"ae99c1df702fed05340f1d8c622386194c7a3a95"},{"_id":"public/archives/index.html","modified":1465439779570,"shasum":"22918a8fd011c95ad1cdfdd895b50ce4fb0033c8"},{"_id":"public/archives/page/2/index.html","modified":1465437147247,"shasum":"e0be45c10056502a5f0e96bce5c9d23f04a667e7"},{"_id":"public/archives/page/3/index.html","modified":1465437147514,"shasum":"42a5d640f4362fcca3f42435bd998b3743fba8bb"},{"_id":"public/archives/2014/index.html","modified":1465437147631,"shasum":"30af601456f36cf4a396ad7e00cc6a2b31147a39"},{"_id":"public/archives/2014/11/index.html","modified":1465437147736,"shasum":"6bdf5549758947c5a4089d88d04f4c8d051b0361"},{"_id":"public/archives/2014/12/index.html","modified":1465437147865,"shasum":"e31cb2bbe07baaf1e0d3eae9f2c5d62bb82de8a5"},{"_id":"public/archives/2015/index.html","modified":1465437148103,"shasum":"7599cb0976e18a59745614989ebc6d74627dbf9f"},{"_id":"public/archives/2015/page/2/index.html","modified":1465437148329,"shasum":"5024a8874175ce8ab4cee270928f9fdb20d79926"},{"_id":"public/archives/2015/02/index.html","modified":1465437148395,"shasum":"1c8a6816c59c3a7fc679abaeaf15b509784d2e59"},{"_id":"public/archives/2015/03/index.html","modified":1465437148464,"shasum":"4a2c4cae33af41abe70d2c75e87e4800bdc97a03"},{"_id":"public/archives/2015/04/index.html","modified":1465437148534,"shasum":"7f60df3c31c41c63dd6c7a66e7fa0ba81cab8063"},{"_id":"public/archives/2015/05/index.html","modified":1465437148641,"shasum":"c972a87318182bbc9b47159efcd79d9de0aa8d55"},{"_id":"public/archives/2015/06/index.html","modified":1465437148767,"shasum":"5531909dabd2c7eacc003e2289aa3a0604718e1d"},{"_id":"public/archives/2015/07/index.html","modified":1465437148888,"shasum":"3f86f44cae748e591665f98d3ed835cdbb0cd188"},{"_id":"public/archives/2015/08/index.html","modified":1465437148966,"shasum":"bec64459b694d960158ac9d616e5c5429495b7f4"},{"_id":"public/archives/2015/09/index.html","modified":1465437149013,"shasum":"fce0f05f0954eace90d73dad5291467fd29dcab9"},{"_id":"public/archives/2015/10/index.html","modified":1465437149107,"shasum":"812af3a58f081ce3d80329479f8dc3fbb7eaafd4"},{"_id":"public/archives/2015/11/index.html","modified":1465437149216,"shasum":"8420fb595389540c18487ac458b3e9435bf4a290"},{"_id":"public/archives/2015/12/index.html","modified":1465437149310,"shasum":"350335072e6a93742d189a19c4180494f12f0949"},{"_id":"public/archives/2016/index.html","modified":1465439782176,"shasum":"75800ca3423b41e3d7673a2ceb806d37c9ee8649"},{"_id":"public/archives/2016/01/index.html","modified":1465439782254,"shasum":"f1d2a9980210b2d43f789575db4a2de8737ae00c"},{"_id":"public/archives/2016/02/index.html","modified":1465437149637,"shasum":"47a628d4ed029909083fd63f88cca3f176e329ad"},{"_id":"public/archives/2016/03/index.html","modified":1465437149700,"shasum":"48526d37edd20d86ddeabbd611a988b7051747e5"},{"_id":"public/categories/ML/index.html","modified":1465437150029,"shasum":"e8ffe6e746cfb53a60f1aa7ca6ec70d150324856"},{"_id":"public/categories/ML/page/2/index.html","modified":1465437150202,"shasum":"4ea67ebd7c7c4de205b8debb87db5e6285b4ce70"},{"_id":"public/categories/Python/index.html","modified":1465439783050,"shasum":"da9ac3900323536e642e1907960bafd51b682d28"},{"_id":"public/categories/总结/index.html","modified":1465437150500,"shasum":"32c314f0e2ebb1fbca9554a8da14daa79f7f6c30"},{"_id":"public/categories/算法与数据结构/index.html","modified":1465437150647,"shasum":"393b3caac667e62077cfb92f2699cffe5c1b7bde"},{"_id":"public/categories/今日阅读/index.html","modified":1465437150730,"shasum":"7cd09f2a0a03796a239f45496ce1074b3a12eeff"},{"_id":"public/categories/BioInfo/index.html","modified":1465437150847,"shasum":"d4f9d4d07507072de5ec0665a9dbe998a8a9759f"},{"_id":"public/categories/GitHub/index.html","modified":1465437150949,"shasum":"7ffe1f508595304334cd6ae87d947cdbd39cf0cb"},{"_id":"public/categories/工具/index.html","modified":1465437151083,"shasum":"d901d059c3b6c669ff117d161d4e9949766b6a1e"},{"_id":"public/categories/Linux/index.html","modified":1465437151157,"shasum":"fbce850557f07f1f1afa60f1b3be6f2f3772955b"},{"_id":"public/atom.xml","modified":1465439857851,"shasum":"eb54aed239ddf4559f76c48d116b8811267b956f"},{"_id":"public/index.html","modified":1465439783806,"shasum":"e4b3f7d3e0582b01f86afe97f2f489c2faa3dc0b"},{"_id":"public/page/2/index.html","modified":1465437151624,"shasum":"76f487b74576e281503976e4f4c472fb1d917756"},{"_id":"public/page/3/index.html","modified":1465437151853,"shasum":"b7d8392b94781c5a0f63937b1f0ba0ac803c3415"},{"_id":"public/tags/Machine-Learning/index.html","modified":1465437152028,"shasum":"af862a5a50d9e7db0f840ddfa80c86138e8dd740"},{"_id":"public/tags/Machine-Learning/page/2/index.html","modified":1465437152141,"shasum":"7f420fcc8792545f77fb58e76b815e04b8cd7b91"},{"_id":"public/tags/损失函数/index.html","modified":1465437152196,"shasum":"70dfcb8d264837773a5aa4d9cffaba9e39483086"},{"_id":"public/tags/ROC/index.html","modified":1465437152241,"shasum":"5e6f9b9d0fc58084b8779f5a8c0d2e437d46fcb1"},{"_id":"public/tags/AUC/index.html","modified":1465437152294,"shasum":"95eadd3b68d7749d2b8c32e5eec9234726516b9b"},{"_id":"public/tags/PCA/index.html","modified":1465437152344,"shasum":"f9de6402b6ead6c9f96b7f1176a728f99c7288ca"},{"_id":"public/tags/主成分分析/index.html","modified":1465437152413,"shasum":"251f66b3cd26e26685fbe16763c0ac87709989f6"},{"_id":"public/tags/算法选择/index.html","modified":1465437152475,"shasum":"c091ee60995ce2bb0fc4ee3fef439ac640278997"},{"_id":"public/tags/偏差/index.html","modified":1465437152522,"shasum":"474afff86f74ea76281ea12027e79c6773c56ebb"},{"_id":"public/tags/方差/index.html","modified":1465437152569,"shasum":"a092a3d430adc821b657fc105e441ea1678466da"},{"_id":"public/tags/LR/index.html","modified":1465437152600,"shasum":"4b44322424a5044dbf52ada2d121192b1d618085"},{"_id":"public/tags/MNIST/index.html","modified":1465437152663,"shasum":"6bb0f42193a3037a3767f3af7a03bda093488efd"},{"_id":"public/tags/dataset/index.html","modified":1465437152709,"shasum":"87fb374c4af4895a925fb57e482c104bda623c4e"},{"_id":"public/tags/Python/index.html","modified":1465439785538,"shasum":"10c619395099525879372167f32a43d509085025"},{"_id":"public/tags/编码规范/index.html","modified":1465437152881,"shasum":"dc54793cacdf596b2894d4f3d3cc55b39c544983"},{"_id":"public/tags/牛顿方法/index.html","modified":1465437152928,"shasum":"5a0475ff50ffcf7be29e2502a468f30d2eb5dbd7"},{"_id":"public/tags/指数分布族/index.html","modified":1465437152996,"shasum":"19d700675b01a8a6436d92005ef165750b592b62"},{"_id":"public/tags/GLM/index.html","modified":1465437153052,"shasum":"cc18805daed3cf3a9bb2019e7ed0ee6bbc31ca63"},{"_id":"public/tags/数据提取/index.html","modified":1465437153108,"shasum":"87e841d6bb6fe25cf44c8a0f523c70bc2b4e5e4f"},{"_id":"public/tags/正则表达式/index.html","modified":1465437153186,"shasum":"cd2c24e13aa57e9abbd46b334fbc71a74018f3ed"},{"_id":"public/tags/译文/index.html","modified":1465437153279,"shasum":"95bb67ecc6acca820e2b78ad63a73474a4b577a3"},{"_id":"public/tags/总结/index.html","modified":1465437153332,"shasum":"c3d5768805aa8ce1d9c706fa490157da458b93e0"},{"_id":"public/tags/框架-库/index.html","modified":1465437153394,"shasum":"040ad5c757009747115b90bcb00144a19083f0ec"},{"_id":"public/tags/LeetCode/index.html","modified":1465437153441,"shasum":"ffbea96ab8e5df6dba479b200175135b4c53b2e0"},{"_id":"public/tags/数据结构/index.html","modified":1465437153534,"shasum":"1e20d45785ca8d74600567b27ff9204c5a5e92e8"},{"_id":"public/tags/EM/index.html","modified":1465437153581,"shasum":"84b510d6f61599992dca863c063f8b24b5242e69"},{"_id":"public/tags/Data-Science/index.html","modified":1465437153612,"shasum":"b16c2060da1141f868c307216a79ac8570850da8"},{"_id":"public/tags/BioInfo/index.html","modified":1465437153690,"shasum":"18bef78f650550213f26c7f95a6ceea507240398"},{"_id":"public/tags/DSSP/index.html","modified":1465437153737,"shasum":"88f3ff74b04d17bac324783405b23e3fe8bbd0b7"},{"_id":"public/tags/预处理/index.html","modified":1465437153799,"shasum":"7b847c60ff3f7adb7b6d905320967d4419dee3e2"},{"_id":"public/tags/PDB/index.html","modified":1465437153877,"shasum":"246db6014c48d05b79d057a20dada5802aa0a60f"},{"_id":"public/tags/normalization/index.html","modified":1465437153937,"shasum":"e0e31f4feeb1c9d812cf6b05b82a38de0903a494"},{"_id":"public/tags/标准化/index.html","modified":1465437153992,"shasum":"7873733ceb13a6bb6ca928791dd4b9a6bd069871"},{"_id":"public/tags/RegEx/index.html","modified":1465437154059,"shasum":"4c68cbc565bee62721b9c20468bae5fbe1e4adff"},{"_id":"public/tags/scikit-learn/index.html","modified":1465437154132,"shasum":"63c2825bf272d36f9a26c6ab1fa527ceaac485ba"},{"_id":"public/tags/特征工程/index.html","modified":1465437154210,"shasum":"562c0de9aec01ca2248fa7006e05e8cfc5c162a8"},{"_id":"public/tags/GitHub/index.html","modified":1465437154277,"shasum":"10c118f31d6d5711fda2e506a5d65a7e603d38bb"},{"_id":"public/tags/GBDT/index.html","modified":1465437154317,"shasum":"0dad05f06a06d01cf43eb01bcacf2b77e120ed48"},{"_id":"public/tags/组合算法/index.html","modified":1465437154380,"shasum":"d3613083b28b634ea19da5085f3e2d4ba4ab732a"},{"_id":"public/tags/Theano/index.html","modified":1465437154427,"shasum":"7428dedc703110f8f437dd3a14b4387482bdff30"},{"_id":"public/tags/Lasagne/index.html","modified":1465437154490,"shasum":"bf205016bc3f9b109d244e7ed7dc9b22887a0bc9"},{"_id":"public/tags/交叉验证/index.html","modified":1465437154555,"shasum":"3563f2168be7c3502b1917f7e3967581cbf26cac"},{"_id":"public/tags/Cross-Validation/index.html","modified":1465437154627,"shasum":"583e04acb913a1c9f244045817e7f9544c4aa627"},{"_id":"public/tags/ensemble/index.html","modified":1465437154680,"shasum":"5b070852fcdf17c2e0576cb77956006314bf765e"},{"_id":"public/tags/Precision/index.html","modified":1465437154759,"shasum":"ca33398fe46c722cdc7a9dc3f10a8ef258f7ef92"},{"_id":"public/tags/Recall/index.html","modified":1465437154802,"shasum":"6f95b23d63ef895446878f4777a911ae214ef750"},{"_id":"public/tags/计时器/index.html","modified":1465437154848,"shasum":"9c6deaa8bdb22536bd2ed807bc9e1e949fd21079"},{"_id":"public/tags/Adaboost/index.html","modified":1465437154895,"shasum":"e1a2882f58e42450a0779b48a7c4b370fc45000c"},{"_id":"public/tags/Apriori/index.html","modified":1465437154960,"shasum":"4ba6bf29484ff97519381cd08e9b5650843d3158"},{"_id":"public/tags/关联分析/index.html","modified":1465437155002,"shasum":"764896b14fb21bbef6321488b44626122f228893"},{"_id":"public/tags/K-Means/index.html","modified":1465437155065,"shasum":"966c49b3fdd6541f2d7ebf1741cdf04767459fd9"},{"_id":"public/tags/聚类/index.html","modified":1465437155145,"shasum":"98e23a580d2437db98e1de55205fc1ad20c62f59"},{"_id":"public/tags/持久化/index.html","modified":1465437155225,"shasum":"a140457d25ecf4e9d6430c4626211e876cfdede3"},{"_id":"public/tags/Naive-Bayes/index.html","modified":1465437155280,"shasum":"e4389d65d44c22cc7b0996d2a244cae8370a14f6"},{"_id":"public/tags/KNN/index.html","modified":1465437155340,"shasum":"c15f11bbade5f9d1abccc2af7b139f9f35110ff4"},{"_id":"public/tags/最近邻/index.html","modified":1465437155387,"shasum":"202e6a6b027b8e112a1a8bae507b02e8cf1c8300"},{"_id":"public/tags/Decision-Tree/index.html","modified":1465437155446,"shasum":"1eacd6309f29c1908db43e42b88220f5febbdd42"},{"_id":"public/tags/fork/index.html","modified":1465437155498,"shasum":"6f86b232c9fdc63064d62424247f22e406aebbe3"},{"_id":"public/tags/同步/index.html","modified":1465437155549,"shasum":"1fa01a22ecf03c5ede23865f2d3586a755ecb0c8"},{"_id":"public/tags/SublimeLinter/index.html","modified":1465437155588,"shasum":"d783316d72143fc57a0231778fc3e40c70b8457c"},{"_id":"public/tags/汇总/index.html","modified":1465437155635,"shasum":"c0c1aa4a6baf1a0bd3a1ec16f1cb411ced1f001e"},{"_id":"public/tags/字符串匹配/index.html","modified":1465437155690,"shasum":"54fc7b537d3f6354ef9af3541d800e0c92416dfd"},{"_id":"public/tags/笔试/index.html","modified":1465437155737,"shasum":"7facdd8a1e1d2d077b813704f7228e0cec72cfef"},{"_id":"public/tags/归并/index.html","modified":1465437155799,"shasum":"6254192a2722045b6a914d960942d420d5fd0738"},{"_id":"public/tags/排序/index.html","modified":1465437155908,"shasum":"a4f6c4a70fb959a522d4f3ea0d36090b3e6d7d13"},{"_id":"public/tags/C/index.html","modified":1465437155984,"shasum":"48d5c0738dc309af847ea42fedf2320a9d74391c"},{"_id":"public/tags/冒泡排序/index.html","modified":1465437156033,"shasum":"07dd8682d82576c5514ce3994696514208f8aa32"},{"_id":"public/tags/快速排序/index.html","modified":1465437156096,"shasum":"97e90a12a037b9388eaaf0c2b794cfeb90f62f50"},{"_id":"public/tags/直接选择排序/index.html","modified":1465437156146,"shasum":"df3745f130162d0f2782d9120261d6739fd5ce41"},{"_id":"public/tags/堆排序/index.html","modified":1465437156201,"shasum":"685241bd909078c040df9388dadbc8718eea1286"},{"_id":"public/tags/希尔排序/index.html","modified":1465437156266,"shasum":"e2d65709be40daf489ca232979c9b73abde2be44"},{"_id":"public/tags/插入排序/index.html","modified":1465437156306,"shasum":"367c80f51602a84d125ebe3e6c14996d5b76b183"},{"_id":"public/tags/Linux/index.html","modified":1465437156369,"shasum":"81767b73fdb1a91a578d6b319f6a3816dc51db03"},{"_id":"public/tags/Shell/index.html","modified":1465437156416,"shasum":"b46beb00916a67237bfe13f0f92fecc17d2b6d9a"},{"_id":"source/assets/articleImg/2016-04-02-2.jpg","shasum":"7d3ca576e95d80966b537d78152d453e53b35bbe","modified":1459578727922},{"_id":"source/assets/articleImg/2016-04-02-1.jpg","shasum":"bb92fba5431073c6bba509187078cdb7e7c83119","modified":1459578754322},{"_id":"source/assets/articleImg/2016-04-02-0.jpg","shasum":"8556c77a433dec6375672cadfce84419e7ce3457","modified":1459578740427},{"_id":"source/assets/articleImg/2016-04-02-3.jpg","shasum":"d5ea55bea5aa66a6eab830f92f9748bdc24b40c9","modified":1459578718168},{"_id":"source/_posts/2016-04-02-some-day.md","shasum":"8b3f6ffb50948b3e659a8e3d57169ab7b5441708","modified":1459580760150},{"_id":"public/assets/articleImg/2016-04-02-1.jpg","modified":1459578793747,"shasum":"bb92fba5431073c6bba509187078cdb7e7c83119"},{"_id":"public/assets/articleImg/2016-04-02-2.jpg","modified":1459578793757,"shasum":"7d3ca576e95d80966b537d78152d453e53b35bbe"},{"_id":"public/assets/articleImg/2016-04-02-0.jpg","modified":1459578793761,"shasum":"8556c77a433dec6375672cadfce84419e7ce3457"},{"_id":"public/assets/articleImg/2016-04-02-3.jpg","modified":1459578793765,"shasum":"d5ea55bea5aa66a6eab830f92f9748bdc24b40c9"},{"_id":"public/2016/04/02/2016-04-02-some-day/index.html","modified":1465437142498,"shasum":"2f012b95600ad052d110d21c5ac16821cec2e83b"},{"_id":"public/archives/2016/04/index.html","modified":1465437149763,"shasum":"38b4b2108ab3ba2dead94e65de1a09135543f1a7"},{"_id":"source/README.txt","shasum":"036dc3f272b17e201203dde040410df9bc5e298c","modified":1462289598637},{"_id":"source/_draft/2014-12-20-QuikSort.md","shasum":"4f253569893402915c6494118f162b37ada4da4b","modified":1462289598637},{"_id":"source/_draft/2015-11-05 photo show 1.md","shasum":"1552e95d037f401ed2eb5c35cee3225d85fe2c49","modified":1462289598637},{"_id":"source/_draft/black_template.md","shasum":"e7a399dda4b21d88e9220a708abb990742e31c7d","modified":1462289600166},{"_id":"source/_posts/2014-12-21-MergeSort.md","shasum":"cd3f613520ab1360c59768f526008b2f454275cf","modified":1462289600166},{"_id":"source/assets/articleImg/170.jpg","shasum":"0f284ae1baac6109e7565fd80b7c0d0f8f7ff899","modified":1462289600197},{"_id":"source/_posts/2016-05-06-python-and-pip.md","shasum":"eb7121ac66a671a48629215d95a809f53f0a2432","modified":1463494514864},{"_id":"public/2016/05/06/2016-05-06-python-and-pip/index.html","modified":1465437142436,"shasum":"1c3f864de3e1f21c8110585d33de1699b8dcce44"},{"_id":"public/2015/08/29/2015-08-29 Summary/index.html","modified":1464188365553,"shasum":"766f6546dbaa004124399770582d77e3472505c6"},{"_id":"public/2015/07/18/2015-07-18-a precision and recall/index.html","modified":1462636209323,"shasum":"daa7b4496059fb9275ac9752a0c8c24082e0f27c"},{"_id":"public/2015/07/05/2015-07-12-Adaboost/index.html","modified":1462636209682,"shasum":"14e056617b41b463e12ef7c3da190b76803f3d37"},{"_id":"public/2015/06/10/2015-06-10 Python simulate command/index.html","modified":1462636209963,"shasum":"e428a056ed85fda2aef7e26c551634637f57f2e6"},{"_id":"public/2015/06/03/2015-06-03-K-means/index.html","modified":1462636210168,"shasum":"39f86679c21d7eeac6fc14c3585bf053e006eb21"},{"_id":"public/2014/12/21/2014-12-21-MergeSort/index.html","modified":1465437146571,"shasum":"705e529597463ea916d4afbffc1425608e90b05a"},{"_id":"public/archives/page/4/index.html","modified":1464188369541,"shasum":"5cf36304f540b9b38a0b4284de80f22bbd5ace28"},{"_id":"public/archives/2015/page/3/index.html","modified":1464188370732,"shasum":"eac94452b5a4d280f0bdc8d7fb65babc9ab391cc"},{"_id":"public/archives/2016/05/index.html","modified":1465437149826,"shasum":"ff5ec4961c596f25c33ed46b680a6da7c08bbf5c"},{"_id":"public/categories/译文/index.html","modified":1462636212424,"shasum":"1025a775889fa6f3be3776bc21d66bb870b593ae"},{"_id":"public/page/4/index.html","modified":1464188373736,"shasum":"7435c6cff4dc3fcde8e40871aaea6b5ff82e27c0"},{"_id":"public/tags/pip/index.html","modified":1465437156474,"shasum":"a18bcdd230239fc98688d353d71cf476530de51e"},{"_id":"public/2016/05/07/2016-03-19-feature-selection/index.html","modified":1462636206311,"shasum":"c7bf055d3431c74d5ec45b396d0704cbc18ce35d"},{"_id":"public/tags/mRMR/index.html","modified":1465437156529,"shasum":"dceead772ba993c6c20f40f725e9ff0b8ccc5480"},{"_id":"public/tags/Random-Forest/index.html","modified":1465437156582,"shasum":"bae9f4c7791c49a947174ac5590f90f4972ed35c"},{"_id":"public/tags/特征选择/index.html","modified":1465437156647,"shasum":"f5a7cbdebdb246bdeaf44fdb1a592ee190e39c55"},{"_id":"source/_posts/2016-05-07-feature-selection.md","shasum":"c0f5b595f57953d5bc95cf6afdd33d2d6d0669c4","modified":1462896112695},{"_id":"public/2016/05/07/2016-05-07-feature-selection/index.html","modified":1465437142373,"shasum":"cf63627d54a053296c206f57440bec4b2a7645ea"}],"Category":[{"name":"ML","_id":"cimigpytv002k6cujkorl1pbd"},{"name":"Python","_id":"cimigpyuy003o6cuj3zmo8gss"},{"name":"总结","_id":"cimigpyvl004i6cuj7vott2cg"},{"name":"算法与数据结构","_id":"cimigpyvy004t6cujcxi7gqbb"},{"name":"今日阅读","_id":"cimigpywl005b6cujx4qv8mn3"},{"name":"BioInfo","_id":"cimigpywv005k6cujyh1pcxa2"},{"name":"GitHub","_id":"cimigpyye006t6cujvfe76ulx"},{"name":"工具","_id":"cimigpz2400a76cujfb0saqy9"},{"name":"Linux","_id":"cimigpz3r00br6cuj5j4wnook"},{"name":"译文","_id":"cinrllkp10004w8ujyl29yarv"}],"Data":[],"Page":[{"title":"tags","date":"2015-10-19T03:24:27.000Z","type":"tags","comment":"flase","_content":"\n\n","source":"tags/index.md","raw":"title: tags\ndate: 2015-10-19 11:24:27\ntype: \"tags\"\ncomment: flase\n---\n\n\n","updated":"2015-11-22T05:12:27.382Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cimigpyil00006cujqygk5pme"},{"layout":"page","title":"","noDate":"true","comments":0,"description":"个 人 简 历","fancybox":false,"_content":"<style>\nbody{\n\tfont-size: 12px;\n\tfont-family: Arial,Console,Verdana,Courier New;\n}\n</style>\n<script type=\"text/javascript\" src=\"http://sources.ikeepstudying.com/js/jquery-1.8.3.min.js\"></script>  \n<script type=\"text/javascript\" src=\"jquery.media.js\"></script>  \n<script type=\"text/javascript\">  \n    $(function() {  \n        $('a.resume').resume({width:800, height:600});  \n    });  \n</script>  \n<a class=\"resume\" target=\"_black\" href=\"/resume/resume.pdf\"> 下载PDF</a>\n<div style=\"text-align:center;font-size:26px;padding-top:0px\">个 人 简 历</div>\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:18px;\">基本资料</div>\n\n<div style=\"width:100%;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>\n\n<div style=\"width:100%;float:left;margin-top:-12px;\"><div style=\"float:left;width:60%;\">\n姓&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;名： 刘帝伟  \n 出生年月： 1991年7月  \n 所在学校： 中南大学\t\t\t\t\t\n 联系方式： 18707489940  \n 腾讯 Q Q： 466454368\t  \t\n 电子邮件： <a href=\"mailto:csu.ldw@csu.edu.cn\">csu.ldw@csu.edu.cn</a>  \n CSDN博客： <a href=\"http://blog.csdn.net/dream_angel_z\">http://blog.csdn.net/dream_angel_z</a>\n</div><div style=\"width:38%;padding:30px 2% 0 0;float:left;text-align:right;\"><img src=\"../assets/images/face-h200.jpg\" title=\"\" /></div></div>个人说明：中南大学在读硕士， 研究方向为机器学习，数据挖掘以及生物信息领域。热爱生活、乐于Coding！\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-top:13px\">个人能力</div>\n\n<div style=\"width:100%;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div> \n \n精通数据结构基本算法并熟悉数据挖掘常用分类和聚类算法，能将所学算法运用于实际应用中；  \n熟悉Linux安装、配置及常见问题的解决，以及Linux下账户的创建和维护；  \n熟悉Linux下shell及Python脚本编程，有搭建Hadoop集群和PBS高性能集群经验；  \n掌握SVN、Git服务器的搭建和维护，掌握Git的基本操作；  \n熟悉JavaScript、CSS、AJAX、HTML(XHTML)及XML等Web前端开发技术；  \n熟悉 SSH三大框架以和MVC三层架构开发模式并有相关项目开发经验，掌握常用的设计模式；  \n熟练使用MyEclipse、Eclipse、Dreamweaver、SVN等开发工具和Visio建模工具；  \n熟练使用Tomcat服务器进行项目的开发；  \n熟练使用Oracle、MySQL、Microsoft SQL Server等数据库及SQL语言；  \n英语水平：CET-6  456分 具有良好的文献搜索和阅读能力。  \n\n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:6px;padding-top:13px;\">奖励情况</div>\n\n<div style=\"width:100%;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div> \n \n2015年03月 中软实训基地实训结业并获得“个人优胜奖”及“优秀开发团队奖”；  \n2014年—— 发表论文 \" Yang Meng, Lei Deng, Zhigang Chen, Cheng Zhou, **Diwei Liu**, Chao Fan, and Ting Yan. **A Multi-Instance Multi-Label Learning Approach for Protein Domain Annotation**. **Springer LNBI**,104-111（2014）；  \n2013年06月 获得校级“优秀毕业生”荣誉称号，并且毕业设计及毕业论文荣获“优秀”； \n2012年12月 荣获湖南农业大学“校级三好学生”荣誉称号；   \n2012年12月 荣获国家励志奖学金及湖南农业大学校级二等奖学金；    \n2012年05月 荣获湖南农业大学数学建模大赛二等奖；    \n2011年12月 荣获全国大学生数学建模竞赛湖南赛区本科组三等奖； \n2011年05月 被评为湖南农业大学2010-2011年度校级“优秀学生干部”； \n2010年12月 荣获湖南农业大学校级一等奖学金及国家一等助学金。  \n2010年12月 荣获湖南农业大学2009-2010学年“院级三好学生”荣誉称号；\n2010年05月 被评为湖南农业大学2009-2010年度校级“优秀团员”荣誉称号；  \n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:6px;padding-top:13px;\">个人经验</div>\n\n<div style=\"width:100%;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>  \n\n目前——\t研究蛋白质-RNA结合位点的预测；  \n2015年04月 中南大学2015年研究生自主探索创新项目《基于跨物种基因共表达的蛋白质功能预测》通过，担任项目主要负责人；  \n2015年04月 带中南大学本科生软件工程专业学生《云计算》实验课，并指导学生完成部分实验；  \n2015年03月 中软国际春季实训开发《知音交友网》，担任小组组长兼技术总监，负责项目分工和监督。参与需求分析和数据库的详细设计，负责日志功能模块、恋爱秘籍模块、城市地区模块的代码开发；  \n2014年10月 中软国际秋季实训开发《南书房—网上书城》并担任技术总监，参与数据库的详细设计，主要负责项目总体页面设计以及新用户注册、订单模块和购物车模块的代码开发；  \n2013年05月 开发《音像制品出租与销售网》个人本科毕业设计，荣获“优秀”。\n\n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:6px;padding-top:13px;\">自我评价</div>\n\n<div style=\"width:100%;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>  \n\n1.研究欲强，富有创造力；  \n2.性格温和，有耐心，待人友善，能快速适应新环境；  \n3.团队合作能力强，具有较强的合作分工意识，能够积极配合团队工作；   \n4.对自己有严格的要求，做事认真负责，每件事都坚持有始有终，不轻言放弃。\n\n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:6px;padding-top:13px;\">真情独白</div>\n\n<div style=\"width:100%;\"><span><img style=\"width:100%;margin-bottom:10px\" src=\"../assets/images/navigate.png\"></span></div>  \n\n> 我喜欢，驾驭着代码在风驰电掣中创造完美！  \n> 我喜欢，操纵着代码在随心所欲中体验生活！  \n> 我喜欢，书写着代码在时代浪潮中完成经典！  \n> 每一段新的代码在我手中诞生对我来说就像观看刹那花开的感动！留下传奇，创造生命！  \n \n\n---","source":"resume/resume.md","raw":"---\nlayout: page\ntitle: \"\" \nnoDate: \"true\"\ncomments: false\ndescription: \"个 人 简 历\" \nfancybox: false\n---\n<style>\nbody{\n\tfont-size: 12px;\n\tfont-family: Arial,Console,Verdana,Courier New;\n}\n</style>\n<script type=\"text/javascript\" src=\"http://sources.ikeepstudying.com/js/jquery-1.8.3.min.js\"></script>  \n<script type=\"text/javascript\" src=\"jquery.media.js\"></script>  \n<script type=\"text/javascript\">  \n    $(function() {  \n        $('a.resume').resume({width:800, height:600});  \n    });  \n</script>  \n<a class=\"resume\" target=\"_black\" href=\"/resume/resume.pdf\"> 下载PDF</a>\n<div style=\"text-align:center;font-size:26px;padding-top:0px\">个 人 简 历</div>\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:18px;\">基本资料</div>\n\n<div style=\"width:100%;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>\n\n<div style=\"width:100%;float:left;margin-top:-12px;\"><div style=\"float:left;width:60%;\">\n姓&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;名： 刘帝伟  \n 出生年月： 1991年7月  \n 所在学校： 中南大学\t\t\t\t\t\n 联系方式： 18707489940  \n 腾讯 Q Q： 466454368\t  \t\n 电子邮件： <a href=\"mailto:csu.ldw@csu.edu.cn\">csu.ldw@csu.edu.cn</a>  \n CSDN博客： <a href=\"http://blog.csdn.net/dream_angel_z\">http://blog.csdn.net/dream_angel_z</a>\n</div><div style=\"width:38%;padding:30px 2% 0 0;float:left;text-align:right;\"><img src=\"../assets/images/face-h200.jpg\" title=\"\" /></div></div>个人说明：中南大学在读硕士， 研究方向为机器学习，数据挖掘以及生物信息领域。热爱生活、乐于Coding！\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-top:13px\">个人能力</div>\n\n<div style=\"width:100%;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div> \n \n精通数据结构基本算法并熟悉数据挖掘常用分类和聚类算法，能将所学算法运用于实际应用中；  \n熟悉Linux安装、配置及常见问题的解决，以及Linux下账户的创建和维护；  \n熟悉Linux下shell及Python脚本编程，有搭建Hadoop集群和PBS高性能集群经验；  \n掌握SVN、Git服务器的搭建和维护，掌握Git的基本操作；  \n熟悉JavaScript、CSS、AJAX、HTML(XHTML)及XML等Web前端开发技术；  \n熟悉 SSH三大框架以和MVC三层架构开发模式并有相关项目开发经验，掌握常用的设计模式；  \n熟练使用MyEclipse、Eclipse、Dreamweaver、SVN等开发工具和Visio建模工具；  \n熟练使用Tomcat服务器进行项目的开发；  \n熟练使用Oracle、MySQL、Microsoft SQL Server等数据库及SQL语言；  \n英语水平：CET-6  456分 具有良好的文献搜索和阅读能力。  \n\n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:6px;padding-top:13px;\">奖励情况</div>\n\n<div style=\"width:100%;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div> \n \n2015年03月 中软实训基地实训结业并获得“个人优胜奖”及“优秀开发团队奖”；  \n2014年—— 发表论文 \" Yang Meng, Lei Deng, Zhigang Chen, Cheng Zhou, **Diwei Liu**, Chao Fan, and Ting Yan. **A Multi-Instance Multi-Label Learning Approach for Protein Domain Annotation**. **Springer LNBI**,104-111（2014）；  \n2013年06月 获得校级“优秀毕业生”荣誉称号，并且毕业设计及毕业论文荣获“优秀”； \n2012年12月 荣获湖南农业大学“校级三好学生”荣誉称号；   \n2012年12月 荣获国家励志奖学金及湖南农业大学校级二等奖学金；    \n2012年05月 荣获湖南农业大学数学建模大赛二等奖；    \n2011年12月 荣获全国大学生数学建模竞赛湖南赛区本科组三等奖； \n2011年05月 被评为湖南农业大学2010-2011年度校级“优秀学生干部”； \n2010年12月 荣获湖南农业大学校级一等奖学金及国家一等助学金。  \n2010年12月 荣获湖南农业大学2009-2010学年“院级三好学生”荣誉称号；\n2010年05月 被评为湖南农业大学2009-2010年度校级“优秀团员”荣誉称号；  \n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:6px;padding-top:13px;\">个人经验</div>\n\n<div style=\"width:100%;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>  \n\n目前——\t研究蛋白质-RNA结合位点的预测；  \n2015年04月 中南大学2015年研究生自主探索创新项目《基于跨物种基因共表达的蛋白质功能预测》通过，担任项目主要负责人；  \n2015年04月 带中南大学本科生软件工程专业学生《云计算》实验课，并指导学生完成部分实验；  \n2015年03月 中软国际春季实训开发《知音交友网》，担任小组组长兼技术总监，负责项目分工和监督。参与需求分析和数据库的详细设计，负责日志功能模块、恋爱秘籍模块、城市地区模块的代码开发；  \n2014年10月 中软国际秋季实训开发《南书房—网上书城》并担任技术总监，参与数据库的详细设计，主要负责项目总体页面设计以及新用户注册、订单模块和购物车模块的代码开发；  \n2013年05月 开发《音像制品出租与销售网》个人本科毕业设计，荣获“优秀”。\n\n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:6px;padding-top:13px;\">自我评价</div>\n\n<div style=\"width:100%;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>  \n\n1.研究欲强，富有创造力；  \n2.性格温和，有耐心，待人友善，能快速适应新环境；  \n3.团队合作能力强，具有较强的合作分工意识，能够积极配合团队工作；   \n4.对自己有严格的要求，做事认真负责，每件事都坚持有始有终，不轻言放弃。\n\n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:6px;padding-top:13px;\">真情独白</div>\n\n<div style=\"width:100%;\"><span><img style=\"width:100%;margin-bottom:10px\" src=\"../assets/images/navigate.png\"></span></div>  \n\n> 我喜欢，驾驭着代码在风驰电掣中创造完美！  \n> 我喜欢，操纵着代码在随心所欲中体验生活！  \n> 我喜欢，书写着代码在时代浪潮中完成经典！  \n> 每一段新的代码在我手中诞生对我来说就像观看刹那花开的感动！留下传奇，创造生命！  \n \n\n---","date":"2016-02-28T06:59:22.351Z","updated":"2015-11-22T05:12:27.380Z","path":"resume/resume.html","_id":"cimigpyir00016cuj51y981w3"},{"layout":"page","title":"Resume","icon":"glyphicon-tint","date":"2015-07-13T15:51:00.000Z","description":"个 人 简 历","_content":"<style> \nbody{\n\tline-height:22px;\n}\n</style>\n<div style=\"text-align:center;font-size:26px;padding-top:8px\">个 人 简 历</div>\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:16px\">基本资料</div>\n\n<div style=\"width:100%;margin-top:-12px;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>  \n<div style=\"width:100%;float:left;margin-bottom:5px;\">\n<div style=\"float:left;width:60%;\">\n\n 姓&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;名： 刘帝伟<br>\n 出生年月： 1991年7月<br>\t\t\t\t\t\n 所在学校： 中南大学<br>\t\t\t\t\t\n 联系方式： 18707489940 <br> \n 腾讯 Q Q： 466454368<br>\t\t\t\n 电子邮件： <a href=\"mailto:csu.ldw@csu.edu.cn\">csu.ldw@csu.edu.cn</a><br>\n CSDN博客： <a href=\"http://blog.csdn.net/dream_angel_z\">http://blog.csdn.net/dream_angel_z</a><br>\n\n</div>\n<div style=\"padding-right:3%;float:left;text-align:right;width:37%\">\n<a><img height=\"150px\" src=\"../assets/images/face.jpg\" /></a>\n</div>\n</div>\n\n个人说明：中南大学在读硕士， 研究方向为机器学习，数据挖掘以及生物信息领域。热爱生活、乐于Coding！\n\n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:16px\">个人能力</div>\n\n\n<div style=\"width:100%;margin-top:-12px;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>  \n精通数据结构基本算法并熟悉数据挖掘常用分类和聚类算法，能将所学算法运用于实际应用中；  \n熟悉Linux安装、配置及常见问题的解决，以及Linux下账户的创建和维护；  \n熟悉Linux下shell及Python脚本编程，有搭建Hadoop集群和PBS高性能集群经验；  \n熟悉SVN、Git服务器的搭建和维护，掌握Git的基本操作；  \n熟悉JavaScript、CSS、AJAX、HTML(XHTML)及XML等Web前端开发技术；  \n熟悉 SSH三大框架以和MVC三层架构开发模式并有相关项目开发经验，掌握常用的设计模式；  \n熟练使用MyEclipse、Eclipse、Dreamweaver、SVN等开发工具和Visio建模工具；  \n熟练使用Tomcat服务器进行项目的开发；  \n熟练使用Oracle、MySQL、Microsoft SQL Server等数据库及SQL语言；  \n英语水平：CET-6  456分 具有良好的文献搜索和阅读能力。\n\n\n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:16px\">奖励情况</div>\n\n<div style=\"width:100%;margin-top:-12px;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>  \n2015年03月 中软实训基地实训结业并获得“个人优胜奖”及“优秀开发团队奖”；  \n2014年—— 发表论文 \" Yang Meng, Lei Deng, Zhigang Chen, Cheng Zhou, **Diwei Liu**, Chao Fan, and Ting Yan. **A Multi-Instance Multi-Label Learning Approach for Protein Domain Annotation**. **Springer LNBI**,104-111（2014）；  \n2013年06月 获得校级“优秀毕业生”荣誉称号，并且毕业设计及毕业论文荣获“优秀”；  \n2012年12月 荣获湖南农业大学“校级三好学生”荣誉称号；   \n2012年12月 荣获国家励志奖学金及湖南农业大学校级二等奖学金；    \n2012年05月 荣获湖南农业大学数学建模大赛二等奖；    \n2011年12月 荣获全国大学生数学建模竞赛湖南赛区本科组三等奖；  \n2011年05月 被评为湖南农业大学2010-2011年度校级“优秀学生干部”；  \n2010年12月 荣获湖南农业大学校级一等奖学金及国家一等助学金。  \n2010年12月 荣获湖南农业大学2009-2010学年“院级三好学生”荣誉称号；  \n2010年05月 被评为湖南农业大学2009-2010年度校级“优秀团员”荣誉称号；   \n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:16px\">个人经验</div>\n\n<div style=\"width:100%;margin-top:-12px;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>  \n目前——\t研究蛋白质-RNA结合位点的预测；  \n2015年04月 中南大学2015年研究生自主探索创新项目《基于跨物种基因共表达的蛋白质功能预测》通过，担任项目主要负责人；  \n2015年04月 带中南大学本科生软件工程专业学生《云计算》实验课，并指导学生完成部分实验；  \n2015年03月 中软国际春季实训开发《知音交友网》，担任小组组长兼技术总监，负责项目分工和监督。参与需求分析和数据库的详细设计，负责日志功能模块、恋爱秘籍模块、城市地区模块的代码开发；  \n2014年10月 中软国际秋季实训开发《南书房—网上书城》并担任技术指导，参与数据库的详细设计，主要负责项目总体页面设计以及新用户注册、订单模块和购物车模块的代码开发；  \n2013年05月 开发《音像制品出租与销售网》个人本科毕业设计，荣获“优秀”。\n\n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:16px\">自我评价</div>\n\n<div style=\"width:100%;margin-top:-12px;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>  \n\n1.研究欲强，富有创造力；  \n2.性格温和，有耐心，待人友善，能快速适应新环境；  \n3.团队合作能力强，具有较强的合作分工意识，能够积极配合团队工作；   \n4.对自己有严格的要求，做事认真负责，每件事都坚持有始有终，不轻言放弃。","source":"resume/resume-pdf.md","raw":"---\nlayout: page\ntitle: Resume \npermalink: /resume/\nicon: glyphicon-tint\ndate: 2015-07-13 23:51 \ndescription: \"个 人 简 历\" \n---\n<style> \nbody{\n\tline-height:22px;\n}\n</style>\n<div style=\"text-align:center;font-size:26px;padding-top:8px\">个 人 简 历</div>\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:16px\">基本资料</div>\n\n<div style=\"width:100%;margin-top:-12px;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>  \n<div style=\"width:100%;float:left;margin-bottom:5px;\">\n<div style=\"float:left;width:60%;\">\n\n 姓&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;名： 刘帝伟<br>\n 出生年月： 1991年7月<br>\t\t\t\t\t\n 所在学校： 中南大学<br>\t\t\t\t\t\n 联系方式： 18707489940 <br> \n 腾讯 Q Q： 466454368<br>\t\t\t\n 电子邮件： <a href=\"mailto:csu.ldw@csu.edu.cn\">csu.ldw@csu.edu.cn</a><br>\n CSDN博客： <a href=\"http://blog.csdn.net/dream_angel_z\">http://blog.csdn.net/dream_angel_z</a><br>\n\n</div>\n<div style=\"padding-right:3%;float:left;text-align:right;width:37%\">\n<a><img height=\"150px\" src=\"../assets/images/face.jpg\" /></a>\n</div>\n</div>\n\n个人说明：中南大学在读硕士， 研究方向为机器学习，数据挖掘以及生物信息领域。热爱生活、乐于Coding！\n\n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:16px\">个人能力</div>\n\n\n<div style=\"width:100%;margin-top:-12px;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>  \n精通数据结构基本算法并熟悉数据挖掘常用分类和聚类算法，能将所学算法运用于实际应用中；  \n熟悉Linux安装、配置及常见问题的解决，以及Linux下账户的创建和维护；  \n熟悉Linux下shell及Python脚本编程，有搭建Hadoop集群和PBS高性能集群经验；  \n熟悉SVN、Git服务器的搭建和维护，掌握Git的基本操作；  \n熟悉JavaScript、CSS、AJAX、HTML(XHTML)及XML等Web前端开发技术；  \n熟悉 SSH三大框架以和MVC三层架构开发模式并有相关项目开发经验，掌握常用的设计模式；  \n熟练使用MyEclipse、Eclipse、Dreamweaver、SVN等开发工具和Visio建模工具；  \n熟练使用Tomcat服务器进行项目的开发；  \n熟练使用Oracle、MySQL、Microsoft SQL Server等数据库及SQL语言；  \n英语水平：CET-6  456分 具有良好的文献搜索和阅读能力。\n\n\n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:16px\">奖励情况</div>\n\n<div style=\"width:100%;margin-top:-12px;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>  \n2015年03月 中软实训基地实训结业并获得“个人优胜奖”及“优秀开发团队奖”；  \n2014年—— 发表论文 \" Yang Meng, Lei Deng, Zhigang Chen, Cheng Zhou, **Diwei Liu**, Chao Fan, and Ting Yan. **A Multi-Instance Multi-Label Learning Approach for Protein Domain Annotation**. **Springer LNBI**,104-111（2014）；  \n2013年06月 获得校级“优秀毕业生”荣誉称号，并且毕业设计及毕业论文荣获“优秀”；  \n2012年12月 荣获湖南农业大学“校级三好学生”荣誉称号；   \n2012年12月 荣获国家励志奖学金及湖南农业大学校级二等奖学金；    \n2012年05月 荣获湖南农业大学数学建模大赛二等奖；    \n2011年12月 荣获全国大学生数学建模竞赛湖南赛区本科组三等奖；  \n2011年05月 被评为湖南农业大学2010-2011年度校级“优秀学生干部”；  \n2010年12月 荣获湖南农业大学校级一等奖学金及国家一等助学金。  \n2010年12月 荣获湖南农业大学2009-2010学年“院级三好学生”荣誉称号；  \n2010年05月 被评为湖南农业大学2009-2010年度校级“优秀团员”荣誉称号；   \n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:16px\">个人经验</div>\n\n<div style=\"width:100%;margin-top:-12px;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>  \n目前——\t研究蛋白质-RNA结合位点的预测；  \n2015年04月 中南大学2015年研究生自主探索创新项目《基于跨物种基因共表达的蛋白质功能预测》通过，担任项目主要负责人；  \n2015年04月 带中南大学本科生软件工程专业学生《云计算》实验课，并指导学生完成部分实验；  \n2015年03月 中软国际春季实训开发《知音交友网》，担任小组组长兼技术总监，负责项目分工和监督。参与需求分析和数据库的详细设计，负责日志功能模块、恋爱秘籍模块、城市地区模块的代码开发；  \n2014年10月 中软国际秋季实训开发《南书房—网上书城》并担任技术指导，参与数据库的详细设计，主要负责项目总体页面设计以及新用户注册、订单模块和购物车模块的代码开发；  \n2013年05月 开发《音像制品出租与销售网》个人本科毕业设计，荣获“优秀”。\n\n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:16px\">自我评价</div>\n\n<div style=\"width:100%;margin-top:-12px;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>  \n\n1.研究欲强，富有创造力；  \n2.性格温和，有耐心，待人友善，能快速适应新环境；  \n3.团队合作能力强，具有较强的合作分工意识，能够积极配合团队工作；   \n4.对自己有严格的要求，做事认真负责，每件事都坚持有始有终，不轻言放弃。","updated":"2015-11-22T05:12:27.378Z","path":"/resume/index.html","comments":1,"_id":"cimigpyiv00026cujbg4sr1vv"},{"layout":"page","title":"","noDate":"true","comments":0,"description":"个 人 简 历","fancybox":false,"_content":"\n<div style=\"text-align:center;font-size:26px;padding-top:30px\">个 人 简 历</div>\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:13px\">基本资料</div>\n\n<div style=\"width:100%;margin-top:-12px;margin-bottom:-12px\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>\n\n<div style=\"width:100%;float:left;margin-top:-12px;\"><div style=\"float:left;width:60%;\">\n姓&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;名： 刘帝伟  \n 出生年月： 1991年7月  \n 所在学校： 中南大学\t\t\t\t\t\n 联系方式： 18707489940  \n 腾讯 Q Q： 466454368\t  \t\n 电子邮件： <a href=\"mailto:csu.ldw@csu.edu.cn\">csu.ldw@csu.edu.cn</a>  \n CSDN博客： <a href=\"http://blog.csdn.net/dream_angel_z\">http://blog.csdn.net/dream_angel_z</a>\n</div><div style=\"width:37%;padding:30px 3% 0 0;float:left;text-align:right;\"><img src=\"../assets/images/face-h200.jpg\" title=\"\" /></div></div>个人说明：中南大学在读硕士， 研究方向为机器学习，数据挖掘以及生物信息领域。热爱生活、乐于Coding！\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:6px;padding-top:13px\">个人能力</div>\n\n<div style=\"width:100%;margin-top:-12px;padding-bottom:8px\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div> \n \n精通数据结构基本算法并熟悉数据挖掘常用分类和聚类算法，如KNN、SVM、NB、RF、Apriori等,能将所学机器学习算法运用于实际应用中；  \n熟悉C++、JAVA和Python编程语言，并有相关项目经验，了解Perl、R语言以及Matlab编程；  \n熟悉Linux基本命令和Shell高级脚本语言，掌握Git基本操作，有搭建Hadoop集群和PBS高性能集群经验；  \n熟悉JavaScript、CSS、AJAX、HTML(XHTML)，XML等前端开发技术；  \n熟悉SSH三大框架和MVC三层架构开发模式，掌握常用的设计模式；  \n熟练使用MyEclipse、Eclipse、Dreamweaver、SVN等开发工具以及visio建模工具；  \n熟练使用Tomcat服务器进行项目的开发；  \n熟练使用Oracle、MySQL、Microsoft SQL Server等数据库及SQL语言；  \n英语水平：CET-6  456分 具有良好的文献搜索和阅读能力。   \n其它技能：C1机动车辆驾驶证 \n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:6px;padding-top:13px;padding-bottom:8px\">奖励情况</div>\n\n<div style=\"width:100%;margin-top:-12px;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div> \n \n2015年03月 中软实训基地实训结业并获得“个人优胜奖”及“优秀开发团队奖”；  \n2014年—— 发表论文 \" Yang Meng, Lei Deng, Zhigang Chen, Cheng Zhou, **Diwei Liu**, Chao Fan, and Ting Yan. **A Multi-Instance Multi-Label Learning Approach for Protein Domain Annotation**. **Springer LNBI**,104-111（2014）；  \n2013年06月 获得校级“优秀毕业生”荣誉称号，并且毕业设计及毕业论文荣获“优秀”； \n2012年12月 荣获湖南农业大学“校级三好学生”荣誉称号；   \n2012年12月 荣获国家励志奖学金及湖南农业大学校级二等奖学金；    \n2012年05月 荣获湖南农业大学数学建模大赛二等奖；    \n2011年12月 荣获全国大学生数学建模竞赛湖南赛区本科组三等奖； \n2011年05月 被评为湖南农业大学2010-2011年度校级“优秀学生干部”； \n2010年12月 荣获湖南农业大学校级一等奖学金及国家一等助学金。  \n2010年12月 荣获湖南农业大学2009-2010学年“院级三好学生”荣誉称号；\n2010年05月 被评为湖南农业大学2009-2010年度校级“优秀团员”荣誉称号；  \n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:6px;padding-top:13px;padding-bottom:8px\">个人经验</div>\n\n<div style=\"width:100%;margin-top:-12px;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>  \n\n目前——\t研究蛋白质-RNA结合位点的预测；  \n2015年04月 中南大学2015年研究生自主探索创新项目《基于跨物种基因共表达的蛋白质功能预测》通过，担任项目主要负责人；  \n2015年04月 带中南大学本科生软件工程专业学生《云计算》实验课，并指导学生完成部分实验；  \n2015年03月 中软国际春季实训开发《知音交友网》，担任小组组长兼技术总监，负责项目分工和监督。参与需求分析和数据库的详细设计，负责日志功能模块、恋爱秘籍模块、城市地区模块的代码开发；  \n2014年10月 中软国际秋季实训开发《南书房—网上书城》并担任技术总监，参与数据库的详细设计，主要负责项目总体页面设计以及新用户注册、订单模块和购物车模块的代码开发；  \n2013年05月 开发《音像制品出租与销售网》个人本科毕业设计，荣获“优秀”。\n\n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:6px;padding-top:13px;padding-bottom:8px\">自我评价</div>\n\n<div style=\"width:100%;margin-top:-12px;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>  \n\n1.研究欲强，富有创造力；  \n2.性格温和，有耐心，待人友善，能快速适应新环境；  \n3.团队合作能力强，具有较强的合作分工意识，能够积极配合团队工作；   \n4.对自己有严格的要求，做事认真负责，每件事都坚持有始有终，不轻言放弃。\n\n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:6px;padding-top:13px;padding-bottom:8px\">真情独白</div>\n\n<div style=\"width:100%;margin-top:-12px;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>  \n\n> 我喜欢，驾驭着代码在风驰电掣中创造完美！  \n> 我喜欢，操纵着代码在随心所欲中体验生活！  \n> 我喜欢，书写着代码在时代浪潮中完成经典！  \n> 每一段新的代码在我手中诞生对我来说就像观看刹那花开的感动！留下传奇，创造生命！  \n \n\n---","source":"resume/index.md","raw":"---\nlayout: page\ntitle: \"\" \nnoDate: \"true\"\ncomments: false\ndescription: \"个 人 简 历\" \nfancybox: false\n---\n\n<div style=\"text-align:center;font-size:26px;padding-top:30px\">个 人 简 历</div>\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:13px\">基本资料</div>\n\n<div style=\"width:100%;margin-top:-12px;margin-bottom:-12px\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>\n\n<div style=\"width:100%;float:left;margin-top:-12px;\"><div style=\"float:left;width:60%;\">\n姓&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;名： 刘帝伟  \n 出生年月： 1991年7月  \n 所在学校： 中南大学\t\t\t\t\t\n 联系方式： 18707489940  \n 腾讯 Q Q： 466454368\t  \t\n 电子邮件： <a href=\"mailto:csu.ldw@csu.edu.cn\">csu.ldw@csu.edu.cn</a>  \n CSDN博客： <a href=\"http://blog.csdn.net/dream_angel_z\">http://blog.csdn.net/dream_angel_z</a>\n</div><div style=\"width:37%;padding:30px 3% 0 0;float:left;text-align:right;\"><img src=\"../assets/images/face-h200.jpg\" title=\"\" /></div></div>个人说明：中南大学在读硕士， 研究方向为机器学习，数据挖掘以及生物信息领域。热爱生活、乐于Coding！\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:6px;padding-top:13px\">个人能力</div>\n\n<div style=\"width:100%;margin-top:-12px;padding-bottom:8px\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div> \n \n精通数据结构基本算法并熟悉数据挖掘常用分类和聚类算法，如KNN、SVM、NB、RF、Apriori等,能将所学机器学习算法运用于实际应用中；  \n熟悉C++、JAVA和Python编程语言，并有相关项目经验，了解Perl、R语言以及Matlab编程；  \n熟悉Linux基本命令和Shell高级脚本语言，掌握Git基本操作，有搭建Hadoop集群和PBS高性能集群经验；  \n熟悉JavaScript、CSS、AJAX、HTML(XHTML)，XML等前端开发技术；  \n熟悉SSH三大框架和MVC三层架构开发模式，掌握常用的设计模式；  \n熟练使用MyEclipse、Eclipse、Dreamweaver、SVN等开发工具以及visio建模工具；  \n熟练使用Tomcat服务器进行项目的开发；  \n熟练使用Oracle、MySQL、Microsoft SQL Server等数据库及SQL语言；  \n英语水平：CET-6  456分 具有良好的文献搜索和阅读能力。   \n其它技能：C1机动车辆驾驶证 \n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:6px;padding-top:13px;padding-bottom:8px\">奖励情况</div>\n\n<div style=\"width:100%;margin-top:-12px;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div> \n \n2015年03月 中软实训基地实训结业并获得“个人优胜奖”及“优秀开发团队奖”；  \n2014年—— 发表论文 \" Yang Meng, Lei Deng, Zhigang Chen, Cheng Zhou, **Diwei Liu**, Chao Fan, and Ting Yan. **A Multi-Instance Multi-Label Learning Approach for Protein Domain Annotation**. **Springer LNBI**,104-111（2014）；  \n2013年06月 获得校级“优秀毕业生”荣誉称号，并且毕业设计及毕业论文荣获“优秀”； \n2012年12月 荣获湖南农业大学“校级三好学生”荣誉称号；   \n2012年12月 荣获国家励志奖学金及湖南农业大学校级二等奖学金；    \n2012年05月 荣获湖南农业大学数学建模大赛二等奖；    \n2011年12月 荣获全国大学生数学建模竞赛湖南赛区本科组三等奖； \n2011年05月 被评为湖南农业大学2010-2011年度校级“优秀学生干部”； \n2010年12月 荣获湖南农业大学校级一等奖学金及国家一等助学金。  \n2010年12月 荣获湖南农业大学2009-2010学年“院级三好学生”荣誉称号；\n2010年05月 被评为湖南农业大学2009-2010年度校级“优秀团员”荣誉称号；  \n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:6px;padding-top:13px;padding-bottom:8px\">个人经验</div>\n\n<div style=\"width:100%;margin-top:-12px;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>  \n\n目前——\t研究蛋白质-RNA结合位点的预测；  \n2015年04月 中南大学2015年研究生自主探索创新项目《基于跨物种基因共表达的蛋白质功能预测》通过，担任项目主要负责人；  \n2015年04月 带中南大学本科生软件工程专业学生《云计算》实验课，并指导学生完成部分实验；  \n2015年03月 中软国际春季实训开发《知音交友网》，担任小组组长兼技术总监，负责项目分工和监督。参与需求分析和数据库的详细设计，负责日志功能模块、恋爱秘籍模块、城市地区模块的代码开发；  \n2014年10月 中软国际秋季实训开发《南书房—网上书城》并担任技术总监，参与数据库的详细设计，主要负责项目总体页面设计以及新用户注册、订单模块和购物车模块的代码开发；  \n2013年05月 开发《音像制品出租与销售网》个人本科毕业设计，荣获“优秀”。\n\n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:6px;padding-top:13px;padding-bottom:8px\">自我评价</div>\n\n<div style=\"width:100%;margin-top:-12px;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>  \n\n1.研究欲强，富有创造力；  \n2.性格温和，有耐心，待人友善，能快速适应新环境；  \n3.团队合作能力强，具有较强的合作分工意识，能够积极配合团队工作；   \n4.对自己有严格的要求，做事认真负责，每件事都坚持有始有终，不轻言放弃。\n\n\n<div style=\"width:100%;color:#518cc7;font-weight:bold;font-size:20px;padding-bottom:6px;padding-top:13px;padding-bottom:8px\">真情独白</div>\n\n<div style=\"width:100%;margin-top:-12px;\"><span><img style=\"width:100%\" src=\"../assets/images/navigate.png\"></span></div>  \n\n> 我喜欢，驾驭着代码在风驰电掣中创造完美！  \n> 我喜欢，操纵着代码在随心所欲中体验生活！  \n> 我喜欢，书写着代码在时代浪潮中完成经典！  \n> 每一段新的代码在我手中诞生对我来说就像观看刹那花开的感动！留下传奇，创造生命！  \n \n\n---","date":"2016-03-23T12:40:06.401Z","updated":"2015-11-22T05:12:27.377Z","path":"resume/index.html","_id":"cimigpyjf00036cujbrpf0dp3"},{"title":"Leetcode[9]-Palindrome Number","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/palindrome-number/\n\nDetermine whether an integer is a palindrome. Do this without extra space.\n\nSome hints:\nCould negative integers be palindromes? (ie, -1)\n\nIf you are thinking of converting the integer to string, note the restriction of using extra space.\n\nYou could also try reversing an integer. However, if you have solved the problem \"Reverse Integer\", you know that the reversed integer might overflow. How would you handle such case?\n\nThere is a more generic way of solving this problem.\n\n-------------\n\n思路：求出它的反转数，然后比较两个数是否恒等于即可。\n\nC++代码：\n\n\n```\nclass Solution {\npublic:\n    bool isPalindrome(int x) {\n        \n        if(x < 0) return false;\n        int y = x, result = 0;\n        while( y > 0 ){\n            result = result * 10 + y%10;\n            y /= 10;\n        }\n        return result == x;\n    }\n};\n\n```\n\n法二：将数字转换成字符串，遍历一遍字符串，看首位是否相等即可\n\n```\n    bool isPalindrome(int x) {\n        \n        if(x < 0) return false;\n        if(x>=0 && x<=9) return true;\n        string str;\n        stringstream ss;\n        ss<<x;\n        ss>>str;\n        int len = str.length();\n        for(int i = 0; i < (len/2); i++ ){\n            if(str[i] != str[len-1-i])return false;\n        }\n        return true;\n        \n    }\n```\n\n\n</article>\n","source":"leetcode/Leetcode[9]-Palindrome Number.md","raw":"---\ntitle: Leetcode[9]-Palindrome Number\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/palindrome-number/\n\nDetermine whether an integer is a palindrome. Do this without extra space.\n\nSome hints:\nCould negative integers be palindromes? (ie, -1)\n\nIf you are thinking of converting the integer to string, note the restriction of using extra space.\n\nYou could also try reversing an integer. However, if you have solved the problem \"Reverse Integer\", you know that the reversed integer might overflow. How would you handle such case?\n\nThere is a more generic way of solving this problem.\n\n-------------\n\n思路：求出它的反转数，然后比较两个数是否恒等于即可。\n\nC++代码：\n\n\n```\nclass Solution {\npublic:\n    bool isPalindrome(int x) {\n        \n        if(x < 0) return false;\n        int y = x, result = 0;\n        while( y > 0 ){\n            result = result * 10 + y%10;\n            y /= 10;\n        }\n        return result == x;\n    }\n};\n\n```\n\n法二：将数字转换成字符串，遍历一遍字符串，看首位是否相等即可\n\n```\n    bool isPalindrome(int x) {\n        \n        if(x < 0) return false;\n        if(x>=0 && x<=9) return true;\n        string str;\n        stringstream ss;\n        ss<<x;\n        ss>>str;\n        int len = str.length();\n        for(int i = 0; i < (len/2); i++ ){\n            if(str[i] != str[len-1-i])return false;\n        }\n        return true;\n        \n    }\n```\n\n\n</article>\n","date":"2016-03-26T03:12:19.986Z","updated":"2016-03-23T14:33:02.978Z","path":"leetcode/Leetcode[9]-Palindrome Number.html","_id":"cimigpyjj00046cuj1cauw2h1"},{"title":"Leetcode[98]-Validate Binary Search Tree","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/validate-binary-search-tree/\n\nGiven a binary tree, determine if it is a valid binary search tree (BST).\n\nAssume a BST is defined as follows:\n\nThe left subtree of a node contains only nodes with keys less than the node's key.\nThe right subtree of a node contains only nodes with keys greater than the node's key.\nBoth the left and right subtrees must also be binary search trees.\nconfused what \"{1,#,2,3}\" means? > read more on how binary tree is serialized on OJ.\n\n-----\n\n思路：递归方法，对于根结点\n\n- 如果有左子树，比较根结点与左子树的最大值，如果小于等于则返回false；\n- 如果有右子树，比较根结点与右子树的最小值 ，如果大于等于则返回false；\n- 接着判断左子树和右子树是否也是合法的二叉搜索树；\n\nCode(c++):\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    bool isValidBST(TreeNode* root) {\n        if(root == NULL) return true;\n        if(root->left && root->val <= leftMax(root->left)) return false;\n        if(root->right && root->val >= rightMin(root->right)) return false;\n        \n        return isValidBST(root->left) && isValidBST(root->right);\n    }\n    //get the left tree max value\n    int leftMax(TreeNode *root){\n        if(root == NULL) return INT_MIN;\n        int max = root->val;\n    \n        int lmax = leftMax(root->left);\n        int rmax = leftMax(root->right);\n    \n        int max1 = lmax>rmax?lmax:rmax;\n        return max>max1?max:max1;\n    }\n    //get the right tree minimum value\n    int rightMin(TreeNode *root){\n        if(root == NULL) return INT_MAX;\n        int max = root->val;\n    \n        int lmin = rightMin(root->left);\n        int rmin = rightMin(root->right);\n    \n        int max1 = lmin>rmin? rmin:lmin;\n        return max>max1?max1:max;\n    }\n    \n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[98]-Validate Binary Search Tree.md","raw":"---\ntitle: Leetcode[98]-Validate Binary Search Tree\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/validate-binary-search-tree/\n\nGiven a binary tree, determine if it is a valid binary search tree (BST).\n\nAssume a BST is defined as follows:\n\nThe left subtree of a node contains only nodes with keys less than the node's key.\nThe right subtree of a node contains only nodes with keys greater than the node's key.\nBoth the left and right subtrees must also be binary search trees.\nconfused what \"{1,#,2,3}\" means? > read more on how binary tree is serialized on OJ.\n\n-----\n\n思路：递归方法，对于根结点\n\n- 如果有左子树，比较根结点与左子树的最大值，如果小于等于则返回false；\n- 如果有右子树，比较根结点与右子树的最小值 ，如果大于等于则返回false；\n- 接着判断左子树和右子树是否也是合法的二叉搜索树；\n\nCode(c++):\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    bool isValidBST(TreeNode* root) {\n        if(root == NULL) return true;\n        if(root->left && root->val <= leftMax(root->left)) return false;\n        if(root->right && root->val >= rightMin(root->right)) return false;\n        \n        return isValidBST(root->left) && isValidBST(root->right);\n    }\n    //get the left tree max value\n    int leftMax(TreeNode *root){\n        if(root == NULL) return INT_MIN;\n        int max = root->val;\n    \n        int lmax = leftMax(root->left);\n        int rmax = leftMax(root->right);\n    \n        int max1 = lmax>rmax?lmax:rmax;\n        return max>max1?max:max1;\n    }\n    //get the right tree minimum value\n    int rightMin(TreeNode *root){\n        if(root == NULL) return INT_MAX;\n        int max = root->val;\n    \n        int lmin = rightMin(root->left);\n        int rmin = rightMin(root->right);\n    \n        int max1 = lmin>rmin? rmin:lmin;\n        return max>max1?max1:max;\n    }\n    \n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.682Z","updated":"2016-03-23T14:33:02.977Z","path":"leetcode/Leetcode[98]-Validate Binary Search Tree.html","_id":"cimigpyjn00056cujgumc64dx"},{"title":"Leetcode[96]-Unique Binary Search Trees","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/unique-binary-search-trees/\n\nGiven n, how many structurally unique BST's (binary search trees) that store values 1...n?\n\nFor example,\nGiven n = 3, there are a total of 5 unique BST's.\n\n\t   1         3     3      2      1\n\t    \\       /     /      / \\      \\\n\t     3     2     1      1   3      2\n\t    /     /       \\                 \\\n\t   2     1         2                 3\n\n\n\n**思路：** 动态规划解题，dp[n]表示n个节点可以有dp[n]种不同的树，不管n为多少，先固定一个节点，剩余n-1个节点，分配给左右字数，然后把左子树个数乘以右子树的个数，\n\n- 初始值dp[0] = 1,dp[1] = 1,\n- dp[n] = dp[0] * dp[n-1] + dp[1] * dp[n-2] + ...+ dp[i] * dp[n-1-i] +... + dp[n-1] * dp[0]，也就是左边i个节点，右边n-1-i个节点。代码如下：\n\n**Code(c++):**\n\n```\nclass Solution {\npublic:\n    int numTrees(int n) {\n        vector<int> dp;\n        dp.resize(n+1);//set  the length of vector to n+1\n        for(int i = 0; i <= n; i++) {\n\t        //dp[0] = 1 , dp[1] =1\n            if(i<2){\n                dp[i] = 1;\n                continue;\n            }\n            //dp[n] = dp[0]*dp[n-1]+dp[1]*dp[n-2]+...+dp[n-1]*dp[0]\n            for(int j = 1; j<=i; j++) {\n                dp[i] += dp[j-1]*dp[i-j];\n            }\n        }\n        return dp[n];\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[96]-Unique Binary Search Trees.md","raw":"---\ntitle: Leetcode[96]-Unique Binary Search Trees\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/unique-binary-search-trees/\n\nGiven n, how many structurally unique BST's (binary search trees) that store values 1...n?\n\nFor example,\nGiven n = 3, there are a total of 5 unique BST's.\n\n\t   1         3     3      2      1\n\t    \\       /     /      / \\      \\\n\t     3     2     1      1   3      2\n\t    /     /       \\                 \\\n\t   2     1         2                 3\n\n\n\n**思路：** 动态规划解题，dp[n]表示n个节点可以有dp[n]种不同的树，不管n为多少，先固定一个节点，剩余n-1个节点，分配给左右字数，然后把左子树个数乘以右子树的个数，\n\n- 初始值dp[0] = 1,dp[1] = 1,\n- dp[n] = dp[0] * dp[n-1] + dp[1] * dp[n-2] + ...+ dp[i] * dp[n-1-i] +... + dp[n-1] * dp[0]，也就是左边i个节点，右边n-1-i个节点。代码如下：\n\n**Code(c++):**\n\n```\nclass Solution {\npublic:\n    int numTrees(int n) {\n        vector<int> dp;\n        dp.resize(n+1);//set  the length of vector to n+1\n        for(int i = 0; i <= n; i++) {\n\t        //dp[0] = 1 , dp[1] =1\n            if(i<2){\n                dp[i] = 1;\n                continue;\n            }\n            //dp[n] = dp[0]*dp[n-1]+dp[1]*dp[n-2]+...+dp[n-1]*dp[0]\n            for(int j = 1; j<=i; j++) {\n                dp[i] += dp[j-1]*dp[i-j];\n            }\n        }\n        return dp[n];\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.681Z","updated":"2016-03-23T14:33:02.964Z","path":"leetcode/Leetcode[96]-Unique Binary Search Trees.html","_id":"cimigpyjr00066cujcd7y7im8"},{"title":"Leetcode[94]-Binary Tree Inorder Traversal","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/binary-tree-inorder-traversal/\n\nGiven a binary tree, return the inorder traversal of its nodes' values.\n\nFor example:\nGiven binary tree `{1,#,2,3}`,\n\n```\n   1\n    \\\n     2\n    /\n   3\n```\n\nreturn` [1,3,2]`.\n\n-------\n\n递归遍历法C++：\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    vector<int> result;\n    vector<int> inorderTraversal(TreeNode *root) {\n        result.clear();\n        inorder(root);\n        return result;\n    }\n    void inorder(TreeNode* root){\n        if(root == NULL) return;\n        inorder(root->left);\n        result.push_back(root->val);\n        inorder(root->right);\n    }\n};\n```\n\n\n非递归算法1：\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    vector<int> inorderTraversal(TreeNode* root) {\n        vector<int> result;  \n        stack<TreeNode *> myStack;  \n        if (root == NULL)  \n            return result;  \n        TreeNode *p = root;  \n        while (p!=NULL || !myStack.empty()) {  \n            while (p != NULL) {  \n                myStack.push(p);  \n                p = p->left;  \n            }  \n            if (!myStack.empty())  {  \n                p = myStack.top();  \n                myStack.pop();  \n                result.push_back(p->val);  \n                p = p->right;  \n            }\n        }\n        return result;  \n    }\n};\n```\n\n非递归遍历方法二：(递归条件只需要判断栈是否为空)\n在递归条件中，\n\n- 首先取出栈顶节点，如果不为空的话，就把它的左节点进栈，然后再取栈顶元素，如果不为空，则再让它的左节点进栈，直到栈顶元素是空的节点为止；\n- 然后让栈顶的空指针退栈\n- 接着判断栈是否为空，如果不为空，则栈顶节点出栈，并将栈顶元素的值加入到数组中，然后把该节点的右节点入栈（右节点是否是空的，此处不做判断，内部的while循环会判断，因为内while循环后的栈顶节点必定是空指针）\n\n最后，返回数组即可。\n\n```\n /**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    vector<int> inorderTraversal(TreeNode* root) {\n        vector<int> result;\n        if(root == NULL) return result; \n        \n        stack<TreeNode *> stk;\n        TreeNode* p = root;\n        stk.push(root);\n        while(!stk.empty()){\n            while((p = stk.top()) && p){\n                stk.push(p->left);\n            }\n            stk.pop();\n            if(!stk.empty()){\n                p = stk.top();\n                result.push_back(p->val);\n                stk.pop();\n                p = p->right;\n                stk.push(p);\n            }\n        }\n        return result;\n    }\n};   \n```\n\n\n</article>\n","source":"leetcode/Leetcode[94]-Binary Tree Inorder Traversal.md","raw":"---\ntitle: Leetcode[94]-Binary Tree Inorder Traversal\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/binary-tree-inorder-traversal/\n\nGiven a binary tree, return the inorder traversal of its nodes' values.\n\nFor example:\nGiven binary tree `{1,#,2,3}`,\n\n```\n   1\n    \\\n     2\n    /\n   3\n```\n\nreturn` [1,3,2]`.\n\n-------\n\n递归遍历法C++：\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    vector<int> result;\n    vector<int> inorderTraversal(TreeNode *root) {\n        result.clear();\n        inorder(root);\n        return result;\n    }\n    void inorder(TreeNode* root){\n        if(root == NULL) return;\n        inorder(root->left);\n        result.push_back(root->val);\n        inorder(root->right);\n    }\n};\n```\n\n\n非递归算法1：\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    vector<int> inorderTraversal(TreeNode* root) {\n        vector<int> result;  \n        stack<TreeNode *> myStack;  \n        if (root == NULL)  \n            return result;  \n        TreeNode *p = root;  \n        while (p!=NULL || !myStack.empty()) {  \n            while (p != NULL) {  \n                myStack.push(p);  \n                p = p->left;  \n            }  \n            if (!myStack.empty())  {  \n                p = myStack.top();  \n                myStack.pop();  \n                result.push_back(p->val);  \n                p = p->right;  \n            }\n        }\n        return result;  \n    }\n};\n```\n\n非递归遍历方法二：(递归条件只需要判断栈是否为空)\n在递归条件中，\n\n- 首先取出栈顶节点，如果不为空的话，就把它的左节点进栈，然后再取栈顶元素，如果不为空，则再让它的左节点进栈，直到栈顶元素是空的节点为止；\n- 然后让栈顶的空指针退栈\n- 接着判断栈是否为空，如果不为空，则栈顶节点出栈，并将栈顶元素的值加入到数组中，然后把该节点的右节点入栈（右节点是否是空的，此处不做判断，内部的while循环会判断，因为内while循环后的栈顶节点必定是空指针）\n\n最后，返回数组即可。\n\n```\n /**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    vector<int> inorderTraversal(TreeNode* root) {\n        vector<int> result;\n        if(root == NULL) return result; \n        \n        stack<TreeNode *> stk;\n        TreeNode* p = root;\n        stk.push(root);\n        while(!stk.empty()){\n            while((p = stk.top()) && p){\n                stk.push(p->left);\n            }\n            stk.pop();\n            if(!stk.empty()){\n                p = stk.top();\n                result.push_back(p->val);\n                stk.pop();\n                p = p->right;\n                stk.push(p);\n            }\n        }\n        return result;\n    }\n};   \n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.679Z","updated":"2016-03-23T14:33:02.960Z","path":"leetcode/Leetcode[94]-Binary Tree Inorder Traversal.html","_id":"cimigpykd00076cujirpp6usx"},{"title":"Leetcode[92]-Reverse Linked List II","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/reverse-linked-list-ii/\n\nReverse a linked list from position m to n. Do it in-place and in one-pass.\n\nFor example:\nGiven 1->2->3->4->5->NULL, m = 2 and n = 4,\n\nreturn 1->4->3->2->5->NULL.\n\nNote:\nGiven m, n satisfy the following condition:\n1 ≤ m ≤ n ≤ length of list.\n\n----------------\n\n**思路**：分别找到m节点和m的前节点，n节点和n的后节点，然后翻转m到n的部分，最后链接三部分成一个整体；代码如下\n\n**Code(c++):**\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    ListNode* reverseBetween(ListNode* head, int m, int n) {\n        \n        if(head == NULL) return head;\n\n        ListNode *newList = new ListNode(-1);\n        newList->next = head;\n\n        ListNode *prebegin = newList;\n        ListNode *begin = head;\n\n        ListNode *end = newList;\n        ListNode *postend = head;\n        \n        //begin as center start node\n        while(--m){\n            prebegin = prebegin->next;\n            begin = begin->next;\n        }\n        //end as center end node\n        while(n--){\n            end = end->next;\n            postend = postend->next;\n        }\n        \n        //reverse center part\n        reverse(begin, end);\n        //link three part as one list\n        prebegin->next = begin;\n        end->next = postend;\n        \n        head = newList->next;\n        return head;\n    }\n    \n    void reverse(ListNode*& begin, ListNode*& end){\n        if(begin == end)\n            return;\n        if(begin->next == end){\n            end->next = begin;\n        } else {\n            //at least 3 nodes\n            ListNode* pre = begin;\n            ListNode* cur = pre->next;\n            ListNode* post = cur->next;\n            while(post != end->next){\n                cur->next = pre;\n                pre = cur;\n                cur = post;\n                post = post->next;\n            }\n            cur->next = pre;\n        }\n        //swap begin and end\n        ListNode* temp = begin;\n        begin = end;\n        end = temp;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[92]-Reverse Linked List II.md","raw":"---\ntitle: Leetcode[92]-Reverse Linked List II\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/reverse-linked-list-ii/\n\nReverse a linked list from position m to n. Do it in-place and in one-pass.\n\nFor example:\nGiven 1->2->3->4->5->NULL, m = 2 and n = 4,\n\nreturn 1->4->3->2->5->NULL.\n\nNote:\nGiven m, n satisfy the following condition:\n1 ≤ m ≤ n ≤ length of list.\n\n----------------\n\n**思路**：分别找到m节点和m的前节点，n节点和n的后节点，然后翻转m到n的部分，最后链接三部分成一个整体；代码如下\n\n**Code(c++):**\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    ListNode* reverseBetween(ListNode* head, int m, int n) {\n        \n        if(head == NULL) return head;\n\n        ListNode *newList = new ListNode(-1);\n        newList->next = head;\n\n        ListNode *prebegin = newList;\n        ListNode *begin = head;\n\n        ListNode *end = newList;\n        ListNode *postend = head;\n        \n        //begin as center start node\n        while(--m){\n            prebegin = prebegin->next;\n            begin = begin->next;\n        }\n        //end as center end node\n        while(n--){\n            end = end->next;\n            postend = postend->next;\n        }\n        \n        //reverse center part\n        reverse(begin, end);\n        //link three part as one list\n        prebegin->next = begin;\n        end->next = postend;\n        \n        head = newList->next;\n        return head;\n    }\n    \n    void reverse(ListNode*& begin, ListNode*& end){\n        if(begin == end)\n            return;\n        if(begin->next == end){\n            end->next = begin;\n        } else {\n            //at least 3 nodes\n            ListNode* pre = begin;\n            ListNode* cur = pre->next;\n            ListNode* post = cur->next;\n            while(post != end->next){\n                cur->next = pre;\n                pre = cur;\n                cur = post;\n                post = post->next;\n            }\n            cur->next = pre;\n        }\n        //swap begin and end\n        ListNode* temp = begin;\n        begin = end;\n        end = temp;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.678Z","updated":"2016-03-23T14:33:02.959Z","path":"leetcode/Leetcode[92]-Reverse Linked List II.html","_id":"cimigpylb00086cujv7pcnsh9"},{"title":"Leetcode[88]-Merge Sorted Array","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/merge-sorted-array/\n\nGiven two sorted integer arrays nums1 and nums2, merge nums2 into nums1 as one sorted array.\n\nNote:\nYou may assume that nums1 has enough space (size that is greater or equal to m + n) to hold additional elements from nums2. The number of elements initialized in nums1 and nums2 are m and n respectively.\n\n-------\n分析：首先将nums1数组容量扩大到m+n,然后进行m+n-1次迭代，从后往前比较nums1和nums2的大小。\n\n- 如果nums1的值大于nums2的值，就将nums1的值放到nums1的最后一个；\n- 如果nums2的值大于nums1的值，就将nums2的值放到nums1的最后一个；\n- ......\n- 依次迭代\n- ......\n\n最后会必定有一个数组放完了，然后判断，哪个数组没放完，就接着放。\n\nCode(c++):\n\n```\nclass Solution {\npublic:\n    void merge(vector<int>& nums1, int m, vector<int>& nums2, int n) {\n        nums1.resize(m+n);\n        int j = m-1, k = n-1;\n        for(int i = m+n-1; i >= 0; --i) {\n            if(j >=0 && k >= 0){\n                if(nums1[j] >= nums2[k]){\n                    nums1[i] = nums1[j--];\n                }else if(nums1[j] < nums2[k]){\n                    nums1[i] = nums2[k--];\n                }\n            }else if(k>=0){\n                nums1[i] = nums2[k--];\n            }else if(j>=0){\n                nums1[i] = nums1[j--];\n            }\n        }\n    }\n};\n```\n\n方法二：\n\n```\nclass Solution {\npublic:\n    void merge(vector<int>& nums1, int m, vector<int>& nums2, int n) {\n        int s = m+n-1;\n        nums1.resize(m+n);\n        int i = m-1,j = n-1;\n        while(i>=0 && j>=0){\n            if (nums1[i] >= nums2[j]){\n                nums1[s--] = nums1[i--];\n            }else if(nums1[i] <nums2[j]){\n                nums1[s--] = nums2[j--];\n            }\n        }  \n        \n        while(j>=0){\n            nums1[s--] = nums2[j--];\n        }\n        while(i>=0){\n            nums1[s--] = nums1[i--];\n        }\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[88]-Merge Sorted Array.md","raw":"---\ntitle: Leetcode[88]-Merge Sorted Array\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/merge-sorted-array/\n\nGiven two sorted integer arrays nums1 and nums2, merge nums2 into nums1 as one sorted array.\n\nNote:\nYou may assume that nums1 has enough space (size that is greater or equal to m + n) to hold additional elements from nums2. The number of elements initialized in nums1 and nums2 are m and n respectively.\n\n-------\n分析：首先将nums1数组容量扩大到m+n,然后进行m+n-1次迭代，从后往前比较nums1和nums2的大小。\n\n- 如果nums1的值大于nums2的值，就将nums1的值放到nums1的最后一个；\n- 如果nums2的值大于nums1的值，就将nums2的值放到nums1的最后一个；\n- ......\n- 依次迭代\n- ......\n\n最后会必定有一个数组放完了，然后判断，哪个数组没放完，就接着放。\n\nCode(c++):\n\n```\nclass Solution {\npublic:\n    void merge(vector<int>& nums1, int m, vector<int>& nums2, int n) {\n        nums1.resize(m+n);\n        int j = m-1, k = n-1;\n        for(int i = m+n-1; i >= 0; --i) {\n            if(j >=0 && k >= 0){\n                if(nums1[j] >= nums2[k]){\n                    nums1[i] = nums1[j--];\n                }else if(nums1[j] < nums2[k]){\n                    nums1[i] = nums2[k--];\n                }\n            }else if(k>=0){\n                nums1[i] = nums2[k--];\n            }else if(j>=0){\n                nums1[i] = nums1[j--];\n            }\n        }\n    }\n};\n```\n\n方法二：\n\n```\nclass Solution {\npublic:\n    void merge(vector<int>& nums1, int m, vector<int>& nums2, int n) {\n        int s = m+n-1;\n        nums1.resize(m+n);\n        int i = m-1,j = n-1;\n        while(i>=0 && j>=0){\n            if (nums1[i] >= nums2[j]){\n                nums1[s--] = nums1[i--];\n            }else if(nums1[i] <nums2[j]){\n                nums1[s--] = nums2[j--];\n            }\n        }  \n        \n        while(j>=0){\n            nums1[s--] = nums2[j--];\n        }\n        while(i>=0){\n            nums1[s--] = nums1[i--];\n        }\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.677Z","updated":"2016-03-23T14:33:02.957Z","path":"leetcode/Leetcode[88]-Merge Sorted Array.html","_id":"cimigpylh00096cuj3p8cmc8v"},{"title":"Leetcode[86]-Partition List","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink： https://leetcode.com/problems/partition-list/\n\nGiven a linked list and a value x, partition it such that all nodes less than x come before nodes greater than or equal to x.\n\nYou should preserve the original relative order of the nodes in each of the two partitions.\n\nFor example,\nGiven 1->4->3->2->5->2 and x = 3,\nreturn 1->2->2->4->3->5.\n\n-------\n\n思路：设置两个临时单链表，一个存放小于x的链表，一个存放大于x的链表，然后遍历head，一次存入两个链表中，最后合并两个链表。\n\nCode(c++):\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    ListNode* partition(ListNode* head, int x) {\n        if(head == NULL || head->next==NULL) return head;\n        ListNode *left = new ListNode(-1),*right = new ListNode(-1);\n        ListNode *ltail = left,* rtail = right;\n        ListNode *pre = head;\n        while(pre){\n            if(pre->val < x) {\n                ltail->next = pre;\n                ltail = ltail->next;\n            }else{\n                rtail->next = pre;\n                rtail = rtail->next;\n            }\n            pre = pre->next;\n        }\n        if(right->next){\n            ltail->next = right->next;\n            rtail->next = NULL;//set rtail as NULL, otherwise time limited error\n        }\n        left = left->next;\n        return left;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[86]-Partition List.md","raw":"---\ntitle: Leetcode[86]-Partition List\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink： https://leetcode.com/problems/partition-list/\n\nGiven a linked list and a value x, partition it such that all nodes less than x come before nodes greater than or equal to x.\n\nYou should preserve the original relative order of the nodes in each of the two partitions.\n\nFor example,\nGiven 1->4->3->2->5->2 and x = 3,\nreturn 1->2->2->4->3->5.\n\n-------\n\n思路：设置两个临时单链表，一个存放小于x的链表，一个存放大于x的链表，然后遍历head，一次存入两个链表中，最后合并两个链表。\n\nCode(c++):\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    ListNode* partition(ListNode* head, int x) {\n        if(head == NULL || head->next==NULL) return head;\n        ListNode *left = new ListNode(-1),*right = new ListNode(-1);\n        ListNode *ltail = left,* rtail = right;\n        ListNode *pre = head;\n        while(pre){\n            if(pre->val < x) {\n                ltail->next = pre;\n                ltail = ltail->next;\n            }else{\n                rtail->next = pre;\n                rtail = rtail->next;\n            }\n            pre = pre->next;\n        }\n        if(right->next){\n            ltail->next = right->next;\n            rtail->next = NULL;//set rtail as NULL, otherwise time limited error\n        }\n        left = left->next;\n        return left;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.675Z","updated":"2016-03-23T14:33:02.952Z","path":"leetcode/Leetcode[86]-Partition List.html","_id":"cimigpylp000a6cujikmohi8r"},{"title":"Leetcode[83]-Remove Duplicates from Sorted List","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/remove-duplicates-from-sorted-list/\n\nGiven a sorted linked list, delete all duplicates such that each element appear only once.\n\nFor example,\n\n\tGiven 1->1->2, return 1->2.\n\tGiven 1->1->2->3->3, return 1->2->3.\n\n-----\n\n比较简单，直接贴代码了！\n\nC++:\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    ListNode* deleteDuplicates(ListNode* head) {\n        ListNode * pre = head;\n        \n        while(pre && pre->next){\n            if(pre->val == pre->next->val){\n                pre->next = pre->next->next;\n                continue;\n            }\n            pre = pre->next;            \n        }\n        return head;\n    }\n};\n```\n\n**注意while循环的时候也要判断pre->next是否为空，如果为空就不用做判断了！**\n\n\n</article>\n","source":"leetcode/Leetcode[83]-Remove Duplicates from Sorted List.md","raw":"---\ntitle: Leetcode[83]-Remove Duplicates from Sorted List\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/remove-duplicates-from-sorted-list/\n\nGiven a sorted linked list, delete all duplicates such that each element appear only once.\n\nFor example,\n\n\tGiven 1->1->2, return 1->2.\n\tGiven 1->1->2->3->3, return 1->2->3.\n\n-----\n\n比较简单，直接贴代码了！\n\nC++:\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    ListNode* deleteDuplicates(ListNode* head) {\n        ListNode * pre = head;\n        \n        while(pre && pre->next){\n            if(pre->val == pre->next->val){\n                pre->next = pre->next->next;\n                continue;\n            }\n            pre = pre->next;            \n        }\n        return head;\n    }\n};\n```\n\n**注意while循环的时候也要判断pre->next是否为空，如果为空就不用做判断了！**\n\n\n</article>\n","date":"2016-03-23T14:33:15.674Z","updated":"2016-03-23T14:33:02.942Z","path":"leetcode/Leetcode[83]-Remove Duplicates from Sorted List.html","_id":"cimigpylv000b6cuj9d09kmfk"},{"title":"Leetcode[82]-Remove Duplicates from Sorted List II","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/remove-duplicates-from-sorted-list-ii/\n\nGiven a sorted linked list, delete all nodes that have duplicate numbers, leaving only distinct numbers from the original list.\n\nFor example,\nGiven `1->2->3->3->4->4->5`, return`1->2->5`.\nGiven `1->1->1->2->3`, return `2->3`.\n\n-------\n\n思路：跟上道题<a href=\"http://blog.csdn.net/dream_angel_z/article/details/46446067\">Leetcode[83]-Remove Duplicates from Sorted List</a>算法有点区别，这道题需要设置一个标示符，如果某一趟比较的时候两个元素相等了，就设flag等于true，接着下一趟循环如果两个元素不相等，但此时的flag为true，就需要将两个元素前面的那个删掉。\n\n最后，必定第二个元素为空而终止，此时还需要判断flag是否为true，如果为true，则末尾的元素还需要删掉；\n\n代码如下：\nCode(c++):\n\n```c++\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    ListNode* deleteDuplicates(ListNode* head) {\n       ListNode * newList = new ListNode(-1);\n        newList->next = head;\n        ListNode *pre = newList;\n    \n        bool flag = false;\n        while(pre->next && pre->next->next){\n            if(pre->next->val == pre->next->next->val){\n                pre->next = pre->next->next;\n                flag = true;\n                continue;\n            }\n            if(flag == true){\n                pre->next = pre->next->next;\n                flag = false;\n                continue;\n            }\n            pre = pre->next;\n        }\n        //最后还需要判断是否上次判断时元素重复\n        if(flag == true){\n            pre->next = pre->next->next;\n        }\n        head = newList->next;\n        return head;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[82]-Remove Duplicates from Sorted List II.md","raw":"---\ntitle: Leetcode[82]-Remove Duplicates from Sorted List II\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/remove-duplicates-from-sorted-list-ii/\n\nGiven a sorted linked list, delete all nodes that have duplicate numbers, leaving only distinct numbers from the original list.\n\nFor example,\nGiven `1->2->3->3->4->4->5`, return`1->2->5`.\nGiven `1->1->1->2->3`, return `2->3`.\n\n-------\n\n思路：跟上道题<a href=\"http://blog.csdn.net/dream_angel_z/article/details/46446067\">Leetcode[83]-Remove Duplicates from Sorted List</a>算法有点区别，这道题需要设置一个标示符，如果某一趟比较的时候两个元素相等了，就设flag等于true，接着下一趟循环如果两个元素不相等，但此时的flag为true，就需要将两个元素前面的那个删掉。\n\n最后，必定第二个元素为空而终止，此时还需要判断flag是否为true，如果为true，则末尾的元素还需要删掉；\n\n代码如下：\nCode(c++):\n\n```c++\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    ListNode* deleteDuplicates(ListNode* head) {\n       ListNode * newList = new ListNode(-1);\n        newList->next = head;\n        ListNode *pre = newList;\n    \n        bool flag = false;\n        while(pre->next && pre->next->next){\n            if(pre->next->val == pre->next->next->val){\n                pre->next = pre->next->next;\n                flag = true;\n                continue;\n            }\n            if(flag == true){\n                pre->next = pre->next->next;\n                flag = false;\n                continue;\n            }\n            pre = pre->next;\n        }\n        //最后还需要判断是否上次判断时元素重复\n        if(flag == true){\n            pre->next = pre->next->next;\n        }\n        head = newList->next;\n        return head;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.673Z","updated":"2016-03-23T14:33:02.931Z","path":"leetcode/Leetcode[82]-Remove Duplicates from Sorted List II.html","_id":"cimigpyn6000c6cujyfhna4da"},{"title":"Leetcode[81]-Search for a Range","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/search-in-rotated-sorted-array-ii/\n\nGiven a sorted array of integers, find the starting and ending position of a given target value.\n\nYour algorithm's runtime complexity must be in the order of O(log n).\n\nIf the target is not found in the array, return [-1, -1].\n\nFor example,\nGiven [5, 7, 7, 8, 8, 10] and target value 8,\nreturn [3, 4].\n\n-------------\n\n思路：首先初始化一个2列的数组，值为-1，然后一次遍历数组，设置一个变量作为标识，记录出现target值的下标，并保存到数组中，如果标识值等于=了，就不增加它的值，保证数组第二个元素是最后一个出现target的下标。\n\nC++:\n\n```\nclass Solution {\npublic:\n    vector<int> searchRange(vector<int>& nums, int target) {\n        vector<int> res(2);\n        res[0]=-1,res[1]=-1;\n        int n = nums.size();\n        \n        int temp = 0;\n        for(int i = 0; i < n; i++){\n            if(target == nums[i]){\n                if(temp == 2)\n                    res[temp-1] = i;\n                else\n                    res[temp++] = i;\n            }\n        }\n        if(temp ==1) {\n            res[temp] = res[0];\n        }\n        return res;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[81]-Search for a Range.md","raw":"---\ntitle: Leetcode[81]-Search for a Range\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/search-in-rotated-sorted-array-ii/\n\nGiven a sorted array of integers, find the starting and ending position of a given target value.\n\nYour algorithm's runtime complexity must be in the order of O(log n).\n\nIf the target is not found in the array, return [-1, -1].\n\nFor example,\nGiven [5, 7, 7, 8, 8, 10] and target value 8,\nreturn [3, 4].\n\n-------------\n\n思路：首先初始化一个2列的数组，值为-1，然后一次遍历数组，设置一个变量作为标识，记录出现target值的下标，并保存到数组中，如果标识值等于=了，就不增加它的值，保证数组第二个元素是最后一个出现target的下标。\n\nC++:\n\n```\nclass Solution {\npublic:\n    vector<int> searchRange(vector<int>& nums, int target) {\n        vector<int> res(2);\n        res[0]=-1,res[1]=-1;\n        int n = nums.size();\n        \n        int temp = 0;\n        for(int i = 0; i < n; i++){\n            if(target == nums[i]){\n                if(temp == 2)\n                    res[temp-1] = i;\n                else\n                    res[temp++] = i;\n            }\n        }\n        if(temp ==1) {\n            res[temp] = res[0];\n        }\n        return res;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.670Z","updated":"2016-03-23T14:33:02.919Z","path":"leetcode/Leetcode[81]-Search for a Range.html","_id":"cimigpynd000d6cujlgmcg3xq"},{"title":"Leetcode[7]-Reverse Integer","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/reverse-integer/\n\nReverse digits of an integer.\n\n\tExample1: x = 123, return 321\n\tExample2: x = -123, return -321\n\n-----\n\n\n取一个数的最后一位，用`x % 10`,取一个数的前n-1位（共n位），用`x/10`，每一次取的时候，都将上一次取的数乘以10，然后再加上末尾的数即可，代码如下：\n\nCode(C++)\n\n```\nclass Solution {\npublic:\n    int reverse(int x) {\n        long result = 0;\n        while(x != 0)\n        {\n            result = result*10 + x % 10;\n            x /= 10;\n        }\n        return (result > INT_MAX || result < INT_MIN)? 0 : result;\n    }\n    \n};\n\n```\n\n\n</article>\n","source":"leetcode/Leetcode[7]-Reverse Integer.md","raw":"---\ntitle: Leetcode[7]-Reverse Integer\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/reverse-integer/\n\nReverse digits of an integer.\n\n\tExample1: x = 123, return 321\n\tExample2: x = -123, return -321\n\n-----\n\n\n取一个数的最后一位，用`x % 10`,取一个数的前n-1位（共n位），用`x/10`，每一次取的时候，都将上一次取的数乘以10，然后再加上末尾的数即可，代码如下：\n\nCode(C++)\n\n```\nclass Solution {\npublic:\n    int reverse(int x) {\n        long result = 0;\n        while(x != 0)\n        {\n            result = result*10 + x % 10;\n            x /= 10;\n        }\n        return (result > INT_MAX || result < INT_MIN)? 0 : result;\n    }\n    \n};\n\n```\n\n\n</article>\n","date":"2016-03-26T03:12:23.921Z","updated":"2016-03-23T14:33:02.905Z","path":"leetcode/Leetcode[7]-Reverse Integer.html","_id":"cimigpyng000e6cujyd27y8bg"},{"title":"Leetcode[74]-Search a 2D Matrix","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/search-a-2d-matrix/\n\nWrite an efficient algorithm that searches for a value in an m x n matrix. This matrix has the following properties:\n\nIntegers in each row are sorted from left to right.\nThe first integer of each row is greater than the last integer of the previous row.\nFor example,\n\nConsider the following matrix:\n```\n[\n  [1,   3,  5,  7],\n  [10, 11, 16, 20],\n  [23, 30, 34, 50]\n]\n```\nGiven target = 3, return true.\n\n-----\n\n这道题之前做过：<a href=\"http://blog.csdn.net/dream_angel_z/article/details/46413705\">查找特殊矩阵中的一个数</a>\n\n算法思路：\n\n起始从右上角开始查找，a[i][j]初试值为a[0][n-1]，循环下列\nwhile( i < n && j >= 0) \n如果key < a[i][j],往左走，j–，\n如果key > a[i][j],则往下走，执行i++\n如果key == a[i][j],表示找到了\n\nC++代码：\n\n```\nclass Solution {\npublic:\n    bool searchMatrix(vector<vector<int>>& matrix, int target) {\n        \n        int m = matrix.size(), n = matrix[0].size();\n        \n        int i=0,j = n-1;\n        while( i < m && j >= 0){\n            if( target < matrix[i][j] ) j--;\n            else if( target > matrix[i][j] ) i++;\n            else return true;\n        }\n        return false;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[74]-Search a 2D Matrix.md","raw":"---\ntitle: Leetcode[74]-Search a 2D Matrix\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/search-a-2d-matrix/\n\nWrite an efficient algorithm that searches for a value in an m x n matrix. This matrix has the following properties:\n\nIntegers in each row are sorted from left to right.\nThe first integer of each row is greater than the last integer of the previous row.\nFor example,\n\nConsider the following matrix:\n```\n[\n  [1,   3,  5,  7],\n  [10, 11, 16, 20],\n  [23, 30, 34, 50]\n]\n```\nGiven target = 3, return true.\n\n-----\n\n这道题之前做过：<a href=\"http://blog.csdn.net/dream_angel_z/article/details/46413705\">查找特殊矩阵中的一个数</a>\n\n算法思路：\n\n起始从右上角开始查找，a[i][j]初试值为a[0][n-1]，循环下列\nwhile( i < n && j >= 0) \n如果key < a[i][j],往左走，j–，\n如果key > a[i][j],则往下走，执行i++\n如果key == a[i][j],表示找到了\n\nC++代码：\n\n```\nclass Solution {\npublic:\n    bool searchMatrix(vector<vector<int>>& matrix, int target) {\n        \n        int m = matrix.size(), n = matrix[0].size();\n        \n        int i=0,j = n-1;\n        while( i < m && j >= 0){\n            if( target < matrix[i][j] ) j--;\n            else if( target > matrix[i][j] ) i++;\n            else return true;\n        }\n        return false;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.669Z","updated":"2016-03-23T14:33:02.894Z","path":"leetcode/Leetcode[74]-Search a 2D Matrix.html","_id":"cimigpynl000f6cuj6a5nw7jb"},{"title":"Leetcode[70]-Climbing Stairs","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/climbing-stairs/\n\nYou are climbing a stair case. It takes n steps to reach to the top.\n\nEach time you can either climb 1 or 2 steps. In how many distinct ways can you climb to the top?\n\n------\n\n题意：给你一个n阶的台阶，你一次最多只能上2个台阶，请问一共有多少个走法？\n\n分析：典型的斐波那契数列题目，可以使用递归求解，也可以使用DP方法求解；\n\ni表示阶梯数，f(i)表示有多少种走法；\n\n- 当i = 1时，f(1) = 1,\n- 当i = 2时，f(2) = 2;\n- 当i > 3时，f(i) = f(i-1) + f(i-2)。\n\n其实很容易理解，当阶梯数大于2时，它的走法可以是从n-1阶梯走一步，或是从n-2阶梯处一次走两步到达，即f(i) = f(i-1) + f(i-2)。\n\n```\nclass Solution {\npublic:\n    int climbStairs(int n) {\n        vector<int> dp(n);\n        for(int i = 0; i < n; i++){\n            if(i < 2) dp[i] = i + 1;\n            else dp[i] = dp[i-1] + dp[i-2];\n        }\n        return dp[n-1];\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[70]-Climbing Stairs.md","raw":"---\ntitle: Leetcode[70]-Climbing Stairs\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/climbing-stairs/\n\nYou are climbing a stair case. It takes n steps to reach to the top.\n\nEach time you can either climb 1 or 2 steps. In how many distinct ways can you climb to the top?\n\n------\n\n题意：给你一个n阶的台阶，你一次最多只能上2个台阶，请问一共有多少个走法？\n\n分析：典型的斐波那契数列题目，可以使用递归求解，也可以使用DP方法求解；\n\ni表示阶梯数，f(i)表示有多少种走法；\n\n- 当i = 1时，f(1) = 1,\n- 当i = 2时，f(2) = 2;\n- 当i > 3时，f(i) = f(i-1) + f(i-2)。\n\n其实很容易理解，当阶梯数大于2时，它的走法可以是从n-1阶梯走一步，或是从n-2阶梯处一次走两步到达，即f(i) = f(i-1) + f(i-2)。\n\n```\nclass Solution {\npublic:\n    int climbStairs(int n) {\n        vector<int> dp(n);\n        for(int i = 0; i < n; i++){\n            if(i < 2) dp[i] = i + 1;\n            else dp[i] = dp[i-1] + dp[i-2];\n        }\n        return dp[n-1];\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.667Z","updated":"2016-03-23T14:33:02.893Z","path":"leetcode/Leetcode[70]-Climbing Stairs.html","_id":"cimigpynq000g6cujvva47qz7"},{"title":"Leetcode[66]-Plus One","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/plus-one/\n\nGiven a non-negative number represented as an array of digits, plus one to the number.\n\nThe digits are stored such that the most significant digit is at the head of the list.\n\n\n--------\n题意：给定一个数组，表示的是非负数的各个位的数，现在将该数加一，求加一后得到的数组。\n\n分析：由于加以后数组的长度可能发生变化，说以不能单纯的直接在数组后面加一。可以先将数组翻转，个位转到前面来，然后从前往后依次加一，最后判断如果在最后一位相加超过十了，就将数组长度加一，代码如下：\n\nCode(c++):\n```\nclass Solution {\npublic:\n    vector<int> plusOne(vector<int>& digits) {\n        int n = digits.size();\n        reverse(digits.begin(),digits.end());\n        int temp = 0,flag = false;\n        for(int i = 0; i<n ; i++) {\n            if(i==0) temp =1;\n            int sum = digits[i] + temp;\n            digits[i] = sum %10;\n            temp = sum/10;\n            if(i == n-1 && sum >= 10)\n                flag = true;\n        }\n        if(flag){\n            digits.resize(n+1);\n            digits[n] = temp;\n        }\n        reverse(digits.begin(),digits.end());\n        return digits;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[66]-Plus One.md","raw":"---\ntitle: Leetcode[66]-Plus One\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/plus-one/\n\nGiven a non-negative number represented as an array of digits, plus one to the number.\n\nThe digits are stored such that the most significant digit is at the head of the list.\n\n\n--------\n题意：给定一个数组，表示的是非负数的各个位的数，现在将该数加一，求加一后得到的数组。\n\n分析：由于加以后数组的长度可能发生变化，说以不能单纯的直接在数组后面加一。可以先将数组翻转，个位转到前面来，然后从前往后依次加一，最后判断如果在最后一位相加超过十了，就将数组长度加一，代码如下：\n\nCode(c++):\n```\nclass Solution {\npublic:\n    vector<int> plusOne(vector<int>& digits) {\n        int n = digits.size();\n        reverse(digits.begin(),digits.end());\n        int temp = 0,flag = false;\n        for(int i = 0; i<n ; i++) {\n            if(i==0) temp =1;\n            int sum = digits[i] + temp;\n            digits[i] = sum %10;\n            temp = sum/10;\n            if(i == n-1 && sum >= 10)\n                flag = true;\n        }\n        if(flag){\n            digits.resize(n+1);\n            digits[n] = temp;\n        }\n        reverse(digits.begin(),digits.end());\n        return digits;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.665Z","updated":"2016-03-23T14:33:02.891Z","path":"leetcode/Leetcode[66]-Plus One.html","_id":"cimigpyo5000h6cujm4xqdrnj"},{"title":"Leetcode[63]-Unique Paths II","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/unique-paths-ii/\n\nFollow up for \"Unique Paths\":\n\nNow consider if some obstacles are added to the grids. How many unique paths would there be?\n\nAn obstacle and empty space is marked as 1 and 0 respectively in the grid.\n\nFor example,\nThere is one obstacle in the middle of a 3x3 grid as illustrated below.\n\n\t[\n\t  [0,0,0],\n\t  [0,1,0],\n\t  [0,0,0]\n\t]\n\nThe total number of unique paths is 2.\n\n题意：在上题的基础上增加了点限制条件，不过大体上还是差不多的，还是采用动态规划思想，找到初始值和递推关系，和上体相比较，只是初始化和到达dp[i][j]时要加点判断语句，\n\n- 第0列，从上到下，如果碰到一个1，则设置该位置和后面的位置都不可到达，即dp[i to n][0]；\n- 第0行，从左到右，如果碰到一个1，则设置该位置和右方的位置都不可到达，即dp[0][i to n];\n- 其它位置，如果该位置不为1，则到达该位置的方式共有 dp[i][j] = dp[i-1][j] + dp[i][j-1],如果为1，则dp[i][j] = 0；\n\n代码如下：\n\nCode(c++):\n\n```\nclass Solution {\npublic:\n    int uniquePathsWithObstacles(vector<vector<int>>& obstacleGrid) {\n        \n        int m = obstacleGrid.size(),n = obstacleGrid[0].size();\n        vector<vector<int> > dp(m, vector<int>(n));\n        \n        bool flag = false;\n        for(int i = 0; i < m; i++) {\n            if(obstacleGrid[i][0] == 1) flag = true;\n            \n            if(flag == false )dp[i][0] = 1;\n            else dp[i][0] = 0;\n        }  \n        \n        flag = false;\n        for(int j = 0; j < n; j++) {\n            if(obstacleGrid[0][j] == 1) flag = true;\n            if(flag == false )dp[0][j] = 1;\n            else dp[0][j] = 0;\n        }    \n        \n        for(int i = 1; i < m; i++) {\n            for(int j = 1; j < n; j++){\n                if(obstacleGrid[i][j] == 1) obstacleGrid[i][j] = 0; \n                else dp[i][j] = dp[i-1][j] + dp[i][j-1];\n            }\n        }\n        \n        return dp[m-1][n-1];\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[63]-Unique Paths II.md","raw":"---\ntitle: Leetcode[63]-Unique Paths II\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/unique-paths-ii/\n\nFollow up for \"Unique Paths\":\n\nNow consider if some obstacles are added to the grids. How many unique paths would there be?\n\nAn obstacle and empty space is marked as 1 and 0 respectively in the grid.\n\nFor example,\nThere is one obstacle in the middle of a 3x3 grid as illustrated below.\n\n\t[\n\t  [0,0,0],\n\t  [0,1,0],\n\t  [0,0,0]\n\t]\n\nThe total number of unique paths is 2.\n\n题意：在上题的基础上增加了点限制条件，不过大体上还是差不多的，还是采用动态规划思想，找到初始值和递推关系，和上体相比较，只是初始化和到达dp[i][j]时要加点判断语句，\n\n- 第0列，从上到下，如果碰到一个1，则设置该位置和后面的位置都不可到达，即dp[i to n][0]；\n- 第0行，从左到右，如果碰到一个1，则设置该位置和右方的位置都不可到达，即dp[0][i to n];\n- 其它位置，如果该位置不为1，则到达该位置的方式共有 dp[i][j] = dp[i-1][j] + dp[i][j-1],如果为1，则dp[i][j] = 0；\n\n代码如下：\n\nCode(c++):\n\n```\nclass Solution {\npublic:\n    int uniquePathsWithObstacles(vector<vector<int>>& obstacleGrid) {\n        \n        int m = obstacleGrid.size(),n = obstacleGrid[0].size();\n        vector<vector<int> > dp(m, vector<int>(n));\n        \n        bool flag = false;\n        for(int i = 0; i < m; i++) {\n            if(obstacleGrid[i][0] == 1) flag = true;\n            \n            if(flag == false )dp[i][0] = 1;\n            else dp[i][0] = 0;\n        }  \n        \n        flag = false;\n        for(int j = 0; j < n; j++) {\n            if(obstacleGrid[0][j] == 1) flag = true;\n            if(flag == false )dp[0][j] = 1;\n            else dp[0][j] = 0;\n        }    \n        \n        for(int i = 1; i < m; i++) {\n            for(int j = 1; j < n; j++){\n                if(obstacleGrid[i][j] == 1) obstacleGrid[i][j] = 0; \n                else dp[i][j] = dp[i-1][j] + dp[i][j-1];\n            }\n        }\n        \n        return dp[m-1][n-1];\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.664Z","updated":"2016-03-23T14:33:02.889Z","path":"leetcode/Leetcode[63]-Unique Paths II.html","_id":"cimigpyox000i6cujm1sh3gio"},{"title":"Leetcode[62]-Unique Paths","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/unique-paths/\n\nA robot is located at the top-left corner of a m x n grid (marked 'Start' in the diagram below).\n\nThe robot can only move either down or right at any point in time. The robot is trying to reach the bottom-right corner of the grid (marked 'Finish' in the diagram below).\n\nHow many possible unique paths are there?\n\n![这里写图片描述](http://articles.leetcode.com/wp-content/uploads/2014/12/robot_maze.png)\n\nAbove is a 3 x 7 grid. How many possible unique paths are there?\n\nNote: m and n will be at most 100.\n\n---\n\n题目：给定一个m*n的矩阵，让机器人从左上方走到右下方，只能往下和往右走，一共多少种走法。\n\n思路：采用动态规划设计思想，到第0列和第0行的任何位置都只有1种走法，即初始化为d[0][\\*] = 1,d[\\*][0] = 1;当机器人走到第i行第j列的时候，它的走法总数是等于第i-1行第j列的总数加上第i行第j-1列的总数，即dp [ i ] [ j ]  = d[i-1][j] + dp[i][j-1].代码如下:\n\n\nCode(c++): \n\n```\nclass Solution {\npublic:\n    int uniquePaths(int m, int n) {\n        vector<vector<int> > dp(m,vector<int> (n));\n        for(int k = 0; k < m; k++) {\n            dp[k][0] = 1;\n        }\n        for(int t = 0; t < n; t++) {\n            dp[0][t] = 1;        \n        for(int i = 1; i < m; i++) {\n            for(int j = 1; j < n; j++){\n                dp[i][j] = dp[i-1][j] + dp[i][j-1];\n            }\n        }\n        return dp[m-1][n-1];\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[62]-Unique Paths.md","raw":"---\ntitle: Leetcode[62]-Unique Paths\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/unique-paths/\n\nA robot is located at the top-left corner of a m x n grid (marked 'Start' in the diagram below).\n\nThe robot can only move either down or right at any point in time. The robot is trying to reach the bottom-right corner of the grid (marked 'Finish' in the diagram below).\n\nHow many possible unique paths are there?\n\n![这里写图片描述](http://articles.leetcode.com/wp-content/uploads/2014/12/robot_maze.png)\n\nAbove is a 3 x 7 grid. How many possible unique paths are there?\n\nNote: m and n will be at most 100.\n\n---\n\n题目：给定一个m*n的矩阵，让机器人从左上方走到右下方，只能往下和往右走，一共多少种走法。\n\n思路：采用动态规划设计思想，到第0列和第0行的任何位置都只有1种走法，即初始化为d[0][\\*] = 1,d[\\*][0] = 1;当机器人走到第i行第j列的时候，它的走法总数是等于第i-1行第j列的总数加上第i行第j-1列的总数，即dp [ i ] [ j ]  = d[i-1][j] + dp[i][j-1].代码如下:\n\n\nCode(c++): \n\n```\nclass Solution {\npublic:\n    int uniquePaths(int m, int n) {\n        vector<vector<int> > dp(m,vector<int> (n));\n        for(int k = 0; k < m; k++) {\n            dp[k][0] = 1;\n        }\n        for(int t = 0; t < n; t++) {\n            dp[0][t] = 1;        \n        for(int i = 1; i < m; i++) {\n            for(int j = 1; j < n; j++){\n                dp[i][j] = dp[i-1][j] + dp[i][j-1];\n            }\n        }\n        return dp[m-1][n-1];\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.662Z","updated":"2016-03-23T14:33:02.888Z","path":"leetcode/Leetcode[62]-Unique Paths.html","_id":"cimigpyp1000j6cujn8wouohm"},{"title":"Leetcode[53]-Maximum Subarray","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/maximum-subarray/\n\nFind the contiguous subarray within an array (containing at least one number) which has the largest sum.\n\nFor example, given the array [−2,1,−3,4,−1,2,1,−5,4],\nthe contiguous subarray [4,−1,2,1] has the largest sum = 6.\n\nMore practice:\nIf you have figured out the O(n) solution, try coding another solution using the divide and conquer approach, which is more subtle.\n\n--------\n\n给定一个长度为n的序列，求其最大子序列和。\n算法思路：使用动态规划求解，dp[i]表示在尾数在位置i上的最大子序列和，那么dp[i]可以表示为\n\n- dp[i] = max(dp[i-1] + nums[i],nums[i])\n- dp[0] = nums[0]\n\n其中dp[0]表示初值。\n\n**C++代码如下：**\n```\nclass Solution {\npublic:\n    int maxSubArray(vector<int>& nums) {\n        \n        int n = nums.size();\n        vector<int> dp(n);\n        dp[0] = nums[0];\n        int answer = dp[0];\n        \n        for(int i=1; i<n; ++i){\n            dp[i] = max(dp[i-1]+nums[i],nums[i]);\n            answer = max(answer,dp[i]);\n        }\n        \n        return answer;\n        \n    }\n};\n```\n\n**Python代码如下：**\n\n```\nclass Solution(object):\n    def maxSubArray(self, nums):\n        \"\"\"\n        :type nums: List[int]\n        :rtype: int\n        \"\"\"\n        n = len(nums)\n        ans = nums[0]\n        dp = []\n        dp.append(ans)\n        \n        for i in range(1, n):\n            dp.append(max(dp[i-1] + nums[i],nums[i]))\n            ans = max(dp[i], ans)\n        return ans\n```\n\n\n</article>\n","source":"leetcode/Leetcode[53]-Maximum Subarray.md","raw":"---\ntitle: Leetcode[53]-Maximum Subarray\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/maximum-subarray/\n\nFind the contiguous subarray within an array (containing at least one number) which has the largest sum.\n\nFor example, given the array [−2,1,−3,4,−1,2,1,−5,4],\nthe contiguous subarray [4,−1,2,1] has the largest sum = 6.\n\nMore practice:\nIf you have figured out the O(n) solution, try coding another solution using the divide and conquer approach, which is more subtle.\n\n--------\n\n给定一个长度为n的序列，求其最大子序列和。\n算法思路：使用动态规划求解，dp[i]表示在尾数在位置i上的最大子序列和，那么dp[i]可以表示为\n\n- dp[i] = max(dp[i-1] + nums[i],nums[i])\n- dp[0] = nums[0]\n\n其中dp[0]表示初值。\n\n**C++代码如下：**\n```\nclass Solution {\npublic:\n    int maxSubArray(vector<int>& nums) {\n        \n        int n = nums.size();\n        vector<int> dp(n);\n        dp[0] = nums[0];\n        int answer = dp[0];\n        \n        for(int i=1; i<n; ++i){\n            dp[i] = max(dp[i-1]+nums[i],nums[i]);\n            answer = max(answer,dp[i]);\n        }\n        \n        return answer;\n        \n    }\n};\n```\n\n**Python代码如下：**\n\n```\nclass Solution(object):\n    def maxSubArray(self, nums):\n        \"\"\"\n        :type nums: List[int]\n        :rtype: int\n        \"\"\"\n        n = len(nums)\n        ans = nums[0]\n        dp = []\n        dp.append(ans)\n        \n        for i in range(1, n):\n            dp.append(max(dp[i-1] + nums[i],nums[i]))\n            ans = max(dp[i], ans)\n        return ans\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.659Z","updated":"2016-03-23T14:33:02.872Z","path":"leetcode/Leetcode[53]-Maximum Subarray.html","_id":"cimigpyp2000k6cujrr997g4f"},{"title":"Leetcode[4]-Median of Two Sorted Arrays","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/median-of-two-sorted-arrays/\n\nThere are two sorted arrays nums1 and nums2 of size m and n respectively. Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)).\n\n\n----\n\n思路：先将两个数组合并，然后排序，最后找中位数\n\n中位数：若有n个数，n为奇数，则选择第（n+1）/2个为中位数，若n为偶数，则中位数是（n/2以及n/2+1）的平均数；\n\n合并两个vector：merge(nums1.begin(),nums1.end(),nums2.begin(),nums2.end(),nums.begin());\n\n\nCode(c++):\n\n```\nclass Solution {\npublic:\n    double findMedianSortedArrays(vector<int>& nums1, vector<int>& nums2) {\n        int m = nums1.size(),n = nums2.size();\n        vector<int> nums(m+n);\n    \n        merge(nums1.begin(),nums1.end(),nums2.begin(),nums2.end(),nums.begin());\n    \n        sort(nums.begin(),nums.end());\n    \n        int mid = (m+n)/2;\n        if((m+n)%2==0) {\n            return double(nums[mid]+nums[mid - 1])/2;\n        }else\n            return nums[mid];\n    }\n};\n```\n\n\n\n\n</article>\n","source":"leetcode/Leetcode[4]-Median of Two Sorted Arrays.md","raw":"---\ntitle: Leetcode[4]-Median of Two Sorted Arrays\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/median-of-two-sorted-arrays/\n\nThere are two sorted arrays nums1 and nums2 of size m and n respectively. Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)).\n\n\n----\n\n思路：先将两个数组合并，然后排序，最后找中位数\n\n中位数：若有n个数，n为奇数，则选择第（n+1）/2个为中位数，若n为偶数，则中位数是（n/2以及n/2+1）的平均数；\n\n合并两个vector：merge(nums1.begin(),nums1.end(),nums2.begin(),nums2.end(),nums.begin());\n\n\nCode(c++):\n\n```\nclass Solution {\npublic:\n    double findMedianSortedArrays(vector<int>& nums1, vector<int>& nums2) {\n        int m = nums1.size(),n = nums2.size();\n        vector<int> nums(m+n);\n    \n        merge(nums1.begin(),nums1.end(),nums2.begin(),nums2.end(),nums.begin());\n    \n        sort(nums.begin(),nums.end());\n    \n        int mid = (m+n)/2;\n        if((m+n)%2==0) {\n            return double(nums[mid]+nums[mid - 1])/2;\n        }else\n            return nums[mid];\n    }\n};\n```\n\n\n\n\n</article>\n","date":"2016-03-23T14:33:15.631Z","updated":"2016-03-23T14:33:02.865Z","path":"leetcode/Leetcode[4]-Median of Two Sorted Arrays.html","_id":"cimigpyp5000l6cujibdsvqal"},{"title":"Leetcode[36]-Valid Sudoku","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/valid-sudoku/\n\nDetermine if a Sudoku is valid, according to: Sudoku Puzzles - The Rules.\n\nThe Sudoku board could be partially filled, where empty cells are filled with the character '.'.\n![这里写图片描述](http://img.blog.csdn.net/20150609210526658)\n\nA partially filled sudoku which is valid.\n\nNote:\nA valid Sudoku board (partially filled) is not necessarily solvable. Only the filled cells need to be validated.\n\n\n-------\n分析：验证一个数独的合法性，从三个方向入手\n\n- 每一行不能出现重复元素\n- 每一列不能出现重复元素\n- 每一个九方格不能出现重复元素\n\n我采用的是map来保存元素的数值，然后判断map中是否有，有则返回false；参数之间的关系推导如下：\n![这里写图片描述](http://img.blog.csdn.net/20150609213752137)\n</a>\n代码如下\n\nCode(c++):\n```\nclass Solution {\npublic:\n    bool isValidSudoku(vector<vector<char>>& board) {\n        //row\n        for(int  i = 0; i<9; i++) {\n            map<int, int> mp;\n            for (int j = 0; j<9; j++){\n                if(mp.find(board[i][j])!=mp.end())\n                    return false;\n                if(board[i][j] == '.')continue;\n                mp[board[i][j]] = j;\n            }\n        }\n        \n        //cow\n        for(int  j = 0; j<9; j++) {\n            map<int, int> mp;\n            for (int i = 0; i<9; i++){\n                if(mp.find(board[i][j])!=mp.end())\n                    return false;\n                if(board[i][j] == '.')continue;\n                mp[board[i][j]] = i;\n            }\n        }\n        \n        //board\n        for(int i = 0; i < 9; i++){\n            map<int,int> mp;\n            for(int j = (i/3)*3; j < 3 + (i/3)*3 ; j++){\n                for(int k = (3*i)%9; k <= (3*(i+1)-1)%9; k++){\n                    if(mp.find(board[j][k])!=mp.end())\n                        return false;\n                    if(board[j][k] == '.')continue;\n                    mp[board[j][k]] = k;\n                }\n            }\n        }\n        \n        return true;\n        \n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[36]-Valid Sudoku.md","raw":"---\ntitle: Leetcode[36]-Valid Sudoku\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/valid-sudoku/\n\nDetermine if a Sudoku is valid, according to: Sudoku Puzzles - The Rules.\n\nThe Sudoku board could be partially filled, where empty cells are filled with the character '.'.\n![这里写图片描述](http://img.blog.csdn.net/20150609210526658)\n\nA partially filled sudoku which is valid.\n\nNote:\nA valid Sudoku board (partially filled) is not necessarily solvable. Only the filled cells need to be validated.\n\n\n-------\n分析：验证一个数独的合法性，从三个方向入手\n\n- 每一行不能出现重复元素\n- 每一列不能出现重复元素\n- 每一个九方格不能出现重复元素\n\n我采用的是map来保存元素的数值，然后判断map中是否有，有则返回false；参数之间的关系推导如下：\n![这里写图片描述](http://img.blog.csdn.net/20150609213752137)\n</a>\n代码如下\n\nCode(c++):\n```\nclass Solution {\npublic:\n    bool isValidSudoku(vector<vector<char>>& board) {\n        //row\n        for(int  i = 0; i<9; i++) {\n            map<int, int> mp;\n            for (int j = 0; j<9; j++){\n                if(mp.find(board[i][j])!=mp.end())\n                    return false;\n                if(board[i][j] == '.')continue;\n                mp[board[i][j]] = j;\n            }\n        }\n        \n        //cow\n        for(int  j = 0; j<9; j++) {\n            map<int, int> mp;\n            for (int i = 0; i<9; i++){\n                if(mp.find(board[i][j])!=mp.end())\n                    return false;\n                if(board[i][j] == '.')continue;\n                mp[board[i][j]] = i;\n            }\n        }\n        \n        //board\n        for(int i = 0; i < 9; i++){\n            map<int,int> mp;\n            for(int j = (i/3)*3; j < 3 + (i/3)*3 ; j++){\n                for(int k = (3*i)%9; k <= (3*(i+1)-1)%9; k++){\n                    if(mp.find(board[j][k])!=mp.end())\n                        return false;\n                    if(board[j][k] == '.')continue;\n                    mp[board[j][k]] = k;\n                }\n            }\n        }\n        \n        return true;\n        \n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.658Z","updated":"2016-03-23T14:33:02.855Z","path":"leetcode/Leetcode[36]-Valid Sudoku.html","_id":"cimigpypb000m6cujudw3dxqr"},{"title":"Leetcode[35]-Search Insert Position","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/search-insert-position/\n\nGiven a sorted array and a target value, return the index if the target is found. If not, return the index where it would be if it were inserted in order.\n\nYou may assume no duplicates in the array.\n\n\n\tHere are few examples.\n\t[1,3,5,6], 5 → 2\n\t[1,3,5,6], 2 → 1\n\t[1,3,5,6], 7 → 4\n\t[1,3,5,6], 0 → 0\n\n\n题目比较简单，直接给出答案吧\ncode(c++):\n\n```\nclass Solution {\npublic:\n    int searchInsert(vector<int>& nums, int target) {\n        int n = nums.size();\n        int i = 0;\n        bool flag = false;\n        while(i<n) {\n            if( nums[i] >= target) {\n                flag = true;\n                break;\n            }\n            ++i;\n        }\n        return i;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[35]-Search Insert Position.md","raw":"---\ntitle: Leetcode[35]-Search Insert Position\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/search-insert-position/\n\nGiven a sorted array and a target value, return the index if the target is found. If not, return the index where it would be if it were inserted in order.\n\nYou may assume no duplicates in the array.\n\n\n\tHere are few examples.\n\t[1,3,5,6], 5 → 2\n\t[1,3,5,6], 2 → 1\n\t[1,3,5,6], 7 → 4\n\t[1,3,5,6], 0 → 0\n\n\n题目比较简单，直接给出答案吧\ncode(c++):\n\n```\nclass Solution {\npublic:\n    int searchInsert(vector<int>& nums, int target) {\n        int n = nums.size();\n        int i = 0;\n        bool flag = false;\n        while(i<n) {\n            if( nums[i] >= target) {\n                flag = true;\n                break;\n            }\n            ++i;\n        }\n        return i;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.656Z","updated":"2016-03-23T14:33:02.832Z","path":"leetcode/Leetcode[35]-Search Insert Position.html","_id":"cimigpypd000n6cujjy56lgm6"},{"title":"Leetcode[33]-Search in Rotated Sorted Array","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/search-in-rotated-sorted-array/\n\nSuppose a sorted array is rotated at some pivot unknown to you beforehand.\n\n(i.e., 0 1 2 4 5 6 7 might become 4 5 6 7 0 1 2).\n\nYou are given a target value to search. If found in the array return its index, otherwise return -1.\n\nYou may assume no duplicate exists in the array.\n\n--------\n\nC++:\n\n方法一：直接for循环求解\n\n```\nclass Solution {\npublic:\n    int search(vector<int>& nums, int target) {\n        int n = nums.size();\n        \n        for(int i = 0; i<n; i++){\n            if(nums[i] == target) return i;\n        }\n        return -1;\n    }\n};\n```\n\n方法二：二分搜索求解\n分析：从中点处划分，左右两边一定有一部分是有序的，对于有序的分别做判断。\n\n```\nclass Solution {\npublic:\n    int search(vector<int>& nums, int target) {\n        \n        int i = 0, j = nums.size()-1;\n        \n        while(i<=j){\n            int mid = (i+j)/2;\n            \n            if(nums[mid] == target) \n                return mid;\n            //if left is sorted\n            else if(nums[i] <= nums[mid]){\n                if(nums[i] <= target && target < nums[mid]) \n                    j = mid-1;\n                else\n                    i = mid + 1;\n            }else {\n                if(nums[mid] < target && target <= nums[j] ) \n                    i = mid +1;\n                else \n                    j = mid-1;\n            }\n        }\n        return -1;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[33]-Search in Rotated Sorted Array.md","raw":"---\ntitle: Leetcode[33]-Search in Rotated Sorted Array\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/search-in-rotated-sorted-array/\n\nSuppose a sorted array is rotated at some pivot unknown to you beforehand.\n\n(i.e., 0 1 2 4 5 6 7 might become 4 5 6 7 0 1 2).\n\nYou are given a target value to search. If found in the array return its index, otherwise return -1.\n\nYou may assume no duplicate exists in the array.\n\n--------\n\nC++:\n\n方法一：直接for循环求解\n\n```\nclass Solution {\npublic:\n    int search(vector<int>& nums, int target) {\n        int n = nums.size();\n        \n        for(int i = 0; i<n; i++){\n            if(nums[i] == target) return i;\n        }\n        return -1;\n    }\n};\n```\n\n方法二：二分搜索求解\n分析：从中点处划分，左右两边一定有一部分是有序的，对于有序的分别做判断。\n\n```\nclass Solution {\npublic:\n    int search(vector<int>& nums, int target) {\n        \n        int i = 0, j = nums.size()-1;\n        \n        while(i<=j){\n            int mid = (i+j)/2;\n            \n            if(nums[mid] == target) \n                return mid;\n            //if left is sorted\n            else if(nums[i] <= nums[mid]){\n                if(nums[i] <= target && target < nums[mid]) \n                    j = mid-1;\n                else\n                    i = mid + 1;\n            }else {\n                if(nums[mid] < target && target <= nums[j] ) \n                    i = mid +1;\n                else \n                    j = mid-1;\n            }\n        }\n        return -1;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.655Z","updated":"2016-03-23T14:33:02.803Z","path":"leetcode/Leetcode[33]-Search in Rotated Sorted Array.html","_id":"cimigpypg000o6cujiul9q7ct"},{"title":"Leetcode[300]-Longest Increasing Subsequence","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink：https://leetcode.com/problems/longest-increasing-subsequence/\n\n\nGiven an unsorted array of integers, find the length of longest increasing subsequence.\n\nFor example,\nGiven `[10, 9, 2, 5, 3, 7, 101, 18]`,\nThe longest increasing subsequence is `[2, 3, 7, 101]`, therefore the length is `4`. Note that there may be more than one LIS combination, it is only necessary for you to return the length.\n\nYour algorithm should run in O(n2) complexity.\n\nFollow up: Could you improve it to O(n log n) time complexity?\n\n---\n\n这道题和最长连续子序列有些区别，它不限制【连续】这个条件，只要递增即可。\n\n思路：定义一个长度为n的int类型一维数组dp[n]，dp[i]用来表示第i个位置上的最长递增子序列长度。dp[i]的计算过程如下：\n\n- 初始化dp[0]=1；\n- 当i>0时，设置一个变量max_dp，初始值为1,记录的是以当前位置结尾时的最长递增子序列长度。通过循环遍历前面的i-1个数，如果位置i的数大于前面位置j的数，就比较max_dp和dp[j]+1,将大的值赋值给max_dp，最后将max_dp赋值给dp[i]；\n- 最后，遍历dp[n]，找出最大的值，即为最长递增子序列的长度。\n\n\nC++代码：\n\n\n```\nclass Solution {\npublic:\n    int lengthOfLIS(vector<int>& nums) {\n        int n = nums.size();\n        if(n==0) return 0;\n        vector<int> dp(n);\n        dp[0]=1;\n        for(int i=1; i<n; i++){\n            int j=i-1,max_dp=1;            \n            while(j>=0){\n                if(nums[j]<nums[i]){\n                    max_dp=(max_dp>(dp[j]+1)?max_dp:(dp[j]+1));\n                }\n                --j;\n            }\n            dp[i]=max_dp;\n        }\n        int max=0;\n        for(int k=0;k<n;k++){\n            max=(max>dp[k]?max:dp[k]);\n        }\n        return max;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[300]-Longest Increasing Subsequence.md","raw":"---\ntitle: Leetcode[300]-Longest Increasing Subsequence\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink：https://leetcode.com/problems/longest-increasing-subsequence/\n\n\nGiven an unsorted array of integers, find the length of longest increasing subsequence.\n\nFor example,\nGiven `[10, 9, 2, 5, 3, 7, 101, 18]`,\nThe longest increasing subsequence is `[2, 3, 7, 101]`, therefore the length is `4`. Note that there may be more than one LIS combination, it is only necessary for you to return the length.\n\nYour algorithm should run in O(n2) complexity.\n\nFollow up: Could you improve it to O(n log n) time complexity?\n\n---\n\n这道题和最长连续子序列有些区别，它不限制【连续】这个条件，只要递增即可。\n\n思路：定义一个长度为n的int类型一维数组dp[n]，dp[i]用来表示第i个位置上的最长递增子序列长度。dp[i]的计算过程如下：\n\n- 初始化dp[0]=1；\n- 当i>0时，设置一个变量max_dp，初始值为1,记录的是以当前位置结尾时的最长递增子序列长度。通过循环遍历前面的i-1个数，如果位置i的数大于前面位置j的数，就比较max_dp和dp[j]+1,将大的值赋值给max_dp，最后将max_dp赋值给dp[i]；\n- 最后，遍历dp[n]，找出最大的值，即为最长递增子序列的长度。\n\n\nC++代码：\n\n\n```\nclass Solution {\npublic:\n    int lengthOfLIS(vector<int>& nums) {\n        int n = nums.size();\n        if(n==0) return 0;\n        vector<int> dp(n);\n        dp[0]=1;\n        for(int i=1; i<n; i++){\n            int j=i-1,max_dp=1;            \n            while(j>=0){\n                if(nums[j]<nums[i]){\n                    max_dp=(max_dp>(dp[j]+1)?max_dp:(dp[j]+1));\n                }\n                --j;\n            }\n            dp[i]=max_dp;\n        }\n        int max=0;\n        for(int k=0;k<n;k++){\n            max=(max>dp[k]?max:dp[k]);\n        }\n        return max;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.762Z","updated":"2016-03-23T14:33:02.771Z","path":"leetcode/Leetcode[300]-Longest Increasing Subsequence.html","_id":"cimigpypk000p6cujvorwfoob"},{"title":"Leetcode[292]-Nim Game","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/nim-game/\n\n\nYou are playing the following Nim Game with your friend: There is a heap of stones on the table, each time one of you take turns to remove 1 to 3 stones. The one who removes the last stone will be the winner. You will take the first turn to remove the stones.\n\nBoth of you are very clever and have optimal strategies for the game. Write a function to determine whether you can win the game given the number of stones in the heap.\n\nFor example, if there are 4 stones in the heap, then you will never win the game: no matter 1, 2, or 3 stones you remove, the last stone will always be removed by your friend.\n\n---\n\n分析：经过分析之后发现，有以下规律：\n\n- 如果n小于4，返回true；\n- 如果n%4==0，返回false；\n- 否则，返回true。\n\nC++:\n\n```\nclass Solution {\npublic:\n    bool canWinNim(int n) {\n        if(n<=3) return true;\n        if(n%4==0) return false;\n        return true;\n    }\n};\n```\n\nPython：\n\n```\nclass Solution(object):\n    def canWinNim(self, n):\n        \"\"\"\n        :type n: int\n        :rtype: bool\n        \"\"\"\n        if n<4:\n            return True;\n        if n%4==0:\n            return False;\n        return True;\n```\n\n\n</article>\n","source":"leetcode/Leetcode[292]-Nim Game.md","raw":"---\ntitle: Leetcode[292]-Nim Game\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/nim-game/\n\n\nYou are playing the following Nim Game with your friend: There is a heap of stones on the table, each time one of you take turns to remove 1 to 3 stones. The one who removes the last stone will be the winner. You will take the first turn to remove the stones.\n\nBoth of you are very clever and have optimal strategies for the game. Write a function to determine whether you can win the game given the number of stones in the heap.\n\nFor example, if there are 4 stones in the heap, then you will never win the game: no matter 1, 2, or 3 stones you remove, the last stone will always be removed by your friend.\n\n---\n\n分析：经过分析之后发现，有以下规律：\n\n- 如果n小于4，返回true；\n- 如果n%4==0，返回false；\n- 否则，返回true。\n\nC++:\n\n```\nclass Solution {\npublic:\n    bool canWinNim(int n) {\n        if(n<=3) return true;\n        if(n%4==0) return false;\n        return true;\n    }\n};\n```\n\nPython：\n\n```\nclass Solution(object):\n    def canWinNim(self, n):\n        \"\"\"\n        :type n: int\n        :rtype: bool\n        \"\"\"\n        if n<4:\n            return True;\n        if n%4==0:\n            return False;\n        return True;\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.760Z","updated":"2016-03-23T14:33:02.762Z","path":"leetcode/Leetcode[292]-Nim Game.html","_id":"cimigpypm000q6cujs53r9mm3"},{"title":"Leetcode[283]-Move Zeroes","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/move-zeroes/\n\nGiven an array nums, write a function to move all 0's to the end of it while maintaining the relative order of the non-zero elements.\n\nFor example, given nums = [0, 1, 0, 3, 12], after calling your function, nums should be [1, 3, 12, 0, 0].\n\nNote:\n\n- You must do this in-place without making a copy of the array.\n- Minimize the total number of operations.\n\n---\n\nC++代码：\n\n```\nclass Solution {\npublic:\n    void moveZeroes(vector<int>& nums) {\n        int n=nums.size();\n        if (n==0 || n==1) return;\n        int i=0,s = n-1;\n        while(i<=s){\n            if(nums[i]==0){\n                for(int j = i; j<s; j++){\n                    nums[j] = nums[j+1];\n                }\n                nums[s]=0;\n                s = s-1;\n            }else{\n                i=i+1;\n            }\n        }\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[283]-Move Zeroes.md","raw":"---\ntitle: Leetcode[283]-Move Zeroes\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/move-zeroes/\n\nGiven an array nums, write a function to move all 0's to the end of it while maintaining the relative order of the non-zero elements.\n\nFor example, given nums = [0, 1, 0, 3, 12], after calling your function, nums should be [1, 3, 12, 0, 0].\n\nNote:\n\n- You must do this in-place without making a copy of the array.\n- Minimize the total number of operations.\n\n---\n\nC++代码：\n\n```\nclass Solution {\npublic:\n    void moveZeroes(vector<int>& nums) {\n        int n=nums.size();\n        if (n==0 || n==1) return;\n        int i=0,s = n-1;\n        while(i<=s){\n            if(nums[i]==0){\n                for(int j = i; j<s; j++){\n                    nums[j] = nums[j+1];\n                }\n                nums[s]=0;\n                s = s-1;\n            }else{\n                i=i+1;\n            }\n        }\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.759Z","updated":"2016-03-23T14:33:02.747Z","path":"leetcode/Leetcode[283]-Move Zeroes.html","_id":"cimigpypn000r6cuj5w2cwhyj"},{"title":"Leetcode[27]-Remove Element","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/remove-element/\n\nGiven an array and a value, remove all instances of that value in place and return the new length.\n\nThe order of elements can be changed. It doesn't matter what you leave beyond the new length.\n\n-------\n思路：遍历数组，如果数组对应的数等于给定的值，数组最后一位和当前位互换，然后将数组长度减一；否则，就执行i++;最后重置数组长度。\n\nCode(c++):\n```\nclass Solution {\npublic:\n\n    void swap(int *a, int *b){\n        int temp = *a;\n        *a = *b;\n        *b = temp;\n    }\n    int removeElement(vector<int>& nums, int val) {\n        int n = nums.size();\n        if(n == 0) return 0;\n        int i = 0;\n        while( i < n){\n            if(nums[i] == val) {\n                swap(&nums[i],&nums[n-1]);\n                n--;\n            }else{\n                i++;\n            }\n        }\n        nums.resize(n);\n        return n;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[27]-Remove Element.md","raw":"---\ntitle: Leetcode[27]-Remove Element\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/remove-element/\n\nGiven an array and a value, remove all instances of that value in place and return the new length.\n\nThe order of elements can be changed. It doesn't matter what you leave beyond the new length.\n\n-------\n思路：遍历数组，如果数组对应的数等于给定的值，数组最后一位和当前位互换，然后将数组长度减一；否则，就执行i++;最后重置数组长度。\n\nCode(c++):\n```\nclass Solution {\npublic:\n\n    void swap(int *a, int *b){\n        int temp = *a;\n        *a = *b;\n        *b = temp;\n    }\n    int removeElement(vector<int>& nums, int val) {\n        int n = nums.size();\n        if(n == 0) return 0;\n        int i = 0;\n        while( i < n){\n            if(nums[i] == val) {\n                swap(&nums[i],&nums[n-1]);\n                n--;\n            }else{\n                i++;\n            }\n        }\n        nums.resize(n);\n        return n;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.653Z","updated":"2016-03-23T14:33:02.736Z","path":"leetcode/Leetcode[27]-Remove Element.html","_id":"cimigpypq000s6cujtlsxgoci"},{"title":"Leetcode[26]-Remove Duplicates from Sorted Array","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/remove-duplicates-from-sorted-array/\n\nGiven a sorted array, remove the duplicates in place such that each element appear only once and return the new length.\n\nDo not allocate extra space for another array, you must do this in place with constant memory.\n\nFor example,\nGiven input array nums = [1,1,2],\n\nYour function should return length = 2, with the first two elements of nums being 1 and 2 respectively. It doesn't matter what you leave beyond the new length.\n\n--------\n\n**思路**：需要额外添加一个新的变量pos，初始值为0，用来记录非重复元素的位置。从数组的第二个元素开始遍历，如果和前面的元素相等，则直接跳到下一个；如果不等，则将该数组的值赋值给++pos位，接着继续遍历下一个；\n\n**Code(c++):**\n\n```\nclass Solution {\npublic:\n    int removeDuplicates(vector<int>& nums) {\n        int n = nums.size();\n        if(n==0) return 0;\n        int pos = 0,i = 1;\n        while(i < n){\n            if(nums[i] == nums[i-1]){\n                i++;\n            }else{\n                nums[++pos] = nums[i++];\n            }\n        }\n        n = pos+1;\n        nums.resize(n);\n        return n;\n    }\n};\n```\n\n做个简单的修改：\n\n```\nclass Solution {\npublic:\n    int removeDuplicates(vector<int>& nums) {\n        int n = nums.size();\n        if(n==0) return 0;\n        int pos = 1,i = 1;//将pos从1开始\n        while(i < n){\n            if(nums[i] == nums[i-1]){\n                i++;\n            }else{\n                nums[pos++] = nums[i++];//这里保持一致\n            }\n        }\n        n = pos;\n        nums.resize(n);\n        return n;\n    }\n};\n```\n\n**Python代码**\n\n```\nclass Solution(object):\n    def removeDuplicates(self, nums):\n        \"\"\"\n        :type nums: List[int]\n        :rtype: int\n        \"\"\"\n        n = len(nums)\n        if n == 0: \n            return 0\n        pos = 1;i = 1;count=0\n        while i < n:\n            if nums[i] == nums[i-1]:\n                i=i+1\n                count=count+1\n            else:\n                nums[pos] = nums[i]\n                pos = pos+1\n                i = i + 1\n        for i in range(count):\n            nums.pop(-1)\n        return len(nums)\n```\n\n\n</article>\n","source":"leetcode/Leetcode[26]-Remove Duplicates from Sorted Array.md","raw":"---\ntitle: Leetcode[26]-Remove Duplicates from Sorted Array\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/remove-duplicates-from-sorted-array/\n\nGiven a sorted array, remove the duplicates in place such that each element appear only once and return the new length.\n\nDo not allocate extra space for another array, you must do this in place with constant memory.\n\nFor example,\nGiven input array nums = [1,1,2],\n\nYour function should return length = 2, with the first two elements of nums being 1 and 2 respectively. It doesn't matter what you leave beyond the new length.\n\n--------\n\n**思路**：需要额外添加一个新的变量pos，初始值为0，用来记录非重复元素的位置。从数组的第二个元素开始遍历，如果和前面的元素相等，则直接跳到下一个；如果不等，则将该数组的值赋值给++pos位，接着继续遍历下一个；\n\n**Code(c++):**\n\n```\nclass Solution {\npublic:\n    int removeDuplicates(vector<int>& nums) {\n        int n = nums.size();\n        if(n==0) return 0;\n        int pos = 0,i = 1;\n        while(i < n){\n            if(nums[i] == nums[i-1]){\n                i++;\n            }else{\n                nums[++pos] = nums[i++];\n            }\n        }\n        n = pos+1;\n        nums.resize(n);\n        return n;\n    }\n};\n```\n\n做个简单的修改：\n\n```\nclass Solution {\npublic:\n    int removeDuplicates(vector<int>& nums) {\n        int n = nums.size();\n        if(n==0) return 0;\n        int pos = 1,i = 1;//将pos从1开始\n        while(i < n){\n            if(nums[i] == nums[i-1]){\n                i++;\n            }else{\n                nums[pos++] = nums[i++];//这里保持一致\n            }\n        }\n        n = pos;\n        nums.resize(n);\n        return n;\n    }\n};\n```\n\n**Python代码**\n\n```\nclass Solution(object):\n    def removeDuplicates(self, nums):\n        \"\"\"\n        :type nums: List[int]\n        :rtype: int\n        \"\"\"\n        n = len(nums)\n        if n == 0: \n            return 0\n        pos = 1;i = 1;count=0\n        while i < n:\n            if nums[i] == nums[i-1]:\n                i=i+1\n                count=count+1\n            else:\n                nums[pos] = nums[i]\n                pos = pos+1\n                i = i + 1\n        for i in range(count):\n            nums.pop(-1)\n        return len(nums)\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.652Z","updated":"2016-03-23T14:33:02.735Z","path":"leetcode/Leetcode[26]-Remove Duplicates from Sorted Array.html","_id":"cimigpypr000t6cujrhwe7qba"},{"title":"Leetcode[263]-Ugly Number++","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/ugly-number/\n\nWrite a program to check whether a given number is an ugly number.\n\nUgly numbers are positive numbers whose prime factors only include 2, 3, 5. For example, 6, 8 are ugly while 14 is not ugly since it includes another prime factor 7.\n\nNote that 1 is typically treated as an ugly number.\n\n---\n\n```\nclass Solution {\npublic:\n    bool isUgly(int num) {\n        if (num == 0) return false;\n        if (num == 1) return true;\n\n        int pfactor[] = { 2, 3, 5 };\n        for (auto val : pfactor) {\n            while (num % val == 0) { num /= val; }\n        }\n\n        return num == 1;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[263]-Ugly Number++.md","raw":"---\ntitle: Leetcode[263]-Ugly Number++\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/ugly-number/\n\nWrite a program to check whether a given number is an ugly number.\n\nUgly numbers are positive numbers whose prime factors only include 2, 3, 5. For example, 6, 8 are ugly while 14 is not ugly since it includes another prime factor 7.\n\nNote that 1 is typically treated as an ugly number.\n\n---\n\n```\nclass Solution {\npublic:\n    bool isUgly(int num) {\n        if (num == 0) return false;\n        if (num == 1) return true;\n\n        int pfactor[] = { 2, 3, 5 };\n        for (auto val : pfactor) {\n            while (num % val == 0) { num /= val; }\n        }\n\n        return num == 1;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.757Z","updated":"2016-03-23T14:33:02.734Z","path":"leetcode/Leetcode[263]-Ugly Number++.html","_id":"cimigpyps000u6cuj3myxfj4t"},{"title":"Leetcode[260]-Single Number III","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\n\n\nLink: https://leetcode.com/problems/single-number-iii/\n\nGiven an array of numbers nums, in which exactly two elements appear only once and all the other elements appear exactly twice. Find the two elements that appear only once.\n\nFor example:\n\nGiven nums = [1, 2, 1, 3, 2, 5], return [3, 5].\n\nNote:\nThe order of the result is not important. So in the above example, [5, 3] is also correct.\nYour algorithm should run in linear runtime complexity. Could you implement it using only constant space complexity?\n\n---\n\n思路：首先对数组进行排序，然后一对一对的进行比较，如果两个相等，则以步长为2往后移动，如果不相等，则将当前的值加入到返回变量中，然后以步长为1往后移动。\n\nC++:\n\n```\nclass Solution {\npublic:\n    vector<int> singleNumber(vector<int>& nums) {\n        sort(nums.begin(),nums.end());\n        vector<int> res;\n        int n = nums.size();\n        int i = 0;\n        while(i<n-1){\n            if(nums[i]==nums[i+1]){\n                i+=2;\n            }else{\n                res.push_back(nums[i]);\n                i+=1;\n            }\n        }\n        if(nums[n-1]!=nums[n-2]){\n            res.push_back(nums[n-1]);\n        }\n            \n        return res;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[260]-Single Number III.md","raw":"---\ntitle: Leetcode[260]-Single Number III\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\n\n\nLink: https://leetcode.com/problems/single-number-iii/\n\nGiven an array of numbers nums, in which exactly two elements appear only once and all the other elements appear exactly twice. Find the two elements that appear only once.\n\nFor example:\n\nGiven nums = [1, 2, 1, 3, 2, 5], return [3, 5].\n\nNote:\nThe order of the result is not important. So in the above example, [5, 3] is also correct.\nYour algorithm should run in linear runtime complexity. Could you implement it using only constant space complexity?\n\n---\n\n思路：首先对数组进行排序，然后一对一对的进行比较，如果两个相等，则以步长为2往后移动，如果不相等，则将当前的值加入到返回变量中，然后以步长为1往后移动。\n\nC++:\n\n```\nclass Solution {\npublic:\n    vector<int> singleNumber(vector<int>& nums) {\n        sort(nums.begin(),nums.end());\n        vector<int> res;\n        int n = nums.size();\n        int i = 0;\n        while(i<n-1){\n            if(nums[i]==nums[i+1]){\n                i+=2;\n            }else{\n                res.push_back(nums[i]);\n                i+=1;\n            }\n        }\n        if(nums[n-1]!=nums[n-2]){\n            res.push_back(nums[n-1]);\n        }\n            \n        return res;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.755Z","updated":"2016-03-23T14:33:02.725Z","path":"leetcode/Leetcode[260]-Single Number III.html","_id":"cimigpypt000v6cujhrxkuyrk"},{"title":"Leetcode[258]-Add Digits","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/add-digits/\n\nGiven a non-negative integer num, repeatedly add all its digits until the result has only one digit.\n\nFor example:\n\nGiven num = 38, the process is like: 3 + 8 = 11, 1 + 1 = 2. Since 2 has only one digit, return it.\n\nFollow up:\nCould you do it without any loop/recursion in O(1) runtime?\n\n---\n\n思路：此题和202题有点类似，可以参考。主要是在各个位数的想加上，有点技巧。\n\n\nC++\n\n```\nclass Solution {\npublic:\n    int addDigits(int num) {\n        int n=num;\n        while(n>=10){\n            int i = 0;\n            while(n>0){\n                i += n%10;\n                n = n/10;\n            };\n            n = i;\n        }\n        return n;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[258]-Add Digits.md","raw":"---\ntitle: Leetcode[258]-Add Digits\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/add-digits/\n\nGiven a non-negative integer num, repeatedly add all its digits until the result has only one digit.\n\nFor example:\n\nGiven num = 38, the process is like: 3 + 8 = 11, 1 + 1 = 2. Since 2 has only one digit, return it.\n\nFollow up:\nCould you do it without any loop/recursion in O(1) runtime?\n\n---\n\n思路：此题和202题有点类似，可以参考。主要是在各个位数的想加上，有点技巧。\n\n\nC++\n\n```\nclass Solution {\npublic:\n    int addDigits(int num) {\n        int n=num;\n        while(n>=10){\n            int i = 0;\n            while(n>0){\n                i += n%10;\n                n = n/10;\n            };\n            n = i;\n        }\n        return n;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.753Z","updated":"2016-03-23T14:33:02.717Z","path":"leetcode/Leetcode[258]-Add Digits.html","_id":"cimigpypv000w6cujptb60btx"},{"title":"Leetcode[242]-Valid Anagram","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/valid-anagram/\n\nGiven two strings s and t, write a function to determine if t is an anagram of s.\n\nFor example,\ns = \"anagram\", t = \"nagaram\", return true.\ns = \"rat\", t = \"car\", return false.\n\n\nNote:\nYou may assume the string contains only lowercase alphabets.\n\n---\n\n思路：这道题，思路比较简单，将s中字符串的单词个数映射到26个子母中，然后遍历t，出现一个字母，就将该字母数减1，最后判断是否全为0即可。\n\nPython代码比较简单，就给出Python代码吧：\n\nPython：\n\n```\nclass Solution(object):\n    def isAnagram(self, s, t):\n        \"\"\"\n        :type s: str\n        :type t: str\n        :rtype: bool\n        \"\"\"\n        if len(s) != len(t):\n            return False\n        word = [0]*26\n        for i in range(len(s)):\n            index1 = ord(s[i])-97\n            index2 = ord(t[i])-97\n            word[index1] += 1\n            word[index2] -= 1\n        return not any(word)\n```\n\n附加C++:\n\n```\nclass Solution {\npublic:\n    bool isAnagram(string s, string t) {\n        if(s.length()!=t.length())return false;\n        int word[26];\n        memset(word, 0, sizeof(word));\n        for(int i=0;i<s.length();i++){\n            int index1 = s[i]-'a';\n            int index2 = t[i]-'a';\n            word[index1]+=1;\n            word[index2]-=1;\n        }\n        int c=0;\n        while(c<26){\n            if(word[c++]!=0)return false;\n        }\n        return true;\n    }\n};\n```\n\n\n学习心得：有关字符串的题目，可以考虑将其映射到字母表中。\n\n\n</article>\n","source":"leetcode/Leetcode[242]-Valid Anagram.md","raw":"---\ntitle: Leetcode[242]-Valid Anagram\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/valid-anagram/\n\nGiven two strings s and t, write a function to determine if t is an anagram of s.\n\nFor example,\ns = \"anagram\", t = \"nagaram\", return true.\ns = \"rat\", t = \"car\", return false.\n\n\nNote:\nYou may assume the string contains only lowercase alphabets.\n\n---\n\n思路：这道题，思路比较简单，将s中字符串的单词个数映射到26个子母中，然后遍历t，出现一个字母，就将该字母数减1，最后判断是否全为0即可。\n\nPython代码比较简单，就给出Python代码吧：\n\nPython：\n\n```\nclass Solution(object):\n    def isAnagram(self, s, t):\n        \"\"\"\n        :type s: str\n        :type t: str\n        :rtype: bool\n        \"\"\"\n        if len(s) != len(t):\n            return False\n        word = [0]*26\n        for i in range(len(s)):\n            index1 = ord(s[i])-97\n            index2 = ord(t[i])-97\n            word[index1] += 1\n            word[index2] -= 1\n        return not any(word)\n```\n\n附加C++:\n\n```\nclass Solution {\npublic:\n    bool isAnagram(string s, string t) {\n        if(s.length()!=t.length())return false;\n        int word[26];\n        memset(word, 0, sizeof(word));\n        for(int i=0;i<s.length();i++){\n            int index1 = s[i]-'a';\n            int index2 = t[i]-'a';\n            word[index1]+=1;\n            word[index2]-=1;\n        }\n        int c=0;\n        while(c<26){\n            if(word[c++]!=0)return false;\n        }\n        return true;\n    }\n};\n```\n\n\n学习心得：有关字符串的题目，可以考虑将其映射到字母表中。\n\n\n</article>\n","date":"2016-03-23T14:33:15.751Z","updated":"2016-03-23T14:33:02.701Z","path":"leetcode/Leetcode[242]-Valid Anagram.html","_id":"cimigpyq1000x6cujxpu0hmb3"},{"title":"Leetcode[237]-Delete Node in a Linked List","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/delete-node-in-a-linked-list/\n\nWrite a function to delete a node (except the tail) in a singly linked list, given only access to that node.\n\nSupposed the linked list is 1 -> 2 -> 3 -> 4 and you are given the third node with value 3, the linked list should become 1 -> 2 -> 4 after calling your function.\n\nSubscribe to see which companies asked this question\n\n\n---\n比较简单，直接给出答案\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    void deleteNode(ListNode* node) {\n        if(node == NULL) return;\n        ListNode *tmp = node->next;\n        node->val = tmp->val;\n        node->next = tmp->next;\n        delete tmp;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[237]-Delete Node in a Linked List.md","raw":"---\ntitle: Leetcode[237]-Delete Node in a Linked List\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/delete-node-in-a-linked-list/\n\nWrite a function to delete a node (except the tail) in a singly linked list, given only access to that node.\n\nSupposed the linked list is 1 -> 2 -> 3 -> 4 and you are given the third node with value 3, the linked list should become 1 -> 2 -> 4 after calling your function.\n\nSubscribe to see which companies asked this question\n\n\n---\n比较简单，直接给出答案\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    void deleteNode(ListNode* node) {\n        if(node == NULL) return;\n        ListNode *tmp = node->next;\n        node->val = tmp->val;\n        node->next = tmp->next;\n        delete tmp;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.749Z","updated":"2016-03-23T14:33:02.693Z","path":"leetcode/Leetcode[237]-Delete Node in a Linked List.html","_id":"cimigpyq2000y6cujjaxja9yv"},{"title":"Leetcode[231]-Power of Two","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/power-of-two/\n\nGiven an integer, write a function to determine if it is a power of two.\n\n---\n\n分析：\n\n- 如果n小于0，返回false；\n- 如果n等于1或者等于2，返回true；\n- 当n大于2时，根据n大于2的条件进行递归，，如果n%2不为0则直接返回false，否则将n/2赋值给n\n\t- 如果循环结束后还没有返回false，则返回true。\n\n\nC++:\n\n```\nclass Solution {\npublic:\n    bool isPowerOfTwo(int n) {\n        if(n<=0) return false;\n        if (n==2||n==1) return true;\n        while(n>2){\n            if(n%2!=0) return false;\n            n/=2;\n        }\n        return true;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[231]-Power of Two.md","raw":"---\ntitle: Leetcode[231]-Power of Two\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/power-of-two/\n\nGiven an integer, write a function to determine if it is a power of two.\n\n---\n\n分析：\n\n- 如果n小于0，返回false；\n- 如果n等于1或者等于2，返回true；\n- 当n大于2时，根据n大于2的条件进行递归，，如果n%2不为0则直接返回false，否则将n/2赋值给n\n\t- 如果循环结束后还没有返回false，则返回true。\n\n\nC++:\n\n```\nclass Solution {\npublic:\n    bool isPowerOfTwo(int n) {\n        if(n<=0) return false;\n        if (n==2||n==1) return true;\n        while(n>2){\n            if(n%2!=0) return false;\n            n/=2;\n        }\n        return true;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.748Z","updated":"2016-03-23T14:33:02.683Z","path":"leetcode/Leetcode[231]-Power of Two.html","_id":"cimigpyq6000z6cujdwfrzutk"},{"title":"Leetcode[226]-Invert Binary Tree","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/invert-binary-tree/\n\nInvert a binary tree.\n\n\t     4\n\t   /   \\\n\t  2     7\n\t / \\   / \\\n\t1   3 6   9\n\nto\n\n\t     4\n\t   /   \\\n\t  7     2\n\t / \\   / \\\n\t9   6 3   1\n\nTrivia:\nThis problem was inspired by this original tweet by Max Howell:\nGoogle: 90% of our engineers use the software you wrote (Homebrew), but you can’t invert a binary tree on a whiteboard so fuck off.\n\n\n----\n\nC++递归法求解：\n\n```\n\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    TreeNode* invertTree(TreeNode* root) {\n        if(!root) return NULL;\n        \n        invertNode(root);\n        return root;\n    }\n    \n    void invertNode(TreeNode *root){\n        if(root == NULL) return;\n        if(!root->left && !root->right) return;\n    \n        TreeNode *tempNode=NULL;\n        \n        if(root->right) tempNode = root->right;\n        if(root->left){\n            root->right = root->left;\n            root->left = tempNode;\n        }else{\n            root->left = tempNode;\n            root->right = NULL;\n        }\n        invertNode(root->left);\n        invertNode(root->right);\n    \n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[226]-Invert Binary Tree.md","raw":"---\ntitle: Leetcode[226]-Invert Binary Tree\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/invert-binary-tree/\n\nInvert a binary tree.\n\n\t     4\n\t   /   \\\n\t  2     7\n\t / \\   / \\\n\t1   3 6   9\n\nto\n\n\t     4\n\t   /   \\\n\t  7     2\n\t / \\   / \\\n\t9   6 3   1\n\nTrivia:\nThis problem was inspired by this original tweet by Max Howell:\nGoogle: 90% of our engineers use the software you wrote (Homebrew), but you can’t invert a binary tree on a whiteboard so fuck off.\n\n\n----\n\nC++递归法求解：\n\n```\n\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    TreeNode* invertTree(TreeNode* root) {\n        if(!root) return NULL;\n        \n        invertNode(root);\n        return root;\n    }\n    \n    void invertNode(TreeNode *root){\n        if(root == NULL) return;\n        if(!root->left && !root->right) return;\n    \n        TreeNode *tempNode=NULL;\n        \n        if(root->right) tempNode = root->right;\n        if(root->left){\n            root->right = root->left;\n            root->left = tempNode;\n        }else{\n            root->left = tempNode;\n            root->right = NULL;\n        }\n        invertNode(root->left);\n        invertNode(root->right);\n    \n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.746Z","updated":"2016-03-23T14:33:02.678Z","path":"leetcode/Leetcode[226]-Invert Binary Tree.html","_id":"cimigpyq800106cuj20c0xprn"},{"title":"Leetcode[222]-Count Complete Tree Nodes","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/count-complete-tree-nodes/\n\nGiven a complete binary tree, count the number of nodes.\n\nDefinition of a complete binary tree from Wikipedia:\nIn a complete binary tree every level, except possibly the last, is completely filled, and all nodes in the last level are as far left as possible. It can have between 1 and 2h nodes inclusive at the last level h.\n\n\n\n------\n\n思路：分别计算左右子树，然后返回左右字数节点个数加一\n\n递归法：（超时了）\n\n```\nclass Solution {\npublic:\n    int countNodes(TreeNode* root) {\n        if(root == NULL) return 0;\n        \n        int lcount=0,rcount=0;\n        if(root->left != NULL){\n            lcount = countNodes(root->left);\n        }\n        if(root->right != NULL){\n            rcount = countNodes(root->right);\n        }\n        return lcount+rcount+1;  \n    }\n};\n```\n\n方法二：\n先计算左右的深度是否相等，相等则为满二叉树，满二叉树的节点个数为深度的平方减一,即depth^2-1；如果不相等，则递归以同样的方式计算左子树和右子树，并返回两者个数之和加一。\n\n**Code(c++):**\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    int countNodes(TreeNode* root) {\n        if(root == NULL) return 0;\n\t\t\n        int ldepth = getLeftDepth(root);\n        int rdepth = getRightDepth(root);\n        //return the square of leftdepth -1\n        if(ldepth == rdepth) return (1 << ldepth) - 1;\n    \n        return countNodes(root->left)+countNodes(root->right)+1;\n    }\n    //compute the depth of left tree\n    int getLeftDepth(TreeNode *root){\n        int depth = 0;\n        while(root){\n            depth++;\n            root = root->left;\n        }\n        return depth;\n    }\n    //compute the depth of right tree\n    int getRightDepth(TreeNode *root){\n        int depth = 0;\n        while(root){\n            depth++;\n            root = root->right;\n        }\n        return depth;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[222]-Count Complete Tree Nodes.md","raw":"---\ntitle: Leetcode[222]-Count Complete Tree Nodes\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/count-complete-tree-nodes/\n\nGiven a complete binary tree, count the number of nodes.\n\nDefinition of a complete binary tree from Wikipedia:\nIn a complete binary tree every level, except possibly the last, is completely filled, and all nodes in the last level are as far left as possible. It can have between 1 and 2h nodes inclusive at the last level h.\n\n\n\n------\n\n思路：分别计算左右子树，然后返回左右字数节点个数加一\n\n递归法：（超时了）\n\n```\nclass Solution {\npublic:\n    int countNodes(TreeNode* root) {\n        if(root == NULL) return 0;\n        \n        int lcount=0,rcount=0;\n        if(root->left != NULL){\n            lcount = countNodes(root->left);\n        }\n        if(root->right != NULL){\n            rcount = countNodes(root->right);\n        }\n        return lcount+rcount+1;  \n    }\n};\n```\n\n方法二：\n先计算左右的深度是否相等，相等则为满二叉树，满二叉树的节点个数为深度的平方减一,即depth^2-1；如果不相等，则递归以同样的方式计算左子树和右子树，并返回两者个数之和加一。\n\n**Code(c++):**\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    int countNodes(TreeNode* root) {\n        if(root == NULL) return 0;\n\t\t\n        int ldepth = getLeftDepth(root);\n        int rdepth = getRightDepth(root);\n        //return the square of leftdepth -1\n        if(ldepth == rdepth) return (1 << ldepth) - 1;\n    \n        return countNodes(root->left)+countNodes(root->right)+1;\n    }\n    //compute the depth of left tree\n    int getLeftDepth(TreeNode *root){\n        int depth = 0;\n        while(root){\n            depth++;\n            root = root->left;\n        }\n        return depth;\n    }\n    //compute the depth of right tree\n    int getRightDepth(TreeNode *root){\n        int depth = 0;\n        while(root){\n            depth++;\n            root = root->right;\n        }\n        return depth;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.745Z","updated":"2016-03-23T14:33:02.665Z","path":"leetcode/Leetcode[222]-Count Complete Tree Nodes.html","_id":"cimigpyqb00116cujdxr9kvkc"},{"title":"Leetcode[21]-Merge Two Sorted Lists","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/merge-two-sorted-lists/\n\nMerge two sorted linked lists and return it as a new list. The new list should be made by splicing together the nodes of the first two lists.\n\n\n**思路**：要求合并两个排好序的链表。开始我们初始化头front和尾tail，然后从两个单链表的头部比较两个单链表，两链表同时不为空的条件下递归比较：\n\n- 如果l1的值大于l2的值，就将尾部指向l1，并同步向右移动l1的头指针和tail指针\n- 如果l1的值小于l2的值，就将尾部指向l2，并同步向右移动l2的头指针和tail指针\n\n接着，如果l1不为空，则将尾指针的下一个指向l1，如果l2不为空，则将尾指针的下一个指向l2，然后将front右移一位，\n\n最后返回front即可。\n\nCode(c++):\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    ListNode* mergeTwoLists(ListNode* l1, ListNode* l2) {\n        if(l1 == NULL) return l2;\n        if(l2 == NULL) return l1;\n        \n        ListNode* front = new ListNode(-1);\n        ListNode* tail = front;\n        \n        while( l1 && l2){\n            if(l1->val < l2->val){\n                tail->next = l1;\n                l1 = l1->next;\n                tail = tail->next;\n            }else {\n                tail->next = l2;\n                l2 = l2->next;\n                tail = tail->next;\n            }\n        }\n        if(l1){\n            tail->next = l1;\n        }\n        if(l2){\n            tail->next = l2;\n        }\n        front = front->next;\n        return front;\n        \n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[21]-Merge Two Sorted Lists.md","raw":"---\ntitle: Leetcode[21]-Merge Two Sorted Lists\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/merge-two-sorted-lists/\n\nMerge two sorted linked lists and return it as a new list. The new list should be made by splicing together the nodes of the first two lists.\n\n\n**思路**：要求合并两个排好序的链表。开始我们初始化头front和尾tail，然后从两个单链表的头部比较两个单链表，两链表同时不为空的条件下递归比较：\n\n- 如果l1的值大于l2的值，就将尾部指向l1，并同步向右移动l1的头指针和tail指针\n- 如果l1的值小于l2的值，就将尾部指向l2，并同步向右移动l2的头指针和tail指针\n\n接着，如果l1不为空，则将尾指针的下一个指向l1，如果l2不为空，则将尾指针的下一个指向l2，然后将front右移一位，\n\n最后返回front即可。\n\nCode(c++):\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    ListNode* mergeTwoLists(ListNode* l1, ListNode* l2) {\n        if(l1 == NULL) return l2;\n        if(l2 == NULL) return l1;\n        \n        ListNode* front = new ListNode(-1);\n        ListNode* tail = front;\n        \n        while( l1 && l2){\n            if(l1->val < l2->val){\n                tail->next = l1;\n                l1 = l1->next;\n                tail = tail->next;\n            }else {\n                tail->next = l2;\n                l2 = l2->next;\n                tail = tail->next;\n            }\n        }\n        if(l1){\n            tail->next = l1;\n        }\n        if(l2){\n            tail->next = l2;\n        }\n        front = front->next;\n        return front;\n        \n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.650Z","updated":"2016-03-23T14:33:02.663Z","path":"leetcode/Leetcode[21]-Merge Two Sorted Lists.html","_id":"cimigpyqd00126cujt3rw339z"},{"title":"Leetcode[219]-Contains Duplicate II","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/contains-duplicate-ii/\n\nGiven an array of integers and an integer k, find out whether there there are two distinct indices i and j in the array such that nums[i] = nums[j] and the difference between i and j is at most k.\n\n-------\n**分析**：用C++中的map记录num和下标value，key值为数值，value为值在nums数组中的下标。首先遍历数组，如果在map中存在\n【mapv.find(number) != mapv.end()】并且当前位置和map中找到的位置差小于等于k【i-mapv[number] <= k】，就返回true，不然就将该值加入到map中。依次循环...\n\nCode(c++)\n\n```\nclass Solution {  \npublic:  \n    bool containsNearbyDuplicate(vector<int>& nums, int k) {\n        int n = nums.size();\n        map<int, int> mapv;\n        for (int i = 0; i < n; i++){\n            int number = nums[i];\n            if (mapv.find(number) != mapv.end() && i-mapv[number] <= k){\n                return true;\n            }else{\n                mapv[number] = i;\n            }\n        }\n        return false;\n    }\n};  \n\n```\n\n\n</article>\n","source":"leetcode/Leetcode[219]-Contains Duplicate II.md","raw":"---\ntitle: Leetcode[219]-Contains Duplicate II\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/contains-duplicate-ii/\n\nGiven an array of integers and an integer k, find out whether there there are two distinct indices i and j in the array such that nums[i] = nums[j] and the difference between i and j is at most k.\n\n-------\n**分析**：用C++中的map记录num和下标value，key值为数值，value为值在nums数组中的下标。首先遍历数组，如果在map中存在\n【mapv.find(number) != mapv.end()】并且当前位置和map中找到的位置差小于等于k【i-mapv[number] <= k】，就返回true，不然就将该值加入到map中。依次循环...\n\nCode(c++)\n\n```\nclass Solution {  \npublic:  \n    bool containsNearbyDuplicate(vector<int>& nums, int k) {\n        int n = nums.size();\n        map<int, int> mapv;\n        for (int i = 0; i < n; i++){\n            int number = nums[i];\n            if (mapv.find(number) != mapv.end() && i-mapv[number] <= k){\n                return true;\n            }else{\n                mapv[number] = i;\n            }\n        }\n        return false;\n    }\n};  \n\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.744Z","updated":"2016-03-23T14:33:02.642Z","path":"leetcode/Leetcode[219]-Contains Duplicate II.html","_id":"cimigpyqg00136cuj60qsxln7"},{"title":"Leetcode[217]-Contains Duplicate","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink：https://leetcode.com/problems/contains-duplicate/\n\nGiven an array of integers, find if the array contains any duplicates. Your function should return true if any value appears at least twice in the array, and it should return false if every element is distinct.\n\n\n----\n思路：先将数组排序，然后从第二个开始遍历，如果和前一个值相等，则返回true，终止；此方法时间复杂度为O（nlogn），空间复杂度为O（1）\n\n```\nclass Solution {\npublic:\n    bool containsDuplicate(vector<int>& nums) {\n        int n = nums.size();\n        int flag = false;\n        \n        std::sort(nums.begin(), nums.end());\n    \n        int i = 1;\n        while(i < n){\n            if(nums[i] == nums[i-1])\n                return true;\n            i++;\n        }\n        return flag;\n    }\n\n};\n```\n\n**小记**：自己做的时候，开始使用两个for循环遍历，结果超时了，后来使用自己写的快速排序，也超时了。最后使用了std::sort(nums.begin(), nums.end())自带的sort，结果成功了！不知道是快速排序哪里出了问题。\n\n<br><br>\n拓展：快速排序算法\n\n```\nvoid quickSort(vector<int> &nums,int low,int high){\n    int i=low,j=high;\n    if(i < j){\n        int po = nums[low];\n        while(i < j){\n            while(nums[i]<nums[j] && po < nums[j]) j--;\n            if(i<j){\n                int temp = nums[i];\n                nums[i] = nums[j];\n                nums[j] = temp;\n                i++;\n            }\n            while(nums[i]<nums[j] && nums[i] < po) i++;\n            if(i<j){\n                int temp = nums[i];\n                nums[i] = nums[j];\n                nums[j] = temp;\n                j--;\n            }\n        }\n        quickSort(nums,low,j-1);\n        quickSort(nums,j+1,high);\n    }\n}\n```\n\n**Python代码**\n\n```\nclass Solution(object):\n    def containsDuplicate(self, nums):\n        \"\"\"\n        :type nums: List[int]\n        :rtype: bool\n        \"\"\"\n        n = len(nums)\n        if n == 0 or n ==1:\n            return False\n        nums.sort()\n        \n        for i in range(1,n):\n            if nums[i] == nums[i-1]:\n                return True\n        return False\n```\n\n\n</article>\n","source":"leetcode/Leetcode[217]-Contains Duplicate.md","raw":"---\ntitle: Leetcode[217]-Contains Duplicate\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink：https://leetcode.com/problems/contains-duplicate/\n\nGiven an array of integers, find if the array contains any duplicates. Your function should return true if any value appears at least twice in the array, and it should return false if every element is distinct.\n\n\n----\n思路：先将数组排序，然后从第二个开始遍历，如果和前一个值相等，则返回true，终止；此方法时间复杂度为O（nlogn），空间复杂度为O（1）\n\n```\nclass Solution {\npublic:\n    bool containsDuplicate(vector<int>& nums) {\n        int n = nums.size();\n        int flag = false;\n        \n        std::sort(nums.begin(), nums.end());\n    \n        int i = 1;\n        while(i < n){\n            if(nums[i] == nums[i-1])\n                return true;\n            i++;\n        }\n        return flag;\n    }\n\n};\n```\n\n**小记**：自己做的时候，开始使用两个for循环遍历，结果超时了，后来使用自己写的快速排序，也超时了。最后使用了std::sort(nums.begin(), nums.end())自带的sort，结果成功了！不知道是快速排序哪里出了问题。\n\n<br><br>\n拓展：快速排序算法\n\n```\nvoid quickSort(vector<int> &nums,int low,int high){\n    int i=low,j=high;\n    if(i < j){\n        int po = nums[low];\n        while(i < j){\n            while(nums[i]<nums[j] && po < nums[j]) j--;\n            if(i<j){\n                int temp = nums[i];\n                nums[i] = nums[j];\n                nums[j] = temp;\n                i++;\n            }\n            while(nums[i]<nums[j] && nums[i] < po) i++;\n            if(i<j){\n                int temp = nums[i];\n                nums[i] = nums[j];\n                nums[j] = temp;\n                j--;\n            }\n        }\n        quickSort(nums,low,j-1);\n        quickSort(nums,j+1,high);\n    }\n}\n```\n\n**Python代码**\n\n```\nclass Solution(object):\n    def containsDuplicate(self, nums):\n        \"\"\"\n        :type nums: List[int]\n        :rtype: bool\n        \"\"\"\n        n = len(nums)\n        if n == 0 or n ==1:\n            return False\n        nums.sort()\n        \n        for i in range(1,n):\n            if nums[i] == nums[i-1]:\n                return True\n        return False\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.742Z","updated":"2016-03-23T14:33:02.637Z","path":"leetcode/Leetcode[217]-Contains Duplicate.html","_id":"cimigpyqh00146cujf80p0ysi"},{"title":"Leetcode[215]-Kth Largest Element in an Array","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/kth-largest-element-in-an-array/\n\nFind the kth largest element in an unsorted array. Note that it is the kth largest element in the sorted order, not the kth distinct element.\n\nFor example,\nGiven`[3,2,1,5,6,4] `and `k = 2`, return `5`.\n\nNote: \nYou may assume k is always valid, 1 ≤ k ≤ array's length.\n\nCredits:\nSpecial thanks to @mithmatt for adding this problem and creating all test cases.\n\n\n------\n\n法一：使用STL的sort排序O(NlogN)\n\n```\nint findKthLargest(vector<int>& nums, int k) {\n    sort(nums.begin(),nums.end());\n    return nums[nums.size()-k];\n}\n```\n\n法二：自己写快速排序O（NlogN）\n\n```\nint findKthLargest(vector<int>& nums, int k){\n   \n\tquickSort(nums, 0 ,nums.size());\n\treturn nums[nums.size()-k];\n   \n}\nvoid quickSort(vector<int> &nums, int left, int right){\n    int i = left, j = right - 1;\n    if(i < j){\n        int po = nums[i];\n        while(i < j){\n            while(i < j && nums[j] >= po) j--;\n            if(i < j) {\n                nums[i++] = nums[j];\n            }\n            while(i < j && nums[i] <= po ) i++;\n            if(i < j){\n                nums[j--] = nums[i];\n            }\n        }\n        nums[i] = po;\n        quickSort(nums, left, i);\n        quickSort(nums, i+1, right);\n        \n    }\n}\n```\n\n法三：使用建堆法  时间复杂度O(klogN)\n\n```\nint findKthLargest(vector<int>& nums, int k){\n    make_heap(nums.begin(), nums.end());\n    for(auto i=0; i<k-1;i++){\n        pop_heap(nums.begin(), nums.end());\n        nums.pop_back();\n    }\n    return nums.front();\n}\n```\n\n方法四：此方法是论坛看到的，O（N）\n\n```\nint findKthLargest(vector<int>& nums, int k){\n     int i, m, n, pivot, head =0, tail = nums.size()-1, maxV;\n\n    while(1){\n        m = head, n= tail;\n        pivot = nums[m++];\n        while(m <= n) {\n            if(nums[m] >= pivot) m++;\n            else if(nums[n] < pivot) n--;\n            else {\n                swap(nums[m++], nums[n--]);\n            }\n        }\n        if(m-head == k) \n            return pivot;\n        else if(m-head < k) {\n            k -= (m-head); \n            head = m;  \n        }\n        else {\n            tail = m-1;\n            head = head+1;\n        }\n    }\n    \n}\n```\n\n\n</article>\n","source":"leetcode/Leetcode[215]-Kth Largest Element in an Array.md","raw":"---\ntitle: Leetcode[215]-Kth Largest Element in an Array\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/kth-largest-element-in-an-array/\n\nFind the kth largest element in an unsorted array. Note that it is the kth largest element in the sorted order, not the kth distinct element.\n\nFor example,\nGiven`[3,2,1,5,6,4] `and `k = 2`, return `5`.\n\nNote: \nYou may assume k is always valid, 1 ≤ k ≤ array's length.\n\nCredits:\nSpecial thanks to @mithmatt for adding this problem and creating all test cases.\n\n\n------\n\n法一：使用STL的sort排序O(NlogN)\n\n```\nint findKthLargest(vector<int>& nums, int k) {\n    sort(nums.begin(),nums.end());\n    return nums[nums.size()-k];\n}\n```\n\n法二：自己写快速排序O（NlogN）\n\n```\nint findKthLargest(vector<int>& nums, int k){\n   \n\tquickSort(nums, 0 ,nums.size());\n\treturn nums[nums.size()-k];\n   \n}\nvoid quickSort(vector<int> &nums, int left, int right){\n    int i = left, j = right - 1;\n    if(i < j){\n        int po = nums[i];\n        while(i < j){\n            while(i < j && nums[j] >= po) j--;\n            if(i < j) {\n                nums[i++] = nums[j];\n            }\n            while(i < j && nums[i] <= po ) i++;\n            if(i < j){\n                nums[j--] = nums[i];\n            }\n        }\n        nums[i] = po;\n        quickSort(nums, left, i);\n        quickSort(nums, i+1, right);\n        \n    }\n}\n```\n\n法三：使用建堆法  时间复杂度O(klogN)\n\n```\nint findKthLargest(vector<int>& nums, int k){\n    make_heap(nums.begin(), nums.end());\n    for(auto i=0; i<k-1;i++){\n        pop_heap(nums.begin(), nums.end());\n        nums.pop_back();\n    }\n    return nums.front();\n}\n```\n\n方法四：此方法是论坛看到的，O（N）\n\n```\nint findKthLargest(vector<int>& nums, int k){\n     int i, m, n, pivot, head =0, tail = nums.size()-1, maxV;\n\n    while(1){\n        m = head, n= tail;\n        pivot = nums[m++];\n        while(m <= n) {\n            if(nums[m] >= pivot) m++;\n            else if(nums[n] < pivot) n--;\n            else {\n                swap(nums[m++], nums[n--]);\n            }\n        }\n        if(m-head == k) \n            return pivot;\n        else if(m-head < k) {\n            k -= (m-head); \n            head = m;  \n        }\n        else {\n            tail = m-1;\n            head = head+1;\n        }\n    }\n    \n}\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.741Z","updated":"2016-03-23T14:33:02.622Z","path":"leetcode/Leetcode[215]-Kth Largest Element in an Array.html","_id":"cimigpyqk00156cujkhicgpna"},{"title":"Leetcode[20]-Valid Parentheses","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/valid-parentheses/\n\nGiven a string containing just the characters `'(', ')'`, `'{', '}'`, `'[' and ']'`, determine if the input string is valid.\n\nThe brackets must close in the correct order, `\"()\"` and `\"()[]{}\"` are all valid but `\"(]\"` and `\"([)]\"` are not.\n\n---------------\n\n思路：借助vector容器，存放字符'(','{','['，从左到右的读取字符串的每一个字符，\n\n- 如果字符为上面给定的三个，则加入到vector中；\n- 如果不是，在确保vector容器有字符的情况下，则让其和vector的最后一个比较；\n\n\t- 如果是匹配的，则将vector容器的大小缩减为size()-1；\n\t- 如果不匹配，则返回false；\n\n- 最后，如果vector元素全部匹配完了，则返回true，否则返回false；\n\n代码如下（c++）：\n\n```\nclass Solution {\npublic:\n    bool isValid(string s) {\n        vector<char> str;\n        int len = s.length();\n    \n        for(int i=0; i<len; i++){\n            if(isThose(s[i])) {\n                str.push_back(s[i]);\n                continue;\n            }\n            if(str.size()>0 && isTrue(str[str.size()-1],s[i])) {\n                cout<<str.size()<<\"f\"<<isTrue(str[str.size()-1],s[i])<<endl;\n                str.resize(str.size()-1);\n            }else{\n                return false;\n            }\n        }\n        if(str.size() == 0)\n            return true;\n        else\n            return false;\n    }\n    \n    bool isThose(char &a){\n        if(a == '{' || a == '(' || a == '[')return true;\n        return false;\n    }\n    \n    bool isTrue(char &a, char &b){\n        if( a == '(' && b == ')' ) return true;\n        else if( a == '[' && b == ']' ) return true;\n        else if( a == '{' && b == '}' ) return true;\n        \n        return false;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[20]-Valid Parentheses.md","raw":"---\ntitle: Leetcode[20]-Valid Parentheses\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/valid-parentheses/\n\nGiven a string containing just the characters `'(', ')'`, `'{', '}'`, `'[' and ']'`, determine if the input string is valid.\n\nThe brackets must close in the correct order, `\"()\"` and `\"()[]{}\"` are all valid but `\"(]\"` and `\"([)]\"` are not.\n\n---------------\n\n思路：借助vector容器，存放字符'(','{','['，从左到右的读取字符串的每一个字符，\n\n- 如果字符为上面给定的三个，则加入到vector中；\n- 如果不是，在确保vector容器有字符的情况下，则让其和vector的最后一个比较；\n\n\t- 如果是匹配的，则将vector容器的大小缩减为size()-1；\n\t- 如果不匹配，则返回false；\n\n- 最后，如果vector元素全部匹配完了，则返回true，否则返回false；\n\n代码如下（c++）：\n\n```\nclass Solution {\npublic:\n    bool isValid(string s) {\n        vector<char> str;\n        int len = s.length();\n    \n        for(int i=0; i<len; i++){\n            if(isThose(s[i])) {\n                str.push_back(s[i]);\n                continue;\n            }\n            if(str.size()>0 && isTrue(str[str.size()-1],s[i])) {\n                cout<<str.size()<<\"f\"<<isTrue(str[str.size()-1],s[i])<<endl;\n                str.resize(str.size()-1);\n            }else{\n                return false;\n            }\n        }\n        if(str.size() == 0)\n            return true;\n        else\n            return false;\n    }\n    \n    bool isThose(char &a){\n        if(a == '{' || a == '(' || a == '[')return true;\n        return false;\n    }\n    \n    bool isTrue(char &a, char &b){\n        if( a == '(' && b == ')' ) return true;\n        else if( a == '[' && b == ']' ) return true;\n        else if( a == '{' && b == '}' ) return true;\n        \n        return false;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.647Z","updated":"2016-03-23T14:33:02.619Z","path":"leetcode/Leetcode[20]-Valid Parentheses.html","_id":"cimigpyqn00166cuj3fuc4h8h"},{"title":"Leetcode[206]-Reverse Linked List","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/reverse-linked-list/\n\nReverse a singly linked list.Reverse a singly linked list.\n\nHint:\nA linked list can be reversed either iteratively or recursively. Could you implement both?\n\n-------\n\n分析：\n![这里写图片描述](http://img.blog.csdn.net/20150610095309420)\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    ListNode* reverseList(ListNode* head) {\n        ListNode* pre = NULL;\n        if(head == NULL || head->next==NULL) return head;\n    \n        pre= head->next;\n    \n        head->next = NULL;\n        while(pre!=NULL){\n            ListNode * nextNode = NULL;\n            nextNode = pre->next;\n            pre->next = head;\n            head = pre;\n            pre = nextNode;\n            delete nextNode;\n        }\n        delete pre;\n        return head;\n    }\n};\n```\n\n\n\n\n\n</article>\n","source":"leetcode/Leetcode[206]-Reverse Linked List.md","raw":"---\ntitle: Leetcode[206]-Reverse Linked List\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/reverse-linked-list/\n\nReverse a singly linked list.Reverse a singly linked list.\n\nHint:\nA linked list can be reversed either iteratively or recursively. Could you implement both?\n\n-------\n\n分析：\n![这里写图片描述](http://img.blog.csdn.net/20150610095309420)\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    ListNode* reverseList(ListNode* head) {\n        ListNode* pre = NULL;\n        if(head == NULL || head->next==NULL) return head;\n    \n        pre= head->next;\n    \n        head->next = NULL;\n        while(pre!=NULL){\n            ListNode * nextNode = NULL;\n            nextNode = pre->next;\n            pre->next = head;\n            head = pre;\n            pre = nextNode;\n            delete nextNode;\n        }\n        delete pre;\n        return head;\n    }\n};\n```\n\n\n\n\n\n</article>\n","date":"2016-03-23T14:33:15.740Z","updated":"2016-03-23T14:33:02.604Z","path":"leetcode/Leetcode[206]-Reverse Linked List.html","_id":"cimigpyqq00176cuj9zo805bi"},{"title":"Leetcode[203]-Remove Linked List Elements","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nRemove all elements from a linked list of integers that have value val.\n\nExample\nGiven: 1 --> 2 --> 6 --> 3 --> 4 --> 5 --> 6, val = 6\nReturn: 1 --> 2 --> 3 --> 4 --> 5\n\nCredits:\nSpecial thanks to @mithmatt for adding this problem and creating all test cases.\n\n------\n\n**分析：**\n\n- 如果链表不为空，保证第一个节点不等于val，如果等于，直接跳到下一个节点；\n- 如果此时链表为空，返回该链表；\n- 将头结点赋值给一个临时节点，如果该节点的下一个节点不为空，递归遍历；\n\n\t- 如果下一个节点的值等于给定值，直接跳到下下个节点；\n\t- 如果下一个节点的值不等于给定值，则让跳到下个节点再来循环；\n\n- 最后返回链表的头结点即可。\n\nCode（c++）：\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    ListNode* removeElements(ListNode* head, int val) {\n        while(head !=NULL && head->val == val) {\n            head = head->next;\n        }\n        if(head == NULL) return head;\n        ListNode* pre = NULL;\n        pre = head;\n        while(pre->next!=NULL){\n            if(pre->next->val == val){\n                pre->next = pre->next->next;\n            } else{\n                pre = pre->next;\n            }\n        }\n        return head;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[203]-Remove Linked List Elements.md","raw":"---\ntitle: Leetcode[203]-Remove Linked List Elements\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nRemove all elements from a linked list of integers that have value val.\n\nExample\nGiven: 1 --> 2 --> 6 --> 3 --> 4 --> 5 --> 6, val = 6\nReturn: 1 --> 2 --> 3 --> 4 --> 5\n\nCredits:\nSpecial thanks to @mithmatt for adding this problem and creating all test cases.\n\n------\n\n**分析：**\n\n- 如果链表不为空，保证第一个节点不等于val，如果等于，直接跳到下一个节点；\n- 如果此时链表为空，返回该链表；\n- 将头结点赋值给一个临时节点，如果该节点的下一个节点不为空，递归遍历；\n\n\t- 如果下一个节点的值等于给定值，直接跳到下下个节点；\n\t- 如果下一个节点的值不等于给定值，则让跳到下个节点再来循环；\n\n- 最后返回链表的头结点即可。\n\nCode（c++）：\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    ListNode* removeElements(ListNode* head, int val) {\n        while(head !=NULL && head->val == val) {\n            head = head->next;\n        }\n        if(head == NULL) return head;\n        ListNode* pre = NULL;\n        pre = head;\n        while(pre->next!=NULL){\n            if(pre->next->val == val){\n                pre->next = pre->next->next;\n            } else{\n                pre = pre->next;\n            }\n        }\n        return head;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.738Z","updated":"2016-03-23T14:33:02.590Z","path":"leetcode/Leetcode[203]-Remove Linked List Elements.html","_id":"cimigpyqs00186cujsvmj1sni"},{"title":"Leetcode[202]-Happy Number","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/happy-number/\n\nWrite an algorithm to determine if a number is \"happy\".\n\nA happy number is a number defined by the following process: Starting with any positive integer, replace the number by the sum of the squares of its digits, and repeat the process until the number equals 1 (where it will stay), or it loops endlessly in a cycle which does not include 1. Those numbers for which this process ends in 1 are happy numbers.\n\n\nExample: 19 is a happy number\n\n$1^2 + 9^2 = 82$\n$8^2 + 2^2 = 68$\n$6^2 + 8^2 = 100$\n$1^2 + 0^2 + 0^2 = 1$\n\nCredits:\nSpecial thanks to @mithmatt and @ts for adding this problem and creating all test cases.\n\n------\n\n**分析**：题目说的是对任意一个正整数，不断各个数位上数字的平方和，若最终收敛为1，则该数字为happy number，否则程序可能从某个数开始陷入循环。\n\n这里我们使用一个哈希map表存储已经出现过的数字，如果下次还出现，则返回false。\n\n```\nclass Solution {\npublic:\n    bool isHappy(int n) {\n\n        if(n==1) return true;\n        map<int,int> nums;\n\n        while(n>0){\n            int number = 0;\n            # 计算一个数各个位的平方和\n            while(n){\n                number += (n % 10) * (n % 10);\n                n/=10;\n            }\n\n            if(number == 1)\n                return true;\n            else if(nums.find(number)!=nums.end())\n                return false;\n            n = number;\n            nums[n] = 1;\n        }\n    }\n};\n```\n\n另外还有一种简单的算法：\n\n--------\n```\nclass Solution {\npublic:\n    bool isHappy(int n) {\n        while(n>6){  \n            int next = 0;  \n            while(n){\n                next+=(n%10)*(n%10); \n                n/=10;\n            }  \n            n = next;  \n        }  \n        return n==1;  \n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[202]-Happy Number.md","raw":"---\ntitle: Leetcode[202]-Happy Number\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/happy-number/\n\nWrite an algorithm to determine if a number is \"happy\".\n\nA happy number is a number defined by the following process: Starting with any positive integer, replace the number by the sum of the squares of its digits, and repeat the process until the number equals 1 (where it will stay), or it loops endlessly in a cycle which does not include 1. Those numbers for which this process ends in 1 are happy numbers.\n\n\nExample: 19 is a happy number\n\n$1^2 + 9^2 = 82$\n$8^2 + 2^2 = 68$\n$6^2 + 8^2 = 100$\n$1^2 + 0^2 + 0^2 = 1$\n\nCredits:\nSpecial thanks to @mithmatt and @ts for adding this problem and creating all test cases.\n\n------\n\n**分析**：题目说的是对任意一个正整数，不断各个数位上数字的平方和，若最终收敛为1，则该数字为happy number，否则程序可能从某个数开始陷入循环。\n\n这里我们使用一个哈希map表存储已经出现过的数字，如果下次还出现，则返回false。\n\n```\nclass Solution {\npublic:\n    bool isHappy(int n) {\n\n        if(n==1) return true;\n        map<int,int> nums;\n\n        while(n>0){\n            int number = 0;\n            # 计算一个数各个位的平方和\n            while(n){\n                number += (n % 10) * (n % 10);\n                n/=10;\n            }\n\n            if(number == 1)\n                return true;\n            else if(nums.find(number)!=nums.end())\n                return false;\n            n = number;\n            nums[n] = 1;\n        }\n    }\n};\n```\n\n另外还有一种简单的算法：\n\n--------\n```\nclass Solution {\npublic:\n    bool isHappy(int n) {\n        while(n>6){  \n            int next = 0;  \n            while(n){\n                next+=(n%10)*(n%10); \n                n/=10;\n            }  \n            n = next;  \n        }  \n        return n==1;  \n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.737Z","updated":"2016-03-23T14:33:02.461Z","path":"leetcode/Leetcode[202]-Happy Number.html","_id":"cimigpyqt00196cujp5p9v8bj"},{"title":"Leetcode[1]-Two Sum","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/two-sum/  \n\nGiven an array of integers, find two numbers such that they add up to a specific target number.\n\nThe function twoSum should return indices of the two numbers such that they add up to the target, where index1 must be less than index2. Please note that your returned answers (both index1 and index2) are not zero-based.\n\nYou may assume that each input would have exactly one solution.\n\nInput: numbers={2, 7, 11, 15}, target=9\nOutput: index1=1, index2=2\n\n------\n分析：\n方法一：使用两个for循环，依次比较，不过这个方法在leetcode上超时了\n\nc++\n\n```\nvector<int> twoSum(vector<int>& nums, int target) {\n    vector<int> index(2);\n    int n = nums.size();\n    for(int i = 0; i < n ; i++) {\n        index[0] = i+1;\n        for(int j = i+1 ; j < n ; j++) {\n            if(nums[i] + nums[j] == target){\n                index[1] = j+1;\n                return index;\n            }\n        }\n    }\n    return index;\n}\n```\n\n法二：使用map存储所有的数组值和下标值，然后循环在map中找看能否找到target-nums[i]的map，如果找到了就终止循环，没找到继续找；最后返回index数组；\n\n```\nclass Solution {\npublic:\n    vector<int> twoSum(vector<int>& nums, int target) {\n        vector<int> index(2);\n        int n = nums.size();\n        map<int,int> mapv;\n        for(int i = 0; i < n ; i++) {\n            mapv[nums[i]] = i;\n        }\n        map<int,int>::iterator it;\n        for(int i = 0; i < n; i++) {\n            it = mapv.find(target - nums[i]);\n            if(it != mapv.end() && i!=it->second){\n                index[0]=min(i+1, it->second + 1);\n                index[1]=max(i+1, it->second + 1);\n                break;\n            }\n        }\n        return index;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[1]-Two Sum.md","raw":"---\ntitle: Leetcode[1]-Two Sum\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/two-sum/  \n\nGiven an array of integers, find two numbers such that they add up to a specific target number.\n\nThe function twoSum should return indices of the two numbers such that they add up to the target, where index1 must be less than index2. Please note that your returned answers (both index1 and index2) are not zero-based.\n\nYou may assume that each input would have exactly one solution.\n\nInput: numbers={2, 7, 11, 15}, target=9\nOutput: index1=1, index2=2\n\n------\n分析：\n方法一：使用两个for循环，依次比较，不过这个方法在leetcode上超时了\n\nc++\n\n```\nvector<int> twoSum(vector<int>& nums, int target) {\n    vector<int> index(2);\n    int n = nums.size();\n    for(int i = 0; i < n ; i++) {\n        index[0] = i+1;\n        for(int j = i+1 ; j < n ; j++) {\n            if(nums[i] + nums[j] == target){\n                index[1] = j+1;\n                return index;\n            }\n        }\n    }\n    return index;\n}\n```\n\n法二：使用map存储所有的数组值和下标值，然后循环在map中找看能否找到target-nums[i]的map，如果找到了就终止循环，没找到继续找；最后返回index数组；\n\n```\nclass Solution {\npublic:\n    vector<int> twoSum(vector<int>& nums, int target) {\n        vector<int> index(2);\n        int n = nums.size();\n        map<int,int> mapv;\n        for(int i = 0; i < n ; i++) {\n            mapv[nums[i]] = i;\n        }\n        map<int,int>::iterator it;\n        for(int i = 0; i < n; i++) {\n            it = mapv.find(target - nums[i]);\n            if(it != mapv.end() && i!=it->second){\n                index[0]=min(i+1, it->second + 1);\n                index[1]=max(i+1, it->second + 1);\n                break;\n            }\n        }\n        return index;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.628Z","updated":"2016-03-23T14:33:02.446Z","path":"leetcode/Leetcode[1]-Two Sum.html","_id":"cimigpyqu001a6cujg27rrt6n"},{"title":"Leetcode[19]-Remove Nth Node From End of List","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/remove-nth-node-from-end-of-list/\n\nGiven a linked list, remove the nth node from the end of list and return its head.\n\nFor example,\n\n\t   Given linked list: 1->2->3->4->5, and n = 2.\n\n\t   After removing the second node from the end, the linked list becomes 1->2->3->5.\nNote:\nGiven n will always be valid.\nTry to do this in one pass.\n\n--------\n\n**思路：**先将链表翻转，然后遍历，找到第n-1个节点，然后删除第n个节点，最后再次翻转链表即可。\n\n**笔记：**在链表翻转后，我采用的是在翻转后的链表的头部放一个无关的节点，然后往后面找，变量从1到n，当变量为n的时候，此时节点还处于n-1节点上，接着我们就让该节点的下个节点指向它的下下个节点，这样第k个节点就删除了。\n\nCode(c++):\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    ListNode* removeNthFromEnd(ListNode* head, int n) {\n    \n        reverseList(head);\n        ListNode *newList = new ListNode(-1);\n        newList->next = head;\n    \n        int count = 1;\n        ListNode *pre = newList;\n    \n        //find the prior element\n\t\t\t//when we get the Nth Node,delete this node from list\n            if(count==n && pre->next!=NULL){\n                pre->next = pre->next->next;\n                break;\n            }else{\n                pre = pre->next;\n                count++;\n            }\n        }\n        head = newList->next;\n        //when head is not null,reverse it\n        if(head!=NULL)\n            reverseList(head);\n        return head;\n    }\n    \n    void reverseList(ListNode* &head){\n        if(head==NULL || head->next == NULL)return;\n        \n        ListNode *newList = new ListNode(-1);\n        ListNode *pre = head;\n        \n        ListNode *temp;\n        while(pre!=NULL){\n            temp = pre->next;\n            pre->next = newList->next;\n            newList->next = pre;\n            pre = temp;\n        }\n        newList = newList->next;\n        head = newList;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[19]-Remove Nth Node From End of List.md","raw":"---\ntitle: Leetcode[19]-Remove Nth Node From End of List\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/remove-nth-node-from-end-of-list/\n\nGiven a linked list, remove the nth node from the end of list and return its head.\n\nFor example,\n\n\t   Given linked list: 1->2->3->4->5, and n = 2.\n\n\t   After removing the second node from the end, the linked list becomes 1->2->3->5.\nNote:\nGiven n will always be valid.\nTry to do this in one pass.\n\n--------\n\n**思路：**先将链表翻转，然后遍历，找到第n-1个节点，然后删除第n个节点，最后再次翻转链表即可。\n\n**笔记：**在链表翻转后，我采用的是在翻转后的链表的头部放一个无关的节点，然后往后面找，变量从1到n，当变量为n的时候，此时节点还处于n-1节点上，接着我们就让该节点的下个节点指向它的下下个节点，这样第k个节点就删除了。\n\nCode(c++):\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    ListNode* removeNthFromEnd(ListNode* head, int n) {\n    \n        reverseList(head);\n        ListNode *newList = new ListNode(-1);\n        newList->next = head;\n    \n        int count = 1;\n        ListNode *pre = newList;\n    \n        //find the prior element\n\t\t\t//when we get the Nth Node,delete this node from list\n            if(count==n && pre->next!=NULL){\n                pre->next = pre->next->next;\n                break;\n            }else{\n                pre = pre->next;\n                count++;\n            }\n        }\n        head = newList->next;\n        //when head is not null,reverse it\n        if(head!=NULL)\n            reverseList(head);\n        return head;\n    }\n    \n    void reverseList(ListNode* &head){\n        if(head==NULL || head->next == NULL)return;\n        \n        ListNode *newList = new ListNode(-1);\n        ListNode *pre = head;\n        \n        ListNode *temp;\n        while(pre!=NULL){\n            temp = pre->next;\n            pre->next = newList->next;\n            newList->next = pre;\n            pre = temp;\n        }\n        newList = newList->next;\n        head = newList;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.645Z","updated":"2016-03-23T14:33:02.445Z","path":"leetcode/Leetcode[19]-Remove Nth Node From End of List.html","_id":"cimigpyqw001b6cuj50w7m7vb"},{"title":"Leetcode[198]-House Robber","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/house-robber/\n\nYou are a professional robber planning to rob houses along a street. Each house has a certain amount of money stashed, the only constraint stopping you from robbing each of them is that adjacent houses have security system connected and it will automatically contact the police if two adjacent houses were broken into on the same night.\n\nGiven a list of non-negative integers representing the amount of money of each house, determine the maximum amount of money you can rob tonight without alerting the police.\n\n-------\n\n题目意思：假如现在你是一个强盗，一个武功超群，足智多谋的江洋大盗，现在你要去一条街上抢劫，这条街全是贪官污吏，一共有N家，每家都有一定数量的金子，如果相邻的两家在同一个晚上都被打劫了，那么就会有一个类似触发器的东西自动调动兵马来街上抓你。\n\n请问，在不触发这个警报器的前提下，你能抢劫到多少money？\n\n\n**动态规划思想解题**\n\n**分析：**，有N家贪官，假设是从左到右，第i家贪官家里的钱数为m[i]，i从0到N-1，根据题意可知，肯定不能在今晚打劫两个相邻的贪官，也就是假如打劫了第i家，就不能打劫第i-1家和i+1家。\n\n设dp[i]表示我从第1家到达第i家能强盗的最大money数；\n\n- 当你打劫第一家的时候，i = 0，可以得到的钱dp[i] = m[0]；\n- 当你到达第二家的时候，i = 1，此时能得到的钱数为max(m[0],m[1]),因为不能同时打劫第一家和第二家；\n- 当到达第i家的时候，i＞＝２，此时能够得到的钱数应该为max{dp[i-1],dp[i-2]+m[i]},即要么是到达上一家时的最大money数，要么是到达上上家时的最大money+这一家的money数，两者中较大的那个；\n\n所以最后我们要得到的就是dp[N-1]，即到达最后一家时的最大money数。\n\n-------\n\nCode(c++):\n\n```\nclass Solution {\npublic:\n    int rob(vector<int>& nums) {\n        int n = nums.size();\n        if(n == 0) return 0;\n        vector<int> dp(n);\n        for(int i = 0; i < n; i++) {\n            if(i == 0) dp[i] = nums[i];\n            else if(i == 1) dp[i] = max(nums[i],nums[i-1]);\n            else{\n                dp[i] = max(dp[i-1], dp[i-2] + nums[i]);\n            }\n        }\n        return  dp[n-1];\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[198]-House Robber.md","raw":"---\ntitle: Leetcode[198]-House Robber\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/house-robber/\n\nYou are a professional robber planning to rob houses along a street. Each house has a certain amount of money stashed, the only constraint stopping you from robbing each of them is that adjacent houses have security system connected and it will automatically contact the police if two adjacent houses were broken into on the same night.\n\nGiven a list of non-negative integers representing the amount of money of each house, determine the maximum amount of money you can rob tonight without alerting the police.\n\n-------\n\n题目意思：假如现在你是一个强盗，一个武功超群，足智多谋的江洋大盗，现在你要去一条街上抢劫，这条街全是贪官污吏，一共有N家，每家都有一定数量的金子，如果相邻的两家在同一个晚上都被打劫了，那么就会有一个类似触发器的东西自动调动兵马来街上抓你。\n\n请问，在不触发这个警报器的前提下，你能抢劫到多少money？\n\n\n**动态规划思想解题**\n\n**分析：**，有N家贪官，假设是从左到右，第i家贪官家里的钱数为m[i]，i从0到N-1，根据题意可知，肯定不能在今晚打劫两个相邻的贪官，也就是假如打劫了第i家，就不能打劫第i-1家和i+1家。\n\n设dp[i]表示我从第1家到达第i家能强盗的最大money数；\n\n- 当你打劫第一家的时候，i = 0，可以得到的钱dp[i] = m[0]；\n- 当你到达第二家的时候，i = 1，此时能得到的钱数为max(m[0],m[1]),因为不能同时打劫第一家和第二家；\n- 当到达第i家的时候，i＞＝２，此时能够得到的钱数应该为max{dp[i-1],dp[i-2]+m[i]},即要么是到达上一家时的最大money数，要么是到达上上家时的最大money+这一家的money数，两者中较大的那个；\n\n所以最后我们要得到的就是dp[N-1]，即到达最后一家时的最大money数。\n\n-------\n\nCode(c++):\n\n```\nclass Solution {\npublic:\n    int rob(vector<int>& nums) {\n        int n = nums.size();\n        if(n == 0) return 0;\n        vector<int> dp(n);\n        for(int i = 0; i < n; i++) {\n            if(i == 0) dp[i] = nums[i];\n            else if(i == 1) dp[i] = max(nums[i],nums[i-1]);\n            else{\n                dp[i] = max(dp[i-1], dp[i-2] + nums[i]);\n            }\n        }\n        return  dp[n-1];\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.736Z","updated":"2016-03-23T14:33:02.435Z","path":"leetcode/Leetcode[198]-House Robber.html","_id":"cimigpyqx001c6cujmky8cb0g"},{"title":"Leetcode[191]-Number of Bits","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/number-of-1-bits/\n\nWrite a function that takes an unsigned integer and returns the number of ’1' bits it has (also known as the Hamming weight).\n\nFor example, the 32-bit integer ’11' has binary representation 00000000000000000000000000001011, so the function should return 3.\n\n---\n\n分析：**在十进制转换为二进制时，如果n%2=1，则在二进制中有1**.根据这条规则，可以循环判断n，每判断一次，n=n/2，代码如下：\n\nC++:\n\n\n```\nclass Solution {\npublic:\n    int hammingWeight(uint32_t n) {\n        int count = 0;\n        while(n>0){\n            if(n%2==1){\n                count++;\n            }\n            n=n/2; \n        }\n        return count;\n    }\n};\n```\n\n\nPython:\n\n```\nclass Solution(object):\n    def hammingWeight(self, n):\n        \"\"\"\n        :type n: int\n        :rtype: int\n        \"\"\"\n        count = 0\n        while n>0:\n            if n%2==1:\n                count=count+1\n            n=n/2\n        return count\n```\n\n\n</article>\n","source":"leetcode/Leetcode[191]-Number of Bits.md","raw":"---\ntitle: Leetcode[191]-Number of Bits\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/number-of-1-bits/\n\nWrite a function that takes an unsigned integer and returns the number of ’1' bits it has (also known as the Hamming weight).\n\nFor example, the 32-bit integer ’11' has binary representation 00000000000000000000000000001011, so the function should return 3.\n\n---\n\n分析：**在十进制转换为二进制时，如果n%2=1，则在二进制中有1**.根据这条规则，可以循环判断n，每判断一次，n=n/2，代码如下：\n\nC++:\n\n\n```\nclass Solution {\npublic:\n    int hammingWeight(uint32_t n) {\n        int count = 0;\n        while(n>0){\n            if(n%2==1){\n                count++;\n            }\n            n=n/2; \n        }\n        return count;\n    }\n};\n```\n\n\nPython:\n\n```\nclass Solution(object):\n    def hammingWeight(self, n):\n        \"\"\"\n        :type n: int\n        :rtype: int\n        \"\"\"\n        count = 0\n        while n>0:\n            if n%2==1:\n                count=count+1\n            n=n/2\n        return count\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.735Z","updated":"2016-03-23T14:33:02.433Z","path":"leetcode/Leetcode[191]-Number of Bits.html","_id":"cimigpyqy001d6cujdxczu5jy"},{"title":"Leetcode[18]-4Sum","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/4sum/\n\nGiven an array S of n integers, are there elements a, b, c, and d in S such that a + b + c + d = target? Find all unique quadruplets in the array which gives the sum of target.\n\nNote:\nElements in a quadruplet (a,b,c,d) must be in non-descending order. (ie, a ≤ b ≤ c ≤ d)\nThe solution set must not contain duplicate quadruplets.\n\n------\n分析：和第15道题有点类似，仅仅是多了一层循环，注意该循环的条件就行.\n\nC++:\n\n\n```\nclass Solution {\npublic:\n    vector<vector<int> > fourSum(vector<int>& nums, int target) {\n        vector<vector<int> > result;    \n        int n = nums.size();        \n        sort(nums.begin(),nums.end());\n        \n        for(int i = 0; i < n; i++) {\n            if(i>0 && nums[i] == nums[i-1]) continue;\n            for(int j = i+1; j < n; j++){\n                if(j > i+1 && nums[j]== nums[j-1]) continue;\n                fourNumber(nums,result,i,j,target);\n            }\n        }\n        return result;\n    }\n    \n    void fourNumber(vector<int> & nums,vector<vector<int> > &results, int curIndex1,int curIndex2,int target){\n        int i = curIndex2 + 1;\n        int j = nums.size()-1;\n        \n        while(i<j) {\n            if(nums[curIndex1] + nums[curIndex2] + nums[i] + nums[j] < target ) i++;\n            else if(nums[curIndex1] + nums[curIndex2] + nums[i] + nums[j] > target ) j--;\n            else {\n                vector<int> vec;\n                vec.push_back(nums[curIndex1]);\n                vec.push_back(nums[curIndex2]);\n                vec.push_back(nums[i]);\n                vec.push_back(nums[j]);\n                results.push_back(vec);\n                i++,j--;\n                while(i < j && nums[i] == nums[i-1])i++;\n                while(j > i && nums[j] == nums[j+1])j--;\n            }\n        }\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[18]-4Sum.md","raw":"---\ntitle: Leetcode[18]-4Sum\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/4sum/\n\nGiven an array S of n integers, are there elements a, b, c, and d in S such that a + b + c + d = target? Find all unique quadruplets in the array which gives the sum of target.\n\nNote:\nElements in a quadruplet (a,b,c,d) must be in non-descending order. (ie, a ≤ b ≤ c ≤ d)\nThe solution set must not contain duplicate quadruplets.\n\n------\n分析：和第15道题有点类似，仅仅是多了一层循环，注意该循环的条件就行.\n\nC++:\n\n\n```\nclass Solution {\npublic:\n    vector<vector<int> > fourSum(vector<int>& nums, int target) {\n        vector<vector<int> > result;    \n        int n = nums.size();        \n        sort(nums.begin(),nums.end());\n        \n        for(int i = 0; i < n; i++) {\n            if(i>0 && nums[i] == nums[i-1]) continue;\n            for(int j = i+1; j < n; j++){\n                if(j > i+1 && nums[j]== nums[j-1]) continue;\n                fourNumber(nums,result,i,j,target);\n            }\n        }\n        return result;\n    }\n    \n    void fourNumber(vector<int> & nums,vector<vector<int> > &results, int curIndex1,int curIndex2,int target){\n        int i = curIndex2 + 1;\n        int j = nums.size()-1;\n        \n        while(i<j) {\n            if(nums[curIndex1] + nums[curIndex2] + nums[i] + nums[j] < target ) i++;\n            else if(nums[curIndex1] + nums[curIndex2] + nums[i] + nums[j] > target ) j--;\n            else {\n                vector<int> vec;\n                vec.push_back(nums[curIndex1]);\n                vec.push_back(nums[curIndex2]);\n                vec.push_back(nums[i]);\n                vec.push_back(nums[j]);\n                results.push_back(vec);\n                i++,j--;\n                while(i < j && nums[i] == nums[i-1])i++;\n                while(j > i && nums[j] == nums[j+1])j--;\n            }\n        }\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.642Z","updated":"2016-03-23T14:33:02.432Z","path":"leetcode/Leetcode[18]-4Sum.html","_id":"cimigpyr0001e6cujv4a3lrsx"},{"title":"Leetcode[189]-Rotate Array","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/rotate-array/\n\nRotate an array of n elements to the right by k steps.\n\nFor example, with n = 7 and k = 3, the array [1,2,3,4,5,6,7] is rotated to [5,6,7,1,2,3,4].\n\nNote:\nTry to come up as many solutions as you can, there are at least 3 different ways to solve this problem.\n\n[show hint]\n\nRelated problem: Reverse Words in a String II\n\nCredits:\nSpecial thanks to @Freezen for adding this problem and creating all test cases.\n\n-------\n分析： (使用三次反转)利用\n\n$$ba=(b^{r})^{r}(a^{r})^{r}=(a^{r}b^{r})^{r}$$\n\n先分别反转a、b，最后再对所有元素进行一次反转。此算法读写内存各约2*n次。\n\n结论：将数组按照k值分成左右两部分，右边k个，左边n-k个，然后先将左右两部分各自翻转，再将整个数组整体翻转，即可得到结果。\n\nCode（c++）：\n\n```\nclass Solution\n{\n\tpublic:\n\t\tvoid swap(int * s1,int * s2)\n\t\t{\n\t\t\tint temp = *s1;\n\t\t\t*s1 = *s2;\n\t\t\t*s2 = temp;\n\t\t}\n\n\t\tvoid rotate(vector<int> & nums,int k)\n\t\t{\n\t\t\tint n = nums.size();\n\t\t\tint left = n - (k % n);\n\t\t\tfor(int i = 0,j = left - 1;i < j;i++,j--)\n\t\t\t\tswap(&nums[i],&nums[j]);\n\t\t\tfor(int i = left,j = n - 1;i < j;i++,j--)\n\t\t\t\tswap(&nums[i],&nums[j]);\n\t\t\tfor(int i = 0,j = n - 1;i < j;i++,j--)\n\t\t\t\tswap(&nums[i],&nums[j]);\n\t\t}\n};\n```\n\n\n\n\n</article>\n","source":"leetcode/Leetcode[189]-Rotate Array.md","raw":"---\ntitle: Leetcode[189]-Rotate Array\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/rotate-array/\n\nRotate an array of n elements to the right by k steps.\n\nFor example, with n = 7 and k = 3, the array [1,2,3,4,5,6,7] is rotated to [5,6,7,1,2,3,4].\n\nNote:\nTry to come up as many solutions as you can, there are at least 3 different ways to solve this problem.\n\n[show hint]\n\nRelated problem: Reverse Words in a String II\n\nCredits:\nSpecial thanks to @Freezen for adding this problem and creating all test cases.\n\n-------\n分析： (使用三次反转)利用\n\n$$ba=(b^{r})^{r}(a^{r})^{r}=(a^{r}b^{r})^{r}$$\n\n先分别反转a、b，最后再对所有元素进行一次反转。此算法读写内存各约2*n次。\n\n结论：将数组按照k值分成左右两部分，右边k个，左边n-k个，然后先将左右两部分各自翻转，再将整个数组整体翻转，即可得到结果。\n\nCode（c++）：\n\n```\nclass Solution\n{\n\tpublic:\n\t\tvoid swap(int * s1,int * s2)\n\t\t{\n\t\t\tint temp = *s1;\n\t\t\t*s1 = *s2;\n\t\t\t*s2 = temp;\n\t\t}\n\n\t\tvoid rotate(vector<int> & nums,int k)\n\t\t{\n\t\t\tint n = nums.size();\n\t\t\tint left = n - (k % n);\n\t\t\tfor(int i = 0,j = left - 1;i < j;i++,j--)\n\t\t\t\tswap(&nums[i],&nums[j]);\n\t\t\tfor(int i = left,j = n - 1;i < j;i++,j--)\n\t\t\t\tswap(&nums[i],&nums[j]);\n\t\t\tfor(int i = 0,j = n - 1;i < j;i++,j--)\n\t\t\t\tswap(&nums[i],&nums[j]);\n\t\t}\n};\n```\n\n\n\n\n</article>\n","date":"2016-03-23T14:33:15.734Z","updated":"2016-03-23T14:33:02.424Z","path":"leetcode/Leetcode[189]-Rotate Array.html","_id":"cimigpyr1001f6cujfa1pdicm"},{"title":"Leetcode[173]-Binary Search Tree Iterator","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/binary-search-tree-iterator/\n\nImplement an iterator over a binary search tree (BST). Your iterator will be initialized with the root node of a BST.\n\nCalling next() will return the next smallest number in the BST.\n\nNote: next() and hasNext() should run in average O(1) time and uses O(h) memory, where h is the height of the tree.\n\n------\n\n**思路：** 遍历一遍，然后从小到大的放到队列里去，然后判断队列是否非空，不非空则前面的就是最小的，出队即可！\n\nC++:\n\n```\n/**\n * Definition for binary tree\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass BSTIterator {\npublic:\n    queue<int> que;\n    BSTIterator(TreeNode *root) {\n        stack<TreeNode *> stk;\n        map<TreeNode *, int> visited;\n        TreeNode *p;\n        if(root) { \n            stk.push(root);\n            visited[root] = 0;\n        }\n        while(!stk.empty()){\n            p = stk.top();\n            while(p->left && visited[p] == 0){\n                if(visited[p->left] == 1) break;\n                p = p->left;\n                stk.push(p);\n                visited[p]=0;\n            }\n            visited[p]=1;\n            que.push(p->val);\n            stk.pop();\n            \n            if(p->right && (visited.find(p->right)==visited.end() || visited[p->right]==0)){\n                stk.push(p->right);\n                visited[p->right] = 0;\n                continue;\n            }\n        }\n        \n        \n        \n\t/* another way     \n\tstack<TreeNode*> stk;\n        while(root || !stk.empty() ) {\n            if(root){\n                stk.push(root);\n                root = root->left;\n            }else {\n                root = stk.top();\n                stk.pop();\n                que.push(root->val);\n                root = root->right;\n            }   \n        } */ \n    }\n\n/** @return whether we have a next smallest number */\n    bool hasNext() {\n        if(!que.empty()) return true;\n        return false;\n    }\n/** @return the next smallest number */\n    int next() {\n        int val = que.front();\n        que.pop();\n        return val;\n    }\n};\n\n/**\n * Your BSTIterator will be called like this:\n * BSTIterator i = BSTIterator(root);\n * while (i.hasNext()) cout << i.next();\n */\n```\n\n\n</article>\n","source":"leetcode/Leetcode[173]-Binary Search Tree Iterator.md","raw":"---\ntitle: Leetcode[173]-Binary Search Tree Iterator\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/binary-search-tree-iterator/\n\nImplement an iterator over a binary search tree (BST). Your iterator will be initialized with the root node of a BST.\n\nCalling next() will return the next smallest number in the BST.\n\nNote: next() and hasNext() should run in average O(1) time and uses O(h) memory, where h is the height of the tree.\n\n------\n\n**思路：** 遍历一遍，然后从小到大的放到队列里去，然后判断队列是否非空，不非空则前面的就是最小的，出队即可！\n\nC++:\n\n```\n/**\n * Definition for binary tree\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass BSTIterator {\npublic:\n    queue<int> que;\n    BSTIterator(TreeNode *root) {\n        stack<TreeNode *> stk;\n        map<TreeNode *, int> visited;\n        TreeNode *p;\n        if(root) { \n            stk.push(root);\n            visited[root] = 0;\n        }\n        while(!stk.empty()){\n            p = stk.top();\n            while(p->left && visited[p] == 0){\n                if(visited[p->left] == 1) break;\n                p = p->left;\n                stk.push(p);\n                visited[p]=0;\n            }\n            visited[p]=1;\n            que.push(p->val);\n            stk.pop();\n            \n            if(p->right && (visited.find(p->right)==visited.end() || visited[p->right]==0)){\n                stk.push(p->right);\n                visited[p->right] = 0;\n                continue;\n            }\n        }\n        \n        \n        \n\t/* another way     \n\tstack<TreeNode*> stk;\n        while(root || !stk.empty() ) {\n            if(root){\n                stk.push(root);\n                root = root->left;\n            }else {\n                root = stk.top();\n                stk.pop();\n                que.push(root->val);\n                root = root->right;\n            }   \n        } */ \n    }\n\n/** @return whether we have a next smallest number */\n    bool hasNext() {\n        if(!que.empty()) return true;\n        return false;\n    }\n/** @return the next smallest number */\n    int next() {\n        int val = que.front();\n        que.pop();\n        return val;\n    }\n};\n\n/**\n * Your BSTIterator will be called like this:\n * BSTIterator i = BSTIterator(root);\n * while (i.hasNext()) cout << i.next();\n */\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.732Z","updated":"2016-03-23T14:33:02.423Z","path":"leetcode/Leetcode[173]-Binary Search Tree Iterator.html","_id":"cimigpyr3001g6cuj8eesvn68"},{"title":"Leetcode[169]-Majority Element","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nGiven an array of size n, find the majority element. The majority element is the element that appears more than ⌊ n/2 ⌋ times.\n\nYou may assume that the array is non-empty and the majority element always exist in the array.\n\nCredits:\nSpecial thanks to @ts for adding this problem and creating all test cases.\n\n-----\n思路一：将数组排好序，中间的那个数一定就是我们需要的majority element。时间复杂度O(nlogn)\n\n思路二：Moore voting algorithm--每找出两个不同的element，就成对删除即count--，最终剩下的一定就是所求的。时间复杂度：O(n)\n\nCode1(C++):\n\n```\nint majorityElement1(vector<int>& nums) {\n    int n = nums.size();\n    sort(nums.begin(),nums.end());\n    return nums[n/2];\n}\n```\n\nCode2(C++)\n\n```\nclass Solution {\npublic:\n    int majorityElement(vector<int>& nums) {\n        int n = nums.size();  \n        int count = 0,number;\n        for(int i=0;i < n; i++){\n            if(count == 0) {\n                number = nums[i];\n                count++;\n            } else {\n                number == nums[i] ? count++: count--;\n            }\n        }\n        return number;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[169]-Majority Element.md","raw":"---\ntitle: Leetcode[169]-Majority Element\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nGiven an array of size n, find the majority element. The majority element is the element that appears more than ⌊ n/2 ⌋ times.\n\nYou may assume that the array is non-empty and the majority element always exist in the array.\n\nCredits:\nSpecial thanks to @ts for adding this problem and creating all test cases.\n\n-----\n思路一：将数组排好序，中间的那个数一定就是我们需要的majority element。时间复杂度O(nlogn)\n\n思路二：Moore voting algorithm--每找出两个不同的element，就成对删除即count--，最终剩下的一定就是所求的。时间复杂度：O(n)\n\nCode1(C++):\n\n```\nint majorityElement1(vector<int>& nums) {\n    int n = nums.size();\n    sort(nums.begin(),nums.end());\n    return nums[n/2];\n}\n```\n\nCode2(C++)\n\n```\nclass Solution {\npublic:\n    int majorityElement(vector<int>& nums) {\n        int n = nums.size();  \n        int count = 0,number;\n        for(int i=0;i < n; i++){\n            if(count == 0) {\n                number = nums[i];\n                count++;\n            } else {\n                number == nums[i] ? count++: count--;\n            }\n        }\n        return number;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.731Z","updated":"2016-03-23T14:33:02.422Z","path":"leetcode/Leetcode[169]-Majority Element.html","_id":"cimigpyr5001h6cujpo588osf"},{"title":"Leetcode[162]-Find Peak Element","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/find-peak-element/\n\nA peak element is an element that is greater than its neighbors.\n\nGiven an input array where num[i] ≠ num[i+1], find a peak element and return its index.\n\nThe array may contain multiple peaks, in that case return the index to any one of the peaks is fine.\n\nYou may imagine that num[-1] = num[n] = -∞.\n\nFor example, in array [1, 2, 3, 1], 3 is a peak element and your function should return the index number 2.\n\nclick to show spoilers.\n\n\n-----\n\n分析：\n\n- 如果只有一个元素，直接返回0；\n- 如果元素个数>=2，判断首尾是否大于它的附近元素，大于则返回下标；\n- 循环遍历，下标从>=1到 < n-1，判断nums[i]是否同时大于它的附近元素，如果大于则返回该下标；\n \n否则，返回-1；\n\n\nCode(c++)\n\n```\nclass Solution {\npublic:\n    int findPeakElement(vector<int>& nums) {\n        int n = nums.size();\n        if(n==1) return 0;\n        if(nums[0] > nums[1]) return 0;\n        if(nums[n-1] > nums[n-2]) return n-1;\n        \n        for(int i=1; i<n-1; i++){\n            if(nums[i]>nums[i-1] && nums[i]>nums[i+1]){\n                return i;\n            }\n        }\n        return -1;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[162]-Find Peak Element.md","raw":"---\ntitle: Leetcode[162]-Find Peak Element\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/find-peak-element/\n\nA peak element is an element that is greater than its neighbors.\n\nGiven an input array where num[i] ≠ num[i+1], find a peak element and return its index.\n\nThe array may contain multiple peaks, in that case return the index to any one of the peaks is fine.\n\nYou may imagine that num[-1] = num[n] = -∞.\n\nFor example, in array [1, 2, 3, 1], 3 is a peak element and your function should return the index number 2.\n\nclick to show spoilers.\n\n\n-----\n\n分析：\n\n- 如果只有一个元素，直接返回0；\n- 如果元素个数>=2，判断首尾是否大于它的附近元素，大于则返回下标；\n- 循环遍历，下标从>=1到 < n-1，判断nums[i]是否同时大于它的附近元素，如果大于则返回该下标；\n \n否则，返回-1；\n\n\nCode(c++)\n\n```\nclass Solution {\npublic:\n    int findPeakElement(vector<int>& nums) {\n        int n = nums.size();\n        if(n==1) return 0;\n        if(nums[0] > nums[1]) return 0;\n        if(nums[n-1] > nums[n-2]) return n-1;\n        \n        for(int i=1; i<n-1; i++){\n            if(nums[i]>nums[i-1] && nums[i]>nums[i+1]){\n                return i;\n            }\n        }\n        return -1;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.729Z","updated":"2016-03-23T14:33:02.421Z","path":"leetcode/Leetcode[162]-Find Peak Element.html","_id":"cimigpyr6001i6cujcszqqa8h"},{"title":"Leetcode[15]-3Sum","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/3sum/\n\nGiven an array S of n integers, are there elements a, b, c in S such that a + b + c = 0? Find all unique triplets in the array which gives the sum of zero.\n\nNote:\nElements in a triplet (a,b,c) must be in non-descending order. (ie, a ≤ b ≤ c)\nThe solution set must not contain duplicate triplets.\n    For example, given array S = {-1 0 1 2 -1 -4},\n\n    A solution set is:\n    (-1, 0, 1)\n    (-1, -1, 2)\n\n----------\n\n分析：根据题意，我们可以要找出三个数相加等于0的这样的一个集合，所以采用二维数组存储。\n\n首先对数组进行从小到大排序，然后抽取一个变量出来，该变量从左往右递归遍历，递归的同时设置两个变量，让其中一个从第一个变量的右边开始，另一个从数组的末端开始，同步的向中间遍历，有点类似于快速排序的判断方式，\n\n- 如果三个数相加小于零，则让第二个变量自加；\n- 如果三个数相加大于零，则让第三个变量自减；\n- 如果三个数相加等于零，则将三个数加入到数组中，然后让第二个变量和第三个变量同步增减，自增自减的过程中要判断是否有重复数字；\n\n依次递归，直到第一个变量条件终止为止。\n\n\n**Code(c++):**\n\n```\nclass Solution {\npublic:\n    vector<vector<int> > threeSum(vector<int> &nums) {\n        vector<vector<int> >  result;\n\n        sort(nums.begin(), nums.end());\n    \n        for(int i = 0; i < nums.size(); i++){\n            if(i > 0 && nums[i] == nums[i-1]) continue;\n            threeNumber(nums, result, i); \n        }\n        return result;\n    }\n    //return vector<vector<int> > results \n    void threeNumber(vector<int> &nums, vector<vector<int> > &results, int curIndex) {\n        int i = curIndex + 1;\n        int j = nums.size()-1;\n    \n        while(i < j){\n            if(nums[curIndex] + nums[i] + nums[j] < 0)   i++;\n            else if(nums[curIndex] + nums[i] + nums[j] > 0)   j--;\n            else{\n                vector<int> v;\n                v.push_back(nums[curIndex]);\n                v.push_back(nums[i]);\n                v.push_back(nums[j]);\n                results.push_back(v);\n                i++; j--;\n                while(i < j && nums[i]==nums[i - 1]) i++;\n                while(j > i && nums[j] == nums[j + 1]) j--;\n            }\n        }\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[15]-3Sum.md","raw":"---\ntitle: Leetcode[15]-3Sum\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/3sum/\n\nGiven an array S of n integers, are there elements a, b, c in S such that a + b + c = 0? Find all unique triplets in the array which gives the sum of zero.\n\nNote:\nElements in a triplet (a,b,c) must be in non-descending order. (ie, a ≤ b ≤ c)\nThe solution set must not contain duplicate triplets.\n    For example, given array S = {-1 0 1 2 -1 -4},\n\n    A solution set is:\n    (-1, 0, 1)\n    (-1, -1, 2)\n\n----------\n\n分析：根据题意，我们可以要找出三个数相加等于0的这样的一个集合，所以采用二维数组存储。\n\n首先对数组进行从小到大排序，然后抽取一个变量出来，该变量从左往右递归遍历，递归的同时设置两个变量，让其中一个从第一个变量的右边开始，另一个从数组的末端开始，同步的向中间遍历，有点类似于快速排序的判断方式，\n\n- 如果三个数相加小于零，则让第二个变量自加；\n- 如果三个数相加大于零，则让第三个变量自减；\n- 如果三个数相加等于零，则将三个数加入到数组中，然后让第二个变量和第三个变量同步增减，自增自减的过程中要判断是否有重复数字；\n\n依次递归，直到第一个变量条件终止为止。\n\n\n**Code(c++):**\n\n```\nclass Solution {\npublic:\n    vector<vector<int> > threeSum(vector<int> &nums) {\n        vector<vector<int> >  result;\n\n        sort(nums.begin(), nums.end());\n    \n        for(int i = 0; i < nums.size(); i++){\n            if(i > 0 && nums[i] == nums[i-1]) continue;\n            threeNumber(nums, result, i); \n        }\n        return result;\n    }\n    //return vector<vector<int> > results \n    void threeNumber(vector<int> &nums, vector<vector<int> > &results, int curIndex) {\n        int i = curIndex + 1;\n        int j = nums.size()-1;\n    \n        while(i < j){\n            if(nums[curIndex] + nums[i] + nums[j] < 0)   i++;\n            else if(nums[curIndex] + nums[i] + nums[j] > 0)   j--;\n            else{\n                vector<int> v;\n                v.push_back(nums[curIndex]);\n                v.push_back(nums[i]);\n                v.push_back(nums[j]);\n                results.push_back(v);\n                i++; j--;\n                while(i < j && nums[i]==nums[i - 1]) i++;\n                while(j > i && nums[j] == nums[j + 1]) j--;\n            }\n        }\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.639Z","updated":"2016-03-23T14:33:02.420Z","path":"leetcode/Leetcode[15]-3Sum.html","_id":"cimigpyr7001j6cujji1fg7mv"},{"title":"Leetcode[154]-Find Minimum in Rotated Sorted Array II","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink：　https://leetcode.com/problems/find-minimum-in-rotated-sorted-array-ii/\n\n\n\tFollow up for \"Find Minimum in Rotated Sorted Array\":\n\tWhat if duplicates are allowed?\n\n\tWould this affect the run-time complexity? How and why?\nSuppose a sorted array is rotated at some pivot unknown to you beforehand.\n\n(i.e., 0 1 2 4 5 6 7 might become 4 5 6 7 0 1 2).\n\nFind the minimum element.\n\nThe array may contain duplicates.\n\n------\n\nＣ++：\n\n方法一：直接遍历求解\n\n```\nclass Solution {\npublic:\n    int findMin(vector<int>& nums) {\n        \n        int n = nums.size();\n        int min = nums[0];\n        for(int  i = 1; i < n; i++) {\n            if(nums[i]<min){\n                min = nums[i];\n            }\n        }\n        return min;\n    }\n};\n```\n\n\n\n</article>\n","source":"leetcode/Leetcode[154]-Find Minimum in Rotated Sorted Array II.md","raw":"---\ntitle: Leetcode[154]-Find Minimum in Rotated Sorted Array II\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink：　https://leetcode.com/problems/find-minimum-in-rotated-sorted-array-ii/\n\n\n\tFollow up for \"Find Minimum in Rotated Sorted Array\":\n\tWhat if duplicates are allowed?\n\n\tWould this affect the run-time complexity? How and why?\nSuppose a sorted array is rotated at some pivot unknown to you beforehand.\n\n(i.e., 0 1 2 4 5 6 7 might become 4 5 6 7 0 1 2).\n\nFind the minimum element.\n\nThe array may contain duplicates.\n\n------\n\nＣ++：\n\n方法一：直接遍历求解\n\n```\nclass Solution {\npublic:\n    int findMin(vector<int>& nums) {\n        \n        int n = nums.size();\n        int min = nums[0];\n        for(int  i = 1; i < n; i++) {\n            if(nums[i]<min){\n                min = nums[i];\n            }\n        }\n        return min;\n    }\n};\n```\n\n\n\n</article>\n","date":"2016-03-23T14:33:15.725Z","updated":"2016-03-23T14:33:02.418Z","path":"leetcode/Leetcode[154]-Find Minimum in Rotated Sorted Array II.html","_id":"cimigpyra001k6cuj2uwpugiu"},{"title":"Leetcode[153]-Find Minimum in Rotated Sorted Array","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/find-minimum-in-rotated-sorted-array/\n\nSuppose a sorted array is rotated at some pivot unknown to you beforehand.\n\n(i.e., 0 1 2 4 5 6 7 might become 4 5 6 7 0 1 2).\n\nFind the minimum element.\n\nYou may assume no duplicate exists in the array.\n\n\n-----\n\nC++:\n\n方法一：直接遍历，暴力求解\n\n```\nclass Solution {\npublic:\n    int findMin(vector<int>& nums) {\n        int n = nums.size();\n        int min = nums[0];\n        for(int  i = 1; i < n; i++) {\n            if(nums[i]<min){\n                min = nums[i];\n            }\n        }\n        return min;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[153]-Find Minimum in Rotated Sorted Array.md","raw":"---\ntitle: Leetcode[153]-Find Minimum in Rotated Sorted Array\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/find-minimum-in-rotated-sorted-array/\n\nSuppose a sorted array is rotated at some pivot unknown to you beforehand.\n\n(i.e., 0 1 2 4 5 6 7 might become 4 5 6 7 0 1 2).\n\nFind the minimum element.\n\nYou may assume no duplicate exists in the array.\n\n\n-----\n\nC++:\n\n方法一：直接遍历，暴力求解\n\n```\nclass Solution {\npublic:\n    int findMin(vector<int>& nums) {\n        int n = nums.size();\n        int min = nums[0];\n        for(int  i = 1; i < n; i++) {\n            if(nums[i]<min){\n                min = nums[i];\n            }\n        }\n        return min;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.723Z","updated":"2016-03-23T14:33:02.417Z","path":"leetcode/Leetcode[153]-Find Minimum in Rotated Sorted Array.html","_id":"cimigpyrb001l6cuj8w99ic5s"},{"title":"Leetcode[148]-Sort List","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/sort-list/\n\nSort a linked list in O(n log n) time using constant space complexity.\n\n-------\n\n\n**分析：**题目要求时间复杂度为O(nlogn)，所以一开始想到的就是快速排序，但是快速排序一直AC不了，然后就想到用归并排序，没想到归并排序竟然可以。下面给出详细代码：\n\n归并排序需要做的\n\n- 找到中间点\n- 合并两个排好序的链表\n- 递归实现归并排序\n\n\nCode(c++):\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    //mergeSort\n    ListNode* sortList(ListNode* head) {\n    \n        if(head == NULL || head->next==NULL) return head;\n    \n        ListNode *mid = getMid(head);\n        ListNode *left = head,*right;\n    \n        if(mid){\n            cout<<mid->val<<endl;\n            right = mid->next;\n            mid->next = NULL;\n        }\n    \n        return mergeLinkedList(sortList(left),sortList(right));\n    \n    }\n    //get middle point from ListNode\n    ListNode* getMid(ListNode* head){\n        if(head==NULL || head->next==NULL ) return head;\n    \n        ListNode* first = head,* second = head->next;\n    \n        while(second && second->next){\n            first = first->next;\n            second = second->next->next;\n        }\n        return first;\n    }\n    \n    //merge two sorted Linked List\n    ListNode* mergeLinkedList(ListNode* first,ListNode* second){\n        if(first==NULL) return second;\n        if(second==NULL) return first;\n    \n        ListNode* tail,* front;\n        front = new ListNode(-1);\n        tail = front;\n        while(first && second){\n            if(first->val < second->val){\n                tail->next = first;\n                first = first->next;\n                tail = tail->next;\n            }else{\n                tail->next = second;\n                second = second->next;\n                tail = tail->next;\n            }\n        }\n        if(first){\n            tail->next =first;\n        }\n        if(second){\n            tail->next = second;\n        }\n        front = front->next;\n        return front;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[148]-Sort List.md","raw":"---\ntitle: Leetcode[148]-Sort List\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/sort-list/\n\nSort a linked list in O(n log n) time using constant space complexity.\n\n-------\n\n\n**分析：**题目要求时间复杂度为O(nlogn)，所以一开始想到的就是快速排序，但是快速排序一直AC不了，然后就想到用归并排序，没想到归并排序竟然可以。下面给出详细代码：\n\n归并排序需要做的\n\n- 找到中间点\n- 合并两个排好序的链表\n- 递归实现归并排序\n\n\nCode(c++):\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    //mergeSort\n    ListNode* sortList(ListNode* head) {\n    \n        if(head == NULL || head->next==NULL) return head;\n    \n        ListNode *mid = getMid(head);\n        ListNode *left = head,*right;\n    \n        if(mid){\n            cout<<mid->val<<endl;\n            right = mid->next;\n            mid->next = NULL;\n        }\n    \n        return mergeLinkedList(sortList(left),sortList(right));\n    \n    }\n    //get middle point from ListNode\n    ListNode* getMid(ListNode* head){\n        if(head==NULL || head->next==NULL ) return head;\n    \n        ListNode* first = head,* second = head->next;\n    \n        while(second && second->next){\n            first = first->next;\n            second = second->next->next;\n        }\n        return first;\n    }\n    \n    //merge two sorted Linked List\n    ListNode* mergeLinkedList(ListNode* first,ListNode* second){\n        if(first==NULL) return second;\n        if(second==NULL) return first;\n    \n        ListNode* tail,* front;\n        front = new ListNode(-1);\n        tail = front;\n        while(first && second){\n            if(first->val < second->val){\n                tail->next = first;\n                first = first->next;\n                tail = tail->next;\n            }else{\n                tail->next = second;\n                second = second->next;\n                tail = tail->next;\n            }\n        }\n        if(first){\n            tail->next =first;\n        }\n        if(second){\n            tail->next = second;\n        }\n        front = front->next;\n        return front;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.722Z","updated":"2016-03-23T14:33:02.416Z","path":"leetcode/Leetcode[148]-Sort List.html","_id":"cimigpyrd001m6cujrlphrfa6"},{"title":"Leetcode[147]-Insertion Sort List","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/insertion-sort-list/\n\nSort a linked list using insertion sort.\n\n----\n链表的插入排序\n\n思路：新开辟一个链表空间，用来作为插入排序的目标链。循环遍历原链表，对每个节点，让其从头到尾的在已经排好序的链表中找到插入位置（此处记录的是插入位置的前一个位置），然后将其插入进去即可。\n\n代码Code(c++)：\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    ListNode* insertionSortList(ListNode* head) {\n        \n        if(head == NULL || head->next ==NULL) return head;\n        ListNode *pre = new ListNode(-1);\n    \n        pre->next = head;\n        head = head->next;\n        pre->next->next = NULL;\n        ListNode *temp,*headNext;\n    \n        while(head!=NULL){\n            ListNode *prior = pre;\n            temp = pre->next;\n            while(temp){\n                if(head->val > temp->val){\n                    prior = temp;\n                    temp = temp->next;\n                }\n                else break;\n            }\n            headNext = head->next;\n            head->next = prior->next;\n            prior->next = head;\n            head = headNext;\n        }\n        head= pre->next;\n        return head;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[147]-Insertion Sort List.md","raw":"---\ntitle: Leetcode[147]-Insertion Sort List\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/insertion-sort-list/\n\nSort a linked list using insertion sort.\n\n----\n链表的插入排序\n\n思路：新开辟一个链表空间，用来作为插入排序的目标链。循环遍历原链表，对每个节点，让其从头到尾的在已经排好序的链表中找到插入位置（此处记录的是插入位置的前一个位置），然后将其插入进去即可。\n\n代码Code(c++)：\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    ListNode* insertionSortList(ListNode* head) {\n        \n        if(head == NULL || head->next ==NULL) return head;\n        ListNode *pre = new ListNode(-1);\n    \n        pre->next = head;\n        head = head->next;\n        pre->next->next = NULL;\n        ListNode *temp,*headNext;\n    \n        while(head!=NULL){\n            ListNode *prior = pre;\n            temp = pre->next;\n            while(temp){\n                if(head->val > temp->val){\n                    prior = temp;\n                    temp = temp->next;\n                }\n                else break;\n            }\n            headNext = head->next;\n            head->next = prior->next;\n            prior->next = head;\n            head = headNext;\n        }\n        head= pre->next;\n        return head;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.720Z","updated":"2016-03-23T14:33:02.411Z","path":"leetcode/Leetcode[147]-Insertion Sort List.html","_id":"cimigpyrf001n6cuj7rojc7s9"},{"title":"Leetcode[145]-Binary Tree Postorder Traversal","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/binary-tree-postorder-traversal/\n\nGiven a binary tree, return the postorder traversal of its nodes' values.\n\nFor example:\nGiven binary tree `{1,#,2,3}`,\n\n\t   1\n\t    \\\n\t     2\n\t    /\n\t   3\n\nreturn `[3,2,1]`.\n\nNote: Recursive solution is trivial, could you do it iteratively?\n\n-------\n\n\n方法一：递归遍历\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n\n    vector<int> nums;\n    vector<int> postorderTraversal(TreeNode* root) {\n        postorder(root);\n        return nums;\n    }\n    \n    void postorder(TreeNode * root){\n        if(root==NULL) return;\n        if(root->left) postorder(root->left);\n        if(root->right) postorder(root->right);\n        nums.push_back(root->val);\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[145]-Binary Tree Postorder Traversal.md","raw":"---\ntitle: Leetcode[145]-Binary Tree Postorder Traversal\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/binary-tree-postorder-traversal/\n\nGiven a binary tree, return the postorder traversal of its nodes' values.\n\nFor example:\nGiven binary tree `{1,#,2,3}`,\n\n\t   1\n\t    \\\n\t     2\n\t    /\n\t   3\n\nreturn `[3,2,1]`.\n\nNote: Recursive solution is trivial, could you do it iteratively?\n\n-------\n\n\n方法一：递归遍历\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n\n    vector<int> nums;\n    vector<int> postorderTraversal(TreeNode* root) {\n        postorder(root);\n        return nums;\n    }\n    \n    void postorder(TreeNode * root){\n        if(root==NULL) return;\n        if(root->left) postorder(root->left);\n        if(root->right) postorder(root->right);\n        nums.push_back(root->val);\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.718Z","updated":"2016-03-23T14:33:02.409Z","path":"leetcode/Leetcode[145]-Binary Tree Postorder Traversal.html","_id":"cimigpyrh001o6cujjmbvugly"},{"title":"Leetcode[144]-Binary Tree Preorder Traversal","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/binary-tree-preorder-traversal/\n\nGiven a binary tree, return the preorder traversal of its nodes' values.\n\nFor example:\nGiven binary tree` {1,#,2,3}`,\n\n\t   1\n\t    \\\n\t     2\n\t    /\n\t   3\n\nreturn [1,2,3].\n\n\n\n-----------\n\n\n##  C++递归遍历：\n\n```\n/**C++\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    vector<int> nums;\n    vector<int> preorderTraversal(TreeNode* root) {\n        if(root == NULL) return nums;\n        preOrder(root);\n        return nums;\n    }\n    void preOrder(TreeNode * root){\n        if(root == NULL) return;\n        nums.push_back(root->val);\n        if(root->left)  preOrder(root->left);\n        if(root->right) preOrder(root->right);\n    }   \n};\n```\n\n## C++递归遍历二:\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    vector<int> preorderTraversal(TreeNode* root) {\n        vector<int> ves;\n        preorder(root, ves);\n        return ves;\n    }\n    void preorder(TreeNode* root, vector<int> &nums){\n        if(!root) return;\n        nums.push_back(root->val);\n        preorder(root->left, nums);\n        preorder(root->right, nums);\n    }   \n};\n```\n\n## 非递归遍历C++：\n\n```\nvector<int> preorderTraversal(TreeNode* root) {\n    vector<int > nums;\n    stack<TreeNode* > stk;\n    if(root == NULL) return nums;\n    TreeNode * p = root;\n    stk.push(p);   \n    while(!stk.empty()){\n        p = stk.top();\n        nums.push_back(p->val);\n        stk.pop();\n        if(p->right) stk.push(p->right);\n        if(p->left) stk.push(p->left);\n    }\n}\n```\n\n\n</article>\n","source":"leetcode/Leetcode[144]-Binary Tree Preorder Traversal.md","raw":"---\ntitle: Leetcode[144]-Binary Tree Preorder Traversal\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/binary-tree-preorder-traversal/\n\nGiven a binary tree, return the preorder traversal of its nodes' values.\n\nFor example:\nGiven binary tree` {1,#,2,3}`,\n\n\t   1\n\t    \\\n\t     2\n\t    /\n\t   3\n\nreturn [1,2,3].\n\n\n\n-----------\n\n\n##  C++递归遍历：\n\n```\n/**C++\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    vector<int> nums;\n    vector<int> preorderTraversal(TreeNode* root) {\n        if(root == NULL) return nums;\n        preOrder(root);\n        return nums;\n    }\n    void preOrder(TreeNode * root){\n        if(root == NULL) return;\n        nums.push_back(root->val);\n        if(root->left)  preOrder(root->left);\n        if(root->right) preOrder(root->right);\n    }   \n};\n```\n\n## C++递归遍历二:\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    vector<int> preorderTraversal(TreeNode* root) {\n        vector<int> ves;\n        preorder(root, ves);\n        return ves;\n    }\n    void preorder(TreeNode* root, vector<int> &nums){\n        if(!root) return;\n        nums.push_back(root->val);\n        preorder(root->left, nums);\n        preorder(root->right, nums);\n    }   \n};\n```\n\n## 非递归遍历C++：\n\n```\nvector<int> preorderTraversal(TreeNode* root) {\n    vector<int > nums;\n    stack<TreeNode* > stk;\n    if(root == NULL) return nums;\n    TreeNode * p = root;\n    stk.push(p);   \n    while(!stk.empty()){\n        p = stk.top();\n        nums.push_back(p->val);\n        stk.pop();\n        if(p->right) stk.push(p->right);\n        if(p->left) stk.push(p->left);\n    }\n}\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.717Z","updated":"2016-03-23T14:33:02.399Z","path":"leetcode/Leetcode[144]-Binary Tree Preorder Traversal.html","_id":"cimigpyrj001p6cujrr9thfak"},{"title":"Leetcode[143]-Reorder List","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/reorder-list/\n\nGiven a singly linked list L: L0→L1→…→Ln-1→Ln,\nreorder it to: L0→Ln→L1→Ln-1→L2→Ln-2→…\n\nYou must do this in-place without altering the nodes' values.\n\nFor example,\nGiven {1,2,3,4}, reorder it to {1,4,2,3}.\n\n-----\n\n思路：将列表分成两半，然后把后一半翻转，最后一个一个构成新链表。\n\nC++:\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n\n    void reorderList(ListNode* head) {\n        \n        if(head==NULL || head->next==NULL) return;\n        \n        ListNode *mid = getMid(head);\n        ListNode *left = head,*right = reverseList(mid->next);\n        \n        mid->next = NULL;\n        \n        ListNode* newHead = new ListNode(-1);\n        ListNode* newTail = newHead;\n        while(left && right){\n            ListNode *temp = left->next;\n            left->next = newTail->next;\n            newTail->next = left;\n            newTail = newTail->next;\n            left = temp;\n    \n            temp = right->next;\n            right->next = newTail->next;\n            newTail->next = right;\n            newTail = newTail->next;\n            right = temp;\n        }\n        if(left) newTail->next = left;\n        if(right) newTail->next = right;\n        newHead = newHead->next;\n        head = newHead;\n    }\n    //reverse list\n    ListNode* reverseList(ListNode* head){\n        if(head==NULL || head->next==NULL) return head;\n        \n        ListNode *pre = head;\n        ListNode *newList = new ListNode(-1);\n        while(pre!=NULL){\n            ListNode* temp = pre->next;\n            pre->next = newList->next;\n            newList->next = pre;\n            pre = temp;\n        }\n        newList = newList->next;\n        return newList;\n    }\n    //get the middle element\n    ListNode* getMid(ListNode* head){\n        if(head==NULL ||head->next ==NULL)return head;\n        \n        ListNode *first=head,*second=head->next;\n        \n        while(second && second->next){\n            first = first->next;\n            second = second->next->next;\n        }\n        return first;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[143]-Reorder List.md","raw":"---\ntitle: Leetcode[143]-Reorder List\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/reorder-list/\n\nGiven a singly linked list L: L0→L1→…→Ln-1→Ln,\nreorder it to: L0→Ln→L1→Ln-1→L2→Ln-2→…\n\nYou must do this in-place without altering the nodes' values.\n\nFor example,\nGiven {1,2,3,4}, reorder it to {1,4,2,3}.\n\n-----\n\n思路：将列表分成两半，然后把后一半翻转，最后一个一个构成新链表。\n\nC++:\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n\n    void reorderList(ListNode* head) {\n        \n        if(head==NULL || head->next==NULL) return;\n        \n        ListNode *mid = getMid(head);\n        ListNode *left = head,*right = reverseList(mid->next);\n        \n        mid->next = NULL;\n        \n        ListNode* newHead = new ListNode(-1);\n        ListNode* newTail = newHead;\n        while(left && right){\n            ListNode *temp = left->next;\n            left->next = newTail->next;\n            newTail->next = left;\n            newTail = newTail->next;\n            left = temp;\n    \n            temp = right->next;\n            right->next = newTail->next;\n            newTail->next = right;\n            newTail = newTail->next;\n            right = temp;\n        }\n        if(left) newTail->next = left;\n        if(right) newTail->next = right;\n        newHead = newHead->next;\n        head = newHead;\n    }\n    //reverse list\n    ListNode* reverseList(ListNode* head){\n        if(head==NULL || head->next==NULL) return head;\n        \n        ListNode *pre = head;\n        ListNode *newList = new ListNode(-1);\n        while(pre!=NULL){\n            ListNode* temp = pre->next;\n            pre->next = newList->next;\n            newList->next = pre;\n            pre = temp;\n        }\n        newList = newList->next;\n        return newList;\n    }\n    //get the middle element\n    ListNode* getMid(ListNode* head){\n        if(head==NULL ||head->next ==NULL)return head;\n        \n        ListNode *first=head,*second=head->next;\n        \n        while(second && second->next){\n            first = first->next;\n            second = second->next->next;\n        }\n        return first;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.716Z","updated":"2016-03-23T14:33:02.393Z","path":"leetcode/Leetcode[143]-Reorder List.html","_id":"cimigpyrl001q6cuji9uf7kp1"},{"title":"Leetcode[141]-Linked List Cycle","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/linked-list-cycle/\n\nGiven a linked list, determine if it has a cycle in it.\n\nFollow up:\nCan you solve it without using extra space?\n\n\n\n\n-------\n\n\n**分析：**设置两个临时指针，一个一次走一步，一个一次走两步，如果再次相遇，表示有环。\n\n\n**Code(c++):**\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    bool hasCycle(ListNode *head) {\n        if(head==NULL || head->next==NULL) return false;\n        \n        ListNode *first = head,*second = head;\n        while(second!=NULL && second->next!=NULL){\n            second = second->next->next;  \n            first = first->next;\n            if(first == second)\n                return true;\n        }\n        return false;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[141]-Linked List Cycle.md","raw":"---\ntitle: Leetcode[141]-Linked List Cycle\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/linked-list-cycle/\n\nGiven a linked list, determine if it has a cycle in it.\n\nFollow up:\nCan you solve it without using extra space?\n\n\n\n\n-------\n\n\n**分析：**设置两个临时指针，一个一次走一步，一个一次走两步，如果再次相遇，表示有环。\n\n\n**Code(c++):**\n\n```\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    bool hasCycle(ListNode *head) {\n        if(head==NULL || head->next==NULL) return false;\n        \n        ListNode *first = head,*second = head;\n        while(second!=NULL && second->next!=NULL){\n            second = second->next->next;  \n            first = first->next;\n            if(first == second)\n                return true;\n        }\n        return false;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.714Z","updated":"2016-03-23T14:33:02.392Z","path":"leetcode/Leetcode[141]-Linked List Cycle.html","_id":"cimigpyrm001r6cujudcpo6oq"},{"title":"Leetcode[13]-Roman to Integer+++","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/roman-to-integer/\n\n\nGiven a roman numeral, convert it to an integer.\n\nInput is guaranteed to be within the range from 1 to 3999.\n\n\n---\n\n分析：\n\n从前往后扫描，用一个临时变量记录分段数字。\n\n如果当前处理的字符对应的值和上一个字符一样，那么临时变量加上这个字符。比如III = 3\n如果当前比前一个大，说明这一段的值应该是当前这个值减去前面记录下的临时变量中的值。比如IIV = 5 – 2\n如果当前比前一个小，那么就可以先将临时变量的值加到结果中，然后开始下一段记录。比如VI = 5 + 1\n\n\nC++:\n\n```\nclass Solution {\npublic:\n    int romanToInt(string s) {\n        int num[256] = { 0 };\n        num['I'] = 1; num['V'] = 5; num['X'] = 10; num['L']=50;\n        num['C'] = 100; num['D'] = 500; num['M'] = 1000;\n        int result = 0;\n        int i = 0;\n        while (i < s.size()){\n            if (num[s[i]] < num[s[i+1]])\n                result -= num[s[i]];\n            else\n                result += num[s[i]];\n            i++;\n        }\n        return result;\n    }\n};\n```\n\n\n\n\n\n\nPython：\n\n```\nclass Solution(object):\n    def romanToInt(self, s):\n        \"\"\"\n        :type s: str\n        :rtype: int\n        \"\"\"\n        Num = {\"I\":1, \"V\":5, \"X\":10, \"L\":50, \"C\":100, \"D\":500, \"M\":1000}\n        L = len(s)\n        sum = 0\n        i = 0\n    \n        while(i < L - 1):\n    \n            if(Num.get(s[i]) < Num.get(s[i + 1])):\n                sum -= Num.get(s[i])\n            else:\n                sum += Num.get(s[i])\n            i += 1\n        sum += Num.get(s[i])\n        return sum\n```\n\n\n</article>\n","source":"leetcode/Leetcode[13]-Roman to Integer+++.md","raw":"---\ntitle: Leetcode[13]-Roman to Integer+++\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/roman-to-integer/\n\n\nGiven a roman numeral, convert it to an integer.\n\nInput is guaranteed to be within the range from 1 to 3999.\n\n\n---\n\n分析：\n\n从前往后扫描，用一个临时变量记录分段数字。\n\n如果当前处理的字符对应的值和上一个字符一样，那么临时变量加上这个字符。比如III = 3\n如果当前比前一个大，说明这一段的值应该是当前这个值减去前面记录下的临时变量中的值。比如IIV = 5 – 2\n如果当前比前一个小，那么就可以先将临时变量的值加到结果中，然后开始下一段记录。比如VI = 5 + 1\n\n\nC++:\n\n```\nclass Solution {\npublic:\n    int romanToInt(string s) {\n        int num[256] = { 0 };\n        num['I'] = 1; num['V'] = 5; num['X'] = 10; num['L']=50;\n        num['C'] = 100; num['D'] = 500; num['M'] = 1000;\n        int result = 0;\n        int i = 0;\n        while (i < s.size()){\n            if (num[s[i]] < num[s[i+1]])\n                result -= num[s[i]];\n            else\n                result += num[s[i]];\n            i++;\n        }\n        return result;\n    }\n};\n```\n\n\n\n\n\n\nPython：\n\n```\nclass Solution(object):\n    def romanToInt(self, s):\n        \"\"\"\n        :type s: str\n        :rtype: int\n        \"\"\"\n        Num = {\"I\":1, \"V\":5, \"X\":10, \"L\":50, \"C\":100, \"D\":500, \"M\":1000}\n        L = len(s)\n        sum = 0\n        i = 0\n    \n        while(i < L - 1):\n    \n            if(Num.get(s[i]) < Num.get(s[i + 1])):\n                sum -= Num.get(s[i])\n            else:\n                sum += Num.get(s[i])\n            i += 1\n        sum += Num.get(s[i])\n        return sum\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.637Z","updated":"2016-03-23T14:33:02.380Z","path":"leetcode/Leetcode[13]-Roman to Integer+++.html","_id":"cimigpyro001s6cujai5y4w2n"},{"title":"Leetcode[137]-Single Number II","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/single-number-ii/\n\nGiven an array of integers, every element appears three times except for one. Find that single one.\n\nNote:\n\nYour algorithm should have a linear runtime complexity. Could you implement it without using extra memory?\n\n---\n\n思路：先排序，然后一对一对的进行比较.\n\nC++\n\n```\nclass Solution {\npublic:\n    int singleNumber(vector<int>& nums) {\n        int n = nums.size();\n        if(n==1) return nums[0];\n        sort(nums.begin(),nums.end());\n        int i = 0;\n        while(i<n-2){\n            if(nums[i]!=nums[i+1]){\n                return nums[i];\n            }else{\n                i = i + 3;\n            }\n        }\n        return nums[n-1];\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[137]-Single Number II.md","raw":"---\ntitle: Leetcode[137]-Single Number II\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/single-number-ii/\n\nGiven an array of integers, every element appears three times except for one. Find that single one.\n\nNote:\n\nYour algorithm should have a linear runtime complexity. Could you implement it without using extra memory?\n\n---\n\n思路：先排序，然后一对一对的进行比较.\n\nC++\n\n```\nclass Solution {\npublic:\n    int singleNumber(vector<int>& nums) {\n        int n = nums.size();\n        if(n==1) return nums[0];\n        sort(nums.begin(),nums.end());\n        int i = 0;\n        while(i<n-2){\n            if(nums[i]!=nums[i+1]){\n                return nums[i];\n            }else{\n                i = i + 3;\n            }\n        }\n        return nums[n-1];\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.713Z","updated":"2016-03-23T14:33:02.364Z","path":"leetcode/Leetcode[137]-Single Number II.html","_id":"cimigpyrq001t6cujg7d4299p"},{"title":"Leetcode[136]-Single Number","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLind:https://leetcode.com/problems/single-number/\n\nGiven an array of integers, every element appears twice except for one. Find that single one.\n\nNote:\nYour algorithm should have a linear runtime complexity. Could you implement it without using extra memory?\n\n-----\n\n分析：首先对数组进行排序，然后从开始进行两两比较，如果两个相等，则以步长为2往后比较，如果不相等，则返回第一个值。代码如下：\n\nCode(c++)\n\n```\nclass Solution {\npublic:\n    int singleNumber(vector<int>& nums) {\n        int n = nums.size();\n        \n        sort(nums.begin(),nums.end());\n        if(n==1) return nums[0];\n        int i = 0;\n        while(i<n) {\n            if(nums[i] == nums[i+1])\n                i = i+2;\n            else\n                return nums[i];\n        }\n        return 0;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[136]-Single Number.md","raw":"---\ntitle: Leetcode[136]-Single Number\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLind:https://leetcode.com/problems/single-number/\n\nGiven an array of integers, every element appears twice except for one. Find that single one.\n\nNote:\nYour algorithm should have a linear runtime complexity. Could you implement it without using extra memory?\n\n-----\n\n分析：首先对数组进行排序，然后从开始进行两两比较，如果两个相等，则以步长为2往后比较，如果不相等，则返回第一个值。代码如下：\n\nCode(c++)\n\n```\nclass Solution {\npublic:\n    int singleNumber(vector<int>& nums) {\n        int n = nums.size();\n        \n        sort(nums.begin(),nums.end());\n        if(n==1) return nums[0];\n        int i = 0;\n        while(i<n) {\n            if(nums[i] == nums[i+1])\n                i = i+2;\n            else\n                return nums[i];\n        }\n        return 0;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.712Z","updated":"2016-03-23T14:33:02.357Z","path":"leetcode/Leetcode[136]-Single Number.html","_id":"cimigpyru001u6cujt9a5qemh"},{"title":"Leetcode[12]-Integer to Roman+++","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/integer-to-roman/\n\n\nGiven an integer, convert it to a roman numeral.\n\nInput is guaranteed to be within the range from 1 to 3999.\n\n\n---\n\n分析：\n\n\nC++:\n\n```\nclass Solution {\npublic:\n    string intToRoman(int num) {\n        int s[7]={0};\n        int Roman[7]={1000,500,100,50,10,5,1};\n        char ch[7]={'M','D','C','L','X','V','I'};\n        int index=0;\n        string result;\n        while(index<7) {\n            s[index]=num/Roman[index];\n            num%=Roman[index++];\n        }\n        for(int i=0;i<7;i++){\n            if (s[i]==1&&i+1<7&&s[i+1]==4)\n                continue;\n            if(s[i]==4){\n                if (s[i-1]==1)\n                    result=result+ch[i]+ch[i-2];\n                else\n                    result=result+ch[i]+ch[i-1];\n            }else{\n                for(int j=0;j<s[i];j++)\n                    result+=ch[i];\n            }\n        }\n        return result;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[12]-Integer to Roman+++.md","raw":"---\ntitle: Leetcode[12]-Integer to Roman+++\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/integer-to-roman/\n\n\nGiven an integer, convert it to a roman numeral.\n\nInput is guaranteed to be within the range from 1 to 3999.\n\n\n---\n\n分析：\n\n\nC++:\n\n```\nclass Solution {\npublic:\n    string intToRoman(int num) {\n        int s[7]={0};\n        int Roman[7]={1000,500,100,50,10,5,1};\n        char ch[7]={'M','D','C','L','X','V','I'};\n        int index=0;\n        string result;\n        while(index<7) {\n            s[index]=num/Roman[index];\n            num%=Roman[index++];\n        }\n        for(int i=0;i<7;i++){\n            if (s[i]==1&&i+1<7&&s[i+1]==4)\n                continue;\n            if(s[i]==4){\n                if (s[i-1]==1)\n                    result=result+ch[i]+ch[i-2];\n                else\n                    result=result+ch[i]+ch[i-1];\n            }else{\n                for(int j=0;j<s[i];j++)\n                    result+=ch[i];\n            }\n        }\n        return result;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.635Z","updated":"2016-03-23T14:33:02.342Z","path":"leetcode/Leetcode[12]-Integer to Roman+++.html","_id":"cimigpyrx001v6cujkg58f7h8"},{"title":"Leetcode[129]-Sum Root to Leaf Numbers","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/sum-root-to-leaf-numbers/\n\nGiven a binary tree containing digits from 0-9 only, each root-to-leaf path could represent a number.\n\nAn example is the root-to-leaf path 1->2->3 which represents the number 123.\n\nFind the total sum of all root-to-leaf numbers.\n\nFor example,\n\n```\n    1\n   / \\\n  2   3\n```\n\nThe root-to-leaf path 1->2 represents the number 12.\nThe root-to-leaf path 1->3 represents the number 13.\n\nReturn the sum = 12 + 13 = 25.\n\n--------\n\n这道题让我真的醉了，先说下思路吧。\n\n先求出每个叶子节点的值，然后将这些值相加。求叶子节点的值可以通过深度优先遍历，一遍往下，一遍增加各个节点的值，如果是叶子节点就将数组值的和加入到一个只有叶子节点的数组中，最后求这个只有叶子节点的数组的值得和。从头到尾自己写的代码，可以AC了，还没有进行优化，先做到这里吧。\n\n代码（C++）：\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n\t//return sum of newleafValue\n    int sumNumbers(TreeNode* root) {\n        if(root == NULL) return 0;\n        if(!root->left && !root->right) return root->val;\n    \n        vector<int> nums = saveLeafNums(root);\n        return sumV(nums);\n    }\n    //save leftnode to vector\n    vector<int> saveLeafNums(TreeNode * root){\n    \n        vector<int> nums,nodeValue;\n        int eachSum = 0;\n        stack<TreeNode *> stk;\n        map<TreeNode *, int> visited;\n    \n        TreeNode *p = root;\n    \n        stk.push(p);\n        visited[p] = 0;\n        nodeValue.push_back(p->val);\n    \n        while(!stk.empty()){\n            while(p->left && visited[p]==0 ){\n\t            //if this node is visited,break \n                if(visited[p->left]==1) break;\n                p = p->left;\n                stk.push(p);\n                visited[p] = 0;\n                tenMutilVector(nodeValue);//enlarge vector element's value\n                nodeValue.push_back(p->val);\n            }\n            if(!stk.empty()) {\n                p = stk.top();\n                if(!p->left && !p->right){\n                    nums.push_back(sumV(nodeValue));\n                }\n                if(p->right && (visited.find(p->right)==visited.end() || visited[p->right]==0)){\n                    p = p->right;\n                    stk.push(p);\n                    visited[p] = 0;\n                    tenMutilVector(nodeValue);\n                    nodeValue.push_back(p->val);\n                    continue;\n                }\n                visited[p] = 1;\n                stk.pop();\n                tenDivideVector(nodeValue);\n                nodeValue.resize(nodeValue.size()-1);\n            }\n        }\n        return nums;\n    }\n    \n    void tenMutilVector(vector<int> &nums) {\n        int n = nums.size();\n        for(int i = 0; i < n; i++){\n            nums[i] *= 10;\n        }\n    }\n    \n    void tenDivideVector(vector<int> &nums) {\n        int n = nums.size();\n        for(int i = 0; i < n; i++){\n            nums[i] /= 10;\n        }\n    }\n    \n    int sumV(vector<int> &nums){\n        int n = nums.size();\n        int sumValue = 0;\n        for(int i = 0; i < n; i++){\n            sumValue += nums[i];\n        }\n        return sumValue;\n    }   \n};\n```\n\n\n附加一个求深度的代码：\n\n```C++\n    int getDepth(TreeNode* root) {\n        if(root == NULL) return 0;\n    \n        int ldepth = 0,rdepth = 0;\n    \n        ldepth = getDepth(root->left);\n        rdepth = getDepth(root->right);\n    \n        return ldepth>rdepth?ldepth+1:rdepth+1;\n    }\n```\n\n\n方法二：（递归法）\n\n```\nclass Solution {\npublic:\n    int sumNumbers(TreeNode* root) {\n        sum = 0;\n        sumStep(root, 0);\n        return sum;\n    }\nprivate:\n    int sum;\n    void sumStep(TreeNode *root, int num){\n        if(!root) return;\n        if(!root->left && !root->right) {\n            sum = sum + num*10 + root->val;\n        }else{\n            sumStep(root->left, num*10 + root->val);\n            sumStep(root->right, num*10 + root->val);\n        }\n        \n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[129]-Sum Root to Leaf Numbers.md","raw":"---\ntitle: Leetcode[129]-Sum Root to Leaf Numbers\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/sum-root-to-leaf-numbers/\n\nGiven a binary tree containing digits from 0-9 only, each root-to-leaf path could represent a number.\n\nAn example is the root-to-leaf path 1->2->3 which represents the number 123.\n\nFind the total sum of all root-to-leaf numbers.\n\nFor example,\n\n```\n    1\n   / \\\n  2   3\n```\n\nThe root-to-leaf path 1->2 represents the number 12.\nThe root-to-leaf path 1->3 represents the number 13.\n\nReturn the sum = 12 + 13 = 25.\n\n--------\n\n这道题让我真的醉了，先说下思路吧。\n\n先求出每个叶子节点的值，然后将这些值相加。求叶子节点的值可以通过深度优先遍历，一遍往下，一遍增加各个节点的值，如果是叶子节点就将数组值的和加入到一个只有叶子节点的数组中，最后求这个只有叶子节点的数组的值得和。从头到尾自己写的代码，可以AC了，还没有进行优化，先做到这里吧。\n\n代码（C++）：\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n\t//return sum of newleafValue\n    int sumNumbers(TreeNode* root) {\n        if(root == NULL) return 0;\n        if(!root->left && !root->right) return root->val;\n    \n        vector<int> nums = saveLeafNums(root);\n        return sumV(nums);\n    }\n    //save leftnode to vector\n    vector<int> saveLeafNums(TreeNode * root){\n    \n        vector<int> nums,nodeValue;\n        int eachSum = 0;\n        stack<TreeNode *> stk;\n        map<TreeNode *, int> visited;\n    \n        TreeNode *p = root;\n    \n        stk.push(p);\n        visited[p] = 0;\n        nodeValue.push_back(p->val);\n    \n        while(!stk.empty()){\n            while(p->left && visited[p]==0 ){\n\t            //if this node is visited,break \n                if(visited[p->left]==1) break;\n                p = p->left;\n                stk.push(p);\n                visited[p] = 0;\n                tenMutilVector(nodeValue);//enlarge vector element's value\n                nodeValue.push_back(p->val);\n            }\n            if(!stk.empty()) {\n                p = stk.top();\n                if(!p->left && !p->right){\n                    nums.push_back(sumV(nodeValue));\n                }\n                if(p->right && (visited.find(p->right)==visited.end() || visited[p->right]==0)){\n                    p = p->right;\n                    stk.push(p);\n                    visited[p] = 0;\n                    tenMutilVector(nodeValue);\n                    nodeValue.push_back(p->val);\n                    continue;\n                }\n                visited[p] = 1;\n                stk.pop();\n                tenDivideVector(nodeValue);\n                nodeValue.resize(nodeValue.size()-1);\n            }\n        }\n        return nums;\n    }\n    \n    void tenMutilVector(vector<int> &nums) {\n        int n = nums.size();\n        for(int i = 0; i < n; i++){\n            nums[i] *= 10;\n        }\n    }\n    \n    void tenDivideVector(vector<int> &nums) {\n        int n = nums.size();\n        for(int i = 0; i < n; i++){\n            nums[i] /= 10;\n        }\n    }\n    \n    int sumV(vector<int> &nums){\n        int n = nums.size();\n        int sumValue = 0;\n        for(int i = 0; i < n; i++){\n            sumValue += nums[i];\n        }\n        return sumValue;\n    }   \n};\n```\n\n\n附加一个求深度的代码：\n\n```C++\n    int getDepth(TreeNode* root) {\n        if(root == NULL) return 0;\n    \n        int ldepth = 0,rdepth = 0;\n    \n        ldepth = getDepth(root->left);\n        rdepth = getDepth(root->right);\n    \n        return ldepth>rdepth?ldepth+1:rdepth+1;\n    }\n```\n\n\n方法二：（递归法）\n\n```\nclass Solution {\npublic:\n    int sumNumbers(TreeNode* root) {\n        sum = 0;\n        sumStep(root, 0);\n        return sum;\n    }\nprivate:\n    int sum;\n    void sumStep(TreeNode *root, int num){\n        if(!root) return;\n        if(!root->left && !root->right) {\n            sum = sum + num*10 + root->val;\n        }else{\n            sumStep(root->left, num*10 + root->val);\n            sumStep(root->right, num*10 + root->val);\n        }\n        \n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.711Z","updated":"2016-03-23T14:33:02.337Z","path":"leetcode/Leetcode[129]-Sum Root to Leaf Numbers.html","_id":"cimigpyrz001w6cuj48t8l893"},{"title":"Leetcode[128]-Longest Consecutive Sequence","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/longest-consecutive-sequence/\n\nGiven an unsorted array of integers, find the length of the longest consecutive elements sequence.\n\nFor example,\nGiven [100, 4, 200, 1, 3, 2],\nThe longest consecutive elements sequence is [1, 2, 3, 4]. Return its length: 4.\n\nYour algorithm should run in O(n) complexity.\n\n---\n\n思路：跟最大连续子序列和的思路类似，采用DP思想。设置一个长度为n的数组dp[n]，dp[i]表示在下标为i的时候，当前最大连续序列的长度为dp[i]，最后找到dp[i]中最大的那个值即可。\n\nC++:\n\n```\nclass Solution {\npublic:\n    int longestConsecutive(vector<int>& nums) {\n        int n=nums.size();\n        sort(nums.begin(),nums.end());\n        vector<int> dp(n);\n        dp[0]=1;\n        for(int i=1; i<n; i++){\n            if(nums[i]==(nums[i-1]+1))dp[i]=dp[i-1]+1;\n            else if (nums[i] == nums[i-1]){\n                dp[i] = dp[i-1];\n            }else{\n                dp[i]=1;\n            }\n        }\n        int maxl=0;\n        for(int j=0; j<n;j++){\n            maxl = max(maxl,dp[j]);\n        }\n        return maxl;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[128]-Longest Consecutive Sequence.md","raw":"---\ntitle: Leetcode[128]-Longest Consecutive Sequence\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink:https://leetcode.com/problems/longest-consecutive-sequence/\n\nGiven an unsorted array of integers, find the length of the longest consecutive elements sequence.\n\nFor example,\nGiven [100, 4, 200, 1, 3, 2],\nThe longest consecutive elements sequence is [1, 2, 3, 4]. Return its length: 4.\n\nYour algorithm should run in O(n) complexity.\n\n---\n\n思路：跟最大连续子序列和的思路类似，采用DP思想。设置一个长度为n的数组dp[n]，dp[i]表示在下标为i的时候，当前最大连续序列的长度为dp[i]，最后找到dp[i]中最大的那个值即可。\n\nC++:\n\n```\nclass Solution {\npublic:\n    int longestConsecutive(vector<int>& nums) {\n        int n=nums.size();\n        sort(nums.begin(),nums.end());\n        vector<int> dp(n);\n        dp[0]=1;\n        for(int i=1; i<n; i++){\n            if(nums[i]==(nums[i-1]+1))dp[i]=dp[i-1]+1;\n            else if (nums[i] == nums[i-1]){\n                dp[i] = dp[i-1];\n            }else{\n                dp[i]=1;\n            }\n        }\n        int maxl=0;\n        for(int j=0; j<n;j++){\n            maxl = max(maxl,dp[j]);\n        }\n        return maxl;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.709Z","updated":"2016-03-23T14:33:02.330Z","path":"leetcode/Leetcode[128]-Longest Consecutive Sequence.html","_id":"cimigpys1001x6cujgjho3wb8"},{"title":"Leetcode[125]-Valid Palindrome","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/valid-palindrome/\n\nGiven a string, determine if it is a palindrome, considering only alphanumeric characters and ignoring cases.\n\n```\nFor example,\n\"A man, a plan, a canal: Panama\" is a palindrome.\n\"race a car\" is not a palindrome.\n```\n\nNote:\nHave you consider that the string might be empty? This is a good question to ask during an interview.\n\nFor the purpose of this problem, we define empty string as valid palindrome.\n\n\n-----\n\n 思路：定义两个标示符，一个指向字符串前面，一个指向字符串末尾，如果前后位置的字符不是字母或是数字，则直接跳过该字符，如果是大写，则转换成小写再比较，如果碰到不匹配的直接返回false。\n\n\nCode(C++):\n\n```\nclass Solution {\npublic:\n\n    bool isPalindrome(string s) {\n        \n        int length = s.length();\n        \n        if(length == 0){  \n            return true;  \n        }  \n        int i = 0, j = length-1;\n        \n        while(i <= j){\n            if(!isStr(s[i])) i++;\n            else if(!isStr(s[j])) j--;\n            else if(s[i++] != s[j--]) return false;\n        }\n        return true;\n    }\n    \n    \n    bool isStr(char &a){\n        if(a >= '0' && a <= '9' ) {\n            return true;\n        }else if(a >= 'a' && a <= 'z' ) {\n            a -= 32;\n            return true;\n        } else if(a >= 'A' && a <= 'Z' ) {\n            return true;\n        } \n        return false;\n    }\n   \n};\n\n```\n\n\n</article>\n","source":"leetcode/Leetcode[125]-Valid Palindrome.md","raw":"---\ntitle: Leetcode[125]-Valid Palindrome\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/valid-palindrome/\n\nGiven a string, determine if it is a palindrome, considering only alphanumeric characters and ignoring cases.\n\n```\nFor example,\n\"A man, a plan, a canal: Panama\" is a palindrome.\n\"race a car\" is not a palindrome.\n```\n\nNote:\nHave you consider that the string might be empty? This is a good question to ask during an interview.\n\nFor the purpose of this problem, we define empty string as valid palindrome.\n\n\n-----\n\n 思路：定义两个标示符，一个指向字符串前面，一个指向字符串末尾，如果前后位置的字符不是字母或是数字，则直接跳过该字符，如果是大写，则转换成小写再比较，如果碰到不匹配的直接返回false。\n\n\nCode(C++):\n\n```\nclass Solution {\npublic:\n\n    bool isPalindrome(string s) {\n        \n        int length = s.length();\n        \n        if(length == 0){  \n            return true;  \n        }  \n        int i = 0, j = length-1;\n        \n        while(i <= j){\n            if(!isStr(s[i])) i++;\n            else if(!isStr(s[j])) j--;\n            else if(s[i++] != s[j--]) return false;\n        }\n        return true;\n    }\n    \n    \n    bool isStr(char &a){\n        if(a >= '0' && a <= '9' ) {\n            return true;\n        }else if(a >= 'a' && a <= 'z' ) {\n            a -= 32;\n            return true;\n        } else if(a >= 'A' && a <= 'Z' ) {\n            return true;\n        } \n        return false;\n    }\n   \n};\n\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.707Z","updated":"2016-03-23T14:33:02.318Z","path":"leetcode/Leetcode[125]-Valid Palindrome.html","_id":"cimigpys3001y6cujdsu1x6p2"},{"title":"Leetcode[119]-Pascal's Triangle II","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/pascals-triangle-ii/\n\nGiven an index k, return the kth row of the Pascal's triangle.\n\nFor example, given k = 3,\nReturn [1,3,3,1].\n\n\nNote:\nCould you optimize your algorithm to use only O(k) extra space?\n\n-------\n\n分析：通过递归设置vector的值，变量i表示当前行数，同时根据行数可以得到当前的vector元素个数。如果我们从前往后遍历，当i增加的时候，我们的num[j] = num[j] + num[j-1]就会出问题，因为num[j+1]=num[j+1]+num[j],而num[j]已经更新了。\n\n所以这里采用的是从后往前遍历，num[j] = num[j] + num[j-1],这样num[j-1] = num[j-1] + num[j-2]，不会受到前面的num[j]的变化而变化。\n\n```\nclass Solution {\npublic:\n    vector<int> getRow(int rowIndex) {\n        vector<int> nums(rowIndex+1);\n        for(int i = 0; i <= rowIndex; i++){\n            nums[i] =1;\n            for(int j = i-1; j >= 1; j--){\n                nums[j] = nums[j] + nums[j-1];\n            }\n        }\n        return nums;\n    }\n};\n```\n\n**Python代码**\n\n```\nclass Solution(object):\n    def getRow(self, rowIndex):\n        \"\"\"\n        :type rowIndex: int\n        :rtype: List[int]\n        \"\"\"\n        if rowIndex < 0: return None\n        nums = []\n        for i in range(rowIndex+1):\n            a = []\n            for j in range(i+1):\n                if j==0:\n                    a.append(1)\n                else:\n                    if j < i:\n                        a.append(nums[i-1][j-1]+nums[i-1][j])\n                    else:\n                        a.append(1)\n            nums.append(a)\n        return nums[-1]\n```\n\n\n</article>\n","source":"leetcode/Leetcode[119]-Pascal's Triangle II.md","raw":"---\ntitle: Leetcode[119]-Pascal's Triangle II\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/pascals-triangle-ii/\n\nGiven an index k, return the kth row of the Pascal's triangle.\n\nFor example, given k = 3,\nReturn [1,3,3,1].\n\n\nNote:\nCould you optimize your algorithm to use only O(k) extra space?\n\n-------\n\n分析：通过递归设置vector的值，变量i表示当前行数，同时根据行数可以得到当前的vector元素个数。如果我们从前往后遍历，当i增加的时候，我们的num[j] = num[j] + num[j-1]就会出问题，因为num[j+1]=num[j+1]+num[j],而num[j]已经更新了。\n\n所以这里采用的是从后往前遍历，num[j] = num[j] + num[j-1],这样num[j-1] = num[j-1] + num[j-2]，不会受到前面的num[j]的变化而变化。\n\n```\nclass Solution {\npublic:\n    vector<int> getRow(int rowIndex) {\n        vector<int> nums(rowIndex+1);\n        for(int i = 0; i <= rowIndex; i++){\n            nums[i] =1;\n            for(int j = i-1; j >= 1; j--){\n                nums[j] = nums[j] + nums[j-1];\n            }\n        }\n        return nums;\n    }\n};\n```\n\n**Python代码**\n\n```\nclass Solution(object):\n    def getRow(self, rowIndex):\n        \"\"\"\n        :type rowIndex: int\n        :rtype: List[int]\n        \"\"\"\n        if rowIndex < 0: return None\n        nums = []\n        for i in range(rowIndex+1):\n            a = []\n            for j in range(i+1):\n                if j==0:\n                    a.append(1)\n                else:\n                    if j < i:\n                        a.append(nums[i-1][j-1]+nums[i-1][j])\n                    else:\n                        a.append(1)\n            nums.append(a)\n        return nums[-1]\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.702Z","updated":"2016-03-23T14:33:02.313Z","path":"leetcode/Leetcode[119]-Pascal's Triangle II.html","_id":"cimigpys5001z6cujox7g7sg2"},{"title":"Leetcode[118]-Pascal's Triangle","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/pascals-triangle/\n\nGiven numRows, generate the first numRows of Pascal's triangle.\n\nFor example, given numRows = 5,\nReturn\n\n```\n[\n     [1],\n    [1,1],\n   [1,2,1],\n  [1,3,3,1],\n [1,4,6,4,1]\n]\n```\n---------\n分析：\n\n- 第j=0列全为1，第j==i列时，都为1\n- 其它列\n\t- a[2][1] = a[1][0]+a[1][1]\n\t- a[3][1] = a[2][0]+a[2][1]\n\t- a[3][2] = a[2][1]+a[2][2]\n\t- ......\n\t- 推算得出\n\t- ......\n\t- a[i][j] = a[i-1][j-1]+a[i-1][j]\n\n**代码（c++）：**\n\n```\nclass Solution {\npublic:\n    vector<vector<int>> generate(int numRows) {\n        vector <vector<int> > vec(numRows);\n        for(int i = 0; i < numRows; i++) {\n            vec[i].resize(i+1);\n            for(int j = 0; j <= i ; j++){\n                if(j==i || j==0)\n                    vec[i][j] = 1;\n                else{\n                    vec[i][j] = vec[i-1][j-1] + vec[i-1][j];\n                }\n            }\n        }\n        return vec;\n    }\n};\n```\n\n**代码（Python）：**\n\n```\nclass Solution(object):\n    def generate(self, numRows):\n        \"\"\"\n        :type numRows: int\n        :rtype: List[List[int]]\n        \"\"\"\n        b=[]\n        for i in range(numRows):\n            temp = []\n            for j in range(i+1):\n                if j==0:\n                    temp.append(1)\n                else:\n                    if j < i:\n                        temp.append(b[i-1][j-1]+b[i-1][j])\n                    elif j==i:\n                        temp.append(1)\n            b.append(temp)\n        return b\n```\n\n\n</article>\n","source":"leetcode/Leetcode[118]-Pascal's Triangle.md","raw":"---\ntitle: Leetcode[118]-Pascal's Triangle\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/pascals-triangle/\n\nGiven numRows, generate the first numRows of Pascal's triangle.\n\nFor example, given numRows = 5,\nReturn\n\n```\n[\n     [1],\n    [1,1],\n   [1,2,1],\n  [1,3,3,1],\n [1,4,6,4,1]\n]\n```\n---------\n分析：\n\n- 第j=0列全为1，第j==i列时，都为1\n- 其它列\n\t- a[2][1] = a[1][0]+a[1][1]\n\t- a[3][1] = a[2][0]+a[2][1]\n\t- a[3][2] = a[2][1]+a[2][2]\n\t- ......\n\t- 推算得出\n\t- ......\n\t- a[i][j] = a[i-1][j-1]+a[i-1][j]\n\n**代码（c++）：**\n\n```\nclass Solution {\npublic:\n    vector<vector<int>> generate(int numRows) {\n        vector <vector<int> > vec(numRows);\n        for(int i = 0; i < numRows; i++) {\n            vec[i].resize(i+1);\n            for(int j = 0; j <= i ; j++){\n                if(j==i || j==0)\n                    vec[i][j] = 1;\n                else{\n                    vec[i][j] = vec[i-1][j-1] + vec[i-1][j];\n                }\n            }\n        }\n        return vec;\n    }\n};\n```\n\n**代码（Python）：**\n\n```\nclass Solution(object):\n    def generate(self, numRows):\n        \"\"\"\n        :type numRows: int\n        :rtype: List[List[int]]\n        \"\"\"\n        b=[]\n        for i in range(numRows):\n            temp = []\n            for j in range(i+1):\n                if j==0:\n                    temp.append(1)\n                else:\n                    if j < i:\n                        temp.append(b[i-1][j-1]+b[i-1][j])\n                    elif j==i:\n                        temp.append(1)\n            b.append(temp)\n        return b\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.700Z","updated":"2016-03-23T14:33:02.311Z","path":"leetcode/Leetcode[118]-Pascal's Triangle.html","_id":"cimigpys600206cuj6zj2f5is"},{"title":"Leetcode[114]-Flatten Binary Tree to Linked List","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/flatten-binary-tree-to-linked-list/\n\nGiven a binary tree, flatten it to a linked list in-place.\n\nFor example,\nGiven\n\n        1\n        / \\\n       2   5\n      / \\   \\\n     3   4   6\n\nThe flattened tree should look like:\n\n\t   1\n\t    \\\n\t     2\n\t      \\\n\t       3\n\t        \\\n\t         4\n\t          \\\n\t           5\n\t            \\\n\t             6\n\n\n\n----------\n\n**思路: **  首先找到根节点左节点的最右子节点，然后把根节点的右子树移到左子树的最右端；接着把根结点的左子树移到右节点上，并将左子树置为空树，同时将根结点往右下移一个节点，依次递归即可。代码如下：\n\nCode(c++):\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    \n    void flatten(TreeNode* root) {\n        if(!root) return;\n        while(root){\n            if(root->left && root->right){\n                TreeNode *p = root->left;\n                while(p->right) \n                    p =p->right;\n                p->right = root->right;\n            }\n            \n            \n            if(root->left)\n                root->right = root->left;\n            root->left = NULL;\n            root = root->right;\n        }\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[114]-Flatten Binary Tree to Linked List.md","raw":"---\ntitle: Leetcode[114]-Flatten Binary Tree to Linked List\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/flatten-binary-tree-to-linked-list/\n\nGiven a binary tree, flatten it to a linked list in-place.\n\nFor example,\nGiven\n\n        1\n        / \\\n       2   5\n      / \\   \\\n     3   4   6\n\nThe flattened tree should look like:\n\n\t   1\n\t    \\\n\t     2\n\t      \\\n\t       3\n\t        \\\n\t         4\n\t          \\\n\t           5\n\t            \\\n\t             6\n\n\n\n----------\n\n**思路: **  首先找到根节点左节点的最右子节点，然后把根节点的右子树移到左子树的最右端；接着把根结点的左子树移到右节点上，并将左子树置为空树，同时将根结点往右下移一个节点，依次递归即可。代码如下：\n\nCode(c++):\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    \n    void flatten(TreeNode* root) {\n        if(!root) return;\n        while(root){\n            if(root->left && root->right){\n                TreeNode *p = root->left;\n                while(p->right) \n                    p =p->right;\n                p->right = root->right;\n            }\n            \n            \n            if(root->left)\n                root->right = root->left;\n            root->left = NULL;\n            root = root->right;\n        }\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.699Z","updated":"2016-03-23T14:33:02.308Z","path":"leetcode/Leetcode[114]-Flatten Binary Tree to Linked List.html","_id":"cimigpys800216cujergxiavm"},{"title":"Leetcode[113]-Path Sum II","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/path-sum-ii/\n\nGiven a binary tree and a sum, find all root-to-leaf paths where each path's sum equals the given sum.\n\nFor example:\nGiven the below binary tree and sum = 22,\n\n\n              5\n             / \\\n            4   8\n           /   / \\\n          11  13  4\n         /  \\    / \\\n        7    2  5   1\n\nreturn\n\n\n\t[\n\t   [5,4,11,2],\n\t   [5,8,4,5]\n\t]\n\n\n------------\n\n思路：使用深度优先遍历，需要\n\n- 一个map，保存节点是否出栈过；\n- 一个一维数组，保存根结点到当前节点的路径；\n- 一个二维数组，保存根结点到当前叶节点的和等于给定sum的路径集合；\n- 一个栈，用来辅助深度优先遍历；\n\n按照深度优先的遍历方式遍历，\n\n- 进栈的时候元素同时添加到一维数组中，并将该节点的map值设置为0,\n- 当节点左右节点都为空的时候，判断一维数组里面的数据和是否等于给定sum，如果等于就把它丢到二维数组中，同时执行下一步出栈；\n- 出栈的时候也同时缩小一维数组的长度，并将该节点的map值设置为1，表示该节点不能再次进栈了；\n\nCode（c++）：非递归算法：\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    vector<vector<int> > pathSum(TreeNode* root, int sum) {\n        vector<vector<int> > res;\n        if(root==NULL) return res;\n        vector<int> nums;\n        map<TreeNode *, int> visited;\n        stack<TreeNode *> stk;\n        \n        TreeNode* p = root;\n        nums.push_back(p->val);\n        stk.push(p);\n        visited[p] = 0;\n        \n        while(!stk.empty()){\n            p = stk.top();\n            while(p->left && visited[p] == 0){\n\t            //this is very important to break this while\n                if(visited[p->left]==1) break;\n                p = p->left;\n                nums.push_back(p->val);\n                stk.push(p);\n                visited[p] = 0;\n            }\n            if(!stk.empty()){\n                p = stk.top();\n                if(!p->left && !p->right && sumVector(nums) == sum){\n                    res.push_back(nums);\n                }\n                if( p->right && (visited.find(p->right) == visited.end() || visited[p->right] == 0)){\n                    p = p->right;\n                    stk.push(p);\n                    nums.push_back(p->val);\n                    visited[p] = 0;\n                    continue;\n                }\n                visited[p] = 1;\n                stk.pop();\n                nums.resize(nums.size()-1);\n            }\n        }\n        return res;\n    }\n    \n    int sumVector(vector<int> & nums){\n        int n = nums.size();\n        if( n == 0 ) return 0;\n        int sum = 0;\n        for(int i = 0; i < n; i++) {\n            sum += nums[i];\n        }\n        return sum;\n    }\n};\n\n```\n\n\n递归方法：\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    vector<vector<int> > pathSum(TreeNode* root, int sum) {\n        vector<vector<int> > result;\n        vector<int> nums;\n        getPath(result,nums,sum,0,root);\n        return result;\n\n    }\n    \n    void getPath(vector<vector<int> > &res, vector<int> &nums, int target, int sum, TreeNode *root) {\n        \n        if(root==NULL) return;\n        sum += root->val;\n        nums.push_back(root->val);\n        if(sum == target && !root->left && !root->right){\n            res.push_back(nums);\n        }\n        \n        getPath(res, nums, target, sum, root->left);\n        getPath(res, nums, target, sum, root->right);\n        \n        nums.pop_back();\n        sum -= root->val;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[113]-Path Sum II.md","raw":"---\ntitle: Leetcode[113]-Path Sum II\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/path-sum-ii/\n\nGiven a binary tree and a sum, find all root-to-leaf paths where each path's sum equals the given sum.\n\nFor example:\nGiven the below binary tree and sum = 22,\n\n\n              5\n             / \\\n            4   8\n           /   / \\\n          11  13  4\n         /  \\    / \\\n        7    2  5   1\n\nreturn\n\n\n\t[\n\t   [5,4,11,2],\n\t   [5,8,4,5]\n\t]\n\n\n------------\n\n思路：使用深度优先遍历，需要\n\n- 一个map，保存节点是否出栈过；\n- 一个一维数组，保存根结点到当前节点的路径；\n- 一个二维数组，保存根结点到当前叶节点的和等于给定sum的路径集合；\n- 一个栈，用来辅助深度优先遍历；\n\n按照深度优先的遍历方式遍历，\n\n- 进栈的时候元素同时添加到一维数组中，并将该节点的map值设置为0,\n- 当节点左右节点都为空的时候，判断一维数组里面的数据和是否等于给定sum，如果等于就把它丢到二维数组中，同时执行下一步出栈；\n- 出栈的时候也同时缩小一维数组的长度，并将该节点的map值设置为1，表示该节点不能再次进栈了；\n\nCode（c++）：非递归算法：\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    vector<vector<int> > pathSum(TreeNode* root, int sum) {\n        vector<vector<int> > res;\n        if(root==NULL) return res;\n        vector<int> nums;\n        map<TreeNode *, int> visited;\n        stack<TreeNode *> stk;\n        \n        TreeNode* p = root;\n        nums.push_back(p->val);\n        stk.push(p);\n        visited[p] = 0;\n        \n        while(!stk.empty()){\n            p = stk.top();\n            while(p->left && visited[p] == 0){\n\t            //this is very important to break this while\n                if(visited[p->left]==1) break;\n                p = p->left;\n                nums.push_back(p->val);\n                stk.push(p);\n                visited[p] = 0;\n            }\n            if(!stk.empty()){\n                p = stk.top();\n                if(!p->left && !p->right && sumVector(nums) == sum){\n                    res.push_back(nums);\n                }\n                if( p->right && (visited.find(p->right) == visited.end() || visited[p->right] == 0)){\n                    p = p->right;\n                    stk.push(p);\n                    nums.push_back(p->val);\n                    visited[p] = 0;\n                    continue;\n                }\n                visited[p] = 1;\n                stk.pop();\n                nums.resize(nums.size()-1);\n            }\n        }\n        return res;\n    }\n    \n    int sumVector(vector<int> & nums){\n        int n = nums.size();\n        if( n == 0 ) return 0;\n        int sum = 0;\n        for(int i = 0; i < n; i++) {\n            sum += nums[i];\n        }\n        return sum;\n    }\n};\n\n```\n\n\n递归方法：\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    vector<vector<int> > pathSum(TreeNode* root, int sum) {\n        vector<vector<int> > result;\n        vector<int> nums;\n        getPath(result,nums,sum,0,root);\n        return result;\n\n    }\n    \n    void getPath(vector<vector<int> > &res, vector<int> &nums, int target, int sum, TreeNode *root) {\n        \n        if(root==NULL) return;\n        sum += root->val;\n        nums.push_back(root->val);\n        if(sum == target && !root->left && !root->right){\n            res.push_back(nums);\n        }\n        \n        getPath(res, nums, target, sum, root->left);\n        getPath(res, nums, target, sum, root->right);\n        \n        nums.pop_back();\n        sum -= root->val;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.697Z","updated":"2016-03-23T14:33:02.307Z","path":"leetcode/Leetcode[113]-Path Sum II.html","_id":"cimigpysa00226cujyttreryj"},{"title":"Leetcode[111]-Minimum Depth of Binary Tree","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/minimum-depth-of-binary-tree/\n\nGiven a binary tree, find its minimum depth.\n\nThe minimum depth is the number of nodes along the shortest path from the root node down to the nearest leaf node.\n\n\n\n-----\n\nC++:\n\n递归法\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    int minDepth(TreeNode* root) {\n        \n        if(root == NULL) return 0;\n        if(!root->left && !root->right) return 1;\n        \n        int dleft=0,dright=0,dmin = 0;\n        \n        if(root->left) dleft = minDepth(root->left) + 1 ;\n        if(root->right) dright = minDepth(root->right) + 1;\n        \n        if(!root->left && root->right) return dright;\n        if(!root->right && root->left) return dleft;\n        \n        dmin = dleft>dright?dright:dleft; \n        return dmin;\n        \n    }\n};\n```\n\n\n\n\n</article>\n","source":"leetcode/Leetcode[111]-Minimum Depth of Binary Tree.md","raw":"---\ntitle: Leetcode[111]-Minimum Depth of Binary Tree\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/minimum-depth-of-binary-tree/\n\nGiven a binary tree, find its minimum depth.\n\nThe minimum depth is the number of nodes along the shortest path from the root node down to the nearest leaf node.\n\n\n\n-----\n\nC++:\n\n递归法\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    int minDepth(TreeNode* root) {\n        \n        if(root == NULL) return 0;\n        if(!root->left && !root->right) return 1;\n        \n        int dleft=0,dright=0,dmin = 0;\n        \n        if(root->left) dleft = minDepth(root->left) + 1 ;\n        if(root->right) dright = minDepth(root->right) + 1;\n        \n        if(!root->left && root->right) return dright;\n        if(!root->right && root->left) return dleft;\n        \n        dmin = dleft>dright?dright:dleft; \n        return dmin;\n        \n    }\n};\n```\n\n\n\n\n</article>\n","date":"2016-03-23T14:33:15.696Z","updated":"2016-03-23T14:33:02.303Z","path":"leetcode/Leetcode[111]-Minimum Depth of Binary Tree.html","_id":"cimigpysb00236cujmq9yad0o"},{"title":"Leetcode[110]-Balanced Binary Tree","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/balanced-binary-tree/\n\nGiven a binary tree, determine if it is height-balanced.\n\nFor this problem, a height-balanced binary tree is defined as a binary tree in which the depth of the two subtrees of every node never differ by more than 1.\n\n-------\n\n判断一棵树是否属于平衡二叉树\n\n判断主节点的左右节点深度大小差，如果不在【-1,1】内，返回false，否则，继续判断其左右节点是否属于平衡二叉树；\n\n只要有不满足的，就返回false\n\nCode(C++):\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    bool isBalanced(TreeNode* root) {\n        if(root == NULL) return true;\n        \n        int ldepth = getDepth(root->left);\n        int rdepth = getDepth(root->right);\n        \n        if(ldepth - rdepth > 1 || ldepth - rdepth < -1) return false;\n        \n        return isBalanced(root->left) && isBalanced(root->right);\n    }\n    \n    //get node's depth\n    int getDepth(TreeNode *root){\n        if(root==NULL) return 0;\n    \n        int ldepth=0,rdepth=0;\n        ldepth = getDepth(root->left);\n        rdepth = getDepth(root->right);\n \n        return ldepth > rdepth ? ldepth+1:rdepth+1;\n        \n    }\n};\n```\n\n\n\n\n</article>\n","source":"leetcode/Leetcode[110]-Balanced Binary Tree.md","raw":"---\ntitle: Leetcode[110]-Balanced Binary Tree\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/balanced-binary-tree/\n\nGiven a binary tree, determine if it is height-balanced.\n\nFor this problem, a height-balanced binary tree is defined as a binary tree in which the depth of the two subtrees of every node never differ by more than 1.\n\n-------\n\n判断一棵树是否属于平衡二叉树\n\n判断主节点的左右节点深度大小差，如果不在【-1,1】内，返回false，否则，继续判断其左右节点是否属于平衡二叉树；\n\n只要有不满足的，就返回false\n\nCode(C++):\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    bool isBalanced(TreeNode* root) {\n        if(root == NULL) return true;\n        \n        int ldepth = getDepth(root->left);\n        int rdepth = getDepth(root->right);\n        \n        if(ldepth - rdepth > 1 || ldepth - rdepth < -1) return false;\n        \n        return isBalanced(root->left) && isBalanced(root->right);\n    }\n    \n    //get node's depth\n    int getDepth(TreeNode *root){\n        if(root==NULL) return 0;\n    \n        int ldepth=0,rdepth=0;\n        ldepth = getDepth(root->left);\n        rdepth = getDepth(root->right);\n \n        return ldepth > rdepth ? ldepth+1:rdepth+1;\n        \n    }\n};\n```\n\n\n\n\n</article>\n","date":"2016-03-23T14:33:15.695Z","updated":"2016-03-23T14:33:02.302Z","path":"leetcode/Leetcode[110]-Balanced Binary Tree.html","_id":"cimigpysd00246cujcnm1wi9x"},{"title":"Leetcode[107]-Binary Tree Level Order Traversal II","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/binary-tree-level-order-traversal-ii/\n\nGiven a binary tree, return the bottom-up level order traversal of its nodes' values. (ie, from left to right, level by level from leaf to root).\n\nFor example:\nGiven binary tree {3,9,20,#,#,15,7},\n\n\t    3\n\t   / \\\n\t  9  20\n\t    /  \\\n\t   15   7\n\nreturn its bottom-up level order traversal as:\n\n\t[\n\t  [15,7],\n\t  [9,20],\n\t  [3]\n\t]\n\n\n------\n使用BFS层序遍历，然后得到的vector数组使用reverse反转即可。\n\nCode(c++):\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    vector<vector<int>> levelOrderBottom(TreeNode* root) {\n        vector<vector<int> > res;\n        if(!root) return res;\n        vector<int> nums;\n        queue<TreeNode *> que;\n        \n        TreeNode *p = root;\n        que.push(p);\n        \n        while(!que.empty()){ \n            int queSize = que.size();\n            nums.resize(0);\n            for(int i = 0; i < queSize; i++) {\n                p = que.front();\n                nums.push_back(p->val);\n                if(p->left) que.push(p->left);\n                if(p->right) que.push(p->right);\n                que.pop();\n            }\n            res.push_back(nums);\n        }\n        reverse(res.begin(),res.end());\n        return res;\n        \n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[107]-Binary Tree Level Order Traversal II.md","raw":"---\ntitle: Leetcode[107]-Binary Tree Level Order Traversal II\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/binary-tree-level-order-traversal-ii/\n\nGiven a binary tree, return the bottom-up level order traversal of its nodes' values. (ie, from left to right, level by level from leaf to root).\n\nFor example:\nGiven binary tree {3,9,20,#,#,15,7},\n\n\t    3\n\t   / \\\n\t  9  20\n\t    /  \\\n\t   15   7\n\nreturn its bottom-up level order traversal as:\n\n\t[\n\t  [15,7],\n\t  [9,20],\n\t  [3]\n\t]\n\n\n------\n使用BFS层序遍历，然后得到的vector数组使用reverse反转即可。\n\nCode(c++):\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    vector<vector<int>> levelOrderBottom(TreeNode* root) {\n        vector<vector<int> > res;\n        if(!root) return res;\n        vector<int> nums;\n        queue<TreeNode *> que;\n        \n        TreeNode *p = root;\n        que.push(p);\n        \n        while(!que.empty()){ \n            int queSize = que.size();\n            nums.resize(0);\n            for(int i = 0; i < queSize; i++) {\n                p = que.front();\n                nums.push_back(p->val);\n                if(p->left) que.push(p->left);\n                if(p->right) que.push(p->right);\n                que.pop();\n            }\n            res.push_back(nums);\n        }\n        reverse(res.begin(),res.end());\n        return res;\n        \n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.693Z","updated":"2016-03-23T14:33:02.294Z","path":"leetcode/Leetcode[107]-Binary Tree Level Order Traversal II.html","_id":"cimigpysf00256cujc3ei471b"},{"title":"Leetcode[104]-Maximum Depth of Binary Tree","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/maximum-depth-of-binary-tree/\n\nGiven a binary tree, find its maximum depth.\n\nThe maximum depth is the number of nodes along the longest path from the root node down to the farthest leaf node.\n\n\n--------\n\n求最大深度，用递归的方法\n\nC++:\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    int maxDepth(TreeNode* root) {\n        \n        if(root==NULL) return 0;\n        int ldepth = 0,rdepth = 0;\n        if(root->left!=NULL){\n            ldepth = maxDepth(root->left);\n        }\n        if(root->right!=NULL){\n            rdepth = maxDepth(root->right);\n        }\n        return ldepth>rdepth?ldepth+1:rdepth+1;   \n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[104]-Maximum Depth of Binary Tree.md","raw":"---\ntitle: Leetcode[104]-Maximum Depth of Binary Tree\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/maximum-depth-of-binary-tree/\n\nGiven a binary tree, find its maximum depth.\n\nThe maximum depth is the number of nodes along the longest path from the root node down to the farthest leaf node.\n\n\n--------\n\n求最大深度，用递归的方法\n\nC++:\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    int maxDepth(TreeNode* root) {\n        \n        if(root==NULL) return 0;\n        int ldepth = 0,rdepth = 0;\n        if(root->left!=NULL){\n            ldepth = maxDepth(root->left);\n        }\n        if(root->right!=NULL){\n            rdepth = maxDepth(root->right);\n        }\n        return ldepth>rdepth?ldepth+1:rdepth+1;   \n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.691Z","updated":"2016-03-23T14:33:02.291Z","path":"leetcode/Leetcode[104]-Maximum Depth of Binary Tree.html","_id":"cimigpysi00266cujgyzyko81"},{"title":"Leetcode[103]-Binary Tree Zigzag Level Order Traversal","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/binary-tree-zigzag-level-order-traversal/\n\nGiven a binary tree, return the zigzag level order traversal of its nodes' values. (ie, from left to right, then right to left for the next level and alternate between).\n\nFor example:\nGiven binary tree {3,9,20,#,#,15,7},\n\n\n\t    3\n\t   / \\\n\t  9  20\n\t    /  \\\n\t   15   7\n\nreturn its zigzag level order traversal as:\n\n\t[\n\t  [3],\n\t  [20,9],\n\t  [15,7]\n\t]\n\n\n-----\n\n思路：使用层序遍历，借助队列，依次遍历每层，如果层数为偶数，则将该层的数字翻转，使用vector的reverse函数即可。\n\n代码Code （C++）：\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    vector<vector<int>> zigzagLevelOrder(TreeNode* root) {\n        vector<vector<int> > res;\n        if(!root) return res;\n        vector<int> nums;\n        queue<TreeNode *> que;\n        TreeNode *p = root;\n        que.push(p);\n       \n        int level  = 0; // curent level\n        while(!que.empty()){\n            nums.resize(0);\n            level += 1;\n            int queSize = que.size();\n            for(int i = 0; i < queSize; i++ ) {\n                p = que.front();\n                nums.push_back(p->val);\n                que.pop();\n                if(p->left) que.push(p->left);\n                if(p->right) que.push(p->right);\n            }\n            if(level % 2 == 0) reverse(nums.begin(),nums.end());\n            res.push_back(nums);\n        }\n        return  res;         \n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[103]-Binary Tree Zigzag Level Order Traversal.md","raw":"---\ntitle: Leetcode[103]-Binary Tree Zigzag Level Order Traversal\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/binary-tree-zigzag-level-order-traversal/\n\nGiven a binary tree, return the zigzag level order traversal of its nodes' values. (ie, from left to right, then right to left for the next level and alternate between).\n\nFor example:\nGiven binary tree {3,9,20,#,#,15,7},\n\n\n\t    3\n\t   / \\\n\t  9  20\n\t    /  \\\n\t   15   7\n\nreturn its zigzag level order traversal as:\n\n\t[\n\t  [3],\n\t  [20,9],\n\t  [15,7]\n\t]\n\n\n-----\n\n思路：使用层序遍历，借助队列，依次遍历每层，如果层数为偶数，则将该层的数字翻转，使用vector的reverse函数即可。\n\n代码Code （C++）：\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    vector<vector<int>> zigzagLevelOrder(TreeNode* root) {\n        vector<vector<int> > res;\n        if(!root) return res;\n        vector<int> nums;\n        queue<TreeNode *> que;\n        TreeNode *p = root;\n        que.push(p);\n       \n        int level  = 0; // curent level\n        while(!que.empty()){\n            nums.resize(0);\n            level += 1;\n            int queSize = que.size();\n            for(int i = 0; i < queSize; i++ ) {\n                p = que.front();\n                nums.push_back(p->val);\n                que.pop();\n                if(p->left) que.push(p->left);\n                if(p->right) que.push(p->right);\n            }\n            if(level % 2 == 0) reverse(nums.begin(),nums.end());\n            res.push_back(nums);\n        }\n        return  res;         \n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.689Z","updated":"2016-03-23T14:33:02.283Z","path":"leetcode/Leetcode[103]-Binary Tree Zigzag Level Order Traversal.html","_id":"cimigpysk00276cuj3xw7pyr4"},{"title":"Leetcode[102]-Binary Tree Level Order Traversal","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/binary-tree-level-order-traversal/\n\nGiven a binary tree, return the level order traversal of its nodes' values. (ie, from left to right, level by level).\n\nFor example:\nGiven binary tree {3,9,20,#,#,15,7},\n\n\n<pre>\t\t 3\n\t   / \\\n\t  9  20\n\t    /  \\\n\t   15   7]</pre>\n\nreturn its level order traversal as:\n\n\n<pre>\t[\n\t  [3],\n\t  [9,20],\n\t  [15,7]\n\t]</pre>\n\n**思路**： 使用层序遍历，一层一层的出队，并将节点值放入数组中；\n\n代码C++：\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    vector<vector<int> > levelOrder(TreeNode* root) {\n        vector<vector<int> > res;\n        vector<int> nums;\n        if(root == NULL) return res;\n        queue<TreeNode *> que;\n        TreeNode *p = root;\n        que.push(p);\n        while(!que.empty()){\n            int queSize = que.size();\n            nums.resize(0);\n            for(int i = 0; i < queSize; i++){\n                p = que.front();\n                nums.push_back(p->val);\n                if(p->left) que.push(p->left);\n                if(p->right) que.push(p->right);\n                que.pop();\n            }\n            res.push_back(nums);\n        }\n        return res;\n    }\n};\n```\n\n\n有问题，欢迎一起讨论~\n\n\n</article>\n","source":"leetcode/Leetcode[102]-Binary Tree Level Order Traversal.md","raw":"---\ntitle: Leetcode[102]-Binary Tree Level Order Traversal\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/binary-tree-level-order-traversal/\n\nGiven a binary tree, return the level order traversal of its nodes' values. (ie, from left to right, level by level).\n\nFor example:\nGiven binary tree {3,9,20,#,#,15,7},\n\n\n<pre>\t\t 3\n\t   / \\\n\t  9  20\n\t    /  \\\n\t   15   7]</pre>\n\nreturn its level order traversal as:\n\n\n<pre>\t[\n\t  [3],\n\t  [9,20],\n\t  [15,7]\n\t]</pre>\n\n**思路**： 使用层序遍历，一层一层的出队，并将节点值放入数组中；\n\n代码C++：\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    vector<vector<int> > levelOrder(TreeNode* root) {\n        vector<vector<int> > res;\n        vector<int> nums;\n        if(root == NULL) return res;\n        queue<TreeNode *> que;\n        TreeNode *p = root;\n        que.push(p);\n        while(!que.empty()){\n            int queSize = que.size();\n            nums.resize(0);\n            for(int i = 0; i < queSize; i++){\n                p = que.front();\n                nums.push_back(p->val);\n                if(p->left) que.push(p->left);\n                if(p->right) que.push(p->right);\n                que.pop();\n            }\n            res.push_back(nums);\n        }\n        return res;\n    }\n};\n```\n\n\n有问题，欢迎一起讨论~\n\n\n</article>\n","date":"2016-03-26T08:22:10.005Z","updated":"2016-03-26T08:22:10.005Z","path":"leetcode/Leetcode[102]-Binary Tree Level Order Traversal.html","_id":"cimigpysl00286cujh5e12xzo"},{"title":"Leetcode[101]-Symmetric Tree","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/symmetric-tree/\n\nGiven a binary tree, check whether it is a mirror of itself (ie, symmetric around its center).\n\nFor example, this binary tree is symmetric:\n\n```\n    1\n   / \\\n  2   2\n / \\ / \\\n3  4 4  3\nBut the following is not:\n    1\n   / \\\n  2   2\n   \\   \\\n   3    3\n```\n\nNote:\nBonus points if you could solve it both recursively and iteratively.\n\n-----\n\n思路：从左右两边同时执行DFS，同步进栈出栈，如果发现不匹配，则返回false,最后如果匹配后，栈中还剩有节点，则也返回false，否则返回true。\n\nCode（c++）：\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    bool isSymmetric(TreeNode* root) {\n        if(root==NULL) return true;\n        \n        TreeNode* p = root,*q = root;\n        stack<TreeNode *> stk,stk2;//define two stack to save node\n        stk.push(p);\n        stk2.push(q);\n        //if both of stk and stk2 is not empty \n        while(!stk.empty() && !stk2.empty() ){\n\t        //p go left,q go right\n            while(p->left && q->right){\n                p = p->left;\n                stk.push(p);\n                q = q->right;\n                stk2.push(q);\n            }\n            //next line is very important to this method \n            if(p->left || q->right) return false;\n            \n            //both of stk and stk2 is not empty,pop from  stack and judge p's right node and q's left node\n            if(!stk.empty() && !stk2.empty()){\n                p = stk.top();\n                q = stk2.top();\n                stk.pop();\n                stk2.pop();\n                if(p->val != q->val) return false;\n                \n                if(p->right) stk.push(p->right);\n                if(q->left) stk2.push(q->left);\n            }\n        }\n        if(!stk.empty() || !stk2.empty()) return false;\n        else return true;\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[101]-Symmetric Tree.md","raw":"---\ntitle: Leetcode[101]-Symmetric Tree\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/symmetric-tree/\n\nGiven a binary tree, check whether it is a mirror of itself (ie, symmetric around its center).\n\nFor example, this binary tree is symmetric:\n\n```\n    1\n   / \\\n  2   2\n / \\ / \\\n3  4 4  3\nBut the following is not:\n    1\n   / \\\n  2   2\n   \\   \\\n   3    3\n```\n\nNote:\nBonus points if you could solve it both recursively and iteratively.\n\n-----\n\n思路：从左右两边同时执行DFS，同步进栈出栈，如果发现不匹配，则返回false,最后如果匹配后，栈中还剩有节点，则也返回false，否则返回true。\n\nCode（c++）：\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    bool isSymmetric(TreeNode* root) {\n        if(root==NULL) return true;\n        \n        TreeNode* p = root,*q = root;\n        stack<TreeNode *> stk,stk2;//define two stack to save node\n        stk.push(p);\n        stk2.push(q);\n        //if both of stk and stk2 is not empty \n        while(!stk.empty() && !stk2.empty() ){\n\t        //p go left,q go right\n            while(p->left && q->right){\n                p = p->left;\n                stk.push(p);\n                q = q->right;\n                stk2.push(q);\n            }\n            //next line is very important to this method \n            if(p->left || q->right) return false;\n            \n            //both of stk and stk2 is not empty,pop from  stack and judge p's right node and q's left node\n            if(!stk.empty() && !stk2.empty()){\n                p = stk.top();\n                q = stk2.top();\n                stk.pop();\n                stk2.pop();\n                if(p->val != q->val) return false;\n                \n                if(p->right) stk.push(p->right);\n                if(q->left) stk2.push(q->left);\n            }\n        }\n        if(!stk.empty() || !stk2.empty()) return false;\n        else return true;\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.685Z","updated":"2016-03-23T14:33:02.278Z","path":"leetcode/Leetcode[101]-Symmetric Tree.html","_id":"cimigpysn00296cujcleyw9cb"},{"title":"Leetcode[100]-Same Tree","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/same-tree/\n\nGiven two binary trees, write a function to check if they are equal or not.\n\nTwo binary trees are considered equal if they are structurally identical and the nodes have the same value.\n\n-----\n\n思路：递归法判断\n假设两棵树根结点为p和q\n\n- 如果p和q都为空，则返回true；否则，\n- 如果p和q都非空，并且他们的值都相等，则判断其左右子树是否是相似树；否则\n- 返回false；\n\n代码如下(C++)：\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    bool isSameTree(TreeNode* p, TreeNode* q) {\n        if(!p && !q) return true;\n        else if(p && q && (p->val == q->val)){\n            return isSameTree(p->left,q->left) && isSameTree(p->right,q->right);\n        }else{\n            return false;\n        }\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/Leetcode[100]-Same Tree.md","raw":"---\ntitle: Leetcode[100]-Same Tree\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/same-tree/\n\nGiven two binary trees, write a function to check if they are equal or not.\n\nTwo binary trees are considered equal if they are structurally identical and the nodes have the same value.\n\n-----\n\n思路：递归法判断\n假设两棵树根结点为p和q\n\n- 如果p和q都为空，则返回true；否则，\n- 如果p和q都非空，并且他们的值都相等，则判断其左右子树是否是相似树；否则\n- 返回false；\n\n代码如下(C++)：\n\n```\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}\n * };\n */\nclass Solution {\npublic:\n    bool isSameTree(TreeNode* p, TreeNode* q) {\n        if(!p && !q) return true;\n        else if(p && q && (p->val == q->val)){\n            return isSameTree(p->left,q->left) && isSameTree(p->right,q->right);\n        }else{\n            return false;\n        }\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.684Z","updated":"2016-03-23T14:33:02.269Z","path":"leetcode/Leetcode[100]-Same Tree.html","_id":"cimigpyso002a6cujb20auwwb"},{"title":"LeetCode[155]-Min Stack","layout":"page","noDate":"true","comments":1,"description":"LeetCode题解","_content":"<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/min-stack/\n\nDesign a stack that supports push, pop, top, and retrieving the minimum element in constant time.\n\npush(x) -- Push element x onto stack.\npop() -- Removes the element on top of the stack.\ntop() -- Get the top element.\ngetMin() -- Retrieve the minimum element in the stack.\n\n------\n思路：需要两个栈，一个用来作为一般的栈，另一个用来存放进栈到某一位置的当前站内最小元素，代码如下：\n\nCode（c++）:\n\n\n```\nclass MinStack {\npublic:\n    std::stack<int> stk;\n    std::stack<int> min;\n    void push(int x) {\n        stk.push(x);\n        if(min.empty() || (!min.empty() && x <= min.top())){\n            min.push(x);\n        }\n    }\n\n    void pop() {\n        if(!stk.empty()){\n            if(stk.top() == min.top())min.pop();\n            stk.pop();\n        }\n    }\n\n    int top() {\n        if(!stk.empty())\n            return stk.top();\n    }\n\n    int getMin() {\n        if(!stk.empty()) return min.top();\n    }\n};\n```\n\n\n</article>\n","source":"leetcode/LeetCode[155]-Min Stack.md","raw":"---\ntitle: LeetCode[155]-Min Stack\nlayout: page\nnoDate: \"true\"\ncomments: true\ndescription: \"LeetCode题解\" \n---\n<article class=\"post post-type-normal\" itemscope=\"\" itemtype=\"http://schema.org/Article\" style=\"opacity: 1; transform: translateY(0px);\">\n\nLink: https://leetcode.com/problems/min-stack/\n\nDesign a stack that supports push, pop, top, and retrieving the minimum element in constant time.\n\npush(x) -- Push element x onto stack.\npop() -- Removes the element on top of the stack.\ntop() -- Get the top element.\ngetMin() -- Retrieve the minimum element in the stack.\n\n------\n思路：需要两个栈，一个用来作为一般的栈，另一个用来存放进栈到某一位置的当前站内最小元素，代码如下：\n\nCode（c++）:\n\n\n```\nclass MinStack {\npublic:\n    std::stack<int> stk;\n    std::stack<int> min;\n    void push(int x) {\n        stk.push(x);\n        if(min.empty() || (!min.empty() && x <= min.top())){\n            min.push(x);\n        }\n    }\n\n    void pop() {\n        if(!stk.empty()){\n            if(stk.top() == min.top())min.pop();\n            stk.pop();\n        }\n    }\n\n    int top() {\n        if(!stk.empty())\n            return stk.top();\n    }\n\n    int getMin() {\n        if(!stk.empty()) return min.top();\n    }\n};\n```\n\n\n</article>\n","date":"2016-03-23T14:33:15.727Z","updated":"2016-03-23T14:33:02.419Z","path":"leetcode/LeetCode[155]-Min Stack.html","_id":"cimigpysp002b6cuj6d25utin"},{"_content":"{\"pagination\":{},\"meta\":{\"code\":200},\"data\":[{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1394290738\",\"link\":\"https:\\/\\/instagram.com\\/p\\/lSSxd8I7kB\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/outbound-distilleryimage11\\/t0.0-17\\/OBPTH\\/a9496b08a6d111e395e20aa496a2d2bb_6.jpg\",\"width\":306,\"height\":306},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/outbound-distilleryimage11\\/t0.0-17\\/OBPTH\\/a9496b08a6d111e395e20aa496a2d2bb_5.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/outbound-distilleryimage11\\/t0.0-17\\/OBPTH\\/a9496b08a6d111e395e20aa496a2d2bb_8.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1394290738\",\"text\":\"\\u4eca\\u5929\\u4e0b\\u96e8\\uff0c\\u7684\\u58eb\\u53f8\\u673a\\u90fd\\u4e0d\\u80af\\u7406\\u6211\\u3002\\u5934\\u4e0a\\u8def\\u706f\\u5149\\u8292\\u9065\\u4e0d\\u53ef\\u53ca\\uff0c\\u811a\\u4e0b\\u8def\\u9762\\u68f1\\u89d2\\u51b0\\u51b7\\u9c9c\\u660e\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"671681859937352191\"},\"type\":\"image\",\"id\":\"671681858670672129_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1394040131\",\"link\":\"https:\\/\\/instagram.com\\/p\\/lK0xswI7s6\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/outbound-distilleryimage4\\/t0.0-17\\/OBPTH\\/26ff9176a48911e3bf7e12aca78890dc_6.jpg\",\"width\":306,\"height\":306},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/outbound-distilleryimage4\\/t0.0-17\\/OBPTH\\/26ff9176a48911e3bf7e12aca78890dc_5.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/outbound-distilleryimage4\\/t0.0-17\\/OBPTH\\/26ff9176a48911e3bf7e12aca78890dc_8.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1394040131\",\"text\":\"\\u8d77\\u98ce\\u5427\\uff0c\\u660e\\u5929\\u3002\\u559c\\u6b22\\u504f\\u51b7\\u7684\\u65e5\\u5b50\\uff0c\\u5047\\u5982\\u662f\\u6625\\u5929\\uff0c\\u5047\\u5982\\u662f\\u98ce\\u5927\\uff0c\\u592a\\u5b8c\\u7f8e\\u4e86\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"669579608720652783\"},\"type\":\"image\",\"id\":\"669579608343165754_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Hefe\",\"created_time\":\"1393706362\",\"link\":\"https:\\/\\/instagram.com\\/p\\/lA4KaBI7go\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/outbound-distilleryimage9\\/t0.0-17\\/OBPTH\\/30cb58b8a18011e396f3121282ee2c71_6.jpg\",\"width\":306,\"height\":306},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/outbound-distilleryimage9\\/t0.0-17\\/OBPTH\\/30cb58b8a18011e396f3121282ee2c71_5.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/outbound-distilleryimage9\\/t0.0-17\\/OBPTH\\/30cb58b8a18011e396f3121282ee2c71_8.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1393706362\",\"text\":\"\\u817e\\u8baf\\u7684\\u51cc\\u6668\\u56db\\u70b9\\u534a\\u3002\\u7b2c\\u4e00\\u6b21\\u5728\\u6b64\\u8fc7\\u591c\\uff0c\\u542c\\u7740\\u8033\\u719f\\u4e0d\\u80fd\\u8be6\\u7684\\u6b4c\\uff0c\\u770b\\u7740\\u5e73\\u9759\\u4e0d\\u5fae\\u7b11\\u7684\\u4eba\\u3002\\u7136\\u540e\\u8bb0\\u8d77\\uff0c\\u5bb6\\u91cc\\u6253\\u6765\\u88ab\\u6211\\u6309\\u6389\\u7684\\u7535\\u8bdd\\uff0c\\u5fd8\\u4e86\\u56de\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"666779751014447553\"},\"type\":\"image\",\"id\":\"666779750586628136_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1393603959\",\"link\":\"https:\\/\\/instagram.com\\/p\\/k902HUI7ms\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s320x320\\/e15\\/1741772_1426622784247263_147777246_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s150x150\\/e15\\/1741772_1426622784247263_147777246_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/e15\\/1741772_1426622784247263_147777246_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1393603959\",\"text\":\"\\u4ece\\u524d\\u6709\\u4e00\\u5ea7\\u817e\\u8baf\\u5927\\u53a6\\uff0c\\u91cc\\u9762\\u6709\\u4e00\\u4e2a\\u8001\\u7a0b\\u5e8f\\u5458\\uff0c\\u5728\\u8ddf\\u4e00\\u4e2a\\u5c0f\\u7a0b\\u5e8f\\u5458\\u8bb2\\u6545\\u4e8b\\u3002\\u8bb2\\u7684\\u4ec0\\u4e48\\u6545\\u4e8b\\u5462\\uff1f\\u4ece\\u524d\\u6709\\u4e00\\u5ea7\\u817e\\u8baf\\u5927\\u53a6\\u2026\\u5728\\u8fd9\\u79cd\\u9012\\u5f52\\u51fd\\u6570\\u7684\\u7d27\\u5bc6\\u5c01\\u88c5\\u4e2d\\uff0c\\u5c0f\\u7a0b\\u5e8f\\u5458\\u558a\\u9053:\\u6211\\u4e0d\\u542c\\uff01\\u4e0d\\u8981\\u5267\\u900f\\u554a\\uff01\\u7528\\u8fd9\\u79cd\\u65b9\\u5f0f\\uff0c\\u4ed6break\\u4e86\\u51fa\\u53bb\\uff01\\u661f\\u591c\\u9003\\u5954\\uff0c\\u655b\\u5f71\\u6f5c\\u5f62\\u3002\\u73b0\\u5728\\u6211\\u89c9\\u5f97\\u81ea\\u5df1\\u4f3c\\u4e4e\\u662f\\u4e2a\\u82f1\\u96c4\\u2026\\u867d\\u7136\\u8fd9\\u9519\\u89c9\\u53ea\\u6709\\u4e00\\u77ac\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"665920737657469242\"},\"type\":\"image\",\"id\":\"665920737045100972_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":{\"latitude\":22.571178926,\"longitude\":113.899987696},\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Hefe\",\"created_time\":\"1393135615\",\"link\":\"https:\\/\\/instagram.com\\/p\\/kv3jNgI7sw\\/\",\"likes\":{\"count\":3,\"data\":[{\"username\":\"wallbase.hd\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/10617029_283951291805046_1229690122_a.jpg\",\"id\":\"1489501811\",\"full_name\":\"\"},{\"username\":\"dingstyle\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_30683156_75sq_1333592929.jpg\",\"id\":\"30683156\",\"full_name\":\"Linjie\"},{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/1737225_591794970889160_1849235580_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/1737225_591794970889160_1849235580_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/1737225_591794970889160_1849235580_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1393135615\",\"text\":\"\\u201c\\u4e0d\\u80fd\\u5403\\u592a\\u80d6\\u5594\\uff0c\\u4f1a\\u88ab\\u6740\\u6389\\u7684\\uff01\\u201d\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"661991984237623781\"},\"type\":\"image\",\"id\":\"661991982484405040_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":{\"latitude\":22.566938333,\"longitude\":113.903916667},\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Rise\",\"created_time\":\"1393004094\",\"link\":\"https:\\/\\/instagram.com\\/p\\/kr8sW8I7nR\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s320x320\\/e15\\/1741200_451260698337036_577792061_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s150x150\\/e15\\/1741200_451260698337036_577792061_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/e15\\/1741200_451260698337036_577792061_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1393004094\",\"text\":\"\\u4eca\\u665a\\uff0c\\u5df2\\u7ecf\\u770b\\u5230\\u4e24\\u4e2a\\u5c0f\\u5973\\u751f\\u5728\\u95ee\\uff0c\\u8fd9\\u91cc\\u6709\\u300a\\u4e5d\\u4e91\\u68a6\\u300b\\u5417\\uff1f\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"660888701821500154\"},\"type\":\"image\",\"id\":\"660888701418846673_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}}]}","source":"instagram/ins2.json","raw":"{\"pagination\":{},\"meta\":{\"code\":200},\"data\":[{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1394290738\",\"link\":\"https:\\/\\/instagram.com\\/p\\/lSSxd8I7kB\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/outbound-distilleryimage11\\/t0.0-17\\/OBPTH\\/a9496b08a6d111e395e20aa496a2d2bb_6.jpg\",\"width\":306,\"height\":306},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/outbound-distilleryimage11\\/t0.0-17\\/OBPTH\\/a9496b08a6d111e395e20aa496a2d2bb_5.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/outbound-distilleryimage11\\/t0.0-17\\/OBPTH\\/a9496b08a6d111e395e20aa496a2d2bb_8.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1394290738\",\"text\":\"\\u4eca\\u5929\\u4e0b\\u96e8\\uff0c\\u7684\\u58eb\\u53f8\\u673a\\u90fd\\u4e0d\\u80af\\u7406\\u6211\\u3002\\u5934\\u4e0a\\u8def\\u706f\\u5149\\u8292\\u9065\\u4e0d\\u53ef\\u53ca\\uff0c\\u811a\\u4e0b\\u8def\\u9762\\u68f1\\u89d2\\u51b0\\u51b7\\u9c9c\\u660e\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"671681859937352191\"},\"type\":\"image\",\"id\":\"671681858670672129_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1394040131\",\"link\":\"https:\\/\\/instagram.com\\/p\\/lK0xswI7s6\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/outbound-distilleryimage4\\/t0.0-17\\/OBPTH\\/26ff9176a48911e3bf7e12aca78890dc_6.jpg\",\"width\":306,\"height\":306},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/outbound-distilleryimage4\\/t0.0-17\\/OBPTH\\/26ff9176a48911e3bf7e12aca78890dc_5.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/outbound-distilleryimage4\\/t0.0-17\\/OBPTH\\/26ff9176a48911e3bf7e12aca78890dc_8.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1394040131\",\"text\":\"\\u8d77\\u98ce\\u5427\\uff0c\\u660e\\u5929\\u3002\\u559c\\u6b22\\u504f\\u51b7\\u7684\\u65e5\\u5b50\\uff0c\\u5047\\u5982\\u662f\\u6625\\u5929\\uff0c\\u5047\\u5982\\u662f\\u98ce\\u5927\\uff0c\\u592a\\u5b8c\\u7f8e\\u4e86\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"669579608720652783\"},\"type\":\"image\",\"id\":\"669579608343165754_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Hefe\",\"created_time\":\"1393706362\",\"link\":\"https:\\/\\/instagram.com\\/p\\/lA4KaBI7go\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/outbound-distilleryimage9\\/t0.0-17\\/OBPTH\\/30cb58b8a18011e396f3121282ee2c71_6.jpg\",\"width\":306,\"height\":306},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/outbound-distilleryimage9\\/t0.0-17\\/OBPTH\\/30cb58b8a18011e396f3121282ee2c71_5.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/outbound-distilleryimage9\\/t0.0-17\\/OBPTH\\/30cb58b8a18011e396f3121282ee2c71_8.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1393706362\",\"text\":\"\\u817e\\u8baf\\u7684\\u51cc\\u6668\\u56db\\u70b9\\u534a\\u3002\\u7b2c\\u4e00\\u6b21\\u5728\\u6b64\\u8fc7\\u591c\\uff0c\\u542c\\u7740\\u8033\\u719f\\u4e0d\\u80fd\\u8be6\\u7684\\u6b4c\\uff0c\\u770b\\u7740\\u5e73\\u9759\\u4e0d\\u5fae\\u7b11\\u7684\\u4eba\\u3002\\u7136\\u540e\\u8bb0\\u8d77\\uff0c\\u5bb6\\u91cc\\u6253\\u6765\\u88ab\\u6211\\u6309\\u6389\\u7684\\u7535\\u8bdd\\uff0c\\u5fd8\\u4e86\\u56de\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"666779751014447553\"},\"type\":\"image\",\"id\":\"666779750586628136_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1393603959\",\"link\":\"https:\\/\\/instagram.com\\/p\\/k902HUI7ms\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s320x320\\/e15\\/1741772_1426622784247263_147777246_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s150x150\\/e15\\/1741772_1426622784247263_147777246_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/e15\\/1741772_1426622784247263_147777246_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1393603959\",\"text\":\"\\u4ece\\u524d\\u6709\\u4e00\\u5ea7\\u817e\\u8baf\\u5927\\u53a6\\uff0c\\u91cc\\u9762\\u6709\\u4e00\\u4e2a\\u8001\\u7a0b\\u5e8f\\u5458\\uff0c\\u5728\\u8ddf\\u4e00\\u4e2a\\u5c0f\\u7a0b\\u5e8f\\u5458\\u8bb2\\u6545\\u4e8b\\u3002\\u8bb2\\u7684\\u4ec0\\u4e48\\u6545\\u4e8b\\u5462\\uff1f\\u4ece\\u524d\\u6709\\u4e00\\u5ea7\\u817e\\u8baf\\u5927\\u53a6\\u2026\\u5728\\u8fd9\\u79cd\\u9012\\u5f52\\u51fd\\u6570\\u7684\\u7d27\\u5bc6\\u5c01\\u88c5\\u4e2d\\uff0c\\u5c0f\\u7a0b\\u5e8f\\u5458\\u558a\\u9053:\\u6211\\u4e0d\\u542c\\uff01\\u4e0d\\u8981\\u5267\\u900f\\u554a\\uff01\\u7528\\u8fd9\\u79cd\\u65b9\\u5f0f\\uff0c\\u4ed6break\\u4e86\\u51fa\\u53bb\\uff01\\u661f\\u591c\\u9003\\u5954\\uff0c\\u655b\\u5f71\\u6f5c\\u5f62\\u3002\\u73b0\\u5728\\u6211\\u89c9\\u5f97\\u81ea\\u5df1\\u4f3c\\u4e4e\\u662f\\u4e2a\\u82f1\\u96c4\\u2026\\u867d\\u7136\\u8fd9\\u9519\\u89c9\\u53ea\\u6709\\u4e00\\u77ac\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"665920737657469242\"},\"type\":\"image\",\"id\":\"665920737045100972_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":{\"latitude\":22.571178926,\"longitude\":113.899987696},\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Hefe\",\"created_time\":\"1393135615\",\"link\":\"https:\\/\\/instagram.com\\/p\\/kv3jNgI7sw\\/\",\"likes\":{\"count\":3,\"data\":[{\"username\":\"wallbase.hd\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/10617029_283951291805046_1229690122_a.jpg\",\"id\":\"1489501811\",\"full_name\":\"\"},{\"username\":\"dingstyle\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_30683156_75sq_1333592929.jpg\",\"id\":\"30683156\",\"full_name\":\"Linjie\"},{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/1737225_591794970889160_1849235580_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/1737225_591794970889160_1849235580_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/1737225_591794970889160_1849235580_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1393135615\",\"text\":\"\\u201c\\u4e0d\\u80fd\\u5403\\u592a\\u80d6\\u5594\\uff0c\\u4f1a\\u88ab\\u6740\\u6389\\u7684\\uff01\\u201d\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"661991984237623781\"},\"type\":\"image\",\"id\":\"661991982484405040_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":{\"latitude\":22.566938333,\"longitude\":113.903916667},\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Rise\",\"created_time\":\"1393004094\",\"link\":\"https:\\/\\/instagram.com\\/p\\/kr8sW8I7nR\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s320x320\\/e15\\/1741200_451260698337036_577792061_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s150x150\\/e15\\/1741200_451260698337036_577792061_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/e15\\/1741200_451260698337036_577792061_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1393004094\",\"text\":\"\\u4eca\\u665a\\uff0c\\u5df2\\u7ecf\\u770b\\u5230\\u4e24\\u4e2a\\u5c0f\\u5973\\u751f\\u5728\\u95ee\\uff0c\\u8fd9\\u91cc\\u6709\\u300a\\u4e5d\\u4e91\\u68a6\\u300b\\u5417\\uff1f\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"660888701821500154\"},\"type\":\"image\",\"id\":\"660888701418846673_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}}]}","date":"2015-11-22T05:12:27.377Z","updated":"2015-11-22T05:12:27.377Z","path":"instagram/ins2.json","layout":"false","title":"","comments":1,"_id":"cimigpysr002c6cujqnhuhr6i"},{"_content":"{\"pagination\":{\"next_url\":\"https:\\/\\/api.instagram.com\\/v1\\/users\\/438522285\\/media\\/recent?count=100\\u0026callback=jQuery19008141340191941708_1433432491285\\u0026client_id=956dd096b6e5496aba6662165b9b8443\\u0026max_id=762309207182785278_438522285\\u0026_=1433432491286\",\"next_max_id\":\"762309207182785278_438522285\"},\"meta\":{\"code\":200},\"data\":[{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":1,\"data\":[{\"created_time\":\"1411210501\",\"text\":\"hi~\",\"from\":{\"username\":\"hawaiiboyzshelwin\",\"profile_picture\":\"https:\\/\\/igcdn-photos-h-a.akamaihd.net\\/hphotos-ak-xap1\\/t51.2885-19\\/10948635_702403553211063_1668445983_a.jpg\",\"id\":\"293705161\",\"full_name\":\"Hawaii\"},\"id\":\"813615113719495343\"}]},\"filter\":\"Mayfair\",\"created_time\":\"1411177261\",\"link\":\"https:\\/\\/instagram.com\\/p\\/tJjQlAo7kH\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/925287_1464119273867077_427071626_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/925287_1464119273867077_427071626_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/925287_1464119273867077_427071626_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1411177261\",\"text\":\"\\u6c89\\u7720\\u7684\\u5e97\\u4e3b\\u5931\\u7720\\u7684\\u72d7\\u3002\\u60f3\\u8d77\\u5927\\u5b66\\u7684\\u6700\\u540e\\u65f6\\u5149\\uff0c\\u5bbf\\u820d24\\u5c0f\\u65f6\\u90fd\\u6709\\u4eba\\u9192\\u7740\\uff0c\\u81ea\\u7531\\u7684\\u4eba\\u751f\\uff0c\\u81ea\\u7531\\u7684\\u9152\\u548c\\u66f2\\u7ec8\\u4eba\\u6563\\uff0c\\u5927\\u5bb6\\u901a\\u5e38\\u6ca1\\u6709\\u53e6\\u4e00\\u534a\\uff0c\\u6ca1\\u6709\\u94b1\\uff0c\\u6ca1\\u6709\\u5fe7\\u6101\\uff0c\\u723d\\u6210\\u72d7\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"813336279132649576\"},\"type\":\"image\",\"id\":\"813336278595778823_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Hefe\",\"created_time\":\"1410970444\",\"link\":\"https:\\/\\/instagram.com\\/p\\/tDYyUeo7oX\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/925284_1534308033454310_855505111_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/925284_1534308033454310_855505111_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/925284_1534308033454310_855505111_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410970444\",\"text\":\"\\u5982\\u679c\\u4ed6\\u662f\\u7a0b\\u5e8f\\u5458\\u2026\\nvar date = lifetime;\\rif(rotate(mountain, water, stupa)){ \\/*return nextLifetime;*\\/ return meetyou(journey);\\r}\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"811601369455900672\"},\"type\":\"image\",\"id\":\"811601368935807511_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1410924584\",\"link\":\"https:\\/\\/instagram.com\\/p\\/tCBULHo7sW\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/10666267_1550871771803214_2074300649_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/10666267_1550871771803214_2074300649_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/10666267_1550871771803214_2074300649_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410924584\",\"text\":\"\\u542c\\u7740\\u5c71\\u5be8\\u7684\\u6c11\\u8c23\\u7535\\u5b50\\u4e50\\uff0c\\u770b\\u7740\\u7f8e\\u597d\\u7684\\u59d1\\u5a18\\u3002\\u529f\\u5fb7\\u65e0\\u91cf\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"811216667700083459\"},\"type\":\"image\",\"id\":\"811216667255487254_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":1,\"data\":[{\"created_time\":\"1411008352\",\"text\":\"\\u6bcf\\u5929\\u90fd\\u8ba9\\u5750\\u5728\\u7535\\u8111\\u524d\\u7684\\u6211\\u76f8\\u4fe1\\u751f\\u6d3b\",\"from\":{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"},\"id\":\"811919369774020696\"}]},\"filter\":\"Mayfair\",\"created_time\":\"1410923563\",\"link\":\"https:\\/\\/instagram.com\\/p\\/tB_Xmao7qG\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s320x320\\/e15\\/10693244_734401199942901_1572709880_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s150x150\\/e15\\/10693244_734401199942901_1572709880_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/e15\\/10693244_734401199942901_1572709880_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410923563\",\"text\":\"\\u5f25\\u91cc\\u5858\\u592a\\u5b81\\u9759\\u3002\\u5728\\u8fd9\\u6211\\u4e00\\u76f4\\u60f3\\u8d77\\u6bcf\\u4e00\\u4e2a\\u88ab\\u6df1\\u5733\\u8f66\\u6c34\\u9a6c\\u9f99\\u58f0\\u5435\\u9192\\u7684\\u65e9\\u6668\\uff0c\\u771f\\u662f\\u5149\\u8f89\\u7684\\u5c81\\u6708\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"811208107217893670\"},\"type\":\"image\",\"id\":\"811208106630691462_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1410794550\",\"text\":\"\\u9ad8\\u539f\\u53cd\\u5e94\\u4e25\\u91cd\\u5417\\uff1fP.S. \\u963f\\u817e\\u4f60\\u5565\\u65f6\\u5019\\u56de\\u6765\\uff1f\",\"from\":{\"username\":\"winiex\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_45182020_75sq_1380706182.jpg\",\"id\":\"45182020\",\"full_name\":\"winiex nie\"},\"id\":\"810125861157321531\"},{\"created_time\":\"1410923814\",\"text\":\"@winiex \\u54c8\\u54c8\\uff0c\\u6ca1\\u4ec0\\u4e48\\u53cd\\u5e94\\u53ea\\u8981\\u6211\\u4e0d\\u4e71\\u8dd1\\u52a8\\u3002\\u5f88\\u5feb\\u56de\\u6765\\u4e86\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"811210206056004013\"}]},\"filter\":\"Normal\",\"created_time\":\"1410737336\",\"link\":\"https:\\/\\/instagram.com\\/p\\/s8cKzLI7pM\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/10693771_1517437541834868_665867908_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/10693771_1517437541834868_665867908_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/10693771_1517437541834868_665867908_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410737336\",\"text\":\"\\u8fdb\\u85cf\\u3002\\u5929\\u7a7a\\u6302\\u6ee1\\u7740\\u4e91\\uff0c\\u9ed1\\u7684\\u767d\\u7684\\u90fd\\u6709\\u3002\\u4e91\\u6735\\u8f6c\\u773c\\u98d8\\u6563\\uff0c\\u5b83\\u5374\\u4f9d\\u7136\\u662f\\u84dd\\u8272\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"809645920867301928\"},\"type\":\"image\",\"id\":\"809645920464648780_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"videos\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t50.2886-16\\/10701710_281586128699201_335902712_a.mp4\",\"width\":480,\"height\":480},\"low_bandwidth\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t50.2886-16\\/10701471_605249519584920_450596792_s.mp4\",\"width\":480,\"height\":480},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t50.2886-16\\/10701900_770932669629703_1501695708_n.mp4\",\"width\":640,\"height\":640}},\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Stinson\",\"created_time\":\"1410688270\",\"link\":\"https:\\/\\/instagram.com\\/p\\/s6-lOFo7ip\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xta1\\/t51.2885-15\\/s320x320\\/e15\\/10693822_497709657032441_1125408654_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xta1\\/t51.2885-15\\/s150x150\\/e15\\/10693822_497709657032441_1125408654_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xta1\\/t51.2885-15\\/e15\\/10693822_497709657032441_1125408654_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410688270\",\"text\":\"\\u201c\\u97f3\\u6d6a\\u592a\\u5f3a\\u4e0d\\u6643\\u4f1a\\u88ab\\u649e\\u5230\\u5730\\u4e0a\\u2026\\u201d\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"809234320184293724\"},\"type\":\"video\",\"id\":\"809234319697754281_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1410625333\",\"link\":\"https:\\/\\/instagram.com\\/p\\/s5GifkI7q7\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s320x320\\/e15\\/10683941_796597910390683_12441123_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s150x150\\/e15\\/10683941_796597910390683_12441123_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/e15\\/10683941_796597910390683_12441123_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410625333\",\"text\":\"\\u964c\\u751f\\u7684\\u670b\\u53cb\\uff0c\\u613f\\u4e0b\\u6b21\\u518d\\u80fd\\u4e0e\\u4f60\\u4eec\\u76f8\\u805a\\u5728\\u4e3d\\u6c5flove wine \\u0026 half\\u3002\\u6211\\u65e0\\u6cd5\\u878d\\u89e3\\u4f60\\u60b2\\u89c2\\u73b0\\u5b9e\\u7684\\u60f3\\u6cd5\\uff0c\\u4f60\\u4e5f\\u65e0\\u6cd5\\u8bf4\\u670d\\u6211\\u65c5\\u884c\\u5e76\\u4e0d\\u662f\\u9003\\u907f\\u3002\\u4f46\\u8fd9\\u90fd\\u5f88\\u6709\\u610f\\u601d\\u3002\\u53ea\\u662f\\u60f3\\u8d77\\u4ee5\\u524d\\u6709\\u4e2a\\u4eba\\u53eb\\u6211\\u4e0d\\u80fd\\u559d\\u592a\\u591a\\u7684\\u9152\\uff0c\\u4e00\\u60f3\\u5230\\u8fd9\\u4e2a\\u5440\\u6211\\u5c31\\u8d8a\\u559d\\u8d8a\\u591a\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"808706367646054518\"},\"type\":\"image\",\"id\":\"808706366723308219_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"videos\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t50.2886-16\\/10701691_550252955102921_1153150516_a.mp4\",\"width\":480,\"height\":480},\"low_bandwidth\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/l\\/t50.2886-16\\/10705857_251763575033861_1402444343_s.mp4\",\"width\":480,\"height\":480},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t50.2886-16\\/10701411_275533589303527_2032117818_n.mp4\",\"width\":640,\"height\":640}},\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1410668529\",\"text\":\"\\u54c7\\uff0cgood,\\u4f60\\u8bf7\\u5047\\u53bb\\u65c5\\u6e38\\u7684\\u5417\",\"from\":{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"},\"id\":\"809068726839392635\"},{\"created_time\":\"1410706116\",\"text\":\"@zheng_ji \\u662f\\u5440\\uff0c\\u653e\\u677e\\u4e0b\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"809384027007203495\"}]},\"filter\":\"Normal\",\"created_time\":\"1410579121\",\"link\":\"https:\\/\\/instagram.com\\/p\\/s3uZcmo7uj\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10661142_164227523747936_1526737465_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10661142_164227523747936_1526737465_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10661142_164227523747936_1526737465_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410579121\",\"text\":\"\\u7389\\u9f99\\u96ea\\u5c71\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"808318717479074388\"},\"type\":\"video\",\"id\":\"808318716975758243_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1410629707\",\"text\":\"\\u53bb\\u675f\\u6cb3\\u4e86\\u5417\",\"from\":{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"},\"id\":\"808743058343704606\"},{\"created_time\":\"1410706038\",\"text\":\"@sasanzuo \\u53bb\\u4e86\\uff0c\\u4e3d\\u6c5f\\u6700\\u559c\\u6b22\\u675f\\u6cb3\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"809383369692657787\"}]},\"filter\":\"Normal\",\"created_time\":\"1410535625\",\"link\":\"https:\\/\\/instagram.com\\/p\\/s2bb5io7p-\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/s320x320\\/e15\\/10661182_550889531706942_2043749716_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/s150x150\\/e15\\/10661182_550889531706942_2043749716_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/e15\\/10661182_550889531706942_2043749716_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410535625\",\"text\":\"\\u4ee5\\u524d\\u60f3\\u53bb\\u4e3d\\u6c5f\\uff0c\\u4f46\\u53bb\\u8fc7\\u7684\\u4eba\\u90fd\\u704c\\u8f93\\u7740\\u4f60\\u4e5f\\u8bb8\\u4f1a\\u5931\\u671b\\u7684\\u89c2\\u5ff5\\uff0c\\u56e0\\u800c\\u751a\\u81f3\\u4e0d\\u6562\\u52a8\\u8eab\\u3002\\u8fd9\\u662f\\u4e00\\u79cd\\u201c\\u6015\\u201d\\u3002\\u6709\\u65f6\\u5019\\u771f\\u5f97\\u81ea\\u5df1\\u53bb\\u770b\\u770b\\u624d\\u4f1a\\u4e86\\u7136\\u3002\\u7b2c\\u4e00\\u5929\\u5728\\u4e3d\\u6c5f\\uff0c\\u6c11\\u8c23\\u5409\\u4ed6\\u7f13\\u7f13\\u6d41\\u8fc7\\u5546\\u4e1a\\u5316\\u7684\\u8857\\u9053\\uff0c\\u539f\\u6765\\u6ca1\\u6709\\u60ca\\u559c\\uff0c\\u4e5f\\u6ca1\\u6709\\u5931\\u671b\\uff0c\\u4e00\\u5207\\u521a\\u521a\\u597d\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"807953848229673047\"},\"type\":\"image\",\"id\":\"807953847625693822_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"videos\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t50.2886-16\\/10687579_864566316888364_601110692_a.mp4\",\"width\":480,\"height\":480},\"low_bandwidth\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t50.2886-16\\/10705731_491458530957700_895623007_s.mp4\",\"width\":480,\"height\":480},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t50.2886-16\\/10701554_631893030261190_220785276_n.mp4\",\"width\":640,\"height\":640}},\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Maven\",\"created_time\":\"1410529596\",\"link\":\"https:\\/\\/instagram.com\\/p\\/s2P72tI7o6\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"winiex\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_45182020_75sq_1380706182.jpg\",\"id\":\"45182020\",\"full_name\":\"winiex nie\"},{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/10520334_1523531751215211_1344090061_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/10520334_1523531751215211_1344090061_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/10520334_1523531751215211_1344090061_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410529596\",\"text\":\"\\u6211\\u6ce8\\u5b9a\\u8981\\u56de\\u5230\\u8001\\u8def\\u4e0a\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"807903268480203532\"},\"type\":\"video\",\"id\":\"807903267045751354_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":5,\"data\":[{\"created_time\":\"1410529334\",\"text\":\"\\u7ec8\\u4e8e\\u53d1\\u73b0\\u4e86\\u963f\\u817e\\u7684 Instagram:)\",\"from\":{\"username\":\"winiex\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_45182020_75sq_1380706182.jpg\",\"id\":\"45182020\",\"full_name\":\"winiex nie\"},\"id\":\"807901070295808629\"},{\"created_time\":\"1410534900\",\"text\":\"@winiex \\u54c8\\u54c8\\uff0c\\u8bf4\\u5b9e\\u8bdd\\u2026\\u5fae\\u535a\\u548c\\u5fae\\u4fe1\\u52a0\\u4e86\\u5f88\\u591a\\u540c\\u4e8b\\uff0c\\u603b\\u611f\\u89c9\\u4e0d\\u81ea\\u5728\\uff0c\\u5c31\\u7528ins\\u6bd4\\u8f83\\u591a\\u4e86\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"807947760767842994\"},{\"created_time\":\"1410537411\",\"text\":\"@litten225 \\u662f\\u8bf4\\u524d\\u6bb5\\u65f6\\u95f4\\u5ffd\\u7136\\u60f3\\u8d77\\u6765\\u4e0a\\u8001\\u6ca1\\u770b\\u5230\\u4f60\\u52a8\\u9759\\u5462;)\\u3002\\u53ef\\u80fd\\u516c\\u53f8\\u5927\\u4e86\\uff0c\\u670b\\u53cb\\u90fd\\u5982\\u725b\\u6392\\uff0c\\u4e03\\u5206\\u719f\\u6700\\u4f73:)\\u3002\",\"from\":{\"username\":\"winiex\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_45182020_75sq_1380706182.jpg\",\"id\":\"45182020\",\"full_name\":\"winiex nie\"},\"id\":\"807968828790388817\"},{\"created_time\":\"1410537434\",\"text\":\"\\u5fae\\u535a\\u4e0a\\uff0ctypo \\u5566\",\"from\":{\"username\":\"winiex\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_45182020_75sq_1380706182.jpg\",\"id\":\"45182020\",\"full_name\":\"winiex nie\"},\"id\":\"807969017861224538\"},{\"created_time\":\"1410571556\",\"text\":\"@winiex \\u662f\\u554a\\uff0c\\u8ddf\\u540c\\u5b66\\u53ef\\u4ee5\\u4e00\\u8d77\\u5410\\u69fd\\u8001\\u5e08\\u548c\\u6559\\u5b66\\uff0c\\u771f\\u5b9e\\u7684\\u60f3\\u6cd5\\u65e0\\u9700\\u987e\\u8651\\u3002\\u4f46\\u662f\\u8ddf\\u540c\\u4e8b\\u4e00\\u8d77\\u5410\\u69fd\\u8001\\u5927\\u548c\\u5de5\\u4f5c\\uff0c\\u53c8\\u662f\\u53e6\\u5916\\u4e00\\u56de\\u4e8b\\u4e86\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"808255256711641620\"}]},\"filter\":\"Normal\",\"created_time\":\"1410523991\",\"link\":\"https:\\/\\/instagram.com\\/p\\/s2FPpGI7o_\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xta1\\/t51.2885-15\\/s320x320\\/e15\\/10693390_547748238660649_761529890_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xta1\\/t51.2885-15\\/s150x150\\/e15\\/10693390_547748238660649_761529890_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xta1\\/t51.2885-15\\/e15\\/10693390_547748238660649_761529890_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410523991\",\"text\":\"\\u5f69\\u4e91\\u4e4b\\u5357\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"807856248839190621\"},\"type\":\"image\",\"id\":\"807856248310708799_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1410493579\",\"link\":\"https:\\/\\/instagram.com\\/p\\/s1LPQPo7v8\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"wallbase.hd\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/10617029_283951291805046_1229690122_a.jpg\",\"id\":\"1489501811\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s320x320\\/e15\\/10693650_837768039589771_1793184733_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s150x150\\/e15\\/10693650_837768039589771_1793184733_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/e15\\/10693650_837768039589771_1793184733_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410493579\",\"text\":\"\\u4e91\\u5357\\uff0c\\u5411\\u5f80\\u5df2\\u4e45\\u7684\\u5730\\u65b9\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"807601135591602253\"},\"type\":\"image\",\"id\":\"807601134928903164_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Lo-fi\",\"created_time\":\"1410433815\",\"link\":\"https:\\/\\/instagram.com\\/p\\/szZP5Io7lY\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"wallbase.hd\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/10617029_283951291805046_1229690122_a.jpg\",\"id\":\"1489501811\",\"full_name\":\"\"},{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xft1\\/t51.2885-15\\/s320x320\\/e15\\/914812_1529561143923493_1662159287_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xft1\\/t51.2885-15\\/s150x150\\/e15\\/914812_1529561143923493_1662159287_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xft1\\/t51.2885-15\\/e15\\/914812_1529561143923493_1662159287_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410433815\",\"text\":\"QQ\\u540c\\u65f6\\u5728\\u7ebf\\u4eba\\u6570\\u78342\\u4ebf\\u7eaa\\u5ff5\\uff0c\\u4f5c\\u4e3a\\u4e00\\u9897\\u5c0f\\u5c0f\\u87ba\\u4e1d\\u9489\\uff0c\\u540d\\u5b57\\u6b63\\u597d\\u9576\\u5230\\u4f01\\u9e45\\u7684\\u5927\\u5634\\u5df4\\u4e0a\\u3002\\u8fd9\\u65f6\\u89c9\\u5f97\\u6709\\u4e00\\u4e1d\\u5149\\u8363\\uff0c\\u4e00\\u79cd\\u52aa\\u529b\\u88ab\\u5b9e\\u5316\\u7684\\u9519\\u89c9\\uff1b\\u7136\\u540e\\u53c8\\u6709\\u70b9\\u4e0d\\u8212\\u670d\\uff0c\\u611f\\u89c9\\u6b64\\u65f6\\u7684\\u81ea\\u5df1\\uff0c\\u548c\\u540d\\u5b57\\u8eab\\u8fb9\\u7684\\u4eba\\u4e00\\u6837\\u3002\\u53ef\\u6211\\u60f3\\u8981\\u7684\\u5c31\\u662f\\u4e0d\\u4e00\\u6837\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"807099801993984938\"},\"type\":\"image\",\"id\":\"807099801532610904_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":1,\"data\":[{\"created_time\":\"1410373253\",\"text\":\"\\u4e00\\u8d77\\u73a9INS\\ue328\\ue328@gggiselle3333\",\"from\":{\"username\":\"yokiaee\",\"profile_picture\":\"https:\\/\\/igcdn-photos-h-a.akamaihd.net\\/hphotos-ak-xfa1\\/t51.2885-19\\/10598222_301874203326431_1095562300_a.jpg\",\"id\":\"1450755432\",\"full_name\":\"\\u7cd6\\u5b9d\"},\"id\":\"806591765504309560\"}]},\"filter\":\"Sierra\",\"created_time\":\"1410184482\",\"link\":\"https:\\/\\/instagram.com\\/p\\/sr9rtNo7lM\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"},{\"username\":\"fiona2523\",\"profile_picture\":\"https:\\/\\/igcdn-photos-a-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11350911_404317656438368_954826284_a.jpg\",\"id\":\"465984487\",\"full_name\":\"\\ud83c\\udf38Fiona\\ud83c\\udf38\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/10644019_368509079979549_2085033896_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/10644019_368509079979549_2085033896_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/10644019_368509079979549_2085033896_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410184482\",\"text\":\"\\u966a\\u4f34\\u4e00\\u5b9a\\u5f97\\u662f\\u4ef6\\u6f2b\\u957f\\u7684\\u4e8b\\u5475\\u3002\\u548c\\u5976\\u5976\\u5728\\u4e00\\u8d77\\u7684\\u4e2d\\u79cb\\u8282\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"805008243199032014\"},\"type\":\"image\",\"id\":\"805008242737658188_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"videos\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t50.2886-16\\/10687823_350153388474464_1223789041_a.mp4\",\"width\":480,\"height\":480},\"low_bandwidth\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t50.2886-16\\/10701732_344063979085756_1879637417_s.mp4\",\"width\":480,\"height\":480},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t50.2886-16\\/10688739_629114507205181_1066132726_n.mp4\",\"width\":640,\"height\":640}},\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Maven\",\"created_time\":\"1410183340\",\"link\":\"https:\\/\\/instagram.com\\/p\\/sr7gXKI7h_\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10684161_918887498139099_2081383304_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10684161_918887498139099_2081383304_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10684161_918887498139099_2081383304_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410183340\",\"text\":\"\\u4e2d\\u79cb\\u548c\\u5bb6\\u4eba\\u4e00\\u8d77\\u53bb\\u770b\\u5b54\\u660e\\u706f\\uff0c\\u70ed\\u95f9\\u800c\\u5b89\\u9038\\uff0c\\u8fd9\\u662f\\u5c0f\\u57ce\\u5e02\\u7684\\u7f8e\\u597d\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"804998667946932332\"},\"type\":\"video\",\"id\":\"804998667049351295_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1410239540\",\"text\":\"\\u8bf4\\u7684\\u6211\\u4e5f\\u52a8\\u5bb9\\u4e86\",\"from\":{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"},\"id\":\"805470101433465439\"},{\"created_time\":\"1410359659\",\"text\":\"@zheng_ji \\u4e00\\u5207\\u597d\\u795e\\u5947\\uff0c\\u5c31\\u662f\\u8d70\\u5230\\u90a3\\uff0c\\u53d1\\u73b0\\u5979\\u8fd8\\u5728\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"806477733090801988\"}]},\"filter\":\"Unknown\",\"created_time\":\"1410155775\",\"link\":\"https:\\/\\/instagram.com\\/p\\/srG7fjo7sV\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/s320x320\\/e15\\/10683828_327931784041264_894089329_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/s150x150\\/e15\\/10683828_327931784041264_894089329_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/e15\\/10683828_327931784041264_894089329_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410155775\",\"text\":\"\\u8001\\u5bb6\\u7684\\u8461\\u8404\\u85e4\\uff0c\\u4ece\\u6211\\u521d\\u4e2d\\u65f6\\u5c31\\u6302\\u5728\\u8fd9\\uff0c\\u518d\\u89c1\\u5df2\\u662f\\u5341\\u4e00\\u5e74\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"804767435447318654\"},\"type\":\"image\",\"id\":\"804767435027888917_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1410085359\",\"link\":\"https:\\/\\/instagram.com\\/p\\/spAnrio7oh\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/s320x320\\/e15\\/10666028_872988212713750_1345360858_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/s150x150\\/e15\\/10666028_872988212713750_1345360858_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/e15\\/10666028_872988212713750_1345360858_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410085359\",\"text\":\"\\u5bb6\\u91cc\\u6a44\\u6984\\u719f\\u4e86\\uff0c\\u76d0\\u6e0d\\uff0c\\u66b4\\u6652\\uff0c\\u8638\\u871c\\uff0c\\u7b80\\u76f4\\u4eba\\u95f4\\u7f8e\\u5473!\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"804176735760529648\"},\"type\":\"image\",\"id\":\"804176735273990689_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1409914668\",\"text\":\"\\u4e2d\\u79cb\\u795d\\u597d\",\"from\":{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"},\"id\":\"802744876627376939\"},{\"created_time\":\"1410085406\",\"text\":\"@zheng_ji \\u4e2d\\u79cb\\u8282\\u5feb\\u4e50\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"804177137474189571\"}]},\"filter\":\"Lo-fi\",\"created_time\":\"1409913076\",\"link\":\"https:\\/\\/instagram.com\\/p\\/sj4BGgI7t_\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10665501_1452353738387652_2075798065_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10665501_1452353738387652_2075798065_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10665501_1452353738387652_2075798065_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1409913076\",\"text\":\"\\u5728\\u4e00\\u573a\\u592a\\u9633\\u96e8\\u91cc\\u56de\\u5230\\u5bb6\\u4e2d\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"802731525369215150\"},\"type\":\"image\",\"id\":\"802731524907842431_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":5,\"data\":[{\"created_time\":\"1409495738\",\"text\":\"\\u5929\\u5929\\u5728\\u88ab\\u670d\\u52a1\\u5668\\u8650\\u6ca1\\u4e2a\\u4eba\\u65f6\\u95f4\\u4e86\",\"from\":{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"},\"id\":\"799230636918553169\"},{\"created_time\":\"1409537231\",\"text\":\"\\u4f60\\u53bb\\u542c\\u542c\\u91ce\\u5b69\\u5b50\\uff0c\\u5f20\\u73ae\\u73ae\\u90ed\\u9f99\\u7684\\u767d\\u94f6\\u996d\\u5e97\\u548c\\u6211\\u7b49\\u7740\\u4f60\\u56de\\u6765\\uff0c\\u770b\\u770b\\u662f\\u5426\\u559c\\u6b22\\u8fd9\\u79cd\\u98ce\\u683c\\u3002\",\"from\":{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"},\"id\":\"799578708500527379\"},{\"created_time\":\"1409913295\",\"text\":\"@sasanzuo \\u6211\\u542c\\u6c11\\u8c23\\u6bd4\\u8f83\\u591a\\uff0c\\u674e\\u5fd7\\u5f20\\u73ae\\u73ae\\u4e00\\u76f4\\u5f88\\u559c\\u6b22\\u5450\\uff0c\\u91ce\\u5b69\\u5b50\\u5c31\\u542c\\u5f97\\u5f88\\u5c11\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"802733361660672253\"},{\"created_time\":\"1409913403\",\"text\":\"@zheng_ji \\u8fd9\\u4e48\\u60e8\\uff1f\\u8d76\\u7d27\\u9a6f\\u670d\\u5b83\\uff01\\u4e00\\u5207\\u78e8\\u4eba\\u7684\\u670d\\u52a1\\u5668\\u90fd\\u662f\\u7eb8\\u8001\\u864e\\uff01\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"802734270063032609\"},{\"created_time\":\"1409917831\",\"text\":\"@litten225 \\u554a\\u90a3\\u6709\\u8bdd\\u804a\\uff0c\\u4ed6\\u4eec\\u90fd\\u662f\\u6211\\u5f88\\u597d\\u7684\\u670b\\u53cb\",\"from\":{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"},\"id\":\"802771409702206463\"}]},\"filter\":\"Unknown\",\"created_time\":\"1409495189\",\"link\":\"https:\\/\\/instagram.com\\/p\\/sXa9g6I7jB\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/s320x320\\/e15\\/10654876_610857929023752_364709543_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/s150x150\\/e15\\/10654876_610857929023752_364709543_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/e15\\/10654876_610857929023752_364709543_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1409495189\",\"text\":\"\\u5728\\u4e66\\u5e97\\u7684\\u665a\\u4e0a\\u7ec8\\u4e8e\\u628a\\u65b0\\u4e13\\u53cd\\u590d\\u542c\\u5b8c\\u3002\\u592a\\u67d4\\u4e86\\u2026\\u6253\\u4e00\\u661f\\u4e24\\u661f\\u7684\\u4eba\\u80af\\u5b9a\\u662f\\u771f\\u7231\\u7c89\\uff0c\\u8fd9\\u70b9\\u6709\\u4eba\\u6562\\u6000\\u7591\\uff1f\\u6211\\u4e0d\\u662f\\uff0c\\u6253\\u56db\\u661f\\uff01\\u505c\\u4e0d\\u4e0b\\u6765\\uff0c\\u76f4\\u5230\\u4e66\\u5e97\\u54cd\\u8d77:\\u6df1\\u5733\\u5373\\u5c06\\u5165\\u7720\\u3002\\u4f4622\\u70b9\\u8fd8\\u662f\\u6df1\\u5733\\u7684\\u65e9\\u6668\\u5440\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"799226037537061117\"},\"type\":\"image\",\"id\":\"799226035314079937_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"videos\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t50.2886-16\\/10619367_685656154851110_766778884_a.mp4\",\"width\":480,\"height\":480},\"low_bandwidth\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t50.2886-16\\/10655768_594287900680172_2084417441_s.mp4\",\"width\":480,\"height\":480},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t50.2886-16\\/10648015_1491243041113750_339844084_n.mp4\",\"width\":640,\"height\":640}},\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1409238867\",\"text\":\"\\u554a\\u9f13\\u624b\\u662f\\u6211\\u597d\\u670b\\u53cb\",\"from\":{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"},\"id\":\"797075846717487722\"},{\"created_time\":\"1409495262\",\"text\":\"@sasanzuo \\u771f\\u597d\\uff01\\u4f60\\u6709\\u8fd9\\u6837\\u7684\\u670b\\u53cb\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"799226645367208237\"}]},\"filter\":\"Stinson\",\"created_time\":\"1409236676\",\"link\":\"https:\\/\\/instagram.com\\/p\\/sPt4u4I7kA\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s320x320\\/e15\\/10644013_777642448965989_544517718_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s150x150\\/e15\\/10644013_777642448965989_544517718_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/e15\\/10644013_777642448965989_544517718_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1409236676\",\"text\":\"\\u6162\\u4e09\\u7684\\u534e\\u5c14\\u5179\\uff0c\\u5927\\u7bc7\\u5e45\\u7684\\u7235\\u58eb\\u5373\\u5174\\u3002\\u611f\\u89c9\\u751f\\u6d3b\\u5f97\\u592a\\u6d6e\\u8e81\\u3002\\u4e5f\\u592a\\u5b89\\u9038\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"797057470305646918\"},\"type\":\"video\",\"id\":\"797057469785553152_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Lo-fi\",\"created_time\":\"1408804690\",\"link\":\"https:\\/\\/instagram.com\\/p\\/sC18G0o7qb\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtf1\\/t51.2885-15\\/s320x320\\/e15\\/924456_1471485796442896_1699836323_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtf1\\/t51.2885-15\\/s150x150\\/e15\\/924456_1471485796442896_1699836323_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtf1\\/t51.2885-15\\/e15\\/924456_1471485796442896_1699836323_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1408804690\",\"text\":\"\\u597d\\u4e45\\u6ca1\\u770b\\u8bdd\\u5267\\uff0c\\u8fd9\\u90e8\\u679c\\u7136\\u6ca1\\u8ba9\\u4eba\\u5931\\u671b\\u3002\\u5bfc\\u6f14\\u592a\\u4f1a\\u8bb2\\u6545\\u4e8b\\u4e86\\uff0c1024\\u4e2a\\u8d5e\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"793433712932141876\"},\"type\":\"image\",\"id\":\"793433711329917595_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Hefe\",\"created_time\":\"1408715905\",\"link\":\"https:\\/\\/instagram.com\\/p\\/sAMmEWI7oC\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10607913_692632367472666_1829853902_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10607913_692632367472666_1829853902_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10607913_692632367472666_1829853902_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1408715905\",\"text\":\"\\u7eb5\\u6709\\u4e00\\u4e07\\u79cd\\u60b2\\u4f24\\u7684\\u7f8e\\u4e3d\\uff0c\\u4e5f\\u6bd4\\u4e0d\\u8fc7\\u8fd9\\u6bb5\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"792688927703284532\"},\"type\":\"image\",\"id\":\"792688926981863938_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"X-Pro II\",\"created_time\":\"1408282865\",\"link\":\"https:\\/\\/instagram.com\\/p\\/rzSow4o7lH\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/10611052_1466241683635233_830264506_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/10611052_1466241683635233_830264506_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/10611052_1466241683635233_830264506_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1408282865\",\"text\":\"\\u5728\\u4e66\\u57ce\\u91cc\\u770b\\u5230\\u7684\\u003c\\u540e\\u4f1a\\u65e0\\u671f\\u003e\\u5206\\u955c\\u56fe\\u3002\\u7535\\u5f71\\u90a3\\u4e48\\u7f8e\\uff0c\\u5206\\u955c\\u662f\\u8fd9\\u6837\\uff0c\\u8fd9\\u5c31\\u662f\\u73b0\\u5b9e~\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"789056326245530503\"},\"type\":\"image\",\"id\":\"789056325826099527_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Hudson\",\"created_time\":\"1407932800\",\"link\":\"https:\\/\\/instagram.com\\/p\\/ro28LPI7oc\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s320x320\\/e15\\/10617144_829548960388746_1611410337_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s150x150\\/e15\\/10617144_829548960388746_1611410337_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/e15\\/10617144_829548960388746_1611410337_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1407932800\",\"text\":\"\\u5982\\u679c\\u4f60\\u4ece\\u5317\\u4eac\\u6765\\u770b\\u6211\\uff0c\\u6211\\u4f1a\\u5f88\\u611f\\u52a8;\\u5982\\u679c\\u4f60\\u50cf\\u5149\\uff0c\\u4ece\\u592a\\u9633\\u90a3\\u5934\\u8fc7\\u6765\\uff0c\\u6211\\u4e0d\\u4ee5\\u4e3a\\u7136\\u3002\\u56e0\\u4e3a\\u5149\\u5230\\u5730\\u7403\\u53ea\\u89818.3\\u5206\\u949f\\u3002\\u6211\\u4eec\\u7ecf\\u5e38\\u9519\\u7528\\u4ee3\\u4ef7\\u6765\\u8861\\u91cf\\u60c5\\u611f\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"786119765132556496\"},\"type\":\"image\",\"id\":\"786119764721515036_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1407328697\",\"text\":\"\\u5bb6\\u91cc\\u4eba\\u5417\",\"from\":{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"},\"id\":\"781052182645685044\"},{\"created_time\":\"1408283949\",\"text\":\"@zheng_ji \\u5bf9\\uff0c\\u6765\\u6df1\\u5733\\u73a9\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"789065414052395483\"}]},\"filter\":\"Nashville\",\"created_time\":\"1407161569\",\"link\":\"https:\\/\\/instagram.com\\/p\\/rR37wLo7iu\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/10453953_542161702576881_1621059386_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/10453953_542161702576881_1621059386_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/10453953_542161702576881_1621059386_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1407161569\",\"text\":\"\\u76f8\\u805a\\u603b\\u6709\\u65f6:)\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"779650209673361431\"},\"type\":\"image\",\"id\":\"779650209253931182_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":1,\"data\":[{\"created_time\":\"1406438900\",\"text\":\"\\u4eba\\u554a\",\"from\":{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"},\"id\":\"773588027516893195\"}]},\"filter\":\"Lo-fi\",\"created_time\":\"1406343109\",\"link\":\"https:\\/\\/instagram.com\\/p\\/q5e2KpI7qn\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s320x320\\/e15\\/925559_1482425071996009_1940959046_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s150x150\\/e15\\/925559_1482425071996009_1940959046_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/e15\\/925559_1482425071996009_1940959046_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1406343109\",\"text\":\"\\u968f\\u4fbf\\u8d70\\u8d70\\uff0c\\u53d1\\u73b0\\u4e16\\u754c\\u8fd8\\u662f\\u5f88\\u7f8e\\u597d\\u7684\\u3002\\u5f53\\u62e5\\u6709\\u7f8e\\u597d\\u4e8b\\u7269\\u65f6\\uff0c\\u7ecf\\u5e38\\u4e60\\u60ef\\u6027\\u7684\\u719f\\u89c6\\u65e0\\u7779;\\u5f53\\u52aa\\u529b\\u6293\\u4f4f\\u4f60\\u60f3\\u8981\\u7684\\u4e1c\\u897f\\u65f6\\uff0c\\u5b83\\u53c8\\u53ef\\u80fd\\u77ac\\u95f4\\u7834\\u788e\\u3002\\u4f46\\u4f9d\\u65e7\\u9700\\u8981\\u4e0d\\u59a5\\u534f\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"772784475122940015\"},\"type\":\"image\",\"id\":\"772784474745453223_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Valencia\",\"created_time\":\"1406104308\",\"link\":\"https:\\/\\/instagram.com\\/p\\/qyXXpNI7q5\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"dingstyle\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_30683156_75sq_1333592929.jpg\",\"id\":\"30683156\",\"full_name\":\"Linjie\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s320x320\\/e15\\/10554006_501929086608023_917623457_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s150x150\\/e15\\/10554006_501929086608023_917623457_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/e15\\/10554006_501929086608023_917623457_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1406104308\",\"text\":\"\\u8354\\u679d\\u2014\\u2014\\u6211\\u5fc3\\u76ee\\u4e2d\\u7684\\u6c34\\u679c\\u4e4b\\u738b\\uff08\\u6709\\u4e4b\\u4e00\\uff09\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"770781266472843689\"},\"type\":\"image\",\"id\":\"770781266095356601_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Unknown\",\"created_time\":\"1406074922\",\"link\":\"https:\\/\\/instagram.com\\/p\\/qxfUe0I7lp\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/10576105_624878090953161_638111947_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/10576105_624878090953161_638111947_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/10576105_624878090953161_638111947_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1406074922\",\"text\":\"\\u9ad8\\u4e2d\\u65f6\\u4ee3\\u6700\\u65b0\\u6b3e\\u7684mp4\\uff0c\\u73b0\\u5df2\\u6210\\u4e86\\u8001\\u53e4\\u8463\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"770534759307917387\"},\"type\":\"image\",\"id\":\"770534758175455593_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Unknown\",\"created_time\":\"1405855985\",\"link\":\"https:\\/\\/instagram.com\\/p\\/qq9usdo7hr\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10570119_332808380211109_125412512_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10570119_332808380211109_125412512_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10570119_332808380211109_125412512_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1405855985\",\"text\":\"\\u53f0\\u98ce\\u6765\\u4e34\\u65f6\\uff0c\\u521a\\u597d\\u4f1a\\u662f\\u6691\\u5047\\u3002\\u4f46\\u6211\\u5df2\\u6ca1\\u6709\\u6691\\u5047\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"768698176489372642\"},\"type\":\"image\",\"id\":\"768698176095107179_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":{\"latitude\":23.476046667,\"longitude\":111.2695},\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1405858388\",\"text\":\"\\u697c\\u4e0b\\u597d\\u6f02\\u4eae\",\"from\":{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"},\"id\":\"768718334289230647\"},{\"created_time\":\"1405860430\",\"text\":\"@zheng_ji \\u662f\\u54e6\\uff0c\\u5f88\\u5c0f\\u7684\\u57ce\\u5e02\\uff0c\\u7eff\\u5316\\u4ec0\\u4e48\\u7684\\u90fd\\u7a0d\\u5fae\\u4f1a\\u6bd4\\u5927\\u57ce\\u5e02\\u597d\\u70b9\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"768735469036092032\"}]},\"filter\":\"Lo-fi\",\"created_time\":\"1405752498\",\"link\":\"https:\\/\\/instagram.com\\/p\\/qn4WCIo7hi\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s320x320\\/e15\\/926536_828142997203682_1319760676_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s150x150\\/e15\\/926536_828142997203682_1319760676_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/e15\\/926536_828142997203682_1319760676_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1405752498\",\"text\":\"\\u770b\\u7740\\u4e00\\u573a\\u96e8\\u7531\\u8fdc\\u53ca\\u8fd1\\u7684\\u6dcb\\u6e7f\\u9662\\u5b50\\uff0c\\u592a\\u6f02\\u4eae\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"767830066634930596\"},\"type\":\"image\",\"id\":\"767830066215499874_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":{\"latitude\":23.475891667,\"longitude\":111.270028333},\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Lo-fi\",\"created_time\":\"1405683338\",\"link\":\"https:\\/\\/instagram.com\\/p\\/ql0brho7vN\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s320x320\\/e15\\/923702_252705761596555_721784545_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s150x150\\/e15\\/923702_252705761596555_721784545_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/e15\\/923702_252705761596555_721784545_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1405683338\",\"text\":\"\\u5f52\\u6765\\u5374\\u7a7a\\u7a7a\\u7684\\u884c\\u56ca  \\u90a3\\u6545\\u4e61\\u7684\\u4e91  \\u90a3\\u6545\\u4e61\\u7684\\u98ce  \\u5566\\u5566\\u5566\\u5566\\u5566 \\u5566\\u5566\\u5566\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"767249912527305209\"},\"type\":\"image\",\"id\":\"767249912116263885_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Hudson\",\"created_time\":\"1405640336\",\"link\":\"https:\\/\\/instagram.com\\/p\\/qkiaYDo7t9\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10549755_708603639175850_2095584541_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10549755_708603639175850_2095584541_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10549755_708603639175850_2095584541_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1405640336\",\"text\":\"\\u5728\\u4eca\\u5e74\\u7b2c\\u4e00\\u4e2a\\u72c2\\u98ce\\u5927\\u4f5c\\u7684\\u65e9\\u4e0a\\uff0c\\u56de\\u5bb6\\u53bb\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"766889183097895198\"},\"type\":\"image\",\"id\":\"766889182678465405_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Unknown\",\"created_time\":\"1405094360\",\"link\":\"https:\\/\\/instagram.com\\/p\\/qURC9fI7r-\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s320x320\\/e15\\/928307_1442957109299429_297849354_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s150x150\\/e15\\/928307_1442957109299429_297849354_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/e15\\/928307_1442957109299429_297849354_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1405094360\",\"text\":\"98\\u5e74\\uff0c\\u4e16\\u754c\\u676f\\u7b2c\\u4e00\\u6b21\\u5728\\u6211\\u8111\\u4e2d\\u7559\\u4e0b\\u8bb0\\u5fc6\\uff0c\\u548c\\u7238\\uff0c\\u56f4\\u7740\\u90a3\\u53f0\\u5f88\\u5c0f\\u7684tcl\\u3002\\u4eca\\u5929\\uff0c\\u7238\\u8fd8\\u6253\\u7535\\u8bdd\\u7ed9\\u6211\\uff0c\\u8ba9\\u6211\\u522b\\u770b\\u592a\\u665a\\u5f71\\u54cd\\u5230\\u660e\\u5929\\u5de5\\u4f5c\\uff0c\\u4f46\\u6211\\u77e5\\u9053\\u4ed6\\u81ea\\u5df1\\u4e5f\\u4f1a\\u53bb\\u770b\\u7684\\u3002\\u662f\\u7684\\uff0c\\u6211\\u4eec\\u7231\\u8db3\\u7403\\uff0c\\u4eca\\u751f\\u4eca\\u4e16\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"762309208290081347\"},\"type\":\"image\",\"id\":\"762309207182785278_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}}]}","source":"instagram/ins1.json","raw":"{\"pagination\":{\"next_url\":\"https:\\/\\/api.instagram.com\\/v1\\/users\\/438522285\\/media\\/recent?count=100\\u0026callback=jQuery19008141340191941708_1433432491285\\u0026client_id=956dd096b6e5496aba6662165b9b8443\\u0026max_id=762309207182785278_438522285\\u0026_=1433432491286\",\"next_max_id\":\"762309207182785278_438522285\"},\"meta\":{\"code\":200},\"data\":[{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":1,\"data\":[{\"created_time\":\"1411210501\",\"text\":\"hi~\",\"from\":{\"username\":\"hawaiiboyzshelwin\",\"profile_picture\":\"https:\\/\\/igcdn-photos-h-a.akamaihd.net\\/hphotos-ak-xap1\\/t51.2885-19\\/10948635_702403553211063_1668445983_a.jpg\",\"id\":\"293705161\",\"full_name\":\"Hawaii\"},\"id\":\"813615113719495343\"}]},\"filter\":\"Mayfair\",\"created_time\":\"1411177261\",\"link\":\"https:\\/\\/instagram.com\\/p\\/tJjQlAo7kH\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/925287_1464119273867077_427071626_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/925287_1464119273867077_427071626_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/925287_1464119273867077_427071626_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1411177261\",\"text\":\"\\u6c89\\u7720\\u7684\\u5e97\\u4e3b\\u5931\\u7720\\u7684\\u72d7\\u3002\\u60f3\\u8d77\\u5927\\u5b66\\u7684\\u6700\\u540e\\u65f6\\u5149\\uff0c\\u5bbf\\u820d24\\u5c0f\\u65f6\\u90fd\\u6709\\u4eba\\u9192\\u7740\\uff0c\\u81ea\\u7531\\u7684\\u4eba\\u751f\\uff0c\\u81ea\\u7531\\u7684\\u9152\\u548c\\u66f2\\u7ec8\\u4eba\\u6563\\uff0c\\u5927\\u5bb6\\u901a\\u5e38\\u6ca1\\u6709\\u53e6\\u4e00\\u534a\\uff0c\\u6ca1\\u6709\\u94b1\\uff0c\\u6ca1\\u6709\\u5fe7\\u6101\\uff0c\\u723d\\u6210\\u72d7\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"813336279132649576\"},\"type\":\"image\",\"id\":\"813336278595778823_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Hefe\",\"created_time\":\"1410970444\",\"link\":\"https:\\/\\/instagram.com\\/p\\/tDYyUeo7oX\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/925284_1534308033454310_855505111_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/925284_1534308033454310_855505111_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/925284_1534308033454310_855505111_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410970444\",\"text\":\"\\u5982\\u679c\\u4ed6\\u662f\\u7a0b\\u5e8f\\u5458\\u2026\\nvar date = lifetime;\\rif(rotate(mountain, water, stupa)){ \\/*return nextLifetime;*\\/ return meetyou(journey);\\r}\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"811601369455900672\"},\"type\":\"image\",\"id\":\"811601368935807511_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1410924584\",\"link\":\"https:\\/\\/instagram.com\\/p\\/tCBULHo7sW\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/10666267_1550871771803214_2074300649_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/10666267_1550871771803214_2074300649_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/10666267_1550871771803214_2074300649_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410924584\",\"text\":\"\\u542c\\u7740\\u5c71\\u5be8\\u7684\\u6c11\\u8c23\\u7535\\u5b50\\u4e50\\uff0c\\u770b\\u7740\\u7f8e\\u597d\\u7684\\u59d1\\u5a18\\u3002\\u529f\\u5fb7\\u65e0\\u91cf\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"811216667700083459\"},\"type\":\"image\",\"id\":\"811216667255487254_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":1,\"data\":[{\"created_time\":\"1411008352\",\"text\":\"\\u6bcf\\u5929\\u90fd\\u8ba9\\u5750\\u5728\\u7535\\u8111\\u524d\\u7684\\u6211\\u76f8\\u4fe1\\u751f\\u6d3b\",\"from\":{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"},\"id\":\"811919369774020696\"}]},\"filter\":\"Mayfair\",\"created_time\":\"1410923563\",\"link\":\"https:\\/\\/instagram.com\\/p\\/tB_Xmao7qG\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s320x320\\/e15\\/10693244_734401199942901_1572709880_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s150x150\\/e15\\/10693244_734401199942901_1572709880_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/e15\\/10693244_734401199942901_1572709880_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410923563\",\"text\":\"\\u5f25\\u91cc\\u5858\\u592a\\u5b81\\u9759\\u3002\\u5728\\u8fd9\\u6211\\u4e00\\u76f4\\u60f3\\u8d77\\u6bcf\\u4e00\\u4e2a\\u88ab\\u6df1\\u5733\\u8f66\\u6c34\\u9a6c\\u9f99\\u58f0\\u5435\\u9192\\u7684\\u65e9\\u6668\\uff0c\\u771f\\u662f\\u5149\\u8f89\\u7684\\u5c81\\u6708\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"811208107217893670\"},\"type\":\"image\",\"id\":\"811208106630691462_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1410794550\",\"text\":\"\\u9ad8\\u539f\\u53cd\\u5e94\\u4e25\\u91cd\\u5417\\uff1fP.S. \\u963f\\u817e\\u4f60\\u5565\\u65f6\\u5019\\u56de\\u6765\\uff1f\",\"from\":{\"username\":\"winiex\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_45182020_75sq_1380706182.jpg\",\"id\":\"45182020\",\"full_name\":\"winiex nie\"},\"id\":\"810125861157321531\"},{\"created_time\":\"1410923814\",\"text\":\"@winiex \\u54c8\\u54c8\\uff0c\\u6ca1\\u4ec0\\u4e48\\u53cd\\u5e94\\u53ea\\u8981\\u6211\\u4e0d\\u4e71\\u8dd1\\u52a8\\u3002\\u5f88\\u5feb\\u56de\\u6765\\u4e86\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"811210206056004013\"}]},\"filter\":\"Normal\",\"created_time\":\"1410737336\",\"link\":\"https:\\/\\/instagram.com\\/p\\/s8cKzLI7pM\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/10693771_1517437541834868_665867908_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/10693771_1517437541834868_665867908_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/10693771_1517437541834868_665867908_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410737336\",\"text\":\"\\u8fdb\\u85cf\\u3002\\u5929\\u7a7a\\u6302\\u6ee1\\u7740\\u4e91\\uff0c\\u9ed1\\u7684\\u767d\\u7684\\u90fd\\u6709\\u3002\\u4e91\\u6735\\u8f6c\\u773c\\u98d8\\u6563\\uff0c\\u5b83\\u5374\\u4f9d\\u7136\\u662f\\u84dd\\u8272\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"809645920867301928\"},\"type\":\"image\",\"id\":\"809645920464648780_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"videos\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t50.2886-16\\/10701710_281586128699201_335902712_a.mp4\",\"width\":480,\"height\":480},\"low_bandwidth\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t50.2886-16\\/10701471_605249519584920_450596792_s.mp4\",\"width\":480,\"height\":480},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t50.2886-16\\/10701900_770932669629703_1501695708_n.mp4\",\"width\":640,\"height\":640}},\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Stinson\",\"created_time\":\"1410688270\",\"link\":\"https:\\/\\/instagram.com\\/p\\/s6-lOFo7ip\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xta1\\/t51.2885-15\\/s320x320\\/e15\\/10693822_497709657032441_1125408654_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xta1\\/t51.2885-15\\/s150x150\\/e15\\/10693822_497709657032441_1125408654_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xta1\\/t51.2885-15\\/e15\\/10693822_497709657032441_1125408654_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410688270\",\"text\":\"\\u201c\\u97f3\\u6d6a\\u592a\\u5f3a\\u4e0d\\u6643\\u4f1a\\u88ab\\u649e\\u5230\\u5730\\u4e0a\\u2026\\u201d\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"809234320184293724\"},\"type\":\"video\",\"id\":\"809234319697754281_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1410625333\",\"link\":\"https:\\/\\/instagram.com\\/p\\/s5GifkI7q7\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s320x320\\/e15\\/10683941_796597910390683_12441123_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s150x150\\/e15\\/10683941_796597910390683_12441123_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/e15\\/10683941_796597910390683_12441123_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410625333\",\"text\":\"\\u964c\\u751f\\u7684\\u670b\\u53cb\\uff0c\\u613f\\u4e0b\\u6b21\\u518d\\u80fd\\u4e0e\\u4f60\\u4eec\\u76f8\\u805a\\u5728\\u4e3d\\u6c5flove wine \\u0026 half\\u3002\\u6211\\u65e0\\u6cd5\\u878d\\u89e3\\u4f60\\u60b2\\u89c2\\u73b0\\u5b9e\\u7684\\u60f3\\u6cd5\\uff0c\\u4f60\\u4e5f\\u65e0\\u6cd5\\u8bf4\\u670d\\u6211\\u65c5\\u884c\\u5e76\\u4e0d\\u662f\\u9003\\u907f\\u3002\\u4f46\\u8fd9\\u90fd\\u5f88\\u6709\\u610f\\u601d\\u3002\\u53ea\\u662f\\u60f3\\u8d77\\u4ee5\\u524d\\u6709\\u4e2a\\u4eba\\u53eb\\u6211\\u4e0d\\u80fd\\u559d\\u592a\\u591a\\u7684\\u9152\\uff0c\\u4e00\\u60f3\\u5230\\u8fd9\\u4e2a\\u5440\\u6211\\u5c31\\u8d8a\\u559d\\u8d8a\\u591a\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"808706367646054518\"},\"type\":\"image\",\"id\":\"808706366723308219_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"videos\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t50.2886-16\\/10701691_550252955102921_1153150516_a.mp4\",\"width\":480,\"height\":480},\"low_bandwidth\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/l\\/t50.2886-16\\/10705857_251763575033861_1402444343_s.mp4\",\"width\":480,\"height\":480},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t50.2886-16\\/10701411_275533589303527_2032117818_n.mp4\",\"width\":640,\"height\":640}},\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1410668529\",\"text\":\"\\u54c7\\uff0cgood,\\u4f60\\u8bf7\\u5047\\u53bb\\u65c5\\u6e38\\u7684\\u5417\",\"from\":{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"},\"id\":\"809068726839392635\"},{\"created_time\":\"1410706116\",\"text\":\"@zheng_ji \\u662f\\u5440\\uff0c\\u653e\\u677e\\u4e0b\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"809384027007203495\"}]},\"filter\":\"Normal\",\"created_time\":\"1410579121\",\"link\":\"https:\\/\\/instagram.com\\/p\\/s3uZcmo7uj\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10661142_164227523747936_1526737465_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10661142_164227523747936_1526737465_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10661142_164227523747936_1526737465_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410579121\",\"text\":\"\\u7389\\u9f99\\u96ea\\u5c71\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"808318717479074388\"},\"type\":\"video\",\"id\":\"808318716975758243_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1410629707\",\"text\":\"\\u53bb\\u675f\\u6cb3\\u4e86\\u5417\",\"from\":{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"},\"id\":\"808743058343704606\"},{\"created_time\":\"1410706038\",\"text\":\"@sasanzuo \\u53bb\\u4e86\\uff0c\\u4e3d\\u6c5f\\u6700\\u559c\\u6b22\\u675f\\u6cb3\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"809383369692657787\"}]},\"filter\":\"Normal\",\"created_time\":\"1410535625\",\"link\":\"https:\\/\\/instagram.com\\/p\\/s2bb5io7p-\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/s320x320\\/e15\\/10661182_550889531706942_2043749716_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/s150x150\\/e15\\/10661182_550889531706942_2043749716_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/e15\\/10661182_550889531706942_2043749716_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410535625\",\"text\":\"\\u4ee5\\u524d\\u60f3\\u53bb\\u4e3d\\u6c5f\\uff0c\\u4f46\\u53bb\\u8fc7\\u7684\\u4eba\\u90fd\\u704c\\u8f93\\u7740\\u4f60\\u4e5f\\u8bb8\\u4f1a\\u5931\\u671b\\u7684\\u89c2\\u5ff5\\uff0c\\u56e0\\u800c\\u751a\\u81f3\\u4e0d\\u6562\\u52a8\\u8eab\\u3002\\u8fd9\\u662f\\u4e00\\u79cd\\u201c\\u6015\\u201d\\u3002\\u6709\\u65f6\\u5019\\u771f\\u5f97\\u81ea\\u5df1\\u53bb\\u770b\\u770b\\u624d\\u4f1a\\u4e86\\u7136\\u3002\\u7b2c\\u4e00\\u5929\\u5728\\u4e3d\\u6c5f\\uff0c\\u6c11\\u8c23\\u5409\\u4ed6\\u7f13\\u7f13\\u6d41\\u8fc7\\u5546\\u4e1a\\u5316\\u7684\\u8857\\u9053\\uff0c\\u539f\\u6765\\u6ca1\\u6709\\u60ca\\u559c\\uff0c\\u4e5f\\u6ca1\\u6709\\u5931\\u671b\\uff0c\\u4e00\\u5207\\u521a\\u521a\\u597d\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"807953848229673047\"},\"type\":\"image\",\"id\":\"807953847625693822_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"videos\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t50.2886-16\\/10687579_864566316888364_601110692_a.mp4\",\"width\":480,\"height\":480},\"low_bandwidth\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t50.2886-16\\/10705731_491458530957700_895623007_s.mp4\",\"width\":480,\"height\":480},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t50.2886-16\\/10701554_631893030261190_220785276_n.mp4\",\"width\":640,\"height\":640}},\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Maven\",\"created_time\":\"1410529596\",\"link\":\"https:\\/\\/instagram.com\\/p\\/s2P72tI7o6\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"winiex\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_45182020_75sq_1380706182.jpg\",\"id\":\"45182020\",\"full_name\":\"winiex nie\"},{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/10520334_1523531751215211_1344090061_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/10520334_1523531751215211_1344090061_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/10520334_1523531751215211_1344090061_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410529596\",\"text\":\"\\u6211\\u6ce8\\u5b9a\\u8981\\u56de\\u5230\\u8001\\u8def\\u4e0a\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"807903268480203532\"},\"type\":\"video\",\"id\":\"807903267045751354_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":5,\"data\":[{\"created_time\":\"1410529334\",\"text\":\"\\u7ec8\\u4e8e\\u53d1\\u73b0\\u4e86\\u963f\\u817e\\u7684 Instagram:)\",\"from\":{\"username\":\"winiex\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_45182020_75sq_1380706182.jpg\",\"id\":\"45182020\",\"full_name\":\"winiex nie\"},\"id\":\"807901070295808629\"},{\"created_time\":\"1410534900\",\"text\":\"@winiex \\u54c8\\u54c8\\uff0c\\u8bf4\\u5b9e\\u8bdd\\u2026\\u5fae\\u535a\\u548c\\u5fae\\u4fe1\\u52a0\\u4e86\\u5f88\\u591a\\u540c\\u4e8b\\uff0c\\u603b\\u611f\\u89c9\\u4e0d\\u81ea\\u5728\\uff0c\\u5c31\\u7528ins\\u6bd4\\u8f83\\u591a\\u4e86\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"807947760767842994\"},{\"created_time\":\"1410537411\",\"text\":\"@litten225 \\u662f\\u8bf4\\u524d\\u6bb5\\u65f6\\u95f4\\u5ffd\\u7136\\u60f3\\u8d77\\u6765\\u4e0a\\u8001\\u6ca1\\u770b\\u5230\\u4f60\\u52a8\\u9759\\u5462;)\\u3002\\u53ef\\u80fd\\u516c\\u53f8\\u5927\\u4e86\\uff0c\\u670b\\u53cb\\u90fd\\u5982\\u725b\\u6392\\uff0c\\u4e03\\u5206\\u719f\\u6700\\u4f73:)\\u3002\",\"from\":{\"username\":\"winiex\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_45182020_75sq_1380706182.jpg\",\"id\":\"45182020\",\"full_name\":\"winiex nie\"},\"id\":\"807968828790388817\"},{\"created_time\":\"1410537434\",\"text\":\"\\u5fae\\u535a\\u4e0a\\uff0ctypo \\u5566\",\"from\":{\"username\":\"winiex\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_45182020_75sq_1380706182.jpg\",\"id\":\"45182020\",\"full_name\":\"winiex nie\"},\"id\":\"807969017861224538\"},{\"created_time\":\"1410571556\",\"text\":\"@winiex \\u662f\\u554a\\uff0c\\u8ddf\\u540c\\u5b66\\u53ef\\u4ee5\\u4e00\\u8d77\\u5410\\u69fd\\u8001\\u5e08\\u548c\\u6559\\u5b66\\uff0c\\u771f\\u5b9e\\u7684\\u60f3\\u6cd5\\u65e0\\u9700\\u987e\\u8651\\u3002\\u4f46\\u662f\\u8ddf\\u540c\\u4e8b\\u4e00\\u8d77\\u5410\\u69fd\\u8001\\u5927\\u548c\\u5de5\\u4f5c\\uff0c\\u53c8\\u662f\\u53e6\\u5916\\u4e00\\u56de\\u4e8b\\u4e86\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"808255256711641620\"}]},\"filter\":\"Normal\",\"created_time\":\"1410523991\",\"link\":\"https:\\/\\/instagram.com\\/p\\/s2FPpGI7o_\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xta1\\/t51.2885-15\\/s320x320\\/e15\\/10693390_547748238660649_761529890_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xta1\\/t51.2885-15\\/s150x150\\/e15\\/10693390_547748238660649_761529890_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xta1\\/t51.2885-15\\/e15\\/10693390_547748238660649_761529890_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410523991\",\"text\":\"\\u5f69\\u4e91\\u4e4b\\u5357\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"807856248839190621\"},\"type\":\"image\",\"id\":\"807856248310708799_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1410493579\",\"link\":\"https:\\/\\/instagram.com\\/p\\/s1LPQPo7v8\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"wallbase.hd\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/10617029_283951291805046_1229690122_a.jpg\",\"id\":\"1489501811\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s320x320\\/e15\\/10693650_837768039589771_1793184733_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s150x150\\/e15\\/10693650_837768039589771_1793184733_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/e15\\/10693650_837768039589771_1793184733_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410493579\",\"text\":\"\\u4e91\\u5357\\uff0c\\u5411\\u5f80\\u5df2\\u4e45\\u7684\\u5730\\u65b9\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"807601135591602253\"},\"type\":\"image\",\"id\":\"807601134928903164_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Lo-fi\",\"created_time\":\"1410433815\",\"link\":\"https:\\/\\/instagram.com\\/p\\/szZP5Io7lY\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"wallbase.hd\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/10617029_283951291805046_1229690122_a.jpg\",\"id\":\"1489501811\",\"full_name\":\"\"},{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xft1\\/t51.2885-15\\/s320x320\\/e15\\/914812_1529561143923493_1662159287_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xft1\\/t51.2885-15\\/s150x150\\/e15\\/914812_1529561143923493_1662159287_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xft1\\/t51.2885-15\\/e15\\/914812_1529561143923493_1662159287_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410433815\",\"text\":\"QQ\\u540c\\u65f6\\u5728\\u7ebf\\u4eba\\u6570\\u78342\\u4ebf\\u7eaa\\u5ff5\\uff0c\\u4f5c\\u4e3a\\u4e00\\u9897\\u5c0f\\u5c0f\\u87ba\\u4e1d\\u9489\\uff0c\\u540d\\u5b57\\u6b63\\u597d\\u9576\\u5230\\u4f01\\u9e45\\u7684\\u5927\\u5634\\u5df4\\u4e0a\\u3002\\u8fd9\\u65f6\\u89c9\\u5f97\\u6709\\u4e00\\u4e1d\\u5149\\u8363\\uff0c\\u4e00\\u79cd\\u52aa\\u529b\\u88ab\\u5b9e\\u5316\\u7684\\u9519\\u89c9\\uff1b\\u7136\\u540e\\u53c8\\u6709\\u70b9\\u4e0d\\u8212\\u670d\\uff0c\\u611f\\u89c9\\u6b64\\u65f6\\u7684\\u81ea\\u5df1\\uff0c\\u548c\\u540d\\u5b57\\u8eab\\u8fb9\\u7684\\u4eba\\u4e00\\u6837\\u3002\\u53ef\\u6211\\u60f3\\u8981\\u7684\\u5c31\\u662f\\u4e0d\\u4e00\\u6837\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"807099801993984938\"},\"type\":\"image\",\"id\":\"807099801532610904_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":1,\"data\":[{\"created_time\":\"1410373253\",\"text\":\"\\u4e00\\u8d77\\u73a9INS\\ue328\\ue328@gggiselle3333\",\"from\":{\"username\":\"yokiaee\",\"profile_picture\":\"https:\\/\\/igcdn-photos-h-a.akamaihd.net\\/hphotos-ak-xfa1\\/t51.2885-19\\/10598222_301874203326431_1095562300_a.jpg\",\"id\":\"1450755432\",\"full_name\":\"\\u7cd6\\u5b9d\"},\"id\":\"806591765504309560\"}]},\"filter\":\"Sierra\",\"created_time\":\"1410184482\",\"link\":\"https:\\/\\/instagram.com\\/p\\/sr9rtNo7lM\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"},{\"username\":\"fiona2523\",\"profile_picture\":\"https:\\/\\/igcdn-photos-a-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11350911_404317656438368_954826284_a.jpg\",\"id\":\"465984487\",\"full_name\":\"\\ud83c\\udf38Fiona\\ud83c\\udf38\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/10644019_368509079979549_2085033896_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/10644019_368509079979549_2085033896_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/10644019_368509079979549_2085033896_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410184482\",\"text\":\"\\u966a\\u4f34\\u4e00\\u5b9a\\u5f97\\u662f\\u4ef6\\u6f2b\\u957f\\u7684\\u4e8b\\u5475\\u3002\\u548c\\u5976\\u5976\\u5728\\u4e00\\u8d77\\u7684\\u4e2d\\u79cb\\u8282\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"805008243199032014\"},\"type\":\"image\",\"id\":\"805008242737658188_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"videos\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t50.2886-16\\/10687823_350153388474464_1223789041_a.mp4\",\"width\":480,\"height\":480},\"low_bandwidth\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t50.2886-16\\/10701732_344063979085756_1879637417_s.mp4\",\"width\":480,\"height\":480},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t50.2886-16\\/10688739_629114507205181_1066132726_n.mp4\",\"width\":640,\"height\":640}},\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Maven\",\"created_time\":\"1410183340\",\"link\":\"https:\\/\\/instagram.com\\/p\\/sr7gXKI7h_\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10684161_918887498139099_2081383304_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10684161_918887498139099_2081383304_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10684161_918887498139099_2081383304_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410183340\",\"text\":\"\\u4e2d\\u79cb\\u548c\\u5bb6\\u4eba\\u4e00\\u8d77\\u53bb\\u770b\\u5b54\\u660e\\u706f\\uff0c\\u70ed\\u95f9\\u800c\\u5b89\\u9038\\uff0c\\u8fd9\\u662f\\u5c0f\\u57ce\\u5e02\\u7684\\u7f8e\\u597d\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"804998667946932332\"},\"type\":\"video\",\"id\":\"804998667049351295_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1410239540\",\"text\":\"\\u8bf4\\u7684\\u6211\\u4e5f\\u52a8\\u5bb9\\u4e86\",\"from\":{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"},\"id\":\"805470101433465439\"},{\"created_time\":\"1410359659\",\"text\":\"@zheng_ji \\u4e00\\u5207\\u597d\\u795e\\u5947\\uff0c\\u5c31\\u662f\\u8d70\\u5230\\u90a3\\uff0c\\u53d1\\u73b0\\u5979\\u8fd8\\u5728\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"806477733090801988\"}]},\"filter\":\"Unknown\",\"created_time\":\"1410155775\",\"link\":\"https:\\/\\/instagram.com\\/p\\/srG7fjo7sV\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/s320x320\\/e15\\/10683828_327931784041264_894089329_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/s150x150\\/e15\\/10683828_327931784041264_894089329_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/e15\\/10683828_327931784041264_894089329_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410155775\",\"text\":\"\\u8001\\u5bb6\\u7684\\u8461\\u8404\\u85e4\\uff0c\\u4ece\\u6211\\u521d\\u4e2d\\u65f6\\u5c31\\u6302\\u5728\\u8fd9\\uff0c\\u518d\\u89c1\\u5df2\\u662f\\u5341\\u4e00\\u5e74\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"804767435447318654\"},\"type\":\"image\",\"id\":\"804767435027888917_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1410085359\",\"link\":\"https:\\/\\/instagram.com\\/p\\/spAnrio7oh\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/s320x320\\/e15\\/10666028_872988212713750_1345360858_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/s150x150\\/e15\\/10666028_872988212713750_1345360858_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/e15\\/10666028_872988212713750_1345360858_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1410085359\",\"text\":\"\\u5bb6\\u91cc\\u6a44\\u6984\\u719f\\u4e86\\uff0c\\u76d0\\u6e0d\\uff0c\\u66b4\\u6652\\uff0c\\u8638\\u871c\\uff0c\\u7b80\\u76f4\\u4eba\\u95f4\\u7f8e\\u5473!\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"804176735760529648\"},\"type\":\"image\",\"id\":\"804176735273990689_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1409914668\",\"text\":\"\\u4e2d\\u79cb\\u795d\\u597d\",\"from\":{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"},\"id\":\"802744876627376939\"},{\"created_time\":\"1410085406\",\"text\":\"@zheng_ji \\u4e2d\\u79cb\\u8282\\u5feb\\u4e50\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"804177137474189571\"}]},\"filter\":\"Lo-fi\",\"created_time\":\"1409913076\",\"link\":\"https:\\/\\/instagram.com\\/p\\/sj4BGgI7t_\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10665501_1452353738387652_2075798065_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10665501_1452353738387652_2075798065_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10665501_1452353738387652_2075798065_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1409913076\",\"text\":\"\\u5728\\u4e00\\u573a\\u592a\\u9633\\u96e8\\u91cc\\u56de\\u5230\\u5bb6\\u4e2d\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"802731525369215150\"},\"type\":\"image\",\"id\":\"802731524907842431_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":5,\"data\":[{\"created_time\":\"1409495738\",\"text\":\"\\u5929\\u5929\\u5728\\u88ab\\u670d\\u52a1\\u5668\\u8650\\u6ca1\\u4e2a\\u4eba\\u65f6\\u95f4\\u4e86\",\"from\":{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"},\"id\":\"799230636918553169\"},{\"created_time\":\"1409537231\",\"text\":\"\\u4f60\\u53bb\\u542c\\u542c\\u91ce\\u5b69\\u5b50\\uff0c\\u5f20\\u73ae\\u73ae\\u90ed\\u9f99\\u7684\\u767d\\u94f6\\u996d\\u5e97\\u548c\\u6211\\u7b49\\u7740\\u4f60\\u56de\\u6765\\uff0c\\u770b\\u770b\\u662f\\u5426\\u559c\\u6b22\\u8fd9\\u79cd\\u98ce\\u683c\\u3002\",\"from\":{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"},\"id\":\"799578708500527379\"},{\"created_time\":\"1409913295\",\"text\":\"@sasanzuo \\u6211\\u542c\\u6c11\\u8c23\\u6bd4\\u8f83\\u591a\\uff0c\\u674e\\u5fd7\\u5f20\\u73ae\\u73ae\\u4e00\\u76f4\\u5f88\\u559c\\u6b22\\u5450\\uff0c\\u91ce\\u5b69\\u5b50\\u5c31\\u542c\\u5f97\\u5f88\\u5c11\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"802733361660672253\"},{\"created_time\":\"1409913403\",\"text\":\"@zheng_ji \\u8fd9\\u4e48\\u60e8\\uff1f\\u8d76\\u7d27\\u9a6f\\u670d\\u5b83\\uff01\\u4e00\\u5207\\u78e8\\u4eba\\u7684\\u670d\\u52a1\\u5668\\u90fd\\u662f\\u7eb8\\u8001\\u864e\\uff01\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"802734270063032609\"},{\"created_time\":\"1409917831\",\"text\":\"@litten225 \\u554a\\u90a3\\u6709\\u8bdd\\u804a\\uff0c\\u4ed6\\u4eec\\u90fd\\u662f\\u6211\\u5f88\\u597d\\u7684\\u670b\\u53cb\",\"from\":{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"},\"id\":\"802771409702206463\"}]},\"filter\":\"Unknown\",\"created_time\":\"1409495189\",\"link\":\"https:\\/\\/instagram.com\\/p\\/sXa9g6I7jB\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/s320x320\\/e15\\/10654876_610857929023752_364709543_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/s150x150\\/e15\\/10654876_610857929023752_364709543_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/e15\\/10654876_610857929023752_364709543_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1409495189\",\"text\":\"\\u5728\\u4e66\\u5e97\\u7684\\u665a\\u4e0a\\u7ec8\\u4e8e\\u628a\\u65b0\\u4e13\\u53cd\\u590d\\u542c\\u5b8c\\u3002\\u592a\\u67d4\\u4e86\\u2026\\u6253\\u4e00\\u661f\\u4e24\\u661f\\u7684\\u4eba\\u80af\\u5b9a\\u662f\\u771f\\u7231\\u7c89\\uff0c\\u8fd9\\u70b9\\u6709\\u4eba\\u6562\\u6000\\u7591\\uff1f\\u6211\\u4e0d\\u662f\\uff0c\\u6253\\u56db\\u661f\\uff01\\u505c\\u4e0d\\u4e0b\\u6765\\uff0c\\u76f4\\u5230\\u4e66\\u5e97\\u54cd\\u8d77:\\u6df1\\u5733\\u5373\\u5c06\\u5165\\u7720\\u3002\\u4f4622\\u70b9\\u8fd8\\u662f\\u6df1\\u5733\\u7684\\u65e9\\u6668\\u5440\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"799226037537061117\"},\"type\":\"image\",\"id\":\"799226035314079937_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"videos\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t50.2886-16\\/10619367_685656154851110_766778884_a.mp4\",\"width\":480,\"height\":480},\"low_bandwidth\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t50.2886-16\\/10655768_594287900680172_2084417441_s.mp4\",\"width\":480,\"height\":480},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t50.2886-16\\/10648015_1491243041113750_339844084_n.mp4\",\"width\":640,\"height\":640}},\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1409238867\",\"text\":\"\\u554a\\u9f13\\u624b\\u662f\\u6211\\u597d\\u670b\\u53cb\",\"from\":{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"},\"id\":\"797075846717487722\"},{\"created_time\":\"1409495262\",\"text\":\"@sasanzuo \\u771f\\u597d\\uff01\\u4f60\\u6709\\u8fd9\\u6837\\u7684\\u670b\\u53cb\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"799226645367208237\"}]},\"filter\":\"Stinson\",\"created_time\":\"1409236676\",\"link\":\"https:\\/\\/instagram.com\\/p\\/sPt4u4I7kA\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s320x320\\/e15\\/10644013_777642448965989_544517718_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s150x150\\/e15\\/10644013_777642448965989_544517718_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/e15\\/10644013_777642448965989_544517718_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1409236676\",\"text\":\"\\u6162\\u4e09\\u7684\\u534e\\u5c14\\u5179\\uff0c\\u5927\\u7bc7\\u5e45\\u7684\\u7235\\u58eb\\u5373\\u5174\\u3002\\u611f\\u89c9\\u751f\\u6d3b\\u5f97\\u592a\\u6d6e\\u8e81\\u3002\\u4e5f\\u592a\\u5b89\\u9038\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"797057470305646918\"},\"type\":\"video\",\"id\":\"797057469785553152_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Lo-fi\",\"created_time\":\"1408804690\",\"link\":\"https:\\/\\/instagram.com\\/p\\/sC18G0o7qb\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtf1\\/t51.2885-15\\/s320x320\\/e15\\/924456_1471485796442896_1699836323_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtf1\\/t51.2885-15\\/s150x150\\/e15\\/924456_1471485796442896_1699836323_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtf1\\/t51.2885-15\\/e15\\/924456_1471485796442896_1699836323_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1408804690\",\"text\":\"\\u597d\\u4e45\\u6ca1\\u770b\\u8bdd\\u5267\\uff0c\\u8fd9\\u90e8\\u679c\\u7136\\u6ca1\\u8ba9\\u4eba\\u5931\\u671b\\u3002\\u5bfc\\u6f14\\u592a\\u4f1a\\u8bb2\\u6545\\u4e8b\\u4e86\\uff0c1024\\u4e2a\\u8d5e\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"793433712932141876\"},\"type\":\"image\",\"id\":\"793433711329917595_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Hefe\",\"created_time\":\"1408715905\",\"link\":\"https:\\/\\/instagram.com\\/p\\/sAMmEWI7oC\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10607913_692632367472666_1829853902_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10607913_692632367472666_1829853902_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10607913_692632367472666_1829853902_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1408715905\",\"text\":\"\\u7eb5\\u6709\\u4e00\\u4e07\\u79cd\\u60b2\\u4f24\\u7684\\u7f8e\\u4e3d\\uff0c\\u4e5f\\u6bd4\\u4e0d\\u8fc7\\u8fd9\\u6bb5\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"792688927703284532\"},\"type\":\"image\",\"id\":\"792688926981863938_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"X-Pro II\",\"created_time\":\"1408282865\",\"link\":\"https:\\/\\/instagram.com\\/p\\/rzSow4o7lH\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/10611052_1466241683635233_830264506_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/10611052_1466241683635233_830264506_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/10611052_1466241683635233_830264506_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1408282865\",\"text\":\"\\u5728\\u4e66\\u57ce\\u91cc\\u770b\\u5230\\u7684\\u003c\\u540e\\u4f1a\\u65e0\\u671f\\u003e\\u5206\\u955c\\u56fe\\u3002\\u7535\\u5f71\\u90a3\\u4e48\\u7f8e\\uff0c\\u5206\\u955c\\u662f\\u8fd9\\u6837\\uff0c\\u8fd9\\u5c31\\u662f\\u73b0\\u5b9e~\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"789056326245530503\"},\"type\":\"image\",\"id\":\"789056325826099527_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Hudson\",\"created_time\":\"1407932800\",\"link\":\"https:\\/\\/instagram.com\\/p\\/ro28LPI7oc\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s320x320\\/e15\\/10617144_829548960388746_1611410337_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s150x150\\/e15\\/10617144_829548960388746_1611410337_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/e15\\/10617144_829548960388746_1611410337_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1407932800\",\"text\":\"\\u5982\\u679c\\u4f60\\u4ece\\u5317\\u4eac\\u6765\\u770b\\u6211\\uff0c\\u6211\\u4f1a\\u5f88\\u611f\\u52a8;\\u5982\\u679c\\u4f60\\u50cf\\u5149\\uff0c\\u4ece\\u592a\\u9633\\u90a3\\u5934\\u8fc7\\u6765\\uff0c\\u6211\\u4e0d\\u4ee5\\u4e3a\\u7136\\u3002\\u56e0\\u4e3a\\u5149\\u5230\\u5730\\u7403\\u53ea\\u89818.3\\u5206\\u949f\\u3002\\u6211\\u4eec\\u7ecf\\u5e38\\u9519\\u7528\\u4ee3\\u4ef7\\u6765\\u8861\\u91cf\\u60c5\\u611f\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"786119765132556496\"},\"type\":\"image\",\"id\":\"786119764721515036_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1407328697\",\"text\":\"\\u5bb6\\u91cc\\u4eba\\u5417\",\"from\":{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"},\"id\":\"781052182645685044\"},{\"created_time\":\"1408283949\",\"text\":\"@zheng_ji \\u5bf9\\uff0c\\u6765\\u6df1\\u5733\\u73a9\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"789065414052395483\"}]},\"filter\":\"Nashville\",\"created_time\":\"1407161569\",\"link\":\"https:\\/\\/instagram.com\\/p\\/rR37wLo7iu\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/10453953_542161702576881_1621059386_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/10453953_542161702576881_1621059386_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/10453953_542161702576881_1621059386_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1407161569\",\"text\":\"\\u76f8\\u805a\\u603b\\u6709\\u65f6:)\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"779650209673361431\"},\"type\":\"image\",\"id\":\"779650209253931182_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":1,\"data\":[{\"created_time\":\"1406438900\",\"text\":\"\\u4eba\\u554a\",\"from\":{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"},\"id\":\"773588027516893195\"}]},\"filter\":\"Lo-fi\",\"created_time\":\"1406343109\",\"link\":\"https:\\/\\/instagram.com\\/p\\/q5e2KpI7qn\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s320x320\\/e15\\/925559_1482425071996009_1940959046_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s150x150\\/e15\\/925559_1482425071996009_1940959046_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/e15\\/925559_1482425071996009_1940959046_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1406343109\",\"text\":\"\\u968f\\u4fbf\\u8d70\\u8d70\\uff0c\\u53d1\\u73b0\\u4e16\\u754c\\u8fd8\\u662f\\u5f88\\u7f8e\\u597d\\u7684\\u3002\\u5f53\\u62e5\\u6709\\u7f8e\\u597d\\u4e8b\\u7269\\u65f6\\uff0c\\u7ecf\\u5e38\\u4e60\\u60ef\\u6027\\u7684\\u719f\\u89c6\\u65e0\\u7779;\\u5f53\\u52aa\\u529b\\u6293\\u4f4f\\u4f60\\u60f3\\u8981\\u7684\\u4e1c\\u897f\\u65f6\\uff0c\\u5b83\\u53c8\\u53ef\\u80fd\\u77ac\\u95f4\\u7834\\u788e\\u3002\\u4f46\\u4f9d\\u65e7\\u9700\\u8981\\u4e0d\\u59a5\\u534f\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"772784475122940015\"},\"type\":\"image\",\"id\":\"772784474745453223_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Valencia\",\"created_time\":\"1406104308\",\"link\":\"https:\\/\\/instagram.com\\/p\\/qyXXpNI7q5\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"dingstyle\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_30683156_75sq_1333592929.jpg\",\"id\":\"30683156\",\"full_name\":\"Linjie\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s320x320\\/e15\\/10554006_501929086608023_917623457_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s150x150\\/e15\\/10554006_501929086608023_917623457_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/e15\\/10554006_501929086608023_917623457_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1406104308\",\"text\":\"\\u8354\\u679d\\u2014\\u2014\\u6211\\u5fc3\\u76ee\\u4e2d\\u7684\\u6c34\\u679c\\u4e4b\\u738b\\uff08\\u6709\\u4e4b\\u4e00\\uff09\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"770781266472843689\"},\"type\":\"image\",\"id\":\"770781266095356601_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Unknown\",\"created_time\":\"1406074922\",\"link\":\"https:\\/\\/instagram.com\\/p\\/qxfUe0I7lp\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/10576105_624878090953161_638111947_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/10576105_624878090953161_638111947_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/10576105_624878090953161_638111947_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1406074922\",\"text\":\"\\u9ad8\\u4e2d\\u65f6\\u4ee3\\u6700\\u65b0\\u6b3e\\u7684mp4\\uff0c\\u73b0\\u5df2\\u6210\\u4e86\\u8001\\u53e4\\u8463\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"770534759307917387\"},\"type\":\"image\",\"id\":\"770534758175455593_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Unknown\",\"created_time\":\"1405855985\",\"link\":\"https:\\/\\/instagram.com\\/p\\/qq9usdo7hr\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10570119_332808380211109_125412512_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10570119_332808380211109_125412512_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10570119_332808380211109_125412512_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1405855985\",\"text\":\"\\u53f0\\u98ce\\u6765\\u4e34\\u65f6\\uff0c\\u521a\\u597d\\u4f1a\\u662f\\u6691\\u5047\\u3002\\u4f46\\u6211\\u5df2\\u6ca1\\u6709\\u6691\\u5047\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"768698176489372642\"},\"type\":\"image\",\"id\":\"768698176095107179_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":{\"latitude\":23.476046667,\"longitude\":111.2695},\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1405858388\",\"text\":\"\\u697c\\u4e0b\\u597d\\u6f02\\u4eae\",\"from\":{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"},\"id\":\"768718334289230647\"},{\"created_time\":\"1405860430\",\"text\":\"@zheng_ji \\u662f\\u54e6\\uff0c\\u5f88\\u5c0f\\u7684\\u57ce\\u5e02\\uff0c\\u7eff\\u5316\\u4ec0\\u4e48\\u7684\\u90fd\\u7a0d\\u5fae\\u4f1a\\u6bd4\\u5927\\u57ce\\u5e02\\u597d\\u70b9\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"768735469036092032\"}]},\"filter\":\"Lo-fi\",\"created_time\":\"1405752498\",\"link\":\"https:\\/\\/instagram.com\\/p\\/qn4WCIo7hi\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s320x320\\/e15\\/926536_828142997203682_1319760676_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s150x150\\/e15\\/926536_828142997203682_1319760676_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/e15\\/926536_828142997203682_1319760676_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1405752498\",\"text\":\"\\u770b\\u7740\\u4e00\\u573a\\u96e8\\u7531\\u8fdc\\u53ca\\u8fd1\\u7684\\u6dcb\\u6e7f\\u9662\\u5b50\\uff0c\\u592a\\u6f02\\u4eae\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"767830066634930596\"},\"type\":\"image\",\"id\":\"767830066215499874_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":{\"latitude\":23.475891667,\"longitude\":111.270028333},\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Lo-fi\",\"created_time\":\"1405683338\",\"link\":\"https:\\/\\/instagram.com\\/p\\/ql0brho7vN\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s320x320\\/e15\\/923702_252705761596555_721784545_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s150x150\\/e15\\/923702_252705761596555_721784545_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/e15\\/923702_252705761596555_721784545_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1405683338\",\"text\":\"\\u5f52\\u6765\\u5374\\u7a7a\\u7a7a\\u7684\\u884c\\u56ca  \\u90a3\\u6545\\u4e61\\u7684\\u4e91  \\u90a3\\u6545\\u4e61\\u7684\\u98ce  \\u5566\\u5566\\u5566\\u5566\\u5566 \\u5566\\u5566\\u5566\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"767249912527305209\"},\"type\":\"image\",\"id\":\"767249912116263885_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Hudson\",\"created_time\":\"1405640336\",\"link\":\"https:\\/\\/instagram.com\\/p\\/qkiaYDo7t9\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10549755_708603639175850_2095584541_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10549755_708603639175850_2095584541_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10549755_708603639175850_2095584541_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1405640336\",\"text\":\"\\u5728\\u4eca\\u5e74\\u7b2c\\u4e00\\u4e2a\\u72c2\\u98ce\\u5927\\u4f5c\\u7684\\u65e9\\u4e0a\\uff0c\\u56de\\u5bb6\\u53bb\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"766889183097895198\"},\"type\":\"image\",\"id\":\"766889182678465405_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Unknown\",\"created_time\":\"1405094360\",\"link\":\"https:\\/\\/instagram.com\\/p\\/qURC9fI7r-\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"zheng_ji\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/anonymousUser.jpg\",\"id\":\"1176976812\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s320x320\\/e15\\/928307_1442957109299429_297849354_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s150x150\\/e15\\/928307_1442957109299429_297849354_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/e15\\/928307_1442957109299429_297849354_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1405094360\",\"text\":\"98\\u5e74\\uff0c\\u4e16\\u754c\\u676f\\u7b2c\\u4e00\\u6b21\\u5728\\u6211\\u8111\\u4e2d\\u7559\\u4e0b\\u8bb0\\u5fc6\\uff0c\\u548c\\u7238\\uff0c\\u56f4\\u7740\\u90a3\\u53f0\\u5f88\\u5c0f\\u7684tcl\\u3002\\u4eca\\u5929\\uff0c\\u7238\\u8fd8\\u6253\\u7535\\u8bdd\\u7ed9\\u6211\\uff0c\\u8ba9\\u6211\\u522b\\u770b\\u592a\\u665a\\u5f71\\u54cd\\u5230\\u660e\\u5929\\u5de5\\u4f5c\\uff0c\\u4f46\\u6211\\u77e5\\u9053\\u4ed6\\u81ea\\u5df1\\u4e5f\\u4f1a\\u53bb\\u770b\\u7684\\u3002\\u662f\\u7684\\uff0c\\u6211\\u4eec\\u7231\\u8db3\\u7403\\uff0c\\u4eca\\u751f\\u4eca\\u4e16\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"762309208290081347\"},\"type\":\"image\",\"id\":\"762309207182785278_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}}]}","date":"2015-11-22T05:12:27.376Z","updated":"2015-11-22T05:12:27.376Z","path":"instagram/ins1.json","layout":"false","title":"","comments":1,"_id":"cimigpyst002d6cujcmvkn6bx"},{"_content":"{\"pagination\":{\"next_url\":\"https:\\/\\/api.instagram.com\\/v1\\/users\\/438522285\\/media\\/recent?count=100\\u0026callback=jQuery19008141340191941708_1433432491285\\u0026client_id=956dd096b6e5496aba6662165b9b8443\\u0026max_id=817324725551479434_438522285\\u0026_=1433432491286\",\"next_max_id\":\"817324725551479434_438522285\"},\"meta\":{\"code\":200},\"data\":[{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Lark\",\"created_time\":\"1433424772\",\"link\":\"https:\\/\\/instagram.com\\/p\\/3glBKbI7jm\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s320x320\\/e15\\/11375982_491190547696110_2013240096_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s150x150\\/e15\\/11375982_491190547696110_2013240096_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/e15\\/11375982_491190547696110_2013240096_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1433424772\",\"text\":\"\\u5c0f\\u841d\\u8389\\u4e0d\\u613f\\u56de\\u5bb6\\uff0c\\u8ddf\\u5976\\u5976\\u8bf4\\uff1a\\u201c\\u518d\\u8ba9\\u6211\\u73a9\\u4f1a\\uff0c\\u660e\\u5929\\u8981\\u5b66\\u94a2\\u7434\\uff0c\\u540e\\u5929\\u8981\\u5b66\\u8df3\\u821e\\uff0c\\u5c31\\u6765\\u4e0d\\u4e86\\u8fd9\\u513f\\u73a9\\u4e86\\u3002\\u201d\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"999961926134119385\"},\"type\":\"image\",\"id\":\"999961924909381862_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":5,\"data\":[{\"created_time\":\"1432100935\",\"text\":\"\\ud83d\\ude0a\",\"from\":{\"username\":\"muvanmf\",\"profile_picture\":\"https:\\/\\/igcdn-photos-f-a.akamaihd.net\\/hphotos-ak-xfa1\\/t51.2885-19\\/11334455_1615248035385837_1443100648_a.jpg\",\"id\":\"1200885749\",\"full_name\":\"\"},\"id\":\"988856776283895820\"},{\"created_time\":\"1432500874\",\"text\":\"\\ud83d\\ude0a\",\"from\":{\"username\":\"y_lang99\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11373510_386713434848322_1596956169_a.jpg\",\"id\":\"1509502800\",\"full_name\":\"\\u2728\\u5c0f\\u963f\\u6d6a\\uff5e\"},\"id\":\"992211705421609081\"},{\"created_time\":\"1432886603\",\"text\":\"\\ud83d\\udc4d\",\"from\":{\"username\":\"cp_water_h2o\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xap1\\/t51.2885-19\\/11191155_897877480271222_1196332450_a.jpg\",\"id\":\"46708139\",\"full_name\":\"\"},\"id\":\"995447436348733496\"},{\"created_time\":\"1433035543\",\"text\":\"\\ud83d\\ude04\",\"from\":{\"username\":\"vocalmomoko\",\"profile_picture\":\"https:\\/\\/igcdn-photos-f-a.akamaihd.net\\/hphotos-ak-xfa1\\/t51.2885-19\\/10601848_849046995107581_1799487354_a.jpg\",\"id\":\"280464724\",\"full_name\":\"Momoko\"},\"id\":\"996696839524956493\"},{\"created_time\":\"1433035564\",\"text\":\"nice  @Ijustinchen\",\"from\":{\"username\":\"dikenxoen\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/925345_933363483364074_1000071537_a.jpg\",\"id\":\"1649582238\",\"full_name\":\"\"},\"id\":\"996697009528486242\"}]},\"filter\":\"Lo-fi\",\"created_time\":\"1432095934\",\"link\":\"https:\\/\\/instagram.com\\/p\\/24-dd6o7uB\\/\",\"likes\":{\"count\":4,\"data\":[{\"username\":\"oliviayhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11326269_1439141373071498_1054025241_a.jpg\",\"id\":\"10631089\",\"full_name\":\"Olivia Yang\"},{\"username\":\"zx_9451\",\"profile_picture\":\"https:\\/\\/igcdn-photos-a-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11327937_953513731373032_1587298722_a.jpg\",\"id\":\"1147297522\",\"full_name\":\"\\u8d24\\u59b9\\u59b9ZX\"},{\"username\":\"irissssw\",\"profile_picture\":\"https:\\/\\/igcdn-photos-d-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/11005023_732965413468795_1308833307_a.jpg\",\"id\":\"231558542\",\"full_name\":\"Iris.W\"},{\"username\":\"juxiequechuicai\",\"profile_picture\":\"https:\\/\\/igcdn-photos-f-a.akamaihd.net\\/hphotos-ak-xap1\\/t51.2885-19\\/10932562_1408525596106461_81586164_a.jpg\",\"id\":\"1649588862\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s320x320\\/e15\\/11252751_1444216632541093_1558227860_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s150x150\\/e15\\/11252751_1444216632541093_1558227860_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/e15\\/11252751_1444216632541093_1558227860_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1432095934\",\"text\":\"\\u98ce\\u96e8\\u6b32\\u6765\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"988814823345338742\"},\"type\":\"image\",\"id\":\"988814822078659457_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"videos\":{\"low_bandwidth\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t50.2886-16\\/11234567_805492662880042_967794598_s.mp4\",\"width\":480,\"height\":480},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t50.2886-16\\/11235514_1629635357248662_1505532808_n.mp4\",\"width\":640,\"height\":640},\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t50.2886-16\\/11234567_805492662880042_967794598_s.mp4\",\"width\":480,\"height\":480}},\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Ashby\",\"created_time\":\"1431736282\",\"link\":\"https:\\/\\/instagram.com\\/p\\/2uQeuaI7nv\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"ashleyfashionblogger\",\"profile_picture\":\"https:\\/\\/igcdn-photos-a-a.akamaihd.net\\/hphotos-ak-xpa1\\/t51.2885-19\\/11190869_428988550612824_1565351360_a.jpg\",\"id\":\"1172999152\",\"full_name\":\"Ashley\\u7cbe\\u5c16\\u5962\\u54c1\"},{\"username\":\"jijileexi\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/10914307_1531769583766522_1188586237_a.jpg\",\"id\":\"1668534092\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s320x320\\/e15\\/11226595_701075516681953_1354085958_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s150x150\\/e15\\/11226595_701075516681953_1354085958_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/e15\\/11226595_701075516681953_1354085958_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1431736282\",\"text\":\"\\u91ce\\u751f\\u6d77\\u5e26\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"985797850168539756\"},\"type\":\"video\",\"id\":\"985797848599869935_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"videos\":{\"low_bandwidth\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t50.2886-16\\/11100588_1627658390782524_1406603363_s.mp4\",\"width\":480,\"height\":480},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t50.2886-16\\/11123341_1574707489481834_1444136079_n.mp4\",\"width\":640,\"height\":640},\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t50.2886-16\\/11100588_1627658390782524_1406603363_s.mp4\",\"width\":480,\"height\":480}},\"tags\":[],\"location\":null,\"comments\":{\"count\":3,\"data\":[{\"created_time\":\"1428633555\",\"text\":\"@nanako0606 :)\",\"from\":{\"username\":\"lvhombeme\",\"profile_picture\":\"https:\\/\\/igcdn-photos-h-a.akamaihd.net\\/hphotos-ak-xap1\\/t51.2885-19\\/11190759_712908695501663_547363914_a.jpg\",\"id\":\"30244942\",\"full_name\":\"\"},\"id\":\"959770281262693297\"},{\"created_time\":\"1428952602\",\"text\":\"\\ud83d\\udc98\\ud83d\\udc98 @MIKATTONG\",\"from\":{\"username\":\"kaogai\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10431811_753900654665570_1046066069_a.jpg\",\"id\":\"1588508371\",\"full_name\":\"\"},\"id\":\"962446649029016324\"},{\"created_time\":\"1430583831\",\"text\":\"\\ud83d\\ude0a\",\"from\":{\"username\":\"geyaoxian\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/11203210_832251100188962_1484152822_a.jpg\",\"id\":\"1026707646\",\"full_name\":\"\\u845b\\u8000\\u5148\"},\"id\":\"976130389424978098\"}]},\"filter\":\"Clarendon\",\"created_time\":\"1428315781\",\"link\":\"https:\\/\\/instagram.com\\/p\\/1IUZByo7vP\\/\",\"likes\":{\"count\":4,\"data\":[{\"username\":\"barb1e2u\",\"profile_picture\":\"https:\\/\\/igcdn-photos-d-a.akamaihd.net\\/hphotos-ak-xap1\\/t51.2885-19\\/11184633_436852723162235_673116011_a.jpg\",\"id\":\"1543932897\",\"full_name\":\"Barbie\\ud83d\\udc8bWeChat:88315113\\ud83d\\udcf2\"},{\"username\":\"huanglh3o3\",\"profile_picture\":\"https:\\/\\/igcdn-photos-b-a.akamaihd.net\\/hphotos-ak-xtf1\\/t51.2885-19\\/11098542_1557115881228953_2108051141_a.jpg\",\"id\":\"1244702090\",\"full_name\":\"\"},{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},{\"username\":\"lixxin1\",\"profile_picture\":\"https:\\/\\/igcdn-photos-b-a.akamaihd.net\\/hphotos-ak-xfa1\\/t51.2885-19\\/10724134_1498809703714993_666658303_a.jpg\",\"id\":\"474735109\",\"full_name\":\"\\u674e\\u7d2b\\u6b23\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpt1\\/t51.2885-15\\/s320x320\\/e15\\/11142212_609961145801361_1913577076_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpt1\\/t51.2885-15\\/s150x150\\/e15\\/11142212_609961145801361_1913577076_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpt1\\/t51.2885-15\\/e15\\/11142212_609961145801361_1913577076_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1428315781\",\"text\":\"\\u8981\\u56de\\u53bb\\u5566\\uff0c\\u518d\\u89c1\\u5317\\u6d41\\u6cb3\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"957104601967082317\"},\"type\":\"video\",\"id\":\"957104601656703951_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Ludwig\",\"created_time\":\"1428314611\",\"link\":\"https:\\/\\/instagram.com\\/p\\/1ISKRxo7r8\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/11049421_1375007652828983_401355534_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/11049421_1375007652828983_401355534_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/11049421_1375007652828983_401355534_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1428314611\",\"text\":\"\\u7075\\u829dget\\u221a\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"957094792144337138\"},\"type\":\"image\",\"id\":\"957094791934622460_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Nashville\",\"created_time\":\"1428245860\",\"link\":\"https:\\/\\/instagram.com\\/p\\/1GPBzpo7qW\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/s320x320\\/e15\\/11137852_1649834698581861_1050691792_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/s150x150\\/e15\\/11137852_1649834698581861_1050691792_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/e15\\/11137852_1649834698581861_1050691792_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1428245860\",\"text\":\"\\u8fd9\\u91cc\\u7684\\u6e05\\u660e\\u662f\\u4e2a\\u5f88\\u91cd\\u8981\\u7684\\u8282\\u65e5\\uff0c\\u5b50\\u5b59\\u4eec\\u90fd\\u4f1a\\u56de\\u6765\\uff0c\\u8dcb\\u5c71\\u6d89\\u6c34\\uff0c\\u7af9\\u6392\\u6e21\\u6c5f\\uff0c\\u8352\\u5c71\\u5bfb\\u8def\\uff0c\\u51ed\\u96c6\\u4f53\\u7684\\u8bb0\\u5fc6\\u5bfb\\u627e\\u5217\\u7956\\u5217\\u5b97\\u7684\\u5b9d\\u5730\\uff0c\\u5bc4\\u54c0\\u601d\\uff0c\\u4e5f\\u6c42\\u798f\\u5fb7\\u3002\\u4e00\\u8def\\u4e0a\\u53ef\\u4ee5\\u542c\\u4ed6\\u4eec\\u5520\\u53e8\\u65e7\\u4e8b\\uff0c\\u4e5f\\u6709\\u8d85\\u7ea7\\u9760\\u8c31\\u7684\\u98ce\\u6c34\\u79d1\\u666e\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"956518065923930728\"},\"type\":\"image\",\"id\":\"956518065739381398_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Mayfair\",\"created_time\":\"1428228071\",\"link\":\"https:\\/\\/instagram.com\\/p\\/1FtGO3I7kN\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/11055751_1573536912901494_1683773508_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/11055751_1573536912901494_1683773508_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/11055751_1573536912901494_1683773508_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1428228071\",\"text\":\"\\u4e3a\\u4e86\\u90e8\\u843d\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"956368836446370643\"},\"type\":\"image\",\"id\":\"956368836253432077_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Mayfair\",\"created_time\":\"1428131481\",\"link\":\"https:\\/\\/instagram.com\\/p\\/1C03iPI7hZ\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/11055897_1407191599597961_1763496348_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/11055897_1407191599597961_1763496348_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/11055897_1407191599597961_1763496348_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1428131481\",\"text\":\"\\u5728\\u6e05\\u660e\\u7684\\u5c71\\u8def\\u9047\\u5230\\u4e86\\u5929\\u7136\\u677e\\u9999\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"955558585941866653\"},\"type\":\"image\",\"id\":\"955558585706985561_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Crema\",\"created_time\":\"1427801745\",\"link\":\"https:\\/\\/instagram.com\\/p\\/04_8fwo7gL\\/\",\"likes\":{\"count\":3,\"data\":[{\"username\":\"bo0oo0\",\"profile_picture\":\"https:\\/\\/igcdn-photos-e-a.akamaihd.net\\/hphotos-ak-xfa1\\/t51.2885-19\\/10507930_301607313382260_661513528_a.jpg\",\"id\":\"51426891\",\"full_name\":\"\"},{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtf1\\/t51.2885-15\\/s320x320\\/e15\\/11123665_1542600796003839_1576473443_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtf1\\/t51.2885-15\\/s150x150\\/e15\\/11123665_1542600796003839_1576473443_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtf1\\/t51.2885-15\\/e15\\/11123665_1542600796003839_1576473443_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1427801745\",\"text\":\"\\u5982\\u679c\\u4f60\\u98de\\u5f97\\u50cf\\u6708\\u4eae\\u8fd9\\u4e48\\u9ad8\\uff0c\\u5c31\\u4e0d\\u4f1a\\u6401\\u6d45\\u5728\\u6811\\u4e0a\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"952792555599411873\"},\"type\":\"image\",\"id\":\"952792555389696011_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":{\"latitude\":22.538938333,\"longitude\":113.92382},\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1425469470\",\"link\":\"https:\\/\\/instagram.com\\/p\\/zzfe7Oo7uc\\/\",\"likes\":{\"count\":4,\"data\":[{\"username\":\"kai_efforts\",\"profile_picture\":\"https:\\/\\/igcdn-photos-b-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11326569_447841455377553_1276311913_a.jpg\",\"id\":\"1319736417\",\"full_name\":\"\\u5f35\\u51f1\\u8317KAI\"},{\"username\":\"yinggg0830\",\"profile_picture\":\"https:\\/\\/igcdn-photos-e-a.akamaihd.net\\/hphotos-ak-xpa1\\/t51.2885-19\\/11191229_478700095619252_1507412393_a.jpg\",\"id\":\"303041107\",\"full_name\":\"\"},{\"username\":\"aofeixi\",\"profile_picture\":\"https:\\/\\/igcdn-photos-a-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/10899120_578003152334536_1461658615_a.jpg\",\"id\":\"1648133428\",\"full_name\":\"\"},{\"username\":\"ritababe_\",\"profile_picture\":\"https:\\/\\/igcdn-photos-e-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11018358_387855874729324_717730599_a.jpg\",\"id\":\"40610366\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/s320x320\\/e15\\/11008101_1593505510894691_369067449_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/s150x150\\/e15\\/11008101_1593505510894691_369067449_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/e15\\/11008101_1593505510894691_369067449_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1425469470\",\"text\":\"\\u559c\\u6b22\\u8fd9\\u4e2a\\u5b63\\u8282\\u7684\\u5929\\u7a7a\\uff0c\\u4f60\\u627e\\u4e2a\\u8349\\u576a\\u4e00\\u8eba\\uff0c\\u98de\\u673a\\uff0c\\u98ce\\u7b5d\\uff0c\\u9e1f\\u513f\\u5c31\\u90fd\\u5728\\u4e0a\\u8fb9\\uff0c\\u5929\\u6c14\\u597d\\u65f6\\u8fd8\\u80fd\\u770b\\u5230\\u767d\\u5929\\u7684\\u6708\\u4eae\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"933228012653230637\"},\"type\":\"image\",\"id\":\"933228012418349980_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":{\"latitude\":23.479396667,\"longitude\":111.271811667},\"comments\":{\"count\":1,\"data\":[{\"created_time\":\"1425083565\",\"text\":\"\\u597d\\u60f3\\u5403\\uff01\",\"from\":{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},\"id\":\"929990810867579125\"}]},\"filter\":\"Sierra\",\"created_time\":\"1424692998\",\"link\":\"https:\\/\\/instagram.com\\/p\\/zcWez6I7uo\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s320x320\\/e15\\/10958252_1405701033068537_2023890854_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s150x150\\/e15\\/10958252_1405701033068537_2023890854_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/e15\\/10958252_1405701033068537_2023890854_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1424692998\",\"text\":\"\\u5f88\\u591a\\u4e1c\\u897f\\u968f\\u7740\\u6162\\u6162\\u957f\\u5927\\uff0c\\u53d8\\u5f97\\u4e0d\\u50cf\\u5c0f\\u65f6\\u5019\\u90a3\\u6837\\u76fc\\u671b\\u70ed\\u5207\\uff0c\\u6bd4\\u5982\\u5de7\\u514b\\u529b\\u9ea6\\u5f53\\u52b3\\u85af\\u7247\\u96ea\\u7cd5\\u3002\\u53ea\\u6709\\u5bf9\\u62c5\\u5b50\\u7c89\\u7684\\u7231\\u6c38\\u8fdc\\u4e0d\\u53d8\\u7684\\u8bf4\\u2026\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"926714497851439701\"},\"type\":\"image\",\"id\":\"926714497675279272_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":1,\"data\":[{\"created_time\":\"1424356143\",\"text\":\"\\u5927\\u5bb6\\u597d\\u6211\\u662f\\u5f71\\u5e1d\\u65af\\u79d1\\u62c9\\uff01\",\"from\":{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},\"id\":\"923888749621000808\"}]},\"filter\":\"Normal\",\"created_time\":\"1424320197\",\"link\":\"https:\\/\\/instagram.com\\/p\\/zRPazvI7ol\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},{\"username\":\"hank_shop\",\"profile_picture\":\"https:\\/\\/igcdn-photos-h-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/11190127_567862313355599_688691834_a.jpg\",\"id\":\"1612494131\",\"full_name\":\"\\u9ad8\\u7ea7\\u73e0\\u5b9d\\u79c1\\u4eba\\u5b9a\\u5236\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s320x320\\/e15\\/10832246_413065338853260_183697882_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s150x150\\/e15\\/10832246_413065338853260_183697882_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/e15\\/10832246_413065338853260_183697882_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1424320197\",\"text\":\"\\u636e\\u8bf4\\u662f\\u4e00\\u5e74\\u4e00\\u5ea6\\u8003\\u9a8c\\u6f14\\u6280\\u7684\\u65f6\\u5019\\u2026\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"923587211736365325\"},\"type\":\"image\",\"id\":\"923587211543427621_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Aden\",\"created_time\":\"1424252263\",\"link\":\"https:\\/\\/instagram.com\\/p\\/zPN2LtI7sT\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s320x320\\/e15\\/10268927_436139166536328_1377561628_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s150x150\\/e15\\/10268927_436139166536328_1377561628_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/e15\\/10268927_436139166536328_1377561628_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1424252263\",\"text\":\"\\u9508\\u8ff9\\u6591\\u6591\\u7684\\u9999\\u7089\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"923017346843654518\"},\"type\":\"image\",\"id\":\"923017346659105555_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1424099803\",\"link\":\"https:\\/\\/instagram.com\\/p\\/zKrDWlo7gZ\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpt1\\/t51.2885-15\\/s320x320\\/e15\\/11008343_410508022446936_713236389_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpt1\\/t51.2885-15\\/s150x150\\/e15\\/11008343_410508022446936_713236389_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpt1\\/t51.2885-15\\/e15\\/11008343_410508022446936_713236389_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1424099803\",\"text\":\"\\u56de\\u8001\\u5bb6\\u4e86\\uff0c\\u5c0f\\u65f6\\u5019\\u8ddf\\u6211\\u6253\\u8fc7\\u73bb\\u7483\\u73e0\\u7684\\u5c0f\\u4f19\\u4f34\\u4eec\\u5462\\uff1f\\u4f60\\u4eec\\u4e00\\u4e2a\\u5728\\u5317\\u4eac\\uff0c\\u4e00\\u4e2a\\u5728\\u5b89\\u5fbd\\uff0c\\u4e00\\u4e2a\\u5728\\u6fb3\\u6d32\\uff0c\\u4e00\\u4e2a\\u6211\\u90fd\\u4e0d\\u77e5\\u9053\\u4e86\\u2026\\u4f46\\u4f60\\u4eec\\u770b\\u5230\\u73bb\\u7483\\u73e0\\u7684\\u65f6\\u5019\\uff0c\\u8981\\u60f3\\u8d77\\u6211\\u6765\\u554a\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"921738420473281180\"},\"type\":\"image\",\"id\":\"921738420162902041_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1422532011\",\"link\":\"https:\\/\\/instagram.com\\/p\\/yb8uaCI7tt\\/\",\"likes\":{\"count\":4,\"data\":[{\"username\":\"hoffy1117\",\"profile_picture\":\"https:\\/\\/igcdn-photos-h-a.akamaihd.net\\/hphotos-ak-xpa1\\/t51.2885-19\\/10848344_1661033877456607_416512853_a.jpg\",\"id\":\"754263937\",\"full_name\":\"\\ud83c\\udde8\\ud83c\\uddf3Hao.G\\ud83c\\udde8\\ud83c\\uddf3\"},{\"username\":\"zrrff97\",\"profile_picture\":\"https:\\/\\/igcdn-photos-b-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10995234_376996879137889_1932382326_a.jpg\",\"id\":\"460957803\",\"full_name\":\"\"},{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},{\"username\":\"venus_nan\",\"profile_picture\":\"https:\\/\\/igcdn-photos-h-a.akamaihd.net\\/hphotos-ak-xft1\\/t51.2885-19\\/10549834_354763768065767_311951679_a.jpg\",\"id\":\"469639381\",\"full_name\":\"\\ud83d\\udc51\\u6db5baby\\ud83d\\udc51\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10932550_620643038062978_1729442807_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10932550_620643038062978_1729442807_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10932550_620643038062978_1729442807_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1422532011\",\"text\":\"\\u8349\\u5730\\u4e0a\\u9057\\u843d\\u7684\\u978b\\u5b50\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"908586821869615866\"},\"type\":\"image\",\"id\":\"908586821685066605_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":1,\"data\":[{\"created_time\":\"1422231801\",\"text\":\"\\u2728 @houuuuuuuuuu\",\"from\":{\"username\":\"callmejamieee\",\"profile_picture\":\"https:\\/\\/igcdn-photos-b-a.akamaihd.net\\/hphotos-ak-xfa1\\/t51.2885-19\\/11379143_1028356523843961_557603003_a.jpg\",\"id\":\"176277794\",\"full_name\":\"Jamie\"},\"id\":\"906068479900367270\"}]},\"filter\":\"Lo-fi\",\"created_time\":\"1421930605\",\"link\":\"https:\\/\\/instagram.com\\/p\\/yKBopho7mX\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/891532_1563899373855738_1180535181_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/891532_1563899373855738_1180535181_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/891532_1563899373855738_1180535181_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1421930605\",\"text\":\"\\u6709\\u4f4d\\u5f88\\u4e45\\u6ca1\\u8054\\u7cfb\\u7684\\u670b\\u53cb\\u5bc4\\u6765\\u660e\\u4fe1\\u7247\\uff0c\\u8bf4\\uff1a\\u6211\\u5f88\\u5c11\\u770b\\u5230\\u6d77\\uff0c\\u6b63\\u5982\\u4f60\\u6ca1\\u89c1\\u8fc7\\u51e0\\u6b21\\u96ea\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"903541867174672911\"},\"type\":\"image\",\"id\":\"903541866654579095_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1421601776\",\"link\":\"https:\\/\\/instagram.com\\/p\\/yAOcawI7pA\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/10005439_338105566394046_854247264_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/10005439_338105566394046_854247264_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/10005439_338105566394046_854247264_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1421601776\",\"text\":\"\\u6df1\\u591c\\u603b\\u662f\\u7075\\u611f\\u4e4d\\u73b0\\u7684\\u6700\\u4f73\\u65f6\\u671f\\uff0c\\u53ea\\u662f\\u51e0\\u4e2a\\u8bbe\\u8ba1\\u65b9\\u6848\\u90fd\\u6ca1\\u6cd5\\u4f7f\\u81ea\\u5df1\\u6ee1\\u610f\\u3002\\u7d2f\\u4e86\\u6253\\u5f00\\u7a97\\u770b\\u5230\\u5929\\u4e0a\\u6709\\u4e2a\\u5927\\u6708\\u4eae\\uff0c\\u53ea\\u60f3\\u7528\\u56fe\\u7ae0\\u5de5\\u5177\\u628a\\u5b83\\u5e72\\u6389\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"900783451389803192\"},\"type\":\"image\",\"id\":\"900783450995538496_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1421378982\",\"text\":\"\\u8fd9\\u662f\\u85b0\\u8863\\u8349\\u4e48\",\"from\":{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},\"id\":\"898914514733611565\"},{\"created_time\":\"1421601128\",\"text\":\"@whitebadwind \\u4e0d\\u77e5\\u9053\\u4ec0\\u4e48\\u82b1\\uff0c\\u4f46\\u5e94\\u8be5\\u4e0d\\u662f\\u85b0\\u8863\\u8349\\uff0c\\u6728\\u6709\\u9999\\u5473\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"900778013826988166\"}]},\"filter\":\"Normal\",\"created_time\":\"1421370258\",\"link\":\"https:\\/\\/instagram.com\\/p\\/x5U25kI7sN\\/\",\"likes\":{\"count\":4,\"data\":[{\"username\":\"nwheather\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_1018712769_75sq_1390664966.jpg\",\"id\":\"1018712769\",\"full_name\":\"Heather Hynes\"},{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},{\"username\":\"dingstyle\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_30683156_75sq_1333592929.jpg\",\"id\":\"30683156\",\"full_name\":\"Linjie\"},{\"username\":\"candychang1113\",\"profile_picture\":\"https:\\/\\/igcdn-photos-f-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/10725077_1498470533762845_1695396371_a.jpg\",\"id\":\"1133304108\",\"full_name\":\"Candy Chang\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10903312_693622147425934_1766884651_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10903312_693622147425934_1766884651_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10903312_693622147425934_1766884651_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1421370258\",\"text\":\"\\u9762\\u671d\\u5927\\u6d77\\u51ac\\u6696\\u82b1\\u5f00\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"898841334497130569\"},\"type\":\"image\",\"id\":\"898841334228695821_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1421235225\",\"link\":\"https:\\/\\/instagram.com\\/p\\/x1TTZUo7gW\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s320x320\\/e15\\/10914460_1546003772305181_1301162053_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s150x150\\/e15\\/10914460_1546003772305181_1301162053_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/e15\\/10914460_1546003772305181_1301162053_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1421235225\",\"text\":\"\\u5206\\u4eab\\u65e5\\u5e38\\u4e0d\\u6b63\\u5e38\\u751f\\u6d3b\\u7167\\u4e00\\u5f20\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"897708596666809269\"},\"type\":\"image\",\"id\":\"897708596473870358_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1420456723\",\"link\":\"https:\\/\\/instagram.com\\/p\\/xeGbWuo7if\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"sleepgo\",\"profile_picture\":\"https:\\/\\/igcdn-photos-h-a.akamaihd.net\\/hphotos-ak-xpa1\\/t51.2885-19\\/10296686_814576801887247_861033020_a.jpg\",\"id\":\"332373544\",\"full_name\":\"Tony H\"},{\"username\":\"panpanbiu\",\"profile_picture\":\"https:\\/\\/igcdn-photos-a-a.akamaihd.net\\/hphotos-ak-xpa1\\/t51.2885-19\\/11190893_828079227246904_2044492120_a.jpg\",\"id\":\"299823572\",\"full_name\":\"PANPAN\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xta1\\/t51.2885-15\\/s320x320\\/e15\\/10903277_832760670116494_255352239_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xta1\\/t51.2885-15\\/s150x150\\/e15\\/10903277_832760670116494_255352239_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xta1\\/t51.2885-15\\/e15\\/10903277_832760670116494_255352239_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1420456723\",\"text\":\"\\u5176\\u5b9e\\u6211\\u60f3\\uff0c\\u90a3\\u4e9b\\u53e4\\u8001\\u7684\\u6e14\\u6c11\\u4eec\\uff0c\\u6bcf\\u5929\\u770b\\u7740\\u6d77\\u5cb8\\u7ebf\\u7684\\u65e5\\u843d\\u65e5\\u51fa\\uff0c\\u80af\\u5b9a\\u662f\\u6709\\u4eba\\u60f3\\u8fc7\\u5730\\u7403\\u662f\\u5706\\u7684\\u3002\\u800c\\u201c\\u60f3\\u6cd5\\u201d\\u4e0e\\u201c\\u8bc1\\u660e\\u201d\\u4e4b\\u95f4\\uff0c\\u5374\\u8de8\\u8d8a\\u4e86\\u4e00\\u6574\\u6761\\u9ea6\\u54f2\\u4f26\\u822a\\u9053\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"891178044837051035\"},\"type\":\"image\",\"id\":\"891178044375677087_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":{\"latitude\":22.100710837,\"name\":\"\\u73e0\\u6d77\\u957f\\u9686\\u6d77\\u6d0b\\u738b\\u56fd Zhuhai Chimelong Ocean Kingdom\",\"longitude\":113.535968094,\"id\":259203746},\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1420249250\",\"text\":\"\\u8fd9\\u9c7c\\u597d\\u56e7\\uff01\",\"from\":{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},\"id\":\"889437634154445764\"},{\"created_time\":\"1420455887\",\"text\":\"@whitebadwind \\u5927\\u732b\\u4f1a\\u559c\\u6b22\\u7684\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"891171033185499457\"}]},\"filter\":\"Normal\",\"created_time\":\"1420241506\",\"link\":\"https:\\/\\/instagram.com\\/p\\/xXr70fI7iD\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s320x320\\/e15\\/924083_1539057536347062_2062767438_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s150x150\\/e15\\/924083_1539057536347062_2062767438_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/e15\\/924083_1539057536347062_2062767438_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1420241506\",\"text\":\"\\u9c7c\\u5c71\\u9c7c\\u6d77\\u4e2d\\uff0c\\u53ea\\u6709\\u4f60\\uff0c\\u80af\\u5b89\\u9759\\u7684\\u8db4\\u572865\\u5398\\u7c73\\u539a\\u7684\\u4e9a\\u514b\\u529b\\u677f\\u5b50\\u4e0a\\u4e0e\\u6211\\u5408\\u5f71\\uff0c\\u5927\\u4e11\\u9c7c\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"889372678713227478\"},\"type\":\"image\",\"id\":\"889372678235076739_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Hefe\",\"created_time\":\"1420118795\",\"link\":\"https:\\/\\/instagram.com\\/p\\/xUB4dOI7g1\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s320x320\\/e15\\/10890944_765121966897759_2039585477_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s150x150\\/e15\\/10890944_765121966897759_2039585477_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/e15\\/10890944_765121966897759_2039585477_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1420118795\",\"text\":\"\\u65b0\\u5e74\\u5355\\u4eba\\u65c5\\u884c\\u8d70\\u8d77\\u3002\\u5176\\u5b9e\\u4ece\\u4e5d\\u6d32\\u6e2f\\u7801\\u5934\\u5f00\\u59cb\\uff0c\\u73e0\\u6d77\\u5e76\\u6ca1\\u6709\\u7ed9\\u4eba\\u5f88\\u60ca\\u559c\\u7684\\u611f\\u89c9\\uff0c\\u5305\\u62ec\\u76db\\u540d\\u4e4b\\u4e0b\\u7684\\u6cbf\\u6d77\\u98ce\\u5149\\u4e0e\\u6e14\\u5973\\u96d5\\u5851\\u3002\\u5012\\u662f\\u4ea4\\u901a\\u4e0d\\u901a\\u7545\\uff0c\\u4ece\\u8f6e\\u6e21\\u5230\\u516c\\u4ea4\\u90fd\\u7ed9\\u6211\\u5e26\\u6765\\u4e86\\u8bb8\\u591a\\u9ebb\\u70e6\\u3002\\u76f4\\u5230\\uff0c\\u665a\\u4e0a\\u5403\\u70e4\\u751f\\u869d\\u7684\\u7b2c\\u4e00\\u53e3\\uff0c\\u6211\\u53c8\\u89c9\\u5f97\\u4ec0\\u4e48\\u4e8b\\u60c5\\u90fd\\u662f\\u53ef\\u4ee5\\u539f\\u8c05\\u7684\\u2026\\u2026\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"888343304673147100\"},\"type\":\"image\",\"id\":\"888343304211773493_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Unknown\",\"created_time\":\"1420028793\",\"link\":\"https:\\/\\/instagram.com\\/p\\/xRWN47I7pW\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},{\"username\":\"elkakosmoss\",\"profile_picture\":\"https:\\/\\/igcdn-photos-f-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11235915_926324447432373_299446423_a.jpg\",\"id\":\"515503821\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10899183_999582293404177_745539859_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10899183_999582293404177_745539859_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10899183_999582293404177_745539859_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1420028793\",\"text\":\"2014\\u5e74\\u6700\\u540e\\u7684\\u9633\\u5149\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"887588313553418897\"},\"type\":\"image\",\"id\":\"887588313066879574_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1419956909\",\"text\":\"life is art. happy new year! kitty!\",\"from\":{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},\"id\":\"886985301730507751\"},{\"created_time\":\"1420000813\",\"text\":\"@whitebadwind \\u5143\\u65e6\\u5feb\\u4e50\\uff01\\u5343\\u4e07\\u8bb0\\u5f97\\u8981\\u628a\\u6050\\u9f99\\u670d\\u7a7f\\u4e0a\\uff01\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"887353597667556016\"}]},\"filter\":\"Rise\",\"created_time\":\"1419945664\",\"link\":\"https:\\/\\/instagram.com\\/p\\/xO3qREI7iW\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xat1\\/t51.2885-15\\/s320x320\\/e15\\/10894909_702627706517406_1277557620_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xat1\\/t51.2885-15\\/s150x150\\/e15\\/10894909_702627706517406_1277557620_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xat1\\/t51.2885-15\\/e15\\/10894909_702627706517406_1277557620_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1419945664\",\"text\":\"\\u6700\\u540e\\u4e00\\u8282\\u5409\\u4ed6\\u8bfe\\u7ed3\\u675f\\u540e\\uff0c\\u9a6c\\u8def\\u4e0a\\u90a3\\u98ce\\u4e00\\u76f4\\u5439\\uff0c\\u624d\\u611f\\u89c9\\u5357\\u65b9\\u7684\\u51ac\\u5929\\u7ec8\\u4e8e\\u662f\\u6765\\u4e86\\u3002\\u5176\\u5b9e\\u5409\\u4ed6\\u5728\\u51ac\\u5929\\u4f1a\\u6709\\u8bb8\\u591a\\u795e\\u5947\\u7684\\u4e8b\\u60c5\\u3002\\u6bd4\\u5982\\u7434\\u5f26\\u5982\\u808c\\u8089\\u4e00\\u6837\\u56e0\\u51b7\\u800c\\u7d27\\u7ef7\\uff0c\\u53d1\\u51fa\\u6bd4\\u4ee5\\u5f80\\u6c89\\u95f7\\u7684\\u4f4e\\u8bed\\uff1b\\u800c\\u7a7a\\u65f7\\u7684\\u5927\\u6559\\u5ba4\\u91cc\\uff0c\\u5982\\u6709\\u5176\\u4ed6\\u540c\\u4f34\\u62e8\\u54cd\\u548c\\u5f26\\uff0c\\u624b\\u4e2d\\u672c\\u5df2\\u6309\\u706d\\u7684\\u7434\\u5f26\\u53c8\\u4f1a\\u56e0\\u5171\\u9e23\\u5fae\\u5fae\\u98a4\\u52a8\\u3002\\u50cf\\u6709\\u751f\\u547d\\u4e00\\u6837\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"886890974224300917\"},\"type\":\"image\",\"id\":\"886890973737760918_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":5,\"data\":[{\"created_time\":\"1417442768\",\"text\":\"\\u554a\\u96be\\u9053\\u4e0d\\u662f\\u7d2b\\u8346\\uff1f\",\"from\":{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"},\"id\":\"865895159683070128\"},{\"created_time\":\"1417475301\",\"text\":\"\\u597d\\u6f02\\u4eae\\u554a \\u7c89\\u8272\\u7684\\u82b1\\uff01\",\"from\":{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},\"id\":\"866168069916179297\"},{\"created_time\":\"1417833120\",\"text\":\"\\ud83c\\udf40\\ud83c\\udf40\",\"from\":{\"username\":\"h.cmzsq\",\"profile_picture\":\"https:\\/\\/igcdn-photos-e-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/11084897_1407176502933692_1292814398_a.jpg\",\"id\":\"244993178\",\"full_name\":\"\\ud83d\\ude4f\"},\"id\":\"869169669249153672\"},{\"created_time\":\"1419333148\",\"text\":\"incredible @color_blocker\",\"from\":{\"username\":\"jiawenlii\",\"profile_picture\":\"https:\\/\\/igcdn-photos-b-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/11093081_735702273195569_1381487601_a.jpg\",\"id\":\"174509764\",\"full_name\":\"\\u5609\\u6587\"},\"id\":\"881752815517808693\"},{\"created_time\":\"1419333206\",\"text\":\"\\ud83d\\ude0a @nicoledaii\",\"from\":{\"username\":\"lawrencens\",\"profile_picture\":\"https:\\/\\/igcdn-photos-h-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11334406_920682824640599_2112492465_a.jpg\",\"id\":\"398977802\",\"full_name\":\"LIQIANLONG\"},\"id\":\"881753305378961490\"}]},\"filter\":\"Normal\",\"created_time\":\"1417442257\",\"link\":\"https:\\/\\/instagram.com\\/p\\/wEQykeo7tU\\/\",\"likes\":{\"count\":4,\"data\":[{\"username\":\"cicici_ton\",\"profile_picture\":\"https:\\/\\/igcdn-photos-a-a.akamaihd.net\\/hphotos-ak-xap1\\/t51.2885-19\\/10632351_1431817843781696_881928506_a.jpg\",\"id\":\"790581808\",\"full_name\":\"\\u4f5f_\\u5b63\\u521d\"},{\"username\":\"t________.y\",\"profile_picture\":\"https:\\/\\/igcdn-photos-b-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/11203194_820402394704713_1736313100_a.jpg\",\"id\":\"1456056098\",\"full_name\":\"Tiffany\"},{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"},{\"username\":\"dannisdannis\",\"profile_picture\":\"https:\\/\\/igcdn-photos-d-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/10005570_1418618885099779_1080129947_a.jpg\",\"id\":\"1536730862\",\"full_name\":\"Dannis\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10831989_483313928477468_40906631_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10831989_483313928477468_40906631_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10831989_483313928477468_40906631_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1417442257\",\"text\":\"\\u6709\\u68f5\\u4e11\\u6811\\uff0c\\u6211\\u7ecf\\u5e38\\u53bb\\u770b\\uff0c\\u53c8\\u80d6\\u53c8\\u6b6a\\uff0c\\u79c3\\u5f97\\u53ef\\u7b11\\u3002\\u5728\\u53d8\\u51b7\\u7684\\u4e00\\u5929\\uff0c\\u5b83\\u7a81\\u7136\\u5c31\\u5f00\\u82b1\\u4e86\\u3002\\u51ac\\u5929\\u7684\\u82b1\\u6211\\u77e5\\u9053\\u5f97\\u5f88\\u5c11\\uff0c\\u5357\\u65b9\\u6ca1\\u6709\\u6885\\u82b1\\uff0c\\u90a3\\u5c31\\u662f\\u5f02\\u6728\\u68c9\\u4e86\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"865890872693341013\"},\"type\":\"image\",\"id\":\"865890872248744788_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1415725886\",\"text\":\"\\u8fd9\\u4e2a\\u592a\\u5389\\u5bb3\\u4e86\\u5427\\uff01\",\"from\":{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},\"id\":\"851492912496883814\"},{\"created_time\":\"1417137485\",\"text\":\"\\ud83d\\udc4d @color_blocker\",\"from\":{\"username\":\"onelai_kk\",\"profile_picture\":\"https:\\/\\/igcdn-photos-d-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11241982_817407918337387_1779316028_a.jpg\",\"id\":\"1289579257\",\"full_name\":\"instagram\\u4e13\\u4e1a\\u670d\\u52d9\\ud83d\\udc8d\\ud83d\\udc8d\\ud83d\\udc96\\ud83d\\udc96\\ud83d\\udc96\\u2728\\u2728\\u2728\"},\"id\":\"863334257859475861\"}]},\"filter\":\"Walden\",\"created_time\":\"1415683797\",\"link\":\"https:\\/\\/instagram.com\\/p\\/vP2ywuo7pq\\/\",\"likes\":{\"count\":5,\"data\":[{\"username\":\"_llpsssss\",\"profile_picture\":\"https:\\/\\/igcdn-photos-b-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11232835_794856153954569_504179174_a.jpg\",\"id\":\"236870082\",\"full_name\":\"Beijing\\ud83c\\udde8\\ud83c\\uddf3UK\\ud83c\\uddec\\ud83c\\udde7\\ud83d\\udc96\"},{\"username\":\"yenny227\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xta1\\/t51.2885-19\\/10919302_830832643620050_701907926_a.jpg\",\"id\":\"268912251\",\"full_name\":\"\"},{\"username\":\"faifaifai99\",\"profile_picture\":\"https:\\/\\/igcdn-photos-b-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/11098264_102231303441561_1493195010_a.jpg\",\"id\":\"473489307\",\"full_name\":\"\"},{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/s320x320\\/e15\\/10784965_1518537748403855_176956695_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/s150x150\\/e15\\/10784965_1518537748403855_176956695_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/e15\\/10784965_1518537748403855_176956695_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1415683797\",\"text\":\"\\u901a\\u7075\\u4e4b\\u672f\\uff01\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"851139843175201387\"},\"type\":\"image\",\"id\":\"851139837403839082_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Valencia\",\"created_time\":\"1415182653\",\"link\":\"https:\\/\\/instagram.com\\/p\\/vA68BLo7tN\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"yenny227\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xta1\\/t51.2885-19\\/10919302_830832643620050_701907926_a.jpg\",\"id\":\"268912251\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/10735195_1505939246340704_1984926778_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/10735195_1505939246340704_1984926778_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/10735195_1505939246340704_1984926778_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1415182653\",\"text\":\"\\u73b0\\u573a\\u6c14\\u6c1b\\u679c\\u7136\\u4e0d\\u4e00\\u6837\\uff0c\\u9a6c\\u4e0a\\u5c31\\u53ef\\u4ee5\\u770b\\u5230\\u5c0f\\u4f1e\\u5728\\u5927\\u54e5\\u80ef\\u4e0b\\u75af\\u72c2\\u8f93\\u51fa\\u2026\\u662f\\u65f6\\u5019\\u6765\\u9996\\u9009\\u4e00\\u8bb0\\u8587\\u6069\\u4e86\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"846935942288882458\"},\"type\":\"image\",\"id\":\"846935941080922957_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":1,\"data\":[{\"created_time\":\"1415116538\",\"text\":\"@litten225 \\u76f8\\u5f53\\u7ec6\\u817b\\u7684\\u4e66\\u554a\",\"from\":{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},\"id\":\"846381329076697864\"}]},\"filter\":\"Unknown\",\"created_time\":\"1415010755\",\"link\":\"https:\\/\\/instagram.com\\/p\\/u7zEVxo7vw\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"yenny227\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xta1\\/t51.2885-19\\/10919302_830832643620050_701907926_a.jpg\",\"id\":\"268912251\",\"full_name\":\"\"},{\"username\":\"dingstyle\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_30683156_75sq_1333592929.jpg\",\"id\":\"30683156\",\"full_name\":\"Linjie\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/10747711_429336373885590_422028037_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/10747711_429336373885590_422028037_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/10747711_429336373885590_422028037_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1415010755\",\"text\":\"\\u6709\\u670b\\u53cb\\u8ddf\\u6211\\u8bf4\\uff0c\\u632a\\u5a01\\u7684\\u68ee\\u6797\\u6839\\u672c\\u770b\\u4e0d\\u4e0b\\u53bb\\uff1b\\u53c8\\u6709\\u670b\\u53cb\\u8bf4\\uff0c\\u770b\\u8fd9\\u4e66\\u4e00\\u53d1\\u4e0d\\u53ef\\u6536\\u62fe\\u3002\\u5dee\\u522b\\u597d\\u5927\\u5440\\uff01\\u6211\\u5012\\u89c9\\u5f97\\u6709\\u4e2a\\u7b80\\u5355\\u7684\\u65b9\\u6cd5\\uff1a\\u7ffb\\u5230\\u5f00\\u7bc7\\u7684\\u8fd9\\u51e0\\u4e2a\\u5b57\\uff0c\\u5982\\u679c\\u5fc3\\u4e2d\\u4e00\\u7d27\\uff0c\\u90a3\\u5c31\\u8bf4\\u660e\\u8fd9\\u672c\\u4e66\\u9002\\u5408\\u4f60\\uff0c\\u5426\\u5219\\u8bf7\\u5f03\\u4e4b\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"845493955538958871\"},\"type\":\"image\",\"id\":\"845493953693465584_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1414650783\",\"text\":\"cute!\",\"from\":{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},\"id\":\"842474292689222356\"},{\"created_time\":\"1414759282\",\"text\":\"\\ud83c\\udd92 @zhaolei395395\",\"from\":{\"username\":\"tearpkc\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/10611023_1535665483313234_214736228_a.jpg\",\"id\":\"1476911167\",\"full_name\":\"\"},\"id\":\"843384447673023032\"}]},\"filter\":\"Hefe\",\"created_time\":\"1414579138\",\"link\":\"https:\\/\\/instagram.com\\/p\\/uu70zJo7qb\\/\",\"likes\":{\"count\":5,\"data\":[{\"username\":\"cachiulee\",\"profile_picture\":\"https:\\/\\/igcdn-photos-h-a.akamaihd.net\\/hphotos-ak-xfa1\\/t51.2885-19\\/11377676_692543867516879_1892210321_a.jpg\",\"id\":\"951795449\",\"full_name\":\"Tonnie Cox's new ins ac\"},{\"username\":\"yenny227\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xta1\\/t51.2885-19\\/10919302_830832643620050_701907926_a.jpg\",\"id\":\"268912251\",\"full_name\":\"\"},{\"username\":\"fanghonglia292\",\"profile_picture\":\"https:\\/\\/igcdn-photos-f-a.akamaihd.net\\/hphotos-ak-xpa1\\/t51.2885-19\\/10518268_489599821175797_494026352_a.jpg\",\"id\":\"1451952020\",\"full_name\":\"Fanghonglia292\"},{\"username\":\"olivia__cyrus\",\"profile_picture\":\"https:\\/\\/igcdn-photos-f-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/10802807_762277510528189_2055295258_a.jpg\",\"id\":\"619274757\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s320x320\\/e15\\/10735112_730529873702428_413107753_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s150x150\\/e15\\/10735112_730529873702428_413107753_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/e15\\/10735112_730529873702428_413107753_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1414579138\",\"text\":\"\\u5929\\u4e0b\\u7684\\u5c0f\\u997c\\u5e72\\u9047\\u5230\\u6211\\uff0c\\u8c8c\\u4f3c\\u5c31\\u53ea\\u6709\\u4e00\\u79cd\\u4e0b\\u573a\\uff01\\uff01\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"841873294635546895\"},\"type\":\"image\",\"id\":\"841873293444364955_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Earlybird\",\"created_time\":\"1413561977\",\"link\":\"https:\\/\\/instagram.com\\/p\\/uQnvluo7sK\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"yenny227\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xta1\\/t51.2885-19\\/10919302_830832643620050_701907926_a.jpg\",\"id\":\"268912251\",\"full_name\":\"\"},{\"username\":\"wallbase.hd\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/10617029_283951291805046_1229690122_a.jpg\",\"id\":\"1489501811\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/s320x320\\/e15\\/10725177_573652486072155_1401604216_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/s150x150\\/e15\\/10725177_573652486072155_1401604216_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/e15\\/10725177_573652486072155_1401604216_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1413561977\",\"text\":\"\\u4e00\\u4e2a\\u4eba\\uff0c\\u4e00\\u652f\\u53e3\\u7434\\uff0c\\u4e00\\u7247\\u6d77\\uff0c\\u4e00\\u74f6\\u9152\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"833340726864755382\"},\"type\":\"image\",\"id\":\"833340725203811082_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":1,\"data\":[{\"created_time\":\"1413394943\",\"text\":\"cool  @gaoxiaobao_\",\"from\":{\"username\":\"accoo7\",\"profile_picture\":\"https:\\/\\/igcdn-photos-f-a.akamaihd.net\\/hphotos-ak-xap1\\/t51.2885-19\\/10570213_329504053891349_1283692450_a.jpg\",\"id\":\"287433724\",\"full_name\":\"\"},\"id\":\"831939546255178477\"}]},\"filter\":\"Valencia\",\"created_time\":\"1413391668\",\"link\":\"https:\\/\\/instagram.com\\/p\\/uLi56Wo7oO\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"yenny227\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xta1\\/t51.2885-19\\/10919302_830832643620050_701907926_a.jpg\",\"id\":\"268912251\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s320x320\\/e15\\/10724868_302191016652312_2097904817_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s150x150\\/e15\\/10724868_302191016652312_2097904817_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/e15\\/10724868_302191016652312_2097904817_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1413391668\",\"text\":\"\\u300a\\u8bba\\u591c\\u5f52\\uff0c\\u6253\\u7684\\uff0c\\u4ee5\\u53ca\\u53d1\\u7968\\u7684\\u6b63\\u786e\\u7528\\u6cd5\\u300b\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"831912071466826589\"},\"type\":\"image\",\"id\":\"831912069428394510_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Rise\",\"created_time\":\"1413163642\",\"link\":\"https:\\/\\/instagram.com\\/p\\/uEv-tCo7rJ\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"yenny227\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xta1\\/t51.2885-19\\/10919302_830832643620050_701907926_a.jpg\",\"id\":\"268912251\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10731727_461314204008708_386749273_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10731727_461314204008708_386749273_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10731727_461314204008708_386749273_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1413163642\",\"text\":\"\\u7ae5\\u5e74\\u771f\\u597d\\u3002\\u6211\\u4ee5\\u540e\\u4e00\\u5b9a\\u4e0d\\u8981\\u8ddf\\u5b69\\u5b50\\u8bf4\\uff1a\\u5e0c\\u671b\\u4f60\\u5feb\\u9ad8\\u957f\\u5927\\u8fd9\\u79cd\\u50bb\\u8bdd\\u2026\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"829999248859969681\"},\"type\":\"image\",\"id\":\"829999248499260105_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":1,\"data\":[{\"created_time\":\"1412404756\",\"text\":\"\\ud83d\\udc4dGOOD\",\"from\":{\"username\":\"somnusresia\",\"profile_picture\":\"https:\\/\\/igcdn-photos-a-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11380897_1586097328311216_1597361628_a.jpg\",\"id\":\"249391877\",\"full_name\":\"Somnus Wen\"},\"id\":\"823633252150655824\"}]},\"filter\":\"Valencia\",\"created_time\":\"1411652721\",\"link\":\"https:\\/\\/instagram.com\\/p\\/tXuIHso7qK\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"yenny227\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xta1\\/t51.2885-19\\/10919302_830832643620050_701907926_a.jpg\",\"id\":\"268912251\",\"full_name\":\"\"},{\"username\":\"cherrymomo412\",\"profile_picture\":\"https:\\/\\/igcdn-photos-a-a.akamaihd.net\\/hphotos-ak-xap1\\/t51.2885-19\\/10802961_759165964121336_488483054_a.jpg\",\"id\":\"54007423\",\"full_name\":\"cherrymomo\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s320x320\\/e15\\/10616983_1382591478697855_2107473552_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s150x150\\/e15\\/10616983_1382591478697855_2107473552_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/e15\\/10616983_1382591478697855_2107473552_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1411652721\",\"text\":\"\\u6211\\u7684\\u597d\\u670b\\u53cb\\u2014\\u2014\\u8d85\\u7ea7\\u9ad8\\u51b7\\u8d85\\u7ea7\\u78e8\\u4eba\\u7684\\u4e1d\\u74dc\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"817324726096738307\"},\"type\":\"image\",\"id\":\"817324725551479434_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}}]}","source":"instagram/ins0.json","raw":"{\"pagination\":{\"next_url\":\"https:\\/\\/api.instagram.com\\/v1\\/users\\/438522285\\/media\\/recent?count=100\\u0026callback=jQuery19008141340191941708_1433432491285\\u0026client_id=956dd096b6e5496aba6662165b9b8443\\u0026max_id=817324725551479434_438522285\\u0026_=1433432491286\",\"next_max_id\":\"817324725551479434_438522285\"},\"meta\":{\"code\":200},\"data\":[{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Lark\",\"created_time\":\"1433424772\",\"link\":\"https:\\/\\/instagram.com\\/p\\/3glBKbI7jm\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s320x320\\/e15\\/11375982_491190547696110_2013240096_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s150x150\\/e15\\/11375982_491190547696110_2013240096_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/e15\\/11375982_491190547696110_2013240096_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1433424772\",\"text\":\"\\u5c0f\\u841d\\u8389\\u4e0d\\u613f\\u56de\\u5bb6\\uff0c\\u8ddf\\u5976\\u5976\\u8bf4\\uff1a\\u201c\\u518d\\u8ba9\\u6211\\u73a9\\u4f1a\\uff0c\\u660e\\u5929\\u8981\\u5b66\\u94a2\\u7434\\uff0c\\u540e\\u5929\\u8981\\u5b66\\u8df3\\u821e\\uff0c\\u5c31\\u6765\\u4e0d\\u4e86\\u8fd9\\u513f\\u73a9\\u4e86\\u3002\\u201d\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"999961926134119385\"},\"type\":\"image\",\"id\":\"999961924909381862_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":5,\"data\":[{\"created_time\":\"1432100935\",\"text\":\"\\ud83d\\ude0a\",\"from\":{\"username\":\"muvanmf\",\"profile_picture\":\"https:\\/\\/igcdn-photos-f-a.akamaihd.net\\/hphotos-ak-xfa1\\/t51.2885-19\\/11334455_1615248035385837_1443100648_a.jpg\",\"id\":\"1200885749\",\"full_name\":\"\"},\"id\":\"988856776283895820\"},{\"created_time\":\"1432500874\",\"text\":\"\\ud83d\\ude0a\",\"from\":{\"username\":\"y_lang99\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11373510_386713434848322_1596956169_a.jpg\",\"id\":\"1509502800\",\"full_name\":\"\\u2728\\u5c0f\\u963f\\u6d6a\\uff5e\"},\"id\":\"992211705421609081\"},{\"created_time\":\"1432886603\",\"text\":\"\\ud83d\\udc4d\",\"from\":{\"username\":\"cp_water_h2o\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xap1\\/t51.2885-19\\/11191155_897877480271222_1196332450_a.jpg\",\"id\":\"46708139\",\"full_name\":\"\"},\"id\":\"995447436348733496\"},{\"created_time\":\"1433035543\",\"text\":\"\\ud83d\\ude04\",\"from\":{\"username\":\"vocalmomoko\",\"profile_picture\":\"https:\\/\\/igcdn-photos-f-a.akamaihd.net\\/hphotos-ak-xfa1\\/t51.2885-19\\/10601848_849046995107581_1799487354_a.jpg\",\"id\":\"280464724\",\"full_name\":\"Momoko\"},\"id\":\"996696839524956493\"},{\"created_time\":\"1433035564\",\"text\":\"nice  @Ijustinchen\",\"from\":{\"username\":\"dikenxoen\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/925345_933363483364074_1000071537_a.jpg\",\"id\":\"1649582238\",\"full_name\":\"\"},\"id\":\"996697009528486242\"}]},\"filter\":\"Lo-fi\",\"created_time\":\"1432095934\",\"link\":\"https:\\/\\/instagram.com\\/p\\/24-dd6o7uB\\/\",\"likes\":{\"count\":4,\"data\":[{\"username\":\"oliviayhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11326269_1439141373071498_1054025241_a.jpg\",\"id\":\"10631089\",\"full_name\":\"Olivia Yang\"},{\"username\":\"zx_9451\",\"profile_picture\":\"https:\\/\\/igcdn-photos-a-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11327937_953513731373032_1587298722_a.jpg\",\"id\":\"1147297522\",\"full_name\":\"\\u8d24\\u59b9\\u59b9ZX\"},{\"username\":\"irissssw\",\"profile_picture\":\"https:\\/\\/igcdn-photos-d-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/11005023_732965413468795_1308833307_a.jpg\",\"id\":\"231558542\",\"full_name\":\"Iris.W\"},{\"username\":\"juxiequechuicai\",\"profile_picture\":\"https:\\/\\/igcdn-photos-f-a.akamaihd.net\\/hphotos-ak-xap1\\/t51.2885-19\\/10932562_1408525596106461_81586164_a.jpg\",\"id\":\"1649588862\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s320x320\\/e15\\/11252751_1444216632541093_1558227860_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s150x150\\/e15\\/11252751_1444216632541093_1558227860_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/e15\\/11252751_1444216632541093_1558227860_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1432095934\",\"text\":\"\\u98ce\\u96e8\\u6b32\\u6765\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"988814823345338742\"},\"type\":\"image\",\"id\":\"988814822078659457_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"videos\":{\"low_bandwidth\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t50.2886-16\\/11234567_805492662880042_967794598_s.mp4\",\"width\":480,\"height\":480},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t50.2886-16\\/11235514_1629635357248662_1505532808_n.mp4\",\"width\":640,\"height\":640},\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t50.2886-16\\/11234567_805492662880042_967794598_s.mp4\",\"width\":480,\"height\":480}},\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Ashby\",\"created_time\":\"1431736282\",\"link\":\"https:\\/\\/instagram.com\\/p\\/2uQeuaI7nv\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"ashleyfashionblogger\",\"profile_picture\":\"https:\\/\\/igcdn-photos-a-a.akamaihd.net\\/hphotos-ak-xpa1\\/t51.2885-19\\/11190869_428988550612824_1565351360_a.jpg\",\"id\":\"1172999152\",\"full_name\":\"Ashley\\u7cbe\\u5c16\\u5962\\u54c1\"},{\"username\":\"jijileexi\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/10914307_1531769583766522_1188586237_a.jpg\",\"id\":\"1668534092\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s320x320\\/e15\\/11226595_701075516681953_1354085958_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s150x150\\/e15\\/11226595_701075516681953_1354085958_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/e15\\/11226595_701075516681953_1354085958_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1431736282\",\"text\":\"\\u91ce\\u751f\\u6d77\\u5e26\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"985797850168539756\"},\"type\":\"video\",\"id\":\"985797848599869935_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"videos\":{\"low_bandwidth\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t50.2886-16\\/11100588_1627658390782524_1406603363_s.mp4\",\"width\":480,\"height\":480},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t50.2886-16\\/11123341_1574707489481834_1444136079_n.mp4\",\"width\":640,\"height\":640},\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t50.2886-16\\/11100588_1627658390782524_1406603363_s.mp4\",\"width\":480,\"height\":480}},\"tags\":[],\"location\":null,\"comments\":{\"count\":3,\"data\":[{\"created_time\":\"1428633555\",\"text\":\"@nanako0606 :)\",\"from\":{\"username\":\"lvhombeme\",\"profile_picture\":\"https:\\/\\/igcdn-photos-h-a.akamaihd.net\\/hphotos-ak-xap1\\/t51.2885-19\\/11190759_712908695501663_547363914_a.jpg\",\"id\":\"30244942\",\"full_name\":\"\"},\"id\":\"959770281262693297\"},{\"created_time\":\"1428952602\",\"text\":\"\\ud83d\\udc98\\ud83d\\udc98 @MIKATTONG\",\"from\":{\"username\":\"kaogai\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10431811_753900654665570_1046066069_a.jpg\",\"id\":\"1588508371\",\"full_name\":\"\"},\"id\":\"962446649029016324\"},{\"created_time\":\"1430583831\",\"text\":\"\\ud83d\\ude0a\",\"from\":{\"username\":\"geyaoxian\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/11203210_832251100188962_1484152822_a.jpg\",\"id\":\"1026707646\",\"full_name\":\"\\u845b\\u8000\\u5148\"},\"id\":\"976130389424978098\"}]},\"filter\":\"Clarendon\",\"created_time\":\"1428315781\",\"link\":\"https:\\/\\/instagram.com\\/p\\/1IUZByo7vP\\/\",\"likes\":{\"count\":4,\"data\":[{\"username\":\"barb1e2u\",\"profile_picture\":\"https:\\/\\/igcdn-photos-d-a.akamaihd.net\\/hphotos-ak-xap1\\/t51.2885-19\\/11184633_436852723162235_673116011_a.jpg\",\"id\":\"1543932897\",\"full_name\":\"Barbie\\ud83d\\udc8bWeChat:88315113\\ud83d\\udcf2\"},{\"username\":\"huanglh3o3\",\"profile_picture\":\"https:\\/\\/igcdn-photos-b-a.akamaihd.net\\/hphotos-ak-xtf1\\/t51.2885-19\\/11098542_1557115881228953_2108051141_a.jpg\",\"id\":\"1244702090\",\"full_name\":\"\"},{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},{\"username\":\"lixxin1\",\"profile_picture\":\"https:\\/\\/igcdn-photos-b-a.akamaihd.net\\/hphotos-ak-xfa1\\/t51.2885-19\\/10724134_1498809703714993_666658303_a.jpg\",\"id\":\"474735109\",\"full_name\":\"\\u674e\\u7d2b\\u6b23\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpt1\\/t51.2885-15\\/s320x320\\/e15\\/11142212_609961145801361_1913577076_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpt1\\/t51.2885-15\\/s150x150\\/e15\\/11142212_609961145801361_1913577076_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpt1\\/t51.2885-15\\/e15\\/11142212_609961145801361_1913577076_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1428315781\",\"text\":\"\\u8981\\u56de\\u53bb\\u5566\\uff0c\\u518d\\u89c1\\u5317\\u6d41\\u6cb3\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"957104601967082317\"},\"type\":\"video\",\"id\":\"957104601656703951_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Ludwig\",\"created_time\":\"1428314611\",\"link\":\"https:\\/\\/instagram.com\\/p\\/1ISKRxo7r8\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/11049421_1375007652828983_401355534_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/11049421_1375007652828983_401355534_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/11049421_1375007652828983_401355534_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1428314611\",\"text\":\"\\u7075\\u829dget\\u221a\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"957094792144337138\"},\"type\":\"image\",\"id\":\"957094791934622460_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Nashville\",\"created_time\":\"1428245860\",\"link\":\"https:\\/\\/instagram.com\\/p\\/1GPBzpo7qW\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/s320x320\\/e15\\/11137852_1649834698581861_1050691792_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/s150x150\\/e15\\/11137852_1649834698581861_1050691792_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfa1\\/t51.2885-15\\/e15\\/11137852_1649834698581861_1050691792_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1428245860\",\"text\":\"\\u8fd9\\u91cc\\u7684\\u6e05\\u660e\\u662f\\u4e2a\\u5f88\\u91cd\\u8981\\u7684\\u8282\\u65e5\\uff0c\\u5b50\\u5b59\\u4eec\\u90fd\\u4f1a\\u56de\\u6765\\uff0c\\u8dcb\\u5c71\\u6d89\\u6c34\\uff0c\\u7af9\\u6392\\u6e21\\u6c5f\\uff0c\\u8352\\u5c71\\u5bfb\\u8def\\uff0c\\u51ed\\u96c6\\u4f53\\u7684\\u8bb0\\u5fc6\\u5bfb\\u627e\\u5217\\u7956\\u5217\\u5b97\\u7684\\u5b9d\\u5730\\uff0c\\u5bc4\\u54c0\\u601d\\uff0c\\u4e5f\\u6c42\\u798f\\u5fb7\\u3002\\u4e00\\u8def\\u4e0a\\u53ef\\u4ee5\\u542c\\u4ed6\\u4eec\\u5520\\u53e8\\u65e7\\u4e8b\\uff0c\\u4e5f\\u6709\\u8d85\\u7ea7\\u9760\\u8c31\\u7684\\u98ce\\u6c34\\u79d1\\u666e\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"956518065923930728\"},\"type\":\"image\",\"id\":\"956518065739381398_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Mayfair\",\"created_time\":\"1428228071\",\"link\":\"https:\\/\\/instagram.com\\/p\\/1FtGO3I7kN\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/11055751_1573536912901494_1683773508_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/11055751_1573536912901494_1683773508_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/11055751_1573536912901494_1683773508_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1428228071\",\"text\":\"\\u4e3a\\u4e86\\u90e8\\u843d\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"956368836446370643\"},\"type\":\"image\",\"id\":\"956368836253432077_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Mayfair\",\"created_time\":\"1428131481\",\"link\":\"https:\\/\\/instagram.com\\/p\\/1C03iPI7hZ\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/11055897_1407191599597961_1763496348_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/11055897_1407191599597961_1763496348_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/11055897_1407191599597961_1763496348_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1428131481\",\"text\":\"\\u5728\\u6e05\\u660e\\u7684\\u5c71\\u8def\\u9047\\u5230\\u4e86\\u5929\\u7136\\u677e\\u9999\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"955558585941866653\"},\"type\":\"image\",\"id\":\"955558585706985561_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Crema\",\"created_time\":\"1427801745\",\"link\":\"https:\\/\\/instagram.com\\/p\\/04_8fwo7gL\\/\",\"likes\":{\"count\":3,\"data\":[{\"username\":\"bo0oo0\",\"profile_picture\":\"https:\\/\\/igcdn-photos-e-a.akamaihd.net\\/hphotos-ak-xfa1\\/t51.2885-19\\/10507930_301607313382260_661513528_a.jpg\",\"id\":\"51426891\",\"full_name\":\"\"},{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtf1\\/t51.2885-15\\/s320x320\\/e15\\/11123665_1542600796003839_1576473443_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtf1\\/t51.2885-15\\/s150x150\\/e15\\/11123665_1542600796003839_1576473443_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtf1\\/t51.2885-15\\/e15\\/11123665_1542600796003839_1576473443_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1427801745\",\"text\":\"\\u5982\\u679c\\u4f60\\u98de\\u5f97\\u50cf\\u6708\\u4eae\\u8fd9\\u4e48\\u9ad8\\uff0c\\u5c31\\u4e0d\\u4f1a\\u6401\\u6d45\\u5728\\u6811\\u4e0a\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"952792555599411873\"},\"type\":\"image\",\"id\":\"952792555389696011_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":{\"latitude\":22.538938333,\"longitude\":113.92382},\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1425469470\",\"link\":\"https:\\/\\/instagram.com\\/p\\/zzfe7Oo7uc\\/\",\"likes\":{\"count\":4,\"data\":[{\"username\":\"kai_efforts\",\"profile_picture\":\"https:\\/\\/igcdn-photos-b-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11326569_447841455377553_1276311913_a.jpg\",\"id\":\"1319736417\",\"full_name\":\"\\u5f35\\u51f1\\u8317KAI\"},{\"username\":\"yinggg0830\",\"profile_picture\":\"https:\\/\\/igcdn-photos-e-a.akamaihd.net\\/hphotos-ak-xpa1\\/t51.2885-19\\/11191229_478700095619252_1507412393_a.jpg\",\"id\":\"303041107\",\"full_name\":\"\"},{\"username\":\"aofeixi\",\"profile_picture\":\"https:\\/\\/igcdn-photos-a-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/10899120_578003152334536_1461658615_a.jpg\",\"id\":\"1648133428\",\"full_name\":\"\"},{\"username\":\"ritababe_\",\"profile_picture\":\"https:\\/\\/igcdn-photos-e-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11018358_387855874729324_717730599_a.jpg\",\"id\":\"40610366\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/s320x320\\/e15\\/11008101_1593505510894691_369067449_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/s150x150\\/e15\\/11008101_1593505510894691_369067449_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/e15\\/11008101_1593505510894691_369067449_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1425469470\",\"text\":\"\\u559c\\u6b22\\u8fd9\\u4e2a\\u5b63\\u8282\\u7684\\u5929\\u7a7a\\uff0c\\u4f60\\u627e\\u4e2a\\u8349\\u576a\\u4e00\\u8eba\\uff0c\\u98de\\u673a\\uff0c\\u98ce\\u7b5d\\uff0c\\u9e1f\\u513f\\u5c31\\u90fd\\u5728\\u4e0a\\u8fb9\\uff0c\\u5929\\u6c14\\u597d\\u65f6\\u8fd8\\u80fd\\u770b\\u5230\\u767d\\u5929\\u7684\\u6708\\u4eae\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"933228012653230637\"},\"type\":\"image\",\"id\":\"933228012418349980_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":{\"latitude\":23.479396667,\"longitude\":111.271811667},\"comments\":{\"count\":1,\"data\":[{\"created_time\":\"1425083565\",\"text\":\"\\u597d\\u60f3\\u5403\\uff01\",\"from\":{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},\"id\":\"929990810867579125\"}]},\"filter\":\"Sierra\",\"created_time\":\"1424692998\",\"link\":\"https:\\/\\/instagram.com\\/p\\/zcWez6I7uo\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s320x320\\/e15\\/10958252_1405701033068537_2023890854_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s150x150\\/e15\\/10958252_1405701033068537_2023890854_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/e15\\/10958252_1405701033068537_2023890854_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1424692998\",\"text\":\"\\u5f88\\u591a\\u4e1c\\u897f\\u968f\\u7740\\u6162\\u6162\\u957f\\u5927\\uff0c\\u53d8\\u5f97\\u4e0d\\u50cf\\u5c0f\\u65f6\\u5019\\u90a3\\u6837\\u76fc\\u671b\\u70ed\\u5207\\uff0c\\u6bd4\\u5982\\u5de7\\u514b\\u529b\\u9ea6\\u5f53\\u52b3\\u85af\\u7247\\u96ea\\u7cd5\\u3002\\u53ea\\u6709\\u5bf9\\u62c5\\u5b50\\u7c89\\u7684\\u7231\\u6c38\\u8fdc\\u4e0d\\u53d8\\u7684\\u8bf4\\u2026\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"926714497851439701\"},\"type\":\"image\",\"id\":\"926714497675279272_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":1,\"data\":[{\"created_time\":\"1424356143\",\"text\":\"\\u5927\\u5bb6\\u597d\\u6211\\u662f\\u5f71\\u5e1d\\u65af\\u79d1\\u62c9\\uff01\",\"from\":{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},\"id\":\"923888749621000808\"}]},\"filter\":\"Normal\",\"created_time\":\"1424320197\",\"link\":\"https:\\/\\/instagram.com\\/p\\/zRPazvI7ol\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},{\"username\":\"hank_shop\",\"profile_picture\":\"https:\\/\\/igcdn-photos-h-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/11190127_567862313355599_688691834_a.jpg\",\"id\":\"1612494131\",\"full_name\":\"\\u9ad8\\u7ea7\\u73e0\\u5b9d\\u79c1\\u4eba\\u5b9a\\u5236\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s320x320\\/e15\\/10832246_413065338853260_183697882_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s150x150\\/e15\\/10832246_413065338853260_183697882_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/e15\\/10832246_413065338853260_183697882_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1424320197\",\"text\":\"\\u636e\\u8bf4\\u662f\\u4e00\\u5e74\\u4e00\\u5ea6\\u8003\\u9a8c\\u6f14\\u6280\\u7684\\u65f6\\u5019\\u2026\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"923587211736365325\"},\"type\":\"image\",\"id\":\"923587211543427621_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Aden\",\"created_time\":\"1424252263\",\"link\":\"https:\\/\\/instagram.com\\/p\\/zPN2LtI7sT\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s320x320\\/e15\\/10268927_436139166536328_1377561628_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s150x150\\/e15\\/10268927_436139166536328_1377561628_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/e15\\/10268927_436139166536328_1377561628_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1424252263\",\"text\":\"\\u9508\\u8ff9\\u6591\\u6591\\u7684\\u9999\\u7089\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"923017346843654518\"},\"type\":\"image\",\"id\":\"923017346659105555_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1424099803\",\"link\":\"https:\\/\\/instagram.com\\/p\\/zKrDWlo7gZ\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpt1\\/t51.2885-15\\/s320x320\\/e15\\/11008343_410508022446936_713236389_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpt1\\/t51.2885-15\\/s150x150\\/e15\\/11008343_410508022446936_713236389_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpt1\\/t51.2885-15\\/e15\\/11008343_410508022446936_713236389_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1424099803\",\"text\":\"\\u56de\\u8001\\u5bb6\\u4e86\\uff0c\\u5c0f\\u65f6\\u5019\\u8ddf\\u6211\\u6253\\u8fc7\\u73bb\\u7483\\u73e0\\u7684\\u5c0f\\u4f19\\u4f34\\u4eec\\u5462\\uff1f\\u4f60\\u4eec\\u4e00\\u4e2a\\u5728\\u5317\\u4eac\\uff0c\\u4e00\\u4e2a\\u5728\\u5b89\\u5fbd\\uff0c\\u4e00\\u4e2a\\u5728\\u6fb3\\u6d32\\uff0c\\u4e00\\u4e2a\\u6211\\u90fd\\u4e0d\\u77e5\\u9053\\u4e86\\u2026\\u4f46\\u4f60\\u4eec\\u770b\\u5230\\u73bb\\u7483\\u73e0\\u7684\\u65f6\\u5019\\uff0c\\u8981\\u60f3\\u8d77\\u6211\\u6765\\u554a\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"921738420473281180\"},\"type\":\"image\",\"id\":\"921738420162902041_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1422532011\",\"link\":\"https:\\/\\/instagram.com\\/p\\/yb8uaCI7tt\\/\",\"likes\":{\"count\":4,\"data\":[{\"username\":\"hoffy1117\",\"profile_picture\":\"https:\\/\\/igcdn-photos-h-a.akamaihd.net\\/hphotos-ak-xpa1\\/t51.2885-19\\/10848344_1661033877456607_416512853_a.jpg\",\"id\":\"754263937\",\"full_name\":\"\\ud83c\\udde8\\ud83c\\uddf3Hao.G\\ud83c\\udde8\\ud83c\\uddf3\"},{\"username\":\"zrrff97\",\"profile_picture\":\"https:\\/\\/igcdn-photos-b-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10995234_376996879137889_1932382326_a.jpg\",\"id\":\"460957803\",\"full_name\":\"\"},{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},{\"username\":\"venus_nan\",\"profile_picture\":\"https:\\/\\/igcdn-photos-h-a.akamaihd.net\\/hphotos-ak-xft1\\/t51.2885-19\\/10549834_354763768065767_311951679_a.jpg\",\"id\":\"469639381\",\"full_name\":\"\\ud83d\\udc51\\u6db5baby\\ud83d\\udc51\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10932550_620643038062978_1729442807_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10932550_620643038062978_1729442807_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10932550_620643038062978_1729442807_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1422532011\",\"text\":\"\\u8349\\u5730\\u4e0a\\u9057\\u843d\\u7684\\u978b\\u5b50\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"908586821869615866\"},\"type\":\"image\",\"id\":\"908586821685066605_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":1,\"data\":[{\"created_time\":\"1422231801\",\"text\":\"\\u2728 @houuuuuuuuuu\",\"from\":{\"username\":\"callmejamieee\",\"profile_picture\":\"https:\\/\\/igcdn-photos-b-a.akamaihd.net\\/hphotos-ak-xfa1\\/t51.2885-19\\/11379143_1028356523843961_557603003_a.jpg\",\"id\":\"176277794\",\"full_name\":\"Jamie\"},\"id\":\"906068479900367270\"}]},\"filter\":\"Lo-fi\",\"created_time\":\"1421930605\",\"link\":\"https:\\/\\/instagram.com\\/p\\/yKBopho7mX\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/891532_1563899373855738_1180535181_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/891532_1563899373855738_1180535181_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/891532_1563899373855738_1180535181_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1421930605\",\"text\":\"\\u6709\\u4f4d\\u5f88\\u4e45\\u6ca1\\u8054\\u7cfb\\u7684\\u670b\\u53cb\\u5bc4\\u6765\\u660e\\u4fe1\\u7247\\uff0c\\u8bf4\\uff1a\\u6211\\u5f88\\u5c11\\u770b\\u5230\\u6d77\\uff0c\\u6b63\\u5982\\u4f60\\u6ca1\\u89c1\\u8fc7\\u51e0\\u6b21\\u96ea\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"903541867174672911\"},\"type\":\"image\",\"id\":\"903541866654579095_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1421601776\",\"link\":\"https:\\/\\/instagram.com\\/p\\/yAOcawI7pA\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/10005439_338105566394046_854247264_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/10005439_338105566394046_854247264_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/10005439_338105566394046_854247264_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1421601776\",\"text\":\"\\u6df1\\u591c\\u603b\\u662f\\u7075\\u611f\\u4e4d\\u73b0\\u7684\\u6700\\u4f73\\u65f6\\u671f\\uff0c\\u53ea\\u662f\\u51e0\\u4e2a\\u8bbe\\u8ba1\\u65b9\\u6848\\u90fd\\u6ca1\\u6cd5\\u4f7f\\u81ea\\u5df1\\u6ee1\\u610f\\u3002\\u7d2f\\u4e86\\u6253\\u5f00\\u7a97\\u770b\\u5230\\u5929\\u4e0a\\u6709\\u4e2a\\u5927\\u6708\\u4eae\\uff0c\\u53ea\\u60f3\\u7528\\u56fe\\u7ae0\\u5de5\\u5177\\u628a\\u5b83\\u5e72\\u6389\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"900783451389803192\"},\"type\":\"image\",\"id\":\"900783450995538496_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1421378982\",\"text\":\"\\u8fd9\\u662f\\u85b0\\u8863\\u8349\\u4e48\",\"from\":{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},\"id\":\"898914514733611565\"},{\"created_time\":\"1421601128\",\"text\":\"@whitebadwind \\u4e0d\\u77e5\\u9053\\u4ec0\\u4e48\\u82b1\\uff0c\\u4f46\\u5e94\\u8be5\\u4e0d\\u662f\\u85b0\\u8863\\u8349\\uff0c\\u6728\\u6709\\u9999\\u5473\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"900778013826988166\"}]},\"filter\":\"Normal\",\"created_time\":\"1421370258\",\"link\":\"https:\\/\\/instagram.com\\/p\\/x5U25kI7sN\\/\",\"likes\":{\"count\":4,\"data\":[{\"username\":\"nwheather\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_1018712769_75sq_1390664966.jpg\",\"id\":\"1018712769\",\"full_name\":\"Heather Hynes\"},{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},{\"username\":\"dingstyle\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_30683156_75sq_1333592929.jpg\",\"id\":\"30683156\",\"full_name\":\"Linjie\"},{\"username\":\"candychang1113\",\"profile_picture\":\"https:\\/\\/igcdn-photos-f-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/10725077_1498470533762845_1695396371_a.jpg\",\"id\":\"1133304108\",\"full_name\":\"Candy Chang\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10903312_693622147425934_1766884651_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10903312_693622147425934_1766884651_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10903312_693622147425934_1766884651_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1421370258\",\"text\":\"\\u9762\\u671d\\u5927\\u6d77\\u51ac\\u6696\\u82b1\\u5f00\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"898841334497130569\"},\"type\":\"image\",\"id\":\"898841334228695821_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1421235225\",\"link\":\"https:\\/\\/instagram.com\\/p\\/x1TTZUo7gW\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s320x320\\/e15\\/10914460_1546003772305181_1301162053_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s150x150\\/e15\\/10914460_1546003772305181_1301162053_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/e15\\/10914460_1546003772305181_1301162053_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1421235225\",\"text\":\"\\u5206\\u4eab\\u65e5\\u5e38\\u4e0d\\u6b63\\u5e38\\u751f\\u6d3b\\u7167\\u4e00\\u5f20\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"897708596666809269\"},\"type\":\"image\",\"id\":\"897708596473870358_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Normal\",\"created_time\":\"1420456723\",\"link\":\"https:\\/\\/instagram.com\\/p\\/xeGbWuo7if\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"sleepgo\",\"profile_picture\":\"https:\\/\\/igcdn-photos-h-a.akamaihd.net\\/hphotos-ak-xpa1\\/t51.2885-19\\/10296686_814576801887247_861033020_a.jpg\",\"id\":\"332373544\",\"full_name\":\"Tony H\"},{\"username\":\"panpanbiu\",\"profile_picture\":\"https:\\/\\/igcdn-photos-a-a.akamaihd.net\\/hphotos-ak-xpa1\\/t51.2885-19\\/11190893_828079227246904_2044492120_a.jpg\",\"id\":\"299823572\",\"full_name\":\"PANPAN\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xta1\\/t51.2885-15\\/s320x320\\/e15\\/10903277_832760670116494_255352239_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xta1\\/t51.2885-15\\/s150x150\\/e15\\/10903277_832760670116494_255352239_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xta1\\/t51.2885-15\\/e15\\/10903277_832760670116494_255352239_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1420456723\",\"text\":\"\\u5176\\u5b9e\\u6211\\u60f3\\uff0c\\u90a3\\u4e9b\\u53e4\\u8001\\u7684\\u6e14\\u6c11\\u4eec\\uff0c\\u6bcf\\u5929\\u770b\\u7740\\u6d77\\u5cb8\\u7ebf\\u7684\\u65e5\\u843d\\u65e5\\u51fa\\uff0c\\u80af\\u5b9a\\u662f\\u6709\\u4eba\\u60f3\\u8fc7\\u5730\\u7403\\u662f\\u5706\\u7684\\u3002\\u800c\\u201c\\u60f3\\u6cd5\\u201d\\u4e0e\\u201c\\u8bc1\\u660e\\u201d\\u4e4b\\u95f4\\uff0c\\u5374\\u8de8\\u8d8a\\u4e86\\u4e00\\u6574\\u6761\\u9ea6\\u54f2\\u4f26\\u822a\\u9053\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"891178044837051035\"},\"type\":\"image\",\"id\":\"891178044375677087_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":{\"latitude\":22.100710837,\"name\":\"\\u73e0\\u6d77\\u957f\\u9686\\u6d77\\u6d0b\\u738b\\u56fd Zhuhai Chimelong Ocean Kingdom\",\"longitude\":113.535968094,\"id\":259203746},\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1420249250\",\"text\":\"\\u8fd9\\u9c7c\\u597d\\u56e7\\uff01\",\"from\":{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},\"id\":\"889437634154445764\"},{\"created_time\":\"1420455887\",\"text\":\"@whitebadwind \\u5927\\u732b\\u4f1a\\u559c\\u6b22\\u7684\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"891171033185499457\"}]},\"filter\":\"Normal\",\"created_time\":\"1420241506\",\"link\":\"https:\\/\\/instagram.com\\/p\\/xXr70fI7iD\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s320x320\\/e15\\/924083_1539057536347062_2062767438_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/s150x150\\/e15\\/924083_1539057536347062_2062767438_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpf1\\/t51.2885-15\\/e15\\/924083_1539057536347062_2062767438_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1420241506\",\"text\":\"\\u9c7c\\u5c71\\u9c7c\\u6d77\\u4e2d\\uff0c\\u53ea\\u6709\\u4f60\\uff0c\\u80af\\u5b89\\u9759\\u7684\\u8db4\\u572865\\u5398\\u7c73\\u539a\\u7684\\u4e9a\\u514b\\u529b\\u677f\\u5b50\\u4e0a\\u4e0e\\u6211\\u5408\\u5f71\\uff0c\\u5927\\u4e11\\u9c7c\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"889372678713227478\"},\"type\":\"image\",\"id\":\"889372678235076739_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Hefe\",\"created_time\":\"1420118795\",\"link\":\"https:\\/\\/instagram.com\\/p\\/xUB4dOI7g1\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s320x320\\/e15\\/10890944_765121966897759_2039585477_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s150x150\\/e15\\/10890944_765121966897759_2039585477_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/e15\\/10890944_765121966897759_2039585477_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1420118795\",\"text\":\"\\u65b0\\u5e74\\u5355\\u4eba\\u65c5\\u884c\\u8d70\\u8d77\\u3002\\u5176\\u5b9e\\u4ece\\u4e5d\\u6d32\\u6e2f\\u7801\\u5934\\u5f00\\u59cb\\uff0c\\u73e0\\u6d77\\u5e76\\u6ca1\\u6709\\u7ed9\\u4eba\\u5f88\\u60ca\\u559c\\u7684\\u611f\\u89c9\\uff0c\\u5305\\u62ec\\u76db\\u540d\\u4e4b\\u4e0b\\u7684\\u6cbf\\u6d77\\u98ce\\u5149\\u4e0e\\u6e14\\u5973\\u96d5\\u5851\\u3002\\u5012\\u662f\\u4ea4\\u901a\\u4e0d\\u901a\\u7545\\uff0c\\u4ece\\u8f6e\\u6e21\\u5230\\u516c\\u4ea4\\u90fd\\u7ed9\\u6211\\u5e26\\u6765\\u4e86\\u8bb8\\u591a\\u9ebb\\u70e6\\u3002\\u76f4\\u5230\\uff0c\\u665a\\u4e0a\\u5403\\u70e4\\u751f\\u869d\\u7684\\u7b2c\\u4e00\\u53e3\\uff0c\\u6211\\u53c8\\u89c9\\u5f97\\u4ec0\\u4e48\\u4e8b\\u60c5\\u90fd\\u662f\\u53ef\\u4ee5\\u539f\\u8c05\\u7684\\u2026\\u2026\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"888343304673147100\"},\"type\":\"image\",\"id\":\"888343304211773493_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Unknown\",\"created_time\":\"1420028793\",\"link\":\"https:\\/\\/instagram.com\\/p\\/xRWN47I7pW\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},{\"username\":\"elkakosmoss\",\"profile_picture\":\"https:\\/\\/igcdn-photos-f-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11235915_926324447432373_299446423_a.jpg\",\"id\":\"515503821\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10899183_999582293404177_745539859_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10899183_999582293404177_745539859_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10899183_999582293404177_745539859_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1420028793\",\"text\":\"2014\\u5e74\\u6700\\u540e\\u7684\\u9633\\u5149\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"887588313553418897\"},\"type\":\"image\",\"id\":\"887588313066879574_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1419956909\",\"text\":\"life is art. happy new year! kitty!\",\"from\":{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},\"id\":\"886985301730507751\"},{\"created_time\":\"1420000813\",\"text\":\"@whitebadwind \\u5143\\u65e6\\u5feb\\u4e50\\uff01\\u5343\\u4e07\\u8bb0\\u5f97\\u8981\\u628a\\u6050\\u9f99\\u670d\\u7a7f\\u4e0a\\uff01\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"887353597667556016\"}]},\"filter\":\"Rise\",\"created_time\":\"1419945664\",\"link\":\"https:\\/\\/instagram.com\\/p\\/xO3qREI7iW\\/\",\"likes\":{\"count\":0,\"data\":[]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xat1\\/t51.2885-15\\/s320x320\\/e15\\/10894909_702627706517406_1277557620_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xat1\\/t51.2885-15\\/s150x150\\/e15\\/10894909_702627706517406_1277557620_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xat1\\/t51.2885-15\\/e15\\/10894909_702627706517406_1277557620_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1419945664\",\"text\":\"\\u6700\\u540e\\u4e00\\u8282\\u5409\\u4ed6\\u8bfe\\u7ed3\\u675f\\u540e\\uff0c\\u9a6c\\u8def\\u4e0a\\u90a3\\u98ce\\u4e00\\u76f4\\u5439\\uff0c\\u624d\\u611f\\u89c9\\u5357\\u65b9\\u7684\\u51ac\\u5929\\u7ec8\\u4e8e\\u662f\\u6765\\u4e86\\u3002\\u5176\\u5b9e\\u5409\\u4ed6\\u5728\\u51ac\\u5929\\u4f1a\\u6709\\u8bb8\\u591a\\u795e\\u5947\\u7684\\u4e8b\\u60c5\\u3002\\u6bd4\\u5982\\u7434\\u5f26\\u5982\\u808c\\u8089\\u4e00\\u6837\\u56e0\\u51b7\\u800c\\u7d27\\u7ef7\\uff0c\\u53d1\\u51fa\\u6bd4\\u4ee5\\u5f80\\u6c89\\u95f7\\u7684\\u4f4e\\u8bed\\uff1b\\u800c\\u7a7a\\u65f7\\u7684\\u5927\\u6559\\u5ba4\\u91cc\\uff0c\\u5982\\u6709\\u5176\\u4ed6\\u540c\\u4f34\\u62e8\\u54cd\\u548c\\u5f26\\uff0c\\u624b\\u4e2d\\u672c\\u5df2\\u6309\\u706d\\u7684\\u7434\\u5f26\\u53c8\\u4f1a\\u56e0\\u5171\\u9e23\\u5fae\\u5fae\\u98a4\\u52a8\\u3002\\u50cf\\u6709\\u751f\\u547d\\u4e00\\u6837\\u3002\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"886890974224300917\"},\"type\":\"image\",\"id\":\"886890973737760918_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":5,\"data\":[{\"created_time\":\"1417442768\",\"text\":\"\\u554a\\u96be\\u9053\\u4e0d\\u662f\\u7d2b\\u8346\\uff1f\",\"from\":{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"},\"id\":\"865895159683070128\"},{\"created_time\":\"1417475301\",\"text\":\"\\u597d\\u6f02\\u4eae\\u554a \\u7c89\\u8272\\u7684\\u82b1\\uff01\",\"from\":{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},\"id\":\"866168069916179297\"},{\"created_time\":\"1417833120\",\"text\":\"\\ud83c\\udf40\\ud83c\\udf40\",\"from\":{\"username\":\"h.cmzsq\",\"profile_picture\":\"https:\\/\\/igcdn-photos-e-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/11084897_1407176502933692_1292814398_a.jpg\",\"id\":\"244993178\",\"full_name\":\"\\ud83d\\ude4f\"},\"id\":\"869169669249153672\"},{\"created_time\":\"1419333148\",\"text\":\"incredible @color_blocker\",\"from\":{\"username\":\"jiawenlii\",\"profile_picture\":\"https:\\/\\/igcdn-photos-b-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/11093081_735702273195569_1381487601_a.jpg\",\"id\":\"174509764\",\"full_name\":\"\\u5609\\u6587\"},\"id\":\"881752815517808693\"},{\"created_time\":\"1419333206\",\"text\":\"\\ud83d\\ude0a @nicoledaii\",\"from\":{\"username\":\"lawrencens\",\"profile_picture\":\"https:\\/\\/igcdn-photos-h-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11334406_920682824640599_2112492465_a.jpg\",\"id\":\"398977802\",\"full_name\":\"LIQIANLONG\"},\"id\":\"881753305378961490\"}]},\"filter\":\"Normal\",\"created_time\":\"1417442257\",\"link\":\"https:\\/\\/instagram.com\\/p\\/wEQykeo7tU\\/\",\"likes\":{\"count\":4,\"data\":[{\"username\":\"cicici_ton\",\"profile_picture\":\"https:\\/\\/igcdn-photos-a-a.akamaihd.net\\/hphotos-ak-xap1\\/t51.2885-19\\/10632351_1431817843781696_881928506_a.jpg\",\"id\":\"790581808\",\"full_name\":\"\\u4f5f_\\u5b63\\u521d\"},{\"username\":\"t________.y\",\"profile_picture\":\"https:\\/\\/igcdn-photos-b-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/11203194_820402394704713_1736313100_a.jpg\",\"id\":\"1456056098\",\"full_name\":\"Tiffany\"},{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"},{\"username\":\"dannisdannis\",\"profile_picture\":\"https:\\/\\/igcdn-photos-d-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/10005570_1418618885099779_1080129947_a.jpg\",\"id\":\"1536730862\",\"full_name\":\"Dannis\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10831989_483313928477468_40906631_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10831989_483313928477468_40906631_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10831989_483313928477468_40906631_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1417442257\",\"text\":\"\\u6709\\u68f5\\u4e11\\u6811\\uff0c\\u6211\\u7ecf\\u5e38\\u53bb\\u770b\\uff0c\\u53c8\\u80d6\\u53c8\\u6b6a\\uff0c\\u79c3\\u5f97\\u53ef\\u7b11\\u3002\\u5728\\u53d8\\u51b7\\u7684\\u4e00\\u5929\\uff0c\\u5b83\\u7a81\\u7136\\u5c31\\u5f00\\u82b1\\u4e86\\u3002\\u51ac\\u5929\\u7684\\u82b1\\u6211\\u77e5\\u9053\\u5f97\\u5f88\\u5c11\\uff0c\\u5357\\u65b9\\u6ca1\\u6709\\u6885\\u82b1\\uff0c\\u90a3\\u5c31\\u662f\\u5f02\\u6728\\u68c9\\u4e86\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"865890872693341013\"},\"type\":\"image\",\"id\":\"865890872248744788_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1415725886\",\"text\":\"\\u8fd9\\u4e2a\\u592a\\u5389\\u5bb3\\u4e86\\u5427\\uff01\",\"from\":{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},\"id\":\"851492912496883814\"},{\"created_time\":\"1417137485\",\"text\":\"\\ud83d\\udc4d @color_blocker\",\"from\":{\"username\":\"onelai_kk\",\"profile_picture\":\"https:\\/\\/igcdn-photos-d-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11241982_817407918337387_1779316028_a.jpg\",\"id\":\"1289579257\",\"full_name\":\"instagram\\u4e13\\u4e1a\\u670d\\u52d9\\ud83d\\udc8d\\ud83d\\udc8d\\ud83d\\udc96\\ud83d\\udc96\\ud83d\\udc96\\u2728\\u2728\\u2728\"},\"id\":\"863334257859475861\"}]},\"filter\":\"Walden\",\"created_time\":\"1415683797\",\"link\":\"https:\\/\\/instagram.com\\/p\\/vP2ywuo7pq\\/\",\"likes\":{\"count\":5,\"data\":[{\"username\":\"_llpsssss\",\"profile_picture\":\"https:\\/\\/igcdn-photos-b-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11232835_794856153954569_504179174_a.jpg\",\"id\":\"236870082\",\"full_name\":\"Beijing\\ud83c\\udde8\\ud83c\\uddf3UK\\ud83c\\uddec\\ud83c\\udde7\\ud83d\\udc96\"},{\"username\":\"yenny227\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xta1\\/t51.2885-19\\/10919302_830832643620050_701907926_a.jpg\",\"id\":\"268912251\",\"full_name\":\"\"},{\"username\":\"faifaifai99\",\"profile_picture\":\"https:\\/\\/igcdn-photos-b-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/11098264_102231303441561_1493195010_a.jpg\",\"id\":\"473489307\",\"full_name\":\"\"},{\"username\":\"sasanzuo\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_235236445_75sq_1393055700.jpg\",\"id\":\"235236445\",\"full_name\":\"\\u8428\\u6851\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/s320x320\\/e15\\/10784965_1518537748403855_176956695_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/s150x150\\/e15\\/10784965_1518537748403855_176956695_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/e15\\/10784965_1518537748403855_176956695_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1415683797\",\"text\":\"\\u901a\\u7075\\u4e4b\\u672f\\uff01\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"851139843175201387\"},\"type\":\"image\",\"id\":\"851139837403839082_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Valencia\",\"created_time\":\"1415182653\",\"link\":\"https:\\/\\/instagram.com\\/p\\/vA68BLo7tN\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"yenny227\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xta1\\/t51.2885-19\\/10919302_830832643620050_701907926_a.jpg\",\"id\":\"268912251\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/10735195_1505939246340704_1984926778_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/10735195_1505939246340704_1984926778_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/10735195_1505939246340704_1984926778_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1415182653\",\"text\":\"\\u73b0\\u573a\\u6c14\\u6c1b\\u679c\\u7136\\u4e0d\\u4e00\\u6837\\uff0c\\u9a6c\\u4e0a\\u5c31\\u53ef\\u4ee5\\u770b\\u5230\\u5c0f\\u4f1e\\u5728\\u5927\\u54e5\\u80ef\\u4e0b\\u75af\\u72c2\\u8f93\\u51fa\\u2026\\u662f\\u65f6\\u5019\\u6765\\u9996\\u9009\\u4e00\\u8bb0\\u8587\\u6069\\u4e86\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"846935942288882458\"},\"type\":\"image\",\"id\":\"846935941080922957_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":1,\"data\":[{\"created_time\":\"1415116538\",\"text\":\"@litten225 \\u76f8\\u5f53\\u7ec6\\u817b\\u7684\\u4e66\\u554a\",\"from\":{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},\"id\":\"846381329076697864\"}]},\"filter\":\"Unknown\",\"created_time\":\"1415010755\",\"link\":\"https:\\/\\/instagram.com\\/p\\/u7zEVxo7vw\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"yenny227\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xta1\\/t51.2885-19\\/10919302_830832643620050_701907926_a.jpg\",\"id\":\"268912251\",\"full_name\":\"\"},{\"username\":\"dingstyle\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_30683156_75sq_1333592929.jpg\",\"id\":\"30683156\",\"full_name\":\"Linjie\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s320x320\\/e15\\/10747711_429336373885590_422028037_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/s150x150\\/e15\\/10747711_429336373885590_422028037_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xfp1\\/t51.2885-15\\/e15\\/10747711_429336373885590_422028037_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1415010755\",\"text\":\"\\u6709\\u670b\\u53cb\\u8ddf\\u6211\\u8bf4\\uff0c\\u632a\\u5a01\\u7684\\u68ee\\u6797\\u6839\\u672c\\u770b\\u4e0d\\u4e0b\\u53bb\\uff1b\\u53c8\\u6709\\u670b\\u53cb\\u8bf4\\uff0c\\u770b\\u8fd9\\u4e66\\u4e00\\u53d1\\u4e0d\\u53ef\\u6536\\u62fe\\u3002\\u5dee\\u522b\\u597d\\u5927\\u5440\\uff01\\u6211\\u5012\\u89c9\\u5f97\\u6709\\u4e2a\\u7b80\\u5355\\u7684\\u65b9\\u6cd5\\uff1a\\u7ffb\\u5230\\u5f00\\u7bc7\\u7684\\u8fd9\\u51e0\\u4e2a\\u5b57\\uff0c\\u5982\\u679c\\u5fc3\\u4e2d\\u4e00\\u7d27\\uff0c\\u90a3\\u5c31\\u8bf4\\u660e\\u8fd9\\u672c\\u4e66\\u9002\\u5408\\u4f60\\uff0c\\u5426\\u5219\\u8bf7\\u5f03\\u4e4b\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"845493955538958871\"},\"type\":\"image\",\"id\":\"845493953693465584_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":2,\"data\":[{\"created_time\":\"1414650783\",\"text\":\"cute!\",\"from\":{\"username\":\"zhengezhao\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xfp1\\/t51.2885-19\\/10727551_282259975296534_305711726_a.jpg\",\"id\":\"1531642371\",\"full_name\":\"Zhenge Zhao\"},\"id\":\"842474292689222356\"},{\"created_time\":\"1414759282\",\"text\":\"\\ud83c\\udd92 @zhaolei395395\",\"from\":{\"username\":\"tearpkc\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/10611023_1535665483313234_214736228_a.jpg\",\"id\":\"1476911167\",\"full_name\":\"\"},\"id\":\"843384447673023032\"}]},\"filter\":\"Hefe\",\"created_time\":\"1414579138\",\"link\":\"https:\\/\\/instagram.com\\/p\\/uu70zJo7qb\\/\",\"likes\":{\"count\":5,\"data\":[{\"username\":\"cachiulee\",\"profile_picture\":\"https:\\/\\/igcdn-photos-h-a.akamaihd.net\\/hphotos-ak-xfa1\\/t51.2885-19\\/11377676_692543867516879_1892210321_a.jpg\",\"id\":\"951795449\",\"full_name\":\"Tonnie Cox's new ins ac\"},{\"username\":\"yenny227\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xta1\\/t51.2885-19\\/10919302_830832643620050_701907926_a.jpg\",\"id\":\"268912251\",\"full_name\":\"\"},{\"username\":\"fanghonglia292\",\"profile_picture\":\"https:\\/\\/igcdn-photos-f-a.akamaihd.net\\/hphotos-ak-xpa1\\/t51.2885-19\\/10518268_489599821175797_494026352_a.jpg\",\"id\":\"1451952020\",\"full_name\":\"Fanghonglia292\"},{\"username\":\"olivia__cyrus\",\"profile_picture\":\"https:\\/\\/igcdn-photos-f-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/10802807_762277510528189_2055295258_a.jpg\",\"id\":\"619274757\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s320x320\\/e15\\/10735112_730529873702428_413107753_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/s150x150\\/e15\\/10735112_730529873702428_413107753_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xpa1\\/t51.2885-15\\/e15\\/10735112_730529873702428_413107753_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1414579138\",\"text\":\"\\u5929\\u4e0b\\u7684\\u5c0f\\u997c\\u5e72\\u9047\\u5230\\u6211\\uff0c\\u8c8c\\u4f3c\\u5c31\\u53ea\\u6709\\u4e00\\u79cd\\u4e0b\\u573a\\uff01\\uff01\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"841873294635546895\"},\"type\":\"image\",\"id\":\"841873293444364955_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Earlybird\",\"created_time\":\"1413561977\",\"link\":\"https:\\/\\/instagram.com\\/p\\/uQnvluo7sK\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"yenny227\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xta1\\/t51.2885-19\\/10919302_830832643620050_701907926_a.jpg\",\"id\":\"268912251\",\"full_name\":\"\"},{\"username\":\"wallbase.hd\",\"profile_picture\":\"https:\\/\\/igcdn-photos-g-a.akamaihd.net\\/hphotos-ak-xpf1\\/t51.2885-19\\/10617029_283951291805046_1229690122_a.jpg\",\"id\":\"1489501811\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/s320x320\\/e15\\/10725177_573652486072155_1401604216_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/s150x150\\/e15\\/10725177_573652486072155_1401604216_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xtp1\\/t51.2885-15\\/e15\\/10725177_573652486072155_1401604216_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1413561977\",\"text\":\"\\u4e00\\u4e2a\\u4eba\\uff0c\\u4e00\\u652f\\u53e3\\u7434\\uff0c\\u4e00\\u7247\\u6d77\\uff0c\\u4e00\\u74f6\\u9152\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"833340726864755382\"},\"type\":\"image\",\"id\":\"833340725203811082_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":1,\"data\":[{\"created_time\":\"1413394943\",\"text\":\"cool  @gaoxiaobao_\",\"from\":{\"username\":\"accoo7\",\"profile_picture\":\"https:\\/\\/igcdn-photos-f-a.akamaihd.net\\/hphotos-ak-xap1\\/t51.2885-19\\/10570213_329504053891349_1283692450_a.jpg\",\"id\":\"287433724\",\"full_name\":\"\"},\"id\":\"831939546255178477\"}]},\"filter\":\"Valencia\",\"created_time\":\"1413391668\",\"link\":\"https:\\/\\/instagram.com\\/p\\/uLi56Wo7oO\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"yenny227\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xta1\\/t51.2885-19\\/10919302_830832643620050_701907926_a.jpg\",\"id\":\"268912251\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s320x320\\/e15\\/10724868_302191016652312_2097904817_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s150x150\\/e15\\/10724868_302191016652312_2097904817_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/e15\\/10724868_302191016652312_2097904817_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1413391668\",\"text\":\"\\u300a\\u8bba\\u591c\\u5f52\\uff0c\\u6253\\u7684\\uff0c\\u4ee5\\u53ca\\u53d1\\u7968\\u7684\\u6b63\\u786e\\u7528\\u6cd5\\u300b\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"831912071466826589\"},\"type\":\"image\",\"id\":\"831912069428394510_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":0,\"data\":[]},\"filter\":\"Rise\",\"created_time\":\"1413163642\",\"link\":\"https:\\/\\/instagram.com\\/p\\/uEv-tCo7rJ\\/\",\"likes\":{\"count\":1,\"data\":[{\"username\":\"yenny227\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xta1\\/t51.2885-19\\/10919302_830832643620050_701907926_a.jpg\",\"id\":\"268912251\",\"full_name\":\"\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s320x320\\/e15\\/10731727_461314204008708_386749273_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/s150x150\\/e15\\/10731727_461314204008708_386749273_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xap1\\/t51.2885-15\\/e15\\/10731727_461314204008708_386749273_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1413163642\",\"text\":\"\\u7ae5\\u5e74\\u771f\\u597d\\u3002\\u6211\\u4ee5\\u540e\\u4e00\\u5b9a\\u4e0d\\u8981\\u8ddf\\u5b69\\u5b50\\u8bf4\\uff1a\\u5e0c\\u671b\\u4f60\\u5feb\\u9ad8\\u957f\\u5927\\u8fd9\\u79cd\\u50bb\\u8bdd\\u2026\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"829999248859969681\"},\"type\":\"image\",\"id\":\"829999248499260105_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}},{\"attribution\":null,\"tags\":[],\"location\":null,\"comments\":{\"count\":1,\"data\":[{\"created_time\":\"1412404756\",\"text\":\"\\ud83d\\udc4dGOOD\",\"from\":{\"username\":\"somnusresia\",\"profile_picture\":\"https:\\/\\/igcdn-photos-a-a.akamaihd.net\\/hphotos-ak-xaf1\\/t51.2885-19\\/11380897_1586097328311216_1597361628_a.jpg\",\"id\":\"249391877\",\"full_name\":\"Somnus Wen\"},\"id\":\"823633252150655824\"}]},\"filter\":\"Valencia\",\"created_time\":\"1411652721\",\"link\":\"https:\\/\\/instagram.com\\/p\\/tXuIHso7qK\\/\",\"likes\":{\"count\":2,\"data\":[{\"username\":\"yenny227\",\"profile_picture\":\"https:\\/\\/igcdn-photos-c-a.akamaihd.net\\/hphotos-ak-xta1\\/t51.2885-19\\/10919302_830832643620050_701907926_a.jpg\",\"id\":\"268912251\",\"full_name\":\"\"},{\"username\":\"cherrymomo412\",\"profile_picture\":\"https:\\/\\/igcdn-photos-a-a.akamaihd.net\\/hphotos-ak-xap1\\/t51.2885-19\\/10802961_759165964121336_488483054_a.jpg\",\"id\":\"54007423\",\"full_name\":\"cherrymomo\"}]},\"images\":{\"low_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s320x320\\/e15\\/10616983_1382591478697855_2107473552_n.jpg\",\"width\":320,\"height\":320},\"thumbnail\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/s150x150\\/e15\\/10616983_1382591478697855_2107473552_n.jpg\",\"width\":150,\"height\":150},\"standard_resolution\":{\"url\":\"https:\\/\\/scontent.cdninstagram.com\\/hphotos-xaf1\\/t51.2885-15\\/e15\\/10616983_1382591478697855_2107473552_n.jpg\",\"width\":640,\"height\":640}},\"users_in_photo\":[],\"caption\":{\"created_time\":\"1411652721\",\"text\":\"\\u6211\\u7684\\u597d\\u670b\\u53cb\\u2014\\u2014\\u8d85\\u7ea7\\u9ad8\\u51b7\\u8d85\\u7ea7\\u78e8\\u4eba\\u7684\\u4e1d\\u74dc\",\"from\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"},\"id\":\"817324726096738307\"},\"type\":\"image\",\"id\":\"817324725551479434_438522285\",\"user\":{\"username\":\"litten225\",\"profile_picture\":\"https:\\/\\/instagramimages-a.akamaihd.net\\/profiles\\/profile_438522285_75sq_1393602208.jpg\",\"id\":\"438522285\",\"full_name\":\"litten\"}}]}","date":"2015-11-22T05:12:27.375Z","updated":"2015-11-22T05:12:27.375Z","path":"instagram/ins0.json","layout":"false","title":"","comments":1,"_id":"cimigpysu002e6cujoccq9b1w"},{"layout":"post","slug":"instagram","title":"相册","noDate":"true","comments":0,"_content":"\n<div class=\"instagram\" data-client-id=\"956dd096b6e5496aba6662165b9b8443\">\n\t<a href=\"http://instagram.com/litten225\" target=\"_blank\" class=\"open-ins\">图片来自instagram，正在加载中…</a>\n</div>","source":"instagram/index.ejs","raw":"---\nlayout: post\nslug: \"instagram\"\ntitle: \"相册\"\nnoDate: \"true\"\ncomments: false\n---\n\n<div class=\"instagram\" data-client-id=\"956dd096b6e5496aba6662165b9b8443\">\n\t<a href=\"http://instagram.com/litten225\" target=\"_blank\" class=\"open-ins\">图片来自instagram，正在加载中…</a>\n</div>","date":"2015-11-22T05:12:27.374Z","updated":"2015-11-22T05:12:27.374Z","path":"instagram/index.html","_id":"cimigpysw002f6cuj0su5li1x"},{"layout":"about","title":"赞助","noDate":"true","comments":1,"_content":"\n## **爱心赞助**\n\n---\n\n欢迎来到由[刘帝伟]维护的个人技术博客...\n\n\n- 如果您觉得本博客对您有帮助，欢迎来此捐赠你的爱心^\\_^，一分一毛都是支持，在此，先衷心的谢过啦。\n\n\n### **赞助方式：**\n\n- 支付宝账号（liudiwei18@sina.com）\n- 微信(Devin_hippo)\n- 或直接扫二维码捐助。\n\n<image style=\"border:0px\" width=\"800\" src=\"/assets/images/denote.jpg\"/>\n\n\n\n","source":"donation/index.md","raw":"---\nlayout: about\ntitle: \"赞助\"\nnoDate: \"true\"\ncomments: true\n---\n\n## **爱心赞助**\n\n---\n\n欢迎来到由[刘帝伟]维护的个人技术博客...\n\n\n- 如果您觉得本博客对您有帮助，欢迎来此捐赠你的爱心^\\_^，一分一毛都是支持，在此，先衷心的谢过啦。\n\n\n### **赞助方式：**\n\n- 支付宝账号（liudiwei18@sina.com）\n- 微信(Devin_hippo)\n- 或直接扫二维码捐助。\n\n<image style=\"border:0px\" width=\"800\" src=\"/assets/images/denote.jpg\"/>\n\n\n\n","date":"2015-11-22T11:18:52.003Z","updated":"2015-11-22T11:18:52.003Z","path":"donation/index.html","_id":"cimigpyt1002g6cujq9cz28bi"},{"title":"categories","date":"2015-10-19T03:27:29.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"title: categories\ndate: 2015-10-19 11:27:29\ntype: \"categories\"\ncomments: false\n---\n","updated":"2015-11-22T05:12:27.365Z","path":"categories/index.html","layout":"page","_id":"cimigpyt3002h6cuji95hc0qf"},{"layout":"about","title":"About Me","noDate":"true","comments":1,"_content":"\n欢迎来到由『刘帝伟』维护的个人技术博客.\n\n## 个人简介\n\n中南大学在读硕士，数学出生，研究方向为机器学习与生物计算（[Our Lab](http://dlab.csu.edu.cn/index.html)），长期关注机器学习、数据挖掘与人工智能领域。\n\n<!-- - [简历 - 中文](http://csuldw.github.io/resume/resume_zh.pdf)-->\n\n有追求，才有动力！有梦想，才会拼搏！\n\n\n## 兴趣爱好\n\n\n爬山、摄影、跑步、散步、看电影、听歌、看书、摩卡、焦糖玛奇朵、拿铁、牛排、奶茶、羊岩勾青、绿茶、茉莉花茶、香蕉、火龙果、草莓、蓝莓、花生、三月萢、唱Ｋ、乒乓、溜冰（双排）、游泳、象棋、轻音乐、Markdown、Wikipedia、Google、Quora、YouTube、Sina、知乎、机器学习、Math、Algorithms、Python、Java、C++、Leetcode、CSDN、Github、博客、Linux、SPN、Beyond、张国荣、刘德华、舒畅、乔布斯、Ng、小小、长沙、蓝色、白色、黑色、橘黄色、Photoshop、写笔记、三月、思考、发呆、大学、旅游、511 etc.\n\n\n\n## 获得奖励\n\n2015年，研究生国家奖学金，中南大学“优秀研究生”，中软实训“优秀开发团队奖”与“个人优胜奖”；  \n2013年，湖南农业大学“优秀毕业生”，Top 5%;  \n2012年，大学生“国家励志奖学金”，湖南农业大学数学建模大赛二等奖，湖南农业大学校级二等奖学金，三好学生；  \n2011年，全国大学生数学建模大赛湖南赛区本科组三等奖，优秀学生干部；  \n2010年，大学生“国家一等助学金”，湖南农业大学“校级一等奖学金”，三好学生.\n  \n\n## 发表论文\n\n[1] Fan, Chao, Diwei Liu, Rui Huang, Zhigang Chen, and Lei Deng. \"PredRSA: a gradient boosted regression trees approach for predicting protein solvent accessibility.\" **BMC Bioinformatics** 17, no. 1 (2016): 85. \n[2] Yong Gao, Weilin Hao, Jing Gu, Diwei Liu, Chao Fan and Lei Deng. PredPhos: An Ensemble Framework for Structure-based Prediction of Phosphorylation Sites. **Journal of Biological Research-Thessalonki**, 2015.  \n[3] Meng, Yang, Lei Deng, Zhigang Chen, Cheng Zhou, Diwei Liu, Chao Fan, and Ting Yan. \"A Multi-Instance Multi-Label Learning Approach for Protein Domain Annotation.\" In **Intelligent Computing in Bioinformatics**, pp. 104-111. Springer International Publishing, 2014.\n\n\n\n---\n\n如果您有什么建议，请在下方留言，或是QQ联系本人，又或是发E-mail吧！\n\n\nQ Q： 466454368\t  \t  \nE-mail： [csu.ldw@csu.edu.cn](mailto:csu.ldw@csu.edu.cn) \n<center>\n<iframe src=\"http://www.google.cn/maps/embed?pb=!1m18!1m12!1m3!1d3518.2573505277455!2d112.98802651280161!3d28.138652839545976!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x3420b54da152a8b3%3A0x3bd670822384b1c6!2z5Lit5Y2X5aSn5a2m6ZOB6YGT5a2m6ZmiIOa5luWNl-ecgemVv-aymeW4guWkqeW_g-WMuumCruaUv-e8lueggTogNDEwMDAw!5e0!3m2!1szh-CN!2scn!4v1458285640054\" width=\"600\" height=\"350\" frameborder=\"0\" style=\"border:0\" allowfullscreen></iframe>\n</center>\n\n\n\n","source":"about/index.md","raw":"---\nlayout: about\ntitle: \"About Me\"\nnoDate: \"true\"\ncomments: true\n---\n\n欢迎来到由『刘帝伟』维护的个人技术博客.\n\n## 个人简介\n\n中南大学在读硕士，数学出生，研究方向为机器学习与生物计算（[Our Lab](http://dlab.csu.edu.cn/index.html)），长期关注机器学习、数据挖掘与人工智能领域。\n\n<!-- - [简历 - 中文](http://csuldw.github.io/resume/resume_zh.pdf)-->\n\n有追求，才有动力！有梦想，才会拼搏！\n\n\n## 兴趣爱好\n\n\n爬山、摄影、跑步、散步、看电影、听歌、看书、摩卡、焦糖玛奇朵、拿铁、牛排、奶茶、羊岩勾青、绿茶、茉莉花茶、香蕉、火龙果、草莓、蓝莓、花生、三月萢、唱Ｋ、乒乓、溜冰（双排）、游泳、象棋、轻音乐、Markdown、Wikipedia、Google、Quora、YouTube、Sina、知乎、机器学习、Math、Algorithms、Python、Java、C++、Leetcode、CSDN、Github、博客、Linux、SPN、Beyond、张国荣、刘德华、舒畅、乔布斯、Ng、小小、长沙、蓝色、白色、黑色、橘黄色、Photoshop、写笔记、三月、思考、发呆、大学、旅游、511 etc.\n\n\n\n## 获得奖励\n\n2015年，研究生国家奖学金，中南大学“优秀研究生”，中软实训“优秀开发团队奖”与“个人优胜奖”；  \n2013年，湖南农业大学“优秀毕业生”，Top 5%;  \n2012年，大学生“国家励志奖学金”，湖南农业大学数学建模大赛二等奖，湖南农业大学校级二等奖学金，三好学生；  \n2011年，全国大学生数学建模大赛湖南赛区本科组三等奖，优秀学生干部；  \n2010年，大学生“国家一等助学金”，湖南农业大学“校级一等奖学金”，三好学生.\n  \n\n## 发表论文\n\n[1] Fan, Chao, Diwei Liu, Rui Huang, Zhigang Chen, and Lei Deng. \"PredRSA: a gradient boosted regression trees approach for predicting protein solvent accessibility.\" **BMC Bioinformatics** 17, no. 1 (2016): 85. \n[2] Yong Gao, Weilin Hao, Jing Gu, Diwei Liu, Chao Fan and Lei Deng. PredPhos: An Ensemble Framework for Structure-based Prediction of Phosphorylation Sites. **Journal of Biological Research-Thessalonki**, 2015.  \n[3] Meng, Yang, Lei Deng, Zhigang Chen, Cheng Zhou, Diwei Liu, Chao Fan, and Ting Yan. \"A Multi-Instance Multi-Label Learning Approach for Protein Domain Annotation.\" In **Intelligent Computing in Bioinformatics**, pp. 104-111. Springer International Publishing, 2014.\n\n\n\n---\n\n如果您有什么建议，请在下方留言，或是QQ联系本人，又或是发E-mail吧！\n\n\nQ Q： 466454368\t  \t  \nE-mail： [csu.ldw@csu.edu.cn](mailto:csu.ldw@csu.edu.cn) \n<center>\n<iframe src=\"http://www.google.cn/maps/embed?pb=!1m18!1m12!1m3!1d3518.2573505277455!2d112.98802651280161!3d28.138652839545976!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x3420b54da152a8b3%3A0x3bd670822384b1c6!2z5Lit5Y2X5aSn5a2m6ZOB6YGT5a2m6ZmiIOa5luWNl-ecgemVv-aymeW4guWkqeW_g-WMuumCruaUv-e8lueggTogNDEwMDAw!5e0!3m2!1szh-CN!2scn!4v1458285640054\" width=\"600\" height=\"350\" frameborder=\"0\" style=\"border:0\" allowfullscreen></iframe>\n</center>\n\n\n\n","date":"2016-06-09T02:22:46.737Z","updated":"2016-06-09T02:22:46.737Z","path":"about/index.html","_id":"cimigpytn002i6cujd4xu5yiw"}],"Post":[{"layout":"post","title":"机器学习-损失函数","date":"2016-03-26T05:04:00.000Z","comment":true,"_content":"\n损失函数（loss function）是用来估量你模型的预测值f(x)与真实值Y的不一致程度，它是一个非负实值函数,通常使用L(Y, f(x))来表示，损失函数越小，模型的鲁棒性就越好。损失函数是**经验风险函数**的核心部分，也是**结构风险函数**重要组成部分。模型的结构风险函数包括了经验风险项和正则项，通常可以表示成如下式子：\n![$$\\theta^* = \\arg \\min_\\theta \\frac{1}{N}{}\\sum_{i=1}^{N} L(y_i, f(x_i; \\theta) + \\lambda\\  \\Phi(\\theta)$$](http://latex.codecogs.com/gif.latex?%24%24%5Ctheta%5E*%20%3D%20%5Carg%20%5Cmin_%5Ctheta%20%5Cfrac%7B1%7D%7BN%7D%7B%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%20L%28y_i%2C%20f%28x_i%3B%20%5Ctheta%29%20&plus;%20%5Clambda%5C%20%5CPhi%28%5Ctheta%29%24%24)\n\n<!-- more -->\n\n其中，前面的均值函数表示的是经验风险函数，L代表的是损失函数，后面的$\\Phi$是正则化项（regularizer）或者叫惩罚项（penalty term），它可以是L1，也可以是L2，或者其他的正则函数。整个式子表示的意思是<font color=\"#1986C7\">**找到使目标函数最小时的$\\theta$值**</font>。下面主要列出几种常见的损失函数。\n\n\n## 一、log对数损失函数（逻辑回归）\n\n有些人可能觉得逻辑回归的损失函数就是平方损失，其实并不是。平方损失函数可以通过线性回归在假设样本是高斯分布的条件下推导得到，而逻辑回归得到的并不是平方损失。在逻辑回归的推导中，它假设样本服从<font color=\"#1986C7\">**伯努利分布（0-1分布）**</font>，然后求得满足该分布的似然函数，接着取对数求极值等等。而逻辑回归并没有求似然函数的极值，而是把极大化当做是一种思想，进而推导出它的经验风险函数为：<font color=\"#1986C7\">**最小化负的似然函数（即max F(y, f(x))  --->  min -F(y, f(x)))**</font>。从损失函数的视角来看，它就成了log损失函数了。\n\n**log损失函数的标准形式**：\n$$L(Y,P(Y|X)) = -\\log P(Y|X)$$\n刚刚说到，取对数是为了方便计算极大似然估计，因为在MLE中，直接求导比较困难，所以通常都是先取对数再求导找极值点。损失函数L(Y, P(Y|X))表达的是样本X在分类Y的情况下，使概率P(Y|X)达到最大值（换言之，<font color=\"#1986C7\">**就是利用已知的样本分布，找到最有可能（即最大概率）导致这种分布的参数值；或者说什么样的参数才能使我们观测到目前这组数据的概率最大**</font>）。因为log函数是单调递增的，所以logP(Y|X)也会达到最大值，因此在前面加上负号之后，最大化P(Y|X)就等价于最小化L了。  \n\n逻辑回归的P(Y=y|x)表达式如下（为了将类别标签y统一为1和0，下面将表达式分开表示）：\n\n![](https://zhihu.com/equation?tex=P%28Y%3Dy%7Cx%29+%3D+%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%0Ah_%5Ctheta%28x%29+%3D+g%28f%28x%29%29+%3D+%5Cfrac%7B1%7D%7B1+%2B+exp%5C%7B-f%28x%29%5C%7D+%7D%26+%2Cy%3D1%5C%5C+%0A1+-+h_%5Ctheta%28x%29+%3D+1+-+g%28f%28x%29%29+%3D+%5Cfrac%7B1%7D%7B1+%2B+exp%5C%7Bf%28x%29%5C%7D+%7D+%26+%2Cy%3D0%0A%5Cend%7Bmatrix%7D%5Cright.)\n\n将它带入到上式，通过推导可以得到logistic的损失函数表达式，如下：\n\n\n![](https://zhihu.com/equation?tex=L%28y%2CP%28Y%3Dy%7Cx%29%29+%3D+%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%0A+%5Clog+%281%2Bexp%5C%7B-f%28x%29%5C%7D%29+%26+%2Cy%3D1%5C%5C+%0A+%5Clog+%281%2Bexp%5C%7B+f%28x%29%5C%7D%29++%26+%2Cy%3D0%5C%5C+%0A%5Cend%7Bmatrix%7D%5Cright.)\n\n逻辑回归最后得到的目标式子如下：\n\n![$$J(\\theta) = - \\frac{1}{m}\\left [ \\sum_{i=1}^m y^{(i)} \\log h_{\\theta}(x^{(i)}) + (1-y^{(i)}) \\log(1-h_{\\theta}(x^{(i)}))  \\right ]$$](http://latex.codecogs.com/gif.latex?J%28%5Ctheta%29%20%3D%20-%20%5Cfrac%7B1%7D%7Bm%7D%5Cleft%20%5B%20%5Csum_%7Bi%3D1%7D%5Em%20y%5E%7B%28i%29%7D%20%5Clog%20h_%7B%5Ctheta%7D%28x%5E%7B%28i%29%7D%29%20&plus;%20%281-y%5E%7B%28i%29%7D%29%20%5Clog%281-h_%7B%5Ctheta%7D%28x%5E%7B%28i%29%7D%29%29%20%5Cright%20%5D)\n\n如果是二分类的话，则m值等于2。这里需要解释一下：<font color=\"green\">**之所以有人认为逻辑回归是平方损失，是因为在使用梯度下降来求最优解的时候，它的迭代式子与平方损失求导后的式子非常相似，从而给人一种直观上的错觉**</font>。\n\n这里有个PDF可以参考一下：[Lecture 6: logistic regression.pdf](https://www.cs.berkeley.edu/~russell/classes/cs194/f11/lectures/CS194%20Fall%202011%20Lecture%2006.pdf).\n\n## 二、平方损失函数（最小二乘法, Ordinary Least Squares ）\n\n最小二乘法是线性回归的一种，OLS将问题转化成了一个凸优化问题。在线性回归中，它假设样本和噪声都服从高斯分布（为什么假设成高斯分布呢？其实这里隐藏了一个小知识点，就是**中心极限定理**，可以参考[【central limit theorem】](https://en.wikipedia.org/wiki/Central_limit_theorem)），最后通过极大似然估计（MLE）可以推导出最小二乘式子。最小二乘的基本原则是：<font color=\"1986C7\">**最优拟合直线应该是使各点到回归直线的距离和最小的直线，即平方和最小**</font>。换言之，OLS是基于距离的，而这个距离就是我们用的最多的欧几里得距离。为什么它会选择使用欧式距离作为误差度量呢（即Mean squared error， MSE），主要有以下几个原因：\n\n- 简单，计算方便；\n- 欧氏距离是一种很好的相似性度量标准；\n- 在不同的表示域变换后特征性质不变。\n\n**平方损失（Square loss）的标准形式如下：**  \n$$ L(Y, f(X)) = (Y - f(X))^2 $$\n当样本个数为n时，此时的损失函数变为：  \n![$$L(Y, f(X)) = \\sum _{i=1}^{n}(Y - f(X))^2$$](http://latex.codecogs.com/gif.latex?L%28Y%2C%20f%28X%29%29%20%3D%20%5Csum%20_%7Bi%3D1%7D%5E%7Bn%7D%28Y%20-%20f%28X%29%29%5E2)    \n`Y-f(X)`表示的是残差，整个式子表示的是<font color=\"#1986C7\">**残差的平方和**</font>，而我们的目的就是最小化这个目标函数值（注：该式子未加入正则项），也就是最小化残差的平方和（residual sum of squares，RSS）。\n\n而在实际应用中，通常会使用均方差（MSE）作为一项衡量指标，公式如下：  \n$$MSE = \\frac{1}{n} \\sum_{i=1} ^{n} (\\tilde{Y_i} - Y_i )^2$$  \n上面提到了线性回归，这里额外补充一句，我们通常说的线性有两种情况，一种是因变量y是自变量x的线性函数，一种是因变量y是参数$\\alpha$的线性函数。在机器学习中，通常指的都是后一种情况。\n\n\n\n## 三、指数损失函数（Adaboost）\n\n学过Adaboost算法的人都知道，它是前向分步加法算法的特例，是一个加和模型，损失函数就是指数函数。在Adaboost中，经过m此迭代之后，可以得到$f_{m} (x)$:\n\n![$$f_m (x) = f_{m-1}(x) + \\alpha_m G_m(x)$$](http://latex.codecogs.com/gif.latex?%24%24f_m%20%28x%29%20%3D%20f_%7Bm-1%7D%28x%29%20&plus;%20%5Calpha_m%20G_m%28x%29%24%24)\n\nAdaboost每次迭代时的目的是为了找到最小化下列式子时的参数$\\alpha$ 和G：\n\n![$$\\arg \\min_{\\alpha, G} = \\sum_{i=1}^{N} exp[-y_{i} (f_{m-1}(x_i) + \\alpha G(x_{i}))]$$](http://latex.codecogs.com/gif.latex?%24%24%5Carg%20%5Cmin_%7B%5Calpha%2C%20G%7D%20%3D%20%5Csum_%7Bi%3D1%7D%5E%7BN%7D%20exp%5B-y_%7Bi%7D%20%28f_%7Bm-1%7D%28x_i%29%20&plus;%20%5Calpha%20G%28x_%7Bi%7D%29%29%5D%24%24)\n\n**而指数损失函数(exp-loss）的标准形式如下**\n\n![$$L(y, f(x)) = \\exp[-yf(x)]$$](http://latex.codecogs.com/gif.latex?L%28y%2C%20f%28x%29%29%20%3D%20%5Cexp%5B-yf%28x%29%5D)\n\n可以看出，Adaboost的目标式子就是指数损失，在给定n个样本的情况下，Adaboost的损失函数为：\n\n![L(y, f(x)) = \\frac{1}{n}\\sum_{i=1}^{n}\\exp[-y_if(x_i)]](http://latex.codecogs.com/gif.latex?L%28y%2C%20f%28x%29%29%20%3D%20%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Cexp%5B-y_if%28x_i%29%5D)\n\n关于Adaboost的推导，可以参考Wikipedia：[AdaBoost](https://en.wikipedia.org/wiki/AdaBoost)或者《统计学习方法》P145.\n\n## 四、Hinge损失函数（SVM）\n\n\n在机器学习算法中，hinge损失函数和SVM是息息相关的。在**线性支持向量机**中，最优化问题可以等价于下列式子：  \n![$$\\min_{w,b}  \\ \\sum_{i}^{N} [1 - y_i(w\\cdot x_i + b)]_{+} + \\lambda||w||^2 $$](http://latex.codecogs.com/gif.latex?%24%24%5Cmin_%7Bw%2Cb%7D%20%5C%20%5Csum_%7Bi%7D%5E%7BN%7D%20%5B1%20-%20y_i%28w%5Ccdot%20x_i%20&plus;%20b%29%5D_%7B&plus;%7D%20&plus;%20%5Clambda%7C%7Cw%7C%7C%5E2%20%24%24)  \n下面来对式子做个变形，令：  \n![$$[1 - y_i(w\\cdot x_i + b)]_{+} = \\xi_{i}$$](http://latex.codecogs.com/gif.latex?%24%24%5B1%20-%20y_i%28w%5Ccdot%20x_i%20&plus;%20b%29%5D_%7B&plus;%7D%20%3D%20%5Cxi_%7Bi%7D%24%24)  \n于是，原式就变成了：  \n![$$\\min_{w,b}  \\ \\sum_{i}^{N} \\xi_i + \\lambda||w||^2 $$](http://latex.codecogs.com/gif.latex?%24%24%5Cmin_%7Bw%2Cb%7D%20%5C%20%5Csum_%7Bi%7D%5E%7BN%7D%20%5Cxi_i%20&plus;%20%5Clambda%7C%7Cw%7C%7C%5E2%20%24%24)  \n如若取$\\lambda=\\frac{1}{2C}$，式子就可以表示成：  \n![$$\\min_{w,b}  \\frac{1}{C}\\left ( \\frac{1}{2}\\ ||w||^2 $$ + C \\sum_{i}^{N} \\xi_i\\right )$$](http://latex.codecogs.com/gif.latex?%24%24%5Cmin_%7Bw%2Cb%7D%20%5Cfrac%7B1%7D%7BC%7D%5Cleft%20%28%20%5Cfrac%7B1%7D%7B2%7D%5C%20%7C%7Cw%7C%7C%5E2%20%24%24%20&plus;%20C%20%5Csum_%7Bi%7D%5E%7BN%7D%20%5Cxi_i%5Cright%20%29%24%24)  \n可以看出，该式子与下式非常相似：  \n![$$\\frac{1}{m} \\sum_{i=1}^{m} l(w \\cdot  x_i + b, y_i) + ||w||^2$$](http://latex.codecogs.com/gif.latex?%5Cfrac%7B1%7D%7Bm%7D%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%20l%28w%20%5Ccdot%20x_i%20&plus;%20b%2C%20y_i%29%20&plus;%20%7C%7Cw%7C%7C%5E2)\n\n前半部分中的$l$就是hinge损失函数，而后面相当于L2正则项。\n\n**Hinge 损失函数的标准形式**  \n$$L(y) = \\max(0, 1-y\\tilde{y}), y=\\pm 1$$  \n可以看出，当|y|>=1时，L(y)=0。\n\n更多内容，参考[Hinge-loss](https://en.wikipedia.org/wiki/Hinge_loss)。\n\n补充一下：在libsvm中一共有4中核函数可以选择，对应的是`-t`参数分别是：\n\n- 0-线性核；\n- 1-多项式核；\n- 2-RBF核；\n- 3-sigmoid核。\n\n\n\n## 五、其它损失函数\n\n除了以上这几种损失函数，常用的还有：\n\n**0-1损失函数**  \n![L(Y, f(X)) = \\left\\{\\begin{matrix}1 ,& Y \\neq f(X)\\\\ 0 ,& y = f(X)    \\end{matrix}\\right.](http://latex.codecogs.com/gif.latex?L%28Y%2C%20f%28X%29%29%20%3D%20%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D1%20%2C%26%20Y%20%5Cneq%20f%28X%29%5C%5C%200%20%2C%26%20y%20%3D%20f%28X%29%20%5Cend%7Bmatrix%7D%5Cright.)  \n**绝对值损失函数**  \n![$$L(Y, f(X)) = |Y-f(X)|$$](http://latex.codecogs.com/gif.latex?L%28Y%2C%20f%28X%29%29%20%3D%20%7CY-f%28X%29%7C)  \n下面来看看几种损失函数的可视化图像，对着图看看横坐标，看看纵坐标，再看看每条线都表示什么损失函数，多看几次好好消化消化。  \n![](/assets/articleImg/4DFDU.png)  \nOK，暂时先写到这里，休息下。最后，需要记住的是：<font color=\"#1986C7\">**参数越多，模型越复杂，而越复杂的模型越容易过拟合**</font>。过拟合就是说模型在训练数据上的效果远远好于在测试集上的性能。此时可以考虑正则化，通过设置正则项前面的hyper parameter，来权衡损失函数和正则项，减小参数规模，达到模型简化的目的，从而使模型具有更好的泛化能力。\n\n\n## 参考文献\n\n- https://github.com/JohnLangford/vowpal_wabbit/wiki/Loss-functions\n- [library_design/losses](http://image.diku.dk/shark/sphinx_pages/build/html/rest_sources/tutorials/concepts/library_design/losses.html)\n- http://www.cs.cmu.edu/~yandongl/loss.html\n- http://math.stackexchange.com/questions/782586/how-do-you-minimize-hinge-loss\n- 《统计学习方法》 李航 著.\n\n---","source":"_posts/2016-03-26-loss-function.md","raw":"---\nlayout: post\ntitle: \"机器学习-损失函数\"\ndate: 2016-03-26 13:04\ncategories: ML\ntag:\n\t- Machine Learning\n\t- 损失函数\ncomment: true\n---\n\n损失函数（loss function）是用来估量你模型的预测值f(x)与真实值Y的不一致程度，它是一个非负实值函数,通常使用L(Y, f(x))来表示，损失函数越小，模型的鲁棒性就越好。损失函数是**经验风险函数**的核心部分，也是**结构风险函数**重要组成部分。模型的结构风险函数包括了经验风险项和正则项，通常可以表示成如下式子：\n![$$\\theta^* = \\arg \\min_\\theta \\frac{1}{N}{}\\sum_{i=1}^{N} L(y_i, f(x_i; \\theta) + \\lambda\\  \\Phi(\\theta)$$](http://latex.codecogs.com/gif.latex?%24%24%5Ctheta%5E*%20%3D%20%5Carg%20%5Cmin_%5Ctheta%20%5Cfrac%7B1%7D%7BN%7D%7B%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%20L%28y_i%2C%20f%28x_i%3B%20%5Ctheta%29%20&plus;%20%5Clambda%5C%20%5CPhi%28%5Ctheta%29%24%24)\n\n<!-- more -->\n\n其中，前面的均值函数表示的是经验风险函数，L代表的是损失函数，后面的$\\Phi$是正则化项（regularizer）或者叫惩罚项（penalty term），它可以是L1，也可以是L2，或者其他的正则函数。整个式子表示的意思是<font color=\"#1986C7\">**找到使目标函数最小时的$\\theta$值**</font>。下面主要列出几种常见的损失函数。\n\n\n## 一、log对数损失函数（逻辑回归）\n\n有些人可能觉得逻辑回归的损失函数就是平方损失，其实并不是。平方损失函数可以通过线性回归在假设样本是高斯分布的条件下推导得到，而逻辑回归得到的并不是平方损失。在逻辑回归的推导中，它假设样本服从<font color=\"#1986C7\">**伯努利分布（0-1分布）**</font>，然后求得满足该分布的似然函数，接着取对数求极值等等。而逻辑回归并没有求似然函数的极值，而是把极大化当做是一种思想，进而推导出它的经验风险函数为：<font color=\"#1986C7\">**最小化负的似然函数（即max F(y, f(x))  --->  min -F(y, f(x)))**</font>。从损失函数的视角来看，它就成了log损失函数了。\n\n**log损失函数的标准形式**：\n$$L(Y,P(Y|X)) = -\\log P(Y|X)$$\n刚刚说到，取对数是为了方便计算极大似然估计，因为在MLE中，直接求导比较困难，所以通常都是先取对数再求导找极值点。损失函数L(Y, P(Y|X))表达的是样本X在分类Y的情况下，使概率P(Y|X)达到最大值（换言之，<font color=\"#1986C7\">**就是利用已知的样本分布，找到最有可能（即最大概率）导致这种分布的参数值；或者说什么样的参数才能使我们观测到目前这组数据的概率最大**</font>）。因为log函数是单调递增的，所以logP(Y|X)也会达到最大值，因此在前面加上负号之后，最大化P(Y|X)就等价于最小化L了。  \n\n逻辑回归的P(Y=y|x)表达式如下（为了将类别标签y统一为1和0，下面将表达式分开表示）：\n\n![](https://zhihu.com/equation?tex=P%28Y%3Dy%7Cx%29+%3D+%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%0Ah_%5Ctheta%28x%29+%3D+g%28f%28x%29%29+%3D+%5Cfrac%7B1%7D%7B1+%2B+exp%5C%7B-f%28x%29%5C%7D+%7D%26+%2Cy%3D1%5C%5C+%0A1+-+h_%5Ctheta%28x%29+%3D+1+-+g%28f%28x%29%29+%3D+%5Cfrac%7B1%7D%7B1+%2B+exp%5C%7Bf%28x%29%5C%7D+%7D+%26+%2Cy%3D0%0A%5Cend%7Bmatrix%7D%5Cright.)\n\n将它带入到上式，通过推导可以得到logistic的损失函数表达式，如下：\n\n\n![](https://zhihu.com/equation?tex=L%28y%2CP%28Y%3Dy%7Cx%29%29+%3D+%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%0A+%5Clog+%281%2Bexp%5C%7B-f%28x%29%5C%7D%29+%26+%2Cy%3D1%5C%5C+%0A+%5Clog+%281%2Bexp%5C%7B+f%28x%29%5C%7D%29++%26+%2Cy%3D0%5C%5C+%0A%5Cend%7Bmatrix%7D%5Cright.)\n\n逻辑回归最后得到的目标式子如下：\n\n![$$J(\\theta) = - \\frac{1}{m}\\left [ \\sum_{i=1}^m y^{(i)} \\log h_{\\theta}(x^{(i)}) + (1-y^{(i)}) \\log(1-h_{\\theta}(x^{(i)}))  \\right ]$$](http://latex.codecogs.com/gif.latex?J%28%5Ctheta%29%20%3D%20-%20%5Cfrac%7B1%7D%7Bm%7D%5Cleft%20%5B%20%5Csum_%7Bi%3D1%7D%5Em%20y%5E%7B%28i%29%7D%20%5Clog%20h_%7B%5Ctheta%7D%28x%5E%7B%28i%29%7D%29%20&plus;%20%281-y%5E%7B%28i%29%7D%29%20%5Clog%281-h_%7B%5Ctheta%7D%28x%5E%7B%28i%29%7D%29%29%20%5Cright%20%5D)\n\n如果是二分类的话，则m值等于2。这里需要解释一下：<font color=\"green\">**之所以有人认为逻辑回归是平方损失，是因为在使用梯度下降来求最优解的时候，它的迭代式子与平方损失求导后的式子非常相似，从而给人一种直观上的错觉**</font>。\n\n这里有个PDF可以参考一下：[Lecture 6: logistic regression.pdf](https://www.cs.berkeley.edu/~russell/classes/cs194/f11/lectures/CS194%20Fall%202011%20Lecture%2006.pdf).\n\n## 二、平方损失函数（最小二乘法, Ordinary Least Squares ）\n\n最小二乘法是线性回归的一种，OLS将问题转化成了一个凸优化问题。在线性回归中，它假设样本和噪声都服从高斯分布（为什么假设成高斯分布呢？其实这里隐藏了一个小知识点，就是**中心极限定理**，可以参考[【central limit theorem】](https://en.wikipedia.org/wiki/Central_limit_theorem)），最后通过极大似然估计（MLE）可以推导出最小二乘式子。最小二乘的基本原则是：<font color=\"1986C7\">**最优拟合直线应该是使各点到回归直线的距离和最小的直线，即平方和最小**</font>。换言之，OLS是基于距离的，而这个距离就是我们用的最多的欧几里得距离。为什么它会选择使用欧式距离作为误差度量呢（即Mean squared error， MSE），主要有以下几个原因：\n\n- 简单，计算方便；\n- 欧氏距离是一种很好的相似性度量标准；\n- 在不同的表示域变换后特征性质不变。\n\n**平方损失（Square loss）的标准形式如下：**  \n$$ L(Y, f(X)) = (Y - f(X))^2 $$\n当样本个数为n时，此时的损失函数变为：  \n![$$L(Y, f(X)) = \\sum _{i=1}^{n}(Y - f(X))^2$$](http://latex.codecogs.com/gif.latex?L%28Y%2C%20f%28X%29%29%20%3D%20%5Csum%20_%7Bi%3D1%7D%5E%7Bn%7D%28Y%20-%20f%28X%29%29%5E2)    \n`Y-f(X)`表示的是残差，整个式子表示的是<font color=\"#1986C7\">**残差的平方和**</font>，而我们的目的就是最小化这个目标函数值（注：该式子未加入正则项），也就是最小化残差的平方和（residual sum of squares，RSS）。\n\n而在实际应用中，通常会使用均方差（MSE）作为一项衡量指标，公式如下：  \n$$MSE = \\frac{1}{n} \\sum_{i=1} ^{n} (\\tilde{Y_i} - Y_i )^2$$  \n上面提到了线性回归，这里额外补充一句，我们通常说的线性有两种情况，一种是因变量y是自变量x的线性函数，一种是因变量y是参数$\\alpha$的线性函数。在机器学习中，通常指的都是后一种情况。\n\n\n\n## 三、指数损失函数（Adaboost）\n\n学过Adaboost算法的人都知道，它是前向分步加法算法的特例，是一个加和模型，损失函数就是指数函数。在Adaboost中，经过m此迭代之后，可以得到$f_{m} (x)$:\n\n![$$f_m (x) = f_{m-1}(x) + \\alpha_m G_m(x)$$](http://latex.codecogs.com/gif.latex?%24%24f_m%20%28x%29%20%3D%20f_%7Bm-1%7D%28x%29%20&plus;%20%5Calpha_m%20G_m%28x%29%24%24)\n\nAdaboost每次迭代时的目的是为了找到最小化下列式子时的参数$\\alpha$ 和G：\n\n![$$\\arg \\min_{\\alpha, G} = \\sum_{i=1}^{N} exp[-y_{i} (f_{m-1}(x_i) + \\alpha G(x_{i}))]$$](http://latex.codecogs.com/gif.latex?%24%24%5Carg%20%5Cmin_%7B%5Calpha%2C%20G%7D%20%3D%20%5Csum_%7Bi%3D1%7D%5E%7BN%7D%20exp%5B-y_%7Bi%7D%20%28f_%7Bm-1%7D%28x_i%29%20&plus;%20%5Calpha%20G%28x_%7Bi%7D%29%29%5D%24%24)\n\n**而指数损失函数(exp-loss）的标准形式如下**\n\n![$$L(y, f(x)) = \\exp[-yf(x)]$$](http://latex.codecogs.com/gif.latex?L%28y%2C%20f%28x%29%29%20%3D%20%5Cexp%5B-yf%28x%29%5D)\n\n可以看出，Adaboost的目标式子就是指数损失，在给定n个样本的情况下，Adaboost的损失函数为：\n\n![L(y, f(x)) = \\frac{1}{n}\\sum_{i=1}^{n}\\exp[-y_if(x_i)]](http://latex.codecogs.com/gif.latex?L%28y%2C%20f%28x%29%29%20%3D%20%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Cexp%5B-y_if%28x_i%29%5D)\n\n关于Adaboost的推导，可以参考Wikipedia：[AdaBoost](https://en.wikipedia.org/wiki/AdaBoost)或者《统计学习方法》P145.\n\n## 四、Hinge损失函数（SVM）\n\n\n在机器学习算法中，hinge损失函数和SVM是息息相关的。在**线性支持向量机**中，最优化问题可以等价于下列式子：  \n![$$\\min_{w,b}  \\ \\sum_{i}^{N} [1 - y_i(w\\cdot x_i + b)]_{+} + \\lambda||w||^2 $$](http://latex.codecogs.com/gif.latex?%24%24%5Cmin_%7Bw%2Cb%7D%20%5C%20%5Csum_%7Bi%7D%5E%7BN%7D%20%5B1%20-%20y_i%28w%5Ccdot%20x_i%20&plus;%20b%29%5D_%7B&plus;%7D%20&plus;%20%5Clambda%7C%7Cw%7C%7C%5E2%20%24%24)  \n下面来对式子做个变形，令：  \n![$$[1 - y_i(w\\cdot x_i + b)]_{+} = \\xi_{i}$$](http://latex.codecogs.com/gif.latex?%24%24%5B1%20-%20y_i%28w%5Ccdot%20x_i%20&plus;%20b%29%5D_%7B&plus;%7D%20%3D%20%5Cxi_%7Bi%7D%24%24)  \n于是，原式就变成了：  \n![$$\\min_{w,b}  \\ \\sum_{i}^{N} \\xi_i + \\lambda||w||^2 $$](http://latex.codecogs.com/gif.latex?%24%24%5Cmin_%7Bw%2Cb%7D%20%5C%20%5Csum_%7Bi%7D%5E%7BN%7D%20%5Cxi_i%20&plus;%20%5Clambda%7C%7Cw%7C%7C%5E2%20%24%24)  \n如若取$\\lambda=\\frac{1}{2C}$，式子就可以表示成：  \n![$$\\min_{w,b}  \\frac{1}{C}\\left ( \\frac{1}{2}\\ ||w||^2 $$ + C \\sum_{i}^{N} \\xi_i\\right )$$](http://latex.codecogs.com/gif.latex?%24%24%5Cmin_%7Bw%2Cb%7D%20%5Cfrac%7B1%7D%7BC%7D%5Cleft%20%28%20%5Cfrac%7B1%7D%7B2%7D%5C%20%7C%7Cw%7C%7C%5E2%20%24%24%20&plus;%20C%20%5Csum_%7Bi%7D%5E%7BN%7D%20%5Cxi_i%5Cright%20%29%24%24)  \n可以看出，该式子与下式非常相似：  \n![$$\\frac{1}{m} \\sum_{i=1}^{m} l(w \\cdot  x_i + b, y_i) + ||w||^2$$](http://latex.codecogs.com/gif.latex?%5Cfrac%7B1%7D%7Bm%7D%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%20l%28w%20%5Ccdot%20x_i%20&plus;%20b%2C%20y_i%29%20&plus;%20%7C%7Cw%7C%7C%5E2)\n\n前半部分中的$l$就是hinge损失函数，而后面相当于L2正则项。\n\n**Hinge 损失函数的标准形式**  \n$$L(y) = \\max(0, 1-y\\tilde{y}), y=\\pm 1$$  \n可以看出，当|y|>=1时，L(y)=0。\n\n更多内容，参考[Hinge-loss](https://en.wikipedia.org/wiki/Hinge_loss)。\n\n补充一下：在libsvm中一共有4中核函数可以选择，对应的是`-t`参数分别是：\n\n- 0-线性核；\n- 1-多项式核；\n- 2-RBF核；\n- 3-sigmoid核。\n\n\n\n## 五、其它损失函数\n\n除了以上这几种损失函数，常用的还有：\n\n**0-1损失函数**  \n![L(Y, f(X)) = \\left\\{\\begin{matrix}1 ,& Y \\neq f(X)\\\\ 0 ,& y = f(X)    \\end{matrix}\\right.](http://latex.codecogs.com/gif.latex?L%28Y%2C%20f%28X%29%29%20%3D%20%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D1%20%2C%26%20Y%20%5Cneq%20f%28X%29%5C%5C%200%20%2C%26%20y%20%3D%20f%28X%29%20%5Cend%7Bmatrix%7D%5Cright.)  \n**绝对值损失函数**  \n![$$L(Y, f(X)) = |Y-f(X)|$$](http://latex.codecogs.com/gif.latex?L%28Y%2C%20f%28X%29%29%20%3D%20%7CY-f%28X%29%7C)  \n下面来看看几种损失函数的可视化图像，对着图看看横坐标，看看纵坐标，再看看每条线都表示什么损失函数，多看几次好好消化消化。  \n![](/assets/articleImg/4DFDU.png)  \nOK，暂时先写到这里，休息下。最后，需要记住的是：<font color=\"#1986C7\">**参数越多，模型越复杂，而越复杂的模型越容易过拟合**</font>。过拟合就是说模型在训练数据上的效果远远好于在测试集上的性能。此时可以考虑正则化，通过设置正则项前面的hyper parameter，来权衡损失函数和正则项，减小参数规模，达到模型简化的目的，从而使模型具有更好的泛化能力。\n\n\n## 参考文献\n\n- https://github.com/JohnLangford/vowpal_wabbit/wiki/Loss-functions\n- [library_design/losses](http://image.diku.dk/shark/sphinx_pages/build/html/rest_sources/tutorials/concepts/library_design/losses.html)\n- http://www.cs.cmu.edu/~yandongl/loss.html\n- http://math.stackexchange.com/questions/782586/how-do-you-minimize-hinge-loss\n- 《统计学习方法》 李航 著.\n\n---","slug":"2016-03-26-loss-function","published":1,"updated":"2016-06-09T02:03:10.723Z","_id":"cimigpytq002j6cujs6njxuqa","comments":1,"photos":[],"link":""},{"layout":"post","date":"2016-03-12T12:03:00.000Z","title":"分类之性能评估指标","_content":"\n本文主要介绍几种常用的用于分类的性能评估指标，同时介绍如何绘制ROC曲线以及计算AUC值的便捷方法。最后再附上一个绘制ROC曲线和计算AUC的源码实现（Python）。\n\n<!-- more -->\n\n## Precision和Recall\n\n首先我们来看看下面这个混淆矩阵：\n\n|pred\\_label/true\\_label|Positive|Negative|  \n|--------|-----|----|  \n|Positive|TP|FP|  \n|Negtive|FN|TN|    \n\n如上表所示，行表示预测的label值，列表示真实label值。TP，FP，FN，TN分别表示如下意思：\n\n- TP（true positive）：表示样本的真实类别为正，最后预测得到的结果也为正；\n- FP（false positive）：表示样本的真实类别为负，最后预测得到的结果却为正；\n- FN（false negative）：表示样本的真实类别为正，最后预测得到的结果却为负；\n- TN（true negative）：表示样本的真实类别为负，最后预测得到的结果也为负.\n\n\n根据以上几个指标，可以分别计算出Accuracy、Precision、Recall（Sensitivity，SN），Specificity（SP）。\n\n$$Accuracy = \\frac{TP+TN}{TP+FP+TN+FN}$$\n\n$$Precision = \\frac{TP}{TP+FP}$$\n\n$$Recall = \\frac{TP}{TP+FN}$$\n\n$$SP = \\frac{TN}{TN + FP}$$\n\n- Accuracy：表示预测结果的精确度，预测正确的样本数除以总样本数。\n- precision，准确率，表示预测结果中，预测为正样本的样本中，正确预测为正样本的概率；\n- recall，召回率，表示在原始样本的正样本中，最后被正确预测为正样本的概率；\n- specificity，常常称作特异性，它研究的样本集是原始样本中的负样本，表示的是在这些负样本中最后被正确预测为负样本的概率。\n\n在实际当中，我们往往希望得到的precision和recall都比较高，比如当FN和FP等于0的时候，他们的值都等于1。但是，它们往往在某种情况下是互斥的，比如这种情况，50个正样本，50个负样本，结果全部预测为正，那么它的precision为1而recall却为0.5.所以需要一种折衷的方式，因此就有了F1-score。\n\n$$ F1-score = \\frac{ 2 \\times recall \\times precision}{ recall + precision}$$\n\nF1-score表示的是precision和recall的调和平均评估指标。\n\n\n此外还有MCC：\n\n![$$MCC = \\frac{TP \\times TN - FP \\times FN}{ \\sqrt {(TP + FP)(TP + FN)( TN + FP)(TN+FN)}}$$](http://latex.codecogs.com/gif.latex?%24%24MCC%20%3D%20%5Cfrac%7BTP%20%5Ctimes%20TN%20-%20FP%20%5Ctimes%20FN%7D%7B%20%5Csqrt%20%7B%28TP%20&plus;%20FP%29%28TP%20&plus;%20FN%29%28%20TN%20&plus;%20FP%29%28TN&plus;FN%29%7D%7D%24%24)\n\n\n\n## ROC曲线\n\nROC（receiver operating characteristic），平面的横坐标是false positive rate(FPR)假阳率，纵坐标是true positive rate(TPR)真阳率。ROC计算过程如下：\n\n- 首先每个样本都需要有一个label值，并且还需要一个预测的score值（取值0到1）;\n- 然后按这个score对样本由大到小进行排序，假设这些数据位于表格中的一列，从上到下依次降序;\n- 现在从上到下按照样本点的取值进行划分，位于分界点上面的我们把它归为预测为正样本，位于分界点下面的归为负样本;\n- 分别计算出此时的TPR（Recall）=TP/P和FPR（1-SP）=FP/N，然后在图中绘制（FPR, TPR）点。\n\n从上往下逐个样本计算，最后会得到一条光滑的曲线 。\n\n然而，千言万语不如下面的这幅图懂得快：\n\n![](http://www.csuldw.com/assets/articleImg/roc_plot.gif)\n\n<div class=\"caption\">『roc曲线绘制动画—图片来自[参考文献5](http://stats.stackexchange.com/questions/105501/understanding-roc-curve/105577).』</div>\n\n\n## AUC计算\n\nAUC（area under the curve）就是ROC曲线下方的面积，取值在0.5到1之间，因为随机猜测得到额AUC就是0.5。面积如下图所示，阴影部分即为AUC面积：\n\n![](http://www.csuldw.com/assets/articleImg/area_under_curve.png)\n\n<div class=\"caption\">『AUC面积图解—图片来自[参考文献5](http://stats.stackexchange.com/questions/105501/understanding-roc-curve/105577).』</div>\n\nAUC的几种解释（来自[【Interpreting the AUROC】](http://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it?)）:\n\n- The expectation that a uniformly drawn random positive is ranked before a uniformly drawn random negative.\n- The expected proportion of positives ranked before a uniformly drawn random negative.\n- The expected true positive rate if the ranking is split just before a uniformly drawn random negative.\n- The expected proportion of negatives ranked after a uniformly drawn random positive.\n- The expected false positive rate if the ranking is split just after a uniformly drawn random positive.\n\n\n下面来介绍下它的计算方法，AUC的计算主要有以下三种。\n\n第一种：积分思维。这也是在早期机器学习文献中常用的AUC计算方法。从积分的思想中演化而来的。假如我们的测试样本有限，那么我们得到的AUC曲线必然是呈现阶梯形状。因此，计算的AUC也就是这些阶梯下面的面积之和（有没有想起以前学高数时的积分面积哈）。我们可以这样来计算，首先把score值进行排序，假设score越大，此样本属于正类的概率就越大。然后一边扫描一边计算就可以得到我们想要的AUC。但是，这样做会有个缺点，当多个测试样本的score值相等时，我们调整一下阈值，得到的不是往上或者往右的延展，而是斜着向上形成一个梯形。此时，就需要计算这个梯形的面积，这样是比较麻烦。 简单的用代码描述下\n\n```\nauc = 0.0\nheight = 0.0\n\nfor each training example x_i, y_i：\n  if y_i = 1.0:\n    height = height + tpr\n  else \n    auc +=  height * fpr\n\nreturn auc\n```\n\n\n第二种：[Mann–Whitney U test（MWW）](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test)。关于AUC还有一个很有趣的性质，它和Wilcoxon-Mann-Witney Test类似（可以去google搜一下），而Wilcoxon-Mann-Witney Test就是<font color=\"#007FFF\">**测试任意给一个正类样本和一个负类样本，正类样本的score有多大的概率大于负类样本的score**</font>。有了这个定义，就可以得到了另外一中计算AUC的方法：计算出这个概率值。我们知道，在有限样本中我们常用的得到概率的办法就是通过频率来估计之。这种估计随着样本规模的扩大而逐渐逼近真实值。样本数越多，计算的AUC越准确类似，也和计算积分的时候，小区间划分的越细，计算的越准确是同样的道理。具体来说就是：<font color=\"red\"> 统计一下所有的 M×N(M为正类样本的数目，N为负类样本的数目)个正负样本对中，有多少个组中的正样本的score大于负样本的score。当二元组中正负样本的 score相等的时候，按照0.5计算。然后除以MN。实现这个方法的复杂度为O(n^2  )。n为样本数(即n=M+N)</font>,公式表示如下：\n\n\n![$$**AUC = \\frac{\\sum_i^n ( \\ pos\\_score  > neg\\_score \\ )}{M * N}**$$](http://latex.codecogs.com/gif.latex?AUC%20%3D%20%5Cfrac%7B%5Csum_i%5En%20%28%20%5C%20pos%5C_score%20%3E%20neg%5C_score%20%5C%20%29%20&plus;%200.5%20*%20%5Csum_i%5En%7B%28%5C%20pos%5C_score%3Dneg%5C_score%5C%20%29%7D%7D%7BM%20*%20N%7D)\n\n第三种：该方法和上述第二种方法原理一样，但复杂度降低了。首先对score从大到小排序，然后令最大score对应的sample的rank值为n，第二大score对应sample的rank值为n-1，以此类推从n到1。然后把所有的正类样本的rank相加，再减去正类样本的score为最小的那M个值的情况。得到的结果就是有多少对正类样本的score值大于负类样本的score值，最后再除以M×N即可。值得注意的是，当存在score相等的时候，对于score相等的样本，需要赋予相同的rank值(无论这个相等的score是出现在同类样本还是不同类的样本之间，都需要这样处理)。具体操作就是再把所有这些score相等的样本 的rank取平均。然后再使用上述公式。此公式描述如下： \n\n![$$AUC = \\frac{\\sum_{ins_i \\epsilon pos}rank_{ins_i} - \\frac{M * (M+1)}{2}}{M * N}$$](http://latex.codecogs.com/gif.latex?AUC%20%3D%20%5Cfrac%7B%5Csum_%7Bins_i%20%5Cepsilon%20pos%7Drank_%7Bins_i%7D%20-%20%5Cfrac%7BM%20*%20%28M&plus;1%29%7D%7B2%7D%7D%7BM%20*%20N%7D)\n\n这三种方法，第一种比较好理解，后面两种确实不太好理解，先记下，慢慢理解。\n\n## 源码\n\n最后，附上ROC曲线绘制代码。下面使用的思想类似积分，但是求得是AUC的近似值，忽略了梯形部分，Code如下：\n\n依赖库：\n\n- numpy\n- matplotlib\n\n\n```\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Sat Mar 12 17:43:48 2016\n\n@author: liudiwei\n\"\"\"\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef plotROC(predScore, labels):\n    point = (1.0, 1.0) #由于下面排序的索引是从小到大，所以这里从(1,1)开始绘制\n    ySum = 0.0 \n    numPos = np.sum(np.array(labels)==1.0)\n    numNeg = len(labels)-numPos\n    yStep = 1/np.float(numPos)\n    xStep = 1/np.float(numNeg)\n    sortedIndex = predScore.argsort() #对predScore进行排序，的到排序索引值\n    fig = plt.figure()\n    fig.clf()\n    ax = plt.subplot(111)\n    for index in sortedIndex.tolist()[0]:\n        if labels[index] == 1.0: #如果正样本各入加1，则x不走动，y往下走动一步\n            delX = 0\n            delY = yStep;\n        else:                   #否则，x往左走动一步，y不走动\n            delX = xStep\n            delY = 0\n            ySum += point[1]     #统计y走动的所有步数的和\n        ax.plot([point[0], point[0] - delX], [point[1], point[1] - delY],c='b')\n        point = (point[0] - delX, point[1] - delY)\n    ax.plot([0,1],[0,1],'b--')\n    plt.xlabel('False positive rate'); plt.ylabel('True positive rate')\n    plt.title('ROC Curve')\n    ax.axis([0, 1, 0, 1])\n    plt.show() \n    #最后，所有将所有矩形的高度进行累加，最后乘以xStep得到的总面积，即为AUC值\n    print \"the Area Under the Curve is: \", ySum * xStep\n``` \n\n对于ROC曲线绘制中的参数，输入的第二个参数是类别标签（如，+1，-1形成的文件，每行表示一个样本的真实类别）；第一个参数则是由模型训练出来的预测强度，如Adaboost对样本i预测的结果为0.67，对i+1个样本预测的结果是0.3，等等，每行一个，格式和classLabels一样。最后绘制ROC曲线的同时，也在输出ROC曲线下方的AUC面积。\n\n\n## 参考文献\n\n[1] https://en.wikipedia.org/wiki/Receiver_operating_characteristic  \n[2] http://blog.csdn.net/chjjunking/article/details/5933105  \n[3]《Machine Learning in Action》\n[4] https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test\n[5] [Understanding ROC curve](http://stats.stackexchange.com/questions/105501/understanding-roc-curve/105577)  \n[6] http://stats.stackexchange.com/questions/145566/how-to-calculate-area-under-the-curve-auc-or-the-c-statistic-by-hand\n","source":"_posts/2016-03-12-performance-evaluation.md","raw":"---\nlayout: post\ndate: 2016-03-12 20:03\ntitle: \"分类之性能评估指标\"\ncategories: ML\ntags:\n\t- Machine Learning\n\t- ROC\n\t- AUC\n---\n\n本文主要介绍几种常用的用于分类的性能评估指标，同时介绍如何绘制ROC曲线以及计算AUC值的便捷方法。最后再附上一个绘制ROC曲线和计算AUC的源码实现（Python）。\n\n<!-- more -->\n\n## Precision和Recall\n\n首先我们来看看下面这个混淆矩阵：\n\n|pred\\_label/true\\_label|Positive|Negative|  \n|--------|-----|----|  \n|Positive|TP|FP|  \n|Negtive|FN|TN|    \n\n如上表所示，行表示预测的label值，列表示真实label值。TP，FP，FN，TN分别表示如下意思：\n\n- TP（true positive）：表示样本的真实类别为正，最后预测得到的结果也为正；\n- FP（false positive）：表示样本的真实类别为负，最后预测得到的结果却为正；\n- FN（false negative）：表示样本的真实类别为正，最后预测得到的结果却为负；\n- TN（true negative）：表示样本的真实类别为负，最后预测得到的结果也为负.\n\n\n根据以上几个指标，可以分别计算出Accuracy、Precision、Recall（Sensitivity，SN），Specificity（SP）。\n\n$$Accuracy = \\frac{TP+TN}{TP+FP+TN+FN}$$\n\n$$Precision = \\frac{TP}{TP+FP}$$\n\n$$Recall = \\frac{TP}{TP+FN}$$\n\n$$SP = \\frac{TN}{TN + FP}$$\n\n- Accuracy：表示预测结果的精确度，预测正确的样本数除以总样本数。\n- precision，准确率，表示预测结果中，预测为正样本的样本中，正确预测为正样本的概率；\n- recall，召回率，表示在原始样本的正样本中，最后被正确预测为正样本的概率；\n- specificity，常常称作特异性，它研究的样本集是原始样本中的负样本，表示的是在这些负样本中最后被正确预测为负样本的概率。\n\n在实际当中，我们往往希望得到的precision和recall都比较高，比如当FN和FP等于0的时候，他们的值都等于1。但是，它们往往在某种情况下是互斥的，比如这种情况，50个正样本，50个负样本，结果全部预测为正，那么它的precision为1而recall却为0.5.所以需要一种折衷的方式，因此就有了F1-score。\n\n$$ F1-score = \\frac{ 2 \\times recall \\times precision}{ recall + precision}$$\n\nF1-score表示的是precision和recall的调和平均评估指标。\n\n\n此外还有MCC：\n\n![$$MCC = \\frac{TP \\times TN - FP \\times FN}{ \\sqrt {(TP + FP)(TP + FN)( TN + FP)(TN+FN)}}$$](http://latex.codecogs.com/gif.latex?%24%24MCC%20%3D%20%5Cfrac%7BTP%20%5Ctimes%20TN%20-%20FP%20%5Ctimes%20FN%7D%7B%20%5Csqrt%20%7B%28TP%20&plus;%20FP%29%28TP%20&plus;%20FN%29%28%20TN%20&plus;%20FP%29%28TN&plus;FN%29%7D%7D%24%24)\n\n\n\n## ROC曲线\n\nROC（receiver operating characteristic），平面的横坐标是false positive rate(FPR)假阳率，纵坐标是true positive rate(TPR)真阳率。ROC计算过程如下：\n\n- 首先每个样本都需要有一个label值，并且还需要一个预测的score值（取值0到1）;\n- 然后按这个score对样本由大到小进行排序，假设这些数据位于表格中的一列，从上到下依次降序;\n- 现在从上到下按照样本点的取值进行划分，位于分界点上面的我们把它归为预测为正样本，位于分界点下面的归为负样本;\n- 分别计算出此时的TPR（Recall）=TP/P和FPR（1-SP）=FP/N，然后在图中绘制（FPR, TPR）点。\n\n从上往下逐个样本计算，最后会得到一条光滑的曲线 。\n\n然而，千言万语不如下面的这幅图懂得快：\n\n![](http://www.csuldw.com/assets/articleImg/roc_plot.gif)\n\n<div class=\"caption\">『roc曲线绘制动画—图片来自[参考文献5](http://stats.stackexchange.com/questions/105501/understanding-roc-curve/105577).』</div>\n\n\n## AUC计算\n\nAUC（area under the curve）就是ROC曲线下方的面积，取值在0.5到1之间，因为随机猜测得到额AUC就是0.5。面积如下图所示，阴影部分即为AUC面积：\n\n![](http://www.csuldw.com/assets/articleImg/area_under_curve.png)\n\n<div class=\"caption\">『AUC面积图解—图片来自[参考文献5](http://stats.stackexchange.com/questions/105501/understanding-roc-curve/105577).』</div>\n\nAUC的几种解释（来自[【Interpreting the AUROC】](http://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it?)）:\n\n- The expectation that a uniformly drawn random positive is ranked before a uniformly drawn random negative.\n- The expected proportion of positives ranked before a uniformly drawn random negative.\n- The expected true positive rate if the ranking is split just before a uniformly drawn random negative.\n- The expected proportion of negatives ranked after a uniformly drawn random positive.\n- The expected false positive rate if the ranking is split just after a uniformly drawn random positive.\n\n\n下面来介绍下它的计算方法，AUC的计算主要有以下三种。\n\n第一种：积分思维。这也是在早期机器学习文献中常用的AUC计算方法。从积分的思想中演化而来的。假如我们的测试样本有限，那么我们得到的AUC曲线必然是呈现阶梯形状。因此，计算的AUC也就是这些阶梯下面的面积之和（有没有想起以前学高数时的积分面积哈）。我们可以这样来计算，首先把score值进行排序，假设score越大，此样本属于正类的概率就越大。然后一边扫描一边计算就可以得到我们想要的AUC。但是，这样做会有个缺点，当多个测试样本的score值相等时，我们调整一下阈值，得到的不是往上或者往右的延展，而是斜着向上形成一个梯形。此时，就需要计算这个梯形的面积，这样是比较麻烦。 简单的用代码描述下\n\n```\nauc = 0.0\nheight = 0.0\n\nfor each training example x_i, y_i：\n  if y_i = 1.0:\n    height = height + tpr\n  else \n    auc +=  height * fpr\n\nreturn auc\n```\n\n\n第二种：[Mann–Whitney U test（MWW）](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test)。关于AUC还有一个很有趣的性质，它和Wilcoxon-Mann-Witney Test类似（可以去google搜一下），而Wilcoxon-Mann-Witney Test就是<font color=\"#007FFF\">**测试任意给一个正类样本和一个负类样本，正类样本的score有多大的概率大于负类样本的score**</font>。有了这个定义，就可以得到了另外一中计算AUC的方法：计算出这个概率值。我们知道，在有限样本中我们常用的得到概率的办法就是通过频率来估计之。这种估计随着样本规模的扩大而逐渐逼近真实值。样本数越多，计算的AUC越准确类似，也和计算积分的时候，小区间划分的越细，计算的越准确是同样的道理。具体来说就是：<font color=\"red\"> 统计一下所有的 M×N(M为正类样本的数目，N为负类样本的数目)个正负样本对中，有多少个组中的正样本的score大于负样本的score。当二元组中正负样本的 score相等的时候，按照0.5计算。然后除以MN。实现这个方法的复杂度为O(n^2  )。n为样本数(即n=M+N)</font>,公式表示如下：\n\n\n![$$**AUC = \\frac{\\sum_i^n ( \\ pos\\_score  > neg\\_score \\ )}{M * N}**$$](http://latex.codecogs.com/gif.latex?AUC%20%3D%20%5Cfrac%7B%5Csum_i%5En%20%28%20%5C%20pos%5C_score%20%3E%20neg%5C_score%20%5C%20%29%20&plus;%200.5%20*%20%5Csum_i%5En%7B%28%5C%20pos%5C_score%3Dneg%5C_score%5C%20%29%7D%7D%7BM%20*%20N%7D)\n\n第三种：该方法和上述第二种方法原理一样，但复杂度降低了。首先对score从大到小排序，然后令最大score对应的sample的rank值为n，第二大score对应sample的rank值为n-1，以此类推从n到1。然后把所有的正类样本的rank相加，再减去正类样本的score为最小的那M个值的情况。得到的结果就是有多少对正类样本的score值大于负类样本的score值，最后再除以M×N即可。值得注意的是，当存在score相等的时候，对于score相等的样本，需要赋予相同的rank值(无论这个相等的score是出现在同类样本还是不同类的样本之间，都需要这样处理)。具体操作就是再把所有这些score相等的样本 的rank取平均。然后再使用上述公式。此公式描述如下： \n\n![$$AUC = \\frac{\\sum_{ins_i \\epsilon pos}rank_{ins_i} - \\frac{M * (M+1)}{2}}{M * N}$$](http://latex.codecogs.com/gif.latex?AUC%20%3D%20%5Cfrac%7B%5Csum_%7Bins_i%20%5Cepsilon%20pos%7Drank_%7Bins_i%7D%20-%20%5Cfrac%7BM%20*%20%28M&plus;1%29%7D%7B2%7D%7D%7BM%20*%20N%7D)\n\n这三种方法，第一种比较好理解，后面两种确实不太好理解，先记下，慢慢理解。\n\n## 源码\n\n最后，附上ROC曲线绘制代码。下面使用的思想类似积分，但是求得是AUC的近似值，忽略了梯形部分，Code如下：\n\n依赖库：\n\n- numpy\n- matplotlib\n\n\n```\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Sat Mar 12 17:43:48 2016\n\n@author: liudiwei\n\"\"\"\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef plotROC(predScore, labels):\n    point = (1.0, 1.0) #由于下面排序的索引是从小到大，所以这里从(1,1)开始绘制\n    ySum = 0.0 \n    numPos = np.sum(np.array(labels)==1.0)\n    numNeg = len(labels)-numPos\n    yStep = 1/np.float(numPos)\n    xStep = 1/np.float(numNeg)\n    sortedIndex = predScore.argsort() #对predScore进行排序，的到排序索引值\n    fig = plt.figure()\n    fig.clf()\n    ax = plt.subplot(111)\n    for index in sortedIndex.tolist()[0]:\n        if labels[index] == 1.0: #如果正样本各入加1，则x不走动，y往下走动一步\n            delX = 0\n            delY = yStep;\n        else:                   #否则，x往左走动一步，y不走动\n            delX = xStep\n            delY = 0\n            ySum += point[1]     #统计y走动的所有步数的和\n        ax.plot([point[0], point[0] - delX], [point[1], point[1] - delY],c='b')\n        point = (point[0] - delX, point[1] - delY)\n    ax.plot([0,1],[0,1],'b--')\n    plt.xlabel('False positive rate'); plt.ylabel('True positive rate')\n    plt.title('ROC Curve')\n    ax.axis([0, 1, 0, 1])\n    plt.show() \n    #最后，所有将所有矩形的高度进行累加，最后乘以xStep得到的总面积，即为AUC值\n    print \"the Area Under the Curve is: \", ySum * xStep\n``` \n\n对于ROC曲线绘制中的参数，输入的第二个参数是类别标签（如，+1，-1形成的文件，每行表示一个样本的真实类别）；第一个参数则是由模型训练出来的预测强度，如Adaboost对样本i预测的结果为0.67，对i+1个样本预测的结果是0.3，等等，每行一个，格式和classLabels一样。最后绘制ROC曲线的同时，也在输出ROC曲线下方的AUC面积。\n\n\n## 参考文献\n\n[1] https://en.wikipedia.org/wiki/Receiver_operating_characteristic  \n[2] http://blog.csdn.net/chjjunking/article/details/5933105  \n[3]《Machine Learning in Action》\n[4] https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test\n[5] [Understanding ROC curve](http://stats.stackexchange.com/questions/105501/understanding-roc-curve/105577)  \n[6] http://stats.stackexchange.com/questions/145566/how-to-calculate-area-under-the-curve-auc-or-the-c-statistic-by-hand\n","slug":"2016-03-12-performance-evaluation","published":1,"updated":"2016-06-09T02:26:37.644Z","_id":"cimigpyu2002q6cuje9mgs8ik","comments":1,"photos":[],"link":""},{"layout":"post","date":"2016-02-28T07:24:00.000Z","title":"PCA主成分分析Python实现","comment":true,"_content":"\nGithub源码：https://github.com/csuldw/MachineLearning/tree/master/PCA\n\nPCA（principle component analysis） ，主成分分析，主要是用来降低数据集的维度，然后挑选出主要的特征。原理简单，实现也简单。关于原理公式的推导，本文不会涉及，你可以参考下面的参考文献，也可以去Wikipedia，这里主要关注实现，算是锻炼一下自己，对PCA在理论的基础上画个圆满的句号。\n\n<!-- more-->\n\n本来是在复习LDA的，然后就看到了PCA，就跟着下面这篇文章的步骤，把PCA用python实现了一遍，具体的思想可以参考这篇文章，讲的通俗易懂，主要是有个实例参考，值得拥有！\n\n- [JerryLead之PCA主成分分析](http://www.cnblogs.com/jerrylead/archive/2011/04/18/2020209.html)\n\n下面自己来简单的清理下思路！\n\n## PCA思想\n\n思想：<font color=\"#007FFF\">**移动坐标轴，将n维特征映射到k维上（k<n），这k维是全新的正交特征。**</font>这k维特征称为主元，是重新构造出来的k维特征，而不是简单地从n维特征中去除其余n-k维特征。\n\n说到PCA难免会提到LDA（linear discriminate analysis，线性判别分析），以及FA（factor analysis，因子分析）。关于LDA，打算有时间也用代码实现一遍，下面给出它的主要思想。\n\nLDA思想：<font color=\"#007FFF\">**最大类间距离，最小类内距离**</font>。简而言之，第一，为了实现投影后的两个类别的距离较远，用映射后两个类别的均值差的绝对值来度量。第二，为了实现投影后，每个类内部数据点比较聚集，用投影后每个类别的方差来度量。\n\n三者的描述如下\n\n 以下内容引自 [Wikipedia- Linear discriminant analysis](https://en.wikipedia.org/wiki/Linear_discriminant_analysis)\n>LDA is also closely related to principal component analysis (PCA) and factor \t\tanalysis in that they both look for linear combinations of variables which best explain the data.[4] LDA explicitly attempts to model the difference between the classes of data. PCA on the other hand does not take into account any difference in class, and factor analysis builds the feature combinations based on differences rather than similarities. Discriminant analysis is also different from factor analysis in that it is not an interdependence technique: a distinction between independent variables and dependent variables (also called criterion variables) must be made.\n\n区别：PCA选择样本点投影具有最大方差的方向，LDA选择分类性能最好的方向。\n\n好了，下面来看下实现源码！\n\n## 基本步骤\n\n\n基本步骤：\n\n- 对数据进行归一化处理（代码中并非这么做的，而是直接减去均值）\n- 计算归一化后的数据集的协方差矩阵                   \n- 计算协方差矩阵的特征值和特征向量\n- 保留最重要的k个特征（通常k<n），可以自己制定，也可以选择个阈值，让后通过前k个特征值之和减去后面n-k个特征值之和大于这个阈值，找到这个k\n- 找出k个特征值对应的特征向量\n- 将m $\\*$ n的数据集乘以k个n维的特征向量的特征向量（n $\\*$ k）,得到最后降维的数据。\n\n其实PCA的本质就是对角化协方差矩阵。有必要解释下为什么将特征值按从大到小排序后再选。首先，要明白特征值表示的是什么？在线性代数里面我们求过无数次了，那么它具体有什么意义呢？对一个$n\\*n$的对称矩阵进行分解，我们可以求出它的特征值和特征向量，就会产生n个n维的正交基，每个正交基会对应一个特征值。然后把矩阵投影到这n个基上，此时特征值的模就表示矩阵在该基的投影长度。<font color=\"#007FFF\">**特征值越大，说明矩阵（样本）在对应的特征向量上投影后的方差越大，样本点越离散，越容易区分，信息量也就越多**</font>。因此，特征值最大的对应的特征向量方向上所包含的信息量就越多，如果某几个特征值很小，那么就说明在该方向的信息量非常少，我们就可以删除小特征值对应方向的数据，只保留大特征值方向对应的数据，这样做以后数据量减小，但有用的信息量都保留下来了。PCA就是这个原理。\n\n## 源码实现\n\n1.首先引入numpy，由于测试中用到了pandas和matplotlib，所以这里一并加载\n\n```\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n```\n\n2.定义一个均值函数\n\n```\n#计算均值,要求输入数据为numpy的矩阵格式，行表示样本数，列表示特征    \ndef meanX(dataX):\n    return np.mean(dataX,axis=0)#axis=0表示按照列来求均值，如果输入list,则axis=1\n```\n\n3.编写pca方法，具体解释参考注释\n\n```\n\"\"\"\n参数：\n\t- XMat：传入的是一个numpy的矩阵格式，行表示样本数，列表示特征    \n\t- k：表示取前k个特征值对应的特征向量\n返回值：\n\t- finalData：参数一指的是返回的低维矩阵，对应于输入参数二\n\t- reconData：参数二对应的是移动坐标轴后的矩阵\n\"\"\"\ndef pca(XMat, k):\n    average = meanX(XMat) \n    m, n = np.shape(XMat)\n    data_adjust = []\n    avgs = np.tile(average, (m, 1))\n    data_adjust = XMat - avgs\n    covX = np.cov(data_adjust.T)   #计算协方差矩阵\n    featValue, featVec=  np.linalg.eig(covX)  #求解协方差矩阵的特征值和特征向量\n    index = np.argsort(-featValue) #按照featValue进行从大到小排序\n    finalData = []\n    if k > n:\n        print \"k must lower than feature number\"\n        return\n    else:\n        #注意特征向量时列向量，而numpy的二维矩阵(数组)a[m][n]中，a[1]表示第1行值\n        selectVec = np.matrix(featVec.T[index[:k]]) #所以这里需要进行转置\n        finalData = data_adjust * selectVec.T \n        reconData = (finalData * selectVec) + average  \n    return finalData, reconData\n```\n\n\n4.编写一个加载数据集的函数\n\n```\n#输入文件的每行数据都以\\t隔开\ndef loaddata(datafile):\n    return np.array(pd.read_csv(datafile,sep=\"\\t\",header=-1)).astype(np.float)\n```\n\n5.可视化结果\n\n因为我将维数k指定为2，所以可以使用下面的函数将其绘制出来：\n\n```\ndef plotBestFit(data1, data2):\t  \n    dataArr1 = np.array(data1)\n    dataArr2 = np.array(data2)\n    \n    m = np.shape(dataArr1)[0]\n    axis_x1 = []\n    axis_y1 = []\n    axis_x2 = []\n    axis_y2 = []\n    for i in range(m):\n        axis_x1.append(dataArr1[i,0])\n        axis_y1.append(dataArr1[i,1])\n        axis_x2.append(dataArr2[i,0]) \n        axis_y2.append(dataArr2[i,1])\t\t\t\t  \n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.scatter(axis_x1, axis_y1, s=50, c='red', marker='s')\n    ax.scatter(axis_x2, axis_y2, s=50, c='blue')\n    plt.xlabel('x1'); plt.ylabel('x2');\n    plt.savefig(\"outfile.png\")\n    plt.show()\t\n```\n\n6.测试方法\n\n测试方法写入main函数中，然后直接执行main方法即可：\n\ndata.txt可到github中下载：[data.txt](https://github.com/csuldw/MachineLearning/tree/master/PCA/data.txt)\n\n```\n#根据数据集data.txt\ndef main():    \n    datafile = \"data.txt\"\n    XMat = loaddata(datafile)\n    k = 2\n    return pca(XMat, k)\nif __name__ == \"__main__\":\n    finalData, reconMat = main()\n    plotBestFit(finalData, reconMat)\n```\n\n## 结果展示\n\n最后的结果图如下：\n\n![](/assets/images/pca.png)\n\n\n蓝色部分为重构后的原始数据，红色则是提取后的二维特征！\n\n\n## 参考文献\n\n[1] http://www.cnblogs.com/jerrylead/archive/2011/04/18/2020209.html  \n[2] [Wikipedia- Linear discriminant analysis](https://en.wikipedia.org/wiki/Linear_discriminant_analysis)  \n[3] [Wikipedia- Principal_component_analysis](https://en.wikipedia.org/wiki/Principal_component_analysis)  \n[4][知乎-如何理解矩阵特征值](https://www.zhihu.com/question/21874816)","source":"_posts/2016-02-28-pca.md","raw":"---\nlayout: post\ndate: 2016-02-28 15:24\ntitle: \"PCA主成分分析Python实现\"\ncategories: ML\ntag: \n\t- Machine Learning\n\t- PCA\n\t- 主成分分析\ncomment: true\n---\n\nGithub源码：https://github.com/csuldw/MachineLearning/tree/master/PCA\n\nPCA（principle component analysis） ，主成分分析，主要是用来降低数据集的维度，然后挑选出主要的特征。原理简单，实现也简单。关于原理公式的推导，本文不会涉及，你可以参考下面的参考文献，也可以去Wikipedia，这里主要关注实现，算是锻炼一下自己，对PCA在理论的基础上画个圆满的句号。\n\n<!-- more-->\n\n本来是在复习LDA的，然后就看到了PCA，就跟着下面这篇文章的步骤，把PCA用python实现了一遍，具体的思想可以参考这篇文章，讲的通俗易懂，主要是有个实例参考，值得拥有！\n\n- [JerryLead之PCA主成分分析](http://www.cnblogs.com/jerrylead/archive/2011/04/18/2020209.html)\n\n下面自己来简单的清理下思路！\n\n## PCA思想\n\n思想：<font color=\"#007FFF\">**移动坐标轴，将n维特征映射到k维上（k<n），这k维是全新的正交特征。**</font>这k维特征称为主元，是重新构造出来的k维特征，而不是简单地从n维特征中去除其余n-k维特征。\n\n说到PCA难免会提到LDA（linear discriminate analysis，线性判别分析），以及FA（factor analysis，因子分析）。关于LDA，打算有时间也用代码实现一遍，下面给出它的主要思想。\n\nLDA思想：<font color=\"#007FFF\">**最大类间距离，最小类内距离**</font>。简而言之，第一，为了实现投影后的两个类别的距离较远，用映射后两个类别的均值差的绝对值来度量。第二，为了实现投影后，每个类内部数据点比较聚集，用投影后每个类别的方差来度量。\n\n三者的描述如下\n\n 以下内容引自 [Wikipedia- Linear discriminant analysis](https://en.wikipedia.org/wiki/Linear_discriminant_analysis)\n>LDA is also closely related to principal component analysis (PCA) and factor \t\tanalysis in that they both look for linear combinations of variables which best explain the data.[4] LDA explicitly attempts to model the difference between the classes of data. PCA on the other hand does not take into account any difference in class, and factor analysis builds the feature combinations based on differences rather than similarities. Discriminant analysis is also different from factor analysis in that it is not an interdependence technique: a distinction between independent variables and dependent variables (also called criterion variables) must be made.\n\n区别：PCA选择样本点投影具有最大方差的方向，LDA选择分类性能最好的方向。\n\n好了，下面来看下实现源码！\n\n## 基本步骤\n\n\n基本步骤：\n\n- 对数据进行归一化处理（代码中并非这么做的，而是直接减去均值）\n- 计算归一化后的数据集的协方差矩阵                   \n- 计算协方差矩阵的特征值和特征向量\n- 保留最重要的k个特征（通常k<n），可以自己制定，也可以选择个阈值，让后通过前k个特征值之和减去后面n-k个特征值之和大于这个阈值，找到这个k\n- 找出k个特征值对应的特征向量\n- 将m $\\*$ n的数据集乘以k个n维的特征向量的特征向量（n $\\*$ k）,得到最后降维的数据。\n\n其实PCA的本质就是对角化协方差矩阵。有必要解释下为什么将特征值按从大到小排序后再选。首先，要明白特征值表示的是什么？在线性代数里面我们求过无数次了，那么它具体有什么意义呢？对一个$n\\*n$的对称矩阵进行分解，我们可以求出它的特征值和特征向量，就会产生n个n维的正交基，每个正交基会对应一个特征值。然后把矩阵投影到这n个基上，此时特征值的模就表示矩阵在该基的投影长度。<font color=\"#007FFF\">**特征值越大，说明矩阵（样本）在对应的特征向量上投影后的方差越大，样本点越离散，越容易区分，信息量也就越多**</font>。因此，特征值最大的对应的特征向量方向上所包含的信息量就越多，如果某几个特征值很小，那么就说明在该方向的信息量非常少，我们就可以删除小特征值对应方向的数据，只保留大特征值方向对应的数据，这样做以后数据量减小，但有用的信息量都保留下来了。PCA就是这个原理。\n\n## 源码实现\n\n1.首先引入numpy，由于测试中用到了pandas和matplotlib，所以这里一并加载\n\n```\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n```\n\n2.定义一个均值函数\n\n```\n#计算均值,要求输入数据为numpy的矩阵格式，行表示样本数，列表示特征    \ndef meanX(dataX):\n    return np.mean(dataX,axis=0)#axis=0表示按照列来求均值，如果输入list,则axis=1\n```\n\n3.编写pca方法，具体解释参考注释\n\n```\n\"\"\"\n参数：\n\t- XMat：传入的是一个numpy的矩阵格式，行表示样本数，列表示特征    \n\t- k：表示取前k个特征值对应的特征向量\n返回值：\n\t- finalData：参数一指的是返回的低维矩阵，对应于输入参数二\n\t- reconData：参数二对应的是移动坐标轴后的矩阵\n\"\"\"\ndef pca(XMat, k):\n    average = meanX(XMat) \n    m, n = np.shape(XMat)\n    data_adjust = []\n    avgs = np.tile(average, (m, 1))\n    data_adjust = XMat - avgs\n    covX = np.cov(data_adjust.T)   #计算协方差矩阵\n    featValue, featVec=  np.linalg.eig(covX)  #求解协方差矩阵的特征值和特征向量\n    index = np.argsort(-featValue) #按照featValue进行从大到小排序\n    finalData = []\n    if k > n:\n        print \"k must lower than feature number\"\n        return\n    else:\n        #注意特征向量时列向量，而numpy的二维矩阵(数组)a[m][n]中，a[1]表示第1行值\n        selectVec = np.matrix(featVec.T[index[:k]]) #所以这里需要进行转置\n        finalData = data_adjust * selectVec.T \n        reconData = (finalData * selectVec) + average  \n    return finalData, reconData\n```\n\n\n4.编写一个加载数据集的函数\n\n```\n#输入文件的每行数据都以\\t隔开\ndef loaddata(datafile):\n    return np.array(pd.read_csv(datafile,sep=\"\\t\",header=-1)).astype(np.float)\n```\n\n5.可视化结果\n\n因为我将维数k指定为2，所以可以使用下面的函数将其绘制出来：\n\n```\ndef plotBestFit(data1, data2):\t  \n    dataArr1 = np.array(data1)\n    dataArr2 = np.array(data2)\n    \n    m = np.shape(dataArr1)[0]\n    axis_x1 = []\n    axis_y1 = []\n    axis_x2 = []\n    axis_y2 = []\n    for i in range(m):\n        axis_x1.append(dataArr1[i,0])\n        axis_y1.append(dataArr1[i,1])\n        axis_x2.append(dataArr2[i,0]) \n        axis_y2.append(dataArr2[i,1])\t\t\t\t  \n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.scatter(axis_x1, axis_y1, s=50, c='red', marker='s')\n    ax.scatter(axis_x2, axis_y2, s=50, c='blue')\n    plt.xlabel('x1'); plt.ylabel('x2');\n    plt.savefig(\"outfile.png\")\n    plt.show()\t\n```\n\n6.测试方法\n\n测试方法写入main函数中，然后直接执行main方法即可：\n\ndata.txt可到github中下载：[data.txt](https://github.com/csuldw/MachineLearning/tree/master/PCA/data.txt)\n\n```\n#根据数据集data.txt\ndef main():    \n    datafile = \"data.txt\"\n    XMat = loaddata(datafile)\n    k = 2\n    return pca(XMat, k)\nif __name__ == \"__main__\":\n    finalData, reconMat = main()\n    plotBestFit(finalData, reconMat)\n```\n\n## 结果展示\n\n最后的结果图如下：\n\n![](/assets/images/pca.png)\n\n\n蓝色部分为重构后的原始数据，红色则是提取后的二维特征！\n\n\n## 参考文献\n\n[1] http://www.cnblogs.com/jerrylead/archive/2011/04/18/2020209.html  \n[2] [Wikipedia- Linear discriminant analysis](https://en.wikipedia.org/wiki/Linear_discriminant_analysis)  \n[3] [Wikipedia- Principal_component_analysis](https://en.wikipedia.org/wiki/Principal_component_analysis)  \n[4][知乎-如何理解矩阵特征值](https://www.zhihu.com/question/21874816)","slug":"2016-02-28-pca","published":1,"updated":"2016-05-10T16:17:28.968Z","_id":"cimigpyu8002x6cuj3awrm2j5","comments":1,"photos":[],"link":""},{"layout":"post","date":"2016-02-26T12:24:00.000Z","title":"机器学习算法比较","comment":true,"_content":"\n本文主要回顾下几个常用算法的适应场景及其优缺点！（提示：部分内容摘自网络）。\n\n机器学习算法太多了，分类、回归、聚类、推荐、图像识别领域等等，要想找到一个合适算法真的不容易，所以在实际应用中，我们一般都是采用启发式学习方式来实验。通常最开始我们都会选择大家普遍认同的算法，诸如SVM，GBDT，Adaboost，现在深度学习很火热，神经网络也是一个不错的选择。假如你在乎精度（accuracy）的话，最好的方法就是通过交叉验证（cross-validation）对各个算法一个个地进行测试，进行比较，然后调整参数确保每个算法达到最优解，最后选择最好的一个。但是如果你只是在寻找一个“足够好”的算法来解决你的问题，或者这里有些技巧可以参考，下面来分析下各个算法的优缺点，基于算法的优缺点，更易于我们去选择它。\n\n<!-- more -->\n\n## 偏差&方差\n\n在统计学中，一个模型好坏，是根据偏差和方差来衡量的，所以我们先来普及一下偏差和方差：\n\n- 偏差：描述的是预测值（估计值）的期望E'与真实值Y之间的差距。偏差越大，越偏离真实数据。\n\n![](https://upload.wikimedia.org/math/d/5/0/d50ed92100881594dd3e3e5fe524d1d9.png)\n\n- 方差：描述的是预测值P的变化范围，离散程度，是预测值的方差，也就是离其期望值E的距离。方差越大，数据的分布越分散。\n\n![](https://upload.wikimedia.org/math/6/4/9/6491e89f257cf71eea37182592f4cd3c.png)\n\n模型的真实误差是两者之和，如下图：\n\n![](https://upload.wikimedia.org/math/c/b/c/cbc65310d09a6efa630d8c1f33cdfa88.png)\n\n如果是小训练集，高偏差/低方差的分类器（例如，朴素贝叶斯NB）要比低偏差/高方差大分类的优势大（例如，KNN），因为后者会过拟合。但是，随着你训练集的增长，模型对于原数据的预测能力就越好，偏差就会降低，此时低偏差/高方差分类器就会渐渐的表现其优势（因为它们有较低的渐近误差），此时高偏差分类器此时已经不足以提供准确的模型了。\n\n当然，你也可以认为这是生成模型（NB）与判别模型（KNN）的一个区别。\n\n<font color=red>为什么说朴素贝叶斯是高偏差低方差?</font>\n\n以下内容引自知乎：\n\n> 首先，假设你知道训练集和测试集的关系。简单来讲是我们要在训练集上学习一个模型，然后拿到测试集去用，效果好不好要根据测试集的错误率来衡量。但很多时候，我们只能假设测试集和训练集的是符合同一个数据分布的，但却拿不到真正的测试数据。这时候怎么在只看到训练错误率的情况下，去衡量测试错误率呢？\n\n>由于训练样本很少（至少不足够多），所以通过训练集得到的模型，总不是真正正确的。（就算在训练集上正确率100%，也不能说明它刻画了真实的数据分布，要知道刻画真实的数据分布才是我们的目的，而不是只刻画训练集的有限的数据点）。而且，实际中，训练样本往往还有一定的噪音误差，所以如果太追求在训练集上的完美而采用一个很复杂的模型，会使得模型把训练集里面的误差都当成了真实的数据分布特征，从而得到错误的数据分布估计。这样的话，到了真正的测试集上就错的一塌糊涂了（这种现象叫过拟合）。但是也不能用太简单的模型，否则在数据分布比较复杂的时候，模型就不足以刻画数据分布了（体现为连在训练集上的错误率都很高，这种现象较欠拟合）。过拟合表明采用的模型比真实的数据分布更复杂，而欠拟合表示采用的模型比真实的数据分布要简单。\n\n>在统计学习框架下，大家刻画模型复杂度的时候，有这么个观点，认为Error = Bias + Variance。这里的Error大概可以理解为模型的预测错误率，是有两部分组成的，一部分是由于模型太简单而带来的估计不准确的部分（Bias），另一部分是由于模型太复杂而带来的更大的变化空间和不确定性（Variance）。\n\n>所以，这样就容易分析朴素贝叶斯了。它简单的假设了各个数据之间是无关的，是一个被<font color=blue>**严重简化了的模型**</font>。所以，对于这样一个简单模型，大部分场合都会Bias部分大于Variance部分，也就是说高偏差而低方差。\n\n>在实际中，为了让Error尽量小，我们在选择模型的时候需要平衡Bias和Variance所占的比例，也就是平衡over-fitting和under-fitting。\n\n偏差和方差与模型复杂度的关系使用下图更加明了：\n\n![](/assets/articleImg/bias_variance.png)\n\n当模型复杂度上升的时候，偏差会逐渐变小，而方差会逐渐变大。\n\n## 常见算法优缺点\n\n### 1.**朴素贝叶斯**\n\n朴素贝叶斯属于生成式模型（关于生成模型和判别式模型，主要还是在于是否是要求联合分布），非常简单，你只是做了一堆计数。如果注有条件独立性假设（一个比较严格的条件），朴素贝叶斯分类器的收敛速度将快于判别模型，如逻辑回归，所以你只需要较少的训练数据即可。即使NB条件独立假设不成立，NB分类器在实践中仍然表现的很出色。它的主要缺点是它不能学习特征间的相互作用，用mRMR中R来讲，就是特征冗余。引用一个比较经典的例子，比如，虽然你喜欢Brad Pitt和Tom Cruise的电影，但是它不能学习出你不喜欢他们在一起演的电影。\n\n**优点**：\n\n- 朴素贝叶斯模型发源于古典数学理论，有着坚实的数学基础，以及稳定的分类效率。\n- 对小规模的数据表现很好，能个处理多分类任务，适合增量式训练；\n- 对缺失数据不太敏感，算法也比较简单，常用于文本分类。\n \n**缺点**：\n\n- 需要计算先验概率；\n- 分类决策存在错误率；\n- 对输入数据的表达形式很敏感。\n\n---\n\n###  2.**Logistic Regression（逻辑回归）**\n\n属于判别式模型，有很多正则化模型的方法（L0， L1，L2，etc），而且你不必像在用朴素贝叶斯那样担心你的特征是否相关。与决策树与SVM机相比，你还会得到一个不错的概率解释，你甚至可以轻松地利用新数据来更新模型（使用在线梯度下降算法，online gradient descent）。如果你需要一个概率架构（比如，简单地调节分类阈值，指明不确定性，或者是要获得置信区间），或者你希望以后将更多的训练数据快速整合到模型中去，那么使用它吧。\n\n**Sigmoid函数**：  \n\n![$$f(x) = \\frac{1}{1+e^{-x}}$$](http://latex.codecogs.com/gif.latex?%24%24f%28x%29%20%3D%20%5Cfrac%7B1%7D%7B1&plus;e%5E%7B-x%7D%7D%24%24)\n\n**优点：**  \n\n- 实现简单，广泛的应用于工业问题上；\n- 分类时计算量非常小，速度很快，存储资源低；\n- 便利的观测样本概率分数；\n- 对逻辑回归而言，多重共线性并不是问题，它可以结合L2正则化来解决该问题；\n\n**缺点**：\n\n- 当特征空间很大时，逻辑回归的性能不是很好；\n- 容易**欠拟合**，一般准确度不太高\n- 不能很好地处理大量多类特征或变量；\n- 只能处理两分类问题（在此基础上衍生出来的softmax可以用于多分类），且必须**线性可分**；\n- 对于非线性特征，需要进行转换；\n\n---\n\n###  **3.线性回归**\n\n 线性回归是用于回归的，而不像Logistic回归是用于分类，其基本思想是用**梯度下降法**对最小二乘法形式的误差函数进行优化，当然也可以用normal equation直接求得参数的解，结果为：\n\n![$$ \\hat{w}=(X^{T}X)^{-1}X^Ty$$](http://latex.codecogs.com/gif.latex?%24%24%20%5Chat%7Bw%7D%3D%28X%5E%7BT%7DX%29%5E%7B-1%7DX%5ETy%24%24)\n\n而在LWLR（局部加权线性回归）中，参数的计算表达式为:\n\n![$$ \\hat{w}=(X^{T}WX)^{-1}X^TWy$$](http://latex.codecogs.com/gif.latex?%24%24%20%5Chat%7Bw%7D%3D%28X%5E%7BT%7DWX%29%5E%7B-1%7DX%5ETWy%24%24)\n\n由此可见LWLR与LR不同，LWLR是一个非参数模型，因为每次进行回归计算都要遍历训练样本至少一次。\n\n**优点**： 实现简单，计算简单；  \n**缺点**： 不能拟合非线性数据.\n\n---\n\n###  4.最近领算法——KNN\n\nKNN即最近邻算法，其主要过程为：\n\n\t1. 计算训练样本和测试样本中每个样本点的距离（常见的距离度量有欧式距离，马氏距离等）；\n\t2. 对上面所有的距离值进行排序；\n\t3. 选前k个最小距离的样本；\n\t4. 根据这k个样本的标签进行投票，得到最后的分类类别；\n\n如何选择一个最佳的K值，这取决于数据。一般情况下，在分类时较大的K值能够减小噪声的影响。但会使类别之间的界限变得模糊。一个较好的K值可通过各种启发式技术来获取，比如，交叉验证。另外噪声和非相关性特征向量的存在会使K近邻算法的准确性减小。\n\n近邻算法具有较强的一致性结果。随着数据趋于无限，算法保证错误率不会超过贝叶斯算法错误率的两倍。对于一些好的K值，K近邻保证错误率不会超过贝叶斯理论误差率。\n\n**KNN算法的优点**\n\n- 理论成熟，思想简单，既可以用来做分类也可以用来做回归；\n- 可用于非线性分类；\n- 训练时间复杂度为O(n)；\n- 对数据没有假设，准确度高，对outlier不敏感；\n\n**缺点**\n\n- 计算量大；\n- 样本不平衡问题（即有些类别的样本数量很多，而其它样本的数量很少）；\n-  需要大量的内存；\n\n---\n\n\n###  5.决策树\n\n易于解释。它可以毫无压力地处理特征间的交互关系并且是非参数化的，因此你不必担心异常值或者数据是否线性可分（举个例子，决策树能轻松处理好类别A在某个特征维度x的末端，类别B在中间，然后类别A又出现在特征维度x前端的情况）。它的缺点之一就是不支持在线学习，于是在新样本到来后，决策树需要全部重建。另一个缺点就是容易出现过拟合，但这也就是诸如随机森林RF（或提升树boosted tree）之类的集成方法的切入点。另外，随机森林经常是很多分类问题的赢家（通常比支持向量机好上那么一丁点），它训练快速并且可调，同时你无须担心要像支持向量机那样调一大堆参数，所以在以前都一直很受欢迎。\n\n决策树中很重要的一点就是选择一个属性进行分枝，因此要注意一下信息增益的计算公式，并深入理解它。\n\n信息熵的计算公式如下:\n\n![$$H=-\\sum^{n}_{i=1}p(x_i)log_2p(x_i)$$](http://latex.codecogs.com/gif.latex?%24%24H%3D-%5Csum%5E%7Bn%7D_%7Bi%3D1%7Dp%28x_i%29log_2p%28x_i%29%24%24)\n\n\n其中的n代表有n个分类类别（比如假设是2类问题，那么n=2）。分别计算这2类样本在总样本中出现的概率p1和p2，这样就可以计算出未选中属性分枝前的信息熵。\n\n现在选中一个属性$x_i$用来进行分枝，此时分枝规则是：如果$x_i=v$的话，将样本分到树的一个分支；如果不相等则进入另一个分支。很显然，分支中的样本很有可能包括2个类别，分别计算这2个分支的熵H1和H2,计算出分枝后的总信息熵H' =p1 * H1+p2 * H2,则此时的信息增益ΔH = H - H'。以信息增益为原则，把所有的属性都测试一边，选择一个使增益最大的属性作为本次分枝属性。\n\n**决策树自身的优点**\n\n- 计算简单，易于理解，可解释性强；\n- 比较适合处理有缺失属性的样本；\n- 能够处理不相关的特征；\n- 在相对短的时间内能够对大型数据源做出可行且效果良好的结果。\n\n**缺点**\n\n- 容易发生过拟合（随机森林可以很大程度上减少过拟合）；\n- 忽略了数据之间的相关性；\n- 对于那些各类别样本数量不一致的数据，在决策树当中,信息增益的结果偏向于那些具有更多数值的特征（只要是使用了信息增益，都有这个缺点，如RF）。\n\n\n#### 5.1 Adaboosting\n\nAdaboost是一种加和模型，每个模型都是基于上一次模型的错误率来建立的，过分关注分错的样本，而对正确分类的样本减少关注度，逐次迭代之后，可以得到一个相对较好的模型。是一种典型的boosting算法。下面是总结下它的优缺点。\n\n**优点**\n\n- adaboost是一种有很高精度的分类器。\n- 可以使用各种方法构建子分类器，Adaboost算法提供的是框架。\n- 当使用简单分类器时，计算出的结果是可以理解的，并且弱分类器的构造极其简单。\n- 简单，不用做特征筛选。\n- 不容易发生overfitting。\n\n关于随机森林和GBDT等组合算法，参考这篇文章：[机器学习-组合算法总结](http://www.csuldw.com/2015/07/22/2015-07-22%20%20ensemble/)\n\n**缺点：**对outlier比较敏感\n \n---\n\n### 6.SVM支持向量机\n\n高准确率，为避免过拟合提供了很好的理论保证，而且就算数据在原特征空间线性不可分，只要给个合适的核函数，它就能运行得很好。在动辄超高维的文本分类问题中特别受欢迎。可惜内存消耗大，难以解释，运行和调参也有些烦人，而随机森林却刚好避开了这些缺点，比较实用。\n\n\n**优点**\n\n- 可以解决高维问题，即大型特征空间；\n- 能够处理非线性特征的相互作用；\n- 无需依赖整个数据；\n- 可以提高泛化能力；\n\n**缺点**\n\n- 当观测样本很多时，效率并不是很高；\n- 对非线性问题没有通用解决方案，有时候很难找到一个合适的核函数；\n- 对缺失数据敏感；\n\n对于核的选择也是有技巧的（libsvm中自带了四种核函数：线性核、多项式核、RBF以及sigmoid核）：\n\n- 第一，如果样本数量小于特征数，那么就没必要选择非线性核，简单的使用线性核就可以了；\n- 第二，如果样本数量大于特征数目，这时可以使用非线性核，将样本映射到更高维度，一般可以得到更好的结果；\n- 第三，如果样本数目和特征数目相等，该情况可以使用非线性核，原理和第二种一样。\n\n对于第一种情况，也可以先对数据进行降维，然后使用非线性核，这也是一种方法。\n\n---\n\n### 7. 人工神经网络的优缺点\n\n**人工神经网络的优点：**\n\n- 分类的准确度高；\n- 并行分布处理能力强,分布存储及学习能力强，\n- 对噪声神经有较强的鲁棒性和容错能力，能充分逼近复杂的非线性关系；\n- 具备联想记忆的功能。\n\n**人工神经网络的缺点：**\n\n- 神经网络需要大量的参数，如网络拓扑结构、权值和阈值的初始值；\n- 不能观察之间的学习过程，输出结果难以解释，会影响到结果的可信度和可接受程度；\n- 学习时间过长,甚至可能达不到学习的目的。\n\n---\n\n\n###　8、K-Means聚类\n\n之前写过一篇关于K-Means聚类的文章，博文链接：[机器学习算法-K-means聚类](http://www.csuldw.com/2015/06/03/2015-06-03-ml-algorithm-K-means/)。关于K-Means的推导，里面有着很强大的EM思想。\n\n**优点**\n\n- 算法简单，容易实现 ；\n- 对处理大数据集，该算法是相对可伸缩的和高效率的，因为它的复杂度大约是O(nkt)，其中n是所有对象的数目，k是簇的数目,t是迭代的次数。通常k<<n。这个算法通常局部收敛。\n- 算法尝试找出使平方误差函数值最小的k个划分。当簇是密集的、球状或团状的，且簇与簇之间区别明显时，聚类效果较好。\n\n**缺点**\n\n- 对数据类型要求较高，适合数值型数据；\n- 可能收敛到局部最小值，在大规模数据上收敛较慢  \n- K值比较难以选取；\n- 对初值的簇心值敏感，对于不同的初始值，可能会导致不同的聚类结果；\n- 不适合于发现非凸面形状的簇，或者大小差别很大的簇。\n- 对于\"噪声\"和孤立点数据敏感，少量的该类数据能够对平均值产生极大影响。\n\n## 算法选择参考\n\n之前翻译过一些国外的文章，有一篇文章中给出了一个简单的算法选择技巧：\n\n1. 首当其冲应该选择的就是逻辑回归，如果它的效果不怎么样，那么可以将它的结果作为基准来参考，在基础上与其他算法进行比较；\n2. 然后试试决策树（随机森林）看看是否可以大幅度提升你的模型性能。即便最后你并没有把它当做为最终模型，你也可以使用随机森林来移除噪声变量，做特征选择；\n3. 如果特征的数量和观测样本特别多，那么当资源和时间充足时（这个前提很重要），使用SVM不失为一种选择。\n\n通常情况下：【GBDT>=SVM>=RF>=Adaboost>=Other...】，现在深度学习很热门，很多领域都用到，它是以神经网络为基础的，目前我自己也在学习，只是理论知识不是很厚实，理解的不够深，这里就不做介绍了。\n\n算法固然重要，**但好的数据却要优于好的算法**，设计优良特征是大有裨益的。假如你有一个超大数据集，那么无论你使用哪种算法可能对分类性能都没太大影响（此时就可以根据速度和易用性来进行抉择）。\n\n\n## 参考文献\n\n[1] https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff  \n[2] http://blog.echen.me/2011/04/27/choosing-a-machine-learning-classifier/  \n[3] http://www.csuldw.com/2016/02/26/2016-02-26-choosing-a-machine-learning-classifier/  \n","source":"_posts/2016-02-26-choosing-a-machine-learning-classifier.md","raw":"---\nlayout: post\ndate: 2016-02-26 20:24\ntitle: \"机器学习算法比较\"\ncategories: ML\ntag: \n\t- Machine Learning\n\t- 算法选择\n\t- 偏差\n\t- 方差\n\t- LR\ncomment: true\n---\n\n本文主要回顾下几个常用算法的适应场景及其优缺点！（提示：部分内容摘自网络）。\n\n机器学习算法太多了，分类、回归、聚类、推荐、图像识别领域等等，要想找到一个合适算法真的不容易，所以在实际应用中，我们一般都是采用启发式学习方式来实验。通常最开始我们都会选择大家普遍认同的算法，诸如SVM，GBDT，Adaboost，现在深度学习很火热，神经网络也是一个不错的选择。假如你在乎精度（accuracy）的话，最好的方法就是通过交叉验证（cross-validation）对各个算法一个个地进行测试，进行比较，然后调整参数确保每个算法达到最优解，最后选择最好的一个。但是如果你只是在寻找一个“足够好”的算法来解决你的问题，或者这里有些技巧可以参考，下面来分析下各个算法的优缺点，基于算法的优缺点，更易于我们去选择它。\n\n<!-- more -->\n\n## 偏差&方差\n\n在统计学中，一个模型好坏，是根据偏差和方差来衡量的，所以我们先来普及一下偏差和方差：\n\n- 偏差：描述的是预测值（估计值）的期望E'与真实值Y之间的差距。偏差越大，越偏离真实数据。\n\n![](https://upload.wikimedia.org/math/d/5/0/d50ed92100881594dd3e3e5fe524d1d9.png)\n\n- 方差：描述的是预测值P的变化范围，离散程度，是预测值的方差，也就是离其期望值E的距离。方差越大，数据的分布越分散。\n\n![](https://upload.wikimedia.org/math/6/4/9/6491e89f257cf71eea37182592f4cd3c.png)\n\n模型的真实误差是两者之和，如下图：\n\n![](https://upload.wikimedia.org/math/c/b/c/cbc65310d09a6efa630d8c1f33cdfa88.png)\n\n如果是小训练集，高偏差/低方差的分类器（例如，朴素贝叶斯NB）要比低偏差/高方差大分类的优势大（例如，KNN），因为后者会过拟合。但是，随着你训练集的增长，模型对于原数据的预测能力就越好，偏差就会降低，此时低偏差/高方差分类器就会渐渐的表现其优势（因为它们有较低的渐近误差），此时高偏差分类器此时已经不足以提供准确的模型了。\n\n当然，你也可以认为这是生成模型（NB）与判别模型（KNN）的一个区别。\n\n<font color=red>为什么说朴素贝叶斯是高偏差低方差?</font>\n\n以下内容引自知乎：\n\n> 首先，假设你知道训练集和测试集的关系。简单来讲是我们要在训练集上学习一个模型，然后拿到测试集去用，效果好不好要根据测试集的错误率来衡量。但很多时候，我们只能假设测试集和训练集的是符合同一个数据分布的，但却拿不到真正的测试数据。这时候怎么在只看到训练错误率的情况下，去衡量测试错误率呢？\n\n>由于训练样本很少（至少不足够多），所以通过训练集得到的模型，总不是真正正确的。（就算在训练集上正确率100%，也不能说明它刻画了真实的数据分布，要知道刻画真实的数据分布才是我们的目的，而不是只刻画训练集的有限的数据点）。而且，实际中，训练样本往往还有一定的噪音误差，所以如果太追求在训练集上的完美而采用一个很复杂的模型，会使得模型把训练集里面的误差都当成了真实的数据分布特征，从而得到错误的数据分布估计。这样的话，到了真正的测试集上就错的一塌糊涂了（这种现象叫过拟合）。但是也不能用太简单的模型，否则在数据分布比较复杂的时候，模型就不足以刻画数据分布了（体现为连在训练集上的错误率都很高，这种现象较欠拟合）。过拟合表明采用的模型比真实的数据分布更复杂，而欠拟合表示采用的模型比真实的数据分布要简单。\n\n>在统计学习框架下，大家刻画模型复杂度的时候，有这么个观点，认为Error = Bias + Variance。这里的Error大概可以理解为模型的预测错误率，是有两部分组成的，一部分是由于模型太简单而带来的估计不准确的部分（Bias），另一部分是由于模型太复杂而带来的更大的变化空间和不确定性（Variance）。\n\n>所以，这样就容易分析朴素贝叶斯了。它简单的假设了各个数据之间是无关的，是一个被<font color=blue>**严重简化了的模型**</font>。所以，对于这样一个简单模型，大部分场合都会Bias部分大于Variance部分，也就是说高偏差而低方差。\n\n>在实际中，为了让Error尽量小，我们在选择模型的时候需要平衡Bias和Variance所占的比例，也就是平衡over-fitting和under-fitting。\n\n偏差和方差与模型复杂度的关系使用下图更加明了：\n\n![](/assets/articleImg/bias_variance.png)\n\n当模型复杂度上升的时候，偏差会逐渐变小，而方差会逐渐变大。\n\n## 常见算法优缺点\n\n### 1.**朴素贝叶斯**\n\n朴素贝叶斯属于生成式模型（关于生成模型和判别式模型，主要还是在于是否是要求联合分布），非常简单，你只是做了一堆计数。如果注有条件独立性假设（一个比较严格的条件），朴素贝叶斯分类器的收敛速度将快于判别模型，如逻辑回归，所以你只需要较少的训练数据即可。即使NB条件独立假设不成立，NB分类器在实践中仍然表现的很出色。它的主要缺点是它不能学习特征间的相互作用，用mRMR中R来讲，就是特征冗余。引用一个比较经典的例子，比如，虽然你喜欢Brad Pitt和Tom Cruise的电影，但是它不能学习出你不喜欢他们在一起演的电影。\n\n**优点**：\n\n- 朴素贝叶斯模型发源于古典数学理论，有着坚实的数学基础，以及稳定的分类效率。\n- 对小规模的数据表现很好，能个处理多分类任务，适合增量式训练；\n- 对缺失数据不太敏感，算法也比较简单，常用于文本分类。\n \n**缺点**：\n\n- 需要计算先验概率；\n- 分类决策存在错误率；\n- 对输入数据的表达形式很敏感。\n\n---\n\n###  2.**Logistic Regression（逻辑回归）**\n\n属于判别式模型，有很多正则化模型的方法（L0， L1，L2，etc），而且你不必像在用朴素贝叶斯那样担心你的特征是否相关。与决策树与SVM机相比，你还会得到一个不错的概率解释，你甚至可以轻松地利用新数据来更新模型（使用在线梯度下降算法，online gradient descent）。如果你需要一个概率架构（比如，简单地调节分类阈值，指明不确定性，或者是要获得置信区间），或者你希望以后将更多的训练数据快速整合到模型中去，那么使用它吧。\n\n**Sigmoid函数**：  \n\n![$$f(x) = \\frac{1}{1+e^{-x}}$$](http://latex.codecogs.com/gif.latex?%24%24f%28x%29%20%3D%20%5Cfrac%7B1%7D%7B1&plus;e%5E%7B-x%7D%7D%24%24)\n\n**优点：**  \n\n- 实现简单，广泛的应用于工业问题上；\n- 分类时计算量非常小，速度很快，存储资源低；\n- 便利的观测样本概率分数；\n- 对逻辑回归而言，多重共线性并不是问题，它可以结合L2正则化来解决该问题；\n\n**缺点**：\n\n- 当特征空间很大时，逻辑回归的性能不是很好；\n- 容易**欠拟合**，一般准确度不太高\n- 不能很好地处理大量多类特征或变量；\n- 只能处理两分类问题（在此基础上衍生出来的softmax可以用于多分类），且必须**线性可分**；\n- 对于非线性特征，需要进行转换；\n\n---\n\n###  **3.线性回归**\n\n 线性回归是用于回归的，而不像Logistic回归是用于分类，其基本思想是用**梯度下降法**对最小二乘法形式的误差函数进行优化，当然也可以用normal equation直接求得参数的解，结果为：\n\n![$$ \\hat{w}=(X^{T}X)^{-1}X^Ty$$](http://latex.codecogs.com/gif.latex?%24%24%20%5Chat%7Bw%7D%3D%28X%5E%7BT%7DX%29%5E%7B-1%7DX%5ETy%24%24)\n\n而在LWLR（局部加权线性回归）中，参数的计算表达式为:\n\n![$$ \\hat{w}=(X^{T}WX)^{-1}X^TWy$$](http://latex.codecogs.com/gif.latex?%24%24%20%5Chat%7Bw%7D%3D%28X%5E%7BT%7DWX%29%5E%7B-1%7DX%5ETWy%24%24)\n\n由此可见LWLR与LR不同，LWLR是一个非参数模型，因为每次进行回归计算都要遍历训练样本至少一次。\n\n**优点**： 实现简单，计算简单；  \n**缺点**： 不能拟合非线性数据.\n\n---\n\n###  4.最近领算法——KNN\n\nKNN即最近邻算法，其主要过程为：\n\n\t1. 计算训练样本和测试样本中每个样本点的距离（常见的距离度量有欧式距离，马氏距离等）；\n\t2. 对上面所有的距离值进行排序；\n\t3. 选前k个最小距离的样本；\n\t4. 根据这k个样本的标签进行投票，得到最后的分类类别；\n\n如何选择一个最佳的K值，这取决于数据。一般情况下，在分类时较大的K值能够减小噪声的影响。但会使类别之间的界限变得模糊。一个较好的K值可通过各种启发式技术来获取，比如，交叉验证。另外噪声和非相关性特征向量的存在会使K近邻算法的准确性减小。\n\n近邻算法具有较强的一致性结果。随着数据趋于无限，算法保证错误率不会超过贝叶斯算法错误率的两倍。对于一些好的K值，K近邻保证错误率不会超过贝叶斯理论误差率。\n\n**KNN算法的优点**\n\n- 理论成熟，思想简单，既可以用来做分类也可以用来做回归；\n- 可用于非线性分类；\n- 训练时间复杂度为O(n)；\n- 对数据没有假设，准确度高，对outlier不敏感；\n\n**缺点**\n\n- 计算量大；\n- 样本不平衡问题（即有些类别的样本数量很多，而其它样本的数量很少）；\n-  需要大量的内存；\n\n---\n\n\n###  5.决策树\n\n易于解释。它可以毫无压力地处理特征间的交互关系并且是非参数化的，因此你不必担心异常值或者数据是否线性可分（举个例子，决策树能轻松处理好类别A在某个特征维度x的末端，类别B在中间，然后类别A又出现在特征维度x前端的情况）。它的缺点之一就是不支持在线学习，于是在新样本到来后，决策树需要全部重建。另一个缺点就是容易出现过拟合，但这也就是诸如随机森林RF（或提升树boosted tree）之类的集成方法的切入点。另外，随机森林经常是很多分类问题的赢家（通常比支持向量机好上那么一丁点），它训练快速并且可调，同时你无须担心要像支持向量机那样调一大堆参数，所以在以前都一直很受欢迎。\n\n决策树中很重要的一点就是选择一个属性进行分枝，因此要注意一下信息增益的计算公式，并深入理解它。\n\n信息熵的计算公式如下:\n\n![$$H=-\\sum^{n}_{i=1}p(x_i)log_2p(x_i)$$](http://latex.codecogs.com/gif.latex?%24%24H%3D-%5Csum%5E%7Bn%7D_%7Bi%3D1%7Dp%28x_i%29log_2p%28x_i%29%24%24)\n\n\n其中的n代表有n个分类类别（比如假设是2类问题，那么n=2）。分别计算这2类样本在总样本中出现的概率p1和p2，这样就可以计算出未选中属性分枝前的信息熵。\n\n现在选中一个属性$x_i$用来进行分枝，此时分枝规则是：如果$x_i=v$的话，将样本分到树的一个分支；如果不相等则进入另一个分支。很显然，分支中的样本很有可能包括2个类别，分别计算这2个分支的熵H1和H2,计算出分枝后的总信息熵H' =p1 * H1+p2 * H2,则此时的信息增益ΔH = H - H'。以信息增益为原则，把所有的属性都测试一边，选择一个使增益最大的属性作为本次分枝属性。\n\n**决策树自身的优点**\n\n- 计算简单，易于理解，可解释性强；\n- 比较适合处理有缺失属性的样本；\n- 能够处理不相关的特征；\n- 在相对短的时间内能够对大型数据源做出可行且效果良好的结果。\n\n**缺点**\n\n- 容易发生过拟合（随机森林可以很大程度上减少过拟合）；\n- 忽略了数据之间的相关性；\n- 对于那些各类别样本数量不一致的数据，在决策树当中,信息增益的结果偏向于那些具有更多数值的特征（只要是使用了信息增益，都有这个缺点，如RF）。\n\n\n#### 5.1 Adaboosting\n\nAdaboost是一种加和模型，每个模型都是基于上一次模型的错误率来建立的，过分关注分错的样本，而对正确分类的样本减少关注度，逐次迭代之后，可以得到一个相对较好的模型。是一种典型的boosting算法。下面是总结下它的优缺点。\n\n**优点**\n\n- adaboost是一种有很高精度的分类器。\n- 可以使用各种方法构建子分类器，Adaboost算法提供的是框架。\n- 当使用简单分类器时，计算出的结果是可以理解的，并且弱分类器的构造极其简单。\n- 简单，不用做特征筛选。\n- 不容易发生overfitting。\n\n关于随机森林和GBDT等组合算法，参考这篇文章：[机器学习-组合算法总结](http://www.csuldw.com/2015/07/22/2015-07-22%20%20ensemble/)\n\n**缺点：**对outlier比较敏感\n \n---\n\n### 6.SVM支持向量机\n\n高准确率，为避免过拟合提供了很好的理论保证，而且就算数据在原特征空间线性不可分，只要给个合适的核函数，它就能运行得很好。在动辄超高维的文本分类问题中特别受欢迎。可惜内存消耗大，难以解释，运行和调参也有些烦人，而随机森林却刚好避开了这些缺点，比较实用。\n\n\n**优点**\n\n- 可以解决高维问题，即大型特征空间；\n- 能够处理非线性特征的相互作用；\n- 无需依赖整个数据；\n- 可以提高泛化能力；\n\n**缺点**\n\n- 当观测样本很多时，效率并不是很高；\n- 对非线性问题没有通用解决方案，有时候很难找到一个合适的核函数；\n- 对缺失数据敏感；\n\n对于核的选择也是有技巧的（libsvm中自带了四种核函数：线性核、多项式核、RBF以及sigmoid核）：\n\n- 第一，如果样本数量小于特征数，那么就没必要选择非线性核，简单的使用线性核就可以了；\n- 第二，如果样本数量大于特征数目，这时可以使用非线性核，将样本映射到更高维度，一般可以得到更好的结果；\n- 第三，如果样本数目和特征数目相等，该情况可以使用非线性核，原理和第二种一样。\n\n对于第一种情况，也可以先对数据进行降维，然后使用非线性核，这也是一种方法。\n\n---\n\n### 7. 人工神经网络的优缺点\n\n**人工神经网络的优点：**\n\n- 分类的准确度高；\n- 并行分布处理能力强,分布存储及学习能力强，\n- 对噪声神经有较强的鲁棒性和容错能力，能充分逼近复杂的非线性关系；\n- 具备联想记忆的功能。\n\n**人工神经网络的缺点：**\n\n- 神经网络需要大量的参数，如网络拓扑结构、权值和阈值的初始值；\n- 不能观察之间的学习过程，输出结果难以解释，会影响到结果的可信度和可接受程度；\n- 学习时间过长,甚至可能达不到学习的目的。\n\n---\n\n\n###　8、K-Means聚类\n\n之前写过一篇关于K-Means聚类的文章，博文链接：[机器学习算法-K-means聚类](http://www.csuldw.com/2015/06/03/2015-06-03-ml-algorithm-K-means/)。关于K-Means的推导，里面有着很强大的EM思想。\n\n**优点**\n\n- 算法简单，容易实现 ；\n- 对处理大数据集，该算法是相对可伸缩的和高效率的，因为它的复杂度大约是O(nkt)，其中n是所有对象的数目，k是簇的数目,t是迭代的次数。通常k<<n。这个算法通常局部收敛。\n- 算法尝试找出使平方误差函数值最小的k个划分。当簇是密集的、球状或团状的，且簇与簇之间区别明显时，聚类效果较好。\n\n**缺点**\n\n- 对数据类型要求较高，适合数值型数据；\n- 可能收敛到局部最小值，在大规模数据上收敛较慢  \n- K值比较难以选取；\n- 对初值的簇心值敏感，对于不同的初始值，可能会导致不同的聚类结果；\n- 不适合于发现非凸面形状的簇，或者大小差别很大的簇。\n- 对于\"噪声\"和孤立点数据敏感，少量的该类数据能够对平均值产生极大影响。\n\n## 算法选择参考\n\n之前翻译过一些国外的文章，有一篇文章中给出了一个简单的算法选择技巧：\n\n1. 首当其冲应该选择的就是逻辑回归，如果它的效果不怎么样，那么可以将它的结果作为基准来参考，在基础上与其他算法进行比较；\n2. 然后试试决策树（随机森林）看看是否可以大幅度提升你的模型性能。即便最后你并没有把它当做为最终模型，你也可以使用随机森林来移除噪声变量，做特征选择；\n3. 如果特征的数量和观测样本特别多，那么当资源和时间充足时（这个前提很重要），使用SVM不失为一种选择。\n\n通常情况下：【GBDT>=SVM>=RF>=Adaboost>=Other...】，现在深度学习很热门，很多领域都用到，它是以神经网络为基础的，目前我自己也在学习，只是理论知识不是很厚实，理解的不够深，这里就不做介绍了。\n\n算法固然重要，**但好的数据却要优于好的算法**，设计优良特征是大有裨益的。假如你有一个超大数据集，那么无论你使用哪种算法可能对分类性能都没太大影响（此时就可以根据速度和易用性来进行抉择）。\n\n\n## 参考文献\n\n[1] https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff  \n[2] http://blog.echen.me/2011/04/27/choosing-a-machine-learning-classifier/  \n[3] http://www.csuldw.com/2016/02/26/2016-02-26-choosing-a-machine-learning-classifier/  \n","slug":"2016-02-26-choosing-a-machine-learning-classifier","published":1,"updated":"2016-05-10T16:17:03.091Z","_id":"cimigpyug00346cuja5g5fono","comments":1,"photos":[],"link":""},{"layout":"post","date":"2016-02-25T09:24:00.000Z","title":"机器学习数据集-MNIST","comment":true,"_content":"\n## 介绍\n\n在学习机器学习的时候，首当其冲的就是准备一份通用的数据集，方便与其他的算法进行比较。在这里，我写了一个用于加载MNIST数据集的方法，并将其进行封装，主要用于将MNIST数据集转换成numpy.array()格式的训练数据。直接下面看下面的代码吧(主要还是如何用python去读取binnary file)！\n\n<!-- more -->\n\nMNIST数据集原网址：[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)\n\nGithub源码下载：[数据集（源文件+解压文件+字体图像jpg格式）](https://github.com/csuldw/MachineLearning/tree/master/dataset/MNIST)， [py源码文件](https://github.com/csuldw/MachineLearning/tree/master/utils/)\n\n## 文件目录\n\n- [/utils/data_util.py](https://github.com/csuldw/MachineLearning/tree/master/utils/data_util.py) 用于加载MNIST数据集方法文件\n- [/utils/test.py](https://github.com/csuldw/MachineLearning/tree/master/utils/test.py) 用于测试的文件，一个简单的KNN测试MNIST数据集\n- [/data/train-images.idx3-ubyte](https://github.com/csuldw/MachineLearning/tree/master/dataset/MNIST) 训练集X\n- [/dataset/train-labels.idx1-ubyte](https://github.com/csuldw/MachineLearning/tree/master/dataset/MNIST) 训练集y\n- [/dataset/data/t10k-images.idx3-ubyte](https://github.com/csuldw/MachineLearning/tree/master/dataset/MNIST) 测试集X\n- [/dataset/data/t10k-labels.idx1-ubyte](https://github.com/csuldw/MachineLearning/tree/master/dataset/MNIST) 测试集y\n\n\n## MNIST数据集解释\n\n将MNIST文件解压后，发现这些文件并不是标准的图像格式。这些图像数据都保存在二进制文件中。每个样本图像的宽高为28*28。\n\nmnist的结构如下，选取train-images\n\n    TRAINING SET IMAGE FILE (train-images-idx3-ubyte):\n\n    [offset] [type]          [value]          [description] \n    0000     32 bit integer  0x00000803(2051) magic number \n    0004     32 bit integer  60000            number of images \n    0008     32 bit integer  28               number of rows \n    0012     32 bit integer  28               number of columns \n    0016     unsigned byte   ??               pixel \n    0017     unsigned byte   ??               pixel \n    ........ \n    xxxx     unsigned byte   ??               pixel\n\n\n首先该数据是以二进制存储的，我们读取的时候要以'rb'方式读取；其次，真正的数据只有[value]这一项，其他的[type]等只是来描述的，并不真正在数据文件里面。也就是说，在读取真实数据之前，我们要读取4个`32 bit integer`.由[offset]我们可以看出真正的pixel是从0016开始的，一个int 32位，所以在读取pixel之前我们要读取4个 32 bit integer，也就是magic number, number of images, number of rows, number of columns. 当然，在这里使用struct.unpack_from()会比较方便.\n\n\n## 源码\n\n说明：\n\n- '>IIII'指的是使用大端法读取4个unsinged int 32 bit integer\n- '>784B'指的是使用大端法读取784个unsigned byte\n\n\ndata_util.py文件\n\n```\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Thu Feb 25 14:40:06 2016\nload MNIST dataset\n@author: liudiwei\n\"\"\"\nimport numpy as np \nimport struct\nimport matplotlib.pyplot as plt \nimport os\n\nclass DataUtils(object):\n    \"\"\"MNIST数据集加载\n    输出格式为：numpy.array()    \n    \n    使用方法如下\n    from data_util import DataUtils\n    def main():\n        trainfile_X = '../dataset/MNIST/train-images.idx3-ubyte'\n        trainfile_y = '../dataset/MNIST/train-labels.idx1-ubyte'\n        testfile_X = '../dataset/MNIST/t10k-images.idx3-ubyte'\n        testfile_y = '../dataset/MNIST/t10k-labels.idx1-ubyte'\n        \n        train_X = DataUtils(filename=trainfile_X).getImage()\n        train_y = DataUtils(filename=trainfile_y).getLabel()\n        test_X = DataUtils(testfile_X).getImage()\n        test_y = DataUtils(testfile_y).getLabel()\n        \n        #以下内容是将图像保存到本地文件中\n        #path_trainset = \"../dataset/MNIST/imgs_train\"\n        #path_testset = \"../dataset/MNIST/imgs_test\"\n        #if not os.path.exists(path_trainset):\n        #    os.mkdir(path_trainset)\n        #if not os.path.exists(path_testset):\n        #    os.mkdir(path_testset)\n        #DataUtils(outpath=path_trainset).outImg(train_X, train_y)\n        #DataUtils(outpath=path_testset).outImg(test_X, test_y)\n    \n        return train_X, train_y, test_X, test_y \n    \"\"\"\n\n\n    def __init__(self, filename=None, outpath=None):\n        self._filename = filename\n        self._outpath = outpath\n        \n        self._tag = '>'\n        self._twoBytes = 'II'\n        self._fourBytes = 'IIII'    \n        self._pictureBytes = '784B'\n        self._labelByte = '1B'\n        self._twoBytes2 = self._tag + self._twoBytes\n        self._fourBytes2 = self._tag + self._fourBytes\n        self._pictureBytes2 = self._tag + self._pictureBytes\n        self._labelByte2 = self._tag + self._labelByte\n    \n    def getImage(self):\n        \"\"\"\n        将MNIST的二进制文件转换成像素特征数据\n        \"\"\"\n        binfile = open(self._filename, 'rb') #以二进制方式打开文件\n        buf = binfile.read() \n        binfile.close()\n        index = 0\n        numMagic,numImgs,numRows,numCols=struct.unpack_from(self._fourBytes2,\\\n                                                                    buf,\\\n                                                                    index)\n        index += struct.calcsize(self._fourBytes)\n        images = []\n        for i in range(numImgs):\n            imgVal = struct.unpack_from(self._pictureBytes2, buf, index)\n            index += struct.calcsize(self._pictureBytes2)\n            imgVal = list(imgVal)\n            for j in range(len(imgVal)):\n                if imgVal[j] > 1:\n                    imgVal[j] = 1\n            images.append(imgVal)\n        return np.array(images)\n        \n    def getLabel(self):\n        \"\"\"\n        将MNIST中label二进制文件转换成对应的label数字特征\n        \"\"\"\n        binFile = open(self._filename,'rb')\n        buf = binFile.read()\n        binFile.close()\n        index = 0\n        magic, numItems= struct.unpack_from(self._twoBytes2, buf,index)\n        index += struct.calcsize(self._twoBytes2)\n        labels = [];\n        for x in range(numItems):\n            im = struct.unpack_from(self._labelByte2,buf,index)\n            index += struct.calcsize(self._labelByte2)\n            labels.append(im[0])\n        return np.array(labels)\n\n    def outImg(self, arrX, arrY):\n        \"\"\"\n        根据生成的特征和数字标号，输出png的图像\n        \"\"\"\n        m, n = np.shape(arrX)\n        #每张图是28*28=784Byte\n        for i in range(1):\n            img = np.array(arrX[i])\n            img = img.reshape(28,28)\n            outfile = str(i) + \"_\" +  str(arrY[i]) + \".png\"\n            plt.figure()\n            plt.imshow(img, cmap = 'binary') #将图像黑白显示\n            plt.savefig(self._outpath + \"/\" + outfile)\n```\n\n\ntest.py文件:简单地测试了一下KNN算法，代码如下\n\n```\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Thu Feb 25 16:09:58 2016\nTest MNIST dataset \n@author: liudiwei\n\"\"\"\n\nfrom sklearn import neighbors  \nfrom data_util import DataUtils\nimport datetime  \n\n\ndef main():\n    trainfile_X = '../dataset/MNIST/train-images.idx3-ubyte'\n    trainfile_y = '../dataset/MNIST/train-labels.idx1-ubyte'\n    testfile_X = '../dataset/MNIST/t10k-images.idx3-ubyte'\n    testfile_y = '../dataset/MNIST/t10k-labels.idx1-ubyte'\n    train_X = DataUtils(filename=trainfile_X).getImage()\n    train_y = DataUtils(filename=trainfile_y).getLabel()\n    test_X = DataUtils(testfile_X).getImage()\n    test_y = DataUtils(testfile_y).getLabel()\n\n    return train_X, train_y, test_X, test_y \n\n\ndef testKNN():\n    train_X, train_y, test_X, test_y = main()\n    startTime = datetime.datetime.now()\n    knn = neighbors.KNeighborsClassifier(n_neighbors=3)  \n    knn.fit(train_X, train_y)  \n    match = 0;  \n    for i in xrange(len(test_y)):  \n        predictLabel = knn.predict(test_X[i])[0]  \n        if(predictLabel==test_y[i]):  \n            match += 1  \n      \n    endTime = datetime.datetime.now()  \n    print 'use time: '+str(endTime-startTime)  \n    print 'error rate: '+ str(1-(match*1.0/len(test_y)))  \n\nif __name__ == \"__main__\":\n    testKNN()\n```\n\n通过main方法，最后直接返回numpy.array()格式的数据：train_X, train_y, test_X, test_y。如果你需要，直接条用main方法即可！\n\n---\n\n","source":"_posts/2016-02-25-machine-learning-MNIST-dataset.md","raw":"---\nlayout: post\ndate: 2016-02-25 17:24\ntitle: \"机器学习数据集-MNIST\"\ncategories: ML\ntag: \n\t- MNIST\n\t- dataset\n\t- Python\ncomment: true\n---\n\n## 介绍\n\n在学习机器学习的时候，首当其冲的就是准备一份通用的数据集，方便与其他的算法进行比较。在这里，我写了一个用于加载MNIST数据集的方法，并将其进行封装，主要用于将MNIST数据集转换成numpy.array()格式的训练数据。直接下面看下面的代码吧(主要还是如何用python去读取binnary file)！\n\n<!-- more -->\n\nMNIST数据集原网址：[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)\n\nGithub源码下载：[数据集（源文件+解压文件+字体图像jpg格式）](https://github.com/csuldw/MachineLearning/tree/master/dataset/MNIST)， [py源码文件](https://github.com/csuldw/MachineLearning/tree/master/utils/)\n\n## 文件目录\n\n- [/utils/data_util.py](https://github.com/csuldw/MachineLearning/tree/master/utils/data_util.py) 用于加载MNIST数据集方法文件\n- [/utils/test.py](https://github.com/csuldw/MachineLearning/tree/master/utils/test.py) 用于测试的文件，一个简单的KNN测试MNIST数据集\n- [/data/train-images.idx3-ubyte](https://github.com/csuldw/MachineLearning/tree/master/dataset/MNIST) 训练集X\n- [/dataset/train-labels.idx1-ubyte](https://github.com/csuldw/MachineLearning/tree/master/dataset/MNIST) 训练集y\n- [/dataset/data/t10k-images.idx3-ubyte](https://github.com/csuldw/MachineLearning/tree/master/dataset/MNIST) 测试集X\n- [/dataset/data/t10k-labels.idx1-ubyte](https://github.com/csuldw/MachineLearning/tree/master/dataset/MNIST) 测试集y\n\n\n## MNIST数据集解释\n\n将MNIST文件解压后，发现这些文件并不是标准的图像格式。这些图像数据都保存在二进制文件中。每个样本图像的宽高为28*28。\n\nmnist的结构如下，选取train-images\n\n    TRAINING SET IMAGE FILE (train-images-idx3-ubyte):\n\n    [offset] [type]          [value]          [description] \n    0000     32 bit integer  0x00000803(2051) magic number \n    0004     32 bit integer  60000            number of images \n    0008     32 bit integer  28               number of rows \n    0012     32 bit integer  28               number of columns \n    0016     unsigned byte   ??               pixel \n    0017     unsigned byte   ??               pixel \n    ........ \n    xxxx     unsigned byte   ??               pixel\n\n\n首先该数据是以二进制存储的，我们读取的时候要以'rb'方式读取；其次，真正的数据只有[value]这一项，其他的[type]等只是来描述的，并不真正在数据文件里面。也就是说，在读取真实数据之前，我们要读取4个`32 bit integer`.由[offset]我们可以看出真正的pixel是从0016开始的，一个int 32位，所以在读取pixel之前我们要读取4个 32 bit integer，也就是magic number, number of images, number of rows, number of columns. 当然，在这里使用struct.unpack_from()会比较方便.\n\n\n## 源码\n\n说明：\n\n- '>IIII'指的是使用大端法读取4个unsinged int 32 bit integer\n- '>784B'指的是使用大端法读取784个unsigned byte\n\n\ndata_util.py文件\n\n```\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Thu Feb 25 14:40:06 2016\nload MNIST dataset\n@author: liudiwei\n\"\"\"\nimport numpy as np \nimport struct\nimport matplotlib.pyplot as plt \nimport os\n\nclass DataUtils(object):\n    \"\"\"MNIST数据集加载\n    输出格式为：numpy.array()    \n    \n    使用方法如下\n    from data_util import DataUtils\n    def main():\n        trainfile_X = '../dataset/MNIST/train-images.idx3-ubyte'\n        trainfile_y = '../dataset/MNIST/train-labels.idx1-ubyte'\n        testfile_X = '../dataset/MNIST/t10k-images.idx3-ubyte'\n        testfile_y = '../dataset/MNIST/t10k-labels.idx1-ubyte'\n        \n        train_X = DataUtils(filename=trainfile_X).getImage()\n        train_y = DataUtils(filename=trainfile_y).getLabel()\n        test_X = DataUtils(testfile_X).getImage()\n        test_y = DataUtils(testfile_y).getLabel()\n        \n        #以下内容是将图像保存到本地文件中\n        #path_trainset = \"../dataset/MNIST/imgs_train\"\n        #path_testset = \"../dataset/MNIST/imgs_test\"\n        #if not os.path.exists(path_trainset):\n        #    os.mkdir(path_trainset)\n        #if not os.path.exists(path_testset):\n        #    os.mkdir(path_testset)\n        #DataUtils(outpath=path_trainset).outImg(train_X, train_y)\n        #DataUtils(outpath=path_testset).outImg(test_X, test_y)\n    \n        return train_X, train_y, test_X, test_y \n    \"\"\"\n\n\n    def __init__(self, filename=None, outpath=None):\n        self._filename = filename\n        self._outpath = outpath\n        \n        self._tag = '>'\n        self._twoBytes = 'II'\n        self._fourBytes = 'IIII'    \n        self._pictureBytes = '784B'\n        self._labelByte = '1B'\n        self._twoBytes2 = self._tag + self._twoBytes\n        self._fourBytes2 = self._tag + self._fourBytes\n        self._pictureBytes2 = self._tag + self._pictureBytes\n        self._labelByte2 = self._tag + self._labelByte\n    \n    def getImage(self):\n        \"\"\"\n        将MNIST的二进制文件转换成像素特征数据\n        \"\"\"\n        binfile = open(self._filename, 'rb') #以二进制方式打开文件\n        buf = binfile.read() \n        binfile.close()\n        index = 0\n        numMagic,numImgs,numRows,numCols=struct.unpack_from(self._fourBytes2,\\\n                                                                    buf,\\\n                                                                    index)\n        index += struct.calcsize(self._fourBytes)\n        images = []\n        for i in range(numImgs):\n            imgVal = struct.unpack_from(self._pictureBytes2, buf, index)\n            index += struct.calcsize(self._pictureBytes2)\n            imgVal = list(imgVal)\n            for j in range(len(imgVal)):\n                if imgVal[j] > 1:\n                    imgVal[j] = 1\n            images.append(imgVal)\n        return np.array(images)\n        \n    def getLabel(self):\n        \"\"\"\n        将MNIST中label二进制文件转换成对应的label数字特征\n        \"\"\"\n        binFile = open(self._filename,'rb')\n        buf = binFile.read()\n        binFile.close()\n        index = 0\n        magic, numItems= struct.unpack_from(self._twoBytes2, buf,index)\n        index += struct.calcsize(self._twoBytes2)\n        labels = [];\n        for x in range(numItems):\n            im = struct.unpack_from(self._labelByte2,buf,index)\n            index += struct.calcsize(self._labelByte2)\n            labels.append(im[0])\n        return np.array(labels)\n\n    def outImg(self, arrX, arrY):\n        \"\"\"\n        根据生成的特征和数字标号，输出png的图像\n        \"\"\"\n        m, n = np.shape(arrX)\n        #每张图是28*28=784Byte\n        for i in range(1):\n            img = np.array(arrX[i])\n            img = img.reshape(28,28)\n            outfile = str(i) + \"_\" +  str(arrY[i]) + \".png\"\n            plt.figure()\n            plt.imshow(img, cmap = 'binary') #将图像黑白显示\n            plt.savefig(self._outpath + \"/\" + outfile)\n```\n\n\ntest.py文件:简单地测试了一下KNN算法，代码如下\n\n```\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Thu Feb 25 16:09:58 2016\nTest MNIST dataset \n@author: liudiwei\n\"\"\"\n\nfrom sklearn import neighbors  \nfrom data_util import DataUtils\nimport datetime  \n\n\ndef main():\n    trainfile_X = '../dataset/MNIST/train-images.idx3-ubyte'\n    trainfile_y = '../dataset/MNIST/train-labels.idx1-ubyte'\n    testfile_X = '../dataset/MNIST/t10k-images.idx3-ubyte'\n    testfile_y = '../dataset/MNIST/t10k-labels.idx1-ubyte'\n    train_X = DataUtils(filename=trainfile_X).getImage()\n    train_y = DataUtils(filename=trainfile_y).getLabel()\n    test_X = DataUtils(testfile_X).getImage()\n    test_y = DataUtils(testfile_y).getLabel()\n\n    return train_X, train_y, test_X, test_y \n\n\ndef testKNN():\n    train_X, train_y, test_X, test_y = main()\n    startTime = datetime.datetime.now()\n    knn = neighbors.KNeighborsClassifier(n_neighbors=3)  \n    knn.fit(train_X, train_y)  \n    match = 0;  \n    for i in xrange(len(test_y)):  \n        predictLabel = knn.predict(test_X[i])[0]  \n        if(predictLabel==test_y[i]):  \n            match += 1  \n      \n    endTime = datetime.datetime.now()  \n    print 'use time: '+str(endTime-startTime)  \n    print 'error rate: '+ str(1-(match*1.0/len(test_y)))  \n\nif __name__ == \"__main__\":\n    testKNN()\n```\n\n通过main方法，最后直接返回numpy.array()格式的数据：train_X, train_y, test_X, test_y。如果你需要，直接条用main方法即可！\n\n---\n\n","slug":"2016-02-25-machine-learning-MNIST-dataset","published":1,"updated":"2016-03-08T09:03:30.616Z","comments":1,"photos":[],"link":"","_id":"cimigpyuo003f6cuju3oxlk3l"},{"layout":"post","date":"2016-02-23T12:37:00.000Z","title":"Python编码规范","comment":true,"_content":"\n接触Python已将近两年了，写过的代码也不少，每次对代码的编写都没有统一的规范，所以，根据自己以往的经验，专门为自己定制了一份用于编写Python代码时使用的代码规范。\n\n<!-- more -->\n\n## 常量\n\n常量名所有字母大写，由下划线连接各个单词，如：\n\n```\nUSER_CONSTANT\n```\n\n## 变量 \n\n变量名全部小写，由下划线连接各个单词，如：\n\n```\ncolor = WHITE\nthis_is_a_variable = 1\n```\n\n## 函数和方法\n\n- 私有方法：小写和一个前导下划线\n\n```python\ndef _secrete(self):\n    print \"don't test me.\"\n```\n\n- 函数参数：小写和下划线，缺省值等号两边无空格\n\n\n```python\ndef connect(self, user=None):\n    self._user = user\n```\n\n\n## 类\n\n- 类总是使用驼峰格式命名，不使用下划线连接单词，也不加入 C、T 等前缀，即所有单词首字母大写其余字母小写。类名应该简明，精确，并足以从中理解类所完成的工作。常见的一个方法是使用表示其类型或者特性的后缀，例如:\n\n```python\nclass SQLEngine(object):\n    pass\n```\n\n- 对于基类而言，可以使用一个 Base 或者 Abstract 前缀\n\n```python\nclass BaseCookie(object):\n    pass\nclass AbstractGroup(object):\n    psss\n```\n\n## 特定命名方式\n主要是指 \\_\\_xxx__ 形式的系统保留字命名法。项目中也可以使用这种命名，它的意义在于这种形式的变量是只读的，这种形式的类成员函数尽量不要重载。如\n\n\n```python\nclass Base(object):\n    def __init__(self, id, parent = None):\n        self.__id__ = id\n        self.__parent__ = parent\n    def __message__(self, msgid):\n        # ...略\n```\n\n其中 `_id`、`parent_` 和 `_message_ `都采用了系统保留字命名法。\n\n## 空格\n\n1. 在二元算术、逻辑运算符前后加空格：如 `a = b + c`；\n- 在一元前缀运算符后不加空格，如 `if !flg: pass`；\n- \":\"用在行尾时前后皆不加空格，如分支、循环、函数和类定义语言；用在非行尾时后端加空格，如 `dict` 对象的定义 `d = {'key': 'value'}`;\n- 括号（含圆括号、方括号和花括号）前后不加空格，如 `do_something(arg1, arg2)`, 而不是 `do_something( arg1, arg2 )`；\n- 逗号后面加一个空格，前面不加空格。\n\n## 空行\n\n1. 在类、函数的定义间加空行；\n- 在import不同种类的模块间加空行；\n- 在函数中的逻辑段落间加空行，即把相关的代码紧凑写在一起，作为一个逻辑段落，段落间以空行分隔。\n\n## 断行\n\n（1）行的最大长度不得超过 80 个字符的标准。折叠长行的方法有以下几种方法：\n1）为长变量名换一个短名，如：\n\n```\nthis.is.a.very.long.variable_name = this.is.another.long.variable_name\n```\n\n应改为：\n\n```python\nvariable_name1 = this.is.a.very.long.variable_name\nvariable_name2 = this.is.another.variable_name\nvariable_name1 = variable_name2\n```\n\n（2）在括号（包括圆括号、方括号和花括号）内换行，如：\n\n```python\nclass Edit(CBase):\n    def __init__(self, parent, width,\n                font = FONT, color = BLACK, pos = POS, style = 0):\n```\n\n或：\n\n```python\nvery_very_very_long_variable_name = Edit(parent, \\\n                                         width, \\\n                                         font, \\\n                                         color, \\\n                                         pos)\n```\n\n（3）在长行加入续行符强行断行，断行的位置应在操作符前，且换行后多一个缩进，以使维护人员看代码的时候看到代码行首即可判定这里存在换行，如：\n\n```python\nif color == WHITE or color == BLACK \\\n              or color == BLUE:\n    do_something(color);\n```\n\n\n\n## 语句\n\n- import\n\nimport 语句有以下几个原则需要遵守：\n\n（1）import 的次序，先`import Python`内置模块，再import第三方模块，最后import自己开发的项目中的其它模块；这几种模块中用空行分隔开来。\n\n（2）一条import语句import一个模块。\n\n（3）当从模块中 import 多个对象且超过一行时，使用如下断行法（此语法 py2.5 以上版本才支持）：\n\n```python\nfrom module import (obj1, obj2, obj3, obj4,\nobj5, obj6)\n```\n4）不要使用 `from module import *`，除非是 `import `常量定义模块或其它你确保不会出现命名空间冲突的模块。\n\n\n## 赋值\n\n对于赋值语言，等号前后空一格，格式如下：\n\n```python\na = 1\nvariable = 2\nfn = callback_function\n```\n\n## 分支和循环\n\n不要写成一行，如：\n\n```python\nif !flg: pass\nfor i in xrange(10): print i\n```\n\n应该写成：\n\n```python\nif !flg:\n    pass\nfor i in xrange(10):\n    print i\n```\n## 其他\n\n- 使用 has 或 is 前缀命名布尔元素\n\n```python\nis_connect = True\nhas_member = False\n```\n- 用复数形式命名序列\n\n```python\nmembers = ['user_1', 'user_2']\n```\n- 用显式名称命名字典\n\n```python\nperson_address = {'user_1':'10 road WD', 'user_2' : '20 street huafu'}\n```\n\n- 避免通用名称\n\n\t- 诸如 list, dict, sequence 或者 element 这样的名称应该避免。\n\n* 一些数字\n\n\t- 一行列数 : PEP 8 规定为 79 列，这有些苛刻了。根据自己的情况，比如不要超过满屏时编辑器的显示列数。这样就可以在不动水平游标的情况下，方便的查看代码。\n\t- 一个函数 : 不要超过 30 行代码, 即可显示在一个屏幕类，可以不使用垂直游标即可看到整个函数。\n\t- 一个类 : 不要超过 200 行代码，不要有超过 10 个方法。\n\t- 一个模块 不要超过 500 行。\n\n## Contributor\n\n- Liu Diwei: https://github.com/csuldw\n","source":"_posts/2016-02-23-Python-coding-standards.md","raw":"---\nlayout: post\ndate: 2016-02-23 20:37\ntitle: \"Python编码规范\"\ncategories: Python\ntag: \n\t- Python\n\t- 编码规范\ncomment: true\n---\n\n接触Python已将近两年了，写过的代码也不少，每次对代码的编写都没有统一的规范，所以，根据自己以往的经验，专门为自己定制了一份用于编写Python代码时使用的代码规范。\n\n<!-- more -->\n\n## 常量\n\n常量名所有字母大写，由下划线连接各个单词，如：\n\n```\nUSER_CONSTANT\n```\n\n## 变量 \n\n变量名全部小写，由下划线连接各个单词，如：\n\n```\ncolor = WHITE\nthis_is_a_variable = 1\n```\n\n## 函数和方法\n\n- 私有方法：小写和一个前导下划线\n\n```python\ndef _secrete(self):\n    print \"don't test me.\"\n```\n\n- 函数参数：小写和下划线，缺省值等号两边无空格\n\n\n```python\ndef connect(self, user=None):\n    self._user = user\n```\n\n\n## 类\n\n- 类总是使用驼峰格式命名，不使用下划线连接单词，也不加入 C、T 等前缀，即所有单词首字母大写其余字母小写。类名应该简明，精确，并足以从中理解类所完成的工作。常见的一个方法是使用表示其类型或者特性的后缀，例如:\n\n```python\nclass SQLEngine(object):\n    pass\n```\n\n- 对于基类而言，可以使用一个 Base 或者 Abstract 前缀\n\n```python\nclass BaseCookie(object):\n    pass\nclass AbstractGroup(object):\n    psss\n```\n\n## 特定命名方式\n主要是指 \\_\\_xxx__ 形式的系统保留字命名法。项目中也可以使用这种命名，它的意义在于这种形式的变量是只读的，这种形式的类成员函数尽量不要重载。如\n\n\n```python\nclass Base(object):\n    def __init__(self, id, parent = None):\n        self.__id__ = id\n        self.__parent__ = parent\n    def __message__(self, msgid):\n        # ...略\n```\n\n其中 `_id`、`parent_` 和 `_message_ `都采用了系统保留字命名法。\n\n## 空格\n\n1. 在二元算术、逻辑运算符前后加空格：如 `a = b + c`；\n- 在一元前缀运算符后不加空格，如 `if !flg: pass`；\n- \":\"用在行尾时前后皆不加空格，如分支、循环、函数和类定义语言；用在非行尾时后端加空格，如 `dict` 对象的定义 `d = {'key': 'value'}`;\n- 括号（含圆括号、方括号和花括号）前后不加空格，如 `do_something(arg1, arg2)`, 而不是 `do_something( arg1, arg2 )`；\n- 逗号后面加一个空格，前面不加空格。\n\n## 空行\n\n1. 在类、函数的定义间加空行；\n- 在import不同种类的模块间加空行；\n- 在函数中的逻辑段落间加空行，即把相关的代码紧凑写在一起，作为一个逻辑段落，段落间以空行分隔。\n\n## 断行\n\n（1）行的最大长度不得超过 80 个字符的标准。折叠长行的方法有以下几种方法：\n1）为长变量名换一个短名，如：\n\n```\nthis.is.a.very.long.variable_name = this.is.another.long.variable_name\n```\n\n应改为：\n\n```python\nvariable_name1 = this.is.a.very.long.variable_name\nvariable_name2 = this.is.another.variable_name\nvariable_name1 = variable_name2\n```\n\n（2）在括号（包括圆括号、方括号和花括号）内换行，如：\n\n```python\nclass Edit(CBase):\n    def __init__(self, parent, width,\n                font = FONT, color = BLACK, pos = POS, style = 0):\n```\n\n或：\n\n```python\nvery_very_very_long_variable_name = Edit(parent, \\\n                                         width, \\\n                                         font, \\\n                                         color, \\\n                                         pos)\n```\n\n（3）在长行加入续行符强行断行，断行的位置应在操作符前，且换行后多一个缩进，以使维护人员看代码的时候看到代码行首即可判定这里存在换行，如：\n\n```python\nif color == WHITE or color == BLACK \\\n              or color == BLUE:\n    do_something(color);\n```\n\n\n\n## 语句\n\n- import\n\nimport 语句有以下几个原则需要遵守：\n\n（1）import 的次序，先`import Python`内置模块，再import第三方模块，最后import自己开发的项目中的其它模块；这几种模块中用空行分隔开来。\n\n（2）一条import语句import一个模块。\n\n（3）当从模块中 import 多个对象且超过一行时，使用如下断行法（此语法 py2.5 以上版本才支持）：\n\n```python\nfrom module import (obj1, obj2, obj3, obj4,\nobj5, obj6)\n```\n4）不要使用 `from module import *`，除非是 `import `常量定义模块或其它你确保不会出现命名空间冲突的模块。\n\n\n## 赋值\n\n对于赋值语言，等号前后空一格，格式如下：\n\n```python\na = 1\nvariable = 2\nfn = callback_function\n```\n\n## 分支和循环\n\n不要写成一行，如：\n\n```python\nif !flg: pass\nfor i in xrange(10): print i\n```\n\n应该写成：\n\n```python\nif !flg:\n    pass\nfor i in xrange(10):\n    print i\n```\n## 其他\n\n- 使用 has 或 is 前缀命名布尔元素\n\n```python\nis_connect = True\nhas_member = False\n```\n- 用复数形式命名序列\n\n```python\nmembers = ['user_1', 'user_2']\n```\n- 用显式名称命名字典\n\n```python\nperson_address = {'user_1':'10 road WD', 'user_2' : '20 street huafu'}\n```\n\n- 避免通用名称\n\n\t- 诸如 list, dict, sequence 或者 element 这样的名称应该避免。\n\n* 一些数字\n\n\t- 一行列数 : PEP 8 规定为 79 列，这有些苛刻了。根据自己的情况，比如不要超过满屏时编辑器的显示列数。这样就可以在不动水平游标的情况下，方便的查看代码。\n\t- 一个函数 : 不要超过 30 行代码, 即可显示在一个屏幕类，可以不使用垂直游标即可看到整个函数。\n\t- 一个类 : 不要超过 200 行代码，不要有超过 10 个方法。\n\t- 一个模块 不要超过 500 行。\n\n## Contributor\n\n- Liu Diwei: https://github.com/csuldw\n","slug":"2016-02-23-Python-coding-standards","published":1,"updated":"2016-06-09T02:34:06.571Z","_id":"cimigpyuw003n6cuj1vethrc5","comments":1,"photos":[],"link":""},{"layout":"post","date":"2016-01-22T02:24:00.000Z","title":"Python笔记-shape、extend、append、tile、numpy.sum","comment":true,"_content":"\n本文主要记录在学习过程中碰到的易混淆的Python语法。\n\n### shape函数\npython中的shape有两个，一个是numpy中的shape，一个是array的shape，本质上是一样的。\n\n<!-- more -->\n\n\n\n```\nimport numpy as np\ny=[1,2,3,1,2,2,1,2,1,2]  # list\ny_arr = array(y)         #array\ny_mat = np.mat(y_arr)  #matrix\ny_arr.shape[0]   #output:10L\ny_mat.shape[0]   #output:1L\ny_mat.shape[1]   #output:10L\nnp.shape(y_arr)  #output :(1L, 10L)\n```\n\n### extend和append\n\n对于python中的list，假设有a=[1,2,3], b=[4,5,4]，如果使用a.append(b),结果为：\n\n\t[1,2,3,[4,5,4]]\n\n如果使用a.extend(b),结果为：\n\n\t[1,2,3,4,5,4]\n\n\n### numpy中的tile函数\n\n看下面几个列子就懂了\n\n```\nimport numpy as np\nx = np.array([1,2,3])\nx1 = np.tile(x,1)   # array([1,2,3])\nx2 = np.tile(x,2)   # array([1,2,3,1,2,3])\nx3 = np.tile(x,(1,2))   # array([1,2,3,1,2,3])\nx4 = np.tile(x,(2,2))   # array([1,2,3,1,2,3],[1,2,3,1,2,3])\nx5 = np.tile(x,(2,1))   # array([1,2,3],[1,2,3])\n```\n\n其实就相当于在tile的第二个参数中指定维数，将第一个变量的值整块填写到里面即可。\n\n### numpy中的sum函数axis=1\n\n对于sum看起来挺简单的样子，但是在给sum函数中加入参数。`sum(a, axis=0)`或者是`.sum(axis=1) `就有点不解了。在我实验以后发现,我们平时用的`sum`应该是默认的`axis=0`就是普通的相加。当加入`axis=1`以后就是将一个矩阵的每一行向量相加：\n\n例如：\n\n```\nimport numpy as np\nx = np.array([[0,1,2],[2,1,3]])\nnp.sum(x, axis=1)\n```\n\n返回的结果就是：array（[3,6]）\n\n`np.sum(x, axis=1)`等价于`x.sum(axis=1)`，注意：python中list没有sum属性【'list' object has no attribute 'sum'】。\n\n\n如果使用的是`x.sum(axis=0)`，则返回的结果是：array([2, 2, 5])\n\n它是对x的每一进行列求和运算。\n\n\n### dict中的get()方法\n\nget()方法返回给定键的值。如果键不可用，则返回默认值None。\n\n语法\n以下是get()方法的语法：\n\n```\ndict.get(key, default=None)\n```\n\n参数:\n\n- key: 这是要搜索在字典中的键。\n- default: 这是要返回键不存在的的情况下默认值。\n- 返回值: 该方法返回一个给定键的值。如果键不可用，则返回默认值为None。\n\n\n### operator的itemgetter()\n\noperator模块提供的itemgetter函数用于获取对象的哪些维的数据，参数为一些序号（即需要获取的数据在对象中的序号）.\n\n例如：\n\n```\na = [1,2,3] \nb=operator.itemgetter(1)\nb(a)   #输出2\n```\n要注意，operator.itemgetter函数获取的不是值，而是定义了一个函数，通过该函数作用到对象上才能获取值。\n\nPython内置的排序函数sorted可以对list或者iterator进行排序\n\nsorted(iterable[, cmp[, key[, reverse]]])\n\n第一个参数是一个iterable，返回值是一个对iterable中元素进行排序后的列表(list)。\n\n可选的参数有三个，cmp、key和reverse。\n1)cmp指定一个定制的比较函数，这个函数接收两个参数（iterable的元素），如果第一个参数小于第二个参数，返回一个负数；如果第一个参数等于第二个参数，返回零；如果第一个参数大于第二个参数，返回一个正数。默认值为None。\n2)key指定一个接收一个参数的函数，这个函数用于从每个元素中提取一个用于比较的关键字。默认值为None。\n3)reverse是一个布尔值。如果设置为True，列表元素将被倒序排列。\n通常来说，key和reverse比一个等价的cmp函数处理速度要快。这是因为对于每个列表元素，cmp都会被调用多次，而key和reverse只被调用一次。\n\n\n比如下面一个例子：\n\n```\nb = {0:1, 1:5}\nsorted(b.iteritems(), key=operator.itemgetter(1), reverse=True)   #表示按照第二维进行降序\n```\n\n输出：[(1, 5), (0, 1)]\n\n\n### 步进切片\n\n使用步进切片可以轻松实现sequence（list, tuple, string）反转\n\n```\n>>>name = 'AlphaGO'\n>>>name[::-1]\nOut[121]: 'OGahplA'\n\n>>>name = [\"A\", \"is\",  \"C\"]\n>>>name[::-1]\nOut[125]: ['C', 'is', 'A']\n```\n","source":"_posts/2016-01-21-Python-notes.md","raw":"---\nlayout: post\ndate: 2016-01-22 10:24\ntitle: \"Python笔记-shape、extend、append、tile、numpy.sum\"\ncategories: Python\ntag: \n\t- Python\ncomment: true\n---\n\n本文主要记录在学习过程中碰到的易混淆的Python语法。\n\n### shape函数\npython中的shape有两个，一个是numpy中的shape，一个是array的shape，本质上是一样的。\n\n<!-- more -->\n\n\n\n```\nimport numpy as np\ny=[1,2,3,1,2,2,1,2,1,2]  # list\ny_arr = array(y)         #array\ny_mat = np.mat(y_arr)  #matrix\ny_arr.shape[0]   #output:10L\ny_mat.shape[0]   #output:1L\ny_mat.shape[1]   #output:10L\nnp.shape(y_arr)  #output :(1L, 10L)\n```\n\n### extend和append\n\n对于python中的list，假设有a=[1,2,3], b=[4,5,4]，如果使用a.append(b),结果为：\n\n\t[1,2,3,[4,5,4]]\n\n如果使用a.extend(b),结果为：\n\n\t[1,2,3,4,5,4]\n\n\n### numpy中的tile函数\n\n看下面几个列子就懂了\n\n```\nimport numpy as np\nx = np.array([1,2,3])\nx1 = np.tile(x,1)   # array([1,2,3])\nx2 = np.tile(x,2)   # array([1,2,3,1,2,3])\nx3 = np.tile(x,(1,2))   # array([1,2,3,1,2,3])\nx4 = np.tile(x,(2,2))   # array([1,2,3,1,2,3],[1,2,3,1,2,3])\nx5 = np.tile(x,(2,1))   # array([1,2,3],[1,2,3])\n```\n\n其实就相当于在tile的第二个参数中指定维数，将第一个变量的值整块填写到里面即可。\n\n### numpy中的sum函数axis=1\n\n对于sum看起来挺简单的样子，但是在给sum函数中加入参数。`sum(a, axis=0)`或者是`.sum(axis=1) `就有点不解了。在我实验以后发现,我们平时用的`sum`应该是默认的`axis=0`就是普通的相加。当加入`axis=1`以后就是将一个矩阵的每一行向量相加：\n\n例如：\n\n```\nimport numpy as np\nx = np.array([[0,1,2],[2,1,3]])\nnp.sum(x, axis=1)\n```\n\n返回的结果就是：array（[3,6]）\n\n`np.sum(x, axis=1)`等价于`x.sum(axis=1)`，注意：python中list没有sum属性【'list' object has no attribute 'sum'】。\n\n\n如果使用的是`x.sum(axis=0)`，则返回的结果是：array([2, 2, 5])\n\n它是对x的每一进行列求和运算。\n\n\n### dict中的get()方法\n\nget()方法返回给定键的值。如果键不可用，则返回默认值None。\n\n语法\n以下是get()方法的语法：\n\n```\ndict.get(key, default=None)\n```\n\n参数:\n\n- key: 这是要搜索在字典中的键。\n- default: 这是要返回键不存在的的情况下默认值。\n- 返回值: 该方法返回一个给定键的值。如果键不可用，则返回默认值为None。\n\n\n### operator的itemgetter()\n\noperator模块提供的itemgetter函数用于获取对象的哪些维的数据，参数为一些序号（即需要获取的数据在对象中的序号）.\n\n例如：\n\n```\na = [1,2,3] \nb=operator.itemgetter(1)\nb(a)   #输出2\n```\n要注意，operator.itemgetter函数获取的不是值，而是定义了一个函数，通过该函数作用到对象上才能获取值。\n\nPython内置的排序函数sorted可以对list或者iterator进行排序\n\nsorted(iterable[, cmp[, key[, reverse]]])\n\n第一个参数是一个iterable，返回值是一个对iterable中元素进行排序后的列表(list)。\n\n可选的参数有三个，cmp、key和reverse。\n1)cmp指定一个定制的比较函数，这个函数接收两个参数（iterable的元素），如果第一个参数小于第二个参数，返回一个负数；如果第一个参数等于第二个参数，返回零；如果第一个参数大于第二个参数，返回一个正数。默认值为None。\n2)key指定一个接收一个参数的函数，这个函数用于从每个元素中提取一个用于比较的关键字。默认值为None。\n3)reverse是一个布尔值。如果设置为True，列表元素将被倒序排列。\n通常来说，key和reverse比一个等价的cmp函数处理速度要快。这是因为对于每个列表元素，cmp都会被调用多次，而key和reverse只被调用一次。\n\n\n比如下面一个例子：\n\n```\nb = {0:1, 1:5}\nsorted(b.iteritems(), key=operator.itemgetter(1), reverse=True)   #表示按照第二维进行降序\n```\n\n输出：[(1, 5), (0, 1)]\n\n\n### 步进切片\n\n使用步进切片可以轻松实现sequence（list, tuple, string）反转\n\n```\n>>>name = 'AlphaGO'\n>>>name[::-1]\nOut[121]: 'OGahplA'\n\n>>>name = [\"A\", \"is\",  \"C\"]\n>>>name[::-1]\nOut[125]: ['C', 'is', 'A']\n```\n","slug":"2016-01-21-Python-notes","published":1,"updated":"2016-06-09T02:35:47.500Z","_id":"cimigpyv1003t6cuj2dkipeh8","comments":1,"photos":[],"link":""},{"layout":"post","date":"2016-01-12T02:24:00.000Z","title":"机器学习-牛顿方法&指数分布族&GLM","comment":true,"_content":"\n\n<font color=\"green\">回头再温习一下Andrew Ng的机器学习视频课，顺便把没写完的笔记写完。</font>\n\n本节内容\n\n- 牛顿方法\n- 指数分布族\n- 广义线性模型\n\n<!-- more -->\n\n之前学习了梯度下降方法，关于梯度下降（gradient descent），这里简单的回顾下【参考感知机学习部分提到的梯度下降([gradient descent](http://blog.csdn.net/dream_angel_z/article/details/48915561))】。在最小化损失函数时，采用的就是梯度下降的方法逐步逼近最优解，规则为$\\theta := \\theta - \\eta \\nabla_{\\theta} \\ell(\\theta)$。其实梯度下降属于一种优化方法，但梯度下降找到的是局部最优解。如下图：\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20151006094200515)\n</center>\n\n\n本节首先讲解的是牛顿方法（NewTon's Method）。牛顿方法也是一种优化方法，它考虑的是**全局最优**。接着还会讲到指数分布族和广义线性模型。下面来详细介绍。\n\n## **1.牛顿方法**\n\n现在介绍另一种最小化损失函数$\\ell(\\theta)$的方法——牛顿方法,参考[Approximations Of Roots Of Functions – Newton's Method](http://www.phengkimving.com/calc_of_one_real_var/08_app_of_the_der_part_2/08_05_approx_of_roots_of_func_newtons_meth.htm)\n。它与梯度下降不同，其基本思想如下：\n\n假设一个函数$f(x) = 0$,我们需要求解此时的$x$值。如下图所示：\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20151006095845371)\n图1 $f(x0) = 0, a1, a2, a3, ... 逐步接近 x0$.\n</center>\n\n在\n$a_1$点的时候，$f(x)$切线的目标函数$y = f(a_1) + f '(a_1)(x – a_1)$. 由于$(a_2,0)$在这条线上，所以我们有$ 0 = f(a_1) + f '(a_1)(a_2 – a_1)$,so:\n\n$$a_2 = a_1-\\frac{f(a_1)}{f'(a_1)}$$\n\n同理，在$a_2$点的时候，切线的目标函数$y = f(a_2) + f '(a_2)(x – a_2)$. 由于$(a_3,0)$在这条线上，所以我们有$ 0 = f(a_2) + f '(a_2)(a_3– a_2)$,so:\n\n$$a_3 = a_2-\\frac{f(a_2)}{f'(a_2)}$$\n\n假设在第$n$次迭代，有$f(a_n)=0$,那么此时有下面这个递推公式：\n\n![](http://latex.codecogs.com/gif.latex?%24%24a_n%20%3D%20a_%7Bn-1%7D-%5Cfrac%7Bf%28a_%7Bn-1%7D%29%7D%7Bf%27%28a_%7Bn-1%7D%29%7D%24%24)\n\n其中$n>=2$.\n\n最后得到的公式也就是牛顿方法的学习规则，为了和梯度下降对比，我们来替换一下变量，公式如下：\n\n$$\\theta := \\theta - \\frac{f(\\theta)}{f'(\\theta)}$$\n\n\n<font color=\"green\">**那么问题来了，怎么将牛顿方法应用到我们的问题上，最小化损失函数$\\ell(\\theta)$(或者是求极大似然估计的极大值)呢？**\n</font>\n\n  对于机器学习问题，现在我们优化的目标函数为极大似然估计$\\ell$，当极大似然估计函数取值最大时，其导数为 0，这样就和上面函数f取 0 的问题一致了，令$f(\\theta) = \\ell'(\\theta)$。极大似然函数的求解更新规则是：\n  \n$$\\theta := \\theta - \\frac{\\ell'(\\theta)}{\\ell''(\\theta)}$$\n\n对于$\\ell$，当一阶导数为零时，有极值；此时，如果二阶导数大于零，则$\\ell$有极小值，如果二阶导数小于零，则有极大值。\n\n上面的式子是当参数$\\theta$为实数时的情况，下面我们要求出一般式。当参数为向量时，更新规则变为如下公式：\n\n$$\\theta := \\theta - H^{-1} \\nabla_{\\theta}\\ell(\\theta)$$\n\n其中$\\nabla$后半部分$和之前梯度下降中提到的一样，是梯度，$H$是一个$n*n$的矩阵，$H $是函数的二次导数矩阵，被成为$Hessian$矩阵。其某个元素$ H_{ij}$ 计算公式如下：\n\n![$$H_{ij}=\\dfrac{\\partial^{2}\\ell(\\theta)}{\\partial\\theta_{i}\\theta_{j}}$$](http://latex.codecogs.com/gif.latex?%24%24H_%7Bij%7D%3D%5Cdfrac%7B%5Cpartial%5E%7B2%7D%5Cell%28%5Ctheta%29%7D%7B%5Cpartial%5Ctheta_%7Bi%7D%5Ctheta_%7Bj%7D%7D%24%24)\n\n<font color=\"red\">**和梯度下降相比，牛顿方法的收敛速度更快，通常只要十几次或者更少就可以收敛，牛顿方法也被称为二次收敛（quadratic convergence），因为当迭代到距离收敛值比较近的时候，每次迭代都能使误差变为原来的平方。缺点是当参数向量较大的时候，每次迭代都需要计算一次 Hessian 矩阵的逆，比较耗时。**\n</font>\n\n## **2.指数分布族（The exponential family）**\n\n\n指数分布族是指可以表示为指数形式的概率分布。指数分布的形式如下：\n\n$$P(y;\\eta)=b(y)exp(\\eta^{T}T(y)-a(\\eta))$$\n\n其中，η成为分布的**自然参数**（nature parameter）；T(y)是**充分统计量**（sufficient statistic），通常 **T(y)=y**。当参数 a、b、T 都固定的时候，就定义了一个以η为参数的函数族。\n\n下面介绍两种分布，伯努利分布和高斯分布，分别把它们表示成指数分布族的形式。\n\n### **伯努利分布**\n\n伯努利分布是对0，1问题进行建模的，对于Bernoulli（$\\varphi$）,$y\\epsilon\\{0, 1\\}$.有$p(y=1; \\varphi ) = \\varphi; p(y=0; \\varphi ) = 1- \\varphi$，下面将其推导成指数分布族形式：\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20151006105233062)\n</center>\n\n将其与指数族分布形式对比，可以看出：\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20151006105357353)\n</center>\n\n表明伯努利分布也是指数分布族的一种。从上述式子可以看到，$\\eta$的形式与logistic函数（sigmoid）一致，这是因为 logistic模型对问题的前置概率估计其实就是伯努利分布。\n\n### **高斯分布**\n下面对高斯分布进行推导，推导公式如下（为了方便计算，我们将方差 $\\sigma$设置为1）：\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20151006105614842)\n</center>\n\n将上式与指数族分布形式比对，可知：\n\n$$b(y) = \\frac{1}{\\sqrt{2\\pi}}exp(-\\frac{1}{2}y^{2})$$\n\n$$T(y) = y$$\n\n$$\\eta = \\mu$$\n\n$$a(\\eta)=\\frac{1}{2}\\mu^{2}$$\n\n两个典型的指数分布族，伯努利和高斯分布。其实大多数概率分布都可以表示成指数分布族形式，如下所示：\n\n- 伯努利分布（Bernoulli）：对 0、1 问题进行建模；\n- 多项式分布（Multinomial）：多有 K 个离散结果的事件建模；\n- 泊松分布（Poisson）：对计数过程进行建模，比如网站访问量的计数问题，放射性衰变的数目，商店顾客数量等问题；\n- 伽马分布（gamma）与指数分布（exponential）：对有间隔的正数进行建模，比如公交车的到站时间问题；\n- β 分布：对小数建模；\n- Dirichlet 分布：对概率分布进建模；\n- Wishart 分布：协方差矩阵的分布；\n- 高斯分布（Gaussian）；\n\n下面来介绍下广义线性模型（Generalized Linear Model, GLM）。\n\n## **3.广义线性模型（Generalized Linear Model, GLM）**\n\n你可能会问，指数分布族究竟有何用？其实我们的目的是要引出GLM，通过指数分布族引出广义线性模型。\n\n仔细观察伯努利分布和高斯分布的指数分布族形式中的$\\eta$变量。可以发现，在伯努利的指数分布族形式中，$\\eta$与伯努利分布的参数$\\varphi$是一个logistic函数（下面会介绍logistic回归的推导）。此外，在高斯分布的指数分布族表示形式中，$\\eta$与正态分布的参数$\\mu$相等，下面会根据它推导出普通最小二乘法（Ordinary Least Squares）。通过这两个例子，我们大致可以得到一个结论，<font color=\"red\">**$η$以不同的映射函数与其它概率分布函数中的参数发生联系，从而得到不同的模型，广义线性模型正是将指数分布族中的所有成员（每个成员正好有一个这样的联系）都作为线性模型的扩展，通过各种非线性的连接函数将线性函数映射到其他空间，从而大大扩大了线性模型可解决的问题。**</font>\n\n下面我们看 GLM 的形式化定义，GLM 有三个假设：\n\n- (1) $y|x; \\theta~ExponentialFamily（\\eta）$；给定样本$ x $与参数$θ$，样本分类$ y$ 服从指数分布族中的某个分布；\n- (2) 给定一个 $x$，我们需要的目标函数为$h_{\\theta}(x)=E[T(y)|x]$;\n- (3)$\\eta=\\theta^{T}x$。\n\n依据这三个假设，我们可以推导出logistic模型与普通最小二乘模型。首先根据伯努利分布推导Logistic模型，推导过程如下:\n\n$$h_{\\theta}(x) = E[T(y)|x]=E[y|x]=p(y=1|x;\\theta)$$\n\n$$=\\varphi$$\n\n$$=\\frac{1}{1+e^{-\\eta}}$$\n\n$$=\\frac{1}{1+e^{-\\theta^{T}x}}$$\n\n公式第一行来自假设(2)，公式第二行通过伯努利分布计算得出，第三行通过伯努利的指数分布族表示形式得出，然后在公式第四行，根据假设三替换变量得到。\n\n同样，可以根据高斯分布推导出普通最小二乘，如下：\n\n$$h_{\\theta}(x) = E(T(y)|x)=E[y|x]$$\n\n$$=\\mu$$\n\n$$=\\eta$$\n\n$$=\\theta^{T}x$$\n\n公式第一行来自假设（2），第二行是通过高斯分布$y|x;\\theta$~$ N(\\mu,\\sigma^{2})$计算得出，第三行是通过高斯分布的指数分布族形式表示得出，第四行即为假设（3）。\n\n其中，将η与原始概率分布中的参数联系起来的函数成为正则相应函数（canonical response function），如$φ =\\frac{1}{1+e^{-\\eta}}、μ = η$即是正则响应函数。正则响应函数的逆成为正则关联函数（canonical link function）。\n\n所以，对于广义线性模型，需要决策的是选用什么样的分布，当选取高斯分布时，我们就得到最小二乘模型，当选取伯努利分布时，我们得到 logistic 模型，这里所说的模型是假设函数 h 的形式。\n\n最后总结一下：<font color=\"red\">**广义线性模型通过假设一个概率分布，得到不同的模型，而梯度下降和牛顿方法都是为了求取模型中的线性部分$(\\theta^{T}x)$的参数$\\theta$的。**</font>\n\n**多分类模型-Softmax Regression**\n\n下面再给出GLM的一个例子——**Softmax Regression**.\n\n假设一个分类问题，y可取k个值，即$y \\epsilon\\{1,2,...,k\\}$。现在考虑的不再是一个二分类问题，现在的类别可以是多个。如邮件分类：垃圾邮件、个人邮件、工作相关邮件。下面要介绍的是多项式分布（multinomial distribution）。\n\n多项式分布推导出的GLM可以解决多类分类问题，是 logistic 模型的扩展。对于多项式分布中的各个y的取值，我们可以使用k个参数$\\phi_1,\\phi_2,...,\\phi_k$来表示这k个取值的概率。即\n\n$$P(y=i) = \\phi_{i}$$\n\n但是，这些参数可能会冗余，更正式的说可能不独立，因为$\\sum\\phi_i=1$，知道了前k-1个，就可以通过$1-\\sum_{i=1}^{k-1}\\phi_{i}$计算出第k个概率。所以，我们只假定前k-1个结果的概率参数$\\phi_1$,$\\phi_2$,...,$\\phi_{k-1}$，第k个输出的概率通过下面的式子计算得出：\n\n![$$\\phi_{k} = 1- \\sum_{i=1}^{k-1}\\phi_{i}$$](http://latex.codecogs.com/gif.latex?%24%24%5Cphi_%7Bk%7D%20%3D%201-%20%5Csum_%7Bi%3D1%7D%5E%7Bk-1%7D%5Cphi_%7Bi%7D%24%24)\n\n为了使多项式分布能够写成指数分布族的形式，我们首先定义 T(y)，如下所示：\n\n<center>\n![](http://img.blog.csdn.net/20151006125938706)\n</center>\n\n和之前的不一样，这里我们的$T(y)$不等$y$，$T(y)$现在是一个$k-1$维的向量，而不是一个真实值。接下来，我们将使用$(T(y))_{i}$表示$T(y)$的第i个元素。\n\n下面我们引入指数函数I，使得：\n\n$$I(True)=1,I(False)=0$$\n\n这样，$T(y)$向量中的某个元素还可以表示成：\n\n$$(T(y))_{i}=I(y=i)$$\n\n举例来说，当$ y=2 时，T(2)_2=I(2=2)=1，T(2)_3=I(2=3)=0$。根据公式 15，我们还可以得到：\n\n![$$E[(T(y))_{i}]=\\sum_{y=1}^{k}(T(y)){\\phi}_i=\\sum_{y=1}^{k}I(y=i)\\phi_i=\\phi_i$$](http://latex.codecogs.com/gif.latex?%24%24E%5B%28T%28y%29%29_%7Bi%7D%5D%3D%5Csum_%7By%3D1%7D%5E%7Bk%7D%28T%28y%29%29%7B%5Cphi%7D_i%3D%5Csum_%7By%3D1%7D%5E%7Bk%7DI%28y%3Di%29%5Cphi_i%3D%5Cphi_i%24%24)\n\n$$\\sum_{i=1}^{k}I(y=i)=1$$\n\n下面，二项分布转变为指数分布族的推导如下：\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20151006131133675)\n</center>\n\n其中，最后一步的各个变量如下：\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20151006131218488)\n</center>\n\n由$\\eta$的表达式可知：\n\n![$$\\eta_{i}=log\\frac{\\phi_{i}}{\\phi_{k}}\\Rightarrow \\phi_{i}=\\phi_{k}e^{\\eta_{i}}$$](http://latex.codecogs.com/gif.latex?%24%24%5Ceta_%7Bi%7D%3Dlog%5Cfrac%7B%5Cphi_%7Bi%7D%7D%7B%5Cphi_%7Bk%7D%7D%5CRightarrow%20%5Cphi_%7Bi%7D%3D%5Cphi_%7Bk%7De%5E%7B%5Ceta_%7Bi%7D%7D%24%24)\n\n为了方便，再定义：\n\n![$$\\eta_{k} = log \\frac{\\phi_{k}}{\\phi_{k}}=0$$](http://latex.codecogs.com/gif.latex?%24%24%5Ceta_%7Bk%7D%20%3D%20log%20%5Cfrac%7B%5Cphi_%7Bk%7D%7D%7B%5Cphi_%7Bk%7D%7D%3D0%24%24)\n\n于是，可以得到：\n\n![$$\\sum_{j=1}^{k}\\phi_{i}=\\sum_{j=1}^{k}\\phi_{k}e^{\\eta_{i}}=1 \\Rightarrow \\phi_{k}=\\frac{1}{\\sum_{j=1}^{k}e^{\\eta_{i}}}$$](http://latex.codecogs.com/gif.latex?%24%24%5Csum_%7Bj%3D1%7D%5E%7Bk%7D%5Cphi_%7Bi%7D%3D%5Csum_%7Bj%3D1%7D%5E%7Bk%7D%5Cphi_%7Bk%7De%5E%7B%5Ceta_%7Bi%7D%7D%3D1%20%5CRightarrow%20%5Cphi_%7Bk%7D%3D%5Cfrac%7B1%7D%7B%5Csum_%7Bj%3D1%7D%5E%7Bk%7De%5E%7B%5Ceta_%7Bi%7D%7D%7D%24%24)\n\n将上式代入到\n\n![$$\\eta_{i}=log\\frac{\\phi_{i}}{\\phi_{k}}\\Rightarrow \\phi_{i}=\\phi_{k}e^{\\eta_{i}}$$](http://latex.codecogs.com/gif.latex?%5Ceta_%7Bi%7D%3Dlog%5Cfrac%7B%5Cphi_%7Bi%7D%7D%7B%5Cphi_%7Bk%7D%7D%5CRightarrow%20%5Cphi_%7Bi%7D%3D%5Cphi_%7Bk%7De%5E%7B%5Ceta_%7Bi%7D%7D)，得到：\n\n![$$\\phi_{i}=\\frac{e^{\\eta_{i}}}{\\sum_{j=1}^{k}e^{\\eta_{i}}}=\\frac{e^{\\eta_{i}}}{1+\\sum_{j=1}^{k-1}e^{\\eta_{i}}}$$](http://latex.codecogs.com/gif.latex?%24%24%5Cphi_%7Bi%7D%3D%5Cfrac%7Be%5E%7B%5Ceta_%7Bi%7D%7D%7D%7B%5Csum_%7Bj%3D1%7D%5E%7Bk%7De%5E%7B%5Ceta_%7Bi%7D%7D%7D%3D%5Cfrac%7Be%5E%7B%5Ceta_%7Bi%7D%7D%7D%7B1&plus;%5Csum_%7Bj%3D1%7D%5E%7Bk-1%7De%5E%7B%5Ceta_%7Bi%7D%7D%7D%24%24)\n\n从而，我们就得到了连接函数，有了连接函数后，就可以把多项式分布的概率表达出来:\n\n![$$P(y=i)=\\phi_{i}=\\frac{e^{\\eta_{i}}}{1+\\sum_{j=1}^{k-1}e^{\\eta_{i}}}=\\frac{e^{\\theta_{i}^{T}x}}{1+\\sum_{j=1}^{k-1}e^{\\theta_{j}^{T}x}}$$](http://latex.codecogs.com/gif.latex?%24%24P%28y%3Di%29%3D%5Cphi_%7Bi%7D%3D%5Cfrac%7Be%5E%7B%5Ceta_%7Bi%7D%7D%7D%7B1&plus;%5Csum_%7Bj%3D1%7D%5E%7Bk-1%7De%5E%7B%5Ceta_%7Bi%7D%7D%7D%3D%5Cfrac%7Be%5E%7B%5Ctheta_%7Bi%7D%5E%7BT%7Dx%7D%7D%7B1&plus;%5Csum_%7Bj%3D1%7D%5E%7Bk-1%7De%5E%7B%5Ctheta_%7Bj%7D%5E%7BT%7Dx%7D%7D%24%24)\n\n注意到，上式中的每个参数$\\eta_i$都是一个可用线性向量$\\theta_i^Tx$表示出来的，因而这里的$\\theta$其实是一个二维矩阵。\n\n于是，我们可以得到假设函数 h 如下：\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20151006132537928)\n</center>\n\n那么就建立了假设函数，最后就获得了最大似然估计 \n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20151006132628356)\n</center>\n\n对该式子可以使用梯度下降算法或者牛顿方法求得参数$\\theta$后，使用假设函数$h$对新的样例进行预测，即可完成多类分类任务。这种多种分类问题的解法被称为 softmax regression.\n\n\n## **References**\n\n- [Approximations Of Roots Of Functions – Newton's Method](http://www.phengkimving.com/calc_of_one_real_var/08_app_of_the_der_part_2/08_05_approx_of_roots_of_func_newtons_meth.htm)\n- 机器学习-Andrew Ng 斯坦福大学[机器学习视频-第四讲](http://open.163.com/movie/2008/1/E/D/M6SGF6VB4_M6SGHKAED.html)\n\n---\n<center><strong>本栏目机器学习持续更新中，欢迎来访：<a href=\"http://blog.csdn.net/dream_angel_z\">Dream_Angel_Z 博客</a>\n新浪微博： <a href=\"http://weibo.com/liudiwei210\" target=\"_black\">@拾毅者</a><br>\n</strong></center>","source":"_posts/2016-01-12-Newton-Method.md","raw":"---\nlayout: post\ndate: 2016-01-12 10:24\ntitle: \"机器学习-牛顿方法&指数分布族&GLM\"\ncategories: ML\ntag: \n\t- 牛顿方法\n\t- 指数分布族\n\t- GLM\n\t- Machine Learning\ncomment: true\n---\n\n\n<font color=\"green\">回头再温习一下Andrew Ng的机器学习视频课，顺便把没写完的笔记写完。</font>\n\n本节内容\n\n- 牛顿方法\n- 指数分布族\n- 广义线性模型\n\n<!-- more -->\n\n之前学习了梯度下降方法，关于梯度下降（gradient descent），这里简单的回顾下【参考感知机学习部分提到的梯度下降([gradient descent](http://blog.csdn.net/dream_angel_z/article/details/48915561))】。在最小化损失函数时，采用的就是梯度下降的方法逐步逼近最优解，规则为$\\theta := \\theta - \\eta \\nabla_{\\theta} \\ell(\\theta)$。其实梯度下降属于一种优化方法，但梯度下降找到的是局部最优解。如下图：\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20151006094200515)\n</center>\n\n\n本节首先讲解的是牛顿方法（NewTon's Method）。牛顿方法也是一种优化方法，它考虑的是**全局最优**。接着还会讲到指数分布族和广义线性模型。下面来详细介绍。\n\n## **1.牛顿方法**\n\n现在介绍另一种最小化损失函数$\\ell(\\theta)$的方法——牛顿方法,参考[Approximations Of Roots Of Functions – Newton's Method](http://www.phengkimving.com/calc_of_one_real_var/08_app_of_the_der_part_2/08_05_approx_of_roots_of_func_newtons_meth.htm)\n。它与梯度下降不同，其基本思想如下：\n\n假设一个函数$f(x) = 0$,我们需要求解此时的$x$值。如下图所示：\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20151006095845371)\n图1 $f(x0) = 0, a1, a2, a3, ... 逐步接近 x0$.\n</center>\n\n在\n$a_1$点的时候，$f(x)$切线的目标函数$y = f(a_1) + f '(a_1)(x – a_1)$. 由于$(a_2,0)$在这条线上，所以我们有$ 0 = f(a_1) + f '(a_1)(a_2 – a_1)$,so:\n\n$$a_2 = a_1-\\frac{f(a_1)}{f'(a_1)}$$\n\n同理，在$a_2$点的时候，切线的目标函数$y = f(a_2) + f '(a_2)(x – a_2)$. 由于$(a_3,0)$在这条线上，所以我们有$ 0 = f(a_2) + f '(a_2)(a_3– a_2)$,so:\n\n$$a_3 = a_2-\\frac{f(a_2)}{f'(a_2)}$$\n\n假设在第$n$次迭代，有$f(a_n)=0$,那么此时有下面这个递推公式：\n\n![](http://latex.codecogs.com/gif.latex?%24%24a_n%20%3D%20a_%7Bn-1%7D-%5Cfrac%7Bf%28a_%7Bn-1%7D%29%7D%7Bf%27%28a_%7Bn-1%7D%29%7D%24%24)\n\n其中$n>=2$.\n\n最后得到的公式也就是牛顿方法的学习规则，为了和梯度下降对比，我们来替换一下变量，公式如下：\n\n$$\\theta := \\theta - \\frac{f(\\theta)}{f'(\\theta)}$$\n\n\n<font color=\"green\">**那么问题来了，怎么将牛顿方法应用到我们的问题上，最小化损失函数$\\ell(\\theta)$(或者是求极大似然估计的极大值)呢？**\n</font>\n\n  对于机器学习问题，现在我们优化的目标函数为极大似然估计$\\ell$，当极大似然估计函数取值最大时，其导数为 0，这样就和上面函数f取 0 的问题一致了，令$f(\\theta) = \\ell'(\\theta)$。极大似然函数的求解更新规则是：\n  \n$$\\theta := \\theta - \\frac{\\ell'(\\theta)}{\\ell''(\\theta)}$$\n\n对于$\\ell$，当一阶导数为零时，有极值；此时，如果二阶导数大于零，则$\\ell$有极小值，如果二阶导数小于零，则有极大值。\n\n上面的式子是当参数$\\theta$为实数时的情况，下面我们要求出一般式。当参数为向量时，更新规则变为如下公式：\n\n$$\\theta := \\theta - H^{-1} \\nabla_{\\theta}\\ell(\\theta)$$\n\n其中$\\nabla$后半部分$和之前梯度下降中提到的一样，是梯度，$H$是一个$n*n$的矩阵，$H $是函数的二次导数矩阵，被成为$Hessian$矩阵。其某个元素$ H_{ij}$ 计算公式如下：\n\n![$$H_{ij}=\\dfrac{\\partial^{2}\\ell(\\theta)}{\\partial\\theta_{i}\\theta_{j}}$$](http://latex.codecogs.com/gif.latex?%24%24H_%7Bij%7D%3D%5Cdfrac%7B%5Cpartial%5E%7B2%7D%5Cell%28%5Ctheta%29%7D%7B%5Cpartial%5Ctheta_%7Bi%7D%5Ctheta_%7Bj%7D%7D%24%24)\n\n<font color=\"red\">**和梯度下降相比，牛顿方法的收敛速度更快，通常只要十几次或者更少就可以收敛，牛顿方法也被称为二次收敛（quadratic convergence），因为当迭代到距离收敛值比较近的时候，每次迭代都能使误差变为原来的平方。缺点是当参数向量较大的时候，每次迭代都需要计算一次 Hessian 矩阵的逆，比较耗时。**\n</font>\n\n## **2.指数分布族（The exponential family）**\n\n\n指数分布族是指可以表示为指数形式的概率分布。指数分布的形式如下：\n\n$$P(y;\\eta)=b(y)exp(\\eta^{T}T(y)-a(\\eta))$$\n\n其中，η成为分布的**自然参数**（nature parameter）；T(y)是**充分统计量**（sufficient statistic），通常 **T(y)=y**。当参数 a、b、T 都固定的时候，就定义了一个以η为参数的函数族。\n\n下面介绍两种分布，伯努利分布和高斯分布，分别把它们表示成指数分布族的形式。\n\n### **伯努利分布**\n\n伯努利分布是对0，1问题进行建模的，对于Bernoulli（$\\varphi$）,$y\\epsilon\\{0, 1\\}$.有$p(y=1; \\varphi ) = \\varphi; p(y=0; \\varphi ) = 1- \\varphi$，下面将其推导成指数分布族形式：\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20151006105233062)\n</center>\n\n将其与指数族分布形式对比，可以看出：\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20151006105357353)\n</center>\n\n表明伯努利分布也是指数分布族的一种。从上述式子可以看到，$\\eta$的形式与logistic函数（sigmoid）一致，这是因为 logistic模型对问题的前置概率估计其实就是伯努利分布。\n\n### **高斯分布**\n下面对高斯分布进行推导，推导公式如下（为了方便计算，我们将方差 $\\sigma$设置为1）：\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20151006105614842)\n</center>\n\n将上式与指数族分布形式比对，可知：\n\n$$b(y) = \\frac{1}{\\sqrt{2\\pi}}exp(-\\frac{1}{2}y^{2})$$\n\n$$T(y) = y$$\n\n$$\\eta = \\mu$$\n\n$$a(\\eta)=\\frac{1}{2}\\mu^{2}$$\n\n两个典型的指数分布族，伯努利和高斯分布。其实大多数概率分布都可以表示成指数分布族形式，如下所示：\n\n- 伯努利分布（Bernoulli）：对 0、1 问题进行建模；\n- 多项式分布（Multinomial）：多有 K 个离散结果的事件建模；\n- 泊松分布（Poisson）：对计数过程进行建模，比如网站访问量的计数问题，放射性衰变的数目，商店顾客数量等问题；\n- 伽马分布（gamma）与指数分布（exponential）：对有间隔的正数进行建模，比如公交车的到站时间问题；\n- β 分布：对小数建模；\n- Dirichlet 分布：对概率分布进建模；\n- Wishart 分布：协方差矩阵的分布；\n- 高斯分布（Gaussian）；\n\n下面来介绍下广义线性模型（Generalized Linear Model, GLM）。\n\n## **3.广义线性模型（Generalized Linear Model, GLM）**\n\n你可能会问，指数分布族究竟有何用？其实我们的目的是要引出GLM，通过指数分布族引出广义线性模型。\n\n仔细观察伯努利分布和高斯分布的指数分布族形式中的$\\eta$变量。可以发现，在伯努利的指数分布族形式中，$\\eta$与伯努利分布的参数$\\varphi$是一个logistic函数（下面会介绍logistic回归的推导）。此外，在高斯分布的指数分布族表示形式中，$\\eta$与正态分布的参数$\\mu$相等，下面会根据它推导出普通最小二乘法（Ordinary Least Squares）。通过这两个例子，我们大致可以得到一个结论，<font color=\"red\">**$η$以不同的映射函数与其它概率分布函数中的参数发生联系，从而得到不同的模型，广义线性模型正是将指数分布族中的所有成员（每个成员正好有一个这样的联系）都作为线性模型的扩展，通过各种非线性的连接函数将线性函数映射到其他空间，从而大大扩大了线性模型可解决的问题。**</font>\n\n下面我们看 GLM 的形式化定义，GLM 有三个假设：\n\n- (1) $y|x; \\theta~ExponentialFamily（\\eta）$；给定样本$ x $与参数$θ$，样本分类$ y$ 服从指数分布族中的某个分布；\n- (2) 给定一个 $x$，我们需要的目标函数为$h_{\\theta}(x)=E[T(y)|x]$;\n- (3)$\\eta=\\theta^{T}x$。\n\n依据这三个假设，我们可以推导出logistic模型与普通最小二乘模型。首先根据伯努利分布推导Logistic模型，推导过程如下:\n\n$$h_{\\theta}(x) = E[T(y)|x]=E[y|x]=p(y=1|x;\\theta)$$\n\n$$=\\varphi$$\n\n$$=\\frac{1}{1+e^{-\\eta}}$$\n\n$$=\\frac{1}{1+e^{-\\theta^{T}x}}$$\n\n公式第一行来自假设(2)，公式第二行通过伯努利分布计算得出，第三行通过伯努利的指数分布族表示形式得出，然后在公式第四行，根据假设三替换变量得到。\n\n同样，可以根据高斯分布推导出普通最小二乘，如下：\n\n$$h_{\\theta}(x) = E(T(y)|x)=E[y|x]$$\n\n$$=\\mu$$\n\n$$=\\eta$$\n\n$$=\\theta^{T}x$$\n\n公式第一行来自假设（2），第二行是通过高斯分布$y|x;\\theta$~$ N(\\mu,\\sigma^{2})$计算得出，第三行是通过高斯分布的指数分布族形式表示得出，第四行即为假设（3）。\n\n其中，将η与原始概率分布中的参数联系起来的函数成为正则相应函数（canonical response function），如$φ =\\frac{1}{1+e^{-\\eta}}、μ = η$即是正则响应函数。正则响应函数的逆成为正则关联函数（canonical link function）。\n\n所以，对于广义线性模型，需要决策的是选用什么样的分布，当选取高斯分布时，我们就得到最小二乘模型，当选取伯努利分布时，我们得到 logistic 模型，这里所说的模型是假设函数 h 的形式。\n\n最后总结一下：<font color=\"red\">**广义线性模型通过假设一个概率分布，得到不同的模型，而梯度下降和牛顿方法都是为了求取模型中的线性部分$(\\theta^{T}x)$的参数$\\theta$的。**</font>\n\n**多分类模型-Softmax Regression**\n\n下面再给出GLM的一个例子——**Softmax Regression**.\n\n假设一个分类问题，y可取k个值，即$y \\epsilon\\{1,2,...,k\\}$。现在考虑的不再是一个二分类问题，现在的类别可以是多个。如邮件分类：垃圾邮件、个人邮件、工作相关邮件。下面要介绍的是多项式分布（multinomial distribution）。\n\n多项式分布推导出的GLM可以解决多类分类问题，是 logistic 模型的扩展。对于多项式分布中的各个y的取值，我们可以使用k个参数$\\phi_1,\\phi_2,...,\\phi_k$来表示这k个取值的概率。即\n\n$$P(y=i) = \\phi_{i}$$\n\n但是，这些参数可能会冗余，更正式的说可能不独立，因为$\\sum\\phi_i=1$，知道了前k-1个，就可以通过$1-\\sum_{i=1}^{k-1}\\phi_{i}$计算出第k个概率。所以，我们只假定前k-1个结果的概率参数$\\phi_1$,$\\phi_2$,...,$\\phi_{k-1}$，第k个输出的概率通过下面的式子计算得出：\n\n![$$\\phi_{k} = 1- \\sum_{i=1}^{k-1}\\phi_{i}$$](http://latex.codecogs.com/gif.latex?%24%24%5Cphi_%7Bk%7D%20%3D%201-%20%5Csum_%7Bi%3D1%7D%5E%7Bk-1%7D%5Cphi_%7Bi%7D%24%24)\n\n为了使多项式分布能够写成指数分布族的形式，我们首先定义 T(y)，如下所示：\n\n<center>\n![](http://img.blog.csdn.net/20151006125938706)\n</center>\n\n和之前的不一样，这里我们的$T(y)$不等$y$，$T(y)$现在是一个$k-1$维的向量，而不是一个真实值。接下来，我们将使用$(T(y))_{i}$表示$T(y)$的第i个元素。\n\n下面我们引入指数函数I，使得：\n\n$$I(True)=1,I(False)=0$$\n\n这样，$T(y)$向量中的某个元素还可以表示成：\n\n$$(T(y))_{i}=I(y=i)$$\n\n举例来说，当$ y=2 时，T(2)_2=I(2=2)=1，T(2)_3=I(2=3)=0$。根据公式 15，我们还可以得到：\n\n![$$E[(T(y))_{i}]=\\sum_{y=1}^{k}(T(y)){\\phi}_i=\\sum_{y=1}^{k}I(y=i)\\phi_i=\\phi_i$$](http://latex.codecogs.com/gif.latex?%24%24E%5B%28T%28y%29%29_%7Bi%7D%5D%3D%5Csum_%7By%3D1%7D%5E%7Bk%7D%28T%28y%29%29%7B%5Cphi%7D_i%3D%5Csum_%7By%3D1%7D%5E%7Bk%7DI%28y%3Di%29%5Cphi_i%3D%5Cphi_i%24%24)\n\n$$\\sum_{i=1}^{k}I(y=i)=1$$\n\n下面，二项分布转变为指数分布族的推导如下：\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20151006131133675)\n</center>\n\n其中，最后一步的各个变量如下：\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20151006131218488)\n</center>\n\n由$\\eta$的表达式可知：\n\n![$$\\eta_{i}=log\\frac{\\phi_{i}}{\\phi_{k}}\\Rightarrow \\phi_{i}=\\phi_{k}e^{\\eta_{i}}$$](http://latex.codecogs.com/gif.latex?%24%24%5Ceta_%7Bi%7D%3Dlog%5Cfrac%7B%5Cphi_%7Bi%7D%7D%7B%5Cphi_%7Bk%7D%7D%5CRightarrow%20%5Cphi_%7Bi%7D%3D%5Cphi_%7Bk%7De%5E%7B%5Ceta_%7Bi%7D%7D%24%24)\n\n为了方便，再定义：\n\n![$$\\eta_{k} = log \\frac{\\phi_{k}}{\\phi_{k}}=0$$](http://latex.codecogs.com/gif.latex?%24%24%5Ceta_%7Bk%7D%20%3D%20log%20%5Cfrac%7B%5Cphi_%7Bk%7D%7D%7B%5Cphi_%7Bk%7D%7D%3D0%24%24)\n\n于是，可以得到：\n\n![$$\\sum_{j=1}^{k}\\phi_{i}=\\sum_{j=1}^{k}\\phi_{k}e^{\\eta_{i}}=1 \\Rightarrow \\phi_{k}=\\frac{1}{\\sum_{j=1}^{k}e^{\\eta_{i}}}$$](http://latex.codecogs.com/gif.latex?%24%24%5Csum_%7Bj%3D1%7D%5E%7Bk%7D%5Cphi_%7Bi%7D%3D%5Csum_%7Bj%3D1%7D%5E%7Bk%7D%5Cphi_%7Bk%7De%5E%7B%5Ceta_%7Bi%7D%7D%3D1%20%5CRightarrow%20%5Cphi_%7Bk%7D%3D%5Cfrac%7B1%7D%7B%5Csum_%7Bj%3D1%7D%5E%7Bk%7De%5E%7B%5Ceta_%7Bi%7D%7D%7D%24%24)\n\n将上式代入到\n\n![$$\\eta_{i}=log\\frac{\\phi_{i}}{\\phi_{k}}\\Rightarrow \\phi_{i}=\\phi_{k}e^{\\eta_{i}}$$](http://latex.codecogs.com/gif.latex?%5Ceta_%7Bi%7D%3Dlog%5Cfrac%7B%5Cphi_%7Bi%7D%7D%7B%5Cphi_%7Bk%7D%7D%5CRightarrow%20%5Cphi_%7Bi%7D%3D%5Cphi_%7Bk%7De%5E%7B%5Ceta_%7Bi%7D%7D)，得到：\n\n![$$\\phi_{i}=\\frac{e^{\\eta_{i}}}{\\sum_{j=1}^{k}e^{\\eta_{i}}}=\\frac{e^{\\eta_{i}}}{1+\\sum_{j=1}^{k-1}e^{\\eta_{i}}}$$](http://latex.codecogs.com/gif.latex?%24%24%5Cphi_%7Bi%7D%3D%5Cfrac%7Be%5E%7B%5Ceta_%7Bi%7D%7D%7D%7B%5Csum_%7Bj%3D1%7D%5E%7Bk%7De%5E%7B%5Ceta_%7Bi%7D%7D%7D%3D%5Cfrac%7Be%5E%7B%5Ceta_%7Bi%7D%7D%7D%7B1&plus;%5Csum_%7Bj%3D1%7D%5E%7Bk-1%7De%5E%7B%5Ceta_%7Bi%7D%7D%7D%24%24)\n\n从而，我们就得到了连接函数，有了连接函数后，就可以把多项式分布的概率表达出来:\n\n![$$P(y=i)=\\phi_{i}=\\frac{e^{\\eta_{i}}}{1+\\sum_{j=1}^{k-1}e^{\\eta_{i}}}=\\frac{e^{\\theta_{i}^{T}x}}{1+\\sum_{j=1}^{k-1}e^{\\theta_{j}^{T}x}}$$](http://latex.codecogs.com/gif.latex?%24%24P%28y%3Di%29%3D%5Cphi_%7Bi%7D%3D%5Cfrac%7Be%5E%7B%5Ceta_%7Bi%7D%7D%7D%7B1&plus;%5Csum_%7Bj%3D1%7D%5E%7Bk-1%7De%5E%7B%5Ceta_%7Bi%7D%7D%7D%3D%5Cfrac%7Be%5E%7B%5Ctheta_%7Bi%7D%5E%7BT%7Dx%7D%7D%7B1&plus;%5Csum_%7Bj%3D1%7D%5E%7Bk-1%7De%5E%7B%5Ctheta_%7Bj%7D%5E%7BT%7Dx%7D%7D%24%24)\n\n注意到，上式中的每个参数$\\eta_i$都是一个可用线性向量$\\theta_i^Tx$表示出来的，因而这里的$\\theta$其实是一个二维矩阵。\n\n于是，我们可以得到假设函数 h 如下：\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20151006132537928)\n</center>\n\n那么就建立了假设函数，最后就获得了最大似然估计 \n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20151006132628356)\n</center>\n\n对该式子可以使用梯度下降算法或者牛顿方法求得参数$\\theta$后，使用假设函数$h$对新的样例进行预测，即可完成多类分类任务。这种多种分类问题的解法被称为 softmax regression.\n\n\n## **References**\n\n- [Approximations Of Roots Of Functions – Newton's Method](http://www.phengkimving.com/calc_of_one_real_var/08_app_of_the_der_part_2/08_05_approx_of_roots_of_func_newtons_meth.htm)\n- 机器学习-Andrew Ng 斯坦福大学[机器学习视频-第四讲](http://open.163.com/movie/2008/1/E/D/M6SGF6VB4_M6SGHKAED.html)\n\n---\n<center><strong>本栏目机器学习持续更新中，欢迎来访：<a href=\"http://blog.csdn.net/dream_angel_z\">Dream_Angel_Z 博客</a>\n新浪微博： <a href=\"http://weibo.com/liudiwei210\" target=\"_black\">@拾毅者</a><br>\n</strong></center>","slug":"2016-01-12-Newton-Method","published":1,"updated":"2016-03-14T13:43:20.336Z","comments":1,"photos":[],"link":"","_id":"cimigpyv4003w6cuj73dchwah"},{"layout":"post","date":"2016-01-02T02:24:00.000Z","title":"用python模拟网页数据提交","comment":true,"_content":"\n## 背景\n\n做实验的时候，需要将独立测试集的数据与别人server跑出来的结果进行比较，比如下面这个：[http://bioinfo.ggc.org/bindn/](http://bioinfo.ggc.org/bindn/) 。但是这个server一次性只能提交一个fasta文件，也就是说，我有很多数据的话，就要分多次提交。如果是人工的去操作，会比较耗时，而且工作量特别大，因此这里就需要模拟网页的数据提交。这就是本文的主要内容，\n\n<!--more-->\n\n## 思路\n\n下面先来理清下思路。我的目的是通过自己构造post数据来实现数据提交。\n\n当模拟在网页上提交数据时，首先要弄清楚整个数据处理流程，比如发送了什么样的数据，给谁发的等。那么如果我要在网页上提交数据的话，肯定是要传递参数的，所以我们要知道如何查找这些参数，这是最重要的一点。其次，模拟数据提交，必须要知道提交前的网页和提交后的网页，这样才能将提交后显示结果网页保存下来。最后就是数据处理了，使用正则表达式将需要的数据抽取出来。\n\n## 实践\n\n### 参数分析\n\n关于参数，可以从数据包中分析出来，我是使用google自带的抓包工具分析的，使用ctrl+shift+I快捷键，点击进入Network列，如下图：\n\n![](/assets/articleImg/2016-01-01-img1.png)\n\n可以看到，当前什么都没有，下面我将参数填写完整\n\n![](/assets/articleImg/2016-01-01-img2.png)\n\n当我将数据设置好之后，点击Submit Query按钮后，结果如下图所示：\n\n![](/assets/articleImg/2016-01-01-img3.png)\n\n多了一个bindn.pl文件，我们来看看这个文件的内容，看看headers部分：\n\n![](/assets/articleImg/2016-01-01-img4.png)\n\n和图二进行比较，你会看到是相互对应。也就是说，这就是我们需要提交的参数：\n\n```\npostData = {'seq' : oneseq,  #oneseq是一个字符串，后面作为一个参数传递进来\n        'qtype' : 'rna',  \n        'vtype' : 'sp',\n        'val' : '80',\n        'submit' : 'Submit Query' \n        } \n```\n\n而点击发送后的请求URL和HTML头内容，如下图：\n\n\n![](/assets/articleImg/2016-01-01-img5.png)\n\n所以现在我们可以得到以下这些数据（postData在上面已经分析出来了）：\n\n```\nhosturl = 'http://bioinfo.ggc.org/bindn/' \nposturl = 'http://bioinfo.ggc.org/cgi-bin/bindn/bindn.pl' #可以从数据包中分析出，处理post请求的url  \nheaders = {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.80 Safari/537.36',  \n           'Referer' : 'http://bioinfo.ggc.org/bindn/'}   \n```\n\n\n### Python模拟\n\n分析结束后，我们要构造自己的HTTP数据包，并发送给指定url。我们通过urllib2等几个模块提供的API来实现request请求的发送和相应的接收。最后需要编写一个函数，将自己需要的内容抽取出来。完整代码和讲解如下如下：\n\n\n```\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Fri Jan 01 09:34:50 2016\n\n@author: liudiwei\n\"\"\"\n\nimport os \nimport urllib  \nimport urllib2  \nimport cookielib  \nimport re\n\n#首先定义一个模拟数据提交的函数，传入刚刚分析出来的四个参数即可\ndef scratchData(hosturl, posturl, postData, headers):\n    #设置一个cookie处理器，它负责从服务器下载cookie到本地，并且在发送请求时带上本地的cookie  \n    cj = cookielib.LWPCookieJar()  \n    cookie_support = urllib2.HTTPCookieProcessor(cj)  \n    opener = urllib2.build_opener(cookie_support, urllib2.HTTPHandler)  \n    urllib2.install_opener(opener) \n    #打开登录主页面（他的目的是从页面下载cookie，这样我们在再送post数据时就有cookie了，否则发送不成功）\n    urllib2.urlopen(hosturl)  \n    #需要给Post数据编码  \n    postDataEncode = urllib.urlencode(postData)  \n    #通过urllib2提供的request方法来向指定Url发送我们构造的数据，并完成数据发送过程  \n    request = urllib2.Request(posturl, postDataEncode, headers)  \n    print request  \n    response = urllib2.urlopen(request)  \n    resultText = response.read()  \n    return resultText \n\n#将一次提交写到一个函数里面，每次只需传入一个序列即可，因为其它的参数不变\ndef BindN(oneseq, outdir):\n    #当前页面，即提交数据页面\n    hosturl = 'http://bioinfo.ggc.org/bindn/' \n    #post数据接收和处理的页面（我们要向这个页面发送我们构造的Post数据）  \n    posturl = 'http://bioinfo.ggc.org/cgi-bin/bindn/bindn.pl' #可以从数据包中分析出，处理post请求的url  \n     #构造header，一般header至少要包含一下两项。这两项是从抓到的包里分析得出的。  \n    headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.80 Safari/537.36',  \n               'Referer' : 'http://bioinfo.ggc.org/bindn/'}   \n    #构造Post数据，他也是从抓大的包里分析得出的。\n    postData = {'seq' : oneseq,  \n            'qtype' : 'rna',  \n            'vtype' : 'sp',\n            'val' : '80',\n            'submit' : 'Submit Query' \n            } \n    result = scratchData(hosturl, posturl, postData, headers)\n    print \"+++++\", oneseq \n    chainname = oneseq[1:5] + oneseq[6:7]\n    outfilename = str(chainname) + '.html'\n    fw_result = open(outdir + '/' + outfilename, 'w')\n    fw_result.write(result)\n    fw_result.close()\n    return result, str(chainname)\n\n\n#使用正则表达式提取数据\ndef extractBindN(htmlfmt, outfile):\n    fw_result = open(outfile, 'w')\n    inputdata = htmlfmt.split('\\n')\n    for i in range(len(inputdata)):\n        onedata = inputdata[i].strip()\n        if not onedata:\n            continue\n        if '<' in onedata or '*' in onedata:\n            continue\n        regText = onedata.split('\\t')[0].strip()\n        if re.match(r'^\\d+$', regText) and True or False:\n            fw_result.write(onedata + '\\n')\n    fw_result.close()\n\n#main方法\nif __name__==\"__main__\":\n    oneseq = \">2XD0_A\\nMKFYTISSKYIEYLKEFDDKVPNSEDPTYQNPKAFIGIVLEIQGHKYLAPLTSPK\\\n    KWHNNVKESSLSCFKLHENGVPENQLGLINLKFMIPIIEAEVSLLDLGNMPNTPYKRMLYKQLQFIRANSDKIA\\\n    SKSDTLRNLVLQGKMQGTCNFSLLEEKYRDFGK\"\n    outdir = \"/home/liudiwei/result\" #输出路径\n    if not os.path.exists(outdir):\n        os.mkdir(outdir)\n    print outdir\n    result, chainname = BindN(oneseq, outdir)\n    outfile = outdir + \"/\" + chainname + \".data\" #最终输出的文件名\n    extractBindN(result, outfile)\n\n```\n\n---\n\n","source":"_posts/2016-01-02-extracte-data-from-web-server-in-python.md","raw":"---\nlayout: post\ndate: 2016-01-02 10:24\ntitle: \"用python模拟网页数据提交\"\ncategories: Python\ntag: \n\t- 数据提取\n\t- Python\n\t- 正则表达式\ncomment: true\n---\n\n## 背景\n\n做实验的时候，需要将独立测试集的数据与别人server跑出来的结果进行比较，比如下面这个：[http://bioinfo.ggc.org/bindn/](http://bioinfo.ggc.org/bindn/) 。但是这个server一次性只能提交一个fasta文件，也就是说，我有很多数据的话，就要分多次提交。如果是人工的去操作，会比较耗时，而且工作量特别大，因此这里就需要模拟网页的数据提交。这就是本文的主要内容，\n\n<!--more-->\n\n## 思路\n\n下面先来理清下思路。我的目的是通过自己构造post数据来实现数据提交。\n\n当模拟在网页上提交数据时，首先要弄清楚整个数据处理流程，比如发送了什么样的数据，给谁发的等。那么如果我要在网页上提交数据的话，肯定是要传递参数的，所以我们要知道如何查找这些参数，这是最重要的一点。其次，模拟数据提交，必须要知道提交前的网页和提交后的网页，这样才能将提交后显示结果网页保存下来。最后就是数据处理了，使用正则表达式将需要的数据抽取出来。\n\n## 实践\n\n### 参数分析\n\n关于参数，可以从数据包中分析出来，我是使用google自带的抓包工具分析的，使用ctrl+shift+I快捷键，点击进入Network列，如下图：\n\n![](/assets/articleImg/2016-01-01-img1.png)\n\n可以看到，当前什么都没有，下面我将参数填写完整\n\n![](/assets/articleImg/2016-01-01-img2.png)\n\n当我将数据设置好之后，点击Submit Query按钮后，结果如下图所示：\n\n![](/assets/articleImg/2016-01-01-img3.png)\n\n多了一个bindn.pl文件，我们来看看这个文件的内容，看看headers部分：\n\n![](/assets/articleImg/2016-01-01-img4.png)\n\n和图二进行比较，你会看到是相互对应。也就是说，这就是我们需要提交的参数：\n\n```\npostData = {'seq' : oneseq,  #oneseq是一个字符串，后面作为一个参数传递进来\n        'qtype' : 'rna',  \n        'vtype' : 'sp',\n        'val' : '80',\n        'submit' : 'Submit Query' \n        } \n```\n\n而点击发送后的请求URL和HTML头内容，如下图：\n\n\n![](/assets/articleImg/2016-01-01-img5.png)\n\n所以现在我们可以得到以下这些数据（postData在上面已经分析出来了）：\n\n```\nhosturl = 'http://bioinfo.ggc.org/bindn/' \nposturl = 'http://bioinfo.ggc.org/cgi-bin/bindn/bindn.pl' #可以从数据包中分析出，处理post请求的url  \nheaders = {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.80 Safari/537.36',  \n           'Referer' : 'http://bioinfo.ggc.org/bindn/'}   \n```\n\n\n### Python模拟\n\n分析结束后，我们要构造自己的HTTP数据包，并发送给指定url。我们通过urllib2等几个模块提供的API来实现request请求的发送和相应的接收。最后需要编写一个函数，将自己需要的内容抽取出来。完整代码和讲解如下如下：\n\n\n```\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Fri Jan 01 09:34:50 2016\n\n@author: liudiwei\n\"\"\"\n\nimport os \nimport urllib  \nimport urllib2  \nimport cookielib  \nimport re\n\n#首先定义一个模拟数据提交的函数，传入刚刚分析出来的四个参数即可\ndef scratchData(hosturl, posturl, postData, headers):\n    #设置一个cookie处理器，它负责从服务器下载cookie到本地，并且在发送请求时带上本地的cookie  \n    cj = cookielib.LWPCookieJar()  \n    cookie_support = urllib2.HTTPCookieProcessor(cj)  \n    opener = urllib2.build_opener(cookie_support, urllib2.HTTPHandler)  \n    urllib2.install_opener(opener) \n    #打开登录主页面（他的目的是从页面下载cookie，这样我们在再送post数据时就有cookie了，否则发送不成功）\n    urllib2.urlopen(hosturl)  \n    #需要给Post数据编码  \n    postDataEncode = urllib.urlencode(postData)  \n    #通过urllib2提供的request方法来向指定Url发送我们构造的数据，并完成数据发送过程  \n    request = urllib2.Request(posturl, postDataEncode, headers)  \n    print request  \n    response = urllib2.urlopen(request)  \n    resultText = response.read()  \n    return resultText \n\n#将一次提交写到一个函数里面，每次只需传入一个序列即可，因为其它的参数不变\ndef BindN(oneseq, outdir):\n    #当前页面，即提交数据页面\n    hosturl = 'http://bioinfo.ggc.org/bindn/' \n    #post数据接收和处理的页面（我们要向这个页面发送我们构造的Post数据）  \n    posturl = 'http://bioinfo.ggc.org/cgi-bin/bindn/bindn.pl' #可以从数据包中分析出，处理post请求的url  \n     #构造header，一般header至少要包含一下两项。这两项是从抓到的包里分析得出的。  \n    headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.80 Safari/537.36',  \n               'Referer' : 'http://bioinfo.ggc.org/bindn/'}   \n    #构造Post数据，他也是从抓大的包里分析得出的。\n    postData = {'seq' : oneseq,  \n            'qtype' : 'rna',  \n            'vtype' : 'sp',\n            'val' : '80',\n            'submit' : 'Submit Query' \n            } \n    result = scratchData(hosturl, posturl, postData, headers)\n    print \"+++++\", oneseq \n    chainname = oneseq[1:5] + oneseq[6:7]\n    outfilename = str(chainname) + '.html'\n    fw_result = open(outdir + '/' + outfilename, 'w')\n    fw_result.write(result)\n    fw_result.close()\n    return result, str(chainname)\n\n\n#使用正则表达式提取数据\ndef extractBindN(htmlfmt, outfile):\n    fw_result = open(outfile, 'w')\n    inputdata = htmlfmt.split('\\n')\n    for i in range(len(inputdata)):\n        onedata = inputdata[i].strip()\n        if not onedata:\n            continue\n        if '<' in onedata or '*' in onedata:\n            continue\n        regText = onedata.split('\\t')[0].strip()\n        if re.match(r'^\\d+$', regText) and True or False:\n            fw_result.write(onedata + '\\n')\n    fw_result.close()\n\n#main方法\nif __name__==\"__main__\":\n    oneseq = \">2XD0_A\\nMKFYTISSKYIEYLKEFDDKVPNSEDPTYQNPKAFIGIVLEIQGHKYLAPLTSPK\\\n    KWHNNVKESSLSCFKLHENGVPENQLGLINLKFMIPIIEAEVSLLDLGNMPNTPYKRMLYKQLQFIRANSDKIA\\\n    SKSDTLRNLVLQGKMQGTCNFSLLEEKYRDFGK\"\n    outdir = \"/home/liudiwei/result\" #输出路径\n    if not os.path.exists(outdir):\n        os.mkdir(outdir)\n    print outdir\n    result, chainname = BindN(oneseq, outdir)\n    outfile = outdir + \"/\" + chainname + \".data\" #最终输出的文件名\n    extractBindN(result, outfile)\n\n```\n\n---\n\n","slug":"2016-01-02-extracte-data-from-web-server-in-python","published":1,"updated":"2016-03-13T06:50:11.811Z","comments":1,"photos":[],"link":"","_id":"cimigpyvb00456cujmqn5kks5"},{"layout":"post","date":"2016-01-01T02:24:00.000Z","title":"机器学习-CSDN个人译文目录","comment":true,"_content":"\n\n## **个人译文**\n\n下面是笔者在CSDN云计算栏目发布的译文，如有翻译不准确的地方，还望多加包涵，只希望能给大家带来点帮助！\n\n<!-- more -->\n\n译文列表如下：\n\n- 2015-12-31 [如何让神经网络把熊猫识别为秃鹫](http://www.csdn.net/article/1970-01-01/2826566)\n- 2015-12-25 [25个Java机器学习工具&库](http://www.csdn.net/article/2015-12-25/2826560)\n- 2015-12-10 [Python机器学习库](http://www.csdn.net/article/2015-12-10/2826435?t=1450960417375)\n- 2015-12-07 [逻辑回归 vs 决策树 vs 支持向量机（II）](http://www.csdn.net/article/2015-12-02/2826374?reload=1)\n- 2015-12-02 [逻辑回归、决策树和支持向量机（I）](http://www.csdn.net/article/2015-11-26/2826332)\n- 2015-11-02 [你应该知道的机器学习方法](http://www.csdn.net/article/2015-11-02/2826107)\n- 2015-10-26 [深度学习和拓扑数据分析的六大惊人之举](http://www.csdn.net/article/2015-10-23/2826027)\n- 2015-10-16 [[访谈]数据大师Olivier Grisel给志向高远的数据科学家的指引 - Part2](http://www.csdn.net/article/2015-10-16/2825926)\n- 2015-10-11 [[访谈] Olivier Grisel谈scikit-learn和机器学习技术的未来 - Part1](http://www.csdn.net/article/2015-10-11/2825882)\n- 2015-09-14 [LSTM实现详解](http://www.csdn.net/article/2015-09-14/2825693)\n- 2015-09-10 [从零实现来理解机器学习算法：书籍推荐及障碍的克服](http://www.csdn.net/article/2015-09-08/2825646)\n- 2015-08-31  [机器学习开发者的现代化路径：不需要从统计学微积分开始](http://www.csdn.net/article/2015-08-27/2825551)\n- 2015-08-27 [基于Python的卷积神经网络和特征提取](http://www.csdn.net/article/2015-08-27/2825549)\n- 2015-08-20 [你应该掌握的七种回归技术](http://www.csdn.net/article/2015-08-19/2825492)\n- 2015-08-11 [机器学习API Top 10：AT&T Speech、IBM Watson和Google Prediction](http://www.csdn.net/article/2015-08-10/2825430)\n- 2015-08-09 [使用GPU和Theano加速深度学习](http://www.csdn.net/article/2015-08-07/2825415)\n- 2015-08-03 [从Theano到Lasagne：基于Python的深度学习的框架和库](http://www.csdn.net/article/2015-08-01/2825362)\n- 2015-07-13 [开发者成功使用机器学习的十大诀窍](http://www.csdn.net/article/2015-07-13/2825187)\n\n下面是其他译者的译文，仅供参考：\n\n- 2015-10-03 [基于Hadoop集群的大规模分布式深度学习](http://www.csdn.net/article/2015-10-01/2825840)\n- 2015-09-16 [各种编程语言的深度学习库整理](http://www.csdn.net/article/2015-09-15/2825714)\n- 2015-09-11 [机器学习温和指南](http://www.csdn.net/article/2015-09-08/2825647)\n- 2015-09-10 [关于数据科学，书上不曾提及的三点经验](http://www.csdn.net/article/2015-09-10/2825668)\n- 2015-08-12 [特征工程 vs. 特征提取：比赛开始！](http://www.csdn.net/article/2015-08-07/2825416)\n\n\n由于本人翻译水平有限，有的地方可能有所漏洞，还望读者海涵。\n\n\n","source":"_posts/2016-01-01-csdn-cloud-column-translation.md","raw":"---\nlayout: post\ndate: 2016-01-01 10:24\ntitle: \"机器学习-CSDN个人译文目录\"\ncategories: ML\ntag: \n\t- Machine Learning\n\t- 译文\ncomment: true\n---\n\n\n## **个人译文**\n\n下面是笔者在CSDN云计算栏目发布的译文，如有翻译不准确的地方，还望多加包涵，只希望能给大家带来点帮助！\n\n<!-- more -->\n\n译文列表如下：\n\n- 2015-12-31 [如何让神经网络把熊猫识别为秃鹫](http://www.csdn.net/article/1970-01-01/2826566)\n- 2015-12-25 [25个Java机器学习工具&库](http://www.csdn.net/article/2015-12-25/2826560)\n- 2015-12-10 [Python机器学习库](http://www.csdn.net/article/2015-12-10/2826435?t=1450960417375)\n- 2015-12-07 [逻辑回归 vs 决策树 vs 支持向量机（II）](http://www.csdn.net/article/2015-12-02/2826374?reload=1)\n- 2015-12-02 [逻辑回归、决策树和支持向量机（I）](http://www.csdn.net/article/2015-11-26/2826332)\n- 2015-11-02 [你应该知道的机器学习方法](http://www.csdn.net/article/2015-11-02/2826107)\n- 2015-10-26 [深度学习和拓扑数据分析的六大惊人之举](http://www.csdn.net/article/2015-10-23/2826027)\n- 2015-10-16 [[访谈]数据大师Olivier Grisel给志向高远的数据科学家的指引 - Part2](http://www.csdn.net/article/2015-10-16/2825926)\n- 2015-10-11 [[访谈] Olivier Grisel谈scikit-learn和机器学习技术的未来 - Part1](http://www.csdn.net/article/2015-10-11/2825882)\n- 2015-09-14 [LSTM实现详解](http://www.csdn.net/article/2015-09-14/2825693)\n- 2015-09-10 [从零实现来理解机器学习算法：书籍推荐及障碍的克服](http://www.csdn.net/article/2015-09-08/2825646)\n- 2015-08-31  [机器学习开发者的现代化路径：不需要从统计学微积分开始](http://www.csdn.net/article/2015-08-27/2825551)\n- 2015-08-27 [基于Python的卷积神经网络和特征提取](http://www.csdn.net/article/2015-08-27/2825549)\n- 2015-08-20 [你应该掌握的七种回归技术](http://www.csdn.net/article/2015-08-19/2825492)\n- 2015-08-11 [机器学习API Top 10：AT&T Speech、IBM Watson和Google Prediction](http://www.csdn.net/article/2015-08-10/2825430)\n- 2015-08-09 [使用GPU和Theano加速深度学习](http://www.csdn.net/article/2015-08-07/2825415)\n- 2015-08-03 [从Theano到Lasagne：基于Python的深度学习的框架和库](http://www.csdn.net/article/2015-08-01/2825362)\n- 2015-07-13 [开发者成功使用机器学习的十大诀窍](http://www.csdn.net/article/2015-07-13/2825187)\n\n下面是其他译者的译文，仅供参考：\n\n- 2015-10-03 [基于Hadoop集群的大规模分布式深度学习](http://www.csdn.net/article/2015-10-01/2825840)\n- 2015-09-16 [各种编程语言的深度学习库整理](http://www.csdn.net/article/2015-09-15/2825714)\n- 2015-09-11 [机器学习温和指南](http://www.csdn.net/article/2015-09-08/2825647)\n- 2015-09-10 [关于数据科学，书上不曾提及的三点经验](http://www.csdn.net/article/2015-09-10/2825668)\n- 2015-08-12 [特征工程 vs. 特征提取：比赛开始！](http://www.csdn.net/article/2015-08-07/2825416)\n\n\n由于本人翻译水平有限，有的地方可能有所漏洞，还望读者海涵。\n\n\n","slug":"2016-01-01-csdn-cloud-column-translation","published":1,"updated":"2016-03-24T06:58:07.138Z","comments":1,"photos":[],"link":"","_id":"cimigpyvf004c6cujixcvrys0"},{"layout":"post","date":"2015-12-31T15:00:00.000Z","title":"2015，稳稳地幸福","comment":true,"_content":"\n就用这首《稳稳地幸福》作为开场白吧，希望也有一种稳稳的幸福！\n\n_有一天，我发现自怜资格都已没有   \n只剩下不知疲倦的肩膀  \n担负着简单的满足   \n有一天，开始从平淡日子感受快乐  \n看到了明明白白的远方  \n我要的幸福......_ \n\n<!-- more -->\n\n不知道从什么时候起，渐渐地开始喜欢安静，喜欢自言自语，喜欢胡思乱想，喜欢对着电脑敲打着键盘写着自己想说的话。也好，算是自己一种放松的方式吧。\n\n\n2015对我来说是一个充满着故事的数字，装载了很多回忆，有美好的，当然也有难忘的。经历了很多，明白了许多，周围的人也在不断的发生变化，最明显的便是大学四年的室友也结婚了。这个话题似乎比较沉重，在这里就不谈了吧，归根结底，还是自己经历的太少了。\n\n\n今年从研一进入了研二，过的很快，当你还没感觉到正式开始的时候，研究生生涯就已经过半了，同时也过了一整年。幸运地是，在研一期间收获了一群小伙伴。其实我很怀念今年三月的那段时间，实训的时候，一群实验室的同学经常上完实训课就结伴去食堂旁边的餐厅点菜，一边吃饭一边聊天，随便开玩笑，没有什么顾虑，有种亲切随和心安的感觉，当然还有一种大家庭的味道。当自己难过的时候，还有一群兄弟朋友在旁边陪伴，虽然偶尔会开下玩笑，但还是挺好的。虽然从四月开始，大家都纷纷出去实习了，但几个同城的小伙伴偶尔聚一次，搞点活动，过的倒也蛮潇洒。如果让我用一句话来形容我们的话，我会引用《速七》里面的一句话“we are not friends, we are family”。\n\n\n言归正传，还是来总结一下今年的生活吧。说到总结，对于还生活在学生时期的我来说，学习是个不可逃避的话题，那么索性就先从学习开始吧。14年的时候，只是简单的学习了数据挖掘，当时拿着韩家炜的那本《数据挖掘概念与技术》就开始漫无目的的去看，很吃力，同样也很难理解，效果也不好，“万事开头难”确实是如此。一学期后，对算法并没有深入了解，然后就不了了事了。这次，乘着三月份之后大部分课程完结了，打算全面地重新学习下常用的算法知识。因而自从实训结束后，就全心地投入到ML的学习中了。看视频跑代码做实验等等，学习斯坦福大学AndrewNg的ML视频教程，还有《统计学习方法》，《机器学习实战》以及相关的Python机器学习库等，还买了很多的书籍，大多是与ML相关的书籍，也有和Linux相关的。虽然这个过程很艰苦，但慢慢的还是坚持了下来，对机器学习也有了进一步的认识，比如什么时候会发生overfiting，如何降低overfiting，又如何提高一个算法的robust等，说到底好的数据比算法更加重要吧，只是现在感觉缺乏一些实践。四月份，因为导师让我带本科生的云计算实验课，所以就顺便初步学习了Hadoop，但并没有深入，只是简单的配置了一下，了解了下Hadoop的文件系统HDFS。后来在博客里写了很多的博文，大多是和ML有关的（都是比较基础的），也有一些与python、Linux、R有关的文章，目前CSDN博客的访问量上升至7w+，主要还是给自己留一个空间，以后回头看的时候会有一些小成就感吧！也因此被CSDN的一个编辑人员发现。随后便成了CSDN云计算专栏的一名机器学习兼职翻译人员，开启了一段翻译旅程，主要负责将国外近期的机器学习优秀博文翻译成中文。时至今日，大概翻译过30余篇文章吧，受益匪浅，感触颇多。\n\n\n五月下旬的时候，忘记是从哪儿冒出的灵感，突然脑子就产生了一个想法，决定搭建一个属于自己的博客，专门用来记录自己的学习与生活。所以在接下来的业余时间，就开始搭建了自己的[个人博客](http://csuldw.github.io)。其实这个经历还是够呛的，起初自己很多东西都不知道，跟个小白没什么两样，比如域名解析、Git、VPS之类的也只是听过，没有实践过，有的只是一个目的（搭建博客）。然后听别人说到了WordPress，接着自己就去查阅资料，还花了点钱租了一个VPS并买了一个域名——csuldw。其实这个域名取名也是讲究了下，前三个字目csu表示Central South University，ldw是我名字的拼音首字母，很容易记的，然后就在VPS中搭建了一个WordPress个人博客，但使用WordPress搭建的博客挂在VPS上的访问速度真的不行，另外需要管理的东西太多了，也不方便发文章，现在连VPS账号都忘记了。无奈之下又去查资料，根据网上的推荐，就使用Jekyll搭建了一个静态博客，当时对这个主题还算满意。没过多久，想对主题进行修改，可是发现修改起来很困难（其实是自己对前端知识了解的不多）。最后，干脆再次换样式，换框架，然后便使用一款基于nodejs的Hexo框架在GitHub上搭建了一个纯静态博客。经过几番折腾之后，主题也修改好了，博客也就诞生了，自己也从一个Git小白慢慢地熟悉了Git，而且对Markdown的使用也越发熟练了，撰写笔记更加方便多了。一个小博客，算是今年的一个小成果吧，内容慢慢再充实。使用github搭建的静态博客，遇到的一个很直接的问题就是图片加载的比较慢，介于这一点，可以将图片上传到其它的图床中或是新浪相册，只要能够获取到图片的链接就OK了，说到底这个还是自己体验上的一个小强迫症吧。\n\n下面是5月26日写下的日记，博客的缘由原来是这样的：\n\n> 2015.05.26 今天上午看了机器学习的“贝叶斯”部分，朴素贝叶斯比较简单，后来就去打印室帮一个在外地的在职研究生打印毕业论文。吃了中饭后无意间在网上看到说作为一个大学生，就应该有一个专属于自己的博客。带着一种学习的心情，去网上买了域名，租了一个美国的VPS，然后使用WordPress搭建了一个属于自己的博客。整个过程碰到了些许问题，然后请教横天的客服，原来是我这边网络的问题，后来就把VPS换成香港的，网速也上去了。很开心~不过由于WordPress是使用php编写的，而我学的是java，很多东西不是很懂，看来以后有时间得好好学习学习。然后自己又折腾了下github，因为看到一位大牛pluskid现在使用的是static 的blog，使用的是github，然后我折腾了好久，没折腾好。算了，先用着WordPress吧，等到以后那天也成“大牛”了，也换个地方折腾折腾。现在主要是能写下东西就ok了。中午没休息，好累，回去睡觉去了。\n\n\n说了这么多，在学习上其实还有一件虐心事，折腾了好几个月了，也就是论文，很揪心。七月份开始睡实验室，跑实验，开始是在自己电脑上面跑，几天没关机，电脑硬盘直接挂掉了，后来直接网购了一个SSD硬盘，换了原来的硬盘，把原来的硬盘撞在了光驱位用来存放临时数据，开机和关机都快了很多，心情一下子就愉快了。八月份跑完实验后就开始写论文，投稿的经历就不说了，结果就是至今还在大修，接下来还需要继续做实验，慢慢改吧，有时候做梦都在调参数，希望能够早点做完吧，然后顺利的出去实习！不过在这方面真的要感谢一下自己的导师，不仅耐心的指导我们，还特别地亲民和善，很nice的一位老师。说到论文，自己从实验中还是学到了很多东西。从数据集的处理，到特征选取，然后如何去处理不均衡数据问题，再到算法的使用、选择、评估。整个流程重复了好多遍，很多原本对理论模棱两可的知识都进一步理解了。比如评估指标的计算、ROC曲线的绘制以及scikit-learn的使用等，收获算是比较大吧。八月之后，从九月开始，大大小小的事情确实比较多了，自己能够安排的时间并不多，可现在回头一想，这段时间也并没有做出什么成果，一直处于瞎忙的状态，结果也就是“郁郁而终”了。其实起初我对自己的时间是有计划的，只是突如其来的事情太多，再加上看论文作报告修改论文等等，一下子一个学期就过去了。唯一值得欣慰的就是拿到了今年的研究生国奖，“否极泰来，物极必反”，大概就是这样的吧。敲门声响起无数次，其它的都是诱惑，只有一次是机会，估计是把今年的运气都集在这里了。突然想到了那句话“上帝为你关上一扇门的同时,还打开了一扇天窗”！\n\n\n![fdsfsf](/assets/articleImg/2015-12-31-desktop.jpg)\n\n\n<div class=\"caption\">『上图是三月底的桌面，下图是十二月底的桌面，多了很多的书籍.』</div>\n\n\n在学习上还有一件让我印象比较深而且很难忘的事情，那就是今年一月下旬那会儿做的事情，应导师之需去配置实验室的cluster（集群）。当时自己压根就不知道cluster是什么，然后就去配置。当然，这里的cluster并不是大家常说的Hadoop，而是Torque，一种用于高性能计算的cluster。当时凭着之前自学的Linux知识，就从装系统开始，一步一步的去配。开始是在实验室的三台台式机器上做测试，只记得那会儿出错后就重装系统，很笨很笨的方式，遇到问题也只能去Google搜索，而那会儿对英文有种莫名恐惧的feel，想必大多数人都有过这种feel！经过几天之后，这三天机器配好了，然后就去配置服务器上的机器，一共开了62台虚拟机器，就我一个人，当时还是个小白，有问题也只能去Google。现在回想下，都不知道自己当时是怎么熬过来的，所幸还是把所有服务器配好了。最后集群之间可以通过NFS进行文件共享，还使用NIS对用户进行统一管理，只是对软件没有使用统一的管理方式，比如现在需要安装一个python库，那么我就需要给所有的机器都安装一遍，工作量太大，不科学。现在也想到了一种解决方法，就是将python安装在一个共享目录下，所有的库也安装在在此目录下，然后把这个目录mount到其它节点中，理论上是可以解决的。只是自那之后就没有对系统进行升级了，有时间再去折腾吧！！！\n\n最近应导师之需，让我想个方法把今年大家做的报告PPT集中起来，比如新建一个百度云账号，或者在我们的服务器上建立一个公共文件夹等。起初我自己想到的是在Github上面建立一个仓库，然后让大家都把东西上传到上面去，也比较方便，但是考虑到Github上面的仓库都是公共的（私有的需要付费），所以这个念头从一开始就被自己全盘否决了。后来想，在服务器上弄个ftp服务器怎么样呢？就这样一个想法，剩下的就是如何去实现。记得之前也有这个想法，五月份的时候，不过那时用的外网的服务器是学校的机器，因为当时配置完SELinux时重启了服务器，后来导致半个小时没启动成功。下面是当天的日记：\n\n> 2015.05.28 今天按照导师的要求在学校的服务器上挂载了我们自己内网服务器上的两个共享文件夹，成功了。后来导师说装一个Samba吧，我正打算在学校的服务器上装的时候，安装完了还没有配置，需要重启机器，我就使用reboot重启了，结果服务器启动不了了。我就纳闷了，这怎么可能。然后我就跟管理服务器的史大牛汇报了一下，因为他在北京，所以不能处理，就跟管理这台服务器的周老师说了。这不说还好，一说就被骂了。因为周老师都不知道我们有这台服务器的权限，这台服务器的密码还是史给我们的，这下把他坑惨了。差点把他从北京坑回来了。所幸没什么事，过了没多久服务器启动成功了。然后周老师把密码都给改了，因为我们实验室的路由器的网络和实验室服务器的网络是两个不同内网，不在一个局域网，使用PuTTY登陆不上去。之前是因为学校的服务器接了多个网卡，我们可以通过先登录到学校的服务器上，然后通过内网透析使用SSH切换到我们自己的服务器上，现在好了，没权限了，让给我们开个非root用户当做登陆用户都不肯，导师说学校那帮人最懒了，一点也不假呀，占着资源不肯放。然后晚上跟导师群聊了下，导师说我们干脆自己再买一台服务器算了，免得用学校的到时候出问题了又赖在我们头上。汗，只能这样了，加油吧，多学点linux操作~fighting！！！\n\n周老师将服务器密码改了之后，最后导师就干脆自己买了一台服务器。因为这台服务器的大多配置都是我配的，比较了解。因为对其他机器没什么依赖，所以重启机器也不会出任何问题。于是就打算在这台服务器上配置一个FTP服务器。因为配置服务器当天中午开完组会之后没休息，所以从开始到最后，用了将近一个下午的时间。碰到的一个比较简单的问题就是端口设置，如何让防火墙开放某个端口。去年自己在虚拟机上的centos6.5系统配置过这个，当时是直接将防火墙关闭掉，但现在考虑到安全问题，所以不能这么做了。其实只要弄懂了思路，整个配置也就显得简单了。如果默认端口号是21的话，可以直接直接访问[ftp://192.168.12.12]，不过我在配置vsftpd的时候修改了端口，所以需要在ip地址后面加上端口号，也就是类似这种[ftp://192.168.12.12:9999]。配置的时候，在细节上也碰到一些问题，不过通过google还是很容易就搜到结果的。总的来说，得到了一个小道理：对于小白来说，就是用时间去攒经验，用时间去买教训，所以必须自己去动手实践，这样才能得到更加直观的结果。而我希望我能够尽最大的速度攒更多的经验，买更多的教训。学习就是一个不断升华的过程，以前看似复杂而困难的问题，当你在相关知识上达到一定深度之后，它们都将随之而变的简单。现在能做的就是不断的去练习、去实践，然后去总结，化教训为经验！\n\n\n今年做过很多次小组报告，大多时候讲的主题都是与课题相关的论文。有时候自己在作报告的时候也会紧张，因为先前准备的不充分，很多论文中的东西还来不及理解，有时甚至连文章中的核心思想都还没完全弄懂，讲出来之后，大家可能也很迷惑。通过多次的锻炼，在这方面还是有了很大的提升，给我的教训就是：要做好一个报告，前提是自己要对这个报告主题内容详熟，能够达到那种完全脱稿的水平就再好不过了。这里说的脱稿并不是不看ppt，而是不要对着ppt上面的内容进行实读，要能够用自己的话进行总结，进行归纳，通过一个主题，自己能够扩展其他的内容，然后将语言表达通顺就OK了。在多次的报告讲解中我发现，如果是讲解自己的论文，那么完全不需要做太多的准备，毕竟整个实验过程自己都知道。另外，每次在讲解服务器的时候，思路很清晰，讲起来也很顺手，可能也是因为熟悉的原因吧！但是大家能不能听懂，又是另外一回事了吧，事实上我觉得听完之后能有个概念也就差不多了。\n\n\n谈完学习，下面来说说与娱乐有关的吧。很遗憾，今年并没有去过多少地方游玩，离学校最远的地方也只是张家界（虽然离家很近，但我却从未去过），走得较多的还是市内的景点吧，去过植物园，爬过岳麓山，逛过橘子洲等，还回过几次农大，摘过草莓，看过枫叶，顺便在校园里散散心。其实并不是自己不想出去，而是今年压根就没闲下来，或者说是自己不想闲吧。一方面，时间确实比较紧，一直奔波在宿舍与实验室之间，更多的是想多学点东西；另一方面，自己今年也确实没计划过要去别的地方，然后很快地一年就过了。曾经自己也想过要去哪些地方，走哪些路，看哪些风景，想在某年某月某一天，背起行囊去流浪。就这样，一个人，一个背包，还有一颗毅然行动的心，去一个陌生的地方。曾想象，一个人留恋于古色古香的苏杭，闲游于景色迷人的西湖，雷峰塔下，断桥旁边，坐于亭中观看行人匆匆，烟雨濛濛。提一壶新茗，浪迹天涯，悠然地寻找江南文化的气息。曾期待，一个人游走在车水马龙的外滩，越过黄浦江眺望远方的东方明珠，在一片灯红酒绿迷人的世界里，感叹着时代的变迁。曾盼望，一个人站在魅力弥漫的日光城下，看着那神圣的布达拉宫，听颂着来自上天的独白，随着飘动的经幡，传到遥远的他方。曾渴望，一个人漫步于浪漫之都，仰望埃菲尔铁塔，身处薰衣草花海，品尝法式甜点，惊叹画家之笔，触摸着法兰西风情熏陶下香榭丽舍的梧桐树。曾梦想，一个人浪迹在伦敦街头，乘一辆红色双层巴士，与阿狸一同探寻永远站的方向。然后寻一家小店，品位正宗英国红茶带来的英伦历史的沉淀，感受风雨后之的痕迹。就这样，一个人，一座城。然而，后来慢慢地变得开始理性了，渐渐地想的也多了，明白的东西也多了。那么还是让我现实点，踏实地做该做的事情吧！突然想到那句，“累就对了,舒服是留给死人的！”，是的，加油吧！时机到了，会有机会出去的（算是给自己一个安慰吧T_T！）。只需记住，越有故事的人越沉静简单，越肤浅单薄的人越浮躁不安。每一个优秀的人，都有一段沉默的时光。\n\n\n相比于游山玩山，今年做的最多的娱乐活动就是看电影了。回想了下，三月看了《帕丁顿熊》，四月看了吴京主演的《战狼》，还有《速度与激情7》，五月看了《何以笙箫默》，七月月看了《捉妖记》，八月看了《大圣归来》、九月看了《港囧》与《碟中谍5神秘国度》，十月看了《夏洛特烦恼》、《小王子》以及《蚁人》，就这些，有搞笑的，也有比较敷衍人的，总的来说还是比较开心，算是弥补了今年没有外出游玩的自己吧！还记得九月下旬那会儿，中秋在即，去了大学母校拜访了文静姐，一个正在享受着当母亲的老师。晚上请我吃了一顿大餐，还送给我一提月饼，感觉好幸福，所以我从来都不去羡慕别人家的老师啦^_^！十一月回农大看枫叶，逛了下校园，然后去红旗市场的溜冰场玩了一会儿，那时那地那景那情，缠绕于指尖，记忆犹深！其实我的爱好也很多的，比如摄影、爬山、溜冰、打桌球、唱K（属于瞎吼的那种）等等，当然也包括了学习（必要时还是得装一下，虽然装的不像）。只是现在除了想学好点，似乎对其它的东西都渐渐地失去了以往的热情，没有了那份心思和真诚，简单地说就是心不在此吧。都说在外待太久，会比较想家，可能我属于异类，回头想想，从过年后回校到现在，中途只回家待了三天，而且还待不住。比往年少了很多，以前至少暑假会回去，各方面的原因都有，可能真是因为自己长大了。其实长大并不可怕，可怕的应该是遗忘吧。\n\n\n![](/assets/articleImg/2015-12-31-movie_all1.jpg)\n\n<div class=\"caption\">『今年保留的所有电影票，与以往比较，多了很多.』</div>\n\n今年并没有得什么大病，只是生过两次小病，并无大碍，但生病的时候还是让人很难受的。一次是在六月底七月初的时候，由于喉咙发炎，接着引发了感冒，发烧，然后头晕，后来连噎食喉咙都痛，大夏天的真是受罪。另外一次是十二月，也是喉咙发炎，不过幸好及时吃了消炎药，没有恶化，第三天就好了。可前些日子，突然心脏部位略微阵痛，算是尝到了什么叫心痛，真正的心痛，应该是最近太累了，一个本命年，过的真是受罪。恩，对，本命年，已经二十四了！！！希望明年的自己能有一个健康的身体吧。写到这里，不禁地想总结一下自己今年的作息。从三月实训开时，早上八点半到晚上五点半待在机房，晚上直到十点多才离开实验室，持续到27号实训结束，一个月只外出三次，一次农大，一次植物园，一次新校区。四月，外出看过两次电影。五月接待同学一天，然后张家界来回三天。六月全月不外出。七月开始睡实验室，中途和小伙伴们聚餐一次，外出看电影一次。八月开始赶论文到中旬，加班至一两点。中下旬接待同学，外出两天，随后搬往宿舍休息。九月回家待了三天，同学聚餐一次，外出看电影两次，农大探望老师一次。十月导师组织烧烤活动一次，外出看电影三次。十一月去农大看枫叶一次。十二月同学结婚，外出两天。其余时间都待在了实验室。对我来说，似乎没有假期与周末可言吧，每天都是一样的日子，千篇一律，有时待到十一点左右才回去，还是那句话，“累就对了，舒服是留给死人的！”。一年的实验室生活，碰到过很多问题，也学到了很多。每一位苦行僧的背后大概都有一段不为人知的往事吧。事实上，如果自己想休息，倒也可以给自己放个假，自由但不放纵，收敛自如，感觉还是很自在、很舒服！毕竟除了待在实验室，也没有其他的地方可以去，似乎到了这里情绪有些低落！！！！\n\n\n![](/assets/articleImg/2015-12-31-lab-morning.jpg)\n\n<div class=\"caption\">『某天早晨，阳光从对面楼层的玻璃反射到我的卓子上，很温暖，特别的温馨.』</div>\n\n\n今年参与的活动不多，除了四月的时候研会举行的那次“最强班集体活动”外，还有一次就是十月中旬左右导师组织的野外烧烤了，其它的就是同学聚餐之类的。回想下四月份，那时的我还算比较积极，参加了好几个比赛项目，有的还拿到了第一名，不过不是个人赛啦。最后我们1402班拿下了冠军，奖励了400大洋呀，钱没发下来就先出去吃了顿好的，算是意料之外的收获吧。另外，印象比较深刻的就是那时的抽奖活动，至今都记忆犹新。也就是那些跟我一起的小伙伴每个人都抽到了奖品，唯独我没抽到，想必我应该就是那个传说中万中无一的人了(*^__^*)……。这应该不是巧合，运气太背了，于是乎“本命年”似乎又躺枪了，(^__^) ……。十月那会儿的烧烤活动，是由导师发起的，不过烧烤食物的原材料是由我和其他几个人一起去超市购买的。因为是第一次买这些食材，没有经验，份量更是不好估计，所幸最后大家都吃完了，关键是大家开心就好！\n\n\n事实上，每个人都有不开心的时候，我也一样，但我的不开心，我的难受，我都尽量留给了自己。只是很多时候，那些安慰别人的话，怎么也安慰不了自己。原因不详，有待细查！那么在这里，就让所有不开心的事情随着2015的离去而过去吧！似乎是从今年五月起，慢慢地开始戒掉了QQ、微信这些社交网络，不会再刻意地去翻阅手机动态，不再专注于回复别人或是查看别人的回复，开始做一个沉默寡言的人，事不关已的事也无需多去关心，只是偶尔会在Sina这样一个安静的人少的地方水水心情！现在，也已习惯了这种节奏，晚上回到宿舍，洗漱完之后也不再会像以往那样经常刷状态，反倒是给自己省下了很多时间做其他的事情！我的计划是明年上半年就出去实习，如果能够早点学校这边的事情搞完，自己也就多点时间复习面试知识。“没有三两三，哪敢上梁山”嘛，掂量掂量自己的水平，提前做好面试准备，也好有个心理准备。可能很多人都觉得我学的好，不过，自己到底有几斤几两，水深还是不深，自己还是有自知之明的，能够将自己80%的好表现出来就行了。Remember，你所恐惧的东西，最终都将变成你的弱点！每当一个人独处的时候，总会想到很多的事情。过去，现在，未来，总有自己可想的事。现在的我，更多的是希望好好把技术学扎实，锻炼好自己各方面能力吧。之前就说过这样一句话，“对现在的自己要求高点，就是给未来的自已最好的礼物！”，一点都没错。相信自己！每当翻阅浙大张弛原和张睿卿两位大牛的文章，总给我一种奋勇向上的激情。如果自己的知识能够达到一定的深度，即便是苦点累点或是慢点，也值了！自己选择的路，跪着也要走完。\n\n\n![](/assets/articleImg/2015-12-31-huatian.jpg)\n\n<div class=\"caption\">『今年十二月，大学室友结婚接新娘的那天早上在华天酒店拍的，当时还没系腰带.』</div>\n\n今年结婚的同学有两个，一位是大学时候的班长，一位是大学的一位室友。一个在二月，一个在十二月，很喜庆，一年好始好终的过了！班长结婚是在常德石门，因此几个有空的同学就跑到常德石门去祝福了，虽说参加别人的婚礼就像是花钱去看别人虐狗（开个玩笑），但有空还是要去的啦，至少还可以当个演员嘛^_^。在大学室友结婚那天也是挺开心的，当了一回伴郎。当伴郎收获比较多的就是，对整个婚礼的流程都了解的很清楚，当地的习俗也知道个大概。身为伴郎，在当天的酒席上并没有吃饭，只记得那天喝的有点多。那种酒席上的玻璃杯，喝了三大半杯白酒，只不过当伴郎喝酒也是没办法的事！随后应新郎支托给同学们开了间麻将房，接着去他们打麻将，自己就在里面睡了一下午，后来大脑虽然清醒，但真的很是难受，半醉半醒的状态更是不堪回首。毕竟我也是不喜欢喝酒的，当然也不抽烟，更谈不上喜欢了。说到吃的，其实我并不挑食，草莓，香蕉，水龙果，橘子好多水果都吃，喜欢喝咖啡，奶茶，绿茶，还喜欢嗑瓜子，最近又喜欢上夏威夷果子，而对巧克力也是无法抗拒的。以前还喜欢吃各类糖果，算一算也是蛮多的。只是如今一天到对着电脑，也顾不上吃这些水果零食了。说到大学同学，自从班长结婚之后，今年就很少聚了，大家交流的也很少了。一方面，大家应该都很忙吧，各自忙各自的，就像我一样。另一方面，可能班长结婚后，没有一个好的据点了吧！另外，听说有位同学已经奉子领证了，果真是士别三日当刮目相待呀！！！\n\n![](/assets/articleImg/2015-12-31-tiedao1.jpg)\n\n<div class=\"caption\">『学校的西门，摄于某个晴空万里的冬天下午.』</div>\n\n来到中南，步入一个新的地方，认识了新的同学，结交了新的朋友，进入了一种新的学习状态，一年又半载，很多事情都在不经意间就开始了，而我也早已习惯了这里的生活！数落着剩下的研途生涯，希望自己能够学到更多的东西吧。烟雾蒙蒙的今晚，已经看不到点点繁星了，望着天空残寂的孤月，明亮中夹带着些许凄美，些许迷离。唏嘘的叹息，在这无眠清寂的长夜里，留下无数的落寞。过往的点滴，都渐渐的在遗逝的记忆里沉淀。走过了似水流年，看过了风花雪月，曾经有一段时光，做了温馨的梦，曾经有一场梦，沧桑中透着凄凉，曾经也有一座城市，却成了一生的梦。夜已深，心已静，默默的守候着今年最后的一点时光，就此成为往后的回忆。。。\n\n\n![](/assets/articleImg/2015-12-31-bagong.jpg)\n\n<div class=\"caption\">『执着忠厚的八公.』</div>\n\n总之，好好奋斗吧……\n\n\n_我要稳稳的幸福  \n能抵挡失落的痛楚  \n一个人的路途  \n也不会孤独_  \n\n\n2016年，祝大家新年快乐！同时也希望自己在新的一年能有一个好的开始！\n\n\n\n---\n","source":"_posts/2015-12-31-annual-summary.md","raw":"---\nlayout: post\ndate: 2015-12-31 23:00\ntitle: \"2015，稳稳地幸福\"\ncategories: 总结\ntag: \n\t- 总结\ncomment: true\n---\n\n就用这首《稳稳地幸福》作为开场白吧，希望也有一种稳稳的幸福！\n\n_有一天，我发现自怜资格都已没有   \n只剩下不知疲倦的肩膀  \n担负着简单的满足   \n有一天，开始从平淡日子感受快乐  \n看到了明明白白的远方  \n我要的幸福......_ \n\n<!-- more -->\n\n不知道从什么时候起，渐渐地开始喜欢安静，喜欢自言自语，喜欢胡思乱想，喜欢对着电脑敲打着键盘写着自己想说的话。也好，算是自己一种放松的方式吧。\n\n\n2015对我来说是一个充满着故事的数字，装载了很多回忆，有美好的，当然也有难忘的。经历了很多，明白了许多，周围的人也在不断的发生变化，最明显的便是大学四年的室友也结婚了。这个话题似乎比较沉重，在这里就不谈了吧，归根结底，还是自己经历的太少了。\n\n\n今年从研一进入了研二，过的很快，当你还没感觉到正式开始的时候，研究生生涯就已经过半了，同时也过了一整年。幸运地是，在研一期间收获了一群小伙伴。其实我很怀念今年三月的那段时间，实训的时候，一群实验室的同学经常上完实训课就结伴去食堂旁边的餐厅点菜，一边吃饭一边聊天，随便开玩笑，没有什么顾虑，有种亲切随和心安的感觉，当然还有一种大家庭的味道。当自己难过的时候，还有一群兄弟朋友在旁边陪伴，虽然偶尔会开下玩笑，但还是挺好的。虽然从四月开始，大家都纷纷出去实习了，但几个同城的小伙伴偶尔聚一次，搞点活动，过的倒也蛮潇洒。如果让我用一句话来形容我们的话，我会引用《速七》里面的一句话“we are not friends, we are family”。\n\n\n言归正传，还是来总结一下今年的生活吧。说到总结，对于还生活在学生时期的我来说，学习是个不可逃避的话题，那么索性就先从学习开始吧。14年的时候，只是简单的学习了数据挖掘，当时拿着韩家炜的那本《数据挖掘概念与技术》就开始漫无目的的去看，很吃力，同样也很难理解，效果也不好，“万事开头难”确实是如此。一学期后，对算法并没有深入了解，然后就不了了事了。这次，乘着三月份之后大部分课程完结了，打算全面地重新学习下常用的算法知识。因而自从实训结束后，就全心地投入到ML的学习中了。看视频跑代码做实验等等，学习斯坦福大学AndrewNg的ML视频教程，还有《统计学习方法》，《机器学习实战》以及相关的Python机器学习库等，还买了很多的书籍，大多是与ML相关的书籍，也有和Linux相关的。虽然这个过程很艰苦，但慢慢的还是坚持了下来，对机器学习也有了进一步的认识，比如什么时候会发生overfiting，如何降低overfiting，又如何提高一个算法的robust等，说到底好的数据比算法更加重要吧，只是现在感觉缺乏一些实践。四月份，因为导师让我带本科生的云计算实验课，所以就顺便初步学习了Hadoop，但并没有深入，只是简单的配置了一下，了解了下Hadoop的文件系统HDFS。后来在博客里写了很多的博文，大多是和ML有关的（都是比较基础的），也有一些与python、Linux、R有关的文章，目前CSDN博客的访问量上升至7w+，主要还是给自己留一个空间，以后回头看的时候会有一些小成就感吧！也因此被CSDN的一个编辑人员发现。随后便成了CSDN云计算专栏的一名机器学习兼职翻译人员，开启了一段翻译旅程，主要负责将国外近期的机器学习优秀博文翻译成中文。时至今日，大概翻译过30余篇文章吧，受益匪浅，感触颇多。\n\n\n五月下旬的时候，忘记是从哪儿冒出的灵感，突然脑子就产生了一个想法，决定搭建一个属于自己的博客，专门用来记录自己的学习与生活。所以在接下来的业余时间，就开始搭建了自己的[个人博客](http://csuldw.github.io)。其实这个经历还是够呛的，起初自己很多东西都不知道，跟个小白没什么两样，比如域名解析、Git、VPS之类的也只是听过，没有实践过，有的只是一个目的（搭建博客）。然后听别人说到了WordPress，接着自己就去查阅资料，还花了点钱租了一个VPS并买了一个域名——csuldw。其实这个域名取名也是讲究了下，前三个字目csu表示Central South University，ldw是我名字的拼音首字母，很容易记的，然后就在VPS中搭建了一个WordPress个人博客，但使用WordPress搭建的博客挂在VPS上的访问速度真的不行，另外需要管理的东西太多了，也不方便发文章，现在连VPS账号都忘记了。无奈之下又去查资料，根据网上的推荐，就使用Jekyll搭建了一个静态博客，当时对这个主题还算满意。没过多久，想对主题进行修改，可是发现修改起来很困难（其实是自己对前端知识了解的不多）。最后，干脆再次换样式，换框架，然后便使用一款基于nodejs的Hexo框架在GitHub上搭建了一个纯静态博客。经过几番折腾之后，主题也修改好了，博客也就诞生了，自己也从一个Git小白慢慢地熟悉了Git，而且对Markdown的使用也越发熟练了，撰写笔记更加方便多了。一个小博客，算是今年的一个小成果吧，内容慢慢再充实。使用github搭建的静态博客，遇到的一个很直接的问题就是图片加载的比较慢，介于这一点，可以将图片上传到其它的图床中或是新浪相册，只要能够获取到图片的链接就OK了，说到底这个还是自己体验上的一个小强迫症吧。\n\n下面是5月26日写下的日记，博客的缘由原来是这样的：\n\n> 2015.05.26 今天上午看了机器学习的“贝叶斯”部分，朴素贝叶斯比较简单，后来就去打印室帮一个在外地的在职研究生打印毕业论文。吃了中饭后无意间在网上看到说作为一个大学生，就应该有一个专属于自己的博客。带着一种学习的心情，去网上买了域名，租了一个美国的VPS，然后使用WordPress搭建了一个属于自己的博客。整个过程碰到了些许问题，然后请教横天的客服，原来是我这边网络的问题，后来就把VPS换成香港的，网速也上去了。很开心~不过由于WordPress是使用php编写的，而我学的是java，很多东西不是很懂，看来以后有时间得好好学习学习。然后自己又折腾了下github，因为看到一位大牛pluskid现在使用的是static 的blog，使用的是github，然后我折腾了好久，没折腾好。算了，先用着WordPress吧，等到以后那天也成“大牛”了，也换个地方折腾折腾。现在主要是能写下东西就ok了。中午没休息，好累，回去睡觉去了。\n\n\n说了这么多，在学习上其实还有一件虐心事，折腾了好几个月了，也就是论文，很揪心。七月份开始睡实验室，跑实验，开始是在自己电脑上面跑，几天没关机，电脑硬盘直接挂掉了，后来直接网购了一个SSD硬盘，换了原来的硬盘，把原来的硬盘撞在了光驱位用来存放临时数据，开机和关机都快了很多，心情一下子就愉快了。八月份跑完实验后就开始写论文，投稿的经历就不说了，结果就是至今还在大修，接下来还需要继续做实验，慢慢改吧，有时候做梦都在调参数，希望能够早点做完吧，然后顺利的出去实习！不过在这方面真的要感谢一下自己的导师，不仅耐心的指导我们，还特别地亲民和善，很nice的一位老师。说到论文，自己从实验中还是学到了很多东西。从数据集的处理，到特征选取，然后如何去处理不均衡数据问题，再到算法的使用、选择、评估。整个流程重复了好多遍，很多原本对理论模棱两可的知识都进一步理解了。比如评估指标的计算、ROC曲线的绘制以及scikit-learn的使用等，收获算是比较大吧。八月之后，从九月开始，大大小小的事情确实比较多了，自己能够安排的时间并不多，可现在回头一想，这段时间也并没有做出什么成果，一直处于瞎忙的状态，结果也就是“郁郁而终”了。其实起初我对自己的时间是有计划的，只是突如其来的事情太多，再加上看论文作报告修改论文等等，一下子一个学期就过去了。唯一值得欣慰的就是拿到了今年的研究生国奖，“否极泰来，物极必反”，大概就是这样的吧。敲门声响起无数次，其它的都是诱惑，只有一次是机会，估计是把今年的运气都集在这里了。突然想到了那句话“上帝为你关上一扇门的同时,还打开了一扇天窗”！\n\n\n![fdsfsf](/assets/articleImg/2015-12-31-desktop.jpg)\n\n\n<div class=\"caption\">『上图是三月底的桌面，下图是十二月底的桌面，多了很多的书籍.』</div>\n\n\n在学习上还有一件让我印象比较深而且很难忘的事情，那就是今年一月下旬那会儿做的事情，应导师之需去配置实验室的cluster（集群）。当时自己压根就不知道cluster是什么，然后就去配置。当然，这里的cluster并不是大家常说的Hadoop，而是Torque，一种用于高性能计算的cluster。当时凭着之前自学的Linux知识，就从装系统开始，一步一步的去配。开始是在实验室的三台台式机器上做测试，只记得那会儿出错后就重装系统，很笨很笨的方式，遇到问题也只能去Google搜索，而那会儿对英文有种莫名恐惧的feel，想必大多数人都有过这种feel！经过几天之后，这三天机器配好了，然后就去配置服务器上的机器，一共开了62台虚拟机器，就我一个人，当时还是个小白，有问题也只能去Google。现在回想下，都不知道自己当时是怎么熬过来的，所幸还是把所有服务器配好了。最后集群之间可以通过NFS进行文件共享，还使用NIS对用户进行统一管理，只是对软件没有使用统一的管理方式，比如现在需要安装一个python库，那么我就需要给所有的机器都安装一遍，工作量太大，不科学。现在也想到了一种解决方法，就是将python安装在一个共享目录下，所有的库也安装在在此目录下，然后把这个目录mount到其它节点中，理论上是可以解决的。只是自那之后就没有对系统进行升级了，有时间再去折腾吧！！！\n\n最近应导师之需，让我想个方法把今年大家做的报告PPT集中起来，比如新建一个百度云账号，或者在我们的服务器上建立一个公共文件夹等。起初我自己想到的是在Github上面建立一个仓库，然后让大家都把东西上传到上面去，也比较方便，但是考虑到Github上面的仓库都是公共的（私有的需要付费），所以这个念头从一开始就被自己全盘否决了。后来想，在服务器上弄个ftp服务器怎么样呢？就这样一个想法，剩下的就是如何去实现。记得之前也有这个想法，五月份的时候，不过那时用的外网的服务器是学校的机器，因为当时配置完SELinux时重启了服务器，后来导致半个小时没启动成功。下面是当天的日记：\n\n> 2015.05.28 今天按照导师的要求在学校的服务器上挂载了我们自己内网服务器上的两个共享文件夹，成功了。后来导师说装一个Samba吧，我正打算在学校的服务器上装的时候，安装完了还没有配置，需要重启机器，我就使用reboot重启了，结果服务器启动不了了。我就纳闷了，这怎么可能。然后我就跟管理服务器的史大牛汇报了一下，因为他在北京，所以不能处理，就跟管理这台服务器的周老师说了。这不说还好，一说就被骂了。因为周老师都不知道我们有这台服务器的权限，这台服务器的密码还是史给我们的，这下把他坑惨了。差点把他从北京坑回来了。所幸没什么事，过了没多久服务器启动成功了。然后周老师把密码都给改了，因为我们实验室的路由器的网络和实验室服务器的网络是两个不同内网，不在一个局域网，使用PuTTY登陆不上去。之前是因为学校的服务器接了多个网卡，我们可以通过先登录到学校的服务器上，然后通过内网透析使用SSH切换到我们自己的服务器上，现在好了，没权限了，让给我们开个非root用户当做登陆用户都不肯，导师说学校那帮人最懒了，一点也不假呀，占着资源不肯放。然后晚上跟导师群聊了下，导师说我们干脆自己再买一台服务器算了，免得用学校的到时候出问题了又赖在我们头上。汗，只能这样了，加油吧，多学点linux操作~fighting！！！\n\n周老师将服务器密码改了之后，最后导师就干脆自己买了一台服务器。因为这台服务器的大多配置都是我配的，比较了解。因为对其他机器没什么依赖，所以重启机器也不会出任何问题。于是就打算在这台服务器上配置一个FTP服务器。因为配置服务器当天中午开完组会之后没休息，所以从开始到最后，用了将近一个下午的时间。碰到的一个比较简单的问题就是端口设置，如何让防火墙开放某个端口。去年自己在虚拟机上的centos6.5系统配置过这个，当时是直接将防火墙关闭掉，但现在考虑到安全问题，所以不能这么做了。其实只要弄懂了思路，整个配置也就显得简单了。如果默认端口号是21的话，可以直接直接访问[ftp://192.168.12.12]，不过我在配置vsftpd的时候修改了端口，所以需要在ip地址后面加上端口号，也就是类似这种[ftp://192.168.12.12:9999]。配置的时候，在细节上也碰到一些问题，不过通过google还是很容易就搜到结果的。总的来说，得到了一个小道理：对于小白来说，就是用时间去攒经验，用时间去买教训，所以必须自己去动手实践，这样才能得到更加直观的结果。而我希望我能够尽最大的速度攒更多的经验，买更多的教训。学习就是一个不断升华的过程，以前看似复杂而困难的问题，当你在相关知识上达到一定深度之后，它们都将随之而变的简单。现在能做的就是不断的去练习、去实践，然后去总结，化教训为经验！\n\n\n今年做过很多次小组报告，大多时候讲的主题都是与课题相关的论文。有时候自己在作报告的时候也会紧张，因为先前准备的不充分，很多论文中的东西还来不及理解，有时甚至连文章中的核心思想都还没完全弄懂，讲出来之后，大家可能也很迷惑。通过多次的锻炼，在这方面还是有了很大的提升，给我的教训就是：要做好一个报告，前提是自己要对这个报告主题内容详熟，能够达到那种完全脱稿的水平就再好不过了。这里说的脱稿并不是不看ppt，而是不要对着ppt上面的内容进行实读，要能够用自己的话进行总结，进行归纳，通过一个主题，自己能够扩展其他的内容，然后将语言表达通顺就OK了。在多次的报告讲解中我发现，如果是讲解自己的论文，那么完全不需要做太多的准备，毕竟整个实验过程自己都知道。另外，每次在讲解服务器的时候，思路很清晰，讲起来也很顺手，可能也是因为熟悉的原因吧！但是大家能不能听懂，又是另外一回事了吧，事实上我觉得听完之后能有个概念也就差不多了。\n\n\n谈完学习，下面来说说与娱乐有关的吧。很遗憾，今年并没有去过多少地方游玩，离学校最远的地方也只是张家界（虽然离家很近，但我却从未去过），走得较多的还是市内的景点吧，去过植物园，爬过岳麓山，逛过橘子洲等，还回过几次农大，摘过草莓，看过枫叶，顺便在校园里散散心。其实并不是自己不想出去，而是今年压根就没闲下来，或者说是自己不想闲吧。一方面，时间确实比较紧，一直奔波在宿舍与实验室之间，更多的是想多学点东西；另一方面，自己今年也确实没计划过要去别的地方，然后很快地一年就过了。曾经自己也想过要去哪些地方，走哪些路，看哪些风景，想在某年某月某一天，背起行囊去流浪。就这样，一个人，一个背包，还有一颗毅然行动的心，去一个陌生的地方。曾想象，一个人留恋于古色古香的苏杭，闲游于景色迷人的西湖，雷峰塔下，断桥旁边，坐于亭中观看行人匆匆，烟雨濛濛。提一壶新茗，浪迹天涯，悠然地寻找江南文化的气息。曾期待，一个人游走在车水马龙的外滩，越过黄浦江眺望远方的东方明珠，在一片灯红酒绿迷人的世界里，感叹着时代的变迁。曾盼望，一个人站在魅力弥漫的日光城下，看着那神圣的布达拉宫，听颂着来自上天的独白，随着飘动的经幡，传到遥远的他方。曾渴望，一个人漫步于浪漫之都，仰望埃菲尔铁塔，身处薰衣草花海，品尝法式甜点，惊叹画家之笔，触摸着法兰西风情熏陶下香榭丽舍的梧桐树。曾梦想，一个人浪迹在伦敦街头，乘一辆红色双层巴士，与阿狸一同探寻永远站的方向。然后寻一家小店，品位正宗英国红茶带来的英伦历史的沉淀，感受风雨后之的痕迹。就这样，一个人，一座城。然而，后来慢慢地变得开始理性了，渐渐地想的也多了，明白的东西也多了。那么还是让我现实点，踏实地做该做的事情吧！突然想到那句，“累就对了,舒服是留给死人的！”，是的，加油吧！时机到了，会有机会出去的（算是给自己一个安慰吧T_T！）。只需记住，越有故事的人越沉静简单，越肤浅单薄的人越浮躁不安。每一个优秀的人，都有一段沉默的时光。\n\n\n相比于游山玩山，今年做的最多的娱乐活动就是看电影了。回想了下，三月看了《帕丁顿熊》，四月看了吴京主演的《战狼》，还有《速度与激情7》，五月看了《何以笙箫默》，七月月看了《捉妖记》，八月看了《大圣归来》、九月看了《港囧》与《碟中谍5神秘国度》，十月看了《夏洛特烦恼》、《小王子》以及《蚁人》，就这些，有搞笑的，也有比较敷衍人的，总的来说还是比较开心，算是弥补了今年没有外出游玩的自己吧！还记得九月下旬那会儿，中秋在即，去了大学母校拜访了文静姐，一个正在享受着当母亲的老师。晚上请我吃了一顿大餐，还送给我一提月饼，感觉好幸福，所以我从来都不去羡慕别人家的老师啦^_^！十一月回农大看枫叶，逛了下校园，然后去红旗市场的溜冰场玩了一会儿，那时那地那景那情，缠绕于指尖，记忆犹深！其实我的爱好也很多的，比如摄影、爬山、溜冰、打桌球、唱K（属于瞎吼的那种）等等，当然也包括了学习（必要时还是得装一下，虽然装的不像）。只是现在除了想学好点，似乎对其它的东西都渐渐地失去了以往的热情，没有了那份心思和真诚，简单地说就是心不在此吧。都说在外待太久，会比较想家，可能我属于异类，回头想想，从过年后回校到现在，中途只回家待了三天，而且还待不住。比往年少了很多，以前至少暑假会回去，各方面的原因都有，可能真是因为自己长大了。其实长大并不可怕，可怕的应该是遗忘吧。\n\n\n![](/assets/articleImg/2015-12-31-movie_all1.jpg)\n\n<div class=\"caption\">『今年保留的所有电影票，与以往比较，多了很多.』</div>\n\n今年并没有得什么大病，只是生过两次小病，并无大碍，但生病的时候还是让人很难受的。一次是在六月底七月初的时候，由于喉咙发炎，接着引发了感冒，发烧，然后头晕，后来连噎食喉咙都痛，大夏天的真是受罪。另外一次是十二月，也是喉咙发炎，不过幸好及时吃了消炎药，没有恶化，第三天就好了。可前些日子，突然心脏部位略微阵痛，算是尝到了什么叫心痛，真正的心痛，应该是最近太累了，一个本命年，过的真是受罪。恩，对，本命年，已经二十四了！！！希望明年的自己能有一个健康的身体吧。写到这里，不禁地想总结一下自己今年的作息。从三月实训开时，早上八点半到晚上五点半待在机房，晚上直到十点多才离开实验室，持续到27号实训结束，一个月只外出三次，一次农大，一次植物园，一次新校区。四月，外出看过两次电影。五月接待同学一天，然后张家界来回三天。六月全月不外出。七月开始睡实验室，中途和小伙伴们聚餐一次，外出看电影一次。八月开始赶论文到中旬，加班至一两点。中下旬接待同学，外出两天，随后搬往宿舍休息。九月回家待了三天，同学聚餐一次，外出看电影两次，农大探望老师一次。十月导师组织烧烤活动一次，外出看电影三次。十一月去农大看枫叶一次。十二月同学结婚，外出两天。其余时间都待在了实验室。对我来说，似乎没有假期与周末可言吧，每天都是一样的日子，千篇一律，有时待到十一点左右才回去，还是那句话，“累就对了，舒服是留给死人的！”。一年的实验室生活，碰到过很多问题，也学到了很多。每一位苦行僧的背后大概都有一段不为人知的往事吧。事实上，如果自己想休息，倒也可以给自己放个假，自由但不放纵，收敛自如，感觉还是很自在、很舒服！毕竟除了待在实验室，也没有其他的地方可以去，似乎到了这里情绪有些低落！！！！\n\n\n![](/assets/articleImg/2015-12-31-lab-morning.jpg)\n\n<div class=\"caption\">『某天早晨，阳光从对面楼层的玻璃反射到我的卓子上，很温暖，特别的温馨.』</div>\n\n\n今年参与的活动不多，除了四月的时候研会举行的那次“最强班集体活动”外，还有一次就是十月中旬左右导师组织的野外烧烤了，其它的就是同学聚餐之类的。回想下四月份，那时的我还算比较积极，参加了好几个比赛项目，有的还拿到了第一名，不过不是个人赛啦。最后我们1402班拿下了冠军，奖励了400大洋呀，钱没发下来就先出去吃了顿好的，算是意料之外的收获吧。另外，印象比较深刻的就是那时的抽奖活动，至今都记忆犹新。也就是那些跟我一起的小伙伴每个人都抽到了奖品，唯独我没抽到，想必我应该就是那个传说中万中无一的人了(*^__^*)……。这应该不是巧合，运气太背了，于是乎“本命年”似乎又躺枪了，(^__^) ……。十月那会儿的烧烤活动，是由导师发起的，不过烧烤食物的原材料是由我和其他几个人一起去超市购买的。因为是第一次买这些食材，没有经验，份量更是不好估计，所幸最后大家都吃完了，关键是大家开心就好！\n\n\n事实上，每个人都有不开心的时候，我也一样，但我的不开心，我的难受，我都尽量留给了自己。只是很多时候，那些安慰别人的话，怎么也安慰不了自己。原因不详，有待细查！那么在这里，就让所有不开心的事情随着2015的离去而过去吧！似乎是从今年五月起，慢慢地开始戒掉了QQ、微信这些社交网络，不会再刻意地去翻阅手机动态，不再专注于回复别人或是查看别人的回复，开始做一个沉默寡言的人，事不关已的事也无需多去关心，只是偶尔会在Sina这样一个安静的人少的地方水水心情！现在，也已习惯了这种节奏，晚上回到宿舍，洗漱完之后也不再会像以往那样经常刷状态，反倒是给自己省下了很多时间做其他的事情！我的计划是明年上半年就出去实习，如果能够早点学校这边的事情搞完，自己也就多点时间复习面试知识。“没有三两三，哪敢上梁山”嘛，掂量掂量自己的水平，提前做好面试准备，也好有个心理准备。可能很多人都觉得我学的好，不过，自己到底有几斤几两，水深还是不深，自己还是有自知之明的，能够将自己80%的好表现出来就行了。Remember，你所恐惧的东西，最终都将变成你的弱点！每当一个人独处的时候，总会想到很多的事情。过去，现在，未来，总有自己可想的事。现在的我，更多的是希望好好把技术学扎实，锻炼好自己各方面能力吧。之前就说过这样一句话，“对现在的自己要求高点，就是给未来的自已最好的礼物！”，一点都没错。相信自己！每当翻阅浙大张弛原和张睿卿两位大牛的文章，总给我一种奋勇向上的激情。如果自己的知识能够达到一定的深度，即便是苦点累点或是慢点，也值了！自己选择的路，跪着也要走完。\n\n\n![](/assets/articleImg/2015-12-31-huatian.jpg)\n\n<div class=\"caption\">『今年十二月，大学室友结婚接新娘的那天早上在华天酒店拍的，当时还没系腰带.』</div>\n\n今年结婚的同学有两个，一位是大学时候的班长，一位是大学的一位室友。一个在二月，一个在十二月，很喜庆，一年好始好终的过了！班长结婚是在常德石门，因此几个有空的同学就跑到常德石门去祝福了，虽说参加别人的婚礼就像是花钱去看别人虐狗（开个玩笑），但有空还是要去的啦，至少还可以当个演员嘛^_^。在大学室友结婚那天也是挺开心的，当了一回伴郎。当伴郎收获比较多的就是，对整个婚礼的流程都了解的很清楚，当地的习俗也知道个大概。身为伴郎，在当天的酒席上并没有吃饭，只记得那天喝的有点多。那种酒席上的玻璃杯，喝了三大半杯白酒，只不过当伴郎喝酒也是没办法的事！随后应新郎支托给同学们开了间麻将房，接着去他们打麻将，自己就在里面睡了一下午，后来大脑虽然清醒，但真的很是难受，半醉半醒的状态更是不堪回首。毕竟我也是不喜欢喝酒的，当然也不抽烟，更谈不上喜欢了。说到吃的，其实我并不挑食，草莓，香蕉，水龙果，橘子好多水果都吃，喜欢喝咖啡，奶茶，绿茶，还喜欢嗑瓜子，最近又喜欢上夏威夷果子，而对巧克力也是无法抗拒的。以前还喜欢吃各类糖果，算一算也是蛮多的。只是如今一天到对着电脑，也顾不上吃这些水果零食了。说到大学同学，自从班长结婚之后，今年就很少聚了，大家交流的也很少了。一方面，大家应该都很忙吧，各自忙各自的，就像我一样。另一方面，可能班长结婚后，没有一个好的据点了吧！另外，听说有位同学已经奉子领证了，果真是士别三日当刮目相待呀！！！\n\n![](/assets/articleImg/2015-12-31-tiedao1.jpg)\n\n<div class=\"caption\">『学校的西门，摄于某个晴空万里的冬天下午.』</div>\n\n来到中南，步入一个新的地方，认识了新的同学，结交了新的朋友，进入了一种新的学习状态，一年又半载，很多事情都在不经意间就开始了，而我也早已习惯了这里的生活！数落着剩下的研途生涯，希望自己能够学到更多的东西吧。烟雾蒙蒙的今晚，已经看不到点点繁星了，望着天空残寂的孤月，明亮中夹带着些许凄美，些许迷离。唏嘘的叹息，在这无眠清寂的长夜里，留下无数的落寞。过往的点滴，都渐渐的在遗逝的记忆里沉淀。走过了似水流年，看过了风花雪月，曾经有一段时光，做了温馨的梦，曾经有一场梦，沧桑中透着凄凉，曾经也有一座城市，却成了一生的梦。夜已深，心已静，默默的守候着今年最后的一点时光，就此成为往后的回忆。。。\n\n\n![](/assets/articleImg/2015-12-31-bagong.jpg)\n\n<div class=\"caption\">『执着忠厚的八公.』</div>\n\n总之，好好奋斗吧……\n\n\n_我要稳稳的幸福  \n能抵挡失落的痛楚  \n一个人的路途  \n也不会孤独_  \n\n\n2016年，祝大家新年快乐！同时也希望自己在新的一年能有一个好的开始！\n\n\n\n---\n","slug":"2015-12-31-annual-summary","published":1,"updated":"2016-03-12T11:24:05.933Z","comments":1,"photos":[],"link":"","_id":"cimigpyvk004h6cujor1ya83u"},{"layout":"post","date":"2015-12-25T14:24:00.000Z","title":"25个Java机器学习工具&库(译)","comment":true,"_content":"\n本列表总结了25个Java机器学习工具&库：\n\n\n- 原文地址：[25 Java Machine Learning Tools & Libraries](http://bigdataanalyticsnews.com/25-java-machine-learning-tools-libraries/)\n- CSDN译文链接：http://www.csdn.net/article/2015-12-25/2826560\n\n<!-- more -->\n\n1.[Weka](http://www.cs.waikato.ac.nz/ml/weka/)集成了数据挖掘工作的机器学习算法。这些算法可以直接应用于一个数据集上或者你可以自己编写代码来调用。Weka包括一系列的工具，如数据预处理、分类、回归、聚类、关联规则以及可视化。\n\n2.[Massive Online Analysis](http://moa.cms.waikato.ac.nz/)（MOA）是一个面向数据流挖掘的流行开源框架，有着非常活跃的成长社区。它包括一系列的机器学习算法（分类、回归、聚类、异常检测、概念漂移检测和推荐系统）和评估工具。关联了WEKA项目，MOA也是用Java编写的，其扩展性更强。\n\n3.[MEKA](http://meka.sourceforge.net/)项目提供了一个面向多标签学习和评价方法的开源实现。在多标签分类中，我们要预测每个输入实例的多个输出变量。这与“普通”情况下只涉及一个单一目标变量的情形不同。此外，MEKA基于WEKA的机器学习工具包。\n\n4.[Advanced Data mining And Machine learning System](https://adams.cms.waikato.ac.nz/)（ADAMS）是一种新型的柔性工作流引擎，旨在迅速建立并保持真实世界的复杂知识流，它是基于GPLv3发行的。\n\n5.[Environment for Developing KDD-Applications Supported by Index-Structure](http://elki.dbs.ifi.lmu.de/)（ELKI）是一款基于Java的开源（AGPLv3）数据挖掘软件。ELKI主要集中于算法研究，重点研究聚类分析中的无监督方法和异常检测。\n\n6.[Mallet](http://mallet.cs.umass.edu/)是一个基于Java的面向文本文件的机器学习工具包。Mallet支持分类算法，如最大熵、朴素贝叶斯和决策树分类。\n\n7.[Encog](http://www.heatonresearch.com/encog)是一个先进的机器学习框架，集成了支持向量机（SVM）、人工神经网络、遗传算法、贝叶斯网络、隐马尔可夫模型（HMM）、遗传编程和遗传算法。\n\n8.[Datumbox](http://www.datumbox.com/)机器学习框架是一个用Java编写的开源框架，允许快速地开发机器学习和统计应用。该框架的核心重点包括大量的机器学习算法以及统计测试，能够处理中等规模的数据集。\n\n9.[Deeplearning4j](http://deeplearning4j.org/)是使用Java和Scala编写的第一个商业级的、开源的、分布式深入学习库。其设计的目的是用于商业环境中，而不是作为一个研究工具。\n\n10.[Mahout](http://mahout.apache.org/)是一个内置算法的机器学习框架。Mahout-Samsara帮助人们创建他们自己的数学，并提供了一些现成的算法实现。\n\n11[Rapid Miner](https://rapidminer.com/)是德国多特蒙特技术大学开发的。它为开发者开发应用程序提供了一个GUI（图形用户界面）和Java API。它还提供了一些机器学习算法，用来做数据处理、可视化以及建模。\n\n12.[Apache SAMOA](http://samoa.incubator.apache.org/)是一个机器学习（ML）框架，内嵌面向分布式流ML算法的编程抽象，并且允许在没有直接处理底层分布式流处理引擎（DSPEe，如Apache Storm、Apache S4和Apache samza）复杂性的情况下，开发新的ML算法。用户可以开发分布式流ML算法，而且可以在多个DSPEs上执行。\n\n13.[Neuroph](http://neuroph.sourceforge.net/)通过提供支持创建、训练和保存神经网络的Java网络库和GUI工具，简化了神经网络开发。\n\n14.[Oryx 2](http://oryx.io/)是一个建立在Apache Spark和Apache Kafka的Lambda架构实现，但随着实时大规模机器学习而逐渐开始专业化。这是一个用于构建应用程序的框架，但也包括打包，以及面向协同过滤、分类、回归和聚类的端到端的应用程序。\n\n15.[Stanford Classifier](http://nlp.stanford.edu/software/classifier.shtml)是一个机器学习工具，它可以将数据项归置到一个类别。一个概率分类器，比如这个，它可以对一个数据项给出类分配的概率分布。该软件是最大熵分类器的一个Java实现。\n\n16[io](http://www.cortical.io/)是一个Retina API，有着快速精确的类似大脑的自然语言处理算法。\n\n17.[JSAT](https://github.com/EdwardRaff/JSAT/tree/master)是一个快速入门的机器学习库。该库是我在业余时间开发的，基于GPL3发行的。库中的一部分内容可自主学习，例如所有的代码都是独立的。JSAT没有外部依赖，而且是纯Java编写的。\n\n18.[N-Dimensional Arrays for Java(ND4J)](http://nd4j.org/)是一个用于JVM的科学计算库。它们是用来在生产环境中使用的，这表明例程的设计是以最小的内存需求来运行的。\n\n19.[Java Machine Learning Library](https://www.openhub.net/p/8582)（Java机器学习库）是一系列机器学习算法的相关实现。这些算法，无论是源代码还是文档，都编写的很出色。其主要语言是Java。\n\n20.[Java-ML](http://java-ml.sourceforge.net/)是一个使用Java编写的一系列机器学习算法的Java API。它只提供了一个标准的算法接口。\n\n21.[MLlib(Spark)](http://spark.apache.org/mllib/) 是Apache Spark的可扩展机器学习库。虽然是Java，但该库与平台还支持Java，Scala和Python绑定。此库是最新的，并且算法很多。\n\n22.[H2O](https://github.com/h2oai/h2o-3)是用于智能应用的机器学习API。它在大数据上对统计学、机器学习和数学进行了规模化。H2O可扩展，开发者可以在核心部分使用简单的数学知识。\n\n23.[WalnutiQ](https://github.com/WalnutiQ/wAlnut)是人脑部分面向对象模型，有着理论常用的学习算法（正在向简单强烈的情感人工智能模型方向研究）。\n\n24.[RankLib](http://sourceforge.net/p/lemur/wiki/RankLib/)是一个排名学习算法库。目前已经实现八种流行的算法。\n\n25.[htm.java](https://github.com/numenta/htm.java)（基于Java的Hierarchical Temporal Memory算法实现）是一个面向智能计算的Numenta平台的Java接口。[源码](http://www.demnag.com/b/java-machine-learning-tools-libraries-cm570/)\n\n\n\n---\n\n","source":"_posts/2015-12-25-25-Java-Machine-Learning-Tools-&-Libraries.md","raw":"---\nlayout: post\ndate: 2015-12-25 22:24\ntitle: \"25个Java机器学习工具&库(译)\"\ncategories: ML\ntag: \n\t- Machine Learning\n\t- 译文\n\t- 框架&库 \ncomment: true\n---\n\n本列表总结了25个Java机器学习工具&库：\n\n\n- 原文地址：[25 Java Machine Learning Tools & Libraries](http://bigdataanalyticsnews.com/25-java-machine-learning-tools-libraries/)\n- CSDN译文链接：http://www.csdn.net/article/2015-12-25/2826560\n\n<!-- more -->\n\n1.[Weka](http://www.cs.waikato.ac.nz/ml/weka/)集成了数据挖掘工作的机器学习算法。这些算法可以直接应用于一个数据集上或者你可以自己编写代码来调用。Weka包括一系列的工具，如数据预处理、分类、回归、聚类、关联规则以及可视化。\n\n2.[Massive Online Analysis](http://moa.cms.waikato.ac.nz/)（MOA）是一个面向数据流挖掘的流行开源框架，有着非常活跃的成长社区。它包括一系列的机器学习算法（分类、回归、聚类、异常检测、概念漂移检测和推荐系统）和评估工具。关联了WEKA项目，MOA也是用Java编写的，其扩展性更强。\n\n3.[MEKA](http://meka.sourceforge.net/)项目提供了一个面向多标签学习和评价方法的开源实现。在多标签分类中，我们要预测每个输入实例的多个输出变量。这与“普通”情况下只涉及一个单一目标变量的情形不同。此外，MEKA基于WEKA的机器学习工具包。\n\n4.[Advanced Data mining And Machine learning System](https://adams.cms.waikato.ac.nz/)（ADAMS）是一种新型的柔性工作流引擎，旨在迅速建立并保持真实世界的复杂知识流，它是基于GPLv3发行的。\n\n5.[Environment for Developing KDD-Applications Supported by Index-Structure](http://elki.dbs.ifi.lmu.de/)（ELKI）是一款基于Java的开源（AGPLv3）数据挖掘软件。ELKI主要集中于算法研究，重点研究聚类分析中的无监督方法和异常检测。\n\n6.[Mallet](http://mallet.cs.umass.edu/)是一个基于Java的面向文本文件的机器学习工具包。Mallet支持分类算法，如最大熵、朴素贝叶斯和决策树分类。\n\n7.[Encog](http://www.heatonresearch.com/encog)是一个先进的机器学习框架，集成了支持向量机（SVM）、人工神经网络、遗传算法、贝叶斯网络、隐马尔可夫模型（HMM）、遗传编程和遗传算法。\n\n8.[Datumbox](http://www.datumbox.com/)机器学习框架是一个用Java编写的开源框架，允许快速地开发机器学习和统计应用。该框架的核心重点包括大量的机器学习算法以及统计测试，能够处理中等规模的数据集。\n\n9.[Deeplearning4j](http://deeplearning4j.org/)是使用Java和Scala编写的第一个商业级的、开源的、分布式深入学习库。其设计的目的是用于商业环境中，而不是作为一个研究工具。\n\n10.[Mahout](http://mahout.apache.org/)是一个内置算法的机器学习框架。Mahout-Samsara帮助人们创建他们自己的数学，并提供了一些现成的算法实现。\n\n11[Rapid Miner](https://rapidminer.com/)是德国多特蒙特技术大学开发的。它为开发者开发应用程序提供了一个GUI（图形用户界面）和Java API。它还提供了一些机器学习算法，用来做数据处理、可视化以及建模。\n\n12.[Apache SAMOA](http://samoa.incubator.apache.org/)是一个机器学习（ML）框架，内嵌面向分布式流ML算法的编程抽象，并且允许在没有直接处理底层分布式流处理引擎（DSPEe，如Apache Storm、Apache S4和Apache samza）复杂性的情况下，开发新的ML算法。用户可以开发分布式流ML算法，而且可以在多个DSPEs上执行。\n\n13.[Neuroph](http://neuroph.sourceforge.net/)通过提供支持创建、训练和保存神经网络的Java网络库和GUI工具，简化了神经网络开发。\n\n14.[Oryx 2](http://oryx.io/)是一个建立在Apache Spark和Apache Kafka的Lambda架构实现，但随着实时大规模机器学习而逐渐开始专业化。这是一个用于构建应用程序的框架，但也包括打包，以及面向协同过滤、分类、回归和聚类的端到端的应用程序。\n\n15.[Stanford Classifier](http://nlp.stanford.edu/software/classifier.shtml)是一个机器学习工具，它可以将数据项归置到一个类别。一个概率分类器，比如这个，它可以对一个数据项给出类分配的概率分布。该软件是最大熵分类器的一个Java实现。\n\n16[io](http://www.cortical.io/)是一个Retina API，有着快速精确的类似大脑的自然语言处理算法。\n\n17.[JSAT](https://github.com/EdwardRaff/JSAT/tree/master)是一个快速入门的机器学习库。该库是我在业余时间开发的，基于GPL3发行的。库中的一部分内容可自主学习，例如所有的代码都是独立的。JSAT没有外部依赖，而且是纯Java编写的。\n\n18.[N-Dimensional Arrays for Java(ND4J)](http://nd4j.org/)是一个用于JVM的科学计算库。它们是用来在生产环境中使用的，这表明例程的设计是以最小的内存需求来运行的。\n\n19.[Java Machine Learning Library](https://www.openhub.net/p/8582)（Java机器学习库）是一系列机器学习算法的相关实现。这些算法，无论是源代码还是文档，都编写的很出色。其主要语言是Java。\n\n20.[Java-ML](http://java-ml.sourceforge.net/)是一个使用Java编写的一系列机器学习算法的Java API。它只提供了一个标准的算法接口。\n\n21.[MLlib(Spark)](http://spark.apache.org/mllib/) 是Apache Spark的可扩展机器学习库。虽然是Java，但该库与平台还支持Java，Scala和Python绑定。此库是最新的，并且算法很多。\n\n22.[H2O](https://github.com/h2oai/h2o-3)是用于智能应用的机器学习API。它在大数据上对统计学、机器学习和数学进行了规模化。H2O可扩展，开发者可以在核心部分使用简单的数学知识。\n\n23.[WalnutiQ](https://github.com/WalnutiQ/wAlnut)是人脑部分面向对象模型，有着理论常用的学习算法（正在向简单强烈的情感人工智能模型方向研究）。\n\n24.[RankLib](http://sourceforge.net/p/lemur/wiki/RankLib/)是一个排名学习算法库。目前已经实现八种流行的算法。\n\n25.[htm.java](https://github.com/numenta/htm.java)（基于Java的Hierarchical Temporal Memory算法实现）是一个面向智能计算的Numenta平台的Java接口。[源码](http://www.demnag.com/b/java-machine-learning-tools-libraries-cm570/)\n\n\n\n---\n\n","slug":"2015-12-25-25-Java-Machine-Learning-Tools-&-Libraries","published":1,"updated":"2016-03-08T09:04:26.439Z","comments":1,"photos":[],"link":"","_id":"cimigpyvn004m6cujjjrgqfrz"},{"title":"LeetCode题解目录[待更新]","layout":"post","date":"2015-12-11T16:00:00.000Z","comments":1,"_content":"\n原文链接：http://www.csuldw.com/2015/12/12/2015-12-12-LeetCode-ans/\n\n本文是先前做LeetCode时的题解目录，代码有C++编写的，也有python编写的【内容待更新】。\n\n注：目录是使用python编码排序的，非手工排版。\n\n![leetcode](/assets/articleImg/2015-12-12-leetcode.png)\n\n<!--more--> \n\n<a target='black' href='http://www.csuldw.com/leetcode/LeetCode[155]-Min Stack.html'>LeetCode[155]-Min Stack</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[100]-Same Tree.html'>Leetcode[100]-Same Tree</a> \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[101]-Symmetric Tree.html'>Leetcode[101]-Symmetric Tree</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[102]-Binary Tree Level Order Traversal.html'>Leetcode[102]-Binary Tree Level Order Traversal</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[103]-Binary Tree Zigzag Level Order Traversal.html'>Leetcode[103]-Binary Tree Zigzag Level Order Traversal</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[104]-Maximum Depth of Binary Tree.html'>Leetcode[104]-Maximum Depth of Binary Tree</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[107]-Binary Tree Level Order Traversal II.html'>Leetcode[107]-Binary Tree Level Order Traversal II</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[110]-Balanced Binary Tree.html'>Leetcode[110]-Balanced Binary Tree</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[111]-Minimum Depth of Binary Tree.html'>Leetcode[111]-Minimum Depth of Binary Tree</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[113]-Path Sum II.html'>Leetcode[113]-Path Sum II</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[114]-Flatten Binary Tree to Linked List.html'>Leetcode[114]-Flatten Binary Tree to Linked List</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[118]-Pascal's Triangle.html'>Leetcode[118]-Pascal's Triangle</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[119]-Pascal's Triangle II.html'>Leetcode[119]-Pascal's Triangle II</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[125]-Valid Palindrome.html'>Leetcode[125]-Valid Palindrome</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[128]-Longest Consecutive Sequence.html'>Leetcode[128]-Longest Consecutive Sequence</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[129]-Sum Root to Leaf Numbers.html'>Leetcode[129]-Sum Root to Leaf Numbers</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[12]-Integer to Roman+++.html'>Leetcode[12]-Integer to Roman+++</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[136]-Single Number.html'>Leetcode[136]-Single Number</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[137]-Single Number II.html'>Leetcode[137]-Single Number II</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[13]-Roman to Integer+++.html'>Leetcode[13]-Roman to Integer+++</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[141]-Linked List Cycle.html'>Leetcode[141]-Linked List Cycle</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[143]-Reorder List.html'>Leetcode[143]-Reorder List</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[144]-Binary Tree Preorder Traversal.html'>Leetcode[144]-Binary Tree Preorder Traversal</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[145]-Binary Tree Postorder Traversal.html'>Leetcode[145]-Binary Tree Postorder Traversal</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[147]-Insertion Sort List.html'>Leetcode[147]-Insertion Sort List</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[148]-Sort List.html'>Leetcode[148]-Sort List</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[153]-Find Minimum in Rotated Sorted Array.html'>Leetcode[153]-Find Minimum in Rotated Sorted Array</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[154]-Find Minimum in Rotated Sorted Array II.html'>Leetcode[154]-Find Minimum in Rotated Sorted Array II</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[15]-3Sum.html'>Leetcode[15]-3Sum</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[162]-Find Peak Element.html'>Leetcode[162]-Find Peak Element</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[169]-Majority Element.html'>Leetcode[169]-Majority Element</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[173]-Binary Search Tree Iterator.html'>Leetcode[173]-Binary Search Tree Iterator</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[189]-Rotate Array.html'>Leetcode[189]-Rotate Array</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[18]-4Sum.html'>Leetcode[18]-4Sum</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[191]-Number of Bits.html'>Leetcode[191]-Number of Bits</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[198]-House Robber.html'>Leetcode[198]-House Robber</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[19]-Remove Nth Node From End of List.html'>Leetcode[19]-Remove Nth Node From End of List</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[1]-Two Sum.html'>Leetcode[1]-Two Sum</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[202]-Happy Number.html'>Leetcode[202]-Happy Number</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[203]-Remove Linked List Elements.html'>Leetcode[203]-Remove Linked List Elements</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[206]-Reverse Linked List.html'>Leetcode[206]-Reverse Linked List</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[20]-Valid Parentheses.html'>Leetcode[20]-Valid Parentheses</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[215]-Kth Largest Element in an Array.html'>Leetcode[215]-Kth Largest Element in an Array</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[217]-Contains Duplicate.html'>Leetcode[217]-Contains Duplicate</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[219]-Contains Duplicate II.html'>Leetcode[219]-Contains Duplicate II</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[21]-Merge Two Sorted Lists.html'>Leetcode[21]-Merge Two Sorted Lists</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[222]-Count Complete Tree Nodes.html'>Leetcode[222]-Count Complete Tree Nodes</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[226]-Invert Binary Tree.html'>Leetcode[226]-Invert Binary Tree</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[231]-Power of Two.html'>Leetcode[231]-Power of Two</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[237]-Delete Node in a Linked List.html'>Leetcode[237]-Delete Node in a Linked List</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[242]-Valid Anagram.html'>Leetcode[242]-Valid Anagram</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[258]-Add Digits.html'>Leetcode[258]-Add Digits</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[260]-Single Number III.html'>Leetcode[260]-Single Number III</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[263]-Ugly Number++.html'>Leetcode[263]-Ugly Number++</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[26]-Remove Duplicates from Sorted Array.html'>Leetcode[26]-Remove Duplicates from Sorted Array</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[27]-Remove Element.html'>Leetcode[27]-Remove Element</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[283]-Move Zeroes.html'>Leetcode[283]-Move Zeroes</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[292]-Nim Game.html'>Leetcode[292]-Nim Game</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[300]-Longest Increasing Subsequence.html'>Leetcode[300]-Longest Increasing Subsequence</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[33]-Search in Rotated Sorted Array.html'>Leetcode[33]-Search in Rotated Sorted Array</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[35]-Search Insert Position.html'>Leetcode[35]-Search Insert Position</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[36]-Valid Sudoku.html'>Leetcode[36]-Valid Sudoku</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[4]-Median of Two Sorted Arrays.html'>Leetcode[4]-Median of Two Sorted Arrays</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[53]-Maximum Subarray.html'>Leetcode[53]-Maximum Subarray</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[62]-Unique Paths.html'>Leetcode[62]-Unique Paths</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[63]-Unique Paths II.html'>Leetcode[63]-Unique Paths II</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[66]-Plus One.html'>Leetcode[66]-Plus One</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[70]-Climbing Stairs.html'>Leetcode[70]-Climbing Stairs</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[74]-Search a 2D Matrix.html'>Leetcode[74]-Search a 2D Matrix</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[7]-Reverse Integer.html'>Leetcode[7]-Reverse Integer</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[81]-Search for a Range.html'>Leetcode[81]-Search for a Range</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[82]-Remove Duplicates from Sorted List II.html'>Leetcode[82]-Remove Duplicates from Sorted List II</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[83]-Remove Duplicates from Sorted List.html'>Leetcode[83]-Remove Duplicates from Sorted List</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[86]-Partition List.html'>Leetcode[86]-Partition List</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[88]-Merge Sorted Array.html'>Leetcode[88]-Merge Sorted Array</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[92]-Reverse Linked List II.html'>Leetcode[92]-Reverse Linked List II</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[94]-Binary Tree Inorder Traversal.html'>Leetcode[94]-Binary Tree Inorder Traversal</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[96]-Unique Binary Search Trees.html'>Leetcode[96]-Unique Binary Search Trees</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[98]-Validate Binary Search Tree.html'>Leetcode[98]-Validate Binary Search Tree</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[9]-Palindrome Number.html'>Leetcode[9]-Palindrome Number</a>  \n","source":"_posts/2015-12-12-LeetCode-ans.md","raw":"---\ntitle: \"LeetCode题解目录[待更新]\"\nlayout: post\ndate: 2015-12-12\ncategories: 算法与数据结构\ntag: \n\t- LeetCode\n\t- 数据结构\ncomments: true\n---\n\n原文链接：http://www.csuldw.com/2015/12/12/2015-12-12-LeetCode-ans/\n\n本文是先前做LeetCode时的题解目录，代码有C++编写的，也有python编写的【内容待更新】。\n\n注：目录是使用python编码排序的，非手工排版。\n\n![leetcode](/assets/articleImg/2015-12-12-leetcode.png)\n\n<!--more--> \n\n<a target='black' href='http://www.csuldw.com/leetcode/LeetCode[155]-Min Stack.html'>LeetCode[155]-Min Stack</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[100]-Same Tree.html'>Leetcode[100]-Same Tree</a> \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[101]-Symmetric Tree.html'>Leetcode[101]-Symmetric Tree</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[102]-Binary Tree Level Order Traversal.html'>Leetcode[102]-Binary Tree Level Order Traversal</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[103]-Binary Tree Zigzag Level Order Traversal.html'>Leetcode[103]-Binary Tree Zigzag Level Order Traversal</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[104]-Maximum Depth of Binary Tree.html'>Leetcode[104]-Maximum Depth of Binary Tree</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[107]-Binary Tree Level Order Traversal II.html'>Leetcode[107]-Binary Tree Level Order Traversal II</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[110]-Balanced Binary Tree.html'>Leetcode[110]-Balanced Binary Tree</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[111]-Minimum Depth of Binary Tree.html'>Leetcode[111]-Minimum Depth of Binary Tree</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[113]-Path Sum II.html'>Leetcode[113]-Path Sum II</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[114]-Flatten Binary Tree to Linked List.html'>Leetcode[114]-Flatten Binary Tree to Linked List</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[118]-Pascal's Triangle.html'>Leetcode[118]-Pascal's Triangle</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[119]-Pascal's Triangle II.html'>Leetcode[119]-Pascal's Triangle II</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[125]-Valid Palindrome.html'>Leetcode[125]-Valid Palindrome</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[128]-Longest Consecutive Sequence.html'>Leetcode[128]-Longest Consecutive Sequence</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[129]-Sum Root to Leaf Numbers.html'>Leetcode[129]-Sum Root to Leaf Numbers</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[12]-Integer to Roman+++.html'>Leetcode[12]-Integer to Roman+++</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[136]-Single Number.html'>Leetcode[136]-Single Number</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[137]-Single Number II.html'>Leetcode[137]-Single Number II</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[13]-Roman to Integer+++.html'>Leetcode[13]-Roman to Integer+++</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[141]-Linked List Cycle.html'>Leetcode[141]-Linked List Cycle</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[143]-Reorder List.html'>Leetcode[143]-Reorder List</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[144]-Binary Tree Preorder Traversal.html'>Leetcode[144]-Binary Tree Preorder Traversal</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[145]-Binary Tree Postorder Traversal.html'>Leetcode[145]-Binary Tree Postorder Traversal</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[147]-Insertion Sort List.html'>Leetcode[147]-Insertion Sort List</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[148]-Sort List.html'>Leetcode[148]-Sort List</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[153]-Find Minimum in Rotated Sorted Array.html'>Leetcode[153]-Find Minimum in Rotated Sorted Array</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[154]-Find Minimum in Rotated Sorted Array II.html'>Leetcode[154]-Find Minimum in Rotated Sorted Array II</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[15]-3Sum.html'>Leetcode[15]-3Sum</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[162]-Find Peak Element.html'>Leetcode[162]-Find Peak Element</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[169]-Majority Element.html'>Leetcode[169]-Majority Element</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[173]-Binary Search Tree Iterator.html'>Leetcode[173]-Binary Search Tree Iterator</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[189]-Rotate Array.html'>Leetcode[189]-Rotate Array</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[18]-4Sum.html'>Leetcode[18]-4Sum</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[191]-Number of Bits.html'>Leetcode[191]-Number of Bits</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[198]-House Robber.html'>Leetcode[198]-House Robber</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[19]-Remove Nth Node From End of List.html'>Leetcode[19]-Remove Nth Node From End of List</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[1]-Two Sum.html'>Leetcode[1]-Two Sum</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[202]-Happy Number.html'>Leetcode[202]-Happy Number</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[203]-Remove Linked List Elements.html'>Leetcode[203]-Remove Linked List Elements</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[206]-Reverse Linked List.html'>Leetcode[206]-Reverse Linked List</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[20]-Valid Parentheses.html'>Leetcode[20]-Valid Parentheses</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[215]-Kth Largest Element in an Array.html'>Leetcode[215]-Kth Largest Element in an Array</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[217]-Contains Duplicate.html'>Leetcode[217]-Contains Duplicate</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[219]-Contains Duplicate II.html'>Leetcode[219]-Contains Duplicate II</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[21]-Merge Two Sorted Lists.html'>Leetcode[21]-Merge Two Sorted Lists</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[222]-Count Complete Tree Nodes.html'>Leetcode[222]-Count Complete Tree Nodes</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[226]-Invert Binary Tree.html'>Leetcode[226]-Invert Binary Tree</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[231]-Power of Two.html'>Leetcode[231]-Power of Two</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[237]-Delete Node in a Linked List.html'>Leetcode[237]-Delete Node in a Linked List</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[242]-Valid Anagram.html'>Leetcode[242]-Valid Anagram</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[258]-Add Digits.html'>Leetcode[258]-Add Digits</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[260]-Single Number III.html'>Leetcode[260]-Single Number III</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[263]-Ugly Number++.html'>Leetcode[263]-Ugly Number++</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[26]-Remove Duplicates from Sorted Array.html'>Leetcode[26]-Remove Duplicates from Sorted Array</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[27]-Remove Element.html'>Leetcode[27]-Remove Element</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[283]-Move Zeroes.html'>Leetcode[283]-Move Zeroes</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[292]-Nim Game.html'>Leetcode[292]-Nim Game</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[300]-Longest Increasing Subsequence.html'>Leetcode[300]-Longest Increasing Subsequence</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[33]-Search in Rotated Sorted Array.html'>Leetcode[33]-Search in Rotated Sorted Array</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[35]-Search Insert Position.html'>Leetcode[35]-Search Insert Position</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[36]-Valid Sudoku.html'>Leetcode[36]-Valid Sudoku</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[4]-Median of Two Sorted Arrays.html'>Leetcode[4]-Median of Two Sorted Arrays</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[53]-Maximum Subarray.html'>Leetcode[53]-Maximum Subarray</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[62]-Unique Paths.html'>Leetcode[62]-Unique Paths</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[63]-Unique Paths II.html'>Leetcode[63]-Unique Paths II</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[66]-Plus One.html'>Leetcode[66]-Plus One</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[70]-Climbing Stairs.html'>Leetcode[70]-Climbing Stairs</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[74]-Search a 2D Matrix.html'>Leetcode[74]-Search a 2D Matrix</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[7]-Reverse Integer.html'>Leetcode[7]-Reverse Integer</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[81]-Search for a Range.html'>Leetcode[81]-Search for a Range</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[82]-Remove Duplicates from Sorted List II.html'>Leetcode[82]-Remove Duplicates from Sorted List II</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[83]-Remove Duplicates from Sorted List.html'>Leetcode[83]-Remove Duplicates from Sorted List</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[86]-Partition List.html'>Leetcode[86]-Partition List</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[88]-Merge Sorted Array.html'>Leetcode[88]-Merge Sorted Array</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[92]-Reverse Linked List II.html'>Leetcode[92]-Reverse Linked List II</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[94]-Binary Tree Inorder Traversal.html'>Leetcode[94]-Binary Tree Inorder Traversal</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[96]-Unique Binary Search Trees.html'>Leetcode[96]-Unique Binary Search Trees</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[98]-Validate Binary Search Tree.html'>Leetcode[98]-Validate Binary Search Tree</a>  \n<a target='black' href='http://www.csuldw.com/leetcode/Leetcode[9]-Palindrome Number.html'>Leetcode[9]-Palindrome Number</a>  \n","slug":"2015-12-12-LeetCode-ans","published":1,"updated":"2016-03-24T03:04:53.331Z","photos":[],"link":"","_id":"cimigpyvu004s6cujfv70tpf4"},{"layout":"post","date":"2015-12-04T01:03:00.000Z","title":"Python笔记-均值列表","_content":"\n一个小小的实例，做个小笔记！\n\n比如有三个列表，列表元素均为数值型，三个列表的长度都一样，现在我想要求这三个列表的均值，即求一个均值列表，对应元素为上述三个列表对应元素的均值。\n\n<!--more-->\n\n\n代码实现如下：\n\n```\ndef meanMethod(one,two,three):\n    comb = zip(one,two,three)\n    return [float(i+j+k)/3 for i,j,k in comb]\n```\n\n第二行使用的是zip函数，先将三个列表合并起来，zip函数返回的是一个列表，但里面的元素是一个元组。\n\n第三行是列表推导式，计算comb每个元组的均值。","source":"_posts/2015-12-04-Python-two-list-add-item-add-item.md","raw":"---\nlayout: post\ndate: 2015-12-04 09:03\ntitle: \"Python笔记-均值列表\"\ncategories: Python\ntags:\n\t- Python\n---\n\n一个小小的实例，做个小笔记！\n\n比如有三个列表，列表元素均为数值型，三个列表的长度都一样，现在我想要求这三个列表的均值，即求一个均值列表，对应元素为上述三个列表对应元素的均值。\n\n<!--more-->\n\n\n代码实现如下：\n\n```\ndef meanMethod(one,two,three):\n    comb = zip(one,two,three)\n    return [float(i+j+k)/3 for i,j,k in comb]\n```\n\n第二行使用的是zip函数，先将三个列表合并起来，zip函数返回的是一个列表，但里面的元素是一个元组。\n\n第三行是列表推导式，计算comb每个元组的均值。","slug":"2015-12-04-Python-two-list-add-item-add-item","published":1,"updated":"2016-03-13T05:54:06.975Z","comments":1,"photos":[],"link":"","_id":"cimigpyw2004z6cujkbzlolvy"},{"layout":"post","date":"2015-12-04T04:12:00.000Z","title":"Python笔记-几种取整方式","_content":"\n## 背景\n\n　　在处理数据的时候，碰到了一个问题，就是取整方式！比如给定一个数值型列表，我需要分别获取它位置为长度的0%,25%,50%,75%,100%处的几个数字。但Python自带的`int`是向下取整，如果数字长度是5，理论上这五个数字分别对应0%,25%,50%,75%,100%的位置，但使用`int`，结果却并不是入次。比如当`5*0.75`时,如果加上`int(5*0.75)`，就等于`3`，而我想要的应该是4，显然不是我想要的，所以这里需要用到向上取整方式。因此，顺便总结了一下Python的几种取整方式。\n\n<!--more-->\n\n## 取整方式\n\n　　下面介绍几种常用的取整方法，包括向下取整、四舍五入、向上取整。\n\n### （1）向下取整\n\n　　向下取整很简单，直接使用int()函数即可，如下代码(Python 2.7.5 IDLE)\n\n```\n>>> a = 3.75\n>>> int(a)\n3 \n```\n\n### （2）四舍五入\n\n　　第二种就是对数字进行四舍五入，具体的看下面的代码：\n\n```\n>>> a=3.25;b=3.75\n>>> round(a);round(b)\n3.0\n4.0\n```\n\n## （3)向上取整\n\n　　但三种，就是向上取整，也就是我这次数据处理中需要的，由于之前没在Python中用到过，所以不太熟悉，其实Python的math中就带了向上取整的函数，即`ceil`方法，专门用于向上取整，实例如下：\n\n\n```\n>>> import math\n>>> math.ceil(3.25)\n4.0\n>>> math.ceil(3.75)\n4.0\n```\n\n\n\n好了，取整方式，大概就是这三种，介绍到此吧！","source":"_posts/2015-12-04-Python-Round.md","raw":"---\nlayout: post\ndate: 2015-12-04 12:12\ntitle: \"Python笔记-几种取整方式\"\ncategories: Python\ntags:\n\t- Python\n---\n\n## 背景\n\n　　在处理数据的时候，碰到了一个问题，就是取整方式！比如给定一个数值型列表，我需要分别获取它位置为长度的0%,25%,50%,75%,100%处的几个数字。但Python自带的`int`是向下取整，如果数字长度是5，理论上这五个数字分别对应0%,25%,50%,75%,100%的位置，但使用`int`，结果却并不是入次。比如当`5*0.75`时,如果加上`int(5*0.75)`，就等于`3`，而我想要的应该是4，显然不是我想要的，所以这里需要用到向上取整方式。因此，顺便总结了一下Python的几种取整方式。\n\n<!--more-->\n\n## 取整方式\n\n　　下面介绍几种常用的取整方法，包括向下取整、四舍五入、向上取整。\n\n### （1）向下取整\n\n　　向下取整很简单，直接使用int()函数即可，如下代码(Python 2.7.5 IDLE)\n\n```\n>>> a = 3.75\n>>> int(a)\n3 \n```\n\n### （2）四舍五入\n\n　　第二种就是对数字进行四舍五入，具体的看下面的代码：\n\n```\n>>> a=3.25;b=3.75\n>>> round(a);round(b)\n3.0\n4.0\n```\n\n## （3)向上取整\n\n　　但三种，就是向上取整，也就是我这次数据处理中需要的，由于之前没在Python中用到过，所以不太熟悉，其实Python的math中就带了向上取整的函数，即`ceil`方法，专门用于向上取整，实例如下：\n\n\n```\n>>> import math\n>>> math.ceil(3.25)\n4.0\n>>> math.ceil(3.75)\n4.0\n```\n\n\n\n好了，取整方式，大概就是这三种，介绍到此吧！","slug":"2015-12-04-Python-Round","published":1,"updated":"2016-03-08T09:02:37.645Z","comments":1,"photos":[],"link":"","_id":"cimigpyw700526cujo8lw5ang"},{"layout":"post","date":"2015-12-02T02:24:00.000Z","title":"EM-最大期望算法","comment":true,"_content":"\n对于EM算法，一直都是云里雾里琢磨不清。所以，今天索性就下个决定，不搞懂它，善不罢休。通过今天的学习，加上之前的基础，EM算法终于算是搞明白了。果真是做事不冲动点，真的很难有结果。下面，我打算将EM算法的整个推导过程通俗地来讲解一遍，虽然网上也有很多EM算法的理论知识讲解，但我觉得只有自己再来整理并总结一遍，才能理解的更加透彻，这样收获的知识也会更多。\n\n根据自己的博文写作风格，首先来看一张EM算法的聚类图，来自wikipedia，效果直观点。\n\n![](/assets/articleImg/2015-12-02-EM_Clustering_of_Old_Faithful_data.gif)\n\n<!--more-->\n\n期望最大算法是一种从不完全数据或有数据丢失的数据集（存在隐含变量）中求解概率模型参数的最大似然估计方法。EM算法是机器学习十大算法之一，之所以被纳入十大算法之中，是因为它解决了其它算法解决不了的问题或者效果更佳。下面先来说说它的定义吧。\n\n## 一、定义\n\nEM算法，全称Expectation Maximization Algorithm，译作最大期望化算法或期望最大算法，它是一种迭代算法，用于含有隐变量（hidden variable）的概率参数模型的最大似然估计或极大后验概率估计。\n\n## 二、Jensen不等式\n\n在完善EM算法之前，首先来了解下Jensen不等式，因为在EM算法的推导过程中会用到。\n\nJensen不等式在优化理论中大量用到，首先来回顾下凸函数和凹函数的定义。假设f是定义域为实数的函数，如果对于所有的x，f(x)的二阶导数大于等于0，那么f是凸函数。当x是向量时，如果hessian矩阵H是半正定（即H>=0），那么f是凸函数。如果，f(x)的二阶导数小于0或者H>0，那么f就是凹函数。\n\nJensen不等式描述如下：\n\n- 如果f是凸函数，X是随机变量，则E[f(X)]>=f(E[X])，特别地，如果f是严格凸函数，E[f(X)]>=f(E[X])，那么当且仅当p(x=E[X])=1时（也就是说X是常量），E[f(x)]=f(E[X])；\n- 如果f是凹函数，X是随机变量，则f(E[X])<=E[f(X)].当f是（严格）凹函数当且仅当-f是（严格）凸函数。\n\n通过下面这张图，可以加深印象：\n\n![](/assets/articleImg/2015-12-02-Jensen-inequality.png)\n\n图中，实线f是凸函数，X是随机变量，有0.5的概率是a，有0.5的概率是b。X的期望值就是a和b的中值了，图中可以看到E[f(X)]>=f(E[X])成立。\n\n\n## 三、EM算法\n\nEM算法推导过程中，会使用到极大似然估计法估计参数，所以，首先给出一个求最大似然函数估计值的一般步骤：\n\n- （1）写出似然函数；\n- （2）对似然函数取对数，并整理；\n- （3）求导数，令导数为0，得到似然方程；\n- （4）解似然方程，得到的参数即为所求；\n\n关于极大似然估计的实例，就不在提及了，下面介绍EM算法。\n\n给定m个训练样本{$x^{(1)},...,x^{(m)}$},样本间相互独立，根据分布，我们可以得到一个似然函数：\n\n![](/assets/articleImg/2015-12-02-gs1.png)\n\n第一步是对极大似然函数取对数，第二步是对每个样本实例的每个可能类别`z`求联合分布概率和。但直接来求这个参数$\\theta$,可能很困难，因为存在一个隐含类别变量`z`。如果这个`z`是个已知的数，那么我们就可以使用极大似然估计来估算。所以，在这种情形下，EM算法就派上用场了。\n\nEM是一种解决存在隐含变量优化问题的有效方法。既然不能直接最大化$l(\\theta)$，我们可以不断地建立$l$的下界（E步），然后优化下界（M步）。依次迭代，直至收敛。\n\n---\n\n下面简单的描述下EM的算法思想：\n\n<font color=\"#1986C7\">**EM算法通过引入隐含变量,然后使用MLE（极大似然估计）进行迭代求解参数</font>**。假设引入隐含变量后有两个参数，EM算法会先固定第一个变量，然后使用MLE计算第二个变量值，然后通过固定第二个变量，再使用MLE估测第一个变量值，依次迭代，直至收敛。关于收敛终止条件，后面会提到。\n\nEM算法分为两步，E-Step和M-Step。\n\n- E-Step：通过observed data和现有模型估计参数估计值 missing data；\n- M-Step：假设missing data已知的情况下，最大化似然函数。\n\n**由于算法保证了每次迭代之后，似然函数都会增加，所以函数最终会收敛(最后有推到)**。\n\n---\n\n## 四、EM算法推导\n\n下面来推导EM算法：\n\n对于每个实例$i$,用$Q_{i}$表示样本实例隐含变量`z`的某种分布，$Q_i$满足条件（$\\sum_zQ_i(z)=1,Q_i(z)>=0$） ,如果$Q_i$是连续性的，则$Q_i$表示概率密度函数，需要将求和符号换成积分符号。\n\n对于前面的式子，做如下变换：\n\n![](/assets/articleImg/2015-12-02-gs2.png)\n\n上面三个式子中，式（1）和式（2）比较容易理解，式（1）是根据联合概率密度下某个变量的边缘密度函数来求解的，这里把z当做是随机变量。对每一个样本i的所有可能类别z求等式右边的联合概率密度函数和，也就得到等式左边为随机变量x的边缘概率密度。由于对式（1）直接求导非常困难，所以将其变换为式（2），分子分母都乘以一个相等的函数。而在式（2）变为式（3）的过程，采用了上面提到的**Jensen不等式**。下面来仔细分析下：\n\n<font color=red>把（1）式中的log函数体看成是一个整体，由于log(x)的二阶导数为$-\\frac{1}{x^2}$,小于0，为凹函数。所以使用Jensen不等式时，应该使用第二条规则：**f(E[X])>=E[f(x)]**。</font>\n\n还记得当年读大学的时候，概率论中的随机变量的期望计算方法么，如下所示：\n\n![](/assets/articleImg/2015-12-02-p2.png)\n\n因此，结合上面的知识点，我们可以把(2)式当中的$Q_i(z^{(i)})$看成相应的概率$p_i$，把$\\frac{p(x^{i},z^{(i)};\\theta)}{Q_i(z^{(i)})}$看作是$z^{(i)}$的函数$g(z)$，\n\n类似地，根据期望公式$E(x)=\\sum x*p(x)$可以得到：\n\n![](/assets/articleImg/2015-12-02-gs3.png)\n\n其实就是$\\frac{p(x^{i},z^{(i)};\\theta)}{Q_i(z^{(i)})}$的期望，再根据凹函数对应的Jensen不等式性质：\n\n\n![](/assets/articleImg/2015-12-02-gs4.png)\n\n因此便得到了公式（3）。\n\n\nOK，现在我们知道上面的式子（2）和式子（3）两个不等式可以写成：似然函数L(θ)>=J(z,Q)的形式（z为隐含变量），那么我们可以通过不断的最大化这个下界J，来使得L(θ)不断提高，最终达到它的最大值。用下面这个图形象的说明下：\n\n![](/assets/articleImg/2015-12-02-p3.png)\n\n这里来说下上图的内在含义，<font color=\"#1986c7\">**首先我们固定θ，调整Q(z)使下界J(z,Q)上升至与L(θ)在此点θ处相等（绿色曲线到蓝色曲线），然后固定Q(z)，调整θ使下界J(z,Q)达到最大值（θt到θt+1），然后再固定θ，调整Q(z)……直到收敛到似然函数L(θ)的最大值处的θ**</font>。<font color=red>这里有两个问题：①什么时候下界J(z,Q)与L(θ)在此点θ处相等？②为什么一定会收敛？</font>\n\n\n首先来解决第一个问题（~~<font color=\"red\">①什么时候下界J(z,Q)与L(θ)在此点θ处相等？~~</font>）。在Jensen不等式中说到，当自变量X=E(X)时，即为常数的时候，等式成立。而在这里，为：\n\n![](/assets/articleImg/2015-12-02-gs5.png)\n\n对该式做个变换，取所有的z，得到\n\n$$\\sum_z{p(x^{i},z^{(i)};\\theta)}=\\sum_z{Q_i(z^{(i)})}c$$\n\n因为前面提到$\\sum_zQ_i(z)=1$（因为概率之和为1），所以可以推导出：\n\n$$\\sum_z{p(x^{i},z^{(i)};\\theta)}=c$$\n\n因此也就可以得到下面的式子：\n\n![](/assets/articleImg/2015-12-02-gs6.png)\n\n\n至此，我们推出了在固定参数θ后，使下界拉升的Q(z)的计算公式就是后验概率（条件概率），解决了Q(z)如何选择的问题。这一步就是E步，建立L(θ)的下界。接下来的M步，就是在给定Q(z)后，调整θ，去极大化L(θ)的下界J（在固定Q(z)后，下界还可以调整的更大）。所以，到了这一步，来总结下使用EM算法的步骤：\n\n第一步，初始化分布参数θ；  \n第二步，重复以下步骤直到收敛：\n\n- E步骤：根据参数的初始值或上一次迭代的模型参数来计算出的隐性变量的后验概率（条件概率），其实就是隐性变量的期望值。作为隐藏变量的现有估计值：\n\n![](/assets/articleImg/2015-12-02-gs7.png)\n\n- M步骤：最大化似然函数从而获得新的参数值：\n\n![](/assets/articleImg/2015-12-02-gs8.png)\n\n通过不断的迭代，然后就可以得到使似然函数L(θ)最大化的参数θ了。\n\n到了这一步，那么问题又就来了，该怎么确保EM收敛呢？(<font color=\"red\">~~②为什么一定会收敛？~~</font>)下面来证明下.\n\n假定$\\theta^{(t)}$和$\\theta^{(t+1)}$是EM第t次和t+1次迭代后的结果。如果我们证明了$l(\\theta^{(t)})<=l(\\theta^{(t+1)})$，也就是说极大似然估计单调增加，那么最终我们会到达最大似然估计的最大值。下面来证明，选定$\\theta^{(t)}$之后，我们得到E步：\n\n![](/assets/articleImg/2015-12-02-gs9.png)\n\n这一步保证了在给定$\\theta^{(t)}$时，Jensen不等式中的等式成立，也就是\n\n![](/assets/articleImg/2015-12-02-gs10.png)\n\n然后进行M步，固定$Q_i^{(t)}(z^{(i)})$,并将$\\theta^{(t)}$试作变量，对上面的式子求导，得到$\\theta^{(t+1)}$,这样经过一些推导会有以下式子成立：\n\n![](/assets/articleImg/2015-12-02-gs11.png)\n\n在公式（4）中，得到$\\theta^{(t+1)}$,只是最大化$l(\\theta^{(t)})$,也就是$l(\\theta^{(t+1)})$的下界，并没有使等式成立，等式成立只有是在固定$\\theta$，并按E步得到$Q_i$时才能成立。\n\n\n这样就证明了$l(\\theta)$会单调增加。如果要判断收敛情况，可以这样来做：<font color=\"#1986C7\">**一种收敛方法是$l(\\theta)$不再变化，还有一种就是变化幅度很小,即根据$l(\\theta)^{(t+1)}-l(\\theta)^{(t)}$的值来决定**</font>。\n\n\nEM算法类似于坐标上生法（coordinate ascent）：E步：固定θ，优化Q；M步：固定Q，优化θ；交替将极值推向最大。\n\n\n## 五、应用\n\n- [混合高斯模型（Mixtures of Gaussians）](http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006924.html)\n- [K-means聚类算法](http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006910.html)\n\n\n## 六、References\n\n- [wikipedia维基百科](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm)\n- [JerryLead博客-（EM算法）The EM Algorithm](http://blog.csdn.net/zouxy09/article/details/8537620)\n- [从最大似然到EM算法浅解](http://blog.csdn.net/zouxy09/article/details/8537620)\n- [Rachel Zhang-EM算法原理](http://blog.csdn.net/abcjennifer/article/details/8170378)\n\n---\n","source":"_posts/2015-12-02-EM-algorithms.md","raw":"---\nlayout: post\ndate: 2015-12-02 10:24\ntitle: \"EM-最大期望算法\"\ncategories: ML\ntag: \n\t- Machine Learning\n\t- EM\ncomment: true\n---\n\n对于EM算法，一直都是云里雾里琢磨不清。所以，今天索性就下个决定，不搞懂它，善不罢休。通过今天的学习，加上之前的基础，EM算法终于算是搞明白了。果真是做事不冲动点，真的很难有结果。下面，我打算将EM算法的整个推导过程通俗地来讲解一遍，虽然网上也有很多EM算法的理论知识讲解，但我觉得只有自己再来整理并总结一遍，才能理解的更加透彻，这样收获的知识也会更多。\n\n根据自己的博文写作风格，首先来看一张EM算法的聚类图，来自wikipedia，效果直观点。\n\n![](/assets/articleImg/2015-12-02-EM_Clustering_of_Old_Faithful_data.gif)\n\n<!--more-->\n\n期望最大算法是一种从不完全数据或有数据丢失的数据集（存在隐含变量）中求解概率模型参数的最大似然估计方法。EM算法是机器学习十大算法之一，之所以被纳入十大算法之中，是因为它解决了其它算法解决不了的问题或者效果更佳。下面先来说说它的定义吧。\n\n## 一、定义\n\nEM算法，全称Expectation Maximization Algorithm，译作最大期望化算法或期望最大算法，它是一种迭代算法，用于含有隐变量（hidden variable）的概率参数模型的最大似然估计或极大后验概率估计。\n\n## 二、Jensen不等式\n\n在完善EM算法之前，首先来了解下Jensen不等式，因为在EM算法的推导过程中会用到。\n\nJensen不等式在优化理论中大量用到，首先来回顾下凸函数和凹函数的定义。假设f是定义域为实数的函数，如果对于所有的x，f(x)的二阶导数大于等于0，那么f是凸函数。当x是向量时，如果hessian矩阵H是半正定（即H>=0），那么f是凸函数。如果，f(x)的二阶导数小于0或者H>0，那么f就是凹函数。\n\nJensen不等式描述如下：\n\n- 如果f是凸函数，X是随机变量，则E[f(X)]>=f(E[X])，特别地，如果f是严格凸函数，E[f(X)]>=f(E[X])，那么当且仅当p(x=E[X])=1时（也就是说X是常量），E[f(x)]=f(E[X])；\n- 如果f是凹函数，X是随机变量，则f(E[X])<=E[f(X)].当f是（严格）凹函数当且仅当-f是（严格）凸函数。\n\n通过下面这张图，可以加深印象：\n\n![](/assets/articleImg/2015-12-02-Jensen-inequality.png)\n\n图中，实线f是凸函数，X是随机变量，有0.5的概率是a，有0.5的概率是b。X的期望值就是a和b的中值了，图中可以看到E[f(X)]>=f(E[X])成立。\n\n\n## 三、EM算法\n\nEM算法推导过程中，会使用到极大似然估计法估计参数，所以，首先给出一个求最大似然函数估计值的一般步骤：\n\n- （1）写出似然函数；\n- （2）对似然函数取对数，并整理；\n- （3）求导数，令导数为0，得到似然方程；\n- （4）解似然方程，得到的参数即为所求；\n\n关于极大似然估计的实例，就不在提及了，下面介绍EM算法。\n\n给定m个训练样本{$x^{(1)},...,x^{(m)}$},样本间相互独立，根据分布，我们可以得到一个似然函数：\n\n![](/assets/articleImg/2015-12-02-gs1.png)\n\n第一步是对极大似然函数取对数，第二步是对每个样本实例的每个可能类别`z`求联合分布概率和。但直接来求这个参数$\\theta$,可能很困难，因为存在一个隐含类别变量`z`。如果这个`z`是个已知的数，那么我们就可以使用极大似然估计来估算。所以，在这种情形下，EM算法就派上用场了。\n\nEM是一种解决存在隐含变量优化问题的有效方法。既然不能直接最大化$l(\\theta)$，我们可以不断地建立$l$的下界（E步），然后优化下界（M步）。依次迭代，直至收敛。\n\n---\n\n下面简单的描述下EM的算法思想：\n\n<font color=\"#1986C7\">**EM算法通过引入隐含变量,然后使用MLE（极大似然估计）进行迭代求解参数</font>**。假设引入隐含变量后有两个参数，EM算法会先固定第一个变量，然后使用MLE计算第二个变量值，然后通过固定第二个变量，再使用MLE估测第一个变量值，依次迭代，直至收敛。关于收敛终止条件，后面会提到。\n\nEM算法分为两步，E-Step和M-Step。\n\n- E-Step：通过observed data和现有模型估计参数估计值 missing data；\n- M-Step：假设missing data已知的情况下，最大化似然函数。\n\n**由于算法保证了每次迭代之后，似然函数都会增加，所以函数最终会收敛(最后有推到)**。\n\n---\n\n## 四、EM算法推导\n\n下面来推导EM算法：\n\n对于每个实例$i$,用$Q_{i}$表示样本实例隐含变量`z`的某种分布，$Q_i$满足条件（$\\sum_zQ_i(z)=1,Q_i(z)>=0$） ,如果$Q_i$是连续性的，则$Q_i$表示概率密度函数，需要将求和符号换成积分符号。\n\n对于前面的式子，做如下变换：\n\n![](/assets/articleImg/2015-12-02-gs2.png)\n\n上面三个式子中，式（1）和式（2）比较容易理解，式（1）是根据联合概率密度下某个变量的边缘密度函数来求解的，这里把z当做是随机变量。对每一个样本i的所有可能类别z求等式右边的联合概率密度函数和，也就得到等式左边为随机变量x的边缘概率密度。由于对式（1）直接求导非常困难，所以将其变换为式（2），分子分母都乘以一个相等的函数。而在式（2）变为式（3）的过程，采用了上面提到的**Jensen不等式**。下面来仔细分析下：\n\n<font color=red>把（1）式中的log函数体看成是一个整体，由于log(x)的二阶导数为$-\\frac{1}{x^2}$,小于0，为凹函数。所以使用Jensen不等式时，应该使用第二条规则：**f(E[X])>=E[f(x)]**。</font>\n\n还记得当年读大学的时候，概率论中的随机变量的期望计算方法么，如下所示：\n\n![](/assets/articleImg/2015-12-02-p2.png)\n\n因此，结合上面的知识点，我们可以把(2)式当中的$Q_i(z^{(i)})$看成相应的概率$p_i$，把$\\frac{p(x^{i},z^{(i)};\\theta)}{Q_i(z^{(i)})}$看作是$z^{(i)}$的函数$g(z)$，\n\n类似地，根据期望公式$E(x)=\\sum x*p(x)$可以得到：\n\n![](/assets/articleImg/2015-12-02-gs3.png)\n\n其实就是$\\frac{p(x^{i},z^{(i)};\\theta)}{Q_i(z^{(i)})}$的期望，再根据凹函数对应的Jensen不等式性质：\n\n\n![](/assets/articleImg/2015-12-02-gs4.png)\n\n因此便得到了公式（3）。\n\n\nOK，现在我们知道上面的式子（2）和式子（3）两个不等式可以写成：似然函数L(θ)>=J(z,Q)的形式（z为隐含变量），那么我们可以通过不断的最大化这个下界J，来使得L(θ)不断提高，最终达到它的最大值。用下面这个图形象的说明下：\n\n![](/assets/articleImg/2015-12-02-p3.png)\n\n这里来说下上图的内在含义，<font color=\"#1986c7\">**首先我们固定θ，调整Q(z)使下界J(z,Q)上升至与L(θ)在此点θ处相等（绿色曲线到蓝色曲线），然后固定Q(z)，调整θ使下界J(z,Q)达到最大值（θt到θt+1），然后再固定θ，调整Q(z)……直到收敛到似然函数L(θ)的最大值处的θ**</font>。<font color=red>这里有两个问题：①什么时候下界J(z,Q)与L(θ)在此点θ处相等？②为什么一定会收敛？</font>\n\n\n首先来解决第一个问题（~~<font color=\"red\">①什么时候下界J(z,Q)与L(θ)在此点θ处相等？~~</font>）。在Jensen不等式中说到，当自变量X=E(X)时，即为常数的时候，等式成立。而在这里，为：\n\n![](/assets/articleImg/2015-12-02-gs5.png)\n\n对该式做个变换，取所有的z，得到\n\n$$\\sum_z{p(x^{i},z^{(i)};\\theta)}=\\sum_z{Q_i(z^{(i)})}c$$\n\n因为前面提到$\\sum_zQ_i(z)=1$（因为概率之和为1），所以可以推导出：\n\n$$\\sum_z{p(x^{i},z^{(i)};\\theta)}=c$$\n\n因此也就可以得到下面的式子：\n\n![](/assets/articleImg/2015-12-02-gs6.png)\n\n\n至此，我们推出了在固定参数θ后，使下界拉升的Q(z)的计算公式就是后验概率（条件概率），解决了Q(z)如何选择的问题。这一步就是E步，建立L(θ)的下界。接下来的M步，就是在给定Q(z)后，调整θ，去极大化L(θ)的下界J（在固定Q(z)后，下界还可以调整的更大）。所以，到了这一步，来总结下使用EM算法的步骤：\n\n第一步，初始化分布参数θ；  \n第二步，重复以下步骤直到收敛：\n\n- E步骤：根据参数的初始值或上一次迭代的模型参数来计算出的隐性变量的后验概率（条件概率），其实就是隐性变量的期望值。作为隐藏变量的现有估计值：\n\n![](/assets/articleImg/2015-12-02-gs7.png)\n\n- M步骤：最大化似然函数从而获得新的参数值：\n\n![](/assets/articleImg/2015-12-02-gs8.png)\n\n通过不断的迭代，然后就可以得到使似然函数L(θ)最大化的参数θ了。\n\n到了这一步，那么问题又就来了，该怎么确保EM收敛呢？(<font color=\"red\">~~②为什么一定会收敛？~~</font>)下面来证明下.\n\n假定$\\theta^{(t)}$和$\\theta^{(t+1)}$是EM第t次和t+1次迭代后的结果。如果我们证明了$l(\\theta^{(t)})<=l(\\theta^{(t+1)})$，也就是说极大似然估计单调增加，那么最终我们会到达最大似然估计的最大值。下面来证明，选定$\\theta^{(t)}$之后，我们得到E步：\n\n![](/assets/articleImg/2015-12-02-gs9.png)\n\n这一步保证了在给定$\\theta^{(t)}$时，Jensen不等式中的等式成立，也就是\n\n![](/assets/articleImg/2015-12-02-gs10.png)\n\n然后进行M步，固定$Q_i^{(t)}(z^{(i)})$,并将$\\theta^{(t)}$试作变量，对上面的式子求导，得到$\\theta^{(t+1)}$,这样经过一些推导会有以下式子成立：\n\n![](/assets/articleImg/2015-12-02-gs11.png)\n\n在公式（4）中，得到$\\theta^{(t+1)}$,只是最大化$l(\\theta^{(t)})$,也就是$l(\\theta^{(t+1)})$的下界，并没有使等式成立，等式成立只有是在固定$\\theta$，并按E步得到$Q_i$时才能成立。\n\n\n这样就证明了$l(\\theta)$会单调增加。如果要判断收敛情况，可以这样来做：<font color=\"#1986C7\">**一种收敛方法是$l(\\theta)$不再变化，还有一种就是变化幅度很小,即根据$l(\\theta)^{(t+1)}-l(\\theta)^{(t)}$的值来决定**</font>。\n\n\nEM算法类似于坐标上生法（coordinate ascent）：E步：固定θ，优化Q；M步：固定Q，优化θ；交替将极值推向最大。\n\n\n## 五、应用\n\n- [混合高斯模型（Mixtures of Gaussians）](http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006924.html)\n- [K-means聚类算法](http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006910.html)\n\n\n## 六、References\n\n- [wikipedia维基百科](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm)\n- [JerryLead博客-（EM算法）The EM Algorithm](http://blog.csdn.net/zouxy09/article/details/8537620)\n- [从最大似然到EM算法浅解](http://blog.csdn.net/zouxy09/article/details/8537620)\n- [Rachel Zhang-EM算法原理](http://blog.csdn.net/abcjennifer/article/details/8170378)\n\n---\n","slug":"2015-12-02-EM-algorithms","published":1,"updated":"2016-03-14T07:40:34.143Z","comments":1,"photos":[],"link":"","_id":"cimigpywe00556cujx3n5iqug"},{"layout":"post","date":"2015-11-25T13:24:00.000Z","title":"今日阅读","comment":true,"_content":"\n【先给出一张数据科学家的日常工作流图】\n\n![data science work diagram](http://ww4.sinaimg.cn/large/637f3c58gw1eydjolk7mwj20gq09x76m.jpg)\n\n<!-- more-->\n\n---\n\n今天翻译了一篇CSDN给的译文，同时也审阅了一篇译文，对LR、DT、SVM又有了进一步的认识，下面附上两篇博文链接，另外加上一篇同一作者的博文。\n\n- [Logistic Regression Vs Decision Trees Vs SVM: Part I](http://www.edvancer.in/logistic-regression-vs-decision-trees-vs-svm-part1/)\n- [Logistic Regression vs Decision Trees vs SVM: Part II](http://www.edvancer.in/logistic-regression-vs-decision-trees-vs-svm-part2/)\n- [8 must have data science skills](http://www.edvancer.in/8-data-science-skills/)\n\n\n\n\n---\n\n","source":"_posts/2015-11-25-Reading-Today.md","raw":"---\nlayout: post\ndate: 2015-11-25 21:24\ntitle: \"今日阅读\"\ncategories: 今日阅读\ntag: \n\t- Data Science\ncomment: true\n---\n\n【先给出一张数据科学家的日常工作流图】\n\n![data science work diagram](http://ww4.sinaimg.cn/large/637f3c58gw1eydjolk7mwj20gq09x76m.jpg)\n\n<!-- more-->\n\n---\n\n今天翻译了一篇CSDN给的译文，同时也审阅了一篇译文，对LR、DT、SVM又有了进一步的认识，下面附上两篇博文链接，另外加上一篇同一作者的博文。\n\n- [Logistic Regression Vs Decision Trees Vs SVM: Part I](http://www.edvancer.in/logistic-regression-vs-decision-trees-vs-svm-part1/)\n- [Logistic Regression vs Decision Trees vs SVM: Part II](http://www.edvancer.in/logistic-regression-vs-decision-trees-vs-svm-part2/)\n- [8 must have data science skills](http://www.edvancer.in/8-data-science-skills/)\n\n\n\n\n---\n\n","slug":"2015-11-25-Reading-Today","published":1,"updated":"2016-03-08T09:04:55.617Z","comments":1,"photos":[],"link":"","_id":"cimigpywk005a6cujvdylxajh"},{"layout":"post","date":"2015-11-21T02:24:00.000Z","title":"机器学习算法代码汇总","comment":true,"_content":"\n<br>\n\n\n【机器学习算法代码汇总-Python&R】- <a link=\"http://csuldw.github.io/assets/pdf/Full-CheatSheet-on-Machine-Learning-Algorithms(Python-and-R-Codes).pdf\"target=\"_black\">PDF文件下载</a>.\n\n![机器学习算法代码汇总1](http://ww3.sinaimg.cn/large/637f3c58gw1ey8lm4rhn5j20s40fp466.jpg)\n\n<!--more-->\n\n![机器学习算法代码汇总2](http://ww3.sinaimg.cn/large/637f3c58gw1ey8lkrdcwlj20s93kl4qq.jpg)\n\n\n\n原文链接：[点击这里](http://www.analyticsvidhya.com/blog/2015/09/full-cheatsheet-machine-learning-algorithms/).\n\n\n---\n\n","source":"_posts/2015-11-21-machine-learning-algorithms.md","raw":"---\nlayout: post\ndate: 2015-11-21 10:24\ntitle: \"机器学习算法代码汇总\"\ncategories: ML \ntag: \n\t- Machine Learning\n\t- Python\ncomment: true\n---\n\n<br>\n\n\n【机器学习算法代码汇总-Python&R】- <a link=\"http://csuldw.github.io/assets/pdf/Full-CheatSheet-on-Machine-Learning-Algorithms(Python-and-R-Codes).pdf\"target=\"_black\">PDF文件下载</a>.\n\n![机器学习算法代码汇总1](http://ww3.sinaimg.cn/large/637f3c58gw1ey8lm4rhn5j20s40fp466.jpg)\n\n<!--more-->\n\n![机器学习算法代码汇总2](http://ww3.sinaimg.cn/large/637f3c58gw1ey8lkrdcwlj20s93kl4qq.jpg)\n\n\n\n原文链接：[点击这里](http://www.analyticsvidhya.com/blog/2015/09/full-cheatsheet-machine-learning-algorithms/).\n\n\n---\n\n","slug":"2015-11-21-machine-learning-algorithms","published":1,"updated":"2016-03-13T05:54:30.243Z","comments":1,"photos":[],"link":"","_id":"cimigpywp005f6cuj84z90vn9"},{"layout":"post","date":"2015-11-18T04:24:00.000Z","title":"实验笔记[1]-DSSP文件提取序列","comment":true,"_content":"\n__提示：以下内容乃个人实验笔记！__\n\n\n### 功能描述\n\n从格式化后的dssp文件`DSSP`（单一文件）中提取序列信息，要求输出的序列不含有`X`残基，并且序列最短长度`minlen`可人为指定，一般设置为`40`。\n\n<!--more-->\n\n`DSSP`文件格式Top10:\n\n<pre><code class=\"markdown\">1A12\t    1\t   21\t A\t K \t          \t   0   0  172 \t   0 \t 172\t      0, 0.0\t     2,-1.9\t     0, 0.0\t     0, 0.0\t   0.000 \t360.0\t 360.0\t 360.0\t 129.7\t    9.7\t  -11.3\t   33.7\n1A12\t    2\t   22\t A\t K \t       -  \t   0   0  164 \t   0 \t 164\t      1,-0.1\t     2,-0.2\t     0, 0.0\t     0, 0.0\t  -0.433 \t360.0\t-153.3\t -64.1\t  85.0\t   10.1\t  -13.4\t   30.5\n1A12\t    3\t   23\t A\t V \t       -  \t   0   0   42 \t   0 \t  42\t     -2,-1.9\t     2,-0.2\t   114,-0.1\t   768,-0.1\t  -0.429 \t  8.7\t-128.1\t -66.5\t 129.9\t   11.5\t  -10.5\t   28.4\n1A12\t    4\t   24\t A\t K \t       -  \t   0   0  130 \t   0 \t 130\t     -2,-0.2\t     2,-0.3\t   765,-0.1\t   113,-0.3\t  -0.476 \t 21.9\t-164.8\t -79.9\t 149.3\t   10.9\t  -10.9\t   24.7\n1A12\t    5\t   25\t A\t V \t       -  \t   0   0   13 \t   0 \t  13\t    111,-2.8\t     2,-0.2\t    -2,-0.2\t   113,-0.2\t  -0.942 \t  6.3\t-177.4\t-126.4\t 157.4\t   13.6\t  -10.6\t   22.1\n1A12\t    6\t   26\t A\t S \t       -  \t   0   0   20 \t   0 \t  20\t    719,-1.4\t     2,-0.3\t    -2,-0.3\t   720,-0.1\t  -0.694 \t  8.2\t-153.8\t-133.2\t-164.5\t   13.4\t  -10.1\t   18.3\n1A12\t    7\t   27\t A\t H \t   >   -  \t   0   0    2 \t   0 \t   2\t     -2,-0.2\t     3,-1.6\t   718,-0.1\t   721,-0.3\t  -0.944 \t 32.3\t-112.1\t-169.7\t 155.9\t   15.9\t   -9.9\t   15.4\n1A12\t    8\t   28\t A\t R \t T 3  S+  \t   0   0   53 \t   0 \t  53\t    718,-0.4\t   720,-0.3\t   716,-0.3\t   717,-0.1\t   0.690 \t115.2\t  60.4\t -69.3\t -20.9\t   16.0\t   -8.3\t   12.0\n1A12\t    9\t   29\t A\t S \t T 3  S+  \t   0   0   34 \t   0 \t  34\t    146,-0.2\t    -1,-0.3\t   718,-0.1\t     2,-0.2\t   0.548 \t 78.3\t 108.7\t -77.8\t -13.9\t   15.9\t  -11.8\t   10.5\n1A12\t   10\t   30\t A\t H \t   <   -  \t   0   0   22 \t   0 \t  22\t     -3,-1.6\t     2,-0.3\t   145,-0.1\t    93,-0.1\t  -0.516 \t 67.8\t-130.5\t -73.7\t 135.3\t   12.6\t  -12.8\t   12.0\n</code></pre>\n\n\n---\n\n### 代码\n\n\n`generateSeqFromDSSP.py`文件如下：\n\n```\n#!/usr/bin/python\n#-*- coding: utf-8 -*-\nimport os \n'''\nParameters：\n    - dsspfile:\t为格式过的DSSP文件\n    - foseq: \t为输出的序列文件\n    - fochain: \t输出的蛋白链文件\n    - minLen:  \t最短的序列长度\n'''\ndef getSeqFromDSSP(dsspfile, foseq, fochain, minLen):\n    with open(dsspfile, 'r') as inputfile:\n        if not foseq.strip():\n            foseq = 'protein'+ str(minLen) + '.dssp.seq'\n        outchain = open(fochain, 'w')\n        with open(foseq, 'w') as outputfile:\n            residue=[];Ntype=[]\n            preType=[];preRes=[]\n            firstline=[];secondline=[];content=''\n            for eachline in inputfile:\n                oneline = eachline.split('\\t') \n                residue = oneline[0]\n                if not residue.strip(): \n                    continue\n                Ntype = oneline[3].strip()\n                if not Ntype.strip():\n                    continue\n                if preRes!=residue:\n                    content = ''.join(firstline)+'\\n'+''.join(secondline) +'\\n'\n                    if len(secondline)>=int(minLen) and not 'X' in secondline:\n                        outchain.write(''.join(firstline) + '\\n')\n                        outputfile.write(content)\n                    firstline=[]\n                    firstline.append('>' + residue + ':' + Ntype)\n                    secondline=[];secondline.append(oneline[4].strip())\n                    preRes = residue;preType = Ntype\n                    continue\n                if Ntype != preType:\n                    content = ''.join(firstline)+'\\n'+''.join(secondline)+'\\n'\n                    if len(secondline)>=int(minLen) and  not 'X' in secondline:\n                        outchain.write(''.join(firstline) + '\\n')\n                        outputfile.write(content)\n                    firstline=[]\n                    firstline.append('>' + residue + ':' + Ntype)\n                    secondline=[];secondline.append(oneline[4].strip())\n                    preRes = residue;preType = Ntype\n                else: #如果Ntype不为空，且等于preType\n                    secondline.append(oneline[4].strip())\n            content = ''.join(firstline)+'\\n' + ''.join(secondline) +'\\n'\n            #选择长度大于40而且序列中不存在‘X’残基的序列\n            if len(secondline) >= int(minLen) and not 'X' in secondline:  \n                outchain.write(''.join(firstline) + '\\n')\n                outputfile.write(content)\n        outchain.close()\n###############################################################################\nif __name__==\"__main__\":\n    os.chdir(\"/ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/\")\n    dsspfile = os.sys.argv[1]\n    foseq = os.sys.argv[2]\n    fochain = os.sys.argv[3]\n    minlen = os.sys.argv[4]\n    getSeqFromDSSP(dsspfile, foseq, fochain, minlen)\n```\n\n---\n\n### Test sample\n\n在Linux控制台中输入下面命令：\n\n```\npython generateSeqFromDSSP.py \\\n/ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/dssp_testset/DSSP \\\n/ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/protein_test.seq \\\n/ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/protein_test.chain \\\n40\n```\n\n输出文件：\n\n`protein_test.seq`格式Top10：\n\n<pre><code class=\"markdown\">>1A12:A\nKKVKVSHRSHSTEPGLVLTLGQGDVGQLGLGENVMERKKPALVSIPEDVVQAEAGGMHTVCLSKSGQVYSFGCNDEGALGRDTSVEGSEMVPGKVELQEKVVQVSAGDSHTAALTDDGRVFLWGSFRDNNGVIGLLEPMKKSMVPVQVQLDVPVVKVASGNDHLVMLTADGDLYTLGCGEQGQLGRVPELFANRGGRQGLERLLVPKCVMLKSRGSRGHVRFQDAFCGAYFTFAISHEGHVYGFGLSNYHQLGTPGTESCFIPQNLTSFKNSTKSWVGFSGGQHHTVCMDSEGKAYSLGRAEYGRLGLGEGAEEKSIPTLISRLPAVSSVACGASVGYAVTKDGRVFAWGMGTNYQLGTGQDEDAWSPVEMMGKQLENRVVLSVSSGGQHTVLLVKDKEQS\n>1A12:B\nKKVKVSHRSHSTEPGLVLTLGQGDVGQLGLGENVMERKKPALVSIPEDVVQAEAGGMHTVCLSKSGQVYSFGCNDEGALGRDTSVEGSEMVPGKVELQEKVVQVSAGDSHTAALTDDGRVFLWGSFRDNNGVIGLLEPMKKSMVPVQVQLDVPVVKVASGNDHLVMLTADGDLYTLGCGEQGQLGRVPELFANRGGRQGLERLLVPKCVMLKSRGSRGHVRFQDAFCGAYFTFAISHEGHVYGFGLSNYHQLGTPGTESCFIPQNLTSFKNSTKSWVGFSGGQHHTVCMDSEGKAYSLGRAEYGRLGLGEGAEEKSIPTLISRLPAVSSVACGASVGYAVTKDGRVFAWGMGTNYQLGTGQDEDAWSPVEMMGKQLENRVVLSVSSGGQHTVLLVKDKEQS\n>1A12:C\nKKVKVSHRSHSTEPGLVLTLGQGDVGQLGLGENVMERKKPALVSIPEDVVQAEAGGMHTVCLSKSGQVYSFGCNDEGALGRDTSVEGSEMVPGKVELQEKVVQVSAGDSHTAALTDDGRVFLWGSFRDNNGVIGLLEPMKKSMVPVQVQLDVPVVKVASGNDHLVMLTADGDLYTLGCGEQGQLGRVPELFANRGGRQGLERLLVPKCVMLKSRGSRGHVRFQDAFCGAYFTFAISHEGHVYGFGLSNYHQLGTPGTESCFIPQNLTSFKNSTKSWVGFSGGQHHTVCMDSEGKAYSLGRAEYGRLGLGEGAEEKSIPTLISRLPAVSSVACGASVGYAVTKDGRVFAWGMGTNYQLGTGQDEDAWSPVEMMGKQLENRVVLSVSSGGQHTVLLVKDKEQS\n>1BCH:1\nAIEVKLANMEAEINTLKSKLELTNKLHAFSMGKKSGKKFFVTNHERMPFSKVKALaSELRGTVAIPRNAEENKAIQEVAKTSAFLGITDEVTEGQFMYVTGGRLTYSNWKKDQPDDWYGHGLGGGEDbVHIVDNGLWNDISbQASHTAVaEFPA\n>1BCH:2\nAIEVKLANMEAEINTLKSKLELTNKLHAFSMGKKSGKKFFVTNHERMPFSKVKALcSELRGTVAIPRNAEENKAIQEVAKTSAFLGITDEVTEGQFMYVTGGRLTYSNWKKDQPDDWYGHGLGGGEDdVHIVDNGLWNDISdQASHTAVcEFPA\n</code></pre>\n\n`protein_test.chain`文件格式Top10:\n\n<pre><code class=\"markdown\">>1A12:A\n>1A12:B\n>1A12:C\n>1BCH:1\n>1BCH:2\n>1BCH:3\n>1BF6:B\n>1BYP:A\n>1C7J:A\n>1CHM:A\n<code></pre>\n\n---\n\n","source":"_posts/2015-11-18 ExpNotes[1]-Extract protein sequences from a fasta file.md","raw":"---\nlayout: post\ndate: 2015-11-18 12:24\ntitle: \"实验笔记[1]-DSSP文件提取序列\"\ncategories: BioInfo\ntag: \n\t- BioInfo\n\t- DSSP\n\t- 预处理\ncomment: true\n---\n\n__提示：以下内容乃个人实验笔记！__\n\n\n### 功能描述\n\n从格式化后的dssp文件`DSSP`（单一文件）中提取序列信息，要求输出的序列不含有`X`残基，并且序列最短长度`minlen`可人为指定，一般设置为`40`。\n\n<!--more-->\n\n`DSSP`文件格式Top10:\n\n<pre><code class=\"markdown\">1A12\t    1\t   21\t A\t K \t          \t   0   0  172 \t   0 \t 172\t      0, 0.0\t     2,-1.9\t     0, 0.0\t     0, 0.0\t   0.000 \t360.0\t 360.0\t 360.0\t 129.7\t    9.7\t  -11.3\t   33.7\n1A12\t    2\t   22\t A\t K \t       -  \t   0   0  164 \t   0 \t 164\t      1,-0.1\t     2,-0.2\t     0, 0.0\t     0, 0.0\t  -0.433 \t360.0\t-153.3\t -64.1\t  85.0\t   10.1\t  -13.4\t   30.5\n1A12\t    3\t   23\t A\t V \t       -  \t   0   0   42 \t   0 \t  42\t     -2,-1.9\t     2,-0.2\t   114,-0.1\t   768,-0.1\t  -0.429 \t  8.7\t-128.1\t -66.5\t 129.9\t   11.5\t  -10.5\t   28.4\n1A12\t    4\t   24\t A\t K \t       -  \t   0   0  130 \t   0 \t 130\t     -2,-0.2\t     2,-0.3\t   765,-0.1\t   113,-0.3\t  -0.476 \t 21.9\t-164.8\t -79.9\t 149.3\t   10.9\t  -10.9\t   24.7\n1A12\t    5\t   25\t A\t V \t       -  \t   0   0   13 \t   0 \t  13\t    111,-2.8\t     2,-0.2\t    -2,-0.2\t   113,-0.2\t  -0.942 \t  6.3\t-177.4\t-126.4\t 157.4\t   13.6\t  -10.6\t   22.1\n1A12\t    6\t   26\t A\t S \t       -  \t   0   0   20 \t   0 \t  20\t    719,-1.4\t     2,-0.3\t    -2,-0.3\t   720,-0.1\t  -0.694 \t  8.2\t-153.8\t-133.2\t-164.5\t   13.4\t  -10.1\t   18.3\n1A12\t    7\t   27\t A\t H \t   >   -  \t   0   0    2 \t   0 \t   2\t     -2,-0.2\t     3,-1.6\t   718,-0.1\t   721,-0.3\t  -0.944 \t 32.3\t-112.1\t-169.7\t 155.9\t   15.9\t   -9.9\t   15.4\n1A12\t    8\t   28\t A\t R \t T 3  S+  \t   0   0   53 \t   0 \t  53\t    718,-0.4\t   720,-0.3\t   716,-0.3\t   717,-0.1\t   0.690 \t115.2\t  60.4\t -69.3\t -20.9\t   16.0\t   -8.3\t   12.0\n1A12\t    9\t   29\t A\t S \t T 3  S+  \t   0   0   34 \t   0 \t  34\t    146,-0.2\t    -1,-0.3\t   718,-0.1\t     2,-0.2\t   0.548 \t 78.3\t 108.7\t -77.8\t -13.9\t   15.9\t  -11.8\t   10.5\n1A12\t   10\t   30\t A\t H \t   <   -  \t   0   0   22 \t   0 \t  22\t     -3,-1.6\t     2,-0.3\t   145,-0.1\t    93,-0.1\t  -0.516 \t 67.8\t-130.5\t -73.7\t 135.3\t   12.6\t  -12.8\t   12.0\n</code></pre>\n\n\n---\n\n### 代码\n\n\n`generateSeqFromDSSP.py`文件如下：\n\n```\n#!/usr/bin/python\n#-*- coding: utf-8 -*-\nimport os \n'''\nParameters：\n    - dsspfile:\t为格式过的DSSP文件\n    - foseq: \t为输出的序列文件\n    - fochain: \t输出的蛋白链文件\n    - minLen:  \t最短的序列长度\n'''\ndef getSeqFromDSSP(dsspfile, foseq, fochain, minLen):\n    with open(dsspfile, 'r') as inputfile:\n        if not foseq.strip():\n            foseq = 'protein'+ str(minLen) + '.dssp.seq'\n        outchain = open(fochain, 'w')\n        with open(foseq, 'w') as outputfile:\n            residue=[];Ntype=[]\n            preType=[];preRes=[]\n            firstline=[];secondline=[];content=''\n            for eachline in inputfile:\n                oneline = eachline.split('\\t') \n                residue = oneline[0]\n                if not residue.strip(): \n                    continue\n                Ntype = oneline[3].strip()\n                if not Ntype.strip():\n                    continue\n                if preRes!=residue:\n                    content = ''.join(firstline)+'\\n'+''.join(secondline) +'\\n'\n                    if len(secondline)>=int(minLen) and not 'X' in secondline:\n                        outchain.write(''.join(firstline) + '\\n')\n                        outputfile.write(content)\n                    firstline=[]\n                    firstline.append('>' + residue + ':' + Ntype)\n                    secondline=[];secondline.append(oneline[4].strip())\n                    preRes = residue;preType = Ntype\n                    continue\n                if Ntype != preType:\n                    content = ''.join(firstline)+'\\n'+''.join(secondline)+'\\n'\n                    if len(secondline)>=int(minLen) and  not 'X' in secondline:\n                        outchain.write(''.join(firstline) + '\\n')\n                        outputfile.write(content)\n                    firstline=[]\n                    firstline.append('>' + residue + ':' + Ntype)\n                    secondline=[];secondline.append(oneline[4].strip())\n                    preRes = residue;preType = Ntype\n                else: #如果Ntype不为空，且等于preType\n                    secondline.append(oneline[4].strip())\n            content = ''.join(firstline)+'\\n' + ''.join(secondline) +'\\n'\n            #选择长度大于40而且序列中不存在‘X’残基的序列\n            if len(secondline) >= int(minLen) and not 'X' in secondline:  \n                outchain.write(''.join(firstline) + '\\n')\n                outputfile.write(content)\n        outchain.close()\n###############################################################################\nif __name__==\"__main__\":\n    os.chdir(\"/ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/\")\n    dsspfile = os.sys.argv[1]\n    foseq = os.sys.argv[2]\n    fochain = os.sys.argv[3]\n    minlen = os.sys.argv[4]\n    getSeqFromDSSP(dsspfile, foseq, fochain, minlen)\n```\n\n---\n\n### Test sample\n\n在Linux控制台中输入下面命令：\n\n```\npython generateSeqFromDSSP.py \\\n/ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/dssp_testset/DSSP \\\n/ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/protein_test.seq \\\n/ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/protein_test.chain \\\n40\n```\n\n输出文件：\n\n`protein_test.seq`格式Top10：\n\n<pre><code class=\"markdown\">>1A12:A\nKKVKVSHRSHSTEPGLVLTLGQGDVGQLGLGENVMERKKPALVSIPEDVVQAEAGGMHTVCLSKSGQVYSFGCNDEGALGRDTSVEGSEMVPGKVELQEKVVQVSAGDSHTAALTDDGRVFLWGSFRDNNGVIGLLEPMKKSMVPVQVQLDVPVVKVASGNDHLVMLTADGDLYTLGCGEQGQLGRVPELFANRGGRQGLERLLVPKCVMLKSRGSRGHVRFQDAFCGAYFTFAISHEGHVYGFGLSNYHQLGTPGTESCFIPQNLTSFKNSTKSWVGFSGGQHHTVCMDSEGKAYSLGRAEYGRLGLGEGAEEKSIPTLISRLPAVSSVACGASVGYAVTKDGRVFAWGMGTNYQLGTGQDEDAWSPVEMMGKQLENRVVLSVSSGGQHTVLLVKDKEQS\n>1A12:B\nKKVKVSHRSHSTEPGLVLTLGQGDVGQLGLGENVMERKKPALVSIPEDVVQAEAGGMHTVCLSKSGQVYSFGCNDEGALGRDTSVEGSEMVPGKVELQEKVVQVSAGDSHTAALTDDGRVFLWGSFRDNNGVIGLLEPMKKSMVPVQVQLDVPVVKVASGNDHLVMLTADGDLYTLGCGEQGQLGRVPELFANRGGRQGLERLLVPKCVMLKSRGSRGHVRFQDAFCGAYFTFAISHEGHVYGFGLSNYHQLGTPGTESCFIPQNLTSFKNSTKSWVGFSGGQHHTVCMDSEGKAYSLGRAEYGRLGLGEGAEEKSIPTLISRLPAVSSVACGASVGYAVTKDGRVFAWGMGTNYQLGTGQDEDAWSPVEMMGKQLENRVVLSVSSGGQHTVLLVKDKEQS\n>1A12:C\nKKVKVSHRSHSTEPGLVLTLGQGDVGQLGLGENVMERKKPALVSIPEDVVQAEAGGMHTVCLSKSGQVYSFGCNDEGALGRDTSVEGSEMVPGKVELQEKVVQVSAGDSHTAALTDDGRVFLWGSFRDNNGVIGLLEPMKKSMVPVQVQLDVPVVKVASGNDHLVMLTADGDLYTLGCGEQGQLGRVPELFANRGGRQGLERLLVPKCVMLKSRGSRGHVRFQDAFCGAYFTFAISHEGHVYGFGLSNYHQLGTPGTESCFIPQNLTSFKNSTKSWVGFSGGQHHTVCMDSEGKAYSLGRAEYGRLGLGEGAEEKSIPTLISRLPAVSSVACGASVGYAVTKDGRVFAWGMGTNYQLGTGQDEDAWSPVEMMGKQLENRVVLSVSSGGQHTVLLVKDKEQS\n>1BCH:1\nAIEVKLANMEAEINTLKSKLELTNKLHAFSMGKKSGKKFFVTNHERMPFSKVKALaSELRGTVAIPRNAEENKAIQEVAKTSAFLGITDEVTEGQFMYVTGGRLTYSNWKKDQPDDWYGHGLGGGEDbVHIVDNGLWNDISbQASHTAVaEFPA\n>1BCH:2\nAIEVKLANMEAEINTLKSKLELTNKLHAFSMGKKSGKKFFVTNHERMPFSKVKALcSELRGTVAIPRNAEENKAIQEVAKTSAFLGITDEVTEGQFMYVTGGRLTYSNWKKDQPDDWYGHGLGGGEDdVHIVDNGLWNDISdQASHTAVcEFPA\n</code></pre>\n\n`protein_test.chain`文件格式Top10:\n\n<pre><code class=\"markdown\">>1A12:A\n>1A12:B\n>1A12:C\n>1BCH:1\n>1BCH:2\n>1BCH:3\n>1BF6:B\n>1BYP:A\n>1C7J:A\n>1CHM:A\n<code></pre>\n\n---\n\n","slug":"2015-11-18 ExpNotes[1]-Extract protein sequences from a fasta file","published":1,"updated":"2016-03-08T08:54:38.237Z","comments":1,"photos":[],"link":"","_id":"cimigpywt005j6cuj45ppr6gt"},{"layout":"post","date":"2015-11-17T07:11:00.000Z","title":"补集计算: B=U-A","comment":true,"_content":"\n## 问题描述\n\n在做数据处理的时候，根据原论文的蛋白质链下载蛋白质PDB文件，大体上还算正常。但是有的protein的PDB文件在PDB数据库已经不存在了，所以下载后的PDB文件理论上只属于原论文提到的PDB文件的一个子集。由于数据比较大，手动去找会耗费大量的时间，所以为了找出这些不存在的PDB文件，下面写一段代码来实现。\n\n\n## 问题转换与实现\n\n首先，将问题转化成一个数学问题。\n\n<!-- more -->\n\n问题转化：原论文提及的数据集（一个大集合U），现在下载到的只是一个子集合A，目的是求出U中不包含A的子集合（补集）：`B=U-A`.\n\n最终转化为：根据集合U和子集A，计算A的补集B=U-A.\n\n参数：\n\n- file1：大集合文件U\n- file2: 下载后的一个子集合A\n- outfile：输出文件\n\n代码如下：\n\ncompareTwoFile.py\n\n```\n#!/usr/bin/python\n#-*- coding: utf-8 -*-\nimport os\ndef compareTwoFile(file1,file2,outfile):\n    with open(outfile,'w') as fo: \n        fw = []\n        with open(file1,'r') as fr1:\n            fr1_con = [each.strip() for each in fr1.readlines()] \n            with open(file2,'r') as fr2:\n                fr2_con =[each.strip() for each in fr2.readlines()]\n                for eachline in fr1_con:\n                    if eachline not in fr2_con:\n                        fw.append(eachline)\n        fo.write(''.join(fw))\nif __name__==\"__main__\": \n    file1 = os.sys.argv[1]\n    file2 = os.sys.argv[2]\n    outfile = os.sys.argv[3]\n    compareTwoFile(file1,file2,outfile)\n```\n\nTest sample:\n\n```\npython compareTwoFile.py \\\n/ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/train_set.protein  \\\n/ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/pdb_trainset.txt \\\n/ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/compare.result\n```\n\nfile1和file2的top10格式：\n\n\t1A02\n\t1A0A\n\t1A3Q\n\t1A53\n\t1A8E\n\t1A8P\n\t1A8Y\n\t1AAC\t\n\t1ABE\n\t1AC5\n\n\t\n\n\n","source":"_posts/2015-11-17 B=U-A.md","raw":"---\nlayout: post\ndate: 2015-11-17 15:11\ntitle: \"补集计算: B=U-A\"\ncategories: BioInfo\ntag: \n\t- BioInfo\n\t- Python\ncomment: true\n---\n\n## 问题描述\n\n在做数据处理的时候，根据原论文的蛋白质链下载蛋白质PDB文件，大体上还算正常。但是有的protein的PDB文件在PDB数据库已经不存在了，所以下载后的PDB文件理论上只属于原论文提到的PDB文件的一个子集。由于数据比较大，手动去找会耗费大量的时间，所以为了找出这些不存在的PDB文件，下面写一段代码来实现。\n\n\n## 问题转换与实现\n\n首先，将问题转化成一个数学问题。\n\n<!-- more -->\n\n问题转化：原论文提及的数据集（一个大集合U），现在下载到的只是一个子集合A，目的是求出U中不包含A的子集合（补集）：`B=U-A`.\n\n最终转化为：根据集合U和子集A，计算A的补集B=U-A.\n\n参数：\n\n- file1：大集合文件U\n- file2: 下载后的一个子集合A\n- outfile：输出文件\n\n代码如下：\n\ncompareTwoFile.py\n\n```\n#!/usr/bin/python\n#-*- coding: utf-8 -*-\nimport os\ndef compareTwoFile(file1,file2,outfile):\n    with open(outfile,'w') as fo: \n        fw = []\n        with open(file1,'r') as fr1:\n            fr1_con = [each.strip() for each in fr1.readlines()] \n            with open(file2,'r') as fr2:\n                fr2_con =[each.strip() for each in fr2.readlines()]\n                for eachline in fr1_con:\n                    if eachline not in fr2_con:\n                        fw.append(eachline)\n        fo.write(''.join(fw))\nif __name__==\"__main__\": \n    file1 = os.sys.argv[1]\n    file2 = os.sys.argv[2]\n    outfile = os.sys.argv[3]\n    compareTwoFile(file1,file2,outfile)\n```\n\nTest sample:\n\n```\npython compareTwoFile.py \\\n/ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/train_set.protein  \\\n/ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/pdb_trainset.txt \\\n/ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/compare.result\n```\n\nfile1和file2的top10格式：\n\n\t1A02\n\t1A0A\n\t1A3Q\n\t1A53\n\t1A8E\n\t1A8P\n\t1A8Y\n\t1AAC\t\n\t1ABE\n\t1AC5\n\n\t\n\n\n","slug":"2015-11-17 B=U-A","published":1,"updated":"2015-11-22T05:12:27.232Z","comments":1,"photos":[],"link":"","_id":"cimigpywz005s6cuj1uckijs7"},{"layout":"post","date":"2015-11-16T02:24:00.000Z","title":"Download PDB file with wget command","comment":true,"_content":"\n在Linux服务器下，使用`wget`命令下载PDB文件，即蛋白质文件。\n\n- 输入文件格式：一个存有`protein chain`的单独文件，每行的格式为：`1A34A`\n- 输出文件：多个蛋白质文件，买一行下载一个蛋白质，格式：1A34.pdb\n<!--more-->\ndownload.py文件\n\n```\n#!/usr/bin/python\n# -*- coding: utf-8 -*-\nimport os\ndef downloadPDB(namefile,outpath):\n    if not os.path.exists(outpath):\n        os.mkdir(outpath)\n    os.chdir(outpath)\n    inputfile = open(namefile,'r')\n    for eachline in inputfile:\n        pdbname = eachline.lower().strip()[0:4]\n        os.system(\"wget http://ftp.wwpdb.org/pub/pdb/data/structures/all/pdb/pdb\" + pdbname + \".ent.gz\")\n        os.system(\"gzip -d pdb\" + pdbname + '.ent.gz')\n        os.system(\"mv pdb\" + pdbname + \".ent \" + pdbname.upper() + '.pdb')\n    inputfile.close()\nif __name__==\"__main__\":\n    chainfile = os.sys.argv[1] \n    outpath = os.sys.argv[2]\n    proteinList = downloadPDB(chainfile,outpath)\n\"\"\"\ntest sample\npython download.py /ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/train_set.txt /ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/pdb_trainset   \n\"\"\"\n```\n\n命令解释：首先打开文件，然后逐行读取蛋白链，根据蛋白链的前四个字符，得到蛋白质的名字，然后使用`wget`命令下载`.ent.gz`文件，最后使用`gzip`解压文件即可。\n\n命令行输入：\n\n```\npython download.py ../filepath  ../dirpath\n```\n\n其中`filepath`表示的是一个存有多行，每行表示一个蛋白链的单独文件。\n\nTop10格式如下：\n\n\n\t1A12A\n\t1BCH1\n\t1BF6A\n\t1BYPA\n\t1C7JA\n\t1CHMA\n\t1CMNA\n\t1CUHA\n\t1CZYA\n\t1D7EA\n\n\n最后的输出文件Top5：\n\n\n\t1A12.pdb\n\t1BCH.pdb\n\t1BF6.pdb\n\t1BYP.pdb\n\t1C7J.pdb\n\n\n---\n\n<center><strong>\n此文乃原创博文，如果你从中有所收获，欢迎前来赞助，为博主送上你的支持：<a href=\"http://csuldw.github.io/donation\" target=\"_black\"><font color=\"red\">【赞助中心】</font></a>。<br>  CSDN博客： <a href=\"http://blog.csdn.net/dream_angel_z\" target=\"_black\">【Dream_Angel_Z】</a><br>新浪微博： <a href=\"http://weibo.com/liudiwei210\" target=\"_black\">【@拾毅者】</a><br>\n</strong></center>","source":"_posts/2015-11-16 Download PDB file with wget command.md","raw":"---\nlayout: post\ndate: 2015-11-16 10:24\ntitle: \"Download PDB file with wget command\"\ncategories: BioInfo\ntag: \n\t- BioInfo\n\t- PDB\ncomment: true\n---\n\n在Linux服务器下，使用`wget`命令下载PDB文件，即蛋白质文件。\n\n- 输入文件格式：一个存有`protein chain`的单独文件，每行的格式为：`1A34A`\n- 输出文件：多个蛋白质文件，买一行下载一个蛋白质，格式：1A34.pdb\n<!--more-->\ndownload.py文件\n\n```\n#!/usr/bin/python\n# -*- coding: utf-8 -*-\nimport os\ndef downloadPDB(namefile,outpath):\n    if not os.path.exists(outpath):\n        os.mkdir(outpath)\n    os.chdir(outpath)\n    inputfile = open(namefile,'r')\n    for eachline in inputfile:\n        pdbname = eachline.lower().strip()[0:4]\n        os.system(\"wget http://ftp.wwpdb.org/pub/pdb/data/structures/all/pdb/pdb\" + pdbname + \".ent.gz\")\n        os.system(\"gzip -d pdb\" + pdbname + '.ent.gz')\n        os.system(\"mv pdb\" + pdbname + \".ent \" + pdbname.upper() + '.pdb')\n    inputfile.close()\nif __name__==\"__main__\":\n    chainfile = os.sys.argv[1] \n    outpath = os.sys.argv[2]\n    proteinList = downloadPDB(chainfile,outpath)\n\"\"\"\ntest sample\npython download.py /ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/train_set.txt /ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/pdb_trainset   \n\"\"\"\n```\n\n命令解释：首先打开文件，然后逐行读取蛋白链，根据蛋白链的前四个字符，得到蛋白质的名字，然后使用`wget`命令下载`.ent.gz`文件，最后使用`gzip`解压文件即可。\n\n命令行输入：\n\n```\npython download.py ../filepath  ../dirpath\n```\n\n其中`filepath`表示的是一个存有多行，每行表示一个蛋白链的单独文件。\n\nTop10格式如下：\n\n\n\t1A12A\n\t1BCH1\n\t1BF6A\n\t1BYPA\n\t1C7JA\n\t1CHMA\n\t1CMNA\n\t1CUHA\n\t1CZYA\n\t1D7EA\n\n\n最后的输出文件Top5：\n\n\n\t1A12.pdb\n\t1BCH.pdb\n\t1BF6.pdb\n\t1BYP.pdb\n\t1C7J.pdb\n\n\n---\n\n<center><strong>\n此文乃原创博文，如果你从中有所收获，欢迎前来赞助，为博主送上你的支持：<a href=\"http://csuldw.github.io/donation\" target=\"_black\"><font color=\"red\">【赞助中心】</font></a>。<br>  CSDN博客： <a href=\"http://blog.csdn.net/dream_angel_z\" target=\"_black\">【Dream_Angel_Z】</a><br>新浪微博： <a href=\"http://weibo.com/liudiwei210\" target=\"_black\">【@拾毅者】</a><br>\n</strong></center>","slug":"2015-11-16 Download PDB file with wget command","published":1,"updated":"2016-03-08T08:54:14.739Z","comments":1,"photos":[],"link":"","_id":"cimigpyx2005w6cujlur1slca"},{"layout":"post","date":"2015-11-15T02:24:00.000Z","title":"Machine Learning-Normalization","comment":true,"_content":"\n\n本文主要介绍两种基本的数据归一化方法。\n\n- min-max标准化（Min-Max Normalization）\n- Z-score标准化方法\n\n归一化方法有两种形式，一种是把数变为（0，1）之间的小数，一种是把有量纲表达式变为无量纲表达式。\n\n<!--more-->\n\n数据标准化（归一化）处理是数据挖掘的一项基础工作，不同评价指标往往具有不同的量纲和量纲单位，这样的情况会影响到数据分析的结果，为了消除指标之间的量纲影响，需要进行数据标准化处理，以解决数据指标之间的可比性。原始数据经过数据标准化处理后，各指标处于同一数量级，适合进行综合对比评价。\n\n\n下面是归一化和没有归一化的比较：\n\n没有经过归一化，寻找最优解过程如下：\n\n![2015111501](/assets/images/2015111501.png)\n\n经过归一化，把各个特征的尺度控制在相同的范围内：\n\n![2015111502](/assets/images/2015111502.png)\n\n从经验上说，归一化是让不同维度之间的特征在数值上有一定比较性，可以大大提高分类器的准确性。\n\n以下是两种常用的归一化方法：\n\n## 1.min-max标准化（Min-Max Normalization）\n\n\n也称为离差标准化，是对原始数据的线性变换，使结果值映射到[0 - 1]之间。转换函数如下：\n\n\n$$x^{*}=\\frac{x-x\\_{min}}{x\\_{max}-x\\_{min}}$$\n\n\nx_min表示样本数据的最小值，x_max表示样本数据的最大值。\n\n**Python代码实现：**\n\n```\ndef Normalization(x):\n\treturn [(float(i)-min(x))/float(max(x)-min(x)) for i in x]\n```\n\n测试：\n\n```\nx=[1,2,1,4,3,2,5,6,2,7]\nb=Normalization(x)\n```\n\nOutput：\n\n\n```\n[0.0, 0.16666666666666666, 0.0, 0.5, 0.3333333333333333, 0.16666666666666666, 0.6666666666666666, 0.8333333333333334, 0.16666666666666666, 1.0]\n```\n\n如果想要将数据映射到[-1,1]，则将公式换成：\n\n$$x^{*}=\\frac{x-x\\_{mean}}{x\\_{max}-x\\_{min}}$$\n\nx_mean表示数据的均值\n\n**Python代码实现：**\n\n```\nimport numpy as np\ndef Normalization2(x):\n\treturn [(float(i)-np.mean(x))/(max(x)-min(x)) for i in x]\n```\n\n测试：\n\n```\nx=[1,2,1,4,3,2,5,6,2,7]\nb=Normalization2(x)\n```\n\nOutput：\n\n```\n[-0.3833333333333333, -0.21666666666666665, -0.3833333333333333, 0.1166666666666667, -0.049999999999999968, -0.21666666666666665, 0.28333333333333338, 0.45000000000000001, -0.21666666666666665, 0.6166666666666667]\n```\n\n注意：上面的Normalization是处理单个列表的。\n\n## 2.z-score标准化方法\n\n这种方法给予原始数据的均值（mean）和标准差（standard deviation）进行数据的标准化。经过处理的数据符合标准正态分布，即均值为0，标准差为1，转化函数为：\n\n\n\n$$x^{*}=\\frac{x-\\mu}{\\sigma}$$\n\n\n其中，μ表示所有样本数据的均值，σ表示所有样本的标准差。\n\n\n**Python代码实现：**\n\n```\nimport numpy as np\ndef z_score(x):\n    x_mean=np.mean(x)\n    s2=sum([(i-np.mean(x))*(i-np.mean(x)) for i in x])/len(x)\n    return [(i-x_mean)/s2 for i in x]\n```\n\n测试：\n\n```\nx=[1,2,1,4,3,2,5,6,2,7]\nprint z_score(x)    \n```\n\nOutput:\n\n\n```\n[-0.57356608478802995, -0.32418952618453861, -0.57356608478802995, 0.17456359102244395, -0.074812967581047343, -0.32418952618453861, 0.42394014962593524, 0.67331670822942646, -0.32418952618453861, 0.92269326683291775]\n```\n\n\n---\n\n<center><strong>\n此文乃博主即兴之作，如果你从中有所收获，欢迎前来赞助，为博主送上你的支持：<a href=\"http://csuldw.github.io/donation\" target=\"_black\"><font color=\"red\">【赞助中心】</font></a>。<br>  CSDN博客： <a href=\"http://blog.csdn.net/dream_angel_z\" target=\"_black\">【Dream_Angel_Z】</a><br>新浪微博： <a href=\"http://weibo.com/liudiwei210\" target=\"_black\">【@拾毅者】</a><br>\n</strong></center>","source":"_posts/2015-11-15 normalization.md","raw":"---\nlayout: post\ndate: 2015-11-15 10:24\ntitle: \"Machine Learning-Normalization\"\ncategories: ML\ntag: \n\t- normalization\n\t- 标准化\n\t- 预处理\ncomment: true\n---\n\n\n本文主要介绍两种基本的数据归一化方法。\n\n- min-max标准化（Min-Max Normalization）\n- Z-score标准化方法\n\n归一化方法有两种形式，一种是把数变为（0，1）之间的小数，一种是把有量纲表达式变为无量纲表达式。\n\n<!--more-->\n\n数据标准化（归一化）处理是数据挖掘的一项基础工作，不同评价指标往往具有不同的量纲和量纲单位，这样的情况会影响到数据分析的结果，为了消除指标之间的量纲影响，需要进行数据标准化处理，以解决数据指标之间的可比性。原始数据经过数据标准化处理后，各指标处于同一数量级，适合进行综合对比评价。\n\n\n下面是归一化和没有归一化的比较：\n\n没有经过归一化，寻找最优解过程如下：\n\n![2015111501](/assets/images/2015111501.png)\n\n经过归一化，把各个特征的尺度控制在相同的范围内：\n\n![2015111502](/assets/images/2015111502.png)\n\n从经验上说，归一化是让不同维度之间的特征在数值上有一定比较性，可以大大提高分类器的准确性。\n\n以下是两种常用的归一化方法：\n\n## 1.min-max标准化（Min-Max Normalization）\n\n\n也称为离差标准化，是对原始数据的线性变换，使结果值映射到[0 - 1]之间。转换函数如下：\n\n\n$$x^{*}=\\frac{x-x\\_{min}}{x\\_{max}-x\\_{min}}$$\n\n\nx_min表示样本数据的最小值，x_max表示样本数据的最大值。\n\n**Python代码实现：**\n\n```\ndef Normalization(x):\n\treturn [(float(i)-min(x))/float(max(x)-min(x)) for i in x]\n```\n\n测试：\n\n```\nx=[1,2,1,4,3,2,5,6,2,7]\nb=Normalization(x)\n```\n\nOutput：\n\n\n```\n[0.0, 0.16666666666666666, 0.0, 0.5, 0.3333333333333333, 0.16666666666666666, 0.6666666666666666, 0.8333333333333334, 0.16666666666666666, 1.0]\n```\n\n如果想要将数据映射到[-1,1]，则将公式换成：\n\n$$x^{*}=\\frac{x-x\\_{mean}}{x\\_{max}-x\\_{min}}$$\n\nx_mean表示数据的均值\n\n**Python代码实现：**\n\n```\nimport numpy as np\ndef Normalization2(x):\n\treturn [(float(i)-np.mean(x))/(max(x)-min(x)) for i in x]\n```\n\n测试：\n\n```\nx=[1,2,1,4,3,2,5,6,2,7]\nb=Normalization2(x)\n```\n\nOutput：\n\n```\n[-0.3833333333333333, -0.21666666666666665, -0.3833333333333333, 0.1166666666666667, -0.049999999999999968, -0.21666666666666665, 0.28333333333333338, 0.45000000000000001, -0.21666666666666665, 0.6166666666666667]\n```\n\n注意：上面的Normalization是处理单个列表的。\n\n## 2.z-score标准化方法\n\n这种方法给予原始数据的均值（mean）和标准差（standard deviation）进行数据的标准化。经过处理的数据符合标准正态分布，即均值为0，标准差为1，转化函数为：\n\n\n\n$$x^{*}=\\frac{x-\\mu}{\\sigma}$$\n\n\n其中，μ表示所有样本数据的均值，σ表示所有样本的标准差。\n\n\n**Python代码实现：**\n\n```\nimport numpy as np\ndef z_score(x):\n    x_mean=np.mean(x)\n    s2=sum([(i-np.mean(x))*(i-np.mean(x)) for i in x])/len(x)\n    return [(i-x_mean)/s2 for i in x]\n```\n\n测试：\n\n```\nx=[1,2,1,4,3,2,5,6,2,7]\nprint z_score(x)    \n```\n\nOutput:\n\n\n```\n[-0.57356608478802995, -0.32418952618453861, -0.57356608478802995, 0.17456359102244395, -0.074812967581047343, -0.32418952618453861, 0.42394014962593524, 0.67331670822942646, -0.32418952618453861, 0.92269326683291775]\n```\n\n\n---\n\n<center><strong>\n此文乃博主即兴之作，如果你从中有所收获，欢迎前来赞助，为博主送上你的支持：<a href=\"http://csuldw.github.io/donation\" target=\"_black\"><font color=\"red\">【赞助中心】</font></a>。<br>  CSDN博客： <a href=\"http://blog.csdn.net/dream_angel_z\" target=\"_black\">【Dream_Angel_Z】</a><br>新浪微博： <a href=\"http://weibo.com/liudiwei210\" target=\"_black\">【@拾毅者】</a><br>\n</strong></center>","slug":"2015-11-15 normalization","published":1,"updated":"2016-03-08T08:53:59.832Z","comments":1,"photos":[],"link":"","_id":"cimigpyxd00616cuj8dvob89d"},{"layout":"post","date":"2015-11-03T08:24:00.000Z","title":"Add header and footer to some file","comment":true,"_content":"\n今天整理资料的时候，发现要在很多文件中的头部和尾部添加相同的文本，于是自己使用Python做了一个简单的文件拼接功能，也可以说是文件追加功能，给一个文件批量追加头尾内容，达到省事的效果，顺便还可以练习下Python。下面来介绍下这个功能的代码：\n\n现在有三个文件，如下：\n\n- content.txt 位于一个叫path的文件中；\n- header.txt用于添加到content.txt头部的文件；\n- footer.txt用于添加到content.txt尾部的文件。\n\n\n现在要实现的功能就是，将header和footer分别添加到content的头部和尾部。 \n\n<!--more-->\n\n---\n\n函数说明：\n\n- add_footer(infile, outfile)：用于将footer内容添加到content中，第一个参数表示的添加到尾部的文件，如输入footer.txt，第二个为内容文件。如content.txt文件\n- add_header(infile, outfile, auto=True): 用于将一个文件放入好另一个文件的头部，如果auto=Ture，则不对内容做修改，auto为False的话，这里添加了部分需要的东西，如文件的创建时间、标题等信息。\n- addHeadAndFooter(path, header, footer, auto=False)：核心函数，调用头尾两个方法，此处的path为文件夹名称，该函数的功能是将path文件夹下的所有文件都添加头和尾的内容，auto默认为False，功能和上面的相同。\n- getStdTime(seconds):将时间戳格式的日期转换为标准格式，如：2015-11-03 10:24\n\n\n代码（AddHeader.py）：\n\n\n```\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Tue Nov 03 10:32:26 2015\n@author: liudiwei\n\"\"\"\nimport os,time\ndef add_footer(infile, outfile):\n    with open(infile,'r') as inputfile:\n        with open(outfile,'a') as outfile:\n            outfile.write(\"\\n\\n\"+''.join(inputfile.readlines()))\n#如果auto==True，直接将文件内容加入到当前文件\ndef add_header(infile, outfile, auto=True): \n    inf=open(infile,'r')\n    outf = open(outfile,'r')\n    header = inf.readlines()\n    content=outf.readlines()\n    if auto==True:\n        with open(outfile,'w') as output:\n            output.write(''.join(header)+ \"\\n\\n\" \\\n                            +''.join(content))  \n    else:\n        ctime=getStdTime(os.path.getctime(outfile))\n        title=\"title: \" + outfile.split('/')[1].split('.')[0]\n        print title\n        add_content=\"---\\n\"\n        add_content=add_content+title+'\\n'  #add title\n        add_content=add_content+ctime +'\\n' #add date\n        add_content=add_content+''.join(header)\n        with open(outfile,'w') as output:\n            output.write(''.join(add_content)+ \"\\n\\n\" \\\n                        +''.join(content))  \n    outf.close()\n    inf.close()\ndef addHeadAndFooter(path, header, footer, auto=False):\n    filelist=os.listdir(path)\n    for eachfile in filelist:\n        add_header(header,path + \"/\" + eachfile, auto)\n        add_footer(footer,path + \"/\" + eachfile)       \ndef getStdTime(seconds):\n    x = time.localtime(seconds)\n    return \"date: \"+ time.strftime('%Y-%m-%d %H:%M:%S',x)        \nif __name__=='__main__':\n    if (len(os.sys.argv)<4):\n        raise TypeError()\n    else:\n        print \"os.sys.arg\"\n    #path=\"path\"\n    #header=\"head.md\"\n    #footer=\"footer.md\"\n    os.chdir(\".\")\n    path=os.sys.argv[1]\n    print path\n    header=os.sys.argv[2]\n    footer=os.sys.argv[3]\n    filelist=os.listdir(path)\n    addHeadAndFooter(path,header,footer)\n    print \"Success added!\"    \n#----------------    \n# command \n# python AddHead.py \"path\" \"header.txt\" \"footer.txt\"\n#----------------\n```\n\n直接在console控制台上运行下列代码即可 \n\n```\npython AddHeader.py \"path\" \"header.txt\" \"footer.txt\"\n```\n\n\n\n---\n\n\n\n","source":"_posts/2015-11-03 Add header and footer to some file.md","raw":"---\nlayout: post\ndate: 2015-11-03 16:24\ntitle: \"Add header and footer to some file\"\ncategories: Python\ntag: \n\t- Python\ncomment: true\n---\n\n今天整理资料的时候，发现要在很多文件中的头部和尾部添加相同的文本，于是自己使用Python做了一个简单的文件拼接功能，也可以说是文件追加功能，给一个文件批量追加头尾内容，达到省事的效果，顺便还可以练习下Python。下面来介绍下这个功能的代码：\n\n现在有三个文件，如下：\n\n- content.txt 位于一个叫path的文件中；\n- header.txt用于添加到content.txt头部的文件；\n- footer.txt用于添加到content.txt尾部的文件。\n\n\n现在要实现的功能就是，将header和footer分别添加到content的头部和尾部。 \n\n<!--more-->\n\n---\n\n函数说明：\n\n- add_footer(infile, outfile)：用于将footer内容添加到content中，第一个参数表示的添加到尾部的文件，如输入footer.txt，第二个为内容文件。如content.txt文件\n- add_header(infile, outfile, auto=True): 用于将一个文件放入好另一个文件的头部，如果auto=Ture，则不对内容做修改，auto为False的话，这里添加了部分需要的东西，如文件的创建时间、标题等信息。\n- addHeadAndFooter(path, header, footer, auto=False)：核心函数，调用头尾两个方法，此处的path为文件夹名称，该函数的功能是将path文件夹下的所有文件都添加头和尾的内容，auto默认为False，功能和上面的相同。\n- getStdTime(seconds):将时间戳格式的日期转换为标准格式，如：2015-11-03 10:24\n\n\n代码（AddHeader.py）：\n\n\n```\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Tue Nov 03 10:32:26 2015\n@author: liudiwei\n\"\"\"\nimport os,time\ndef add_footer(infile, outfile):\n    with open(infile,'r') as inputfile:\n        with open(outfile,'a') as outfile:\n            outfile.write(\"\\n\\n\"+''.join(inputfile.readlines()))\n#如果auto==True，直接将文件内容加入到当前文件\ndef add_header(infile, outfile, auto=True): \n    inf=open(infile,'r')\n    outf = open(outfile,'r')\n    header = inf.readlines()\n    content=outf.readlines()\n    if auto==True:\n        with open(outfile,'w') as output:\n            output.write(''.join(header)+ \"\\n\\n\" \\\n                            +''.join(content))  \n    else:\n        ctime=getStdTime(os.path.getctime(outfile))\n        title=\"title: \" + outfile.split('/')[1].split('.')[0]\n        print title\n        add_content=\"---\\n\"\n        add_content=add_content+title+'\\n'  #add title\n        add_content=add_content+ctime +'\\n' #add date\n        add_content=add_content+''.join(header)\n        with open(outfile,'w') as output:\n            output.write(''.join(add_content)+ \"\\n\\n\" \\\n                        +''.join(content))  \n    outf.close()\n    inf.close()\ndef addHeadAndFooter(path, header, footer, auto=False):\n    filelist=os.listdir(path)\n    for eachfile in filelist:\n        add_header(header,path + \"/\" + eachfile, auto)\n        add_footer(footer,path + \"/\" + eachfile)       \ndef getStdTime(seconds):\n    x = time.localtime(seconds)\n    return \"date: \"+ time.strftime('%Y-%m-%d %H:%M:%S',x)        \nif __name__=='__main__':\n    if (len(os.sys.argv)<4):\n        raise TypeError()\n    else:\n        print \"os.sys.arg\"\n    #path=\"path\"\n    #header=\"head.md\"\n    #footer=\"footer.md\"\n    os.chdir(\".\")\n    path=os.sys.argv[1]\n    print path\n    header=os.sys.argv[2]\n    footer=os.sys.argv[3]\n    filelist=os.listdir(path)\n    addHeadAndFooter(path,header,footer)\n    print \"Success added!\"    \n#----------------    \n# command \n# python AddHead.py \"path\" \"header.txt\" \"footer.txt\"\n#----------------\n```\n\n直接在console控制台上运行下列代码即可 \n\n```\npython AddHeader.py \"path\" \"header.txt\" \"footer.txt\"\n```\n\n\n\n---\n\n\n\n","slug":"2015-11-03 Add header and footer to some file","published":1,"updated":"2016-03-13T05:54:59.446Z","comments":1,"photos":[],"link":"","_id":"cimigpyxp00686cujeo4kd4ot"},{"layout":"post","date":"2015-10-29T12:24:00.000Z","title":"Python-RegEx（正则表达式）","comment":true,"_content":"\n关于Python的正则表达式，初步学习了下，感觉跟shell脚本的正则表达式大体相同，先来做个小结吧！\n\n## 正则表达式\n\n正则表达式在实际的文本文件处理中，经常用到，其实正则表达式并不是Python的一部分，其它语言中都有。正则表达式是用于处理字符串的强大工具，拥有自己独特的语法以及一个独立的处理引擎，效率上可能不如str自带的方法，但功能真的十分强大。得益于这一点，在提供了正则表达式的语言里，正则表达式的语法都是一样的，区别只在于不同的编程语言实现支持的语法数量不同；但不用担心，不被支持的语法通常是不常用的部分。如果已经在其他语言里使用过正则表达式，只需要简单看一看就可以上手了。\n\n下图展示了使用正则表达式进行匹配的流程： \n\n![](http://ww4.sinaimg.cn/large/637f3c58gw1exic0q7k4ej20cj055t9e.jpg)\n\n<!-- more -->\n\n从上图我们可以看出，正则表达式的大致匹配过程是：依次拿出表达式和文本中的字符比较，如果每一个字符都能匹配，则匹配成功；一旦有匹配不成功的字符则匹配失败。如果表达式中有量词或边界，这个过程会稍微有一些不同，但也是很好理解的，来看看下面的这个正则表达式模式。\n\n|ID|模式|描述|  \n|-------------|--------------:| ------------- |\n|1|^|\t匹配字符串的开头|\n|2|$|\t匹配字符串的末尾。|\n|3|.|\t匹配任意字符，除了换行符，当re.DOTALL标记被指定时，则可以匹配包括换行符的任意字符。|\n|4|[...]|\t用来表示一组字符,单独列出：[amk] 匹配 'a'，'m'或'k'|\n|5|[^...]|\t不在[]中的字符：[^abc] 匹配除了a,b,c之外的字符。|\n|6|*|\t匹配0个或多个的表达式。|\n|7|+|\t匹配1个或多个的表达式。|\n|8|?|\t 匹配0个或1个由前面的正则表达式定义的片段，非贪婪方式|\n|9|{ n,}|\t精确匹配n个前面表达式。|\n|10|{n,m}|\t匹配 n 到 m 次由前面的正则表达式定义的片段，贪婪方式|\n|11|(re)|\tG匹配括号内的表达式，也表示一个组|\n|12|(?imx)|\t正则表达式包含三种可选标志：i, m, 或 x 。只影响括号中的区域。|\n|13|(?-imx)|\t正则表达式关闭 i, m, 或 x 可选标志。只影响括号中的区域。|\n|14|(?:re)|\t 类似 (...), 但是不表示一个组|\n|15|(?imx:re)|\t在括号中使用i, m, 或 x 可选标志|\n|16|(?-imx:re)|\t在括号中不使用i, m, 或 x 可选标志|\n|17|(?#...)|\t注释.|\n|18|(?=re)|\t前向肯定界定符。如果所含正则表达式，以 ... 表示，在当前位置成功匹配时成功，否则失败。但一旦所含表达式已经尝试，匹配引擎根本没有提高；模式的剩余部分还要尝试界定符的右边。|\n|19|(?!re)|\t前向否定界定符。与肯定界定符相反；当所含表达式不能在字符串当前位置匹配时成功|\n|20|(?>re)|\t匹配的独立模式，省去回溯。|\n|21|\\w|\t匹配字母数字,等价于'[A-Za-z0-9_]'|\n|22|\\W|\t匹配非字母数字, [^A-Za-z0-9_]'|\n|23|\\s|\t匹配任意空白字符，等价于[\\t\\n\\r\\f].|\n|24|\\S|\t匹配任意非空字符,等价于[^ \\f\\n\\r\\t\\v]|\n|25|\\d|\t匹配任意数字，等价于[0-9].|\n|26|\\D|\t匹配任意非数字,等价于[^0-9]。|\n|27|\\A|\t匹配字符串开始|\n|28|\\Z|\t匹配字符串结束，如果是存在换行，只匹配到换行前的结束字符串。c|\n|29|\\z|\t匹配字符串结束|\n|30|\\G|\t匹配最后匹配完成的位置。|\n|31|\\b|\t匹配一个单词边界，也就是指单词和空格间的位置。例如， 'er\\b' 可以匹配\"never\" 中的 'er'，但不能匹配 \"verb\" 中的 'er'。|\n|32|\\B|\t匹配非单词边界。'er\\B' 能匹配 \"verb\" 中的 'er'，但不能匹配 \"never\" 中的 'er'。|\n|33|\\n, \\t, 等.|\t匹配一个换行符。匹配一个制表符。等|\n|34|\\1...\\9|\t匹配第n个分组的子表达式。|\n|35|\\10|\t匹配第n个分组的子表达式，如果它经匹配。否则指的是八进制字符码的表达式。|\n\n\n下面从正则表达式的几个函数/方法来简单介绍下正则表达式的用法。\n\n---\n\n## re.match()函数\n\nre.match 尝试<font color=\"#007FFF\">**从字符串的开头匹配一个模式**</font>，如：下面的例子匹配第一个单词。 \n\n```\nimport re\ntext = \"This is a very beautiful girl, I like her very much.\"\nm = re.match(r\"(\\w+)\\s\", text)\nif m:\n\tprint m.group(0), '\\n', m.group(1)\nelse:\n\tprint 'not match'  \n```\n\n输出:\n<pre><code class=\"markdown\">\nThis\nThis\n</code></pre>\n\nre.match的函数原型为：re.match(pattern, string, flags)\n\n* 第一个参数是正则表达式，这里为\"(\\w+)\\s\"，如果匹配成功，则返回一个Match，否则返回一个None；\n* 第二个参数表示要匹配的字符串；\n* 第三个参数是标致位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。\n\n---\n\n\n## re.search()函数\n\nre.search函数会在字符串内查找模式匹配,只到找到第一个匹配然后返回，如果字符串没有匹配，则返回None。\n\n\n```\nimport re\ntext = \"This is a very beautiful girl, I like her very much.\"\nm = re.search(r'\\sbeaut(i)ful\\s', text)\nif m:\n\tprint m.group(0), m.group(1)\nelse:\n\tprint 'not search' \n```\n\n输出结果：\n\n<pre><code class=\"markdown\">\nbeautiful i\n</code></pre>\n\nre.search的函数原型为： re.search(pattern, string, flags)\n\n每个参数的含意与re.match一样。 \n\n---\n\n## re.match()与re.search()的区别\n\n<font color=\"#007FFF\">**re.match只匹配字符串的开始，如果字符串从一开始就不符合正则表达式，则匹配失败，函数返回None；而re.search匹配整个字符串，直到找到一个匹配。**</font>\n\n请看下面这个实例：\n\n\n```\nimport re\nline = \"This is a very beautiful girl, I like her very much.\";\nm = re.match( r'girl', line, re.M|re.I)\nif m:\n   print \"match --> m.group() : \", m.group()\nelse:\n   print \"No match!!\"\n```\n\nmatch会从字符串起始出进行模式匹配，即模式中的其实字母‘g’匹配‘This’中的‘T’，所以，匹配失败。\n\n<pre><code class=\"markdown\">No match!!\n</code></pre>\n\n如果使用的是search，来看看结果：\n\n\n```\nm = re.search( r'girl', line, re.M|re.I)\nif m:\n   print \"search --> m.group() : \", m.group()\nelse:\n   print \"No match!\"\n```\n\n以上实例运行结果如下：\n\n\n<pre><code class=\"markdown\">search --> m.group() :  girl\n</code></pre>\n\n---\n\n## re.sub() & re.subn()函数\n\nre.sub用于替换字符串中的匹配项。下面一个例子将字符串中的空格 ' ' 替换成 '-' : \n\n```\nimport re\ntext = \"I like Cats more than dogs!\"\nprint re.sub(r'\\s+', '-', text) \n\n```\n\n输出：\n\n<pre><code class=\"markdown\">\nI-like-Cats-more-than-dogs!\n</code></pre>\n\n\nre.sub的函数原型为：<font color=\"#007FFF\">**re.sub(pattern, repl, string, count)**</font>\n\n其中第二个函数是替换后的字符串；本例中为'-'\n\n第四个参数指替换个数。默认为0，表示每个匹配项都替换。\n\nre.sub还允许使用函数对匹配项的替换进行复杂的处理。如：re.sub(r'\\s', lambda m: '[' + m.group(0) + ']', text, 0)；将字符串中的空格' '替换为'[ ]'。\n\n\n注：re.subn和re.sub大体相似，唯一不同的就是返回结果，subn会将匹配的个数也显示出来。\n\n如：\n\n```\n>>>import re\n>>>text = \"I like Cats more than dogs!\"\n>>>print re.subn(r'\\s+', '-', text)\n\n('I-like-Cats-more-than-dogs!', 5)\n```\n\n---\n\n\n## re.split()函数\n\n可以使用re.split来分割字符串，如：re.split(r'-', text)；将字符串按'-'符号分割成一个单词列表。\n\n```\nimport re\ntext=\"I-really-like-this-girl!\"\nre.split(r'-',text)\n```\n\n输出：\n\n<pre><code class=\"markdown\">\n['I', 'really', 'like', 'this', 'girl!']\n</code></pre>\n\n\n---\n\n## re.findall()函数\n\nre.findall可以获取字符串中所有匹配的字符串。如：re.findall(r'\\w\\*i\\w\\*', text)；获取字符串中，包含'oo'的所有单词。\n\n\n```\nimport re\ntext=\"I-really-like-this-girl!\"\nre.findall(r'girl',text)\n```\n输出结果：\n<pre><code class=\"markdown\">['like', 'this', 'girl']\n</code></pre>\n\n---\n\n## re.compile()函数\n\n可以把正则表达式编译成一个正则表达式对象。可以把那些经常使用的正则表达式编译成正则表达式对象，这样可以提高一定的效率。下面是一个正则表达式对象的一个例子：\n\n\n```\nimport re\nregex = re.compile(r'\\w*er\\w*') # 将正则表达式编译成Pattern对象\ntext = \"This is a very beautiful girl, I like her very much.\"\nm = regex.search(text) #使用regex来匹配text字符串\nif m:\n    print m.group() # 使用Match获得分组信息\nprint regex.findall(text)   #查找所有包含'oo'的单词\nprint regex.sub(lambda m: '[' + m.group(0) + ']', text) #将字符串中含有'oo'的单词用[]括起来。\n```\n\n分别输出下列信息：\n\n<pre><code class=\"markdown\">'very'\n['very', 'her', 'very']\nThis is a [very] beautiful girl, I like [her] [very] much.\n</code></pre>\n\n---\n\n## 邮箱验证\n\n使用Python写一个简单的邮箱验证的正则表达式：\n\n根据csu.ldw@csu.edu.cn来填写规则\n\n规则：\n\n- @前面可以有'.', '_', '-', 但不能出现在头尾，而且不能连续出现\n- @后面到结尾之间，可以有多个子域名\n- 邮箱的结尾为2~5个字母，比如cn、com、name等\n \n```\n#-*- coding: utf-8 -*-\n\"\"\"\nCreated on Thu Oct 29 20:28:57 2015\n@author: liudiwei\n\"\"\"\nimport re\nregex = re.compile('^[A-Za-z0-9]+(([\\.\\_\\-])?[A-Za-z0-9]+)+@([A-Za-z]+.)+[A-Za-z]{2,5}$')\nm = regex.match(\"csu.ldw@csu.edu.cn\")\nif m:\n    print m.group()\nelse:\n    print \"no match!\"\n```\n\n测试输出：\n\n<pre><code class=\"markdown\">csu.ldw@csu.edu.cn\n</code></pre>\n\n当m = regex.match(\"_csu.ldw@csu.edu.cn\")\n当邮箱为：\n\n<pre><code class=\"markdown\">_csu.ldw@csu.edu.cn  \ncsu.ldw_@csu.edu.cn\ncsu.ldw@csu_.edu.cn\n_csu.ldw@csu.edu.cn1\n</code></pre>\n\n都不会匹配\n\n提示：合法邮箱的规则可能不够完善，这里就简单的匹配这三个规则吧！\n\n---","source":"_posts/2015-10-29 Python RegEx.md","raw":"---\nlayout: post\ndate: 2015-10-29 20:24\ntitle: \"Python-RegEx（正则表达式）\"\ncategories: Python\ntag: \n\t- Python\n\t- 正则表达式\n\t- RegEx\ncomment: true\n---\n\n关于Python的正则表达式，初步学习了下，感觉跟shell脚本的正则表达式大体相同，先来做个小结吧！\n\n## 正则表达式\n\n正则表达式在实际的文本文件处理中，经常用到，其实正则表达式并不是Python的一部分，其它语言中都有。正则表达式是用于处理字符串的强大工具，拥有自己独特的语法以及一个独立的处理引擎，效率上可能不如str自带的方法，但功能真的十分强大。得益于这一点，在提供了正则表达式的语言里，正则表达式的语法都是一样的，区别只在于不同的编程语言实现支持的语法数量不同；但不用担心，不被支持的语法通常是不常用的部分。如果已经在其他语言里使用过正则表达式，只需要简单看一看就可以上手了。\n\n下图展示了使用正则表达式进行匹配的流程： \n\n![](http://ww4.sinaimg.cn/large/637f3c58gw1exic0q7k4ej20cj055t9e.jpg)\n\n<!-- more -->\n\n从上图我们可以看出，正则表达式的大致匹配过程是：依次拿出表达式和文本中的字符比较，如果每一个字符都能匹配，则匹配成功；一旦有匹配不成功的字符则匹配失败。如果表达式中有量词或边界，这个过程会稍微有一些不同，但也是很好理解的，来看看下面的这个正则表达式模式。\n\n|ID|模式|描述|  \n|-------------|--------------:| ------------- |\n|1|^|\t匹配字符串的开头|\n|2|$|\t匹配字符串的末尾。|\n|3|.|\t匹配任意字符，除了换行符，当re.DOTALL标记被指定时，则可以匹配包括换行符的任意字符。|\n|4|[...]|\t用来表示一组字符,单独列出：[amk] 匹配 'a'，'m'或'k'|\n|5|[^...]|\t不在[]中的字符：[^abc] 匹配除了a,b,c之外的字符。|\n|6|*|\t匹配0个或多个的表达式。|\n|7|+|\t匹配1个或多个的表达式。|\n|8|?|\t 匹配0个或1个由前面的正则表达式定义的片段，非贪婪方式|\n|9|{ n,}|\t精确匹配n个前面表达式。|\n|10|{n,m}|\t匹配 n 到 m 次由前面的正则表达式定义的片段，贪婪方式|\n|11|(re)|\tG匹配括号内的表达式，也表示一个组|\n|12|(?imx)|\t正则表达式包含三种可选标志：i, m, 或 x 。只影响括号中的区域。|\n|13|(?-imx)|\t正则表达式关闭 i, m, 或 x 可选标志。只影响括号中的区域。|\n|14|(?:re)|\t 类似 (...), 但是不表示一个组|\n|15|(?imx:re)|\t在括号中使用i, m, 或 x 可选标志|\n|16|(?-imx:re)|\t在括号中不使用i, m, 或 x 可选标志|\n|17|(?#...)|\t注释.|\n|18|(?=re)|\t前向肯定界定符。如果所含正则表达式，以 ... 表示，在当前位置成功匹配时成功，否则失败。但一旦所含表达式已经尝试，匹配引擎根本没有提高；模式的剩余部分还要尝试界定符的右边。|\n|19|(?!re)|\t前向否定界定符。与肯定界定符相反；当所含表达式不能在字符串当前位置匹配时成功|\n|20|(?>re)|\t匹配的独立模式，省去回溯。|\n|21|\\w|\t匹配字母数字,等价于'[A-Za-z0-9_]'|\n|22|\\W|\t匹配非字母数字, [^A-Za-z0-9_]'|\n|23|\\s|\t匹配任意空白字符，等价于[\\t\\n\\r\\f].|\n|24|\\S|\t匹配任意非空字符,等价于[^ \\f\\n\\r\\t\\v]|\n|25|\\d|\t匹配任意数字，等价于[0-9].|\n|26|\\D|\t匹配任意非数字,等价于[^0-9]。|\n|27|\\A|\t匹配字符串开始|\n|28|\\Z|\t匹配字符串结束，如果是存在换行，只匹配到换行前的结束字符串。c|\n|29|\\z|\t匹配字符串结束|\n|30|\\G|\t匹配最后匹配完成的位置。|\n|31|\\b|\t匹配一个单词边界，也就是指单词和空格间的位置。例如， 'er\\b' 可以匹配\"never\" 中的 'er'，但不能匹配 \"verb\" 中的 'er'。|\n|32|\\B|\t匹配非单词边界。'er\\B' 能匹配 \"verb\" 中的 'er'，但不能匹配 \"never\" 中的 'er'。|\n|33|\\n, \\t, 等.|\t匹配一个换行符。匹配一个制表符。等|\n|34|\\1...\\9|\t匹配第n个分组的子表达式。|\n|35|\\10|\t匹配第n个分组的子表达式，如果它经匹配。否则指的是八进制字符码的表达式。|\n\n\n下面从正则表达式的几个函数/方法来简单介绍下正则表达式的用法。\n\n---\n\n## re.match()函数\n\nre.match 尝试<font color=\"#007FFF\">**从字符串的开头匹配一个模式**</font>，如：下面的例子匹配第一个单词。 \n\n```\nimport re\ntext = \"This is a very beautiful girl, I like her very much.\"\nm = re.match(r\"(\\w+)\\s\", text)\nif m:\n\tprint m.group(0), '\\n', m.group(1)\nelse:\n\tprint 'not match'  \n```\n\n输出:\n<pre><code class=\"markdown\">\nThis\nThis\n</code></pre>\n\nre.match的函数原型为：re.match(pattern, string, flags)\n\n* 第一个参数是正则表达式，这里为\"(\\w+)\\s\"，如果匹配成功，则返回一个Match，否则返回一个None；\n* 第二个参数表示要匹配的字符串；\n* 第三个参数是标致位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。\n\n---\n\n\n## re.search()函数\n\nre.search函数会在字符串内查找模式匹配,只到找到第一个匹配然后返回，如果字符串没有匹配，则返回None。\n\n\n```\nimport re\ntext = \"This is a very beautiful girl, I like her very much.\"\nm = re.search(r'\\sbeaut(i)ful\\s', text)\nif m:\n\tprint m.group(0), m.group(1)\nelse:\n\tprint 'not search' \n```\n\n输出结果：\n\n<pre><code class=\"markdown\">\nbeautiful i\n</code></pre>\n\nre.search的函数原型为： re.search(pattern, string, flags)\n\n每个参数的含意与re.match一样。 \n\n---\n\n## re.match()与re.search()的区别\n\n<font color=\"#007FFF\">**re.match只匹配字符串的开始，如果字符串从一开始就不符合正则表达式，则匹配失败，函数返回None；而re.search匹配整个字符串，直到找到一个匹配。**</font>\n\n请看下面这个实例：\n\n\n```\nimport re\nline = \"This is a very beautiful girl, I like her very much.\";\nm = re.match( r'girl', line, re.M|re.I)\nif m:\n   print \"match --> m.group() : \", m.group()\nelse:\n   print \"No match!!\"\n```\n\nmatch会从字符串起始出进行模式匹配，即模式中的其实字母‘g’匹配‘This’中的‘T’，所以，匹配失败。\n\n<pre><code class=\"markdown\">No match!!\n</code></pre>\n\n如果使用的是search，来看看结果：\n\n\n```\nm = re.search( r'girl', line, re.M|re.I)\nif m:\n   print \"search --> m.group() : \", m.group()\nelse:\n   print \"No match!\"\n```\n\n以上实例运行结果如下：\n\n\n<pre><code class=\"markdown\">search --> m.group() :  girl\n</code></pre>\n\n---\n\n## re.sub() & re.subn()函数\n\nre.sub用于替换字符串中的匹配项。下面一个例子将字符串中的空格 ' ' 替换成 '-' : \n\n```\nimport re\ntext = \"I like Cats more than dogs!\"\nprint re.sub(r'\\s+', '-', text) \n\n```\n\n输出：\n\n<pre><code class=\"markdown\">\nI-like-Cats-more-than-dogs!\n</code></pre>\n\n\nre.sub的函数原型为：<font color=\"#007FFF\">**re.sub(pattern, repl, string, count)**</font>\n\n其中第二个函数是替换后的字符串；本例中为'-'\n\n第四个参数指替换个数。默认为0，表示每个匹配项都替换。\n\nre.sub还允许使用函数对匹配项的替换进行复杂的处理。如：re.sub(r'\\s', lambda m: '[' + m.group(0) + ']', text, 0)；将字符串中的空格' '替换为'[ ]'。\n\n\n注：re.subn和re.sub大体相似，唯一不同的就是返回结果，subn会将匹配的个数也显示出来。\n\n如：\n\n```\n>>>import re\n>>>text = \"I like Cats more than dogs!\"\n>>>print re.subn(r'\\s+', '-', text)\n\n('I-like-Cats-more-than-dogs!', 5)\n```\n\n---\n\n\n## re.split()函数\n\n可以使用re.split来分割字符串，如：re.split(r'-', text)；将字符串按'-'符号分割成一个单词列表。\n\n```\nimport re\ntext=\"I-really-like-this-girl!\"\nre.split(r'-',text)\n```\n\n输出：\n\n<pre><code class=\"markdown\">\n['I', 'really', 'like', 'this', 'girl!']\n</code></pre>\n\n\n---\n\n## re.findall()函数\n\nre.findall可以获取字符串中所有匹配的字符串。如：re.findall(r'\\w\\*i\\w\\*', text)；获取字符串中，包含'oo'的所有单词。\n\n\n```\nimport re\ntext=\"I-really-like-this-girl!\"\nre.findall(r'girl',text)\n```\n输出结果：\n<pre><code class=\"markdown\">['like', 'this', 'girl']\n</code></pre>\n\n---\n\n## re.compile()函数\n\n可以把正则表达式编译成一个正则表达式对象。可以把那些经常使用的正则表达式编译成正则表达式对象，这样可以提高一定的效率。下面是一个正则表达式对象的一个例子：\n\n\n```\nimport re\nregex = re.compile(r'\\w*er\\w*') # 将正则表达式编译成Pattern对象\ntext = \"This is a very beautiful girl, I like her very much.\"\nm = regex.search(text) #使用regex来匹配text字符串\nif m:\n    print m.group() # 使用Match获得分组信息\nprint regex.findall(text)   #查找所有包含'oo'的单词\nprint regex.sub(lambda m: '[' + m.group(0) + ']', text) #将字符串中含有'oo'的单词用[]括起来。\n```\n\n分别输出下列信息：\n\n<pre><code class=\"markdown\">'very'\n['very', 'her', 'very']\nThis is a [very] beautiful girl, I like [her] [very] much.\n</code></pre>\n\n---\n\n## 邮箱验证\n\n使用Python写一个简单的邮箱验证的正则表达式：\n\n根据csu.ldw@csu.edu.cn来填写规则\n\n规则：\n\n- @前面可以有'.', '_', '-', 但不能出现在头尾，而且不能连续出现\n- @后面到结尾之间，可以有多个子域名\n- 邮箱的结尾为2~5个字母，比如cn、com、name等\n \n```\n#-*- coding: utf-8 -*-\n\"\"\"\nCreated on Thu Oct 29 20:28:57 2015\n@author: liudiwei\n\"\"\"\nimport re\nregex = re.compile('^[A-Za-z0-9]+(([\\.\\_\\-])?[A-Za-z0-9]+)+@([A-Za-z]+.)+[A-Za-z]{2,5}$')\nm = regex.match(\"csu.ldw@csu.edu.cn\")\nif m:\n    print m.group()\nelse:\n    print \"no match!\"\n```\n\n测试输出：\n\n<pre><code class=\"markdown\">csu.ldw@csu.edu.cn\n</code></pre>\n\n当m = regex.match(\"_csu.ldw@csu.edu.cn\")\n当邮箱为：\n\n<pre><code class=\"markdown\">_csu.ldw@csu.edu.cn  \ncsu.ldw_@csu.edu.cn\ncsu.ldw@csu_.edu.cn\n_csu.ldw@csu.edu.cn1\n</code></pre>\n\n都不会匹配\n\n提示：合法邮箱的规则可能不够完善，这里就简单的匹配这三个规则吧！\n\n---","slug":"2015-10-29 Python RegEx","published":1,"updated":"2016-03-23T12:25:49.452Z","comments":1,"photos":[],"link":"","_id":"cimigpyxs006b6cuj8nsu98fg"},{"layout":"post","date":"2015-10-25T02:24:00.000Z","title":"scikit-learn Preprocessing","comment":true,"_content":"\n本文主要是对照[scikit-learn的preprocessing](http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing)章节结合代码简单的回顾下预处理技术的几种方法，主要包括标准化、数据最大最小缩放处理、正则化、特征二值化和数据缺失值处理。内容比较简单，仅供参考！\n\n首先来回顾一下下面要用到的基本知识。\n\n<!-- more -->\n## **一、知识回顾**\n\n均值公式：\n\n$$\\bar{x}=\\frac{1}{n}\\sum\\_{i=1}^{n}x_{i}$$\n\n方差公式：\n\n$$s^{2}=\\frac{1}{n}\\sum\\_{i=1}^{n}(x_{i}-\\bar{x})^{2}$$\n\n0-范数，向量中非零元素的个数。\n\n1-范数：\n\n$$||X||= \\sum\\_{i=1}^{n} |x_{i}|$$\n\n2-范数：\n\n$$||X||\\_{2} =  (\\sum\\_{i=1}^{n} x_{i}^{2})^{\\frac{1}{2}}$$\n\np-范数的计算公式：\n\n$$||X||_{p}=(|x1|^{p}+|x2|^{p}+...+|xn|^{p})^{\\frac{1}{p}}$$\n\n---\n\n数据标准化：当单个特征的样本取值相差甚大或明显不遵从高斯正态分布时，标准化表现的效果较差。实际操作中，经常忽略特征数据的分布形状，移除每个特征均值，划分离散特征的标准差，从而等级化，进而实现数据中心化。\n\n## **二、标准化(Standardization)，或者去除均值和方差进行缩放**\n\n公式为：(X-X_mean)/X_std 计算时对每个属性/每列分别进行.\n\n将数据按其属性(按列进行)减去其均值，然后除以其方差。最后得到的结果是，对每个属性/每列来说所有数据都聚集在0附近，方差值为1。\n\n首先说明下sklearn中preprocessing库里面的scale函数使用方法：\n\n```\nsklearn.preprocessing.scale(X, axis=0, with_mean=True,with_std=True,copy=True)\n```\n\n根据参数的不同，可以沿任意轴标准化数据集。\n\n参数解释：\n\n- X：数组或者矩阵\n- axis：int类型，初始值为0，axis用来计算均值 means 和标准方差 standard deviations. 如果是0，则单独的标准化每个特征（列），如果是1，则标准化每个观测样本（行）。\n- with_mean: boolean类型，默认为True，表示将数据均值规范到0\n- with_std: boolean类型，默认为True，表示将数据方差规范到1\n\n**一个简单的例子**\n\n假设现在我构造一个数据集X，然后想要将其标准化。下面使用不同的方法来标准化X：\n\n**方法一：使用sklearn.preprocessing.scale()函数**\n\n**方法说明：**\n\n- X.mean(axis=0)用来计算数据X每个特征的均值；\n- X.std(axis=0)用来计算数据X每个特征的方差；\n- preprocessing.scale(X)直接标准化数据X。\n\n将代码整理到一个文件中：\n\n```\nfrom sklearn import preprocessing \nimport numpy as np\nX = np.array([[ 1., -1.,  2.],\n              [ 2.,  0.,  0.],\n              [ 0.,  1., -1.]])\n# calculate mean\nX_mean = X.mean(axis=0)\n# calculate variance \nX_std = X.std(axis=0)\n# standardize X\nX1 = (X-X_mean)/X_std\n# use function preprocessing.scale to standardize X\nX_scale = preprocessing.scale(X)\n```\n\n最后X_scale的值和X1的值是一样的，前面是单独的使用数学公式来计算，主要是为了形成一个对比，能够更好的理解scale()方法。\n\n**方法2：sklearn.preprocessing.StandardScaler类**\n\n该方法也可以对数据X进行标准化处理，实例如下：\n\n```\nfrom sklearn import preprocessing \nimport numpy as np\nX = np.array([[ 1., -1.,  2.],\n              [ 2.,  0.,  0.],\n              [ 0.,  1., -1.]])\nscaler = preprocessing.StandardScaler()\nX_scaled = scaler.fit_transform(X)\n```\n\n这两个方法得到最后的结果都是一样的。\n\n---\n\n## **三、将特征的取值缩小到一个范围（如0到1）**\n\n除了上述介绍的方法之外，另一种常用的方法是将属性缩放到一个指定的最大值和最小值(通常是1-0)之间，这可以通过preprocessing.MinMaxScaler类来实现。\n\n使用这种方法的目的包括：\n\n- 1、对于方差非常小的属性可以增强其稳定性；\n- 2、维持稀疏矩阵中为0的条目。\n\n下面将数据缩至0-1之间，采用MinMaxScaler函数\n\n```\nfrom sklearn import preprocessing \nimport numpy as np\nX = np.array([[ 1., -1.,  2.],\n              [ 2.,  0.,  0.],\n              [ 0.,  1., -1.]])\nmin_max_scaler = preprocessing.MinMaxScaler()\nX_minMax = min_max_scaler.fit_transform(X)\n```\n最后输出：\n\n```\narray([[ 0.5       ,  0.        ,  1.        ],\n       [ 1.        ,  0.5       ,  0.33333333],\n       [ 0.        ,  1.        ,  0.        ]])\n```\n\n测试用例：\n\n```\n>>> X_test = np.array([[ -3., -1.,  4.]])\n>>> X_test_minmax = min_max_scaler.transform(X_test)\n>>> X_test_minmax\narray([[-1.5       ,  0.        ,  1.66666667]])\n```\n\n注意：这些变换都是对列进行处理。\n\n\n\n当然，在构造类对象的时候也可以直接指定最大最小值的范围：feature_range=(min, max)，此时应用的公式变为：\n\n```\nX_std=(X-X.min(axis=0))/(X.max(axis=0)-X.min(axis=0))\nX_minmax=X_std/(X.max(axis=0)-X.min(axis=0))+X.min(axis=0))\n```\n---\n\n## **四、正则化(Normalization)**\n\n正则化的过程是将每个样本缩放到单位范数(每个样本的范数为1)，如果要使用如二次型(点积)或者其它核方法计算两个样本之间的相似性这个方法会很有用。\n\n该方法是文本分类和聚类分析中经常使用的向量空间模型（Vector Space Model)的基础.\n\nNormalization主要思想是对每个样本计算其p-范数，然后对该样本中每个元素除以该范数，这样处理的结果是使得每个处理后样本的p-范数(l1-norm,l2-norm)等于1。\n\n**方法1：使用sklearn.preprocessing.normalize()函数**\n\n```\n>>> X = [[ 1., -1.,  2.],\n...      [ 2.,  0.,  0.],\n...      [ 0.,  1., -1.]]\n>>> X_normalized = preprocessing.normalize(X, norm='l2')\n>>> X_normalized                                      \narray([[ 0.40..., -0.40...,  0.81...],\n       [ 1.  ...,  0.  ...,  0.  ...],\n       [ 0.  ...,  0.70..., -0.70...]])\n```\n\n**方法2：sklearn.preprocessing.StandardScaler类**\n\n```\n>>> normalizer = preprocessing.Normalizer().fit(X)  # fit does nothing\n>>> normalizer\nNormalizer(copy=True, norm='l2')\n```\n\n然后使用正则化实例来转换样本向量：\n\n```\n>>> normalizer.transform(X)                            \narray([[ 0.40..., -0.40...,  0.81...],\n       [ 1.  ...,  0.  ...,  0.  ...],\n       [ 0.  ...,  0.70..., -0.70...]])\n>>> normalizer.transform([[-1.,  1., 0.]])             \narray([[-0.70...,  0.70...,  0.  ...]])\n```\n\n两种方法都可以，效果是一样的。\n\n\n---\n\n## **五、二值化(Binarization)**\n\n特征的二值化主要是为了将数据特征转变成boolean变量。在sklearn中，sklearn.preprocessing.Binarizer函数可以实现这一功能。实例如下：\n\n```\n>>> X = [[ 1., -1.,  2.],\n...      [ 2.,  0.,  0.],\n...      [ 0.,  1., -1.]]\n>>> binarizer = preprocessing.Binarizer().fit(X)  # fit does nothing\n>>> binarizer\nBinarizer(copy=True, threshold=0.0)\n>>> binarizer.transform(X)\narray([[ 1.,  0.,  1.],\n       [ 1.,  0.,  0.],\n       [ 0.,  1.,  0.]])\n```\n\nBinarizer函数也可以设定一个阈值，结果数据值大于阈值的为1，小于阈值的为0，实例代码如下：\n\n```\n>>> binarizer = preprocessing.Binarizer(threshold=1.1)\n>>> binarizer.transform(X)\narray([[ 0.,  0.,  1.],\n       [ 1.,  0.,  0.],\n       [ 0.,  0.,  0.]])\n```\n\n---\n\n## **六、缺失值处理**\n\n由于不同的原因，许多现实中的数据集都包含有缺失值，要么是空白的，要么使用NaNs或者其它的符号替代。这些数据无法直接使用scikit-learn分类器直接训练，所以需要进行处理。幸运地是，sklearn中的**Imputer**类提供了一些基本的方法来处理缺失值，如使用均值、中位值或者缺失值所在列中频繁出现的值来替换。\n\n下面是使用均值来处理的实例：\n\n```\n>>> import numpy as np\n>>> from sklearn.preprocessing import Imputer\n>>> imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n>>> imp.fit([[1, 2], [np.nan, 3], [7, 6]])\nImputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)\n>>> X = [[np.nan, 2], [6, np.nan], [7, 6]]\n>>> print(imp.transform(X))                           \n[[ 4.          2.        ]\n [ 6.          3.666...]\n [ 7.          6.        ]]\n```\n\nImputer类同样支持稀疏矩阵：\n\n```\n>>> import scipy.sparse as sp\n>>> X = sp.csc_matrix([[1, 2], [0, 3], [7, 6]])\n>>> imp = Imputer(missing_values=0, strategy='mean', axis=0)\n>>> imp.fit(X)\nImputer(axis=0, copy=True, missing_values=0, strategy='mean', verbose=0)\n>>> X_test = sp.csc_matrix([[0, 2], [6, 0], [7, 6]])\n>>> print(imp.transform(X_test))                      \n[[ 4.          2.        ]\n [ 6.          3.666...]\n [ 7.          6.        ]]\n```\n\n\n本文讲解的比较接单，如果对这些不是很理解的话，请到scikit-learn的官网中查看英文版本：[preprocessing](http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing).\n\n## **References**\n\n- [Scikit-learn preprocessing](http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing).\n\n\n\n---\n\n\n\n\n\n\n","source":"_posts/2015-10-25 scikit-learn preprocessing.md","raw":"---\nlayout: post\ndate: 2015-10-25 10:24\ntitle: \"scikit-learn Preprocessing\"\ncategories: ML\ntag: \n\t- Machine Learning\n\t- 预处理\n\t- scikit-learn\ncomment: true\n---\n\n本文主要是对照[scikit-learn的preprocessing](http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing)章节结合代码简单的回顾下预处理技术的几种方法，主要包括标准化、数据最大最小缩放处理、正则化、特征二值化和数据缺失值处理。内容比较简单，仅供参考！\n\n首先来回顾一下下面要用到的基本知识。\n\n<!-- more -->\n## **一、知识回顾**\n\n均值公式：\n\n$$\\bar{x}=\\frac{1}{n}\\sum\\_{i=1}^{n}x_{i}$$\n\n方差公式：\n\n$$s^{2}=\\frac{1}{n}\\sum\\_{i=1}^{n}(x_{i}-\\bar{x})^{2}$$\n\n0-范数，向量中非零元素的个数。\n\n1-范数：\n\n$$||X||= \\sum\\_{i=1}^{n} |x_{i}|$$\n\n2-范数：\n\n$$||X||\\_{2} =  (\\sum\\_{i=1}^{n} x_{i}^{2})^{\\frac{1}{2}}$$\n\np-范数的计算公式：\n\n$$||X||_{p}=(|x1|^{p}+|x2|^{p}+...+|xn|^{p})^{\\frac{1}{p}}$$\n\n---\n\n数据标准化：当单个特征的样本取值相差甚大或明显不遵从高斯正态分布时，标准化表现的效果较差。实际操作中，经常忽略特征数据的分布形状，移除每个特征均值，划分离散特征的标准差，从而等级化，进而实现数据中心化。\n\n## **二、标准化(Standardization)，或者去除均值和方差进行缩放**\n\n公式为：(X-X_mean)/X_std 计算时对每个属性/每列分别进行.\n\n将数据按其属性(按列进行)减去其均值，然后除以其方差。最后得到的结果是，对每个属性/每列来说所有数据都聚集在0附近，方差值为1。\n\n首先说明下sklearn中preprocessing库里面的scale函数使用方法：\n\n```\nsklearn.preprocessing.scale(X, axis=0, with_mean=True,with_std=True,copy=True)\n```\n\n根据参数的不同，可以沿任意轴标准化数据集。\n\n参数解释：\n\n- X：数组或者矩阵\n- axis：int类型，初始值为0，axis用来计算均值 means 和标准方差 standard deviations. 如果是0，则单独的标准化每个特征（列），如果是1，则标准化每个观测样本（行）。\n- with_mean: boolean类型，默认为True，表示将数据均值规范到0\n- with_std: boolean类型，默认为True，表示将数据方差规范到1\n\n**一个简单的例子**\n\n假设现在我构造一个数据集X，然后想要将其标准化。下面使用不同的方法来标准化X：\n\n**方法一：使用sklearn.preprocessing.scale()函数**\n\n**方法说明：**\n\n- X.mean(axis=0)用来计算数据X每个特征的均值；\n- X.std(axis=0)用来计算数据X每个特征的方差；\n- preprocessing.scale(X)直接标准化数据X。\n\n将代码整理到一个文件中：\n\n```\nfrom sklearn import preprocessing \nimport numpy as np\nX = np.array([[ 1., -1.,  2.],\n              [ 2.,  0.,  0.],\n              [ 0.,  1., -1.]])\n# calculate mean\nX_mean = X.mean(axis=0)\n# calculate variance \nX_std = X.std(axis=0)\n# standardize X\nX1 = (X-X_mean)/X_std\n# use function preprocessing.scale to standardize X\nX_scale = preprocessing.scale(X)\n```\n\n最后X_scale的值和X1的值是一样的，前面是单独的使用数学公式来计算，主要是为了形成一个对比，能够更好的理解scale()方法。\n\n**方法2：sklearn.preprocessing.StandardScaler类**\n\n该方法也可以对数据X进行标准化处理，实例如下：\n\n```\nfrom sklearn import preprocessing \nimport numpy as np\nX = np.array([[ 1., -1.,  2.],\n              [ 2.,  0.,  0.],\n              [ 0.,  1., -1.]])\nscaler = preprocessing.StandardScaler()\nX_scaled = scaler.fit_transform(X)\n```\n\n这两个方法得到最后的结果都是一样的。\n\n---\n\n## **三、将特征的取值缩小到一个范围（如0到1）**\n\n除了上述介绍的方法之外，另一种常用的方法是将属性缩放到一个指定的最大值和最小值(通常是1-0)之间，这可以通过preprocessing.MinMaxScaler类来实现。\n\n使用这种方法的目的包括：\n\n- 1、对于方差非常小的属性可以增强其稳定性；\n- 2、维持稀疏矩阵中为0的条目。\n\n下面将数据缩至0-1之间，采用MinMaxScaler函数\n\n```\nfrom sklearn import preprocessing \nimport numpy as np\nX = np.array([[ 1., -1.,  2.],\n              [ 2.,  0.,  0.],\n              [ 0.,  1., -1.]])\nmin_max_scaler = preprocessing.MinMaxScaler()\nX_minMax = min_max_scaler.fit_transform(X)\n```\n最后输出：\n\n```\narray([[ 0.5       ,  0.        ,  1.        ],\n       [ 1.        ,  0.5       ,  0.33333333],\n       [ 0.        ,  1.        ,  0.        ]])\n```\n\n测试用例：\n\n```\n>>> X_test = np.array([[ -3., -1.,  4.]])\n>>> X_test_minmax = min_max_scaler.transform(X_test)\n>>> X_test_minmax\narray([[-1.5       ,  0.        ,  1.66666667]])\n```\n\n注意：这些变换都是对列进行处理。\n\n\n\n当然，在构造类对象的时候也可以直接指定最大最小值的范围：feature_range=(min, max)，此时应用的公式变为：\n\n```\nX_std=(X-X.min(axis=0))/(X.max(axis=0)-X.min(axis=0))\nX_minmax=X_std/(X.max(axis=0)-X.min(axis=0))+X.min(axis=0))\n```\n---\n\n## **四、正则化(Normalization)**\n\n正则化的过程是将每个样本缩放到单位范数(每个样本的范数为1)，如果要使用如二次型(点积)或者其它核方法计算两个样本之间的相似性这个方法会很有用。\n\n该方法是文本分类和聚类分析中经常使用的向量空间模型（Vector Space Model)的基础.\n\nNormalization主要思想是对每个样本计算其p-范数，然后对该样本中每个元素除以该范数，这样处理的结果是使得每个处理后样本的p-范数(l1-norm,l2-norm)等于1。\n\n**方法1：使用sklearn.preprocessing.normalize()函数**\n\n```\n>>> X = [[ 1., -1.,  2.],\n...      [ 2.,  0.,  0.],\n...      [ 0.,  1., -1.]]\n>>> X_normalized = preprocessing.normalize(X, norm='l2')\n>>> X_normalized                                      \narray([[ 0.40..., -0.40...,  0.81...],\n       [ 1.  ...,  0.  ...,  0.  ...],\n       [ 0.  ...,  0.70..., -0.70...]])\n```\n\n**方法2：sklearn.preprocessing.StandardScaler类**\n\n```\n>>> normalizer = preprocessing.Normalizer().fit(X)  # fit does nothing\n>>> normalizer\nNormalizer(copy=True, norm='l2')\n```\n\n然后使用正则化实例来转换样本向量：\n\n```\n>>> normalizer.transform(X)                            \narray([[ 0.40..., -0.40...,  0.81...],\n       [ 1.  ...,  0.  ...,  0.  ...],\n       [ 0.  ...,  0.70..., -0.70...]])\n>>> normalizer.transform([[-1.,  1., 0.]])             \narray([[-0.70...,  0.70...,  0.  ...]])\n```\n\n两种方法都可以，效果是一样的。\n\n\n---\n\n## **五、二值化(Binarization)**\n\n特征的二值化主要是为了将数据特征转变成boolean变量。在sklearn中，sklearn.preprocessing.Binarizer函数可以实现这一功能。实例如下：\n\n```\n>>> X = [[ 1., -1.,  2.],\n...      [ 2.,  0.,  0.],\n...      [ 0.,  1., -1.]]\n>>> binarizer = preprocessing.Binarizer().fit(X)  # fit does nothing\n>>> binarizer\nBinarizer(copy=True, threshold=0.0)\n>>> binarizer.transform(X)\narray([[ 1.,  0.,  1.],\n       [ 1.,  0.,  0.],\n       [ 0.,  1.,  0.]])\n```\n\nBinarizer函数也可以设定一个阈值，结果数据值大于阈值的为1，小于阈值的为0，实例代码如下：\n\n```\n>>> binarizer = preprocessing.Binarizer(threshold=1.1)\n>>> binarizer.transform(X)\narray([[ 0.,  0.,  1.],\n       [ 1.,  0.,  0.],\n       [ 0.,  0.,  0.]])\n```\n\n---\n\n## **六、缺失值处理**\n\n由于不同的原因，许多现实中的数据集都包含有缺失值，要么是空白的，要么使用NaNs或者其它的符号替代。这些数据无法直接使用scikit-learn分类器直接训练，所以需要进行处理。幸运地是，sklearn中的**Imputer**类提供了一些基本的方法来处理缺失值，如使用均值、中位值或者缺失值所在列中频繁出现的值来替换。\n\n下面是使用均值来处理的实例：\n\n```\n>>> import numpy as np\n>>> from sklearn.preprocessing import Imputer\n>>> imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n>>> imp.fit([[1, 2], [np.nan, 3], [7, 6]])\nImputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)\n>>> X = [[np.nan, 2], [6, np.nan], [7, 6]]\n>>> print(imp.transform(X))                           \n[[ 4.          2.        ]\n [ 6.          3.666...]\n [ 7.          6.        ]]\n```\n\nImputer类同样支持稀疏矩阵：\n\n```\n>>> import scipy.sparse as sp\n>>> X = sp.csc_matrix([[1, 2], [0, 3], [7, 6]])\n>>> imp = Imputer(missing_values=0, strategy='mean', axis=0)\n>>> imp.fit(X)\nImputer(axis=0, copy=True, missing_values=0, strategy='mean', verbose=0)\n>>> X_test = sp.csc_matrix([[0, 2], [6, 0], [7, 6]])\n>>> print(imp.transform(X_test))                      \n[[ 4.          2.        ]\n [ 6.          3.666...]\n [ 7.          6.        ]]\n```\n\n\n本文讲解的比较接单，如果对这些不是很理解的话，请到scikit-learn的官网中查看英文版本：[preprocessing](http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing).\n\n## **References**\n\n- [Scikit-learn preprocessing](http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing).\n\n\n\n---\n\n\n\n\n\n\n","slug":"2015-10-25 scikit-learn preprocessing","published":1,"updated":"2016-03-13T05:55:40.918Z","comments":1,"photos":[],"link":"","_id":"cimigpyxx006h6cujautwevr4"},{"layout":"post","date":"2015-10-24T02:24:00.000Z","title":"机器学习之特征工程","comment":true,"_content":"\n在这个振奋人心的程序员节日里，我决定认真地写一篇文章来纪念一下自己这长达六年程序员史。o(╯□╰)o\n\n本文是一篇关于特征工程的总结类文章，如有不足之处或理解有偏差的地方，还望多多指教。\n\n首先，给一张特征工程的思维导图吧：\n\n![特征工程](http://ww1.sinaimg.cn/large/637f3c58gw1exd7mcjk7yj28k33uwaoe.jpg)\n\n<!-- more -->\n<center>\n<font color=\"green\">**【如果要浏览图片，建议将其下载到本地，使用图片浏览软件查看】**</font>\n</center>\n\n关于特征工程（Feature Engineering），已经是很古老很常见的话题了，坊间常说：“数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已”。由此可见，特征工程在机器学习中占有相当重要的地位。在实际应用当中，可以说特征工程是机器学习成功的关键。纵观Kaggle、KDD等国内外大大小小的比赛，每个竞赛的冠军其实并没有用到很高深的算法，大多数都是在特征工程这个环节做出了出色的工作，然后使用一些常见的算法，比如LR，就能得到出色的性能。遗憾的是，在很多的书籍中并没有直接提到Feature Engineering，更多的是Feature selection。这也并不，很多ML书籍都是以讲解算法为主，他们的目的是从理论到实践来理解算法，所以用到的数据要么是使用代码生成的，要么是已经处理好的数据，并没有提到特征工程。在这篇文章，我打算自我总结下特征工程，让自己对特征工程有个全面的认识。在这我要说明一下，我并不是说那些书写的不好，其实都很有不错，主要是因为它们的目的是理解算法，所以直接给出数据相对而言对于学习和理解算法效果更佳。\n\n\n这篇文章主要从以下三个问题出发来理解特征工程：\n\n- 特征工程是什么？\n- 为什么要做特征工程？\n- 应该如何做特征工程？\n\n对于第一个问题，我会通过特征工程的目的来解释什么是特征工程。对于第二个问题，主要从特征工程的重要性来阐述。对于第三个问题，我会从特征工程的子问题以及简单的处理方法来进一步说明。下面来看看详细内容！\n\n---\n\n## **1、特征工程是什么**\n\n首先来解释下什么是特征工程？\n\n当你想要你的预测模型性能达到最佳时，你要做的不仅是要选取最好的算法，还要尽可能的从原始数据中获取更多的信息。那么问题来了，<font color=\"red\">你应该如何为你的预测模型得到更好的数据呢？</font>\n\n想必到了这里你也应该猜到了，是的，这就是特征工程要做的事，它的目的就是<font color=\"red\">获取更好的训练数据</font>。\n\n关于特征工程的定义，Wikipedia上是这样说的：\n\n\n\tFeature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. ”\n\n\t\n我的理解：\n\n\n\t特征工程是利用数据领域的相关知识来创建能够使机器学习算法达到最佳性能的特征的过程。\n\n\n简而言之，特征工程就是一个把原始数据转变成特征的过程，这些特征可以很好的描述这些数据，并且利用它们建立的模型在未知数据上的表现性能可以达到最优（或者接近最佳性能）。从数学的角度来看，特征工程就是人工地去设计输入变量X。\n\n特征工程更是一门艺术，跟编程一样。导致许多机器学习项目成功和失败的主要因素就是使用了不同的特征。说了这么多，想必你也大概知道了为什么要做特征工程，下面来说说特征工程的重要性。\n\n---\n\n## **2、特征工程的重要性**\n\n\nOK！知道了特征工程是什么，那么我们必须要来了解下特征工程的重要性，为什么在实际工作中都要有特征工程这个过程，下面不同的角度来分析一下。\n\n首先，我们大家都知道，数据特征会直接影响我们模型的预测性能。你可以这么说：“选择的特征越好，最终得到的性能也就越好”。这句话说得没错，但也会给我们造成误解。事实上，<font color=\"green\">你得到的实验结果取决于你选择的模型、获取的数据以及使用的特征，甚至你问题的形式和你用来评估精度的客观方法也扮演了一部分</font>。此外，你的实验结果还受到许多相互依赖的属性的影响，你需要的是能够很好地描述你数据内部结构的好特征。\n\n**（1）特征越好，灵活性越强**\n\n只要特征选得好，即使是一般的模型（或算法）也能获得很好的性能，因为大多数模型（或算法）在好的数据特征下表现的性能都还不错。<font color=\"red\">好特征的灵活性在于它允许你选择不复杂的模型，同时运行速度也更快，也更容易理解和维护</font>。\n\n**（2）特征越好，构建的模型越简单**\n\n有了好的特征，即便你的参数不是最优的，你的模型性能也能仍然会表现的很nice，所以你就不需要花太多的时间去寻找最有参数，这大大的降低了模型的复杂度，使模型趋于简单。\n\n**（3）特征越好，模型的性能越出色**\n\n显然，这一点是毫无争议的，我们进行特征工程的最终目的就是提升模型的性能。\n\n下面从特征的子问题来分析下特征工程。\n\n---\n\n## **3、特征工程子问题**\n\n大家通常会把特征工程看做是一个问题。事实上，在特征工程下面，还有许多的子问题，主要包括：Feature Selection（特征选择）、Feature Extraction（特征提取）和Feature construction（特征构造）.下面从这三个子问题来详细介绍。\n\n### **3.1 特征选择Feature Selection**\n\n首先，从特征开始说起，假设你现在有一个标准的Excel表格数据，它的每一行表示的是一个观测样本数据，表格数据中的每一列就是一个特征。在这些特征中，有的特征携带的信息量丰富，有的（或许很少）则属于无关数据（irrelevant data），我们可以通过特征项和类别项之间的相关性（特征重要性）来衡量。比如，在实际应用中，常用的方法就是使用一些评价指标单独地计算出单个特征跟类别变量之间的关系。如Pearson相关系数，Gini-index（基尼指数），IG（信息增益）等，下面举Pearson指数为例，它的计算方式如下：\n\n$$r_{xy}^2=(\\frac{con(x,y)}{\\sqrt{var(x)var(y)}})$$\n\n其中，x属于X，X表一个特征的多个观测值，y表示这个特征观测值对应的类别列表。\n\nPearson相关系数的取值在0到1之间，如果你使用这个评价指标来计算所有特征和类别标号的相关性，那么得到这些相关性之后，你可以将它们从高到低进行排名，然后选择一个子集作为特征子集（比如top 10%），接着用这些特征进行训练，看看性能如何。此外，你还可以画出不同子集的一个精度图，根据绘制的图形来找出性能最好的一组特征。\n\n这就是特征工程的子问题之一——特征选择，它的目的是<font color=\"red\">**从特征集合中挑选一组最具统计意义的特征子集，从而达到降维的效果**</font>。\n\n做特征选择的原因是因为这些特征对于目标类别的作用并不是相等的，一些无关的数据需要删掉。做特征选择的方法有多种，上面提到的这种特征子集选择的方法属于filter（刷选器）方法，它主要侧重于单个特征跟目标变量的相关性。优点是计算时间上较高效,对于过拟合问题也具有较高的鲁棒性。缺点就是倾向于选择冗余的特征,因为他们不考虑特征之间的相关性,有可能某一个特征的分类能力很差，但是它和某些其它特征组合起来会得到不错的效果。另外做特征子集选取的方法还有wrapper（封装器）和Embeded(集成方法)。wrapper方法实质上是一个分类器，封装器用选取的特征子集对样本集进行分类，分类的精度作为衡量特征子集好坏的标准,经过比较选出最好的特征子集。常用的有逐步回归（Stepwise regression）、向前选择（Forward selection）和向后选择（Backward selection）。它的优点是考虑了特征与特征之间的关联性，缺点是：当观测数据较少时容易过拟合，而当特征数量较多时,计算时间又会增长。对于Embeded集成方法，它是学习器自身自主选择特征，如使用Regularization做特征选择，或者使用决策树思想，细节这里就不做介绍了。这里还提一下，在做实验的时候，我们有时候会用Random Forest和Gradient boosting做特征选择，本质上都是基于决策树来做的特征选择，只是细节上有些区别。\n\n综上所述，特征选择过程一般包括产生过程，评价函数，停止准则，验证过程，这4个部分。如下图所示：\n\n<center> \n![feature selection](/assets/images/feature selection.png)\n</center>\n\n\n(1) **产生过程( Generation Procedure )**：产生过程是搜索特征子集的过程，负责为评价函数提供特征子集。搜索特征子集的过程有多种，将在2.2小节展开介绍。\n(2) **评价函数( Evaluation Function )**：评价函数是评价一个特征子集好坏程度的一个准则。评价函数将在2.3小节展开介绍。\n(3) **停止准则( Stopping Criterion )**：停止准则是与评价函数相关的，一般是一个阈值，当评价函数值达到这个阈值后就可停止搜索。\n(4) **验证过程( Validation Procedure )** ：在验证数据集上验证选出来的特征子集的有效性。\n\n### **3.2 特征提取**\n\n特征提取的子问题之二——特征提取。\n\n原则上来讲，特征提取应该在特征选择之前。特征提取的对象是原始数据（raw data），它的目的是<font color=\"red\">**自动地构建新的特征，将原始特征转换为一组具有明显物理意义（Gabor、几何特征[角点、不变量]、纹理[LBP HOG]）或者统计意义或核的特征**</font>。比如通过变换特征取值来减少原始数据中某个特征的取值个数等。对于表格数据，你可以在你设计的特征矩阵上使用主要成分分析（Principal Component Analysis，PCA)来进行特征提取从而创建新的特征。对于图像数据，可能还包括了线或边缘检测。\n\n常用的方法有：\n\n- PCA (Principal component analysis，主成分分析)\n- ICA (Independent component analysis，独立成分分析)\n- LDA （Linear Discriminant Analysis，线性判别分析）\n\n对于图像识别中，还有SIFT方法。\n\n\n\n### **3.3 特征构建 Feature Construction**\n\n特征提取的子问题之二——特征构建。\n\n在上面的特征选择部分，我们提到了对特征重要性进行排名。那么，这些特征是如何得到的呢？在实际应用中，显然是不可能凭空而来的，需要我们手工去构建特征。关于特征构建的定义，可以这么说：<font color=\"green\">**特征构建指的是从原始数据中人工的构建新的特征**</font>。我们需要人工的创建它们。这需要我们花大量的时间去研究真实的数据样本，思考问题的潜在形式和数据结构，同时能够更好地应用到预测模型中。\n\n特征构建需要很强的洞察力和分析能力，要求我们能够从原始数据中找出一些具有物理意义的特征。假设原始数据是表格数据，一般你可以使用混合属性或者组合属性来创建新的特征，或是分解或切分原有的特征来创建新的特征。\n\n\n---\n\n## **4、特征工程处理过程**\n\n那么问题来了，特征工程具体是在哪个步骤做呢？\n\n具体的机器学习过程是这样的一个过程：\n\n- 1.（Task before here）\n- 2.选择数据(Select Data): 整合数据，将数据规范化成一个数据集，收集起来.\n- 3.数据预处理（Preprocess Data）: 数据格式化，数据清理，采样等.\n- 4.数据转换（Transform Data）: <font color=\"red\">**这个阶段做特征工程**</font>.\n- 5.数据建模（Model Data）: 建立模型，评估模型并逐步优化.\n- (Tasks after here…)\n\n我们发现，特征工程和数据转换其实是等价的。<font color=\"red\">**事实上，特征工程是一个迭代过程，我们需要不断的设计特征、选择特征、建立模型、评估模型，然后才能得到最终的model**</font>。下面是特征工程的一个迭代过程：\n\n- 1.头脑风暴式特征：意思就是进你可能的从原始数据中提取特征，暂时不考虑其重要性，对应于特征构建；\n- 2.设计特征：根据你的问题，你可以使用自动地特征提取，或者是手工构造特征，或者两者混合使用；\n- 3.选择特征：使用不同的特征重要性评分和特征选择方法进行特征选择；\n- 4.评估模型：使用你选择的特征进行建模，同时使用未知的数据来评估你的模型精度。\n\nBy the way, 在做feature selection的时候，会涉及到特征学习（Feature Learning），这里说下特征学习的概念，一般而言，特征学习（Feature Learning）是指学习输入特征和一个训练实例真是类别之间的关系。\n\n下面举个例子来简单了解下特征工程的处理。\n\n首先是来说下特征提取，假设你的数据里现在有一个颜色类别的属性，比如是“item_Color\",它的取值有三个，分别是：*red，blue，unknown*。从特征提取的角度来看，你可以将其转化成一个二值特征“*has_color*”，取值为1或0。其中1表示有颜色，0表示没颜色。你还可以将其转换成三个二值属性：*Is_Red, Is_Blue and Is_Unknown*。这样构建特征之后，你就可以使用简单的线性模型进行训练了。\n\n另外再举一个例子，假设你有一个日期时间 (i.e. 2014-09-20T20:45:40Z)，这个该如何转换呢？\n\n对于这种时间的数据，我们可以根据需求提取出多种属性。比如，如果你想知道某一天的时间段跟其它属性的关系，你可以创建一个数字特征“**Hour_Of_Day**”来帮你建立一个回归模型，或者你可以建立一个序数特征，“Part_Of_Day”,取值“*Morning,Midday,Afternoon,Night*”来关联你的数据。\n\n此外，你还可以按星期或季度来构建属性，等等等等……\n\n关于特征构建，主要是尽可能的从原始数据中构建特征，而特征选择，经过上面的分析，想必大家也知道了，其实就是达到一个降维的效果。\n\n只要分析能力和实践能力够强，那么特征构建和特征提取对你而言就会显得相对比较简单，所以抓紧时间好好实践吧！\n\n---\n\n## **Conclusion**\n\n恩。说了这么多，大家可能对特征工程、特征选择、特征提取和特征构建有点混乱了，下面来简单的做个总结：\n\n首先来说说这几个术语：\n\n- 特征工程：利用数据领域的相关知识来创建能够使机器学习算法达到最佳性能的特征的过程。\n- 特征构建：是原始数据中人工的构建新的特征。\n- 特征提取：自动地构建新的特征，将原始特征转换为一组具有明显物理意义或者统计意义或核的特征。\n- 特征选择：从特征集合中挑选一组最具统计意义的特征子集，从而达到降维的效果\n\n了解这几个术语的意思后，我们来看看他们之间的关系。\n\n在Quora中有人这么说：\n\nFeature engineering is a super-set of  activities which include feature extraction, feature construction and feature selection. Each of the three are important steps and none should be ignored. We could make a generalization of the importance though, from my experience the relative importance of the steps would be feature construction > feature extraction > feature selection.\n\n用中文来说就是：<font color=\"green\">**特征工程是一个超集，它包括特征提取、特征构建和特征选择这三个子模块。在实践当中，每一个子模块都非常重要，忽略不得。根据答主的经验，他将这三个子模块的重要性进行了一个排名，即：特征构建>特征提取>特征选择。**</font>\n\n事实上，真的是这样，<font color=\"red\">**如果特征构建做的不好，那么它会直接影响特征提取，进而影响了特征选择，最终影响模型的性能**</font>。\n\n\nOK！关于特征工程就到此为止吧，如果有纰漏的地方，还望多多指导！作为一枚行走在ML界的程序员，就让我们快乐的建模，快乐的做特征工程吧^_^！Happy coding, happy modeling！\n\n## **References**\n\n\n- [Neglected machine learning ideas](https://www.quora.com/What-are-some-general-tips-on-feature-selection-and-engineering-that-every-data-scientist-should-know)\n- [Q&A with Xavier Conort](http://blog.kaggle.com/2013/04/10/qa-with-xavier-conort/)\n- [https://www.quora.com/What-is-feature-engineering](https://www.quora.com/What-is-feature-engineering)\n- [Feature_engineering-wikipedia](https://en.wikipedia.org/wiki/Feature_engineering)\n- [An Introduction to Feature Selection](http://machinelearningmastery.com/an-introduction-to-feature-selection/)\n- [Discover Feature Engineering, How to Engineer Features and How to Get Good at It](http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/)\n- [How valuable do you think feature selection is in machine learning? Which do you think improves accuracy more, feature selection or feature engineering?](https://www.quora.com/How-valuable-do-you-think-feature-selection-is-in-machine-learning-Which-do-you-think-improves-accuracy-more-feature-selection-or-feature-engineering)\n\n\n---\n\n\n\n\n","source":"_posts/2015-10-24 feature engineering.md","raw":"---\nlayout: post\ndate: 2015-10-24 10:24\ntitle: \"机器学习之特征工程\"\ncategories: ML\ntag: \n\t- Machine Learning\n\t- 特征工程\ncomment: true\n---\n\n在这个振奋人心的程序员节日里，我决定认真地写一篇文章来纪念一下自己这长达六年程序员史。o(╯□╰)o\n\n本文是一篇关于特征工程的总结类文章，如有不足之处或理解有偏差的地方，还望多多指教。\n\n首先，给一张特征工程的思维导图吧：\n\n![特征工程](http://ww1.sinaimg.cn/large/637f3c58gw1exd7mcjk7yj28k33uwaoe.jpg)\n\n<!-- more -->\n<center>\n<font color=\"green\">**【如果要浏览图片，建议将其下载到本地，使用图片浏览软件查看】**</font>\n</center>\n\n关于特征工程（Feature Engineering），已经是很古老很常见的话题了，坊间常说：“数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已”。由此可见，特征工程在机器学习中占有相当重要的地位。在实际应用当中，可以说特征工程是机器学习成功的关键。纵观Kaggle、KDD等国内外大大小小的比赛，每个竞赛的冠军其实并没有用到很高深的算法，大多数都是在特征工程这个环节做出了出色的工作，然后使用一些常见的算法，比如LR，就能得到出色的性能。遗憾的是，在很多的书籍中并没有直接提到Feature Engineering，更多的是Feature selection。这也并不，很多ML书籍都是以讲解算法为主，他们的目的是从理论到实践来理解算法，所以用到的数据要么是使用代码生成的，要么是已经处理好的数据，并没有提到特征工程。在这篇文章，我打算自我总结下特征工程，让自己对特征工程有个全面的认识。在这我要说明一下，我并不是说那些书写的不好，其实都很有不错，主要是因为它们的目的是理解算法，所以直接给出数据相对而言对于学习和理解算法效果更佳。\n\n\n这篇文章主要从以下三个问题出发来理解特征工程：\n\n- 特征工程是什么？\n- 为什么要做特征工程？\n- 应该如何做特征工程？\n\n对于第一个问题，我会通过特征工程的目的来解释什么是特征工程。对于第二个问题，主要从特征工程的重要性来阐述。对于第三个问题，我会从特征工程的子问题以及简单的处理方法来进一步说明。下面来看看详细内容！\n\n---\n\n## **1、特征工程是什么**\n\n首先来解释下什么是特征工程？\n\n当你想要你的预测模型性能达到最佳时，你要做的不仅是要选取最好的算法，还要尽可能的从原始数据中获取更多的信息。那么问题来了，<font color=\"red\">你应该如何为你的预测模型得到更好的数据呢？</font>\n\n想必到了这里你也应该猜到了，是的，这就是特征工程要做的事，它的目的就是<font color=\"red\">获取更好的训练数据</font>。\n\n关于特征工程的定义，Wikipedia上是这样说的：\n\n\n\tFeature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. ”\n\n\t\n我的理解：\n\n\n\t特征工程是利用数据领域的相关知识来创建能够使机器学习算法达到最佳性能的特征的过程。\n\n\n简而言之，特征工程就是一个把原始数据转变成特征的过程，这些特征可以很好的描述这些数据，并且利用它们建立的模型在未知数据上的表现性能可以达到最优（或者接近最佳性能）。从数学的角度来看，特征工程就是人工地去设计输入变量X。\n\n特征工程更是一门艺术，跟编程一样。导致许多机器学习项目成功和失败的主要因素就是使用了不同的特征。说了这么多，想必你也大概知道了为什么要做特征工程，下面来说说特征工程的重要性。\n\n---\n\n## **2、特征工程的重要性**\n\n\nOK！知道了特征工程是什么，那么我们必须要来了解下特征工程的重要性，为什么在实际工作中都要有特征工程这个过程，下面不同的角度来分析一下。\n\n首先，我们大家都知道，数据特征会直接影响我们模型的预测性能。你可以这么说：“选择的特征越好，最终得到的性能也就越好”。这句话说得没错，但也会给我们造成误解。事实上，<font color=\"green\">你得到的实验结果取决于你选择的模型、获取的数据以及使用的特征，甚至你问题的形式和你用来评估精度的客观方法也扮演了一部分</font>。此外，你的实验结果还受到许多相互依赖的属性的影响，你需要的是能够很好地描述你数据内部结构的好特征。\n\n**（1）特征越好，灵活性越强**\n\n只要特征选得好，即使是一般的模型（或算法）也能获得很好的性能，因为大多数模型（或算法）在好的数据特征下表现的性能都还不错。<font color=\"red\">好特征的灵活性在于它允许你选择不复杂的模型，同时运行速度也更快，也更容易理解和维护</font>。\n\n**（2）特征越好，构建的模型越简单**\n\n有了好的特征，即便你的参数不是最优的，你的模型性能也能仍然会表现的很nice，所以你就不需要花太多的时间去寻找最有参数，这大大的降低了模型的复杂度，使模型趋于简单。\n\n**（3）特征越好，模型的性能越出色**\n\n显然，这一点是毫无争议的，我们进行特征工程的最终目的就是提升模型的性能。\n\n下面从特征的子问题来分析下特征工程。\n\n---\n\n## **3、特征工程子问题**\n\n大家通常会把特征工程看做是一个问题。事实上，在特征工程下面，还有许多的子问题，主要包括：Feature Selection（特征选择）、Feature Extraction（特征提取）和Feature construction（特征构造）.下面从这三个子问题来详细介绍。\n\n### **3.1 特征选择Feature Selection**\n\n首先，从特征开始说起，假设你现在有一个标准的Excel表格数据，它的每一行表示的是一个观测样本数据，表格数据中的每一列就是一个特征。在这些特征中，有的特征携带的信息量丰富，有的（或许很少）则属于无关数据（irrelevant data），我们可以通过特征项和类别项之间的相关性（特征重要性）来衡量。比如，在实际应用中，常用的方法就是使用一些评价指标单独地计算出单个特征跟类别变量之间的关系。如Pearson相关系数，Gini-index（基尼指数），IG（信息增益）等，下面举Pearson指数为例，它的计算方式如下：\n\n$$r_{xy}^2=(\\frac{con(x,y)}{\\sqrt{var(x)var(y)}})$$\n\n其中，x属于X，X表一个特征的多个观测值，y表示这个特征观测值对应的类别列表。\n\nPearson相关系数的取值在0到1之间，如果你使用这个评价指标来计算所有特征和类别标号的相关性，那么得到这些相关性之后，你可以将它们从高到低进行排名，然后选择一个子集作为特征子集（比如top 10%），接着用这些特征进行训练，看看性能如何。此外，你还可以画出不同子集的一个精度图，根据绘制的图形来找出性能最好的一组特征。\n\n这就是特征工程的子问题之一——特征选择，它的目的是<font color=\"red\">**从特征集合中挑选一组最具统计意义的特征子集，从而达到降维的效果**</font>。\n\n做特征选择的原因是因为这些特征对于目标类别的作用并不是相等的，一些无关的数据需要删掉。做特征选择的方法有多种，上面提到的这种特征子集选择的方法属于filter（刷选器）方法，它主要侧重于单个特征跟目标变量的相关性。优点是计算时间上较高效,对于过拟合问题也具有较高的鲁棒性。缺点就是倾向于选择冗余的特征,因为他们不考虑特征之间的相关性,有可能某一个特征的分类能力很差，但是它和某些其它特征组合起来会得到不错的效果。另外做特征子集选取的方法还有wrapper（封装器）和Embeded(集成方法)。wrapper方法实质上是一个分类器，封装器用选取的特征子集对样本集进行分类，分类的精度作为衡量特征子集好坏的标准,经过比较选出最好的特征子集。常用的有逐步回归（Stepwise regression）、向前选择（Forward selection）和向后选择（Backward selection）。它的优点是考虑了特征与特征之间的关联性，缺点是：当观测数据较少时容易过拟合，而当特征数量较多时,计算时间又会增长。对于Embeded集成方法，它是学习器自身自主选择特征，如使用Regularization做特征选择，或者使用决策树思想，细节这里就不做介绍了。这里还提一下，在做实验的时候，我们有时候会用Random Forest和Gradient boosting做特征选择，本质上都是基于决策树来做的特征选择，只是细节上有些区别。\n\n综上所述，特征选择过程一般包括产生过程，评价函数，停止准则，验证过程，这4个部分。如下图所示：\n\n<center> \n![feature selection](/assets/images/feature selection.png)\n</center>\n\n\n(1) **产生过程( Generation Procedure )**：产生过程是搜索特征子集的过程，负责为评价函数提供特征子集。搜索特征子集的过程有多种，将在2.2小节展开介绍。\n(2) **评价函数( Evaluation Function )**：评价函数是评价一个特征子集好坏程度的一个准则。评价函数将在2.3小节展开介绍。\n(3) **停止准则( Stopping Criterion )**：停止准则是与评价函数相关的，一般是一个阈值，当评价函数值达到这个阈值后就可停止搜索。\n(4) **验证过程( Validation Procedure )** ：在验证数据集上验证选出来的特征子集的有效性。\n\n### **3.2 特征提取**\n\n特征提取的子问题之二——特征提取。\n\n原则上来讲，特征提取应该在特征选择之前。特征提取的对象是原始数据（raw data），它的目的是<font color=\"red\">**自动地构建新的特征，将原始特征转换为一组具有明显物理意义（Gabor、几何特征[角点、不变量]、纹理[LBP HOG]）或者统计意义或核的特征**</font>。比如通过变换特征取值来减少原始数据中某个特征的取值个数等。对于表格数据，你可以在你设计的特征矩阵上使用主要成分分析（Principal Component Analysis，PCA)来进行特征提取从而创建新的特征。对于图像数据，可能还包括了线或边缘检测。\n\n常用的方法有：\n\n- PCA (Principal component analysis，主成分分析)\n- ICA (Independent component analysis，独立成分分析)\n- LDA （Linear Discriminant Analysis，线性判别分析）\n\n对于图像识别中，还有SIFT方法。\n\n\n\n### **3.3 特征构建 Feature Construction**\n\n特征提取的子问题之二——特征构建。\n\n在上面的特征选择部分，我们提到了对特征重要性进行排名。那么，这些特征是如何得到的呢？在实际应用中，显然是不可能凭空而来的，需要我们手工去构建特征。关于特征构建的定义，可以这么说：<font color=\"green\">**特征构建指的是从原始数据中人工的构建新的特征**</font>。我们需要人工的创建它们。这需要我们花大量的时间去研究真实的数据样本，思考问题的潜在形式和数据结构，同时能够更好地应用到预测模型中。\n\n特征构建需要很强的洞察力和分析能力，要求我们能够从原始数据中找出一些具有物理意义的特征。假设原始数据是表格数据，一般你可以使用混合属性或者组合属性来创建新的特征，或是分解或切分原有的特征来创建新的特征。\n\n\n---\n\n## **4、特征工程处理过程**\n\n那么问题来了，特征工程具体是在哪个步骤做呢？\n\n具体的机器学习过程是这样的一个过程：\n\n- 1.（Task before here）\n- 2.选择数据(Select Data): 整合数据，将数据规范化成一个数据集，收集起来.\n- 3.数据预处理（Preprocess Data）: 数据格式化，数据清理，采样等.\n- 4.数据转换（Transform Data）: <font color=\"red\">**这个阶段做特征工程**</font>.\n- 5.数据建模（Model Data）: 建立模型，评估模型并逐步优化.\n- (Tasks after here…)\n\n我们发现，特征工程和数据转换其实是等价的。<font color=\"red\">**事实上，特征工程是一个迭代过程，我们需要不断的设计特征、选择特征、建立模型、评估模型，然后才能得到最终的model**</font>。下面是特征工程的一个迭代过程：\n\n- 1.头脑风暴式特征：意思就是进你可能的从原始数据中提取特征，暂时不考虑其重要性，对应于特征构建；\n- 2.设计特征：根据你的问题，你可以使用自动地特征提取，或者是手工构造特征，或者两者混合使用；\n- 3.选择特征：使用不同的特征重要性评分和特征选择方法进行特征选择；\n- 4.评估模型：使用你选择的特征进行建模，同时使用未知的数据来评估你的模型精度。\n\nBy the way, 在做feature selection的时候，会涉及到特征学习（Feature Learning），这里说下特征学习的概念，一般而言，特征学习（Feature Learning）是指学习输入特征和一个训练实例真是类别之间的关系。\n\n下面举个例子来简单了解下特征工程的处理。\n\n首先是来说下特征提取，假设你的数据里现在有一个颜色类别的属性，比如是“item_Color\",它的取值有三个，分别是：*red，blue，unknown*。从特征提取的角度来看，你可以将其转化成一个二值特征“*has_color*”，取值为1或0。其中1表示有颜色，0表示没颜色。你还可以将其转换成三个二值属性：*Is_Red, Is_Blue and Is_Unknown*。这样构建特征之后，你就可以使用简单的线性模型进行训练了。\n\n另外再举一个例子，假设你有一个日期时间 (i.e. 2014-09-20T20:45:40Z)，这个该如何转换呢？\n\n对于这种时间的数据，我们可以根据需求提取出多种属性。比如，如果你想知道某一天的时间段跟其它属性的关系，你可以创建一个数字特征“**Hour_Of_Day**”来帮你建立一个回归模型，或者你可以建立一个序数特征，“Part_Of_Day”,取值“*Morning,Midday,Afternoon,Night*”来关联你的数据。\n\n此外，你还可以按星期或季度来构建属性，等等等等……\n\n关于特征构建，主要是尽可能的从原始数据中构建特征，而特征选择，经过上面的分析，想必大家也知道了，其实就是达到一个降维的效果。\n\n只要分析能力和实践能力够强，那么特征构建和特征提取对你而言就会显得相对比较简单，所以抓紧时间好好实践吧！\n\n---\n\n## **Conclusion**\n\n恩。说了这么多，大家可能对特征工程、特征选择、特征提取和特征构建有点混乱了，下面来简单的做个总结：\n\n首先来说说这几个术语：\n\n- 特征工程：利用数据领域的相关知识来创建能够使机器学习算法达到最佳性能的特征的过程。\n- 特征构建：是原始数据中人工的构建新的特征。\n- 特征提取：自动地构建新的特征，将原始特征转换为一组具有明显物理意义或者统计意义或核的特征。\n- 特征选择：从特征集合中挑选一组最具统计意义的特征子集，从而达到降维的效果\n\n了解这几个术语的意思后，我们来看看他们之间的关系。\n\n在Quora中有人这么说：\n\nFeature engineering is a super-set of  activities which include feature extraction, feature construction and feature selection. Each of the three are important steps and none should be ignored. We could make a generalization of the importance though, from my experience the relative importance of the steps would be feature construction > feature extraction > feature selection.\n\n用中文来说就是：<font color=\"green\">**特征工程是一个超集，它包括特征提取、特征构建和特征选择这三个子模块。在实践当中，每一个子模块都非常重要，忽略不得。根据答主的经验，他将这三个子模块的重要性进行了一个排名，即：特征构建>特征提取>特征选择。**</font>\n\n事实上，真的是这样，<font color=\"red\">**如果特征构建做的不好，那么它会直接影响特征提取，进而影响了特征选择，最终影响模型的性能**</font>。\n\n\nOK！关于特征工程就到此为止吧，如果有纰漏的地方，还望多多指导！作为一枚行走在ML界的程序员，就让我们快乐的建模，快乐的做特征工程吧^_^！Happy coding, happy modeling！\n\n## **References**\n\n\n- [Neglected machine learning ideas](https://www.quora.com/What-are-some-general-tips-on-feature-selection-and-engineering-that-every-data-scientist-should-know)\n- [Q&A with Xavier Conort](http://blog.kaggle.com/2013/04/10/qa-with-xavier-conort/)\n- [https://www.quora.com/What-is-feature-engineering](https://www.quora.com/What-is-feature-engineering)\n- [Feature_engineering-wikipedia](https://en.wikipedia.org/wiki/Feature_engineering)\n- [An Introduction to Feature Selection](http://machinelearningmastery.com/an-introduction-to-feature-selection/)\n- [Discover Feature Engineering, How to Engineer Features and How to Get Good at It](http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/)\n- [How valuable do you think feature selection is in machine learning? Which do you think improves accuracy more, feature selection or feature engineering?](https://www.quora.com/How-valuable-do-you-think-feature-selection-is-in-machine-learning-Which-do-you-think-improves-accuracy-more-feature-selection-or-feature-engineering)\n\n\n---\n\n\n\n\n","slug":"2015-10-24 feature engineering","published":1,"updated":"2016-03-13T05:55:50.418Z","comments":1,"photos":[],"link":"","_id":"cimigpyy5006n6cujg9mdus4b"},{"layout":"post","date":"2015-10-21T08:45:44.000Z","title":"Windows下使用 git push 命令的无密码设置","_content":"\n在使用git时，每次进行git push时都需要输入用户名和密码，简直让人抓狂呀。下面介绍一种方法，可以避免用户名和密码输入，节省大量时间。\n\n## 1.添加环境变量\n\n首先在系统变量中添加一个环境变量HOME，内容为\n\n```\nHOME%USERPROFILE%\n```\n\n<center>\n![配置环境变量](http://ww4.sinaimg.cn/large/637f3c58gw1exbx3roqvcj20bo0cadgy.jpg)\n</center>\n\n<!-- more -->\n\n## 2.新建配置文件\n\n由于使用的是Windows，所以进入%HOME%目录（如我的:C:\\Users\\username），新建一个名为\"_netrc\"的文件，文件中内容格式如下：\n\n```\nmachine github.com\nlogin your-username\npassword your-password\n```\n\n接着，打开git bash后，输入git push 命令就无需再输入用户名和密码了。\n\n爽歪歪啦~\n\n\n---\n\n","source":"_posts/2015-10-21 Windows git push no password.md","raw":"---\nlayout: post\ndate: 2015-10-21 16:45:44\ntag: \n\t- GitHub\ntitle: \"Windows下使用 git push 命令的无密码设置\"\ncategories: GitHub\n---\n\n在使用git时，每次进行git push时都需要输入用户名和密码，简直让人抓狂呀。下面介绍一种方法，可以避免用户名和密码输入，节省大量时间。\n\n## 1.添加环境变量\n\n首先在系统变量中添加一个环境变量HOME，内容为\n\n```\nHOME%USERPROFILE%\n```\n\n<center>\n![配置环境变量](http://ww4.sinaimg.cn/large/637f3c58gw1exbx3roqvcj20bo0cadgy.jpg)\n</center>\n\n<!-- more -->\n\n## 2.新建配置文件\n\n由于使用的是Windows，所以进入%HOME%目录（如我的:C:\\Users\\username），新建一个名为\"_netrc\"的文件，文件中内容格式如下：\n\n```\nmachine github.com\nlogin your-username\npassword your-password\n```\n\n接着，打开git bash后，输入git push 命令就无需再输入用户名和密码了。\n\n爽歪歪啦~\n\n\n---\n\n","slug":"2015-10-21 Windows git push no password","published":1,"updated":"2016-06-09T02:37:04.132Z","_id":"cimigpyyb006s6cujhny2fhya","comments":1,"photos":[],"link":""},{"layout":"post","title":"机器学习-个人资料整理","date":"2015-09-23T14:22:22.000Z","comments":1,"_content":"\n\n学习Machine Learning也有很长一段时间了，前段时间在paper中应用了GTB（Gradient Tree Boosting）算法。在我的数据集上GTB的performance比Random Forest要稍微强一点，整个experiment做完之后，有许多东西都来不及及时整理，很多都遗忘了。打算接下来的时间里，好好整理下自己的学习资料，这份资料绝对不是一时半会就整理得完的，先开个头吧，以后会间断性更新该blog的。\n\n下面来做个资料整理吧。\n\n<!-- more -->\n\n## **书籍推荐**\n\n机器学习的书籍很多，下面推荐几本本人用过而且觉得还不错的书籍。优于机器学习是一门跨领域的学科，所以在书籍上并非全是机器学习的书籍:\n\n- 1.《机器学习实战》**Machine Learning in Action [美] Peter Harington 著**。该书贯穿了10个最受欢迎的机器学习算法，提供了案例研究问题并用Python代码实例来解决。我本人比较喜欢这本书，因为里面的代码给了我很大的帮助，自己在学习机器学习算法的时候，理论上很多东西不太理解透，通过该书实践之后，在算法层面又有了进一步的提高。\n- 2.《统计学习方法》 李航著。该书比较详细地介绍了算法的原理，只从理论层面来研究算法。通过这本书和《机器学习实战》两本书相结合，一本讲理论，一本着手实践，加在一起会有事半功倍的效果。\n- 3.《数据挖掘概念与技术》 韩家炜著。该书介绍了数据挖掘的常用技术，比较详实，但本人觉得不太适合初学者，当时自己初学的时候看的就是这本书，结果最后很多地方理解的不是很好，后来通过《统计学习方法》和算法实践之后，再回头看《数据挖掘概念与技术》，感觉就轻松多了。\n- 4.《数学之美》 吴军著。本书可以当做业余书籍来看，可以在无聊的时候看看，不过里面讲的东西还是挺有用的。\n- 5.《Python科学计算》该书可以当做Python编程参考书籍，但前提是你喜欢使用Python，并爱上了它，不然这本书还是蛮贵的，我自己也是通过“研究生自由探索项目”才买的这本书，因为可以报销嘛。\n\n## **学习工具**\n\n机器学习的tools很多，这里只列出几个参考工具。\n\n- [Scikit-learn](http://scikit-learn.org/stable/user_guide.html).基于Python语言的[scikit-learn](http://scikit-learn.org/stable/user_guide.html)库，里面涵盖了分类、聚类、回归的大部分算法，并且有常用的评估指标以及预处理数据的方法，是一个不错的学习库，强力推荐。附一篇博文：[SOME USEFUL MACHINE LEARNING LIBRARIES](http://www.erogol.com/broad-view-machine-learning-libraries/).\n- [R](http://www.r-project.org/)语言，语言就是一门工具，R语言现在在商业界是用的最多的，在统计方面功能强大，而且也有封装好的算法库可以直接使用。附：[R语言参考卡片](https://cran.r-project.org/doc/contrib/Liu-R-refcard.pdf).\n- [Weka](http://www.cs.waikato.ac.nz/ml/weka/)，是一个基于java开发的数据挖掘工具，可以尝试一下。它为用户提供了一系列据挖掘API、命令行和图形化用户接口。你可以准备数据、可视化、建立分类、进行回归分析、建立聚类模型，同时可以通过第三方插件执行其他算法。除了WEKA之外， [Mahout](http://mahout.apache.org/)是Hadoop中为机器学习提供的一个很好的JAVA框架，你可以自行学习。如果你是机器学习和大数据学习的新手，那么坚持学习WEKA，并且全心全意地学习一个库。\n- Matlab，里面有很多的工具包，不过本人不怎么用过。参考：[Matlab Codes and Datasets for Feature Learning](http://www.cad.zju.edu.cn/home/dengcai/Data/data.html)和[Statistics and Machine Learning Toolbox](http://cn.mathworks.com/products/statistics/)。此外matlab中的[Octave](http://www.gnu.org/software/octave/)可以很方便地解决线性和非线性问题，比如机器学习算法底层涉及的问题。如果你有工程背景，那么你可以由此入手。\n- [BigML](https://bigml.com/):可能你并不想进行编程工作。你完全可以不通过代码，来使用 WEKA那样的工具。你通过使用BigMLS的服务来进行更加深入的工作。BigML通过Web页面，提供了机器学习的接口，因此你可以通过浏览器来建立模型。\n- 如果你使用Python，这里推荐一个IDE，[WinPython](http://sourceforge.net/projects/winpython/files/WinPython_2.7/2.7.10.1/),IDE版本就是Python的版本，自行选择！\n\n\n下面给出一个比较图，具体想要学什么，还需自己抉择。\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20150918075645450)\n</center>\n\n\n## **学习视频**\n\n由于本人比较崇拜Andrew Ng，所以关于视频，首先推荐的便是Andrew Ng的斯坦福大学的机器学习课程。这套视频在网上有两个网址，国外和国内的都有，全程英语教学，内容很好，有时间建议你去听听：\n\n- 一个是国外的Coursera公开课，该课程在机器学习领域很火，是很多入门学者的首选。地址：https://www.coursera.org/；讲义地址：[Stanford CS229 course下载讲义和笔记](http://cs229.stanford.edu/)；\n- 一个是国内的网易公开课，链接地址：http://open.163.com/movie/2008/1/U/O/M6SGF6VB4_M6SGJURUO.html\n\n下面是一个机器学习视频库，由加州理工学院（Caltech）出品。\n\n- 机器学习视频库，地址：http://work.caltech.edu/library/\n\n其它的视频库\n\n- [Machine Learning Category on VideoLectures](http://videolectures.net/Top/Computer_Science/Machine_Learning/)，这个网站的视频比较多。你可以找出比较感兴趣的资源，然后深入学习。\n\n<font color=\"#008B00\">机器学习最近在国内比较火，许多培训机构都相应的开了该门课程，如果想要听中文教程的，可以去网上搜索下，这里就不给培训机构打广告了。</font>\n\n## **博客和文章推荐**\n\n大牛们的博客，会让你感到兴奋，让你觉得你不是一个人在奋斗，让你时刻记住你的前方已经有很多的学者正在等着你，你要加油。他们的经验会让我们少走些冤枉路，能让我们在他们的基础上进一步理解。下面推荐几个我所知道的或者说我了解到的几位牛人博客和几篇文章：\n\n- **pluskid**，真名张弛原，一位技术大牛，毕业于浙江大学，后来出国深造。他的博文质量非常高，深入浅出，其SVM三层境界的讲解让人茅塞顿开，应该给了很多人启发吧，很值得学习。现在的博客网址：[Chiyuan Zhang](http://pluskid.org/about.html)，原博客网址：[Chiyuan Zhang](http://blog.pluskid.org/)\n- **Rachel Zhang**，真名张睿卿，很有气质的一位软妹纸，目前是百度深度学习实验室研发工程师，在CSDN中的博客人气绝对屈指可数，算是IT界的一位女中豪杰。博客网址：[CSDN博客-Rachel Zhang](http://blog.csdn.net/abcjennifer)\n- **July**，对算法研究独具一格，目前是七月在线科技创始人兼CEO。博客网址：[July](http://blog.csdn.net/v_JULY_v)\n- **Jason**，一位国外机器学习爱好者，其博客内容详实，多篇文章被国内机器学习者翻译。博客网址：http://machinelearningmastery.com/blog/\n- 一个国外很好的机器学习博客，里面介绍了详细的算法知识，很全面，从感知机、神经网络、决策树、SVM、Adaboost到随机森林、Deep Learning.网址：[A Blog From a Human-engineer-being](http://www.erogol.com/machine-learning/)\n- 一篇涵盖许多机器学习资料的文章：[机器学习(Machine Learning)&深度学习(Deep Learning)资料](http://www.open-open.com/lib/view/open1428112201271.html)\n- **Edwin Chen**\t，机器学习爱好者，博客内容涵盖数学、机器学习和数据科学。分享其中一篇博文：[Choosing a Machine Learning Classifier](http://blog.echen.me/2011/04/27/choosing-a-machine-learning-classifier/)\t\n- 一篇以前的博文：[A List of Data Science and Machine Learning Resources](http://conductrics.com/data-science-resources/)，有时间好好阅读阅读，对你绝对有帮助。\n- [A Few Useful Things to Know about Machine Learning](http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf),一篇很有帮助的机器学习文章，里面包括了特征选择与模型的简化。\n- [The Discipline of Machine Learning](http://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf)机器学习规则。该文章比较老，2006年发布的，作者是Tom Mitchell，但很有参考价值，其中定义了机器学习的规则。Mitchell在说服CMU总裁为一个百年内都存在的问题建立一个独立的机器学习部门时，也用到了这本书中的观点。希望能对你也有所帮助。\n- 分享一个网站：[简书](http://www.jianshu.com/)。\n\n\n## **国外网站**\n\n如果你想搜索比较新颖的机器学习资料或是文章，可以到以下网站中搜索，里面不仅包括了机器学习的内容，还有许多其它相关领域内容，如数据科学和云计算等。\n\n- InfoWord：http://www.infoworld.com/reviews/\n- Kdnuggets：http://www.kdnuggets.com\n- Datasciencecentral：http://www.datasciencecentral.com/\n- Datascienceplus：http://datascienceplus.com\n\n## **数据科学竞赛**\n\n关于数据分析的竞赛，国内国外都有，下面推荐几个比较火的竞赛网站 ：\n\n- Kaggle比赛，网址：https://www.kaggle.com/\n- DataCastle比赛，网站：http://www.pkbigdata.com/\n- 阿里大数据竞赛，目前没有消息了，2015年有个【2015天池大数据竞赛】\n\n## **ML相关算法参考**\n\n- 决策树-参考：[decision Tree（Python实现）](http://blog.csdn.net/dream_angel_z/article/details/45965463)\n- SVM支持向量机-参考：[pluskid支持向量机三重境界](http://blog.pluskid.org/?page_id=683)\n- Adaboost-参考：[组合算法-Adaboost](http://www.csuldw.com/2015/07/05/2015-07-12-Adaboost/)\n- Random Forest-参考：[随机森林算法](http://www.cnblogs.com/wentingtu/archive/2011/12/22/2297405.html)\n- 朴素贝叶斯算法-参考：[Naive Bayes算法实现](http://blog.csdn.net/dream_angel_z/article/details/46120867)\n- 人工神经网络-参考：http://www.cnblogs.com/luxiaoxun/archive/2012/12/10/2811309.html\n- Apriori算法-参考地址：[Apriori关联分析](http://www.csuldw.com/2015/06/04/2015-06-04-Apriori/)\n- K最近邻算法-参考：[KNN从原理到实现](http://blog.csdn.net/dream_angel_z/article/details/45896449)\n- 梯度树提升GTB算法-参考：[Gradient Tree Boosting（或GBRT）](http://blog.csdn.net/dream_angel_z/article/details/48085889)\n- K-means聚类-参考：[K-means cluster](http://blog.csdn.net/dream_angel_z/article/details/46343597)\n- 组合算法总结-参考：[Ensemble算法总结](http://www.csuldw.com/2015/07/22/2015-07-22%20%20ensemble/)\n- EM期望最大算法-参考：[EM算法](http://blog.csdn.net/zouxy09/article/details/8537620)\n- Logistic回归-参考：[逻辑回归](http://blog.csdn.net/wangran51/article/details/8892923)\n- HMM隐马尔可夫模型，参考:[HMM](http://blog.csdn.net/likelet/article/details/7056068)\n- 条件随机场，参考：[CRF](http://www.tanghuangwhu.com/archives/162)\n- 随机森林和GBDT，参考：[决策树模型组合之随机森林与GBDT](http://www.cnblogs.com/LeftNotEasy/archive/2011/03/07/1976562.html)\n- 特征选择和特征提取，参考：[特征提取与特征选择](http://blog.csdn.net/lanbing510/article/details/40488787)\n- 梯度下降法，参考:[gradient descent](http://blog.csdn.net/woxincd/article/details/7040944)\n- 牛顿法，参考：[牛顿法](http://blog.csdn.net/luoleicn/article/details/6527049)\n- 线性判别分析，参考：[线性判别](http://www.cnblogs.com/jerrylead/archive/2011/04/21/2024384.html)\n- 深度学习-[深度学习概述：从感知机到深度网络](http://www.cnblogs.com/xiaowanyer/p/3701944.html)\n\n\n## **个人译文**\n\n下面是本人在CSDN云计算栏目发布的翻译文章，如有翻译不准确的地方，还望多多包涵，希望能给大家带来点帮助，译文列表如下：\n\n- 2015-09-14 [LSTM实现详解](http://www.csdn.net/article/2015-09-14/2825693)\n- 2015-09-10 [从零实现来理解机器学习算法：书籍推荐及障碍的克服](http://www.csdn.net/article/2015-09-08/2825646)\n- 2015-08-31  [机器学习开发者的现代化路径：不需要从统计学微积分开始](http://www.csdn.net/article/2015-08-27/2825551)\n- 2015-08-27 [基于Python的卷积神经网络和特征提取](http://www.csdn.net/article/2015-08-27/2825549)\n- 2015-08-20 [你应该掌握的七种回归技术](http://www.csdn.net/article/2015-08-19/2825492)\n- 2015-08-11 [机器学习API Top 10：AT&T Speech、IBM Watson和Google Prediction](http://www.csdn.net/article/2015-08-10/2825430)\n- 2015-08-03 [从Theano到Lasagne：基于Python的深度学习的框架和库](http://www.csdn.net/article/2015-08-01/2825362)\n- 2015-07-15 [Airbnb欺诈预测机器学习模型设计：准确率和召回率的故事](http://www.csdn.net/article/2015-07-13/2825188)\n- 2015-07-13 [开发者成功使用机器学习的十大诀窍](http://www.csdn.net/article/2015-07-13/2825187)\n\n下面是相关译者的译文，仅供参考：\n\n- 2015-09-16 [各种编程语言的深度学习库整理](http://www.csdn.net/article/2015-09-15/2825714)\n- 2015-09-11 [机器学习温和指南](http://www.csdn.net/article/2015-09-08/2825647)\n- 2015-09-10 [关于数据科学，书上不曾提及的三点经验](http://www.csdn.net/article/2015-09-10/2825668)\n\n---\n\n<font color=\"#CD3333\" >从这些牛人的博客中，你能学到很多。慢慢地你会体会到，不是你一个人在战斗，还有很多人，所以你不用害怕孤独。</font>\n\n最后，关于机器学习资料的整理，先到此为止吧，如果你有什么好的资料，欢迎在评论中给出推荐或网址链接。\n\n\n\n---\n\n","source":"_posts/2015-09-23 Machine learning materials.md","raw":"---\nlayout: post\ntitle: 机器学习-个人资料整理\ndate: 2015-09-23 22:22:22\ntag:\n\t- Machine Learning\ncomments: true\ncategories: ML\n---\n\n\n学习Machine Learning也有很长一段时间了，前段时间在paper中应用了GTB（Gradient Tree Boosting）算法。在我的数据集上GTB的performance比Random Forest要稍微强一点，整个experiment做完之后，有许多东西都来不及及时整理，很多都遗忘了。打算接下来的时间里，好好整理下自己的学习资料，这份资料绝对不是一时半会就整理得完的，先开个头吧，以后会间断性更新该blog的。\n\n下面来做个资料整理吧。\n\n<!-- more -->\n\n## **书籍推荐**\n\n机器学习的书籍很多，下面推荐几本本人用过而且觉得还不错的书籍。优于机器学习是一门跨领域的学科，所以在书籍上并非全是机器学习的书籍:\n\n- 1.《机器学习实战》**Machine Learning in Action [美] Peter Harington 著**。该书贯穿了10个最受欢迎的机器学习算法，提供了案例研究问题并用Python代码实例来解决。我本人比较喜欢这本书，因为里面的代码给了我很大的帮助，自己在学习机器学习算法的时候，理论上很多东西不太理解透，通过该书实践之后，在算法层面又有了进一步的提高。\n- 2.《统计学习方法》 李航著。该书比较详细地介绍了算法的原理，只从理论层面来研究算法。通过这本书和《机器学习实战》两本书相结合，一本讲理论，一本着手实践，加在一起会有事半功倍的效果。\n- 3.《数据挖掘概念与技术》 韩家炜著。该书介绍了数据挖掘的常用技术，比较详实，但本人觉得不太适合初学者，当时自己初学的时候看的就是这本书，结果最后很多地方理解的不是很好，后来通过《统计学习方法》和算法实践之后，再回头看《数据挖掘概念与技术》，感觉就轻松多了。\n- 4.《数学之美》 吴军著。本书可以当做业余书籍来看，可以在无聊的时候看看，不过里面讲的东西还是挺有用的。\n- 5.《Python科学计算》该书可以当做Python编程参考书籍，但前提是你喜欢使用Python，并爱上了它，不然这本书还是蛮贵的，我自己也是通过“研究生自由探索项目”才买的这本书，因为可以报销嘛。\n\n## **学习工具**\n\n机器学习的tools很多，这里只列出几个参考工具。\n\n- [Scikit-learn](http://scikit-learn.org/stable/user_guide.html).基于Python语言的[scikit-learn](http://scikit-learn.org/stable/user_guide.html)库，里面涵盖了分类、聚类、回归的大部分算法，并且有常用的评估指标以及预处理数据的方法，是一个不错的学习库，强力推荐。附一篇博文：[SOME USEFUL MACHINE LEARNING LIBRARIES](http://www.erogol.com/broad-view-machine-learning-libraries/).\n- [R](http://www.r-project.org/)语言，语言就是一门工具，R语言现在在商业界是用的最多的，在统计方面功能强大，而且也有封装好的算法库可以直接使用。附：[R语言参考卡片](https://cran.r-project.org/doc/contrib/Liu-R-refcard.pdf).\n- [Weka](http://www.cs.waikato.ac.nz/ml/weka/)，是一个基于java开发的数据挖掘工具，可以尝试一下。它为用户提供了一系列据挖掘API、命令行和图形化用户接口。你可以准备数据、可视化、建立分类、进行回归分析、建立聚类模型，同时可以通过第三方插件执行其他算法。除了WEKA之外， [Mahout](http://mahout.apache.org/)是Hadoop中为机器学习提供的一个很好的JAVA框架，你可以自行学习。如果你是机器学习和大数据学习的新手，那么坚持学习WEKA，并且全心全意地学习一个库。\n- Matlab，里面有很多的工具包，不过本人不怎么用过。参考：[Matlab Codes and Datasets for Feature Learning](http://www.cad.zju.edu.cn/home/dengcai/Data/data.html)和[Statistics and Machine Learning Toolbox](http://cn.mathworks.com/products/statistics/)。此外matlab中的[Octave](http://www.gnu.org/software/octave/)可以很方便地解决线性和非线性问题，比如机器学习算法底层涉及的问题。如果你有工程背景，那么你可以由此入手。\n- [BigML](https://bigml.com/):可能你并不想进行编程工作。你完全可以不通过代码，来使用 WEKA那样的工具。你通过使用BigMLS的服务来进行更加深入的工作。BigML通过Web页面，提供了机器学习的接口，因此你可以通过浏览器来建立模型。\n- 如果你使用Python，这里推荐一个IDE，[WinPython](http://sourceforge.net/projects/winpython/files/WinPython_2.7/2.7.10.1/),IDE版本就是Python的版本，自行选择！\n\n\n下面给出一个比较图，具体想要学什么，还需自己抉择。\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20150918075645450)\n</center>\n\n\n## **学习视频**\n\n由于本人比较崇拜Andrew Ng，所以关于视频，首先推荐的便是Andrew Ng的斯坦福大学的机器学习课程。这套视频在网上有两个网址，国外和国内的都有，全程英语教学，内容很好，有时间建议你去听听：\n\n- 一个是国外的Coursera公开课，该课程在机器学习领域很火，是很多入门学者的首选。地址：https://www.coursera.org/；讲义地址：[Stanford CS229 course下载讲义和笔记](http://cs229.stanford.edu/)；\n- 一个是国内的网易公开课，链接地址：http://open.163.com/movie/2008/1/U/O/M6SGF6VB4_M6SGJURUO.html\n\n下面是一个机器学习视频库，由加州理工学院（Caltech）出品。\n\n- 机器学习视频库，地址：http://work.caltech.edu/library/\n\n其它的视频库\n\n- [Machine Learning Category on VideoLectures](http://videolectures.net/Top/Computer_Science/Machine_Learning/)，这个网站的视频比较多。你可以找出比较感兴趣的资源，然后深入学习。\n\n<font color=\"#008B00\">机器学习最近在国内比较火，许多培训机构都相应的开了该门课程，如果想要听中文教程的，可以去网上搜索下，这里就不给培训机构打广告了。</font>\n\n## **博客和文章推荐**\n\n大牛们的博客，会让你感到兴奋，让你觉得你不是一个人在奋斗，让你时刻记住你的前方已经有很多的学者正在等着你，你要加油。他们的经验会让我们少走些冤枉路，能让我们在他们的基础上进一步理解。下面推荐几个我所知道的或者说我了解到的几位牛人博客和几篇文章：\n\n- **pluskid**，真名张弛原，一位技术大牛，毕业于浙江大学，后来出国深造。他的博文质量非常高，深入浅出，其SVM三层境界的讲解让人茅塞顿开，应该给了很多人启发吧，很值得学习。现在的博客网址：[Chiyuan Zhang](http://pluskid.org/about.html)，原博客网址：[Chiyuan Zhang](http://blog.pluskid.org/)\n- **Rachel Zhang**，真名张睿卿，很有气质的一位软妹纸，目前是百度深度学习实验室研发工程师，在CSDN中的博客人气绝对屈指可数，算是IT界的一位女中豪杰。博客网址：[CSDN博客-Rachel Zhang](http://blog.csdn.net/abcjennifer)\n- **July**，对算法研究独具一格，目前是七月在线科技创始人兼CEO。博客网址：[July](http://blog.csdn.net/v_JULY_v)\n- **Jason**，一位国外机器学习爱好者，其博客内容详实，多篇文章被国内机器学习者翻译。博客网址：http://machinelearningmastery.com/blog/\n- 一个国外很好的机器学习博客，里面介绍了详细的算法知识，很全面，从感知机、神经网络、决策树、SVM、Adaboost到随机森林、Deep Learning.网址：[A Blog From a Human-engineer-being](http://www.erogol.com/machine-learning/)\n- 一篇涵盖许多机器学习资料的文章：[机器学习(Machine Learning)&深度学习(Deep Learning)资料](http://www.open-open.com/lib/view/open1428112201271.html)\n- **Edwin Chen**\t，机器学习爱好者，博客内容涵盖数学、机器学习和数据科学。分享其中一篇博文：[Choosing a Machine Learning Classifier](http://blog.echen.me/2011/04/27/choosing-a-machine-learning-classifier/)\t\n- 一篇以前的博文：[A List of Data Science and Machine Learning Resources](http://conductrics.com/data-science-resources/)，有时间好好阅读阅读，对你绝对有帮助。\n- [A Few Useful Things to Know about Machine Learning](http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf),一篇很有帮助的机器学习文章，里面包括了特征选择与模型的简化。\n- [The Discipline of Machine Learning](http://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf)机器学习规则。该文章比较老，2006年发布的，作者是Tom Mitchell，但很有参考价值，其中定义了机器学习的规则。Mitchell在说服CMU总裁为一个百年内都存在的问题建立一个独立的机器学习部门时，也用到了这本书中的观点。希望能对你也有所帮助。\n- 分享一个网站：[简书](http://www.jianshu.com/)。\n\n\n## **国外网站**\n\n如果你想搜索比较新颖的机器学习资料或是文章，可以到以下网站中搜索，里面不仅包括了机器学习的内容，还有许多其它相关领域内容，如数据科学和云计算等。\n\n- InfoWord：http://www.infoworld.com/reviews/\n- Kdnuggets：http://www.kdnuggets.com\n- Datasciencecentral：http://www.datasciencecentral.com/\n- Datascienceplus：http://datascienceplus.com\n\n## **数据科学竞赛**\n\n关于数据分析的竞赛，国内国外都有，下面推荐几个比较火的竞赛网站 ：\n\n- Kaggle比赛，网址：https://www.kaggle.com/\n- DataCastle比赛，网站：http://www.pkbigdata.com/\n- 阿里大数据竞赛，目前没有消息了，2015年有个【2015天池大数据竞赛】\n\n## **ML相关算法参考**\n\n- 决策树-参考：[decision Tree（Python实现）](http://blog.csdn.net/dream_angel_z/article/details/45965463)\n- SVM支持向量机-参考：[pluskid支持向量机三重境界](http://blog.pluskid.org/?page_id=683)\n- Adaboost-参考：[组合算法-Adaboost](http://www.csuldw.com/2015/07/05/2015-07-12-Adaboost/)\n- Random Forest-参考：[随机森林算法](http://www.cnblogs.com/wentingtu/archive/2011/12/22/2297405.html)\n- 朴素贝叶斯算法-参考：[Naive Bayes算法实现](http://blog.csdn.net/dream_angel_z/article/details/46120867)\n- 人工神经网络-参考：http://www.cnblogs.com/luxiaoxun/archive/2012/12/10/2811309.html\n- Apriori算法-参考地址：[Apriori关联分析](http://www.csuldw.com/2015/06/04/2015-06-04-Apriori/)\n- K最近邻算法-参考：[KNN从原理到实现](http://blog.csdn.net/dream_angel_z/article/details/45896449)\n- 梯度树提升GTB算法-参考：[Gradient Tree Boosting（或GBRT）](http://blog.csdn.net/dream_angel_z/article/details/48085889)\n- K-means聚类-参考：[K-means cluster](http://blog.csdn.net/dream_angel_z/article/details/46343597)\n- 组合算法总结-参考：[Ensemble算法总结](http://www.csuldw.com/2015/07/22/2015-07-22%20%20ensemble/)\n- EM期望最大算法-参考：[EM算法](http://blog.csdn.net/zouxy09/article/details/8537620)\n- Logistic回归-参考：[逻辑回归](http://blog.csdn.net/wangran51/article/details/8892923)\n- HMM隐马尔可夫模型，参考:[HMM](http://blog.csdn.net/likelet/article/details/7056068)\n- 条件随机场，参考：[CRF](http://www.tanghuangwhu.com/archives/162)\n- 随机森林和GBDT，参考：[决策树模型组合之随机森林与GBDT](http://www.cnblogs.com/LeftNotEasy/archive/2011/03/07/1976562.html)\n- 特征选择和特征提取，参考：[特征提取与特征选择](http://blog.csdn.net/lanbing510/article/details/40488787)\n- 梯度下降法，参考:[gradient descent](http://blog.csdn.net/woxincd/article/details/7040944)\n- 牛顿法，参考：[牛顿法](http://blog.csdn.net/luoleicn/article/details/6527049)\n- 线性判别分析，参考：[线性判别](http://www.cnblogs.com/jerrylead/archive/2011/04/21/2024384.html)\n- 深度学习-[深度学习概述：从感知机到深度网络](http://www.cnblogs.com/xiaowanyer/p/3701944.html)\n\n\n## **个人译文**\n\n下面是本人在CSDN云计算栏目发布的翻译文章，如有翻译不准确的地方，还望多多包涵，希望能给大家带来点帮助，译文列表如下：\n\n- 2015-09-14 [LSTM实现详解](http://www.csdn.net/article/2015-09-14/2825693)\n- 2015-09-10 [从零实现来理解机器学习算法：书籍推荐及障碍的克服](http://www.csdn.net/article/2015-09-08/2825646)\n- 2015-08-31  [机器学习开发者的现代化路径：不需要从统计学微积分开始](http://www.csdn.net/article/2015-08-27/2825551)\n- 2015-08-27 [基于Python的卷积神经网络和特征提取](http://www.csdn.net/article/2015-08-27/2825549)\n- 2015-08-20 [你应该掌握的七种回归技术](http://www.csdn.net/article/2015-08-19/2825492)\n- 2015-08-11 [机器学习API Top 10：AT&T Speech、IBM Watson和Google Prediction](http://www.csdn.net/article/2015-08-10/2825430)\n- 2015-08-03 [从Theano到Lasagne：基于Python的深度学习的框架和库](http://www.csdn.net/article/2015-08-01/2825362)\n- 2015-07-15 [Airbnb欺诈预测机器学习模型设计：准确率和召回率的故事](http://www.csdn.net/article/2015-07-13/2825188)\n- 2015-07-13 [开发者成功使用机器学习的十大诀窍](http://www.csdn.net/article/2015-07-13/2825187)\n\n下面是相关译者的译文，仅供参考：\n\n- 2015-09-16 [各种编程语言的深度学习库整理](http://www.csdn.net/article/2015-09-15/2825714)\n- 2015-09-11 [机器学习温和指南](http://www.csdn.net/article/2015-09-08/2825647)\n- 2015-09-10 [关于数据科学，书上不曾提及的三点经验](http://www.csdn.net/article/2015-09-10/2825668)\n\n---\n\n<font color=\"#CD3333\" >从这些牛人的博客中，你能学到很多。慢慢地你会体会到，不是你一个人在战斗，还有很多人，所以你不用害怕孤独。</font>\n\n最后，关于机器学习资料的整理，先到此为止吧，如果你有什么好的资料，欢迎在评论中给出推荐或网址链接。\n\n\n\n---\n\n","slug":"2015-09-23 Machine learning materials","published":1,"updated":"2016-03-13T05:56:18.860Z","photos":[],"link":"","_id":"cimigpyyi006x6cujo3mibo7p"},{"layout":"post","title":"Gradient Tree Boosting","date":"2015-08-19T02:54:00.000Z","_content":"\n## **Introduction**\n\n决策树这种算法有着很多良好的特性，比如说训练时间复杂度较低，预测的过程比较快速，模型容易展示（容易将得到的决策树做成图片展示出来）等。但是同时，单决策树又有一些不好的地方，比如说容易over-fitting，虽然有一些方法，如剪枝可以减少这种情况，但是还是不太理想。\n\n模型组合（比如说有Boosting，Bagging等）与决策树相关的算法比较多，如randomForest、Adaboost、GBRT等，这些算法最终的结果是生成N(可能会有几百棵以上）棵树，这样可以大大的减少单决策树带来的毛病，有点类似于三个臭皮匠赛过一个诸葛亮的做法，虽然这几百棵决策树中的每一棵都很简单（相对于C4.5这种单决策树而言），但是他们组合起来确是很强大。虽然这些算法都是通过决策树演变过来的，但在处理的过程上有着一些差异，我会在后面对此做一个本质上的比较。下面先来介绍下本文的梯度提升算法。\n<!-- more -->\n\n## **Gradient Tree Boosting**\n\n梯度树提升（Gradient Tree Boosting）是一种组合算法，也叫做梯度提升回归树（gradient boosting regression tree），它的基分类器是决策树，既可以用来回归，也可以用作分类。在分类性能上，能够和随机森林媲美，甚至在有的数据集上表现的有过之而无不及。如今，Gradient Tree Boosting模型已经广泛的运用在Web搜索排行榜以及生态学上。在阿里内部也用的比较多，所以值得我们去花点时间认真学习。\n\n根据scikit-learn官网的介绍，GBRT的优势有：\n\n- 自然而然地处理混合类型的数据\n- 预测能力强\n- 在输出空间对于异常值的鲁棒性强（通过强大的损失函数）\n\n然而，GBRT也有劣势：\n\n- 可扩展性方面，由于提升的时序性，不能进行并行处理\n\n尽管如此，由于GTB的表现性能很好，所以它仍然受广大业界人士的青睐。下面来介绍下梯度提升树的算法原理。\n\n### __GTB算法__\n\n梯度提升（gradient boosting）算法最初是FreidMan在2000年提出来的，其核心就在于，每棵树是从先前所有树的残差中来学习。利用的是当前模型中损失函数的负梯度值\n\n![](http://latex.codecogs.com/gif.latex?%24%24%20r_%7Bmi%7D%20%3D%20-%20%5CBigg%20%5B%20%5Cfrac%20%7B%5Cpartial%20L%28y_i%2C%20f%20%28x_i%29%29%7D%7B%5Cpartial%20f%20%28x_i%29%7D%5CBigg%20%5D%20_%7Bf%20%28x%29%20%3D%20f%20_%7Bm-1%7D%28x%29%7D%24%24)\n\n作为提升树算法中的残差的近似值，进而拟合一棵回归（分类）树。\n\n梯度提升属于Boost算法的一种，也可以说是Boost算法的一种改进，原始的Boost算法是:<font color=\"#007fff\">**在算法开始时，为每一个样本赋上一个相等的权重值，也就是说，最开始的时候，大家都是一样重要的。在每一次训练中得到的模型，会使得数据点的估计有所差异，所以在每一步结束后，我们需要对权重值进行处理，而处理的方式就是通过增加错分类点的权重，同时减少错分类点的权重，这样使得某些点如果老是被分错，那么就会被“严重关注”，也就被赋上一个很高的权重。然后等进行了N次迭代（由用户指定），将会得到N个简单的基分类器（basic learner），最后将它们组合起来，可以对它们进行加权（错误率越大的基分类器权重值越小，错误率越小的基分类器权重值越大）、或者让它们进行投票等得到一个最终的模型**</font>。\n\nGradient Boost与传统的Boost有着很大的区别，<font color=\"#007fff\">**它的每一次计算都是为了减少上一次的残差(residual)，而为了减少这些残差，可以在残差减少的梯度(Gradient)方向上建立一个新模型**</font>。所以说，在Gradient Boost中，每个新模型的建立是为了使得先前模型残差往梯度方向减少，与传统的Boost算法对正确、错误的样本进行加权有着极大的区别。\n\n\n#### **梯度提升算法（以回归为例）**\n\n对于给定的输入：训练数据集T={(x1,y1),(x2,y2),...,(xn,yn)},损失函数L(y,f(x));\n输出结果：一棵回归树$\\tilde{f}(x)$\n\n---\n\n（1）首先初始化\n\n![$$f_0(x)=\\arg \\ \\min_c \\sum_{i=1}^{N}L(y_i, c)$$](http://latex.codecogs.com/gif.latex?%24%24f_0%28x%29%3D%5Carg%20%5C%20%5Cmin_c%20%5Csum_%7Bi%3D1%7D%5E%7BN%7DL%28y_i%2C%20c%29%24%24)\n\n估计一个使损失函数极小化的常数值，此时它只有一个节点的树；\n（2）迭代的建立M棵提升树\n\nfor m=1 to M:（第一层循环）\nfor i=1 to N：（第二层循环） 计算损失函数的负梯度在当前模型的值，并将它作为残差的估计值。\n\n\n![](http://latex.codecogs.com/gif.latex?%24%24%20r_%7Bmi%7D%20%3D%20-%20%5CBigg%20%5B%20%5Cfrac%20%7B%5Cpartial%20L%28y_i%2C%20f%20%28x_i%29%29%7D%7B%5Cpartial%20f%20%28x_i%29%7D%5CBigg%20%5D%20_%7Bf%20%28x%29%20%3D%20f%20_%7Bm-1%7D%28x%29%7D%24%24)\n\n对于r\\_mi拟合一棵回归树，得到第m棵树的叶节点区域 $R\\_{mj} ,j=1,2,...,J$\n\nfor j=1 to J：（第二层循环）,计算：\n\n![](http://latex.codecogs.com/gif.latex?%24%24c_%7Bmj%7D%20%3D%20arg%20min_c%20%5Csum_%7Bx_i%5Cepsilon%20R_%7Bmj%7D%7DL%28y_i%2Cf_%7Bm-1%7D%28x_i%29&plus;c%29%24%24)\n\n利用线性搜索估计叶节点区域的值，使损失函数极小化；\n\n然后，更新\n\n![](http://latex.codecogs.com/gif.latex?%24%24f_%7Bm%7D%28x%29%20%3D%20f_%7Bm-1%7D%28x%29%20&plus;%20%5Csum_%7Bj%3D1%7D%5EJc_%7Bmj%7DI%28x%20%5Cepsilon%20R_%7Bmj%7D%29%24%24)\n\n（3）最后得到的$f_{m}(x)$就是我们最终的模型\n\n![](http://latex.codecogs.com/gif.latex?%24%24%5Ctilde%7Bf%7D%28x%29%3Df_M%28x%29%3D%5Csum_%7Bm%3D1%7D%5EM%5Csum_%7Bj%3D1%7D%5EJc_%7Bmj%7DI%28x%20%5Cepsilon%20R_%7Bmj%7D%29%24%24)\n\n从式子中也可以看出，GBDT算法是一个加和模型，并在推导中结合了前向分步算法。\n\n---\n\n#### **使用scikit-learn中的GTB**\n\n在scikit-learn中对GTB算法有了很好的封装，对于分类可以选择的损失函数有逻辑回归和指数函数，对于回归的损失函数相对比较多，有最小二乘法、最小绝对偏差函数、huber以及分位数等。具体描述参考下面的图片：\n![](file:///C:/Users/liudiwei/Desktop/QQ截图20150829104337.png)\n\n下面是sklearn中的一个分类原例：\n\n```\n>>> from sklearn.datasets import make_hastie_10_2\n>>> from sklearn.ensemble import GradientBoostingClassifier\n>>> X, y = make_hastie_10_2(random_state=0)\n>>> X_train, X_test = X[:2000], X[2000:]\n>>> y_train, y_test = y[:2000], y[2000:]\n>>> clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n...     max_depth=1, random_state=0).fit(X_train, y_train)\n>>> clf.score(X_test, y_test)                 \n0.913...\n```\n\n其中n_estimators表示弱分类器的个数，learning_rate表示学习率，max_depth表示最大的深度等。GTB的参数比较多，在实际应用中需要自己去调整合适的参数。\n\n\n## **基于决策树的组合算法比较**\n\n基于决策树的组合算法常用的有三个，分别是Adaboost、RandomFrest以及本文的GBRT。\n\nAdaboost是通过迭代的学习每一个基分类器，每次迭代中，把上一次错分类的数据权值增大，正确分类的数据权值减小，然后将基分类器的线性组合作为一个强分类器，同时给分类误差率较小的基本分类器以大的权值，给分类误差率较大的基分类器以小的权重值。Adaboost使用的是自适应的方法，其中概率分布式变化的，关注的是难分类的样本。详细内容请参考我之前的文章：[机器学习算法-Adaboost](http://blog.csdn.net/dream_angel_z/article/details/46764845)。\n\n\n随机森林RandomForest算法，与adaboost有错区别，可以说一种改进的装袋组合算法。随机森林则(randomForest)，不仅对样本进行抽样，还对变量进行抽样。它通过随机的方式建立一个森林，森林里面有许多棵决策树，并且每一棵树之间是没有联系的。在得到森林之后，当有一个新的输入样本进来的时候，就让森林中的每一棵决策树分别对其进行判断，看这个样本应该属于哪一类（就分类算法而言），然后看看哪一类选择最多，就预测这个样本为该类。在建立每一棵决策树的过程中，有两点需要注意，即<font color=\"red\">**采样**</font>与<font color=\"red\">**完全分裂**</font>。首先是两个随机采样的过程，RF对输入的数据要进行行采样和列采样。对于行采样，是采用有放回的方式，也就是在采样得到的样本集合中，可能有重复的样本。假设输入样本为N个，那么采样的样本也为N个。这样使得在训练的时候，每一棵树的输入样本都不是全部的样本，使得相对不容易出现over-fitting过拟合。然后进行列采样，从M个feature特征中，选择m个(m << M)。之后就是对采样之后的数据使用完全分裂的方式建立出决策树，这样决策树的某一个叶子节点要么是无法继续分裂的，要么里面的所有样本的都是指向的同一个类别。一般很多的决策树算法都一个重要的步骤-剪枝，但是这里不这样干，由于之前的两个随机采样的过程保证了随机性，所以就算不剪枝，也不会出现over-fitting。按照这种算法得到的随机森林中的每一棵决策树都是非常弱的，但当它们组合在一起的时候，就相当厉害了。随机森林就好比是：每一棵决策树就是一个精通于某一领域的专家（因为我们从M个feature中选择m个让每一棵决策树进行学习），这样在随机森林中就有了很多个精通不同领域的专家，对一个新的问题（新的输入数据），可以用不同的角度去看待它，最终由各个专家，投票得到结果。随机森林的分类准确率可以与adaboost媲美。它对噪声数据更加鲁棒，运行速度比adaboost也快得多。\n\n\n<font color=\"#007FFF\">**对于梯度提升树，它的每一次计算都是为了减少上一次的残差(residual)，而为了减少这些残差，可以在残差减少的梯度(Gradient)方向上建立一个新模型。**</font>这与adaboost和随机森林有很大的区别。\n\n\n\n### References\n\n\n[1] Introduction to Data Mining 数据挖掘概论. Pang-Ning Tan Michael Steinbach Vipin Kumar著\n[2] 统计学习方法 李航 著\n[3] scikit-learn官网组合算法 [点击这里](http://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting)\n\n参考文章： [随机森林与GBDT](http://www.cnblogs.com/LeftNotEasy/archive/2011/03/07/1976562.html)\n\n------\n<br>\n\n\n","source":"_posts/2015-08-19 GBDT.md","raw":"---\nlayout: post\ntitle: \"Gradient Tree Boosting\"\ndate: 2015-08-19 10:54\ntag: \n\t- Machine Learning\n\t- GBDT\n\t- 组合算法\ncategories: ML\n---\n\n## **Introduction**\n\n决策树这种算法有着很多良好的特性，比如说训练时间复杂度较低，预测的过程比较快速，模型容易展示（容易将得到的决策树做成图片展示出来）等。但是同时，单决策树又有一些不好的地方，比如说容易over-fitting，虽然有一些方法，如剪枝可以减少这种情况，但是还是不太理想。\n\n模型组合（比如说有Boosting，Bagging等）与决策树相关的算法比较多，如randomForest、Adaboost、GBRT等，这些算法最终的结果是生成N(可能会有几百棵以上）棵树，这样可以大大的减少单决策树带来的毛病，有点类似于三个臭皮匠赛过一个诸葛亮的做法，虽然这几百棵决策树中的每一棵都很简单（相对于C4.5这种单决策树而言），但是他们组合起来确是很强大。虽然这些算法都是通过决策树演变过来的，但在处理的过程上有着一些差异，我会在后面对此做一个本质上的比较。下面先来介绍下本文的梯度提升算法。\n<!-- more -->\n\n## **Gradient Tree Boosting**\n\n梯度树提升（Gradient Tree Boosting）是一种组合算法，也叫做梯度提升回归树（gradient boosting regression tree），它的基分类器是决策树，既可以用来回归，也可以用作分类。在分类性能上，能够和随机森林媲美，甚至在有的数据集上表现的有过之而无不及。如今，Gradient Tree Boosting模型已经广泛的运用在Web搜索排行榜以及生态学上。在阿里内部也用的比较多，所以值得我们去花点时间认真学习。\n\n根据scikit-learn官网的介绍，GBRT的优势有：\n\n- 自然而然地处理混合类型的数据\n- 预测能力强\n- 在输出空间对于异常值的鲁棒性强（通过强大的损失函数）\n\n然而，GBRT也有劣势：\n\n- 可扩展性方面，由于提升的时序性，不能进行并行处理\n\n尽管如此，由于GTB的表现性能很好，所以它仍然受广大业界人士的青睐。下面来介绍下梯度提升树的算法原理。\n\n### __GTB算法__\n\n梯度提升（gradient boosting）算法最初是FreidMan在2000年提出来的，其核心就在于，每棵树是从先前所有树的残差中来学习。利用的是当前模型中损失函数的负梯度值\n\n![](http://latex.codecogs.com/gif.latex?%24%24%20r_%7Bmi%7D%20%3D%20-%20%5CBigg%20%5B%20%5Cfrac%20%7B%5Cpartial%20L%28y_i%2C%20f%20%28x_i%29%29%7D%7B%5Cpartial%20f%20%28x_i%29%7D%5CBigg%20%5D%20_%7Bf%20%28x%29%20%3D%20f%20_%7Bm-1%7D%28x%29%7D%24%24)\n\n作为提升树算法中的残差的近似值，进而拟合一棵回归（分类）树。\n\n梯度提升属于Boost算法的一种，也可以说是Boost算法的一种改进，原始的Boost算法是:<font color=\"#007fff\">**在算法开始时，为每一个样本赋上一个相等的权重值，也就是说，最开始的时候，大家都是一样重要的。在每一次训练中得到的模型，会使得数据点的估计有所差异，所以在每一步结束后，我们需要对权重值进行处理，而处理的方式就是通过增加错分类点的权重，同时减少错分类点的权重，这样使得某些点如果老是被分错，那么就会被“严重关注”，也就被赋上一个很高的权重。然后等进行了N次迭代（由用户指定），将会得到N个简单的基分类器（basic learner），最后将它们组合起来，可以对它们进行加权（错误率越大的基分类器权重值越小，错误率越小的基分类器权重值越大）、或者让它们进行投票等得到一个最终的模型**</font>。\n\nGradient Boost与传统的Boost有着很大的区别，<font color=\"#007fff\">**它的每一次计算都是为了减少上一次的残差(residual)，而为了减少这些残差，可以在残差减少的梯度(Gradient)方向上建立一个新模型**</font>。所以说，在Gradient Boost中，每个新模型的建立是为了使得先前模型残差往梯度方向减少，与传统的Boost算法对正确、错误的样本进行加权有着极大的区别。\n\n\n#### **梯度提升算法（以回归为例）**\n\n对于给定的输入：训练数据集T={(x1,y1),(x2,y2),...,(xn,yn)},损失函数L(y,f(x));\n输出结果：一棵回归树$\\tilde{f}(x)$\n\n---\n\n（1）首先初始化\n\n![$$f_0(x)=\\arg \\ \\min_c \\sum_{i=1}^{N}L(y_i, c)$$](http://latex.codecogs.com/gif.latex?%24%24f_0%28x%29%3D%5Carg%20%5C%20%5Cmin_c%20%5Csum_%7Bi%3D1%7D%5E%7BN%7DL%28y_i%2C%20c%29%24%24)\n\n估计一个使损失函数极小化的常数值，此时它只有一个节点的树；\n（2）迭代的建立M棵提升树\n\nfor m=1 to M:（第一层循环）\nfor i=1 to N：（第二层循环） 计算损失函数的负梯度在当前模型的值，并将它作为残差的估计值。\n\n\n![](http://latex.codecogs.com/gif.latex?%24%24%20r_%7Bmi%7D%20%3D%20-%20%5CBigg%20%5B%20%5Cfrac%20%7B%5Cpartial%20L%28y_i%2C%20f%20%28x_i%29%29%7D%7B%5Cpartial%20f%20%28x_i%29%7D%5CBigg%20%5D%20_%7Bf%20%28x%29%20%3D%20f%20_%7Bm-1%7D%28x%29%7D%24%24)\n\n对于r\\_mi拟合一棵回归树，得到第m棵树的叶节点区域 $R\\_{mj} ,j=1,2,...,J$\n\nfor j=1 to J：（第二层循环）,计算：\n\n![](http://latex.codecogs.com/gif.latex?%24%24c_%7Bmj%7D%20%3D%20arg%20min_c%20%5Csum_%7Bx_i%5Cepsilon%20R_%7Bmj%7D%7DL%28y_i%2Cf_%7Bm-1%7D%28x_i%29&plus;c%29%24%24)\n\n利用线性搜索估计叶节点区域的值，使损失函数极小化；\n\n然后，更新\n\n![](http://latex.codecogs.com/gif.latex?%24%24f_%7Bm%7D%28x%29%20%3D%20f_%7Bm-1%7D%28x%29%20&plus;%20%5Csum_%7Bj%3D1%7D%5EJc_%7Bmj%7DI%28x%20%5Cepsilon%20R_%7Bmj%7D%29%24%24)\n\n（3）最后得到的$f_{m}(x)$就是我们最终的模型\n\n![](http://latex.codecogs.com/gif.latex?%24%24%5Ctilde%7Bf%7D%28x%29%3Df_M%28x%29%3D%5Csum_%7Bm%3D1%7D%5EM%5Csum_%7Bj%3D1%7D%5EJc_%7Bmj%7DI%28x%20%5Cepsilon%20R_%7Bmj%7D%29%24%24)\n\n从式子中也可以看出，GBDT算法是一个加和模型，并在推导中结合了前向分步算法。\n\n---\n\n#### **使用scikit-learn中的GTB**\n\n在scikit-learn中对GTB算法有了很好的封装，对于分类可以选择的损失函数有逻辑回归和指数函数，对于回归的损失函数相对比较多，有最小二乘法、最小绝对偏差函数、huber以及分位数等。具体描述参考下面的图片：\n![](file:///C:/Users/liudiwei/Desktop/QQ截图20150829104337.png)\n\n下面是sklearn中的一个分类原例：\n\n```\n>>> from sklearn.datasets import make_hastie_10_2\n>>> from sklearn.ensemble import GradientBoostingClassifier\n>>> X, y = make_hastie_10_2(random_state=0)\n>>> X_train, X_test = X[:2000], X[2000:]\n>>> y_train, y_test = y[:2000], y[2000:]\n>>> clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n...     max_depth=1, random_state=0).fit(X_train, y_train)\n>>> clf.score(X_test, y_test)                 \n0.913...\n```\n\n其中n_estimators表示弱分类器的个数，learning_rate表示学习率，max_depth表示最大的深度等。GTB的参数比较多，在实际应用中需要自己去调整合适的参数。\n\n\n## **基于决策树的组合算法比较**\n\n基于决策树的组合算法常用的有三个，分别是Adaboost、RandomFrest以及本文的GBRT。\n\nAdaboost是通过迭代的学习每一个基分类器，每次迭代中，把上一次错分类的数据权值增大，正确分类的数据权值减小，然后将基分类器的线性组合作为一个强分类器，同时给分类误差率较小的基本分类器以大的权值，给分类误差率较大的基分类器以小的权重值。Adaboost使用的是自适应的方法，其中概率分布式变化的，关注的是难分类的样本。详细内容请参考我之前的文章：[机器学习算法-Adaboost](http://blog.csdn.net/dream_angel_z/article/details/46764845)。\n\n\n随机森林RandomForest算法，与adaboost有错区别，可以说一种改进的装袋组合算法。随机森林则(randomForest)，不仅对样本进行抽样，还对变量进行抽样。它通过随机的方式建立一个森林，森林里面有许多棵决策树，并且每一棵树之间是没有联系的。在得到森林之后，当有一个新的输入样本进来的时候，就让森林中的每一棵决策树分别对其进行判断，看这个样本应该属于哪一类（就分类算法而言），然后看看哪一类选择最多，就预测这个样本为该类。在建立每一棵决策树的过程中，有两点需要注意，即<font color=\"red\">**采样**</font>与<font color=\"red\">**完全分裂**</font>。首先是两个随机采样的过程，RF对输入的数据要进行行采样和列采样。对于行采样，是采用有放回的方式，也就是在采样得到的样本集合中，可能有重复的样本。假设输入样本为N个，那么采样的样本也为N个。这样使得在训练的时候，每一棵树的输入样本都不是全部的样本，使得相对不容易出现over-fitting过拟合。然后进行列采样，从M个feature特征中，选择m个(m << M)。之后就是对采样之后的数据使用完全分裂的方式建立出决策树，这样决策树的某一个叶子节点要么是无法继续分裂的，要么里面的所有样本的都是指向的同一个类别。一般很多的决策树算法都一个重要的步骤-剪枝，但是这里不这样干，由于之前的两个随机采样的过程保证了随机性，所以就算不剪枝，也不会出现over-fitting。按照这种算法得到的随机森林中的每一棵决策树都是非常弱的，但当它们组合在一起的时候，就相当厉害了。随机森林就好比是：每一棵决策树就是一个精通于某一领域的专家（因为我们从M个feature中选择m个让每一棵决策树进行学习），这样在随机森林中就有了很多个精通不同领域的专家，对一个新的问题（新的输入数据），可以用不同的角度去看待它，最终由各个专家，投票得到结果。随机森林的分类准确率可以与adaboost媲美。它对噪声数据更加鲁棒，运行速度比adaboost也快得多。\n\n\n<font color=\"#007FFF\">**对于梯度提升树，它的每一次计算都是为了减少上一次的残差(residual)，而为了减少这些残差，可以在残差减少的梯度(Gradient)方向上建立一个新模型。**</font>这与adaboost和随机森林有很大的区别。\n\n\n\n### References\n\n\n[1] Introduction to Data Mining 数据挖掘概论. Pang-Ning Tan Michael Steinbach Vipin Kumar著\n[2] 统计学习方法 李航 著\n[3] scikit-learn官网组合算法 [点击这里](http://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting)\n\n参考文章： [随机森林与GBDT](http://www.cnblogs.com/LeftNotEasy/archive/2011/03/07/1976562.html)\n\n------\n<br>\n\n\n","slug":"2015-08-19 GBDT","published":1,"updated":"2016-03-13T06:04:59.915Z","comments":1,"photos":[],"link":"","_id":"cimigpyyn00706cuj58ohd4wl"},{"layout":"post","date":"2015-08-12T12:24:00.000Z","title":"从Theano到Lasagne：基于Python的深度学习的框架和库（译文）","comment":true,"_content":"\n英文链接：http://creative-punch.net/2015/07/frameworks-and-libraries-for-deep-learning/\n\n深度学习是机器学习和人工智能的一种形式，利用堆积在彼此顶部的神经网络的多个隐藏层来尝试形成对数据更深层次的“理解”。\n\n最近，深度神经网络以“Deep Dreams”形式在网站中如雨后春笋般出现，或是像谷歌研究原创论文中描述的那样：Inceptionism。\n\n在这篇文章中，我们将讨论几个不同的深度学习框架，库以及工具。\n\n<!--more-->\n\n## Python深度学习\n\n### Theano\n\n主页：http://deeplearning.net/software/theano/\n\nGithub网址：https://github.com/Theano/Theano\n\nTheano不仅是这篇文章中将要讨论的其他框架的核心库，于其自身而言，它也是一个强大的库，几乎能在任何情况下使用，从简单的logistic回归到建模并生成音乐和弦序列或是使用长短期记忆人工神经网络对电影收视率进行分类。\n\nTheano大部分代码是使用Cython编写，Cython是一个可编译为本地可执行代码的Python方言，与仅仅使用解释性Python语言相比，它能够使运行速度快速提升。最重要的是，很多优化程序已经集成到Theano库中，它能够优化你的计算量并让你的运行时间保持最低。\n\n如果速度的提升还不能满足你，它还内置支持使用CUDA在GPU上执行那些所有耗时的计算。所有的这一切仅仅只需要修改配置文件中的标志位即可。在CPU上运行一个脚本，然后切换到GPU，而对于你的代码，则不需要做任何变化。\n\n同时我们应该注意到，尽管Theano使用Cython和CUDA对其性能大大提升，但你仍然可以仅仅使用Python语言来创建几乎任何类型的神经网络结构。\n\n### Pylearn2\n\n主页：http://deeplearning.net/software/pylearn2/\n\nGithub网址：https://github.com/lisa-lab/pylearn2\n\nPylearn2和Theano由同一个开发团队开发，Pylearn2是一个机器学习库，它把深度学习和人工智能研究许多常用的模型以及训练算法封装成一个单一的实验包，如随机梯度下降。\n\n你也可以很轻松的围绕你的类和算法编写一个封装程序，为了能让它在Pylearn2上运行，你需要在一个单独的YAML格式的配置文件中配置你整个神经网络模型的参数。\n\n除此之外，它还有很多数据集及其预编译好的软件包，所以，你现在就可以直接使用MNIST数据集开始做实验了！\n\n\n### Blocks\n\nGithub网址：https://github.com/mila-udem/blocks\n\nBlocks是一个非常模块化的框架，有助于你在Theano上建立神经网络。目前它支持并提供的功能有：\n\n构建参数化Theano运算，称之为“bricks”。\n在大型模型中使用模式匹配来选择变量以及“bricks”。\n使用算法优化模型。\n训练模型的保存和恢复。\n在训练过程中检测和分析值（训练集以及测试集）。\n图形变换的应用，如dropout。\n\n\n\n### Keras\n\n主页：http://keras.io/\n\nGithub网址：https://github.com/fchollet/keras\n\nKeras是一个简约的、高度模块化的神经网络库，设计参考了Torch，基于Theano和Python语言编写，支持GPU和CPU。它的开发侧重于实现快速试验和创造新的深度学习模型。\n\n如果你需要具有以下功能的深度学习库，采用Keras就恰到好处：\n\n可以很容易地、快速地建立原型（通过总体模块化，极简化并且可扩展化）。\n支持卷积网络和递归网络，以及两者的组合。\n支持任意连接方式（包括多输入多输出训练）。\nKeras库与其他采用Theano库的区别是Keras的编码风格非常简约、清晰。它把所有的要点使用小类封装起来，能够很容易地组合在一起并创造出一种全新的模型。\n\n\n### Lasagne\n\nGithub网址：https://github.com/Lasagne/Lasagne\n\nLasagne不只是一个美味的意大利菜，也是一个与Blocks和Keras有着相似功能的深度学习库，但其在设计上与它们有些不同。\n\n下面是Lasagne的一些设计目的：\n\n简单化：它应该是易于使用和扩展的机器学习库。每添加一个特征，就应该考虑其对易用性和扩展性的影响。每一个抽象概念的加入都应该仔细检查，以确定增加的复杂性是否合理。\n小接口：尽可能少的类和方法。尽可能依赖Theano的功能和数据类型，遵循Theano的规定。如果没有严格的必要，不要在类中封装东西。这会使它更容易使用库并且扩展它（不需要有太多的认知）。\n不碍事：未使用的功能应该是不可见的，用户不会考虑他们不使用的功能。尽可能单独的使用库文件中的组件。\n透明性：不要试图掩盖Theano，尽量以Python或NumPy数据类型的形式将函数和方法返回给Theano表达式。\n重点：遵循Unix哲学“做一件事，并把它做好”，重点集中在前馈神经网络。\n实用主义：使普通用例更易于使用，这要比支持每一个可能的用例更为重要。\n\n\n译者简介： [刘帝伟](https://csuldw.github.io)，中南大学软件学院在读研究生，关注机器学习、数据挖掘及生物信息领域。\n\n","source":"_posts/2015-08-12-theano-to-lasagne.md","raw":"---\nlayout: post\ndate: 2015-08-12 20:24\ntitle: \"从Theano到Lasagne：基于Python的深度学习的框架和库（译文）\"\ncategories: ML\ntag: \n\t- Machine Learning\n\t- 框架&库\n\t- 译文\n\t- Theano\n\t- Lasagne\ncomment: true\n---\n\n英文链接：http://creative-punch.net/2015/07/frameworks-and-libraries-for-deep-learning/\n\n深度学习是机器学习和人工智能的一种形式，利用堆积在彼此顶部的神经网络的多个隐藏层来尝试形成对数据更深层次的“理解”。\n\n最近，深度神经网络以“Deep Dreams”形式在网站中如雨后春笋般出现，或是像谷歌研究原创论文中描述的那样：Inceptionism。\n\n在这篇文章中，我们将讨论几个不同的深度学习框架，库以及工具。\n\n<!--more-->\n\n## Python深度学习\n\n### Theano\n\n主页：http://deeplearning.net/software/theano/\n\nGithub网址：https://github.com/Theano/Theano\n\nTheano不仅是这篇文章中将要讨论的其他框架的核心库，于其自身而言，它也是一个强大的库，几乎能在任何情况下使用，从简单的logistic回归到建模并生成音乐和弦序列或是使用长短期记忆人工神经网络对电影收视率进行分类。\n\nTheano大部分代码是使用Cython编写，Cython是一个可编译为本地可执行代码的Python方言，与仅仅使用解释性Python语言相比，它能够使运行速度快速提升。最重要的是，很多优化程序已经集成到Theano库中，它能够优化你的计算量并让你的运行时间保持最低。\n\n如果速度的提升还不能满足你，它还内置支持使用CUDA在GPU上执行那些所有耗时的计算。所有的这一切仅仅只需要修改配置文件中的标志位即可。在CPU上运行一个脚本，然后切换到GPU，而对于你的代码，则不需要做任何变化。\n\n同时我们应该注意到，尽管Theano使用Cython和CUDA对其性能大大提升，但你仍然可以仅仅使用Python语言来创建几乎任何类型的神经网络结构。\n\n### Pylearn2\n\n主页：http://deeplearning.net/software/pylearn2/\n\nGithub网址：https://github.com/lisa-lab/pylearn2\n\nPylearn2和Theano由同一个开发团队开发，Pylearn2是一个机器学习库，它把深度学习和人工智能研究许多常用的模型以及训练算法封装成一个单一的实验包，如随机梯度下降。\n\n你也可以很轻松的围绕你的类和算法编写一个封装程序，为了能让它在Pylearn2上运行，你需要在一个单独的YAML格式的配置文件中配置你整个神经网络模型的参数。\n\n除此之外，它还有很多数据集及其预编译好的软件包，所以，你现在就可以直接使用MNIST数据集开始做实验了！\n\n\n### Blocks\n\nGithub网址：https://github.com/mila-udem/blocks\n\nBlocks是一个非常模块化的框架，有助于你在Theano上建立神经网络。目前它支持并提供的功能有：\n\n构建参数化Theano运算，称之为“bricks”。\n在大型模型中使用模式匹配来选择变量以及“bricks”。\n使用算法优化模型。\n训练模型的保存和恢复。\n在训练过程中检测和分析值（训练集以及测试集）。\n图形变换的应用，如dropout。\n\n\n\n### Keras\n\n主页：http://keras.io/\n\nGithub网址：https://github.com/fchollet/keras\n\nKeras是一个简约的、高度模块化的神经网络库，设计参考了Torch，基于Theano和Python语言编写，支持GPU和CPU。它的开发侧重于实现快速试验和创造新的深度学习模型。\n\n如果你需要具有以下功能的深度学习库，采用Keras就恰到好处：\n\n可以很容易地、快速地建立原型（通过总体模块化，极简化并且可扩展化）。\n支持卷积网络和递归网络，以及两者的组合。\n支持任意连接方式（包括多输入多输出训练）。\nKeras库与其他采用Theano库的区别是Keras的编码风格非常简约、清晰。它把所有的要点使用小类封装起来，能够很容易地组合在一起并创造出一种全新的模型。\n\n\n### Lasagne\n\nGithub网址：https://github.com/Lasagne/Lasagne\n\nLasagne不只是一个美味的意大利菜，也是一个与Blocks和Keras有着相似功能的深度学习库，但其在设计上与它们有些不同。\n\n下面是Lasagne的一些设计目的：\n\n简单化：它应该是易于使用和扩展的机器学习库。每添加一个特征，就应该考虑其对易用性和扩展性的影响。每一个抽象概念的加入都应该仔细检查，以确定增加的复杂性是否合理。\n小接口：尽可能少的类和方法。尽可能依赖Theano的功能和数据类型，遵循Theano的规定。如果没有严格的必要，不要在类中封装东西。这会使它更容易使用库并且扩展它（不需要有太多的认知）。\n不碍事：未使用的功能应该是不可见的，用户不会考虑他们不使用的功能。尽可能单独的使用库文件中的组件。\n透明性：不要试图掩盖Theano，尽量以Python或NumPy数据类型的形式将函数和方法返回给Theano表达式。\n重点：遵循Unix哲学“做一件事，并把它做好”，重点集中在前馈神经网络。\n实用主义：使普通用例更易于使用，这要比支持每一个可能的用例更为重要。\n\n\n译者简介： [刘帝伟](https://csuldw.github.io)，中南大学软件学院在读研究生，关注机器学习、数据挖掘及生物信息领域。\n\n","slug":"2015-08-12-theano-to-lasagne","published":1,"updated":"2016-03-13T10:22:05.428Z","comments":1,"photos":[],"link":"","_id":"cimigpyyt00776cujo0do57cd"},{"layout":"post","date":"2015-07-28T07:40:00.000Z","title":"机器学习-Cross Validation交叉验证Python实现","_content":"\n## __1.原理__\n\n### **1.1 概念**\n\n交叉验证(Cross-validation)主要用于模型训练或建模应用中，如分类预测、PCR、PLS回归建模等。在给定的样本空间中，拿出大部分样本作为训练集来训练模型，剩余的小部分样本使用刚建立的模型进行预测，并求这小部分样本的预测误差或者预测精度，同时记录它们的加和平均值。这个过程迭代K次，即K折交叉。其中，把每个样本的预测误差平方加和，称为PRESS(predicted Error Sum of Squares)。\n<!-- more -->\n\n### **1.2 目的**\n\n用交叉验证的目的是为了得到可靠稳定的模型。在分类，建立PC 或PLS模型时，一个很重要的因素是取多少个主成分的问题。用cross validation校验每个主成分下的PRESS值，选择PRESS值小的主成分数。或PRESS值不再变小时的主成分数。\n\n常用的精度测试方法主要是交叉验证，例如10折交叉验证(10-fold cross validation)，将数据集分成十份，轮流将其中9份做训练1份做验证，10次的结果的均值作为对算法精度的估计，一般还需要进行多次10折交叉验证求均值，例如：10次10折交叉验证，以求更精确一点。\n交叉验证有时也称为交叉比对，如：10折交叉比对\n\n### **1.3 常见的交叉验证形式**：\n\n__Holdout 验证__\n\n>方法：将原始数据随机分为两组,一组做为训练集,一组做为验证集,利用训练集训练分类器,然后利用验证集验证模型,记录最后的分类准确率为此Hold-OutMethod下分类器的性能指标.。Hold-OutMethod相对于K-fold Cross Validation 又称Double cross-validation ，或相对K-CV称 2-fold cross-validation(2-CV)\n\n>一般来说，Holdout 验证并非一种交叉验证，因为数据并没有交叉使用。 随机从最初的样本中选出部分，形成交叉验证数据，而剩余的就当做训练数据。 一般来说，少于原本样本三分之一的数据被选做验证数据。\n\n- 优点：好处的处理简单,只需随机把原始数据分为两组即可\n- 缺点：严格意义来说Hold-Out Method并不能算是CV,因为这种方法没有达到交叉的思想,由于是随机的将原始数据分组,所以最后验证集分类准确率的高低与原始数据的分组有很大的关系,所以这种方法得到的结果其实并不具有说服性.(主要原因是 训练集样本数太少，通常不足以代表母体样本的分布，导致 test 阶段辨识率容易出现明显落差。此外，2-CV 中一分为二的分子集方法的变异度大，往往无法达到「实验过程必须可以被复制」的要求。)\n\n__K-fold cross-validation__\n\n>K折交叉验证，初始采样分割成K个子样本，一个单独的子样本被保留作为验证模型的数据，其他K-1个样本用来训练。交叉验证重复K次，每个子样本验证一次，平均K次的结果或者使用其它结合方式，最终得到一个单一估测。这个方法的优势在于，同时重复运用随机产生的子样本进行训练和验证，每次的结果验证一次，10折交叉验证是最常用的。\n\n- 优点：K-CV可以有效的避免过学习以及欠学习状态的发生,最后得到的结果也比较具有说服性.  \n- 缺点：K值选取上\n\n__留一验证__\n\n>正如名称所建议， 留一验证（LOOCV）意指只使用原本样本中的一项来当做验证资料， 而剩余的则留下来当做训练资料。 这个步骤一直持续到每个样本都被当做一次验证资料。 事实上，这等同于 K-fold 交叉验证是一样的，其中K为原本样本个数。 在某些情况下是存在有效率的演算法，如使用kernel regression 和Tikhonov regularization。\n \n## __2.深入__\n\n使用交叉验证方法的目的主要有3个： \n\n- （1）从有限的学习数据中获取尽可能多的有效信息； \n- （2）交叉验证从多个方向开始学习样本的，可以有效的避免陷入局部最小值； \n- （3）可以在一定程度上避免过拟合问题。\n\n采用交叉验证方法时需要将学习数据样本分为两部分：训练数据样本和验证数据样本。并且为了得到更好的学习效果，无论训练样本还是验证样本都要尽可能参与学习。一般选取10重交叉验证即可达到好的学习效果。下面在上述原则基础上设计算法，主要描述下算法步骤，如下所示。\n\n\nAlgorithm  \n------------------------------------------------\n```\nStep1: \t将学习样本空间 C 分为大小相等的 K 份  \nStep2: \tfor i = 1 to K ：\n\t\t\t取第i份作为测试集\n\t\t\tfor j = 1 to K:\n\t\t\t\tif i != j:\n\t\t\t\t\t将第j份加到训练集中，作为训练集的一部分\n\t\t\t\tend if\n\t\t\tend for\n\t\tend for\nStep3: \tfor i in (K-1训练集)：\n\t\t\t训练第i个训练集，得到一个分类模型\n\t\t\t使用该模型在第N个数据集上测试，计算并保存模型评估指标\n\t\tend for\nStep4: \t计算模型的平均性能\nStep5: \t用这K个模型在最终验证集的分类准确率平均值作为此K-CV下分类器的性能指标.\n```\n\n## __3.实现__\n\n### __3.1 scikit-learn交叉验证__\n\n在scikit-learn中有CrossValidation的实现代码，地址： [scikit-learn官网crossvalidation文档](http://scikit-learn.org/dev/modules/cross_validation.html#cross-validation)\n\n使用方法：\n\n首先加载数据集\n\n```\n>>> import numpy as np\n>>> from sklearn import cross_validation\n>>> from sklearn import datasets\n>>> from sklearn import svm\n>>> iris = datasets.load_iris()\n>>> iris.data.shape, iris.target.shape\n((150, 4), (150,))\n```\n\n通过上面代码，数据集特征和类标签分别为iris.data, iris.target，接着进行交叉验证\n\n```\n>>> X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n...     iris.data, iris.target, test_size=0.4, random_state=0)\n>>> X_train.shape, y_train.shape\n((90, 4), (90,))\n>>> X_test.shape, y_test.shape\n((60, 4), (60,))\n>>> clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n>>> clf.score(X_test, y_test)                           \n0.96...\n```\n\n上面的clf是分类器，可以自己替换，比如我可以使用RandomForest\n\n```\nclf = RandomForestClassifier(n_estimators=400)\n```\n\n一个比较有用的函数是train_test_split。功能是从样本中随机的按比例选取train data和test data。形式为\n\n```\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(train_data,train_target, test_size=0.4, random_state=0)\n```\ntest_size是样本占比。如果是整数的话就是样本的数量。random_state是随机数的种子。\n\n当然，也可以换成别的，具体算法可以参考 [scikit-learn官方文档](http://scikit-learn.org/dev/supervised_learning.html#supervised-learning)\n\n-------------------------\n\n### __3.2 抽样与CV结合__\n\n> 由于我跑的实验，数据是非均衡数据，不能直接套用，所以这里自己写了一个交叉验证的代码，仅供参考，如有问题，欢迎交流。\n\n首先有一个自适应的数据加载函数，主要用于加载本地文本数据，同时文本每行数据以\"\\t\"隔开，最后一列为类标号，数据样例如下：\n\n```\nA1001\t708\tK\t-4\t-3\t6\t2\t-13\t0\t2\t-4\t-4\t-10\t-9\t1\nA1002\t709\tL\t-4\t-4\t-1\t-2\t-11\t-1\t0\t-12\t-7\t-5\t-1\t-1\nA1003\t710\tG\t0\t-6\t-2\t-6\t-8\t-4\t-6\t-6\t-9\t-4\t0\t-1\nA1004\t711\tR\t0\t0\t1\t-3\t-10\t-1\t-3\t-4\t-6\t-9\t-6\t1\n```\n\n**说明**：前面三个不是特征，所以在加载数据集的时候，特征部分起始位置修改了下，loadDataSet函数如下：\n\n```\ndef loadDataSet(fileName):\n    fr = open(fileName)\n    dataMat = []; labelMat = []\n    for eachline in fr:\n        lineArr = []\n        curLine = eachline.strip().split('\\t') #remove '\\n'\n        for i in range(3, len(curLine)-1):\n            lineArr.append(float(curLine[i])) #get all feature from inpurfile\n        dataMat.append(lineArr)\n        labelMat.append(int(curLine[-1])) #last one is class lable\n    fr.close()\n    return dataMat,labelMat\n```\n\n返回的dataMat为纯特征矩阵，labelMat为类别标号。\n\n下面的**splitDataSet**用来切分数据集，如果是十折交叉，则split_size取10，filename为整个数据集文件，outdir则是切分的数据集的存放路径。\n\n```\ndef splitDataSet(fileName, split_size,outdir):\n    if not os.path.exists(outdir): #if not outdir,makrdir\n        os.makedirs(outdir)\n    fr = open(fileName,'r')#open fileName to read\n    num_line = 0\n    onefile = fr.readlines()\n    num_line = len(onefile)        \n    arr = np.arange(num_line) #get a seq and set len=numLine\n    np.random.shuffle(arr) #generate a random seq from arr\n    list_all = arr.tolist()\n    each_size = (num_line+1) / split_size #size of each split sets\n    split_all = []; each_split = []\n    count_num = 0; count_split = 0  #count_num 统计每次遍历的当前个数\n                                    #count_split 统计切分次数\n    for i in range(len(list_all)): #遍历整个数字序列\n        each_split.append(onefile[int(list_all[i])].strip()) \n        count_num += 1\n        if count_num == each_size:\n            count_split += 1 \n            array_ = np.array(each_split)\n            np.savetxt(outdir + \"/split_\" + str(count_split) + '.txt',\\\n                        array_,fmt=\"%s\", delimiter='\\t')  #输出每一份数据\n            split_all.append(each_split) #将每一份数据加入到一个list中\n            each_split = []\n            count_num = 0\n    return split_all\n```\n\nunderSample(datafile)方法为抽样函数，强正负样本比例固定为1:1，返回的是一个正负样本比例均等的数据集合。\n\n```\ndef underSample(datafile): #只针对一个数据集的下采样\n    dataMat,labelMat = loadDataSet(datafile) #加载数据\n    pos_num = 0; pos_indexs = []; neg_indexs = []   \n    for i in range(len(labelMat)):#统计正负样本的下标    \n        if labelMat[i] == 1:\n            pos_num +=1\n            pos_indexs.append(i)\n            continue\n        neg_indexs.append(i)\n    np.random.shuffle(neg_indexs)\n    neg_indexs = neg_indexs[0:pos_num]\n    fr = open(datafile, 'r')\n    onefile = fr.readlines()\n    outfile = []\n    for i in range(pos_num):\n        pos_line = onefile[pos_indexs[i]]    \n        outfile.append(pos_line)\n        neg_line= onefile[neg_indexs[i]]      \n        outfile.append(neg_line)\n    return outfile #输出单个数据集采样结果\n```\n\n下面的generateDataset(datadir,outdir)方法是从切分的数据集中留出一份作为测试集（无需抽样），对其余的进行抽样然后合并为一个作为训练集，代码如下：\n\n```\ndef generateDataset(datadir,outdir): #从切分的数据集中，对其中九份抽样汇成一个,\\\n    #剩余一个做为测试集,将最后的结果按照训练集和测试集输出到outdir中\n    if not os.path.exists(outdir): #if not outdir,makrdir\n        os.makedirs(outdir)\n    listfile = os.listdir(datadir)\n    train_all = []; test_all = [];cross_now = 0\n    for eachfile1 in listfile:\n        train_sets = []; test_sets = []; \n        cross_now += 1 #记录当前的交叉次数\n        for eachfile2 in listfile:\n            if eachfile2 != eachfile1:#对其余九份欠抽样构成训练集\n                one_sample = underSample(datadir + '/' + eachfile2)\n                for i in range(len(one_sample)):\n                    train_sets.append(one_sample[i])\n        #将训练集和测试集文件单独保存起来\n        with open(outdir +\"/test_\"+str(cross_now)+\".datasets\",'w') as fw_test:\n            with open(datadir + '/' + eachfile1, 'r') as fr_testsets:\n                for each_testline in fr_testsets:                \n                    test_sets.append(each_testline) \n            for oneline_test in test_sets:\n                fw_test.write(oneline_test) #输出测试集\n            test_all.append(test_sets)#保存训练集\n        with open(outdir+\"/train_\"+str(cross_now)+\".datasets\",'w') as fw_train:\n            for oneline_train in train_sets:   \n                oneline_train = oneline_train\n                fw_train.write(oneline_train)#输出训练集\n            train_all.append(train_sets)#保存训练集\n    return train_all,test_all\n```\n\n因为需要评估交叉验证，所以我写了一个performance方法根据真实类标签纸和预测值来计算SN和SP，当然如果需要其他的评估标准，继续添加即可。\n\n```\ndef performance(labelArr, predictArr):#类标签为int类型\n    #labelArr[i] is actual value,predictArr[i] is predict value\n    TP = 0.; TN = 0.; FP = 0.; FN = 0.   \n    for i in range(len(labelArr)):\n        if labelArr[i] == 1 and predictArr[i] == 1:\n            TP += 1.\n        if labelArr[i] == 1 and predictArr[i] == -1:\n            FN += 1.\n        if labelArr[i] == -1 and predictArr[i] == 1:\n            FP += 1.\n        if labelArr[i] == -1 and predictArr[i] == -1:\n            TN += 1.\n    SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN \n    SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n    return SN,SP\n```\n\n classifier(clf,train_X, train_y, test_X, test_y)方法是交叉验证中每次用的分类器训练过程以及测试过程，里面使用的分类器是scikit-learn自带的。该方法会将一些训练结果写入到文件中并保存到本地，同时在最后会返回ACC,SP,SN。\n\n```\ndef classifier(clf,train_X, train_y, test_X, test_y):#X:训练特征，y:训练标号\n    # train with randomForest \n    print \" training begin...\"\n    clf = clf.fit(train_X,train_y)\n    print \" training end.\"\n    #==========================================================================\n    # test randomForestClassifier with testsets\n    print \" test begin.\"\n    predict_ = clf.predict(test_X) #return type is float64\n    proba = clf.predict_proba(test_X) #return type is float64\n    score_ = clf.score(test_X,test_y)\n    print \" test end.\"\n    #==========================================================================\n    # Modeal Evaluation\n    ACC = accuracy_score(test_y, predict_)\n    SN,SP = performance(test_y, predict_)\n    MCC = matthews_corrcoef(test_y, predict_)\n    #AUC = roc_auc_score(test_labelMat, proba)\n    #==========================================================================\n    #save output \n    eval_output = []\n    eval_output.append(ACC);eval_output.append(SN)  #eval_output.append(AUC)\n    eval_output.append(SP);eval_output.append(MCC)\n    eval_output.append(score_)\n    eval_output = np.array(eval_output,dtype=float)\n    np.savetxt(\"proba.data\",proba,fmt=\"%f\",delimiter=\"\\t\")\n    np.savetxt(\"test_y.data\",test_y,fmt=\"%f\",delimiter=\"\\t\")\n    np.savetxt(\"predict.data\",predict_,fmt=\"%f\",delimiter=\"\\t\") \n    np.savetxt(\"eval_output.data\",eval_output,fmt=\"%f\",delimiter=\"\\t\")\n    print \"Wrote results to output.data...EOF...\"\n    return ACC,SN,SP\n```\n\n下面的mean_fun用于求列表list中数值的平均值，主要是求ACC_mean,SP_mean,SN_mean，用来评估模型好坏。\n\n```\ndef mean_fun(onelist):\n    count = 0\n    for i in onelist:\n        count += i\n    return float(count/len(onelist))\n```\n\n交叉验证代码\n\n```\ndef crossValidation(clf, clfname, curdir,train_all, test_all):\n    os.chdir(curdir)\n    #构造出纯数据型样本集\n    cur_path = curdir\n    ACCs = [];SNs = []; SPs =[]\n    for i in range(len(train_all)):\n        os.chdir(cur_path)\n        train_data = train_all[i];train_X = [];train_y = []\n        test_data = test_all[i];test_X = [];test_y = []\n        for eachline_train in train_data:\n            one_train = eachline_train.split('\\t') \n            one_train_format = []\n            for index in range(3,len(one_train)-1):\n                one_train_format.append(float(one_train[index]))\n            train_X.append(one_train_format)\n            train_y.append(int(one_train[-1].strip()))\n        for eachline_test in test_data:\n            one_test = eachline_test.split('\\t')\n            one_test_format = []\n            for index in range(3,len(one_test)-1):\n                one_test_format.append(float(one_test[index]))\n            test_X.append(one_test_format)\n            test_y.append(int(one_test[-1].strip()))\n        #======================================================================\n        #classifier start here\n        if not os.path.exists(clfname):#使用的分类器\n            os.mkdir(clfname)\n        out_path = clfname + \"/\" + clfname + \"_00\" + str(i)#计算结果文件夹\n        if not os.path.exists(out_path):\n            os.mkdir(out_path)\n        os.chdir(out_path)\n        ACC, SN, SP = classifier(clf, train_X, train_y, test_X, test_y)\n        ACCs.append(ACC);SNs.append(SN);SPs.append(SP)\n        #======================================================================\n    ACC_mean = mean_fun(ACCs)\n    SN_mean = mean_fun(SNs)\n    SP_mean = mean_fun(SPs)\n    #==========================================================================\n    #output experiment result\n    os.chdir(\"../\")\n    os.system(\"echo `date` '\" + str(clf) + \"' >> log.out\")\n    os.system(\"echo ACC_mean=\" + str(ACC_mean) + \" >> log.out\")\n    os.system(\"echo SN_mean=\" + str(SN_mean) + \" >> log.out\")\n    os.system(\"echo SP_mean=\" + str(SP_mean) + \" >> log.out\")\n    return ACC_mean, SN_mean, SP_mean\n```\n\n**测试：**\n\n```python\nif __name__ == '__main__':\n\tos.chdir(\"your workhome\") #你的数据存放目录\n    datadir = \"split10_1\" #切分后的文件输出目录\n    splitDataSet('datasets',10,datadir)#将数据集datasets切为十个保存到datadir目录中\n\t#==========================================================================\n    outdir = \"sample_data1\"\t#抽样的数据集存放目录\n    train_all,test_all = generateDataset(datadir,outdir) #抽样后返回训练集和测试集\n    print \"generateDataset end and cross validation start\"\n    #==========================================================================\n    #分类器部分\n    from sklearn.ensemble import RandomForestClassifier\n    clf = RandomForestClassifier(n_estimators=500) #使用随机森林分类器来训练\n    clfname = \"RF_1\"\n    #==========================================================================\n    curdir = \"experimentdir\" #工作目录\n\t#clf:分类器,clfname:分类器名称,curdir:当前路径,train_all:训练集,test_all:测试集\n    ACC_mean, SN_mean, SP_mean = crossValidation(clf, clfname, curdir, train_all,test_all)\n    print ACC_mean,SN_mean,SP_mean\t#将ACC均值，SP均值，SN均值都输出到控制台\n```\n\n上面的代码主要用于抽样后的十倍交叉验证，该怎么设置参数，还得具体分析。\n\n总之，交叉验证在一定程度上能够避免陷入局部最小值。一般实际操作中使用的是十折交叉验证，单具体情况还得具体分析，并没有一个统一的标准固定十倍交叉的参数或者是算法的选择以及算法参数的选择。不同的数据使用不同的算法往往会的得到不同的最优分类器。So,just try it!Happy coding!\n\n------\n<br>\n","source":"_posts/2015-07-28 crossvalidation.md","raw":"---\nlayout: post\ndate: 2015-07-28 15:40\ntitle: \"机器学习-Cross Validation交叉验证Python实现\"\ntags: \n\t- Machine Learning\n\t- 交叉验证\n\t- Cross-Validation\ncategories: ML\n---\n\n## __1.原理__\n\n### **1.1 概念**\n\n交叉验证(Cross-validation)主要用于模型训练或建模应用中，如分类预测、PCR、PLS回归建模等。在给定的样本空间中，拿出大部分样本作为训练集来训练模型，剩余的小部分样本使用刚建立的模型进行预测，并求这小部分样本的预测误差或者预测精度，同时记录它们的加和平均值。这个过程迭代K次，即K折交叉。其中，把每个样本的预测误差平方加和，称为PRESS(predicted Error Sum of Squares)。\n<!-- more -->\n\n### **1.2 目的**\n\n用交叉验证的目的是为了得到可靠稳定的模型。在分类，建立PC 或PLS模型时，一个很重要的因素是取多少个主成分的问题。用cross validation校验每个主成分下的PRESS值，选择PRESS值小的主成分数。或PRESS值不再变小时的主成分数。\n\n常用的精度测试方法主要是交叉验证，例如10折交叉验证(10-fold cross validation)，将数据集分成十份，轮流将其中9份做训练1份做验证，10次的结果的均值作为对算法精度的估计，一般还需要进行多次10折交叉验证求均值，例如：10次10折交叉验证，以求更精确一点。\n交叉验证有时也称为交叉比对，如：10折交叉比对\n\n### **1.3 常见的交叉验证形式**：\n\n__Holdout 验证__\n\n>方法：将原始数据随机分为两组,一组做为训练集,一组做为验证集,利用训练集训练分类器,然后利用验证集验证模型,记录最后的分类准确率为此Hold-OutMethod下分类器的性能指标.。Hold-OutMethod相对于K-fold Cross Validation 又称Double cross-validation ，或相对K-CV称 2-fold cross-validation(2-CV)\n\n>一般来说，Holdout 验证并非一种交叉验证，因为数据并没有交叉使用。 随机从最初的样本中选出部分，形成交叉验证数据，而剩余的就当做训练数据。 一般来说，少于原本样本三分之一的数据被选做验证数据。\n\n- 优点：好处的处理简单,只需随机把原始数据分为两组即可\n- 缺点：严格意义来说Hold-Out Method并不能算是CV,因为这种方法没有达到交叉的思想,由于是随机的将原始数据分组,所以最后验证集分类准确率的高低与原始数据的分组有很大的关系,所以这种方法得到的结果其实并不具有说服性.(主要原因是 训练集样本数太少，通常不足以代表母体样本的分布，导致 test 阶段辨识率容易出现明显落差。此外，2-CV 中一分为二的分子集方法的变异度大，往往无法达到「实验过程必须可以被复制」的要求。)\n\n__K-fold cross-validation__\n\n>K折交叉验证，初始采样分割成K个子样本，一个单独的子样本被保留作为验证模型的数据，其他K-1个样本用来训练。交叉验证重复K次，每个子样本验证一次，平均K次的结果或者使用其它结合方式，最终得到一个单一估测。这个方法的优势在于，同时重复运用随机产生的子样本进行训练和验证，每次的结果验证一次，10折交叉验证是最常用的。\n\n- 优点：K-CV可以有效的避免过学习以及欠学习状态的发生,最后得到的结果也比较具有说服性.  \n- 缺点：K值选取上\n\n__留一验证__\n\n>正如名称所建议， 留一验证（LOOCV）意指只使用原本样本中的一项来当做验证资料， 而剩余的则留下来当做训练资料。 这个步骤一直持续到每个样本都被当做一次验证资料。 事实上，这等同于 K-fold 交叉验证是一样的，其中K为原本样本个数。 在某些情况下是存在有效率的演算法，如使用kernel regression 和Tikhonov regularization。\n \n## __2.深入__\n\n使用交叉验证方法的目的主要有3个： \n\n- （1）从有限的学习数据中获取尽可能多的有效信息； \n- （2）交叉验证从多个方向开始学习样本的，可以有效的避免陷入局部最小值； \n- （3）可以在一定程度上避免过拟合问题。\n\n采用交叉验证方法时需要将学习数据样本分为两部分：训练数据样本和验证数据样本。并且为了得到更好的学习效果，无论训练样本还是验证样本都要尽可能参与学习。一般选取10重交叉验证即可达到好的学习效果。下面在上述原则基础上设计算法，主要描述下算法步骤，如下所示。\n\n\nAlgorithm  \n------------------------------------------------\n```\nStep1: \t将学习样本空间 C 分为大小相等的 K 份  \nStep2: \tfor i = 1 to K ：\n\t\t\t取第i份作为测试集\n\t\t\tfor j = 1 to K:\n\t\t\t\tif i != j:\n\t\t\t\t\t将第j份加到训练集中，作为训练集的一部分\n\t\t\t\tend if\n\t\t\tend for\n\t\tend for\nStep3: \tfor i in (K-1训练集)：\n\t\t\t训练第i个训练集，得到一个分类模型\n\t\t\t使用该模型在第N个数据集上测试，计算并保存模型评估指标\n\t\tend for\nStep4: \t计算模型的平均性能\nStep5: \t用这K个模型在最终验证集的分类准确率平均值作为此K-CV下分类器的性能指标.\n```\n\n## __3.实现__\n\n### __3.1 scikit-learn交叉验证__\n\n在scikit-learn中有CrossValidation的实现代码，地址： [scikit-learn官网crossvalidation文档](http://scikit-learn.org/dev/modules/cross_validation.html#cross-validation)\n\n使用方法：\n\n首先加载数据集\n\n```\n>>> import numpy as np\n>>> from sklearn import cross_validation\n>>> from sklearn import datasets\n>>> from sklearn import svm\n>>> iris = datasets.load_iris()\n>>> iris.data.shape, iris.target.shape\n((150, 4), (150,))\n```\n\n通过上面代码，数据集特征和类标签分别为iris.data, iris.target，接着进行交叉验证\n\n```\n>>> X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n...     iris.data, iris.target, test_size=0.4, random_state=0)\n>>> X_train.shape, y_train.shape\n((90, 4), (90,))\n>>> X_test.shape, y_test.shape\n((60, 4), (60,))\n>>> clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n>>> clf.score(X_test, y_test)                           \n0.96...\n```\n\n上面的clf是分类器，可以自己替换，比如我可以使用RandomForest\n\n```\nclf = RandomForestClassifier(n_estimators=400)\n```\n\n一个比较有用的函数是train_test_split。功能是从样本中随机的按比例选取train data和test data。形式为\n\n```\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(train_data,train_target, test_size=0.4, random_state=0)\n```\ntest_size是样本占比。如果是整数的话就是样本的数量。random_state是随机数的种子。\n\n当然，也可以换成别的，具体算法可以参考 [scikit-learn官方文档](http://scikit-learn.org/dev/supervised_learning.html#supervised-learning)\n\n-------------------------\n\n### __3.2 抽样与CV结合__\n\n> 由于我跑的实验，数据是非均衡数据，不能直接套用，所以这里自己写了一个交叉验证的代码，仅供参考，如有问题，欢迎交流。\n\n首先有一个自适应的数据加载函数，主要用于加载本地文本数据，同时文本每行数据以\"\\t\"隔开，最后一列为类标号，数据样例如下：\n\n```\nA1001\t708\tK\t-4\t-3\t6\t2\t-13\t0\t2\t-4\t-4\t-10\t-9\t1\nA1002\t709\tL\t-4\t-4\t-1\t-2\t-11\t-1\t0\t-12\t-7\t-5\t-1\t-1\nA1003\t710\tG\t0\t-6\t-2\t-6\t-8\t-4\t-6\t-6\t-9\t-4\t0\t-1\nA1004\t711\tR\t0\t0\t1\t-3\t-10\t-1\t-3\t-4\t-6\t-9\t-6\t1\n```\n\n**说明**：前面三个不是特征，所以在加载数据集的时候，特征部分起始位置修改了下，loadDataSet函数如下：\n\n```\ndef loadDataSet(fileName):\n    fr = open(fileName)\n    dataMat = []; labelMat = []\n    for eachline in fr:\n        lineArr = []\n        curLine = eachline.strip().split('\\t') #remove '\\n'\n        for i in range(3, len(curLine)-1):\n            lineArr.append(float(curLine[i])) #get all feature from inpurfile\n        dataMat.append(lineArr)\n        labelMat.append(int(curLine[-1])) #last one is class lable\n    fr.close()\n    return dataMat,labelMat\n```\n\n返回的dataMat为纯特征矩阵，labelMat为类别标号。\n\n下面的**splitDataSet**用来切分数据集，如果是十折交叉，则split_size取10，filename为整个数据集文件，outdir则是切分的数据集的存放路径。\n\n```\ndef splitDataSet(fileName, split_size,outdir):\n    if not os.path.exists(outdir): #if not outdir,makrdir\n        os.makedirs(outdir)\n    fr = open(fileName,'r')#open fileName to read\n    num_line = 0\n    onefile = fr.readlines()\n    num_line = len(onefile)        \n    arr = np.arange(num_line) #get a seq and set len=numLine\n    np.random.shuffle(arr) #generate a random seq from arr\n    list_all = arr.tolist()\n    each_size = (num_line+1) / split_size #size of each split sets\n    split_all = []; each_split = []\n    count_num = 0; count_split = 0  #count_num 统计每次遍历的当前个数\n                                    #count_split 统计切分次数\n    for i in range(len(list_all)): #遍历整个数字序列\n        each_split.append(onefile[int(list_all[i])].strip()) \n        count_num += 1\n        if count_num == each_size:\n            count_split += 1 \n            array_ = np.array(each_split)\n            np.savetxt(outdir + \"/split_\" + str(count_split) + '.txt',\\\n                        array_,fmt=\"%s\", delimiter='\\t')  #输出每一份数据\n            split_all.append(each_split) #将每一份数据加入到一个list中\n            each_split = []\n            count_num = 0\n    return split_all\n```\n\nunderSample(datafile)方法为抽样函数，强正负样本比例固定为1:1，返回的是一个正负样本比例均等的数据集合。\n\n```\ndef underSample(datafile): #只针对一个数据集的下采样\n    dataMat,labelMat = loadDataSet(datafile) #加载数据\n    pos_num = 0; pos_indexs = []; neg_indexs = []   \n    for i in range(len(labelMat)):#统计正负样本的下标    \n        if labelMat[i] == 1:\n            pos_num +=1\n            pos_indexs.append(i)\n            continue\n        neg_indexs.append(i)\n    np.random.shuffle(neg_indexs)\n    neg_indexs = neg_indexs[0:pos_num]\n    fr = open(datafile, 'r')\n    onefile = fr.readlines()\n    outfile = []\n    for i in range(pos_num):\n        pos_line = onefile[pos_indexs[i]]    \n        outfile.append(pos_line)\n        neg_line= onefile[neg_indexs[i]]      \n        outfile.append(neg_line)\n    return outfile #输出单个数据集采样结果\n```\n\n下面的generateDataset(datadir,outdir)方法是从切分的数据集中留出一份作为测试集（无需抽样），对其余的进行抽样然后合并为一个作为训练集，代码如下：\n\n```\ndef generateDataset(datadir,outdir): #从切分的数据集中，对其中九份抽样汇成一个,\\\n    #剩余一个做为测试集,将最后的结果按照训练集和测试集输出到outdir中\n    if not os.path.exists(outdir): #if not outdir,makrdir\n        os.makedirs(outdir)\n    listfile = os.listdir(datadir)\n    train_all = []; test_all = [];cross_now = 0\n    for eachfile1 in listfile:\n        train_sets = []; test_sets = []; \n        cross_now += 1 #记录当前的交叉次数\n        for eachfile2 in listfile:\n            if eachfile2 != eachfile1:#对其余九份欠抽样构成训练集\n                one_sample = underSample(datadir + '/' + eachfile2)\n                for i in range(len(one_sample)):\n                    train_sets.append(one_sample[i])\n        #将训练集和测试集文件单独保存起来\n        with open(outdir +\"/test_\"+str(cross_now)+\".datasets\",'w') as fw_test:\n            with open(datadir + '/' + eachfile1, 'r') as fr_testsets:\n                for each_testline in fr_testsets:                \n                    test_sets.append(each_testline) \n            for oneline_test in test_sets:\n                fw_test.write(oneline_test) #输出测试集\n            test_all.append(test_sets)#保存训练集\n        with open(outdir+\"/train_\"+str(cross_now)+\".datasets\",'w') as fw_train:\n            for oneline_train in train_sets:   \n                oneline_train = oneline_train\n                fw_train.write(oneline_train)#输出训练集\n            train_all.append(train_sets)#保存训练集\n    return train_all,test_all\n```\n\n因为需要评估交叉验证，所以我写了一个performance方法根据真实类标签纸和预测值来计算SN和SP，当然如果需要其他的评估标准，继续添加即可。\n\n```\ndef performance(labelArr, predictArr):#类标签为int类型\n    #labelArr[i] is actual value,predictArr[i] is predict value\n    TP = 0.; TN = 0.; FP = 0.; FN = 0.   \n    for i in range(len(labelArr)):\n        if labelArr[i] == 1 and predictArr[i] == 1:\n            TP += 1.\n        if labelArr[i] == 1 and predictArr[i] == -1:\n            FN += 1.\n        if labelArr[i] == -1 and predictArr[i] == 1:\n            FP += 1.\n        if labelArr[i] == -1 and predictArr[i] == -1:\n            TN += 1.\n    SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN \n    SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n    return SN,SP\n```\n\n classifier(clf,train_X, train_y, test_X, test_y)方法是交叉验证中每次用的分类器训练过程以及测试过程，里面使用的分类器是scikit-learn自带的。该方法会将一些训练结果写入到文件中并保存到本地，同时在最后会返回ACC,SP,SN。\n\n```\ndef classifier(clf,train_X, train_y, test_X, test_y):#X:训练特征，y:训练标号\n    # train with randomForest \n    print \" training begin...\"\n    clf = clf.fit(train_X,train_y)\n    print \" training end.\"\n    #==========================================================================\n    # test randomForestClassifier with testsets\n    print \" test begin.\"\n    predict_ = clf.predict(test_X) #return type is float64\n    proba = clf.predict_proba(test_X) #return type is float64\n    score_ = clf.score(test_X,test_y)\n    print \" test end.\"\n    #==========================================================================\n    # Modeal Evaluation\n    ACC = accuracy_score(test_y, predict_)\n    SN,SP = performance(test_y, predict_)\n    MCC = matthews_corrcoef(test_y, predict_)\n    #AUC = roc_auc_score(test_labelMat, proba)\n    #==========================================================================\n    #save output \n    eval_output = []\n    eval_output.append(ACC);eval_output.append(SN)  #eval_output.append(AUC)\n    eval_output.append(SP);eval_output.append(MCC)\n    eval_output.append(score_)\n    eval_output = np.array(eval_output,dtype=float)\n    np.savetxt(\"proba.data\",proba,fmt=\"%f\",delimiter=\"\\t\")\n    np.savetxt(\"test_y.data\",test_y,fmt=\"%f\",delimiter=\"\\t\")\n    np.savetxt(\"predict.data\",predict_,fmt=\"%f\",delimiter=\"\\t\") \n    np.savetxt(\"eval_output.data\",eval_output,fmt=\"%f\",delimiter=\"\\t\")\n    print \"Wrote results to output.data...EOF...\"\n    return ACC,SN,SP\n```\n\n下面的mean_fun用于求列表list中数值的平均值，主要是求ACC_mean,SP_mean,SN_mean，用来评估模型好坏。\n\n```\ndef mean_fun(onelist):\n    count = 0\n    for i in onelist:\n        count += i\n    return float(count/len(onelist))\n```\n\n交叉验证代码\n\n```\ndef crossValidation(clf, clfname, curdir,train_all, test_all):\n    os.chdir(curdir)\n    #构造出纯数据型样本集\n    cur_path = curdir\n    ACCs = [];SNs = []; SPs =[]\n    for i in range(len(train_all)):\n        os.chdir(cur_path)\n        train_data = train_all[i];train_X = [];train_y = []\n        test_data = test_all[i];test_X = [];test_y = []\n        for eachline_train in train_data:\n            one_train = eachline_train.split('\\t') \n            one_train_format = []\n            for index in range(3,len(one_train)-1):\n                one_train_format.append(float(one_train[index]))\n            train_X.append(one_train_format)\n            train_y.append(int(one_train[-1].strip()))\n        for eachline_test in test_data:\n            one_test = eachline_test.split('\\t')\n            one_test_format = []\n            for index in range(3,len(one_test)-1):\n                one_test_format.append(float(one_test[index]))\n            test_X.append(one_test_format)\n            test_y.append(int(one_test[-1].strip()))\n        #======================================================================\n        #classifier start here\n        if not os.path.exists(clfname):#使用的分类器\n            os.mkdir(clfname)\n        out_path = clfname + \"/\" + clfname + \"_00\" + str(i)#计算结果文件夹\n        if not os.path.exists(out_path):\n            os.mkdir(out_path)\n        os.chdir(out_path)\n        ACC, SN, SP = classifier(clf, train_X, train_y, test_X, test_y)\n        ACCs.append(ACC);SNs.append(SN);SPs.append(SP)\n        #======================================================================\n    ACC_mean = mean_fun(ACCs)\n    SN_mean = mean_fun(SNs)\n    SP_mean = mean_fun(SPs)\n    #==========================================================================\n    #output experiment result\n    os.chdir(\"../\")\n    os.system(\"echo `date` '\" + str(clf) + \"' >> log.out\")\n    os.system(\"echo ACC_mean=\" + str(ACC_mean) + \" >> log.out\")\n    os.system(\"echo SN_mean=\" + str(SN_mean) + \" >> log.out\")\n    os.system(\"echo SP_mean=\" + str(SP_mean) + \" >> log.out\")\n    return ACC_mean, SN_mean, SP_mean\n```\n\n**测试：**\n\n```python\nif __name__ == '__main__':\n\tos.chdir(\"your workhome\") #你的数据存放目录\n    datadir = \"split10_1\" #切分后的文件输出目录\n    splitDataSet('datasets',10,datadir)#将数据集datasets切为十个保存到datadir目录中\n\t#==========================================================================\n    outdir = \"sample_data1\"\t#抽样的数据集存放目录\n    train_all,test_all = generateDataset(datadir,outdir) #抽样后返回训练集和测试集\n    print \"generateDataset end and cross validation start\"\n    #==========================================================================\n    #分类器部分\n    from sklearn.ensemble import RandomForestClassifier\n    clf = RandomForestClassifier(n_estimators=500) #使用随机森林分类器来训练\n    clfname = \"RF_1\"\n    #==========================================================================\n    curdir = \"experimentdir\" #工作目录\n\t#clf:分类器,clfname:分类器名称,curdir:当前路径,train_all:训练集,test_all:测试集\n    ACC_mean, SN_mean, SP_mean = crossValidation(clf, clfname, curdir, train_all,test_all)\n    print ACC_mean,SN_mean,SP_mean\t#将ACC均值，SP均值，SN均值都输出到控制台\n```\n\n上面的代码主要用于抽样后的十倍交叉验证，该怎么设置参数，还得具体分析。\n\n总之，交叉验证在一定程度上能够避免陷入局部最小值。一般实际操作中使用的是十折交叉验证，单具体情况还得具体分析，并没有一个统一的标准固定十倍交叉的参数或者是算法的选择以及算法参数的选择。不同的数据使用不同的算法往往会的得到不同的最优分类器。So,just try it!Happy coding!\n\n------\n<br>\n","slug":"2015-07-28 crossvalidation","published":1,"updated":"2016-03-13T10:22:17.928Z","comments":1,"photos":[],"link":"","_id":"cimigpyz4007g6cujgdtrbcmb"},{"layout":"post","date":"2015-07-23T04:53:00.000Z","title":"scikit-klean交叉验证","comment":true,"_content":"\n__一个Windows操作系统能够使用的pythonIDE__\n> winPython下载地址：[WinPython_2.7](http://sourceforge.net/projects/winpython/files/WinPython_2.7/2.7.10.1/)\n\n\n传统的F-measure或平衡的F-score (F1 score)是精度和召回的调和平均值：\n\n$$F_1 = 2 \\times \\dfrac{precision \\times recall}{precision + recall}$$\n\n<!-- more -->\n\n### __1.Cross Validation （交叉验证）__\n\ncross validation大概的意思是：对于原始数据我们要将其一部分分为train_data，一部分分为test_data。train_data用于训练，test_data用于测试准确率。在test_data上测试的结果叫做validation_error。将一个算法作用于一个原始数据，我们不可能只做出随机的划分一次train和test_data，然后得到一个validation_error，就作为衡量这个算法好坏的标准。因为这样存在偶然性。我们必须好多次的随机的划分train_data和test_data，分别在其上面算出各自的validation_error。这样就有一组validation_error，根据这一组validation_error，就可以较好的准确的衡量算法的好坏。\n\ncross validation是在数据量有限的情况下的非常好的一个evaluate performance的方法。而对原始数据划分出train data和test data的方法有很多种，这也就造成了cross validation的方法有很多种。\n\nsklearn中的cross validation模块，最主要的函数是如下函数：\nsklearn.cross_validation.cross_val_score:他的调用形式是scores = cross_validation.cross_val_score(clf, raw_data, raw_target, cv=5, score_func=None)\n\n__参数解释：__\n\n__clf__:表示的是不同的分类器，可以是任何的分类器。比如支持向量机分类器。clf = svm.SVC(kernel='linear', C=1)；   \n__raw_data__：原始数据；  \n__raw_target__:原始类别标号；  \n__cv__：代表的就是不同的cross validation的方法了。引用scikit-learn上的一句话（When the cv argument is an integer, cross_val_score uses the KFold or StratifiedKFold strategies by default, the latter being used if the estimator derives from ClassifierMixin.）如果cv是一个int数字的话，那么默认使用的是KFold或者StratifiedKFold交叉，如果如果指定了类别标签则使用的是StratifiedKFold。  \n__cross_val_score__:这个函数的返回值就是对于每次不同的的划分raw_data时，在test_data上得到的分类的**准确率**。至于准确率的算法可以通过score_func参数指定，如果不指定的话，是用clf默认自带的准确率算法。  \n\nscikit-learn的cross-validation交叉验证代码：\n\n```\n>>> from sklearn import cross_validation\n>>> from sklearn import svm\n>>> clf = svm.SVC(kernel='linear', C=1)\n>>> scores = cross_validation.cross_val_score(clf, iris.data, iris.target, cv=5)#5-fold cv\n# change metrics\n>>> from sklearn import metrics\n>>> cross_validation.cross_val_score(clf, iris.data, iris.target, cv=5, score_func=metrics.f1_score)\n#f1 score: http://en.wikipedia.org/wiki/F1_score\n```\n  \nNote: if using LR, clf = LogisticRegression().\n\n__生成一个数据集做为交叉验证__\n\n```\n>>> import numpy as np\n>>> from sklearn.cross_validation import train_test_split\n>>> X, y = np.arange(10).reshape((5, 2)), range(5)\n>>> X\narray([[0, 1],\n       [2, 3],\n       [4, 5],\n       [6, 7],\n       [8, 9]])\n>>> list(y)\n[0, 1, 2, 3, 4]\n```\n\n__将数据切分为训练集和测试集__\n\n```\n>>> X_train, X_test, y_train, y_test = train_test_split(\n...     X, y, test_size=0.33, random_state=42)\n...\n>>> X_train\narray([[4, 5],\n       [0, 1],\n       [6, 7]])\n>>> y_train\n[2, 0, 3]\n>>> X_test\narray([[2, 3],\n       [8, 9]])\n>>> y_test\n[1, 4]\n```\n\n__交叉验证的使用__\n\n下面是手动划分训练集和测试集，控制台中输入下列代码进行测试：\n\n```\n>>> import numpy as np\n>>> from sklearn import cross_validation\n>>> from sklearn import datasets\n>>> from sklearn import svm\n>>> iris = datasets.load_iris()\n>>> iris.data.shape, iris.target.shape\n((150, 4), (150,))\n>>> X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n...     iris.data, iris.target, test_size=0.4, random_state=0)\n>>> X_train.shape, y_train.shape\n((90, 4), (90,))\n>>> X_test.shape, y_test.shape\n((60, 4), (60,))\n>>> clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n>>> clf.score(X_test, y_test)                           \n0.96...\n```\n\n下面是交叉验证的实例：\n\n```\n>>> clf = svm.SVC(kernel='linear', C=1)\n>>> scores = cross_validation.cross_val_score(\n...    clf, iris.data, iris.target, cv=5)\n...\n>>> scores                                              \narray([ 0.96...,  1.  ...,  0.96...,  0.96...,  1.        ])\n```\n\n通过cross_validation，设置cv=5，进行5倍交叉验证，最后得到一个scores的预测准确率数组，表示每次交叉验证得到的准确率。\n\n```\n>>> print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\nAccuracy: 0.98 (+/- 0.03)\n```\n\n通过scores.mean()求出平均值，得到平均精度。还可以通过指定scoring来设置准确率算法\n\n```\n>>> from sklearn import metrics\n>>> scores = cross_validation.cross_val_score(clf, iris.data, iris.target,\n...     cv=5, scoring='f1_weighted')\n>>> scores                                              \narray([ 0.96...,  1.  ...,  0.96...,  0.96...,  1.        ])\n```\n\n__libsvm格式的数据导入：__\n\n\n```\n>>> from sklearn.datasets import load_svmlight_file\n>>> X_train, y_train = load_svmlight_file(\"/path/to/train_dataset.txt\")\n...\n>>>X_train.todense()#将稀疏矩阵转化为完整特征矩阵\n```\n\n------\n\n### __2.处理非均衡问题__\n\n对于正负样本比例相差较大的非均衡问题，一种调节分类器的方法就是对分类器的训练数据进行改造。一种是**欠抽样**，一种是**过抽样**。过抽样意味着赋值样例，而欠抽样意味着删除样例。对于过抽样，最后可能导致过拟合问题；而对于欠抽样，则删掉的样本中可能包含某些重要的信息，会导致欠拟合。对于正例样本较少的情况下，通常采取的方式是**使用反例类别的欠抽样和正例类别的过抽样相混合的方法**\n\n\n\n\n---\n\n### __3.scikit-learn学习SVM__\n\n```\n>>> from sklearn import datasets\n>>> iris = datasets.load_iris()\n>>> digits = datasets.load_digits()\n>>> print digits.data\n[[  0.   0.   5. ...,   0.   0.   0.]\n [  0.   0.   0. ...,  10.   0.   0.]\n [  0.   0.   0. ...,  16.   9.   0.]\n ..., \n [  0.   0.   1. ...,   6.   0.   0.]\n [  0.   0.   2. ...,  12.   0.   0.]\n [  0.   0.  10. ...,  12.   1.   0.]]\n>>> digits.target\narray([0, 1, 2, ..., 8, 9, 8])\n>>> digits.images[0]\narray([[  0.,   0.,   5.,  13.,   9.,   1.,   0.,   0.],\n       [  0.,   0.,  13.,  15.,  10.,  15.,   5.,   0.],\n       [  0.,   3.,  15.,   2.,   0.,  11.,   8.,   0.],\n       [  0.,   4.,  12.,   0.,   0.,   8.,   8.,   0.],\n       [  0.,   5.,   8.,   0.,   0.,   9.,   8.,   0.],\n       [  0.,   4.,  11.,   0.,   1.,  12.,   7.,   0.],\n       [  0.,   2.,  14.,   5.,  10.,  12.,   0.,   0.],\n       [  0.,   0.,   6.,  13.,  10.,   0.,   0.,   0.]])\n>>> from sklearn import svm\n>>> clf = svm.SVC(gamma=0.001, C=100.)\n>>> clf.fit(digits.data[:-1],digits.target[:-1])\nSVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n  gamma=0.001, kernel='rbf', max_iter=-1, probability=False,\n  random_state=None, shrinking=True, tol=0.001, verbose=False)\n>>> clf.predict(digits.data[-1])\narray([8])\n>>> \n```\n\n---\n\n\n### __4.scikit-learn学习RandomForest__\n\n\n使用例子\n\n```\n>>> from sklearn.ensemble import RandomForestClassifier\n>>> X = [[0, 0], [1, 1]]\n>>> Y = [0, 1]\n>>> clf = RandomForestClassifier(n_estimators=10)\n>>> clf = clf.fit(X, Y)\n```\n\n__Method__\n\n\n![](/assets/articleImg/2015-07-21 randomForest分类器的方法png.png)\n\nrandomForestClassifier分类器的初始值\n\n```\ndef __init__(self,\n\t n_estimators=10,\n\t criterion=\"gini\",\n\t max_depth=None,\n\t min_samples_split=2,\n\t min_samples_leaf=1,\n\t min_weight_fraction_leaf=0.,\n\t max_features=\"auto\",\n\t max_leaf_nodes=None,\n\t bootstrap=True,\n\t oob_score=False,\n\t n_jobs=1,\n\t random_state=None,\n\t verbose=0,\n\t warm_start=False,\n\t class_weight=None):\n```\n\n------\n\n<br>\n\n","source":"_posts/2015-07-23 machine learning tips.md","raw":"---\nlayout: post\ndate: 2015-07-23 12:53\ntitle: \"scikit-klean交叉验证\"\ntags: \n\t- Machine Learning\n\t- 交叉验证\n\t- Cross-Validation\ncomment: true\ncategories: ML\n---\n\n__一个Windows操作系统能够使用的pythonIDE__\n> winPython下载地址：[WinPython_2.7](http://sourceforge.net/projects/winpython/files/WinPython_2.7/2.7.10.1/)\n\n\n传统的F-measure或平衡的F-score (F1 score)是精度和召回的调和平均值：\n\n$$F_1 = 2 \\times \\dfrac{precision \\times recall}{precision + recall}$$\n\n<!-- more -->\n\n### __1.Cross Validation （交叉验证）__\n\ncross validation大概的意思是：对于原始数据我们要将其一部分分为train_data，一部分分为test_data。train_data用于训练，test_data用于测试准确率。在test_data上测试的结果叫做validation_error。将一个算法作用于一个原始数据，我们不可能只做出随机的划分一次train和test_data，然后得到一个validation_error，就作为衡量这个算法好坏的标准。因为这样存在偶然性。我们必须好多次的随机的划分train_data和test_data，分别在其上面算出各自的validation_error。这样就有一组validation_error，根据这一组validation_error，就可以较好的准确的衡量算法的好坏。\n\ncross validation是在数据量有限的情况下的非常好的一个evaluate performance的方法。而对原始数据划分出train data和test data的方法有很多种，这也就造成了cross validation的方法有很多种。\n\nsklearn中的cross validation模块，最主要的函数是如下函数：\nsklearn.cross_validation.cross_val_score:他的调用形式是scores = cross_validation.cross_val_score(clf, raw_data, raw_target, cv=5, score_func=None)\n\n__参数解释：__\n\n__clf__:表示的是不同的分类器，可以是任何的分类器。比如支持向量机分类器。clf = svm.SVC(kernel='linear', C=1)；   \n__raw_data__：原始数据；  \n__raw_target__:原始类别标号；  \n__cv__：代表的就是不同的cross validation的方法了。引用scikit-learn上的一句话（When the cv argument is an integer, cross_val_score uses the KFold or StratifiedKFold strategies by default, the latter being used if the estimator derives from ClassifierMixin.）如果cv是一个int数字的话，那么默认使用的是KFold或者StratifiedKFold交叉，如果如果指定了类别标签则使用的是StratifiedKFold。  \n__cross_val_score__:这个函数的返回值就是对于每次不同的的划分raw_data时，在test_data上得到的分类的**准确率**。至于准确率的算法可以通过score_func参数指定，如果不指定的话，是用clf默认自带的准确率算法。  \n\nscikit-learn的cross-validation交叉验证代码：\n\n```\n>>> from sklearn import cross_validation\n>>> from sklearn import svm\n>>> clf = svm.SVC(kernel='linear', C=1)\n>>> scores = cross_validation.cross_val_score(clf, iris.data, iris.target, cv=5)#5-fold cv\n# change metrics\n>>> from sklearn import metrics\n>>> cross_validation.cross_val_score(clf, iris.data, iris.target, cv=5, score_func=metrics.f1_score)\n#f1 score: http://en.wikipedia.org/wiki/F1_score\n```\n  \nNote: if using LR, clf = LogisticRegression().\n\n__生成一个数据集做为交叉验证__\n\n```\n>>> import numpy as np\n>>> from sklearn.cross_validation import train_test_split\n>>> X, y = np.arange(10).reshape((5, 2)), range(5)\n>>> X\narray([[0, 1],\n       [2, 3],\n       [4, 5],\n       [6, 7],\n       [8, 9]])\n>>> list(y)\n[0, 1, 2, 3, 4]\n```\n\n__将数据切分为训练集和测试集__\n\n```\n>>> X_train, X_test, y_train, y_test = train_test_split(\n...     X, y, test_size=0.33, random_state=42)\n...\n>>> X_train\narray([[4, 5],\n       [0, 1],\n       [6, 7]])\n>>> y_train\n[2, 0, 3]\n>>> X_test\narray([[2, 3],\n       [8, 9]])\n>>> y_test\n[1, 4]\n```\n\n__交叉验证的使用__\n\n下面是手动划分训练集和测试集，控制台中输入下列代码进行测试：\n\n```\n>>> import numpy as np\n>>> from sklearn import cross_validation\n>>> from sklearn import datasets\n>>> from sklearn import svm\n>>> iris = datasets.load_iris()\n>>> iris.data.shape, iris.target.shape\n((150, 4), (150,))\n>>> X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n...     iris.data, iris.target, test_size=0.4, random_state=0)\n>>> X_train.shape, y_train.shape\n((90, 4), (90,))\n>>> X_test.shape, y_test.shape\n((60, 4), (60,))\n>>> clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n>>> clf.score(X_test, y_test)                           \n0.96...\n```\n\n下面是交叉验证的实例：\n\n```\n>>> clf = svm.SVC(kernel='linear', C=1)\n>>> scores = cross_validation.cross_val_score(\n...    clf, iris.data, iris.target, cv=5)\n...\n>>> scores                                              \narray([ 0.96...,  1.  ...,  0.96...,  0.96...,  1.        ])\n```\n\n通过cross_validation，设置cv=5，进行5倍交叉验证，最后得到一个scores的预测准确率数组，表示每次交叉验证得到的准确率。\n\n```\n>>> print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\nAccuracy: 0.98 (+/- 0.03)\n```\n\n通过scores.mean()求出平均值，得到平均精度。还可以通过指定scoring来设置准确率算法\n\n```\n>>> from sklearn import metrics\n>>> scores = cross_validation.cross_val_score(clf, iris.data, iris.target,\n...     cv=5, scoring='f1_weighted')\n>>> scores                                              \narray([ 0.96...,  1.  ...,  0.96...,  0.96...,  1.        ])\n```\n\n__libsvm格式的数据导入：__\n\n\n```\n>>> from sklearn.datasets import load_svmlight_file\n>>> X_train, y_train = load_svmlight_file(\"/path/to/train_dataset.txt\")\n...\n>>>X_train.todense()#将稀疏矩阵转化为完整特征矩阵\n```\n\n------\n\n### __2.处理非均衡问题__\n\n对于正负样本比例相差较大的非均衡问题，一种调节分类器的方法就是对分类器的训练数据进行改造。一种是**欠抽样**，一种是**过抽样**。过抽样意味着赋值样例，而欠抽样意味着删除样例。对于过抽样，最后可能导致过拟合问题；而对于欠抽样，则删掉的样本中可能包含某些重要的信息，会导致欠拟合。对于正例样本较少的情况下，通常采取的方式是**使用反例类别的欠抽样和正例类别的过抽样相混合的方法**\n\n\n\n\n---\n\n### __3.scikit-learn学习SVM__\n\n```\n>>> from sklearn import datasets\n>>> iris = datasets.load_iris()\n>>> digits = datasets.load_digits()\n>>> print digits.data\n[[  0.   0.   5. ...,   0.   0.   0.]\n [  0.   0.   0. ...,  10.   0.   0.]\n [  0.   0.   0. ...,  16.   9.   0.]\n ..., \n [  0.   0.   1. ...,   6.   0.   0.]\n [  0.   0.   2. ...,  12.   0.   0.]\n [  0.   0.  10. ...,  12.   1.   0.]]\n>>> digits.target\narray([0, 1, 2, ..., 8, 9, 8])\n>>> digits.images[0]\narray([[  0.,   0.,   5.,  13.,   9.,   1.,   0.,   0.],\n       [  0.,   0.,  13.,  15.,  10.,  15.,   5.,   0.],\n       [  0.,   3.,  15.,   2.,   0.,  11.,   8.,   0.],\n       [  0.,   4.,  12.,   0.,   0.,   8.,   8.,   0.],\n       [  0.,   5.,   8.,   0.,   0.,   9.,   8.,   0.],\n       [  0.,   4.,  11.,   0.,   1.,  12.,   7.,   0.],\n       [  0.,   2.,  14.,   5.,  10.,  12.,   0.,   0.],\n       [  0.,   0.,   6.,  13.,  10.,   0.,   0.,   0.]])\n>>> from sklearn import svm\n>>> clf = svm.SVC(gamma=0.001, C=100.)\n>>> clf.fit(digits.data[:-1],digits.target[:-1])\nSVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n  gamma=0.001, kernel='rbf', max_iter=-1, probability=False,\n  random_state=None, shrinking=True, tol=0.001, verbose=False)\n>>> clf.predict(digits.data[-1])\narray([8])\n>>> \n```\n\n---\n\n\n### __4.scikit-learn学习RandomForest__\n\n\n使用例子\n\n```\n>>> from sklearn.ensemble import RandomForestClassifier\n>>> X = [[0, 0], [1, 1]]\n>>> Y = [0, 1]\n>>> clf = RandomForestClassifier(n_estimators=10)\n>>> clf = clf.fit(X, Y)\n```\n\n__Method__\n\n\n![](/assets/articleImg/2015-07-21 randomForest分类器的方法png.png)\n\nrandomForestClassifier分类器的初始值\n\n```\ndef __init__(self,\n\t n_estimators=10,\n\t criterion=\"gini\",\n\t max_depth=None,\n\t min_samples_split=2,\n\t min_samples_leaf=1,\n\t min_weight_fraction_leaf=0.,\n\t max_features=\"auto\",\n\t max_leaf_nodes=None,\n\t bootstrap=True,\n\t oob_score=False,\n\t n_jobs=1,\n\t random_state=None,\n\t verbose=0,\n\t warm_start=False,\n\t class_weight=None):\n```\n\n------\n\n<br>\n\n","slug":"2015-07-23 machine learning tips","published":1,"updated":"2016-03-13T10:23:04.957Z","comments":1,"photos":[],"link":"","_id":"cimigpyz9007n6cujp5ohti3n"},{"layout":"post","date":"2015-07-21T22:53:00.000Z","title":"机器学习-组合算法总结","comment":true,"_content":"\n\n## __组合模型__\n\n\n下面简单的介绍下Bootstraping, Bagging, Boosting, AdaBoost, RandomForest 和Gradient boosting这些组合型算法.\n\n### __1.Bootstraping__\n\n**Bootstraping**: 名字来自成语“pull up by your own bootstraps”，意思就是依靠你自己的资源，称为自助法，它是一种有放回的抽样方法，它是非参数统计中一种重要的估计统计量方差进而进行区间估计的统计方法。其核心思想和基本步骤如下：  \n <!-- more -->\n>（1）采用重抽样技术从原始样本中抽取一定数量（自己给定）的样本，此过程允许重复抽样。    \n>（2）根据抽出的样本计算给定的统计量T。  \n>（3）重复上述N次（一般大于1000），得到N个统计量T。  \n>（4）计算上述N个统计量T的样本方差，得到统计量的方差。 \n\n\n应该说Bootstrap是现代统计学较为流行的一种统计方法，在小样本时效果很好。通过方差的估计可以构造置信区间等，其运用范围得到进一步延伸。\n\n---\n\n### **2.装袋bagging**\n\n装袋算法相当于多个专家投票表决，对于多次测试，每个样本返回的是多次预测结果较多的那个。\n\n装袋算法描述\n\n```\n模型生成\n\t令n为训练数据的实例数量\n\t对于t次循环中的每一次\n\t\t从训练数据中采样n个实例\n\t\t将学习应用于所采样本\n\t\t保存结果模型\n分类\n\t对于t个模型的每一个\n\t\t使用模型对实例进行预测\n\t返回被预测次数最多的一个\n```\n\nbagging：bootstrap aggregating的缩写。让该学习算法训练多轮，每轮的训练集由从初始的训练集中随机取出的n个训练样本组成，某个初始训练样本在某轮训练集中可以出现多次或根本不出现，训练之后可得到一个预测函数序列\n\n$$h_1，⋯ ⋯h_n$$ \n\n最终的预测函数H对分类问题采用**投票方式**，对回归问题采用**简单平均方法**对新示例进行判别。\n\n[训练R个分类器f_i，分类器之间其他相同就是参数不同。其中f_i是通过从训练集合中(N篇文档)随机取(取后放回)N次文档构成的训练集合训练得到的。对于新文档d，用这R个分类器去分类，得到的最多的那个类别作为d的最终类别。]\n\n使用scikit-learn测试bagging方法\n\n```\n>>> from sklearn.ensemble import BaggingClassifier\n>>> from sklearn.neighbors import KNeighborsClassifier\n>>> bagging = BaggingClassifier(KNeighborsClassifier(),\n...                             max_samples=0.5, max_features=0.5)\n```\n\n---\n\n### __3.提升Boosting与Adaboost__\n\n**提升算法描述**\n\n```\n模型生成\n\t赋予每个训练实例相同的权值\n\tt次循环中的每一次：\n\t\t将学习算法应用于加了权的数据集上并保存结果模型\n\t\t计算模型在加了权的数据上的误差e并保存这个误差\n\t\t结果e等于0或者大于等于0.5：\n\t\t\t终止模型\n\t\t对于数据集中的每个实例：\n\t\t\t如果模型将实例正确分类\n\t\t\t\t将实例的权值乘以e/(1-e)\n\t\t将所有的实例权重进行正常化\n分类\n\t赋予所有类权重为0\n\t对于t（或小于t）个模型中的每一个：\n\t\t给模型预测的类加权 -log(e/(1-e))\n\t返回权重最高的类\n```\n\n这个模型提供了一种巧妙的方法生成一系列互补型的专家。\n\n**boosting**: 其中主要的是**AdaBoost**（Adaptive boosting，自适应boosting）。初始化时对每一个训练例赋相等的权重1／N，然后用该学算法对训练集训练t轮，每次训练后，对训练失败的训练例赋以较大的权重，也就是让学习算法在后续的学习中集中对比较难的训练例进行学习，从而得到一个预测函数序列$h_1,⋯, h_m$ , 其中h_i也有一定的权重，预测效果好的预测函数权重较大，反之较小。最终的预测函数H对分类问题采用有权重的投票方式，对回归问题采用加权平均的方法对新示例进行判别。\n\n提升算法理想状态是这些模型对于其他模型来说是一个补充，每个模型是这个领域的一个专家，而其他模型在这部分却不能表现很好，就像执行官一样要寻觅那些技能和经验互补的顾问，而不是重复的。这与装袋算法有所区分。\n\nAdaboost算法描述\n\n```\n模型生成\n\t训练数据中的每个样本，并赋予一个权重，构成权重向量D，初始值为1/N\n\tt次循环中的每一次：\n\t\t在训练数据上训练弱分类器并计算分类器的错误率e\n\t\t如果e等于0或者大于等于用户指定的阈值：\n\t\t\t终止模型，break\n\t\t重新调整每个样本的权重，其中alpha=0.5*ln((1-e)/e)\n\t\t对权重向量D进行更新，正确分类的样本的权重降低而错误分类的样本权重值升高\n\t\t对于数据集中的每个样例：\n\t\t\t如果某个样本正确分类：\n\t\t\t\t权重改为D^(t+1)_i = D^(t)_i * e^(-a)/Sum(D)\n\t\t\t如果某个样本错误分类：\n\t\t\t\t权重改为D^(t+1)_i = D^(t)_i * e^(a)/Sum(D)\n分类\n\t赋予所有类权重为0\n\t对于t（或小于t）个模型（基分类器）中的每一个：\n\t\t给模型预测的类加权 -log(e/(1-e))\n\t返回权重最高的类\n```\n（类似Bagging方法，但是训练是串行进行的，第k个分类器训练时关注对前k-1分类器中错分的文档，即不是随机取，而是加大取这些文档的概率。)\n\n__bagging与boosting的区别__：\n\n二者的主要区别是**取样方式不同**。bagging采用**均匀取样**，而Boosting根据**错误率来取样**，因此boosting的分类精度要优于Bagging。bagging的训练集的选择是随机的，各轮训练集之间相互独立，而boostlng的各轮训练集的选择与前面各轮的学习结果有关；bagging的各个预测函数没有权重，而boosting是有权重的；bagging的各个预测函数可以并行生成，而boosting的各个预测函数只能顺序生成。对于象神经网络这样极为耗时的学习方法。bagging可通过并行训练节省大量时间开销。\n\nbagging和boosting都可以有效地提高分类的准确性。在大多数数据集中，boosting的准确性比bagging高。在有些数据集中，boosting会引起退化--- Overfit。  \n\nBoosting思想的一种改进型AdaBoost方法在邮件过滤、文本分类方面都有很好的性能。 \n\n**Gradient boosting（又叫Mart, Treenet)**：Boosting是一种思想，Gradient Boosting是一种实现Boosting的方法，它主要的思想是，每一次建立模型是在之前建立模型**损失函数的梯度下降方向**。**损失函数(loss function)描述的是模型的不靠谱程度，损失函数越大，则说明模型越容易出错。**如果我们的模型能够让损失函数持续的下降，则说明我们的模型在不停的改进，而最好的方式就是**让损失函数在其梯度（Gradient)的方向上下降**。  \n\n使用scikit-learn测试adaboost算法\n\n```\n>>> from sklearn.cross_validation import cross_val_score\n>>> from sklearn.datasets import load_iris\n>>> from sklearn.ensemble import AdaBoostClassifier\n>>> iris = load_iris()\n>>> clf = AdaBoostClassifier(n_estimators=100)\n>>> scores = cross_val_score(clf, iris.data, iris.target)\n>>> scores.mean()                             \n0.9...\n```\n\n\n\n---\n\n### __4.Random Forest__\n\n**Random Forest**： 随机森林，顾名思义，是用随机的方式建立一个森林，森林里面有很多的决策树组成，随机森林的每一棵决策树之间是没有关联的。在得到森林之后，当有一个新的输入样本进入的时候，就让森林中的每一棵决策树分别进行一下判断，看看这个样本应该属于哪一类（对于分类算法），然后看看哪一类被选择最多，就预测这个样本为那一类。 在建立每一棵决策树的过程中，有两点需要注意——**采样**与**完全分裂**。首先是两个随机采样的过程，random forest对输入的数据要进行行和列的采样。对于行采样，采用有放回的方式，也就是在采样得到的样本集合中，可能有重复的样本。假设输入样本为N个，那么采样的样本也为N个。这样使得在训练的时候，每一棵树的输入样本都不是全部的样本，使得相对不容易出现over-fitting。然后进行列采样，从M个feature中，选择m个(m << M)。之后就是对采样之后的数据使用完全分裂的方式建立出决策树，这样决策树的某一个叶子节点要么是无法继续分裂的，要么里面的所有样本的都是指向的同一个分类。**一般很多的决策树算法都一个重要的步骤——剪枝，但随机森林不这样做，由于之前的两个随机采样的过程保证了随机性，所以就算不剪枝，也不会出现over-fitting。** 按这种算法得到的随机森林中的每一棵都是很弱的，但是大家组合起来就很厉害了。可以这样比喻随机森林算法：每一棵决策树就是一个精通于某一个窄领域的专家（因为我们从M个feature中选择m让每一棵决策树进行学习），这样在随机森林中就有了很多个精通不同领域的专家，对一个新的问题（新的输入数据），可以用不同的角度去看待它，最终由各个专家，投票得到结果。  \n\n__Random forest与bagging的区别__：\n\n(1)Random forest是选与输入样本的数目相同多的次数（可能一个样本会被选取多次，同时也会造成一些样本不会被选取到），而bagging一般选取比输入样本的数目少的样本；  \n(2)bagging是用全部特征来得到分类器，而Random forest是需要从全部特征中选取其中的一部分来训练得到分类器； **一般Random forest效果比bagging效果好！**\n\n使用scikit-learn测试随机森林算法\n\n```\n>>> from sklearn.ensemble import RandomForestClassifier\n>>> X = [[0, 0], [1, 1]]\n>>> Y = [0, 1]\n>>> clf = RandomForestClassifier(n_estimators=10)\n>>> clf = clf.fit(X, Y)\n```\n\n\n### __5.Gradient boosting__\n\n梯度提升树或者梯度提升回归树(GBRT)是任意一个不同损失函数的泛化。GBRT是一个灵敏的并且高效程序，可以用在回归和分类中。梯度提升树模型在许多领域中都有使用，如web搜索排行榜和社会生态学中。它主要的思想是，每一次建立模型是在之前建立模型损失函数的梯度下降方向。这句话有一点拗口，损失函数(loss function)描述的是模型的不靠谱程度，损失函数越大，则说明模型越容易出错（其实这里有一个方差、偏差均衡的问题，但是这里就假设损失函数越大，模型越容易出错）。如果我们的模型能够让损失函数持续的下降，则说明我们的模型在不停的改进，而最好的方式就是让损失函数在其梯度（Gradient)的方向上下降。\n\n\nGRBT的优势：\n\n- 混合数据类型的自然处理\n- 预测力强\n- 健壮的输出空间\n\nBoosting主要是一种思想，表示“知错就改”。而Gradient Boosting是在这个思想下的一种函数（也可以说是模型）的优化的方法，首先将函数分解为可加的形式（其实所有的函数都是可加的，只是是否好放在这个框架中，以及最终的效果如何）。然后进行m次迭代，通过使得损失函数在梯度方向上减少，最终得到一个优秀的模型。值得一提的是，每次模型在梯度方向上的减少的部分，可以认为是一个“小”的或者“弱”的模型，最终我们会通过加权(也就是每次在梯度方向上下降的距离）的方式将这些“弱”的模型合并起来，形成一个更好的模型。\n\n------\n\n<br>\n","source":"_posts/2015-07-22  ensemble.md","raw":"---\nlayout: post\ndate: 2015-07-22 06:53\ntitle: \"机器学习-组合算法总结\"\ntags: \n\t- Machine Learning\n\t- 组合算法\n\t- ensemble\ncomment: true\ncategories: ML\n---\n\n\n## __组合模型__\n\n\n下面简单的介绍下Bootstraping, Bagging, Boosting, AdaBoost, RandomForest 和Gradient boosting这些组合型算法.\n\n### __1.Bootstraping__\n\n**Bootstraping**: 名字来自成语“pull up by your own bootstraps”，意思就是依靠你自己的资源，称为自助法，它是一种有放回的抽样方法，它是非参数统计中一种重要的估计统计量方差进而进行区间估计的统计方法。其核心思想和基本步骤如下：  \n <!-- more -->\n>（1）采用重抽样技术从原始样本中抽取一定数量（自己给定）的样本，此过程允许重复抽样。    \n>（2）根据抽出的样本计算给定的统计量T。  \n>（3）重复上述N次（一般大于1000），得到N个统计量T。  \n>（4）计算上述N个统计量T的样本方差，得到统计量的方差。 \n\n\n应该说Bootstrap是现代统计学较为流行的一种统计方法，在小样本时效果很好。通过方差的估计可以构造置信区间等，其运用范围得到进一步延伸。\n\n---\n\n### **2.装袋bagging**\n\n装袋算法相当于多个专家投票表决，对于多次测试，每个样本返回的是多次预测结果较多的那个。\n\n装袋算法描述\n\n```\n模型生成\n\t令n为训练数据的实例数量\n\t对于t次循环中的每一次\n\t\t从训练数据中采样n个实例\n\t\t将学习应用于所采样本\n\t\t保存结果模型\n分类\n\t对于t个模型的每一个\n\t\t使用模型对实例进行预测\n\t返回被预测次数最多的一个\n```\n\nbagging：bootstrap aggregating的缩写。让该学习算法训练多轮，每轮的训练集由从初始的训练集中随机取出的n个训练样本组成，某个初始训练样本在某轮训练集中可以出现多次或根本不出现，训练之后可得到一个预测函数序列\n\n$$h_1，⋯ ⋯h_n$$ \n\n最终的预测函数H对分类问题采用**投票方式**，对回归问题采用**简单平均方法**对新示例进行判别。\n\n[训练R个分类器f_i，分类器之间其他相同就是参数不同。其中f_i是通过从训练集合中(N篇文档)随机取(取后放回)N次文档构成的训练集合训练得到的。对于新文档d，用这R个分类器去分类，得到的最多的那个类别作为d的最终类别。]\n\n使用scikit-learn测试bagging方法\n\n```\n>>> from sklearn.ensemble import BaggingClassifier\n>>> from sklearn.neighbors import KNeighborsClassifier\n>>> bagging = BaggingClassifier(KNeighborsClassifier(),\n...                             max_samples=0.5, max_features=0.5)\n```\n\n---\n\n### __3.提升Boosting与Adaboost__\n\n**提升算法描述**\n\n```\n模型生成\n\t赋予每个训练实例相同的权值\n\tt次循环中的每一次：\n\t\t将学习算法应用于加了权的数据集上并保存结果模型\n\t\t计算模型在加了权的数据上的误差e并保存这个误差\n\t\t结果e等于0或者大于等于0.5：\n\t\t\t终止模型\n\t\t对于数据集中的每个实例：\n\t\t\t如果模型将实例正确分类\n\t\t\t\t将实例的权值乘以e/(1-e)\n\t\t将所有的实例权重进行正常化\n分类\n\t赋予所有类权重为0\n\t对于t（或小于t）个模型中的每一个：\n\t\t给模型预测的类加权 -log(e/(1-e))\n\t返回权重最高的类\n```\n\n这个模型提供了一种巧妙的方法生成一系列互补型的专家。\n\n**boosting**: 其中主要的是**AdaBoost**（Adaptive boosting，自适应boosting）。初始化时对每一个训练例赋相等的权重1／N，然后用该学算法对训练集训练t轮，每次训练后，对训练失败的训练例赋以较大的权重，也就是让学习算法在后续的学习中集中对比较难的训练例进行学习，从而得到一个预测函数序列$h_1,⋯, h_m$ , 其中h_i也有一定的权重，预测效果好的预测函数权重较大，反之较小。最终的预测函数H对分类问题采用有权重的投票方式，对回归问题采用加权平均的方法对新示例进行判别。\n\n提升算法理想状态是这些模型对于其他模型来说是一个补充，每个模型是这个领域的一个专家，而其他模型在这部分却不能表现很好，就像执行官一样要寻觅那些技能和经验互补的顾问，而不是重复的。这与装袋算法有所区分。\n\nAdaboost算法描述\n\n```\n模型生成\n\t训练数据中的每个样本，并赋予一个权重，构成权重向量D，初始值为1/N\n\tt次循环中的每一次：\n\t\t在训练数据上训练弱分类器并计算分类器的错误率e\n\t\t如果e等于0或者大于等于用户指定的阈值：\n\t\t\t终止模型，break\n\t\t重新调整每个样本的权重，其中alpha=0.5*ln((1-e)/e)\n\t\t对权重向量D进行更新，正确分类的样本的权重降低而错误分类的样本权重值升高\n\t\t对于数据集中的每个样例：\n\t\t\t如果某个样本正确分类：\n\t\t\t\t权重改为D^(t+1)_i = D^(t)_i * e^(-a)/Sum(D)\n\t\t\t如果某个样本错误分类：\n\t\t\t\t权重改为D^(t+1)_i = D^(t)_i * e^(a)/Sum(D)\n分类\n\t赋予所有类权重为0\n\t对于t（或小于t）个模型（基分类器）中的每一个：\n\t\t给模型预测的类加权 -log(e/(1-e))\n\t返回权重最高的类\n```\n（类似Bagging方法，但是训练是串行进行的，第k个分类器训练时关注对前k-1分类器中错分的文档，即不是随机取，而是加大取这些文档的概率。)\n\n__bagging与boosting的区别__：\n\n二者的主要区别是**取样方式不同**。bagging采用**均匀取样**，而Boosting根据**错误率来取样**，因此boosting的分类精度要优于Bagging。bagging的训练集的选择是随机的，各轮训练集之间相互独立，而boostlng的各轮训练集的选择与前面各轮的学习结果有关；bagging的各个预测函数没有权重，而boosting是有权重的；bagging的各个预测函数可以并行生成，而boosting的各个预测函数只能顺序生成。对于象神经网络这样极为耗时的学习方法。bagging可通过并行训练节省大量时间开销。\n\nbagging和boosting都可以有效地提高分类的准确性。在大多数数据集中，boosting的准确性比bagging高。在有些数据集中，boosting会引起退化--- Overfit。  \n\nBoosting思想的一种改进型AdaBoost方法在邮件过滤、文本分类方面都有很好的性能。 \n\n**Gradient boosting（又叫Mart, Treenet)**：Boosting是一种思想，Gradient Boosting是一种实现Boosting的方法，它主要的思想是，每一次建立模型是在之前建立模型**损失函数的梯度下降方向**。**损失函数(loss function)描述的是模型的不靠谱程度，损失函数越大，则说明模型越容易出错。**如果我们的模型能够让损失函数持续的下降，则说明我们的模型在不停的改进，而最好的方式就是**让损失函数在其梯度（Gradient)的方向上下降**。  \n\n使用scikit-learn测试adaboost算法\n\n```\n>>> from sklearn.cross_validation import cross_val_score\n>>> from sklearn.datasets import load_iris\n>>> from sklearn.ensemble import AdaBoostClassifier\n>>> iris = load_iris()\n>>> clf = AdaBoostClassifier(n_estimators=100)\n>>> scores = cross_val_score(clf, iris.data, iris.target)\n>>> scores.mean()                             \n0.9...\n```\n\n\n\n---\n\n### __4.Random Forest__\n\n**Random Forest**： 随机森林，顾名思义，是用随机的方式建立一个森林，森林里面有很多的决策树组成，随机森林的每一棵决策树之间是没有关联的。在得到森林之后，当有一个新的输入样本进入的时候，就让森林中的每一棵决策树分别进行一下判断，看看这个样本应该属于哪一类（对于分类算法），然后看看哪一类被选择最多，就预测这个样本为那一类。 在建立每一棵决策树的过程中，有两点需要注意——**采样**与**完全分裂**。首先是两个随机采样的过程，random forest对输入的数据要进行行和列的采样。对于行采样，采用有放回的方式，也就是在采样得到的样本集合中，可能有重复的样本。假设输入样本为N个，那么采样的样本也为N个。这样使得在训练的时候，每一棵树的输入样本都不是全部的样本，使得相对不容易出现over-fitting。然后进行列采样，从M个feature中，选择m个(m << M)。之后就是对采样之后的数据使用完全分裂的方式建立出决策树，这样决策树的某一个叶子节点要么是无法继续分裂的，要么里面的所有样本的都是指向的同一个分类。**一般很多的决策树算法都一个重要的步骤——剪枝，但随机森林不这样做，由于之前的两个随机采样的过程保证了随机性，所以就算不剪枝，也不会出现over-fitting。** 按这种算法得到的随机森林中的每一棵都是很弱的，但是大家组合起来就很厉害了。可以这样比喻随机森林算法：每一棵决策树就是一个精通于某一个窄领域的专家（因为我们从M个feature中选择m让每一棵决策树进行学习），这样在随机森林中就有了很多个精通不同领域的专家，对一个新的问题（新的输入数据），可以用不同的角度去看待它，最终由各个专家，投票得到结果。  \n\n__Random forest与bagging的区别__：\n\n(1)Random forest是选与输入样本的数目相同多的次数（可能一个样本会被选取多次，同时也会造成一些样本不会被选取到），而bagging一般选取比输入样本的数目少的样本；  \n(2)bagging是用全部特征来得到分类器，而Random forest是需要从全部特征中选取其中的一部分来训练得到分类器； **一般Random forest效果比bagging效果好！**\n\n使用scikit-learn测试随机森林算法\n\n```\n>>> from sklearn.ensemble import RandomForestClassifier\n>>> X = [[0, 0], [1, 1]]\n>>> Y = [0, 1]\n>>> clf = RandomForestClassifier(n_estimators=10)\n>>> clf = clf.fit(X, Y)\n```\n\n\n### __5.Gradient boosting__\n\n梯度提升树或者梯度提升回归树(GBRT)是任意一个不同损失函数的泛化。GBRT是一个灵敏的并且高效程序，可以用在回归和分类中。梯度提升树模型在许多领域中都有使用，如web搜索排行榜和社会生态学中。它主要的思想是，每一次建立模型是在之前建立模型损失函数的梯度下降方向。这句话有一点拗口，损失函数(loss function)描述的是模型的不靠谱程度，损失函数越大，则说明模型越容易出错（其实这里有一个方差、偏差均衡的问题，但是这里就假设损失函数越大，模型越容易出错）。如果我们的模型能够让损失函数持续的下降，则说明我们的模型在不停的改进，而最好的方式就是让损失函数在其梯度（Gradient)的方向上下降。\n\n\nGRBT的优势：\n\n- 混合数据类型的自然处理\n- 预测力强\n- 健壮的输出空间\n\nBoosting主要是一种思想，表示“知错就改”。而Gradient Boosting是在这个思想下的一种函数（也可以说是模型）的优化的方法，首先将函数分解为可加的形式（其实所有的函数都是可加的，只是是否好放在这个框架中，以及最终的效果如何）。然后进行m次迭代，通过使得损失函数在梯度方向上减少，最终得到一个优秀的模型。值得一提的是，每次模型在梯度方向上的减少的部分，可以认为是一个“小”的或者“弱”的模型，最终我们会通过加权(也就是每次在梯度方向上下降的距离）的方式将这些“弱”的模型合并起来，形成一个更好的模型。\n\n------\n\n<br>\n","slug":"2015-07-22  ensemble","published":1,"updated":"2016-03-13T05:58:30.693Z","comments":1,"photos":[],"link":"","_id":"cimigpyzf007s6cujmmlyts1a"},{"layout":"post","title":"机器学习scikit-learn入门教程（译）","date":"2015-07-21T13:31:00.000Z","comment":true,"_content":"\n原文链接：http://scikit-learn.github.io/dev/tutorial/basic/tutorial.html\n\n__章节内容__\n\n在这个章节中，我们主要介绍关于scikit-learn机器学习词库，并且将给出一个学习样例。\n\n## **机器学习：问题设置**\n\n通常，一个学习问题是通过一系列的n个样本数据来学习然后尝试预测未知数据的属性。如果每一个样本超过一个单一的数值，例如多维输入（也叫做多维数据），那么它就拥有了多个特征。\n<!-- more -->\n我们可以把学习问题划分为几个大的来别：\n\n* 监督学习: 在监督学习中，这些数据自带了我们想要预测的附加属性（[scikit-learn监督学习链接](http://scikit-learn.github.io/dev/supervised_learning.html#supervised-learning)），这个问题包括：\n\t* 分类：样本属于属于两类或者多类，我们想从已经被标记的数据中来预测未知数据的类别。一个分类问题的例子就是手写字识别。这个例子的目的是从有些的类别中识别出输入向量的类别。对于分类的另一种想法是作为监督学习的一种分离的表格(不是连续的)，在这个表格中，一个是被限制的类别数量，而且对于每个类别都有N个样例被提供；一个是尝试用正确的类别或者类来标记他们。\n\t* 回归：如果期望的输出是由一个或者更多的连续的变量组成，那么就叫做回归。回归问题的例子将通过一条鲑鱼的年龄和重量预测它的长度。\n* 无监督学习：在无监督学习里面，训练数据是由一组没有任何类别标签值的一系列输入向量组成。这种问题的目的是可能可以在这些数据里发现相似的样例组，这些相似的样例被称作聚类。或者在输入空间里决定数据分布，称之为密度估算；或者将数据从高维空间映射到二维或三维空间中，称之为数据可视化问题。（[无监督学习链接](http://scikit-learn.github.io/dev/unsupervised_learning.html#unsupervised-learning)）\n\n**训练集和测试集**\n\n机器学习是关于学习数据集的一些属性然后将它们应用到新的数据上。这就是为什么在机器学习中评价一个算法的通常惯例是把数据集切分为两个数据集，其中一个叫做训练集，用来学习数据的属性；另一个叫做测试集，在测试集上测试那些属性。\n\n\n## **加载样本数据集**\n\n\nscikit-learn带有一些标准的数据集，例如用于分类的[iris](http://en.wikipedia.org/wiki/Iris_flower_data_set)和[digit](http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits)数据集和用于回归的[ boston house prices dataset ](http://archive.ics.uci.edu/ml/datasets/Housing).\n\n下面，我们打开Python编译器，然后载入__iris__和digits数据集。我们的符号'$'表示shell提示，'>>>'表示Python编译器提示\n\n```\n$ python\n>>> from sklearn import datasets\n>>> iris = datasets.load_iris()\n>>> digits = datasets.load_digits()\n```\n\n 数据集是一个类似字典的对象，包含所有的数据和一些和数据有关的元数据。数据存储在.data中，是个n_samples,n_features的数组。在监督问题的情况下，一个或多个类别变量存储在.target成员中。更多有关的不同数据集的细节可以在[dedicated section](http://scikit-learn.github.io/dev/datasets/index.html#datasets)查找。\n \n 例如，在digits数据集情况下，digits.data 提供了可用于分类数字样本。\n\n```\n>>> print(digits.data)  \n[[  0.   0.   5. ...,   0.   0.   0.]\n [  0.   0.   0. ...,  10.   0.   0.]\n [  0.   0.   0. ...,  16.   9.   0.]\n ...,\n [  0.   0.   1. ...,   6.   0.   0.]\n [  0.   0.   2. ...,  12.   0.   0.]\n [  0.   0.  10. ...,  12.   1.   0.]]\n```\n\n并且digits.target给出了digit数据集的真实结果，这些数字是和我们正在学习的每个数字图像相关的数字。\n\n```\n>>> digits.target\narray([0, 1, 2, ..., 8, 9, 8])\n```\n\n**数组的形状**\n\n数据总是一些2D数组，shape(n_samples,n_features),尽管原始数据也许有一个不同的形状，就这个digits而言，每一个原始样例是一个shape(8,8)的图像，并且能被访问使用:\n\n```\n>>> digits.images[0]\narray([[  0.,   0.,   5.,  13.,   9.,   1.,   0.,   0.],\n       [  0.,   0.,  13.,  15.,  10.,  15.,   5.,   0.],\n       [  0.,   3.,  15.,   2.,   0.,  11.,   8.,   0.],\n       [  0.,   4.,  12.,   0.,   0.,   8.,   8.,   0.],\n       [  0.,   5.,   8.,   0.,   0.,   9.,   8.,   0.],\n       [  0.,   4.,  11.,   0.,   1.,  12.,   7.,   0.],\n       [  0.,   2.,  14.,   5.,  10.,  12.,   0.,   0.],\n       [  0.,   0.,   6.,  13.,  10.,   0.,   0.,   0.]])\n```\n\n[simple example on this dataset ](http://scikit-learn.github.io/dev/auto_examples/classification/plot_digits_classification.html#example-classification-plot-digits-classification-py)这个数据集表明了在scikit-learn中怎样从原始问题开始着手制作数据。\n\n\n\n## **学习和预测**\n\n在digits数据集中，给定一幅手写数字的数字图像，任务是预测结果。我们给定的样本有10种类别（是数字0到9），基于此我们建立一个估计方法能够预测我们没有见过的样本属于哪一类。\n\n在scikit-learn中，用于分类的估计模型是一个实现了fit(x,y)方法和predict(T)方法的Python对象。\n    \n估计模型的例子是在实现了[support vector classification支持向量机](http://en.wikipedia.org/wiki/Support_vector_machine)的类 sklearn.svm.SVC。估计模型的构造函数带有模型参数，但是目前，我们将估计模型当做一个黑盒子。\n\n```\n>>> from sklearn import svm  \n>>> clf = svm.SVC(gamma=0.001, C=100.)\n```\n\n**选择模型参数**\n\t\n在这个例子中，我们这设定了gamma值。可以通过使用[网格搜索](http://scikit-learn.github.io/dev/modules/grid_search.html#grid-search)和[交叉验证](http://scikit-learn.github.io/dev/modules/cross_validation.html#cross-validation)自动的找出最好的参数值\n\n我们把我们的评估模型命名为clf，作为一个分类器，它现在必须拟合这个模型，也就是它必须从这个模型学习。我们通过将数据集传递给fit函数完成。作为训练集，除了最后一个样本，我们选择其余的所有样本。通过python语句[:-1]选择样本，这条语句将从digits.data中产生一个除了最后一个样本的新数组。\n\n```\nclf.fit(digits.data[:-1], digits.target[:-1])    \nSVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0, degree=3,  \n  gamma=0.001, kernel='rbf', max_iter=-1, probability=False,  \n  random_state=None, shrinking=True, tol=0.001, verbose=False)  \n```\n\n现在，我们可以预测新值，尤其是我们可以问分类器在digits数据集中的用来训练分类器时没有使用的最后一个数据是数字几：\n\n相应的图像如下所示:\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20150720185355481)\n</center>\n\n正如你看到的，这是一个具有挑战性的任务：图象的分辨率很低。你认同这个分类器吗？\n\n一个完整的分类问题实例可以通过下面的链接下载，用来作为你运行并且学习的例子 [Recognizing hand-written digits](http://scikit-learn.github.io/dev/auto_examples/classification/plot_digits_classification.html#example-classification-plot-digits-classification-py)\n\n## **模型持久化**\n\n可以通过使用python的built-in持久化模型在scikit中保存一个模型，命名[pickle](http://docs.python.org/library/pickle.html):\n\n```\n>>> from sklearn import svm\n>>> from sklearn import datasets\n>>> clf = svm.SVC()\n>>> iris = datasets.load_iris()\n>>> X, y = iris.data, iris.target\n>>> clf.fit(X, y)  \nSVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)\n>>> import pickle\n>>> s = pickle.dumps(clf)\n>>> clf2 = pickle.loads(s)\n>>> clf2.predict(X[0])\narray([0])\n>>> y[0]\n0\n```\n\n在scikit的特别情况下，使用joblib替换pickle(joblib.dump & joblib.load)会更有趣,它在大数据上是更有效的，但是仅仅只能存入的是字典而不是字符串。\n\n```\n>>> from sklearn.externals import joblib\n>>> joblib.dump(clf, 'filename.pkl') \n```\n\n然后你就可以读取上面的pickled模型使用了（通常是在其它的Python程序中）：\n\n```\n>>> clf = joblib.load('filename.pkl') \n```\n\n## **惯例**\n\nscikit-learn估计量有一些特定的规则是的分类器更具有预测性\n\n**Type casting 类型转换**\n\n除非特别指定，否则输入格式是float64\n\n```\n>>> import numpy as np\n>>> from sklearn import random_projection\n>>> rng = np.random.RandomState(0)\n>>> X = rng.rand(10, 2000)\n>>> X = np.array(X, dtype='float32')\n>>> X.dtype\ndtype('float32')\n>>> transformer = random_projection.GaussianRandomProjection()\n>>> X_new = transformer.fit_transform(X)\n>>> X_new.dtype\ndtype('float64')\n```\n\n在这个例子中，X是float32，通过fit_transform(X)把它转为float64\n\n回归的输出值是float64，分类的也是：\n\n```\n>>> from sklearn import datasets\n>>> from sklearn.svm import SVC\n>>> iris = datasets.load_iris()\n>>> clf = SVC()\n>>> clf.fit(iris.data, iris.target)  \nSVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)\n>>> list(clf.predict(iris.data[:3]))\n[0, 0, 0]\n>>> clf.fit(iris.data, iris.target_names[iris.target])  \nSVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)\n>>> list(clf.predict(iris.data[:3]))  \n['setosa', 'setosa', 'setosa']\n```\n\n这里，第一次predict()返回的是一个整数数组，因为在拟合中用到了iris.target（一个整数数组），第二个predict返回的是一个字符串数组，因为用来拟合的是iris.target_names。\n\n\n## Supplementary\n\n推介一个好用的python IDE：\n> winPython下载地址：[WinPython_2.7](http://sourceforge.net/projects/winpython/files/WinPython_2.7/2.7.10.1/)\n\n---\n\n<br>\n\n\n","source":"_posts/2015-07-21-An-introduction-to-machine-learning-with-scikit-learn.md","raw":"---\nlayout: post\ntitle: \"机器学习scikit-learn入门教程（译）\"\ndate: 2015-07-21 21:31\ncomment: true\ntags: \n\t- Machine Learning\n\t- 译文\n\t- scikit-learn\ncategories: ML\n---\n\n原文链接：http://scikit-learn.github.io/dev/tutorial/basic/tutorial.html\n\n__章节内容__\n\n在这个章节中，我们主要介绍关于scikit-learn机器学习词库，并且将给出一个学习样例。\n\n## **机器学习：问题设置**\n\n通常，一个学习问题是通过一系列的n个样本数据来学习然后尝试预测未知数据的属性。如果每一个样本超过一个单一的数值，例如多维输入（也叫做多维数据），那么它就拥有了多个特征。\n<!-- more -->\n我们可以把学习问题划分为几个大的来别：\n\n* 监督学习: 在监督学习中，这些数据自带了我们想要预测的附加属性（[scikit-learn监督学习链接](http://scikit-learn.github.io/dev/supervised_learning.html#supervised-learning)），这个问题包括：\n\t* 分类：样本属于属于两类或者多类，我们想从已经被标记的数据中来预测未知数据的类别。一个分类问题的例子就是手写字识别。这个例子的目的是从有些的类别中识别出输入向量的类别。对于分类的另一种想法是作为监督学习的一种分离的表格(不是连续的)，在这个表格中，一个是被限制的类别数量，而且对于每个类别都有N个样例被提供；一个是尝试用正确的类别或者类来标记他们。\n\t* 回归：如果期望的输出是由一个或者更多的连续的变量组成，那么就叫做回归。回归问题的例子将通过一条鲑鱼的年龄和重量预测它的长度。\n* 无监督学习：在无监督学习里面，训练数据是由一组没有任何类别标签值的一系列输入向量组成。这种问题的目的是可能可以在这些数据里发现相似的样例组，这些相似的样例被称作聚类。或者在输入空间里决定数据分布，称之为密度估算；或者将数据从高维空间映射到二维或三维空间中，称之为数据可视化问题。（[无监督学习链接](http://scikit-learn.github.io/dev/unsupervised_learning.html#unsupervised-learning)）\n\n**训练集和测试集**\n\n机器学习是关于学习数据集的一些属性然后将它们应用到新的数据上。这就是为什么在机器学习中评价一个算法的通常惯例是把数据集切分为两个数据集，其中一个叫做训练集，用来学习数据的属性；另一个叫做测试集，在测试集上测试那些属性。\n\n\n## **加载样本数据集**\n\n\nscikit-learn带有一些标准的数据集，例如用于分类的[iris](http://en.wikipedia.org/wiki/Iris_flower_data_set)和[digit](http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits)数据集和用于回归的[ boston house prices dataset ](http://archive.ics.uci.edu/ml/datasets/Housing).\n\n下面，我们打开Python编译器，然后载入__iris__和digits数据集。我们的符号'$'表示shell提示，'>>>'表示Python编译器提示\n\n```\n$ python\n>>> from sklearn import datasets\n>>> iris = datasets.load_iris()\n>>> digits = datasets.load_digits()\n```\n\n 数据集是一个类似字典的对象，包含所有的数据和一些和数据有关的元数据。数据存储在.data中，是个n_samples,n_features的数组。在监督问题的情况下，一个或多个类别变量存储在.target成员中。更多有关的不同数据集的细节可以在[dedicated section](http://scikit-learn.github.io/dev/datasets/index.html#datasets)查找。\n \n 例如，在digits数据集情况下，digits.data 提供了可用于分类数字样本。\n\n```\n>>> print(digits.data)  \n[[  0.   0.   5. ...,   0.   0.   0.]\n [  0.   0.   0. ...,  10.   0.   0.]\n [  0.   0.   0. ...,  16.   9.   0.]\n ...,\n [  0.   0.   1. ...,   6.   0.   0.]\n [  0.   0.   2. ...,  12.   0.   0.]\n [  0.   0.  10. ...,  12.   1.   0.]]\n```\n\n并且digits.target给出了digit数据集的真实结果，这些数字是和我们正在学习的每个数字图像相关的数字。\n\n```\n>>> digits.target\narray([0, 1, 2, ..., 8, 9, 8])\n```\n\n**数组的形状**\n\n数据总是一些2D数组，shape(n_samples,n_features),尽管原始数据也许有一个不同的形状，就这个digits而言，每一个原始样例是一个shape(8,8)的图像，并且能被访问使用:\n\n```\n>>> digits.images[0]\narray([[  0.,   0.,   5.,  13.,   9.,   1.,   0.,   0.],\n       [  0.,   0.,  13.,  15.,  10.,  15.,   5.,   0.],\n       [  0.,   3.,  15.,   2.,   0.,  11.,   8.,   0.],\n       [  0.,   4.,  12.,   0.,   0.,   8.,   8.,   0.],\n       [  0.,   5.,   8.,   0.,   0.,   9.,   8.,   0.],\n       [  0.,   4.,  11.,   0.,   1.,  12.,   7.,   0.],\n       [  0.,   2.,  14.,   5.,  10.,  12.,   0.,   0.],\n       [  0.,   0.,   6.,  13.,  10.,   0.,   0.,   0.]])\n```\n\n[simple example on this dataset ](http://scikit-learn.github.io/dev/auto_examples/classification/plot_digits_classification.html#example-classification-plot-digits-classification-py)这个数据集表明了在scikit-learn中怎样从原始问题开始着手制作数据。\n\n\n\n## **学习和预测**\n\n在digits数据集中，给定一幅手写数字的数字图像，任务是预测结果。我们给定的样本有10种类别（是数字0到9），基于此我们建立一个估计方法能够预测我们没有见过的样本属于哪一类。\n\n在scikit-learn中，用于分类的估计模型是一个实现了fit(x,y)方法和predict(T)方法的Python对象。\n    \n估计模型的例子是在实现了[support vector classification支持向量机](http://en.wikipedia.org/wiki/Support_vector_machine)的类 sklearn.svm.SVC。估计模型的构造函数带有模型参数，但是目前，我们将估计模型当做一个黑盒子。\n\n```\n>>> from sklearn import svm  \n>>> clf = svm.SVC(gamma=0.001, C=100.)\n```\n\n**选择模型参数**\n\t\n在这个例子中，我们这设定了gamma值。可以通过使用[网格搜索](http://scikit-learn.github.io/dev/modules/grid_search.html#grid-search)和[交叉验证](http://scikit-learn.github.io/dev/modules/cross_validation.html#cross-validation)自动的找出最好的参数值\n\n我们把我们的评估模型命名为clf，作为一个分类器，它现在必须拟合这个模型，也就是它必须从这个模型学习。我们通过将数据集传递给fit函数完成。作为训练集，除了最后一个样本，我们选择其余的所有样本。通过python语句[:-1]选择样本，这条语句将从digits.data中产生一个除了最后一个样本的新数组。\n\n```\nclf.fit(digits.data[:-1], digits.target[:-1])    \nSVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0, degree=3,  \n  gamma=0.001, kernel='rbf', max_iter=-1, probability=False,  \n  random_state=None, shrinking=True, tol=0.001, verbose=False)  \n```\n\n现在，我们可以预测新值，尤其是我们可以问分类器在digits数据集中的用来训练分类器时没有使用的最后一个数据是数字几：\n\n相应的图像如下所示:\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20150720185355481)\n</center>\n\n正如你看到的，这是一个具有挑战性的任务：图象的分辨率很低。你认同这个分类器吗？\n\n一个完整的分类问题实例可以通过下面的链接下载，用来作为你运行并且学习的例子 [Recognizing hand-written digits](http://scikit-learn.github.io/dev/auto_examples/classification/plot_digits_classification.html#example-classification-plot-digits-classification-py)\n\n## **模型持久化**\n\n可以通过使用python的built-in持久化模型在scikit中保存一个模型，命名[pickle](http://docs.python.org/library/pickle.html):\n\n```\n>>> from sklearn import svm\n>>> from sklearn import datasets\n>>> clf = svm.SVC()\n>>> iris = datasets.load_iris()\n>>> X, y = iris.data, iris.target\n>>> clf.fit(X, y)  \nSVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)\n>>> import pickle\n>>> s = pickle.dumps(clf)\n>>> clf2 = pickle.loads(s)\n>>> clf2.predict(X[0])\narray([0])\n>>> y[0]\n0\n```\n\n在scikit的特别情况下，使用joblib替换pickle(joblib.dump & joblib.load)会更有趣,它在大数据上是更有效的，但是仅仅只能存入的是字典而不是字符串。\n\n```\n>>> from sklearn.externals import joblib\n>>> joblib.dump(clf, 'filename.pkl') \n```\n\n然后你就可以读取上面的pickled模型使用了（通常是在其它的Python程序中）：\n\n```\n>>> clf = joblib.load('filename.pkl') \n```\n\n## **惯例**\n\nscikit-learn估计量有一些特定的规则是的分类器更具有预测性\n\n**Type casting 类型转换**\n\n除非特别指定，否则输入格式是float64\n\n```\n>>> import numpy as np\n>>> from sklearn import random_projection\n>>> rng = np.random.RandomState(0)\n>>> X = rng.rand(10, 2000)\n>>> X = np.array(X, dtype='float32')\n>>> X.dtype\ndtype('float32')\n>>> transformer = random_projection.GaussianRandomProjection()\n>>> X_new = transformer.fit_transform(X)\n>>> X_new.dtype\ndtype('float64')\n```\n\n在这个例子中，X是float32，通过fit_transform(X)把它转为float64\n\n回归的输出值是float64，分类的也是：\n\n```\n>>> from sklearn import datasets\n>>> from sklearn.svm import SVC\n>>> iris = datasets.load_iris()\n>>> clf = SVC()\n>>> clf.fit(iris.data, iris.target)  \nSVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)\n>>> list(clf.predict(iris.data[:3]))\n[0, 0, 0]\n>>> clf.fit(iris.data, iris.target_names[iris.target])  \nSVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)\n>>> list(clf.predict(iris.data[:3]))  \n['setosa', 'setosa', 'setosa']\n```\n\n这里，第一次predict()返回的是一个整数数组，因为在拟合中用到了iris.target（一个整数数组），第二个predict返回的是一个字符串数组，因为用来拟合的是iris.target_names。\n\n\n## Supplementary\n\n推介一个好用的python IDE：\n> winPython下载地址：[WinPython_2.7](http://sourceforge.net/projects/winpython/files/WinPython_2.7/2.7.10.1/)\n\n---\n\n<br>\n\n\n","slug":"2015-07-21-An-introduction-to-machine-learning-with-scikit-learn","published":1,"updated":"2016-03-08T08:57:49.910Z","comments":1,"photos":[],"link":"","_id":"cimigpyzo007y6cuj1xfeu6yc"},{"layout":"post","title":"Airbnb欺诈预测机器学习模型设计：准确率和召回率的故事（译）","date":"2015-07-18T04:30:00.000Z","comments":1,"_content":"\n<div style=\"text-align:right;padding-bottom:7px;\">译者：<a href=\"http://blog.csdn.net/dream_angel_z\">刘帝伟</a>   审校：刘翔宇 朱正贵   责编：周建丁</div>\n\n\nAirbnb网站基于允许任何人将闲置的房屋进行长期或短期出租构建商业模式，来自房客或房东的欺诈风险是必须解决的问题。Airbnb信任和安全小组通过构建机器学习模型进行欺诈预测，本文介绍了其设计思想。假想模型是预测某些虚拟人物是否为“反面人物”，基本步骤：构建模型预期，构建训练集和测试集，特征学习，模型性能评估。其中特征转换倾向于采用条件概率编码（CP-coding），评估度量是准确率（Precision）和召回率（Recall），通常偏向于高召回率。\n<!-- more -->\n**以下为全文内容：**\n\n在Airbnb网站上，我们专注于创造一个这样的地方：一个人可以属于任何地方。部分归属感来自于我们用户之间的信任，同时认识到他们的安全是我们最关心的。\n\n虽然我们绝大多数的社区是由友好和可靠的房东和房客组成，但仍然有一小部分用户，他们试图从我们的网站中（非法）获利。这些都是非常罕见的，尽管如此，信任和安全小组还是因此而产生。\n\n信任和安全小组主要是解决任何可能会发生在我们平台的欺诈行为。我们最主要目的是试图保护我们的用户和公司免于不同类型的风险。例如：退款风险——一个绝大多数电子商务企业都熟悉的风险问题。为了减少此类欺诈行为，信任和安全小组的数据科学家构建了不同种类的机器学习模型，用来帮助识别不同类型的风险。想要获得我们模型背后更多的体系结构信息，请参考以前的文章 [机器学习风险系统的设计](http://nerds.airbnb.com/architecting-machine-learning-system-risk/)。\n\n在这篇文章中，我对机器学习的模型建立给了一个简短的思维过程概述。当然，每个模型都有所不同，但希望它能够给读者在关于机器学习中我们如何使用数据来帮助保护我们的用户以及如何改善模型的不同处理方法上带来一个全新的认识。在这篇文章中，我们假设想要构建一个这样的模型：预测某些虚构的角色是否是反面人物。\n\n### 试图预测的是什么？\n\n在模型建立中最基本的问题就是明确你想要用这个模型来预测什么。我知道这个听起来似乎很愚蠢，但很多时候，通过这个问题可以引发出其它更深层的问题。\n\n即使是一个看似简单的角色分类模型，随着我们逐步深入地思考，也可以提出许多更深层的问题。例如，我们想要怎样来给这个模型评分：仅仅是给当前新介绍的角色还是给所有角色？如果是前者，我们想要评分的角色和人物介绍中的角色评分相差多远？如果是后者，我们又该多长时间给这些角色评分呢？\n\n第一个想法可能是根据人物介绍中给每个角色的评分来建立模型。然而，这种模型，我们可能不能随着时间的推移动态地追踪人物的评分。此外，我们可能会因为在介绍时的一些“好”的特征而忽略了潜在的反面人物。\n\n相反，我们还可以建立这样一个模型，只要他/她出现在情节里面就评分一次。这将让我们在每个时间段都会有人物评分并检测出任何异常情况。但是，考虑到在每个角色单独出现的情况下可能没有任何的角色类别发展，所以这可能也不是最实际的方法。\n\n深思熟虑之后，我们决定把模型设计成介于这两种想法之间的模型。例如，建立这样一种模型，在每次有意义的事情发生的时候对角色进行评分，比如结交新盟友，龙族领地占领等等。在这种方式下，我们仍然可以随着时间的变化来跟踪人物的评分，同时，对没有最新进展的角色也不会多加评分。\n\n![](http://img.ptcms.csdn.net/article/201507/13/55a2a2b74a98e.jpg)\n\n### 如何模拟得分？\n\n因为我们的目的是分析每个时期的得分，所以我们的训练集要能反映出某段时间某个角色的类别行为，最后的训练数据集类似于下图：\n\n![](http://img.ptcms.csdn.net/article/201507/13/55a2a2e11dabc_middle.jpg?_=23712)\n\n与每个角色相关的时间不一定是连续的，因为我们关心的是那些有着重要事件发展的时间。\n\n在这个实例当中，Jarden在3个不同的场合有着重要的角色发展并且在一段时间内持续扩充他的军队。相比之下，Dineas 在5个不同的场合有着重要的角色发展并且主管着4个龙族中心基地。\n\n### 采样\n\n在机器学习模型中，从观测数据中下采样是有必要的。采样过程本身很简单，一旦有了所需要的训练数据集，就可以在数据集上做一个基于行的采样。\n\n然而，由于这里描述的模型是处理每个角色多个时期的样本，基于行采样可能会导致这样一种情况，即在建立模型的数据和用来验证的数据之间，场景附加的人物角色被分离开。如下表所示：\n\n\n![](http://img.ptcms.csdn.net/article/201507/13/55a2a304d75b7.jpg)\n\n显然这并不是理想的采样，因为我们没有得到每个角色的整体描述，并且这些缺失的观测数据可能对建立一个好的模型至关重要。\n\n出于这个原因，我们需要做基于角色的采样。这样做能确保在模型数据建立中包含所有场合附加的角色，或者什么都没有。\n\n\n\n\n\n![](http://img.ptcms.csdn.net/article/201507/13/55a2a31c8bc17.jpg)\n\n\n此外，当我们将我们的数据集切分为训练集和测试集时，通常这样的逻辑也适用。\n\n### 特征设计\n\n特征设计是机器学习不可或缺的一部分，通常情况下，在特征种类的选择上，对数据的充分理解有助于形成一个更好的模型设计思路。特征设计的实例包括特征规范化和分类特征处理。\n\n特征规范化是标准化特征的一种方式，允许更合理的对比。如下表所示：\n\n![](http://img.ptcms.csdn.net/article/201507/13/55a2a34d3dd90.jpg)\n\n\n从上表可知，每个人物都有10,000个士兵。然而，Serion掌权长达5年，而Dineas仅仅掌权2年。通过这些人物比较绝对的士兵数量可能并不是非常有效的。但是，通过人物掌权的年份来标准化他们可能会提供更好的见解，并且产生更有预测力的特征。\n\n在分类特征的特征设计上值得单独的写一篇博客文章，因为有很多方式可以去处理它们。特别是对于缺失值的插补，请看一看以前的博客文章—— [使用随机森林分类器处理缺失值](http://nerds.airbnb.com/overcoming-missing-values-in-a-rfc/)。\n\n转换分类特征最常见的方法就是矢量化（也称作one-hot encoding）。然而，在处理有许多不同级别的分类特征时，使用条件概率编码（CP-coding）则更为实用。\n\nCP-coding的基本思想就是在给定的分类级别上，计算出某个特征值发生的概率。这种方法使得我们能够将所有级别的分类特征转化为一个单一的数值型变量。\n\n\n![](http://img.ptcms.csdn.net/article/201507/13/55a2a3b87ef92.jpg)\n\n\n\n然而，这种类型转换可能会因为没有充分描述的类别而造成噪音数据。在上面的例子中，我们只有一个来自House 为 “Tallight”的观测样本。结果相应的概率就是0或1。为了避免这种问题的发生并且降低噪声数据，通常情况下，可以通过考虑加权平均值，全局概率或者引入一个平滑的超系数来调整如何计算概率。\n\n那么，哪一种方法最好呢？这取决于分类特征的数量和级别。CP-coding是个不错的选择，因为他降低了特征的维数，但是这样会牺牲掉特征与特征之间的互信息，这种方法称之为矢量化保留。此外，我们可以整合这两种方法，即组合相似的类别特征，然后使用CP-coding处理整合的特征。\n\n\n### 模型性能评估\n\n当谈及到评估模型性能的时候，我们需要留意正面角色和反面角色的比例。在我们的例子模型中，数据最后的统计格式为[character*period]（下表左）。然而，模型评估应该以角色类别测量（下表右）。\n\n\n![](http://img.ptcms.csdn.net/article/201507/13/55a2a3fb5a353.jpg)\n\n结果，在模型的构建数据和模型的评估数据之间的正面人物和反面人物的比例有着明显的差异。当评估模型准确率和召回率的时候分配合适的权重值是相当重要的。\n\n此外，因为我们可能会使用下采样以减少观测样本的数量，所以我们还需要调整模型占采样过程的准确率和召回率。\n\n### 评估准确率和召回率\n\n对于模型评估的两种主要的评估度量是准确率（Precision）和召回率（Recall）。在我们的例子当中，准确率是预测结果为反面角色中被正确预测为反面角色的比例。它在给定的阈值下衡量模型的准确度。另外，召回率是模型从原本为反面角色当中能够正确检测出为反面角色的比例。它在一个给定的阈值下以识别反面人物来衡量模型的综合指标。这两个变量很容易混淆，所以通过下表会更加的直观看出两者的不同。\n\n![](http://img.ptcms.csdn.net/article/201507/13/55a2a428441f6.jpg)\n\n通常将最后的数据划分为四个不同的部分：\n\nTrue Positives（TP）：角色是反面人物，模型预测为反面人物； \nFalse Positives（FP）：角色是正面人物，模型预测为反面人物； \nTrue Negatives（TN）：角色是正面人物，模型预测为正面人物； \nFalse Negatives（FN）：角色是反面人物，模型预测为正面人物；\n准确率计算：在所有被预测为反面人物中，模型正确预测的比例，即TP /（TP + FP）。\n\n召回率计算：在所有原本就是反面人物中，模型正确预测的比例，即TP / (TP + FN）。\n\n通过观察可以看出，尽管准确率和召回率的分子是相同的，但分母不同。\n\n通常在选择高准确率和高召回率之间总有一种权衡。这要取决于构建模型的最终目的，对于某些情况而言，高准确率的选择可能会优于高召回率。然而，对于欺诈预测模型，通常要偏向于高召回率，即使会牺牲掉一些准确率。\n\n有许多的方式可以用来改善模型的准确度和召回率。其中包括添加更好的特征，优化决策树剪枝或者建立一个更大的森林等等。不过，鉴于讨论广泛，我打算将其单独地放在一篇文章当中。\n\n\n### 结束语\n\n希望这篇文章能让读者了解到什么是构建机器学习模型所需要的。遗憾的是，没有放之四海而皆准的解决方案来构建一种好的模型，充分了解数据的上下文是关键，因为通过它我们能够从中提取出更多更好的预测特征，从而建立出更优化的模型。\n\n最后，虽然将角色分为正面和反面是主观的，但类别标签的确是机器学习的一个非常重要的部分，而不好的类别标签通常会导致一个糟糕的模型。祝建模快乐!\n\n注：这个模型确保每个角色都是正面角色或者是反面角色，即如果他们生来就是反面角色，那么在他们的整个生命当中都是反面角色。如果我们假设角色可以跨越类别标签作为中立人物，那么模型的设计将会完全不同。\n\n英文原文： [Designing Machine Learning Models: A Tale of Precision and Recall](http://nerds.airbnb.com/designing-machine-learning-models/)（译者/刘帝伟 审校/刘翔宇、朱正贵 责编/周建丁）\n\n关于译者： [刘帝伟](http://my.csdn.net/Dream_angel_Z)，中南大学在读研究生，关注机器学习、数据挖掘及生物信息领域。 \n\n------\n\n本文为CSDN编译整理，未经允许不得转载，如需转载请联系market#csdn.net(#换成@)\n\n\n---","source":"_posts/2015-07-18-a precision-and-recall.md","raw":"---\nlayout: post\ntitle: \"Airbnb欺诈预测机器学习模型设计：准确率和召回率的故事（译）\"\ndate: 2015-07-18 12:30\ncomments: true\ncategories: ML\ntags: \n\t- Machine Learning\n\t- 译文\n\t- Precision\n\t- Recall\n---\n\n<div style=\"text-align:right;padding-bottom:7px;\">译者：<a href=\"http://blog.csdn.net/dream_angel_z\">刘帝伟</a>   审校：刘翔宇 朱正贵   责编：周建丁</div>\n\n\nAirbnb网站基于允许任何人将闲置的房屋进行长期或短期出租构建商业模式，来自房客或房东的欺诈风险是必须解决的问题。Airbnb信任和安全小组通过构建机器学习模型进行欺诈预测，本文介绍了其设计思想。假想模型是预测某些虚拟人物是否为“反面人物”，基本步骤：构建模型预期，构建训练集和测试集，特征学习，模型性能评估。其中特征转换倾向于采用条件概率编码（CP-coding），评估度量是准确率（Precision）和召回率（Recall），通常偏向于高召回率。\n<!-- more -->\n**以下为全文内容：**\n\n在Airbnb网站上，我们专注于创造一个这样的地方：一个人可以属于任何地方。部分归属感来自于我们用户之间的信任，同时认识到他们的安全是我们最关心的。\n\n虽然我们绝大多数的社区是由友好和可靠的房东和房客组成，但仍然有一小部分用户，他们试图从我们的网站中（非法）获利。这些都是非常罕见的，尽管如此，信任和安全小组还是因此而产生。\n\n信任和安全小组主要是解决任何可能会发生在我们平台的欺诈行为。我们最主要目的是试图保护我们的用户和公司免于不同类型的风险。例如：退款风险——一个绝大多数电子商务企业都熟悉的风险问题。为了减少此类欺诈行为，信任和安全小组的数据科学家构建了不同种类的机器学习模型，用来帮助识别不同类型的风险。想要获得我们模型背后更多的体系结构信息，请参考以前的文章 [机器学习风险系统的设计](http://nerds.airbnb.com/architecting-machine-learning-system-risk/)。\n\n在这篇文章中，我对机器学习的模型建立给了一个简短的思维过程概述。当然，每个模型都有所不同，但希望它能够给读者在关于机器学习中我们如何使用数据来帮助保护我们的用户以及如何改善模型的不同处理方法上带来一个全新的认识。在这篇文章中，我们假设想要构建一个这样的模型：预测某些虚构的角色是否是反面人物。\n\n### 试图预测的是什么？\n\n在模型建立中最基本的问题就是明确你想要用这个模型来预测什么。我知道这个听起来似乎很愚蠢，但很多时候，通过这个问题可以引发出其它更深层的问题。\n\n即使是一个看似简单的角色分类模型，随着我们逐步深入地思考，也可以提出许多更深层的问题。例如，我们想要怎样来给这个模型评分：仅仅是给当前新介绍的角色还是给所有角色？如果是前者，我们想要评分的角色和人物介绍中的角色评分相差多远？如果是后者，我们又该多长时间给这些角色评分呢？\n\n第一个想法可能是根据人物介绍中给每个角色的评分来建立模型。然而，这种模型，我们可能不能随着时间的推移动态地追踪人物的评分。此外，我们可能会因为在介绍时的一些“好”的特征而忽略了潜在的反面人物。\n\n相反，我们还可以建立这样一个模型，只要他/她出现在情节里面就评分一次。这将让我们在每个时间段都会有人物评分并检测出任何异常情况。但是，考虑到在每个角色单独出现的情况下可能没有任何的角色类别发展，所以这可能也不是最实际的方法。\n\n深思熟虑之后，我们决定把模型设计成介于这两种想法之间的模型。例如，建立这样一种模型，在每次有意义的事情发生的时候对角色进行评分，比如结交新盟友，龙族领地占领等等。在这种方式下，我们仍然可以随着时间的变化来跟踪人物的评分，同时，对没有最新进展的角色也不会多加评分。\n\n![](http://img.ptcms.csdn.net/article/201507/13/55a2a2b74a98e.jpg)\n\n### 如何模拟得分？\n\n因为我们的目的是分析每个时期的得分，所以我们的训练集要能反映出某段时间某个角色的类别行为，最后的训练数据集类似于下图：\n\n![](http://img.ptcms.csdn.net/article/201507/13/55a2a2e11dabc_middle.jpg?_=23712)\n\n与每个角色相关的时间不一定是连续的，因为我们关心的是那些有着重要事件发展的时间。\n\n在这个实例当中，Jarden在3个不同的场合有着重要的角色发展并且在一段时间内持续扩充他的军队。相比之下，Dineas 在5个不同的场合有着重要的角色发展并且主管着4个龙族中心基地。\n\n### 采样\n\n在机器学习模型中，从观测数据中下采样是有必要的。采样过程本身很简单，一旦有了所需要的训练数据集，就可以在数据集上做一个基于行的采样。\n\n然而，由于这里描述的模型是处理每个角色多个时期的样本，基于行采样可能会导致这样一种情况，即在建立模型的数据和用来验证的数据之间，场景附加的人物角色被分离开。如下表所示：\n\n\n![](http://img.ptcms.csdn.net/article/201507/13/55a2a304d75b7.jpg)\n\n显然这并不是理想的采样，因为我们没有得到每个角色的整体描述，并且这些缺失的观测数据可能对建立一个好的模型至关重要。\n\n出于这个原因，我们需要做基于角色的采样。这样做能确保在模型数据建立中包含所有场合附加的角色，或者什么都没有。\n\n\n\n\n\n![](http://img.ptcms.csdn.net/article/201507/13/55a2a31c8bc17.jpg)\n\n\n此外，当我们将我们的数据集切分为训练集和测试集时，通常这样的逻辑也适用。\n\n### 特征设计\n\n特征设计是机器学习不可或缺的一部分，通常情况下，在特征种类的选择上，对数据的充分理解有助于形成一个更好的模型设计思路。特征设计的实例包括特征规范化和分类特征处理。\n\n特征规范化是标准化特征的一种方式，允许更合理的对比。如下表所示：\n\n![](http://img.ptcms.csdn.net/article/201507/13/55a2a34d3dd90.jpg)\n\n\n从上表可知，每个人物都有10,000个士兵。然而，Serion掌权长达5年，而Dineas仅仅掌权2年。通过这些人物比较绝对的士兵数量可能并不是非常有效的。但是，通过人物掌权的年份来标准化他们可能会提供更好的见解，并且产生更有预测力的特征。\n\n在分类特征的特征设计上值得单独的写一篇博客文章，因为有很多方式可以去处理它们。特别是对于缺失值的插补，请看一看以前的博客文章—— [使用随机森林分类器处理缺失值](http://nerds.airbnb.com/overcoming-missing-values-in-a-rfc/)。\n\n转换分类特征最常见的方法就是矢量化（也称作one-hot encoding）。然而，在处理有许多不同级别的分类特征时，使用条件概率编码（CP-coding）则更为实用。\n\nCP-coding的基本思想就是在给定的分类级别上，计算出某个特征值发生的概率。这种方法使得我们能够将所有级别的分类特征转化为一个单一的数值型变量。\n\n\n![](http://img.ptcms.csdn.net/article/201507/13/55a2a3b87ef92.jpg)\n\n\n\n然而，这种类型转换可能会因为没有充分描述的类别而造成噪音数据。在上面的例子中，我们只有一个来自House 为 “Tallight”的观测样本。结果相应的概率就是0或1。为了避免这种问题的发生并且降低噪声数据，通常情况下，可以通过考虑加权平均值，全局概率或者引入一个平滑的超系数来调整如何计算概率。\n\n那么，哪一种方法最好呢？这取决于分类特征的数量和级别。CP-coding是个不错的选择，因为他降低了特征的维数，但是这样会牺牲掉特征与特征之间的互信息，这种方法称之为矢量化保留。此外，我们可以整合这两种方法，即组合相似的类别特征，然后使用CP-coding处理整合的特征。\n\n\n### 模型性能评估\n\n当谈及到评估模型性能的时候，我们需要留意正面角色和反面角色的比例。在我们的例子模型中，数据最后的统计格式为[character*period]（下表左）。然而，模型评估应该以角色类别测量（下表右）。\n\n\n![](http://img.ptcms.csdn.net/article/201507/13/55a2a3fb5a353.jpg)\n\n结果，在模型的构建数据和模型的评估数据之间的正面人物和反面人物的比例有着明显的差异。当评估模型准确率和召回率的时候分配合适的权重值是相当重要的。\n\n此外，因为我们可能会使用下采样以减少观测样本的数量，所以我们还需要调整模型占采样过程的准确率和召回率。\n\n### 评估准确率和召回率\n\n对于模型评估的两种主要的评估度量是准确率（Precision）和召回率（Recall）。在我们的例子当中，准确率是预测结果为反面角色中被正确预测为反面角色的比例。它在给定的阈值下衡量模型的准确度。另外，召回率是模型从原本为反面角色当中能够正确检测出为反面角色的比例。它在一个给定的阈值下以识别反面人物来衡量模型的综合指标。这两个变量很容易混淆，所以通过下表会更加的直观看出两者的不同。\n\n![](http://img.ptcms.csdn.net/article/201507/13/55a2a428441f6.jpg)\n\n通常将最后的数据划分为四个不同的部分：\n\nTrue Positives（TP）：角色是反面人物，模型预测为反面人物； \nFalse Positives（FP）：角色是正面人物，模型预测为反面人物； \nTrue Negatives（TN）：角色是正面人物，模型预测为正面人物； \nFalse Negatives（FN）：角色是反面人物，模型预测为正面人物；\n准确率计算：在所有被预测为反面人物中，模型正确预测的比例，即TP /（TP + FP）。\n\n召回率计算：在所有原本就是反面人物中，模型正确预测的比例，即TP / (TP + FN）。\n\n通过观察可以看出，尽管准确率和召回率的分子是相同的，但分母不同。\n\n通常在选择高准确率和高召回率之间总有一种权衡。这要取决于构建模型的最终目的，对于某些情况而言，高准确率的选择可能会优于高召回率。然而，对于欺诈预测模型，通常要偏向于高召回率，即使会牺牲掉一些准确率。\n\n有许多的方式可以用来改善模型的准确度和召回率。其中包括添加更好的特征，优化决策树剪枝或者建立一个更大的森林等等。不过，鉴于讨论广泛，我打算将其单独地放在一篇文章当中。\n\n\n### 结束语\n\n希望这篇文章能让读者了解到什么是构建机器学习模型所需要的。遗憾的是，没有放之四海而皆准的解决方案来构建一种好的模型，充分了解数据的上下文是关键，因为通过它我们能够从中提取出更多更好的预测特征，从而建立出更优化的模型。\n\n最后，虽然将角色分为正面和反面是主观的，但类别标签的确是机器学习的一个非常重要的部分，而不好的类别标签通常会导致一个糟糕的模型。祝建模快乐!\n\n注：这个模型确保每个角色都是正面角色或者是反面角色，即如果他们生来就是反面角色，那么在他们的整个生命当中都是反面角色。如果我们假设角色可以跨越类别标签作为中立人物，那么模型的设计将会完全不同。\n\n英文原文： [Designing Machine Learning Models: A Tale of Precision and Recall](http://nerds.airbnb.com/designing-machine-learning-models/)（译者/刘帝伟 审校/刘翔宇、朱正贵 责编/周建丁）\n\n关于译者： [刘帝伟](http://my.csdn.net/Dream_angel_Z)，中南大学在读研究生，关注机器学习、数据挖掘及生物信息领域。 \n\n------\n\n本文为CSDN编译整理，未经允许不得转载，如需转载请联系market#csdn.net(#换成@)\n\n\n---","slug":"2015-07-18-a precision-and-recall","published":1,"updated":"2016-03-08T08:44:23.384Z","photos":[],"link":"","_id":"cimigpyzu00836cuja3ego36g"},{"layout":"post","title":"一个简单的Python函数运行时间计时器","date":"2015-07-16T12:24:25.000Z","_content":"\n\n在实际开发中，往往想要计算一段代码运行多长时间，下面我将该功能写入到一个函数里面，只要在每个函数前面调用该函数即可，见下面代码：\n\n<!--more-->\n\n```python\n#--------------------------------\nimport time\nfrom functools import wraps  \ndef fun_timer(function):\n    @wraps(function)\n    def function_timer(*args, **kwargs):\n        t0 = time.time()\n        result = function(*args, **kwargs)\n        t1 = time.time()\n        os.system(\" echo Total time running %s: %s seconds\" % (function.func_name, str(t1-t0)) + \" >> timecount.log\")\n        return result\n    return function_timer\n#-----------------------------------\n```\n\n说明：<font color=\"green\">**一个记时器，只要在函数前面写上@fun_timer即可**</font>.\n\n\n---","source":"_posts/2015-07-16 Python timer.md","raw":"---\nlayout: post\ntitle: \"一个简单的Python函数运行时间计时器\"\ndate: 2015-07-16 20:24:25\ncategories: Python\ntag: \n\t- 计时器\n\t- Python\n---\n\n\n在实际开发中，往往想要计算一段代码运行多长时间，下面我将该功能写入到一个函数里面，只要在每个函数前面调用该函数即可，见下面代码：\n\n<!--more-->\n\n```python\n#--------------------------------\nimport time\nfrom functools import wraps  \ndef fun_timer(function):\n    @wraps(function)\n    def function_timer(*args, **kwargs):\n        t0 = time.time()\n        result = function(*args, **kwargs)\n        t1 = time.time()\n        os.system(\" echo Total time running %s: %s seconds\" % (function.func_name, str(t1-t0)) + \" >> timecount.log\")\n        return result\n    return function_timer\n#-----------------------------------\n```\n\n说明：<font color=\"green\">**一个记时器，只要在函数前面写上@fun_timer即可**</font>.\n\n\n---","slug":"2015-07-16 Python timer","published":1,"updated":"2016-03-13T05:58:45.846Z","comments":1,"photos":[],"link":"","_id":"cimigpz03008b6cujcrftv7r6"},{"layout":"post","title":"开发者成功使用机器学习的十大诀窍(译)","date":"2015-07-13T13:53:12.000Z","comments":1,"_content":"\n<div style=\"text-align:right;padding-bottom:7px;\">译者：<a href=\"http://blog.csdn.net/dream_angel_z\">刘帝伟</a>   审校：刘翔宇 朱正贵   责编：周建丁</div>\n\n在提供发现埋藏数据深层的模式的能力上，机器学习有着潜在的能力使得应用程序更加的强大并且更能响应用户的需求。精心调校好的算法能够从巨大的并且互不相同的数据源中提取价值，同时没有人类思考和分析的限制。对于开发者而言，机器学习为应用业务的关键分析提供了希望，从而实现从改善客户体验到提供产品推荐上升至超个性化内容服务的任何应用程序。\n<!-- more -->\n像Amazon和Micorosoft这样的云供应商提供云功能的机器学习解决方案，承诺为开发者提供一个简单的方法，使得机器学习的能力能够融入到他们的应用程序当中，这也算是最近的头条新闻了。承诺似乎很好，但开发者还需谨慎。\n\n对于开发人员而言，基于云的机器学习工具带来了使用机器学习创造和提供新的功能的可能性。然而，当我们使用不当时，这些工具会输出不好的结果，用户可能会因此而感到不安。测试过<a href=\"http://how-old.net/\">微软年龄检测机器学习工具</a>的人都会发现，伴随即插即用的易用性而来的是主要的精度问题——对于关键应用程序或者是重大决策，它应该不值得信赖。\n\n想要在应用程序中成功地融入机器学习的开发者，需要注意以下的一些关键要点：\n\n**1.算法使用的数据越多，它的精度会更加准确，所以如果可能要尽量避免抽样。**机器学习理论在预测误差上有着非常直观的描述。简而言之，在机器学习模型和最优预测（在理论上达到最佳可能的误差）之间的预测误差的差距可以被分解为三个部分：\n\n- 由于没有找到正确函数形式的模型的误差\n- 由于没有找到最佳参数的模型的误差\n- 由于没用使用足够数据的模型的误差\n- 如果训练集有限，它可能无法支撑解决这个问题所需的模型复杂性。统计学的基本规律告诉我们，如果我们可以的话，应该利用所有的数据而不是抽样。\n\n**2.对给定的问题选择效果最好的机器学习算法是决定成败的关键。**例如，梯度提升树（GBT）是一个非常受欢迎的监督学习算法，由于其精度而被业内开发人员广泛使用。然而，尽管其高度受欢迎，我们也不能盲目的把这种算法应用于任何问题上。相反，我们使用的算法应该是能够最佳地拟合数据特征同时能够保证精度的算法。\n\n为了证明这个观点，尝试做这样一个实验，在数据集 <a href=\"http://www.daviddlewis.com/resources/testcollections/rcv1/\">the popular text categorization dataset rcv1</a>上测试GBT算法和线性支持向量机（SVM）算法，并比较两者的精度。我们观察到在这个问题上，就错误率而言，线性SVM要优于GBT算法。这是因为在文本领域当中，数据通常是高维的。一个线性分类器能够在N-1维当中完美的分离出N个样本，所以，一个样本模型在这种数据上通常表现的更好。此外，模型越简单，通过利用有限的训练样本来避免过拟合的方式学习参数，并且提供一个精确的模型，产生的问题也会随之越少。\n\n另一方面，GBT是高度非线性的并且更加强大，但是在这种环境中却更难学习并且更容易发生过拟合，往往结果精度也较低。\n\n**3.为了得到一个更好的模型，必须选择最佳的的算法和相关的参数。**这对于非数据科学家而言可能不容易。现代的机器学习算法有许多的参数可以调整。例如，对于流行的GBT算法单独的就有十二个参数可以设置，其中包括如何控制树的大小，学习率，行或列的采样方法，损失函数，正则化选项等等。一个特有的项目需要在给定的数据集上为每一个参数找到其最优值并且达到最精准的精度，这确实不是一件容易的事。但是为了得到最佳的结果，数据科学家需要训练大量的模型，而直觉和经验会帮助他们根据交叉验证的得分，然后决定使用什么参数再次尝试。\n\n**4.机器学习模型会随着好的数据而变得更好，错误的数据收集和数据处理会降低你建立预测和归纳的机器学习模型的能力。**根据经验，建议仔细审查与主题相关的数据，从而深入了解数据和幕后数据的生成过程。通常这个过程可以识别与记录、特征、值或采样相关的数据质量问题。\n\n**5.理解数据特征并改进它们（通过创造新的特征或者去掉某个特征）对预测能力有着高度的影响。**机器学习的一个基本任务就是找到能够被机器学习算法充分利用的丰富特征空间来替代原始数据。例如，特征转换是一种流行的方法，可以通过在原始数据的基础上使用数学上的转换提取新的特征来实现。最后的特征空间（也就是最后用来描述数据的特征）要能更好的捕获数据的多复杂性（如非线性和多种特征之间的相互作用），这对于成功的学习过程至关重要。\n\n**6.在应用中，选择合适的灵感来自商业价值的目标函数/损失函数对于最后的成功至关重要。**几乎所有的机器学习算法最后都被当成是一种优化问题。根据业务的性质，合理设置或调整优化的目标函数，是机器学习成功的关键。\n\n以支持向量机为例，通过假设所有错误类型的权重相等，对一个二分类问题的泛化误差进行了优化。这对损失敏感的问题并不合适，如故障检测，其中某些类型的错误比重可能比其它类型的要高。在这种情况下，建议通过在特定的错误类型上，增加更多的惩罚来解释它们的权重，从而调整SVM的损失函数。\n\n**7.确保正确地处理训练数据和测试数据，如此当在生产中部署该模型时，测试数据能够模拟输入数据。**例如，我们可以看到，这对于时间依赖性数据是多么的重要。在这种情况下，使用标准的交叉验证方法进行训练，调整，那么测试模型的结果可能会有偏差，甚至会不准确。这是因为在实施平台上它不能准确的模拟输入数据的性质。为了纠正这一点，在部署时我们必须仿照模型来部署使用。我们应该使用一个基于时间的交叉验证，用时间较新的数据来验证训练模型。\n\n**8.部署前理解模型的泛化误差。泛化误差衡量模型在未知数据上的性能好坏。**因为一个模型在训练数据上的性能好并不意味着它在未知的数据上的表现也好。一个精心设计的模拟实际部署使用的模型评估过程，是估计模型泛化误差所需要的。\n\n一不留心就很容易违反交叉验证的规则，并且也没有一种显而易见的方法来表现交叉验证的非正确性，通常在你试图寻找快捷方式计算时发生。在任何模型部署之前，有必要仔细注意交叉验证的正确性，以获得部署性能的科学评估。\n\n**9.知道如何处理非结构化和半结构化数据，如文本、时间序列、空间、图形或者图像数据。**大多数机器学习算法在处理特征空间中的数据时，一个特征集代表一个对象，特征集的每一个元素都描述对象的一个特点。在实际当中，数据引进时并不是这种格式化的形式，往往来自于最原始的格式，并且最后都必须被改造成机器学习算法能够识别的理想格式。比如，我们必须知道如何使用各种计算机视觉技术从图像中提取特征或者如何将自然语言处理技术应用于影片文本。\n\n**10.学会将商业问题转换成机器学习算法。**一些重要的商业问题，比如欺诈检测、产品推荐、广告精准投放，都有“标准”的机器学习表达形式并且在实践当中取得了合理的成就。即使对于这些众所周知的问题，也还有鲜为人知但功能更强大的表达形式，从而带来更高的预测精度。对于一般在博客和论坛中讨论的小实例的商业问题，适当的机器学习方法则不太明显。\n\n如果你是一个开发者，学习这十个通往成功的诀窍可能似乎是一个艰难的任务，但是不要气馁。事实上，开发者不是数据科学家。认为开发人员可以充分利用所有的机学习工具是不公平的。但是这并不意味着开发人员没有机会去学习一些有水准的数据科学从而改进他们的应用。随着适当的企业解决方案和自动化程度的提高，开发人员可以做模型构建到实施部署的一切事情，使用机器学习最佳实践来保持高精度。\n\n自动化是在应用程序中扩展机器学习的关键。即使你能够供得起一批小的数据科学家团队和开发者携手合作，也没有足够的人才。像Skytree的AutoModel（自动化模型）能够帮助开发者自动地确定最佳的参数并且使得算法得到最大的模型精度。一个易于使用的接口可以引导开发人员通过训练加工，调整并且测试模型来防止统计上的错误。\n\n自动化机器学习过程，有许多方式，包括数据科学家或开发者的人工智能原理，允许算法去思考，学习并且承受更多的建模重任。也就是说，认为数据科学家能够从机器学习中解耦是错误的，特别是在关键任务模型上。谨防这种能够简单使用机器学习功能的承诺，即能够在不需要正确复杂的思考下或者可扩展的应用技术下就使用机器学习——这通常并不会得到高预测精度和机器学习提供的高商业价值结果。更糟糕的是，在应用程序中使用不好的模型实际上可能会适得其反，并迅速在其用户之间建立不信任的产品或服务。\n\n英文原文： <a href=\"http://www.infoworld.com/article/2943862/application-development/what-developers-need-to-know-about-machine-learning.html\">10 keys to successful machine learning for developers</a> （译者/<a href=\"http://blog.csdn.net/dream_angel_z\">刘帝伟</a> 审校/刘翔宇、朱正贵 责编/周建丁）\n\n作者简介：Alexander Gray，Skytree首席技术官，佐治亚理工学院计算机学院副教授，主要致力于大规模数据集的机器学习算法技术研发，1993年开始在NASA喷气推进实验室机器学习系统小组从事大规模科学数据的工作。\n\n译者简介： <a href=\"http://blog.csdn.net/dream_angel_z\">刘帝伟</a>，中南大学软件学院在读研究生，关注机器学习、数据挖掘及生物信息领域。\n\n【预告】<a href=\"http://ccai2015.csdn.net/\">首届中国人工智能大会（CCAI 2015）</a>将于7月26-27日在北京友谊宾馆召开。机器学习与模式识别、大数据的机遇与挑战、人工智能与认知科学、智能机器人四个主题专家云集。人工智能产品库将同步上线，预约咨询：QQ：1192936057。欢迎关注。\n\n本文为CSDN编译整理，未经允许不得转载，如需转载请联系market#csdn.net(#换成@)\n\n---","source":"_posts/2015-07-13-10 keys to successful machine learning for developers.md","raw":"---\nlayout: post\ntitle: \"开发者成功使用机器学习的十大诀窍(译)\"\ndate: 2015-07-13 21:53:12\ncomments: true\ntags: \n\t- Machine Learning\n\t- 译文\n---\n\n<div style=\"text-align:right;padding-bottom:7px;\">译者：<a href=\"http://blog.csdn.net/dream_angel_z\">刘帝伟</a>   审校：刘翔宇 朱正贵   责编：周建丁</div>\n\n在提供发现埋藏数据深层的模式的能力上，机器学习有着潜在的能力使得应用程序更加的强大并且更能响应用户的需求。精心调校好的算法能够从巨大的并且互不相同的数据源中提取价值，同时没有人类思考和分析的限制。对于开发者而言，机器学习为应用业务的关键分析提供了希望，从而实现从改善客户体验到提供产品推荐上升至超个性化内容服务的任何应用程序。\n<!-- more -->\n像Amazon和Micorosoft这样的云供应商提供云功能的机器学习解决方案，承诺为开发者提供一个简单的方法，使得机器学习的能力能够融入到他们的应用程序当中，这也算是最近的头条新闻了。承诺似乎很好，但开发者还需谨慎。\n\n对于开发人员而言，基于云的机器学习工具带来了使用机器学习创造和提供新的功能的可能性。然而，当我们使用不当时，这些工具会输出不好的结果，用户可能会因此而感到不安。测试过<a href=\"http://how-old.net/\">微软年龄检测机器学习工具</a>的人都会发现，伴随即插即用的易用性而来的是主要的精度问题——对于关键应用程序或者是重大决策，它应该不值得信赖。\n\n想要在应用程序中成功地融入机器学习的开发者，需要注意以下的一些关键要点：\n\n**1.算法使用的数据越多，它的精度会更加准确，所以如果可能要尽量避免抽样。**机器学习理论在预测误差上有着非常直观的描述。简而言之，在机器学习模型和最优预测（在理论上达到最佳可能的误差）之间的预测误差的差距可以被分解为三个部分：\n\n- 由于没有找到正确函数形式的模型的误差\n- 由于没有找到最佳参数的模型的误差\n- 由于没用使用足够数据的模型的误差\n- 如果训练集有限，它可能无法支撑解决这个问题所需的模型复杂性。统计学的基本规律告诉我们，如果我们可以的话，应该利用所有的数据而不是抽样。\n\n**2.对给定的问题选择效果最好的机器学习算法是决定成败的关键。**例如，梯度提升树（GBT）是一个非常受欢迎的监督学习算法，由于其精度而被业内开发人员广泛使用。然而，尽管其高度受欢迎，我们也不能盲目的把这种算法应用于任何问题上。相反，我们使用的算法应该是能够最佳地拟合数据特征同时能够保证精度的算法。\n\n为了证明这个观点，尝试做这样一个实验，在数据集 <a href=\"http://www.daviddlewis.com/resources/testcollections/rcv1/\">the popular text categorization dataset rcv1</a>上测试GBT算法和线性支持向量机（SVM）算法，并比较两者的精度。我们观察到在这个问题上，就错误率而言，线性SVM要优于GBT算法。这是因为在文本领域当中，数据通常是高维的。一个线性分类器能够在N-1维当中完美的分离出N个样本，所以，一个样本模型在这种数据上通常表现的更好。此外，模型越简单，通过利用有限的训练样本来避免过拟合的方式学习参数，并且提供一个精确的模型，产生的问题也会随之越少。\n\n另一方面，GBT是高度非线性的并且更加强大，但是在这种环境中却更难学习并且更容易发生过拟合，往往结果精度也较低。\n\n**3.为了得到一个更好的模型，必须选择最佳的的算法和相关的参数。**这对于非数据科学家而言可能不容易。现代的机器学习算法有许多的参数可以调整。例如，对于流行的GBT算法单独的就有十二个参数可以设置，其中包括如何控制树的大小，学习率，行或列的采样方法，损失函数，正则化选项等等。一个特有的项目需要在给定的数据集上为每一个参数找到其最优值并且达到最精准的精度，这确实不是一件容易的事。但是为了得到最佳的结果，数据科学家需要训练大量的模型，而直觉和经验会帮助他们根据交叉验证的得分，然后决定使用什么参数再次尝试。\n\n**4.机器学习模型会随着好的数据而变得更好，错误的数据收集和数据处理会降低你建立预测和归纳的机器学习模型的能力。**根据经验，建议仔细审查与主题相关的数据，从而深入了解数据和幕后数据的生成过程。通常这个过程可以识别与记录、特征、值或采样相关的数据质量问题。\n\n**5.理解数据特征并改进它们（通过创造新的特征或者去掉某个特征）对预测能力有着高度的影响。**机器学习的一个基本任务就是找到能够被机器学习算法充分利用的丰富特征空间来替代原始数据。例如，特征转换是一种流行的方法，可以通过在原始数据的基础上使用数学上的转换提取新的特征来实现。最后的特征空间（也就是最后用来描述数据的特征）要能更好的捕获数据的多复杂性（如非线性和多种特征之间的相互作用），这对于成功的学习过程至关重要。\n\n**6.在应用中，选择合适的灵感来自商业价值的目标函数/损失函数对于最后的成功至关重要。**几乎所有的机器学习算法最后都被当成是一种优化问题。根据业务的性质，合理设置或调整优化的目标函数，是机器学习成功的关键。\n\n以支持向量机为例，通过假设所有错误类型的权重相等，对一个二分类问题的泛化误差进行了优化。这对损失敏感的问题并不合适，如故障检测，其中某些类型的错误比重可能比其它类型的要高。在这种情况下，建议通过在特定的错误类型上，增加更多的惩罚来解释它们的权重，从而调整SVM的损失函数。\n\n**7.确保正确地处理训练数据和测试数据，如此当在生产中部署该模型时，测试数据能够模拟输入数据。**例如，我们可以看到，这对于时间依赖性数据是多么的重要。在这种情况下，使用标准的交叉验证方法进行训练，调整，那么测试模型的结果可能会有偏差，甚至会不准确。这是因为在实施平台上它不能准确的模拟输入数据的性质。为了纠正这一点，在部署时我们必须仿照模型来部署使用。我们应该使用一个基于时间的交叉验证，用时间较新的数据来验证训练模型。\n\n**8.部署前理解模型的泛化误差。泛化误差衡量模型在未知数据上的性能好坏。**因为一个模型在训练数据上的性能好并不意味着它在未知的数据上的表现也好。一个精心设计的模拟实际部署使用的模型评估过程，是估计模型泛化误差所需要的。\n\n一不留心就很容易违反交叉验证的规则，并且也没有一种显而易见的方法来表现交叉验证的非正确性，通常在你试图寻找快捷方式计算时发生。在任何模型部署之前，有必要仔细注意交叉验证的正确性，以获得部署性能的科学评估。\n\n**9.知道如何处理非结构化和半结构化数据，如文本、时间序列、空间、图形或者图像数据。**大多数机器学习算法在处理特征空间中的数据时，一个特征集代表一个对象，特征集的每一个元素都描述对象的一个特点。在实际当中，数据引进时并不是这种格式化的形式，往往来自于最原始的格式，并且最后都必须被改造成机器学习算法能够识别的理想格式。比如，我们必须知道如何使用各种计算机视觉技术从图像中提取特征或者如何将自然语言处理技术应用于影片文本。\n\n**10.学会将商业问题转换成机器学习算法。**一些重要的商业问题，比如欺诈检测、产品推荐、广告精准投放，都有“标准”的机器学习表达形式并且在实践当中取得了合理的成就。即使对于这些众所周知的问题，也还有鲜为人知但功能更强大的表达形式，从而带来更高的预测精度。对于一般在博客和论坛中讨论的小实例的商业问题，适当的机器学习方法则不太明显。\n\n如果你是一个开发者，学习这十个通往成功的诀窍可能似乎是一个艰难的任务，但是不要气馁。事实上，开发者不是数据科学家。认为开发人员可以充分利用所有的机学习工具是不公平的。但是这并不意味着开发人员没有机会去学习一些有水准的数据科学从而改进他们的应用。随着适当的企业解决方案和自动化程度的提高，开发人员可以做模型构建到实施部署的一切事情，使用机器学习最佳实践来保持高精度。\n\n自动化是在应用程序中扩展机器学习的关键。即使你能够供得起一批小的数据科学家团队和开发者携手合作，也没有足够的人才。像Skytree的AutoModel（自动化模型）能够帮助开发者自动地确定最佳的参数并且使得算法得到最大的模型精度。一个易于使用的接口可以引导开发人员通过训练加工，调整并且测试模型来防止统计上的错误。\n\n自动化机器学习过程，有许多方式，包括数据科学家或开发者的人工智能原理，允许算法去思考，学习并且承受更多的建模重任。也就是说，认为数据科学家能够从机器学习中解耦是错误的，特别是在关键任务模型上。谨防这种能够简单使用机器学习功能的承诺，即能够在不需要正确复杂的思考下或者可扩展的应用技术下就使用机器学习——这通常并不会得到高预测精度和机器学习提供的高商业价值结果。更糟糕的是，在应用程序中使用不好的模型实际上可能会适得其反，并迅速在其用户之间建立不信任的产品或服务。\n\n英文原文： <a href=\"http://www.infoworld.com/article/2943862/application-development/what-developers-need-to-know-about-machine-learning.html\">10 keys to successful machine learning for developers</a> （译者/<a href=\"http://blog.csdn.net/dream_angel_z\">刘帝伟</a> 审校/刘翔宇、朱正贵 责编/周建丁）\n\n作者简介：Alexander Gray，Skytree首席技术官，佐治亚理工学院计算机学院副教授，主要致力于大规模数据集的机器学习算法技术研发，1993年开始在NASA喷气推进实验室机器学习系统小组从事大规模科学数据的工作。\n\n译者简介： <a href=\"http://blog.csdn.net/dream_angel_z\">刘帝伟</a>，中南大学软件学院在读研究生，关注机器学习、数据挖掘及生物信息领域。\n\n【预告】<a href=\"http://ccai2015.csdn.net/\">首届中国人工智能大会（CCAI 2015）</a>将于7月26-27日在北京友谊宾馆召开。机器学习与模式识别、大数据的机遇与挑战、人工智能与认知科学、智能机器人四个主题专家云集。人工智能产品库将同步上线，预约咨询：QQ：1192936057。欢迎关注。\n\n本文为CSDN编译整理，未经允许不得转载，如需转载请联系market#csdn.net(#换成@)\n\n---","slug":"2015-07-13-10 keys to successful machine learning for developers","published":1,"updated":"2016-03-13T05:58:58.804Z","photos":[],"link":"","_id":"cimigpz08008g6cujjwuzehkx"},{"layout":"post","date":"2015-07-07T15:23:23.000Z","title":"数据预处理-PDB文件","comments":1,"_content":"\n以下代码为个人原创，python实现，是处理PDB文件的部分常用代码，仅供参考！\n\n### 1.下载PDB文件\n\n下面是一个下载PDB文件的函数，传入的参数是一个写有pdb名字的namefile文件，函数的核心部分是三个系统命令，先通过wget下载，然后解压，最后替换名字。\n\n<!-- more -->\n\n```python\ndef downloadpdb(namefile):\n    inputfile = open(namefile, 'r')\n    for eachline in inputfile:\n        pdbname = eachline.lower().strip()\n        os.system(\"wget http://ftp.wwpdb.org/pub/pdb/data/structures/all/pdb/pdb\" + pdbname + \".ent.gz\")\n        os.system(\"gzip -d pdb\" + pdbname + '.ent.gz')\n        os.system(\"mv pdb\" + pdbname + \".ent \" + pdbname.upper() + '.pdb')\n```\n\n测试用例\n\n```python\nos.chdir('/ifs/home/liudiwei/datasets/RPdatas')\ndownloadpdb('protein.name')\n```\n\n### 2.PDB转DSSP\n\n将下载的PDB文件转成DSSP文件\n\n```python\n# 处理一行dssp数据\ndef formatdsspline(dsspline):\n    eachline  = dsspline\n    col = '\\t' + eachline[0:5]\n    col += '\\t' + eachline[5:10]\n    col += '\\t' + eachline[10:12]\n    col += '\\t' + eachline[12:15]\n    col += '\\t' + eachline[15:25]\n    col += '\\t' + eachline[25:39]\n    col += '\\t' + eachline[29:34]\n    col += '\\t' + eachline[34:38]\n    col += '\\t' + eachline[38:50]\n    col += '\\t' + eachline[50:61]\n    col += '\\t' + eachline[61:72]\n    col += '\\t' + eachline[72:83]\n    col += '\\t' + eachline[83:92]\n    col += '\\t' + eachline[92:97]\n    col += '\\t' + eachline[97:103]\n    col += '\\t' + eachline[103:109]\n    col += '\\t' + eachline[109:115]\n    col += '\\t' + eachline[115:122]\n    col += '\\t' + eachline[122:129]\n    col += '\\t' + eachline[129:136]\n    return col\n```\n\n\nPDB转DSSP格式，需要DSSP软件\n\n参数：\n\n- pdbdir: pdb文件目录   \n- dsspdir: 生成的dssp文件目录（需创建）\n\n```python\ndef pdbToDSSP(pdbnamefile,pdbdir, dsspdir):    \n    pdbfiles = os.listdir(pdbdir)\n    #对于每个pdb文件，生成对应的dssp文件，并保存在dssp目录下\n    for pdb_file in pdbfiles:\n        pdb_name = pdb_file.split('.')[0].upper()\n        command = 'DSSPCMBI.EXE -x ' + pdbdir +'/'+ pdb_file + '  '+ dsspdir +\"/\"+ pdb_name +'.dssp'\n        os.system(command) \n    dsspfiles = os.listdir(dsspdir)\n    if os.path.exists(dsspdir + \"/DSSP\"):      #判断DSSP文件是否存在，存在则删除\n        dsspfiles.remove(\"DSSP\")\n    output=open(dsspdir + '/DSSP','w')\n    #循环读取dssp文件，将其合并成一个整的DSSP\n    with open(pdbnamefile, 'r') as namefile:\n        for eachline in namefile:\n            pdb_name = eachline.strip() \n            dssp_file = pdb_name + '.dssp'\n        #for dssp_file in dsspfiles:\n            #pdb_name = dssp_file.split('.')[0]\n            with open(dsspdir + '/' + dssp_file,\"r\") as f:\n                if not os.path.isdir(dsspdir + '/format'):\n                    os.mkdir(dsspdir + '/format')\n                with open(dsspdir + '/format/' + pdb_name + '.dssp.format','w') as singleOut:\n                    count = 0; preRes=[]\n                    sets = set('');content=''   \n                    for eachline in f.readlines():\n                        list1=[];oneline=[]\n                        count+=1\n                        list1.append(pdb_name)                             \n                        if count >= 29:\n                            eachline = formatdsspline(eachline)\n                            oneline = eachline.split('\\t')\n\n                            if oneline[3].strip():\n                                preRes = oneline[3].strip()                        \n                            \n                            list1.append(eachline)\n                            content += \"\".join(list1)+'\\n'                            \n                            \n                            if '!' == oneline[4].strip():\n                                continue\n                            \n                            if '!*' in eachline or not oneline[3].strip():\n                                if preRes in sets and len(sets):\n                                    content=''\n                                    preRes=[]\n                                    continue\n                                sets.add(preRes)\n                                output.write(content)\n                                singleOut.write(content)\n                                content=''\n                    if preRes and preRes not in sets:\n                        output.write(content)\n                        singleOut.write(content)\n    output.close()\n```\n\n测试\n\n```python\n#test\npdbdir = 'z:/datasets/protein/pdb'\ndsspdir = 'Z:/datasets/protein/DSSPdir' \nproname = 'Z:/datasets/protein/protein.name'\npdbToDSSP(proname,pdbdir, dsspdir)\n```\n### 3.DSSP抽取序列\n从一个整合的DSSP文件中抽取序列文件 \n\n从格式化后的dssp文件获取序列信息\n\n参数：dsspfile为格式过的DSSP文件,seqfile为输出的序列文件,同时输出序列文件\n\n```python\ndef getSeqFromDSSP(dsspfile, seqfile, minLen):\n    with open(dsspfile, 'r') as inputfile:\n        if not seqfile.strip():\n            seqfile = 'protein'+minLen + '.dssp.seq'\n        outchain = open('protein40.chain.all', 'w')\n        with open(seqfile, 'w') as outputfile:\n            residue=[];Ntype=[]\n            preType=[];preRes=[]\n            firstline=[];secondline=[];content=''\n            for eachline in inputfile:\n                oneline = eachline.split('\\t')\n                residue = oneline[0]\n                if not residue.strip(): \n                    continue\n                Ntype = oneline[3].strip()\n                if not Ntype.strip():\n                    continue\n                if preRes!=residue:\n                    content = ''.join(firstline)+'\\n' + ''.join(secondline) +'\\n'\n                    if len(secondline) >=minLen and not 'X' in secondline:\n                        outchain.write(''.join(firstline) + '\\n')\n                        outputfile.write(content)\n                    firstline=[]\n                    firstline.append('>' + residue + ':' + Ntype)\n                    secondline=[];secondline.append(oneline[4].strip())\n                    preRes = residue;preType = Ntype\n                    continue\n                if Ntype != preType:\n                    content = ''.join(firstline)+'\\n' + ''.join(secondline) +'\\n'\n                    if len(secondline) >=minLen and  not 'X' in secondline:\n                        outchain.write(''.join(firstline) + '\\n')\n                        outputfile.write(content)\n                    firstline=[]\n                    firstline.append('>' + residue + ':' + Ntype)\n                    secondline=[];secondline.append(oneline[4].strip())\n                    preRes = residue;preType = Ntype\n                else: #如果Ntype不为空，且等于preType\n                    secondline.append(oneline[4].strip())\n            content = ''.join(firstline)+'\\n' + ''.join(secondline) +'\\n'\n            if len(secondline) >=minLen and not 'X' in secondline:  #选择长度大于40\n                outchain.write(''.join(firstline) + '\\n')\n                outputfile.write(content)\n        outchain.close()\n```\n测试：\n\n```\nos.chdir(r\"E:\\3-CSU\\Academic\\_Oriented\\analysis\\experiment\\Datasets\\ptest.dssp\")\npdbfile = 'DSSP'\noutfile = 'protein.seq'\ngetSeqFromDSSP(pdbfile,outfile)\n```\n\n### 4.对序列做blast聚类\n设置相应的参数，在服务器上跑blast，代码如下：\n\n```python\nifs/share/lib/cd-hit-v4.5.4/cd-hit -i /ifs/home/liudiwei/datasets/protein40.seq -o /ifs/home/liudiwei/experiment/cdhit/fasta.40 -c 0.4 -n 2 -M 2000\n```\n\n### 5.生成聚类后的DSSP，得到protein.name、protein.seq、protein.chain三个文件\n\n从原来的DSSP文件中，根据聚类后的链名抽取新的DSSP文件\n\n```python\n # extract dssp from old dssp file\ndef extractDSSP(dsspfile, chainname, outfile):\n    with open(outfile, 'w') as outdssp:\n        with open(dsspfile, 'r') as inputdssp:\n            for eachline in inputdssp:\n                oneline = eachline.split('\\t')\n                #preNum = oneline[2].strip()     \n                with open(chainname,'r') as chainfile:       \n                    for eachchain in chainfile:\n                        protein_ame = eachchain[1:5]\n                        chain_id = eachchain[6:7]\n                        if oneline[0].strip() == protein_ame and oneline[3].strip() == chain_id:\n                            outdssp.write(eachline)\n                            break\n```\n\n测试实例：\n\n```python\ndsspfile = '/ifs/home/liudiwei/datasets/832.protein/DSSPdir1/DSSP'\nchainname = '/ifs/home/liudiwei/experiment/step1/832p.cluster/cdhit/protein.chain'\noutfile = '/ifs/home/liudiwei/experiment/step1/832p.cluster/cdhit/DSSP'\nextractDSSP(dsspfile, chainname, outfile )\n```\n\n\n-----\n\n","source":"_posts/2015-07-07-PDB.md","raw":"---\nlayout: post\ndate: 2015-07-07 23:23:23\ntitle: \"数据预处理-PDB文件\"\ntags: \n\t- BioInfo\n\t- PDB\n\t- 预处理\ncomments: true\nexcerpt: 以下代码为个人原创，python实现，是处理PDB文件的常用代码，仅供参考！1.下载PDB文件下面是一个下载PDB文件的函数，传入的参数是一个写有pdb名字的namefile文件，函数的核心部分是三个系统命令，先通过wget下载，然后解压，最后替换名字。def downloadpdb(namefile)\ncategories: BioInfo\n---\n\n以下代码为个人原创，python实现，是处理PDB文件的部分常用代码，仅供参考！\n\n### 1.下载PDB文件\n\n下面是一个下载PDB文件的函数，传入的参数是一个写有pdb名字的namefile文件，函数的核心部分是三个系统命令，先通过wget下载，然后解压，最后替换名字。\n\n<!-- more -->\n\n```python\ndef downloadpdb(namefile):\n    inputfile = open(namefile, 'r')\n    for eachline in inputfile:\n        pdbname = eachline.lower().strip()\n        os.system(\"wget http://ftp.wwpdb.org/pub/pdb/data/structures/all/pdb/pdb\" + pdbname + \".ent.gz\")\n        os.system(\"gzip -d pdb\" + pdbname + '.ent.gz')\n        os.system(\"mv pdb\" + pdbname + \".ent \" + pdbname.upper() + '.pdb')\n```\n\n测试用例\n\n```python\nos.chdir('/ifs/home/liudiwei/datasets/RPdatas')\ndownloadpdb('protein.name')\n```\n\n### 2.PDB转DSSP\n\n将下载的PDB文件转成DSSP文件\n\n```python\n# 处理一行dssp数据\ndef formatdsspline(dsspline):\n    eachline  = dsspline\n    col = '\\t' + eachline[0:5]\n    col += '\\t' + eachline[5:10]\n    col += '\\t' + eachline[10:12]\n    col += '\\t' + eachline[12:15]\n    col += '\\t' + eachline[15:25]\n    col += '\\t' + eachline[25:39]\n    col += '\\t' + eachline[29:34]\n    col += '\\t' + eachline[34:38]\n    col += '\\t' + eachline[38:50]\n    col += '\\t' + eachline[50:61]\n    col += '\\t' + eachline[61:72]\n    col += '\\t' + eachline[72:83]\n    col += '\\t' + eachline[83:92]\n    col += '\\t' + eachline[92:97]\n    col += '\\t' + eachline[97:103]\n    col += '\\t' + eachline[103:109]\n    col += '\\t' + eachline[109:115]\n    col += '\\t' + eachline[115:122]\n    col += '\\t' + eachline[122:129]\n    col += '\\t' + eachline[129:136]\n    return col\n```\n\n\nPDB转DSSP格式，需要DSSP软件\n\n参数：\n\n- pdbdir: pdb文件目录   \n- dsspdir: 生成的dssp文件目录（需创建）\n\n```python\ndef pdbToDSSP(pdbnamefile,pdbdir, dsspdir):    \n    pdbfiles = os.listdir(pdbdir)\n    #对于每个pdb文件，生成对应的dssp文件，并保存在dssp目录下\n    for pdb_file in pdbfiles:\n        pdb_name = pdb_file.split('.')[0].upper()\n        command = 'DSSPCMBI.EXE -x ' + pdbdir +'/'+ pdb_file + '  '+ dsspdir +\"/\"+ pdb_name +'.dssp'\n        os.system(command) \n    dsspfiles = os.listdir(dsspdir)\n    if os.path.exists(dsspdir + \"/DSSP\"):      #判断DSSP文件是否存在，存在则删除\n        dsspfiles.remove(\"DSSP\")\n    output=open(dsspdir + '/DSSP','w')\n    #循环读取dssp文件，将其合并成一个整的DSSP\n    with open(pdbnamefile, 'r') as namefile:\n        for eachline in namefile:\n            pdb_name = eachline.strip() \n            dssp_file = pdb_name + '.dssp'\n        #for dssp_file in dsspfiles:\n            #pdb_name = dssp_file.split('.')[0]\n            with open(dsspdir + '/' + dssp_file,\"r\") as f:\n                if not os.path.isdir(dsspdir + '/format'):\n                    os.mkdir(dsspdir + '/format')\n                with open(dsspdir + '/format/' + pdb_name + '.dssp.format','w') as singleOut:\n                    count = 0; preRes=[]\n                    sets = set('');content=''   \n                    for eachline in f.readlines():\n                        list1=[];oneline=[]\n                        count+=1\n                        list1.append(pdb_name)                             \n                        if count >= 29:\n                            eachline = formatdsspline(eachline)\n                            oneline = eachline.split('\\t')\n\n                            if oneline[3].strip():\n                                preRes = oneline[3].strip()                        \n                            \n                            list1.append(eachline)\n                            content += \"\".join(list1)+'\\n'                            \n                            \n                            if '!' == oneline[4].strip():\n                                continue\n                            \n                            if '!*' in eachline or not oneline[3].strip():\n                                if preRes in sets and len(sets):\n                                    content=''\n                                    preRes=[]\n                                    continue\n                                sets.add(preRes)\n                                output.write(content)\n                                singleOut.write(content)\n                                content=''\n                    if preRes and preRes not in sets:\n                        output.write(content)\n                        singleOut.write(content)\n    output.close()\n```\n\n测试\n\n```python\n#test\npdbdir = 'z:/datasets/protein/pdb'\ndsspdir = 'Z:/datasets/protein/DSSPdir' \nproname = 'Z:/datasets/protein/protein.name'\npdbToDSSP(proname,pdbdir, dsspdir)\n```\n### 3.DSSP抽取序列\n从一个整合的DSSP文件中抽取序列文件 \n\n从格式化后的dssp文件获取序列信息\n\n参数：dsspfile为格式过的DSSP文件,seqfile为输出的序列文件,同时输出序列文件\n\n```python\ndef getSeqFromDSSP(dsspfile, seqfile, minLen):\n    with open(dsspfile, 'r') as inputfile:\n        if not seqfile.strip():\n            seqfile = 'protein'+minLen + '.dssp.seq'\n        outchain = open('protein40.chain.all', 'w')\n        with open(seqfile, 'w') as outputfile:\n            residue=[];Ntype=[]\n            preType=[];preRes=[]\n            firstline=[];secondline=[];content=''\n            for eachline in inputfile:\n                oneline = eachline.split('\\t')\n                residue = oneline[0]\n                if not residue.strip(): \n                    continue\n                Ntype = oneline[3].strip()\n                if not Ntype.strip():\n                    continue\n                if preRes!=residue:\n                    content = ''.join(firstline)+'\\n' + ''.join(secondline) +'\\n'\n                    if len(secondline) >=minLen and not 'X' in secondline:\n                        outchain.write(''.join(firstline) + '\\n')\n                        outputfile.write(content)\n                    firstline=[]\n                    firstline.append('>' + residue + ':' + Ntype)\n                    secondline=[];secondline.append(oneline[4].strip())\n                    preRes = residue;preType = Ntype\n                    continue\n                if Ntype != preType:\n                    content = ''.join(firstline)+'\\n' + ''.join(secondline) +'\\n'\n                    if len(secondline) >=minLen and  not 'X' in secondline:\n                        outchain.write(''.join(firstline) + '\\n')\n                        outputfile.write(content)\n                    firstline=[]\n                    firstline.append('>' + residue + ':' + Ntype)\n                    secondline=[];secondline.append(oneline[4].strip())\n                    preRes = residue;preType = Ntype\n                else: #如果Ntype不为空，且等于preType\n                    secondline.append(oneline[4].strip())\n            content = ''.join(firstline)+'\\n' + ''.join(secondline) +'\\n'\n            if len(secondline) >=minLen and not 'X' in secondline:  #选择长度大于40\n                outchain.write(''.join(firstline) + '\\n')\n                outputfile.write(content)\n        outchain.close()\n```\n测试：\n\n```\nos.chdir(r\"E:\\3-CSU\\Academic\\_Oriented\\analysis\\experiment\\Datasets\\ptest.dssp\")\npdbfile = 'DSSP'\noutfile = 'protein.seq'\ngetSeqFromDSSP(pdbfile,outfile)\n```\n\n### 4.对序列做blast聚类\n设置相应的参数，在服务器上跑blast，代码如下：\n\n```python\nifs/share/lib/cd-hit-v4.5.4/cd-hit -i /ifs/home/liudiwei/datasets/protein40.seq -o /ifs/home/liudiwei/experiment/cdhit/fasta.40 -c 0.4 -n 2 -M 2000\n```\n\n### 5.生成聚类后的DSSP，得到protein.name、protein.seq、protein.chain三个文件\n\n从原来的DSSP文件中，根据聚类后的链名抽取新的DSSP文件\n\n```python\n # extract dssp from old dssp file\ndef extractDSSP(dsspfile, chainname, outfile):\n    with open(outfile, 'w') as outdssp:\n        with open(dsspfile, 'r') as inputdssp:\n            for eachline in inputdssp:\n                oneline = eachline.split('\\t')\n                #preNum = oneline[2].strip()     \n                with open(chainname,'r') as chainfile:       \n                    for eachchain in chainfile:\n                        protein_ame = eachchain[1:5]\n                        chain_id = eachchain[6:7]\n                        if oneline[0].strip() == protein_ame and oneline[3].strip() == chain_id:\n                            outdssp.write(eachline)\n                            break\n```\n\n测试实例：\n\n```python\ndsspfile = '/ifs/home/liudiwei/datasets/832.protein/DSSPdir1/DSSP'\nchainname = '/ifs/home/liudiwei/experiment/step1/832p.cluster/cdhit/protein.chain'\noutfile = '/ifs/home/liudiwei/experiment/step1/832p.cluster/cdhit/DSSP'\nextractDSSP(dsspfile, chainname, outfile )\n```\n\n\n-----\n\n","slug":"2015-07-07-PDB","published":1,"updated":"2016-03-08T08:48:57.705Z","photos":[],"link":"","_id":"cimigpz0d008j6cuj5b49oxml"},{"layout":"post","title":"机器学习算法-Adaboost","date":"2015-07-05T14:53:12.000Z","comments":1,"_content":"\nGithub源码实现:[链接](https://github.com/csuldw/MachineLearning/tree/master/Adaboost)\n\n\n## **本章内容**\n\n- 组合算法\n- AdaBoost算法的使用\n- 非均衡数据集分类\n\n<!-- more -->\n\n\n## **主题：**\n\n本文主要介绍的是Adaboost算法，**利用AdaBoost元算法来提高分类器的性能**，主要参考《机器学习实战》来学习Adaboost，同时结合Wikipedia以及网上各位童鞋的资料分享等等。希望通过总结达到学习效果。\n\n\n## 1.基于数据集多重抽样的分类器\n\n先来看看Adaboost的优缺点。\n\n| Feature |AdaBoost  |\n| -- | -- |\n| 优点 |  泛化错误率低，易编码，可以应用在大部分分类器上，无需参数调整 |\n| 缺点 |  对离群点敏感 |\n| 数据 | 数值型和标称型数据 |\n\n\n再来看看bagging和boosting的不同：\n\n- bagging: 基于数据随机重抽样的分类器构建方法\n\n自举汇聚法(bootstrap aggregating),也叫做bagging方法，是从原始数据集选择S次（有放回的抽取）后得到S个新数据集的一种技术。新数据集和原始数据集的大小相等（<font color=\"#007FFF\">**维数和列数都相等**</font>）。每个数据集都是通过在原始数据集中随机选择一个来进行替换而得到的。\n\n在S个数据集建好之后，将某个机器学习算法分别作用域每个数据集就可以得到S个分类器。当我们对新数据进行分类时，就可以应用S个分类器进行分类。与此同时，选择分类器<font color=\"#007fff\">**投票结果最多的类别作为最后的分类结果**</font>。\n\n目前，有一种改进的bagging方法，如**随机森林**（RF,随机森林不同的是，它对列也进行采样），它在一定程度上可以防止过拟合，也是对决策树的一种改进。\n\nboosting是一种与bagging很类似的技术。不论是boosting还是bagging当中，当使用的多个分类器的类型都是一致的。但是在前者当中，不同的分类器是通过串行训练而获得的，每个新分类器都根据已训练出的分类器的性能来进行训练。boosting是通过训练集中关注被已有分类器错分的那些数据来获得新的分类器。\n\nboosting方法有多个版本，当前最流行便属于<font color=\"#007fff\">**AdaBoost**</font>。\n\n**AdaBoost的一般流程**\n\n```\n收集数据：可以使用任何方法；  \n准备数据：依赖于所使用的若分类器类型；  \n分析数据：可以使用任意方法  \n训练算法：AdaBoost的大部分时间都用在训练上，分类器将多次在同一数据集上训练若分类器；  \n测试算法：计算分类的错误率；  \n使用算法：同SVM一样，AdaBoost预测的两个类别中的一个，如果是多类，与其SVM一样。\n```\n\n## 2.训练算法：基于错误提升分类器的性能\n\nAdaBoost是adaptive boosting（自适应boosting）的缩写，其运行过程：训练集中的每个样本，赋予其一个权重，这些权重构成向量D。一开始，这些权重都初试化成相等值。首先在训练数据上训练处一个若分类器并计算该分类器的错误率，然后在同一数据集上再次训练若分类器。在分类器的第二次训练当中，将会重新调整每个样本的权重，其中第一次分队的样本的权重值将会降低，而第一次分错的样本的权重将会提高。为了从所有分类器中得到最终的分类结果，AdaBoost为每个分类器都分配了一个权重值alpha，这些alpha值是基于每个分类器的错误率进行计算的。其中错误率定义为\n\n$$\\epsilon=\\dfrac{为正确分类的样本数目}{所有样本数目}$$\n\nalpha计算公式\n\n![$$\\alpha=\\dfrac{1}{2}ln(\\dfrac{1-\\epsilon}{\\epsilon})$$](http://latex.codecogs.com/gif.latex?%24%24%5Calpha%3D%5Cdfrac%7B1%7D%7B2%7Dln%28%5Cdfrac%7B1-%5Cepsilon%7D%7B%5Cepsilon%7D%29%24%24)\n\n从上式可以看出，$\\alpha$和$\\epsilon$是成反比的（你可以求导试试），所以当$\\epsilon$越大，$\\alpha$就越小，也就是说建立的这个模型应该赋予更少的权值。计算出alpha值之后，可以对权重向量D进行更新，使得正确分类的样本的权重值降低而分错的样本权重值升高，D的计算方法如下\n如果某个样本被正确分类，更新该样本权重值为：\n\n![$$D^{(t+1)}_i=\\dfrac{D_i^{(t)} e^{-\\alpha}}{Sum(D)}$$](http://latex.codecogs.com/gif.latex?%24%24D%5E%7B%28t&plus;1%29%7D_i%3D%5Cdfrac%7BD_i%5E%7B%28t%29%7D%20e%5E%7B-%5Calpha%7D%7D%7BSum%28D%29%7D%24%24)\n\n如果某个样本被错误分类，更新该样本的权重值为：\n\n![$$D^{(t+1)}_i=\\dfrac{D_i^{(t)} e^{\\alpha}}{Sum(D)}$$](http://latex.codecogs.com/gif.latex?%24%24D%5E%7B%28t&plus;1%29%7D_i%3D%5Cdfrac%7BD_i%5E%7B%28t%29%7D%20e%5E%7B%5Calpha%7D%7D%7BSum%28D%29%7D%24%24)\n\n计算出D后，AdaBoost接着开始下一轮的迭代。AdaBoost算法会不断地重复训练和调整权重的过程，知道训练错误率为0或者若分类器的数目达到用户指定值为止。\n\n因此，Adaboost算法是一种加和模型，最终的到的分类器可以表示成这样：\n\n![](https://upload.wikimedia.org/math/5/4/a/54a5bff707b9188fd81d1a725d63643a.png)\n\n在建立完整的AdaBoost算法之前，需要通过一些代码建立若分类器及保存数据集的权重。\n\n\n## 3.基于单层决策树构建若分类器\n\n\n单层决策树是一种简单的决策树。首先构建一个简单的数据集,建立一个adaboost.py文件并加入下列代码：\n\n```python\ndef loadSimpData():\n    datMat = matrix([[ 1. ,  2.1],\n        [ 2. ,  1.1],\n        [ 1.3,  1. ],\n        [ 1. ,  1. ],\n        [ 2. ,  1. ]])\n    classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]\n    return datMat,classLabels\n```\n导入数据\n\n```\n>>> import adaboost\n>>> datMat,classLabels=adaboost.loadSimpData()\n```\n\n下面两个函数，一个用于测试是否某个值小于或者大于我们正在测试的阈值，一个会在一个加权数据集中循环，并找到具有最低错误率的单层决策树。\n\n伪代码如下：<br>\n\n\t将最小错误率minError设为无穷大\n\t对数据及中的每一个特征（第一层循环）：\n\t\t对每个步长（第二层循环）：\n\t\t\t对每个不等号（第三层循环）：\n\t\t\t\t建立一颗单层决策树并利用加权数据集对它进行测试\n\t\t\t\t如果错误率低于minError，则将当前单层决策树设置为最佳单层决策树\n\t返回最佳单层决策树\n\n\n单层决策树生成函数代码：\n\n```python\ndef stumpClassify(dataMatrix,dimen,threshVal,threshIneq):#just classify the data\n    retArray = ones((shape(dataMatrix)[0],1))\n    if threshIneq == 'lt':\n        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0\n    else:\n        retArray[dataMatrix[:,dimen] > threshVal] = -1.0\n    return retArray\n    \n\ndef buildStump(dataArr,classLabels,D):\n    dataMatrix = mat(dataArr); labelMat = mat(classLabels).T\n    m,n = shape(dataMatrix)\n    numSteps = 10.0; bestStump = {}; bestClasEst = mat(zeros((m,1)))\n    minError = inf #init error sum, to +infinity\n    for i in range(n):#loop over all dimensions\n        rangeMin = dataMatrix[:,i].min(); rangeMax = dataMatrix[:,i].max();\n        stepSize = (rangeMax-rangeMin)/numSteps\n        for j in range(-1,int(numSteps)+1):#loop over all range in current dimension\n            for inequal in ['lt', 'gt']: #go over less than and greater than\n                threshVal = (rangeMin + float(j) * stepSize)\n                predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)#call stump classify with i, j, lessThan\n                errArr = mat(ones((m,1)))\n                errArr[predictedVals == labelMat] = 0\n                weightedError = D.T*errArr  #calc total error multiplied by D\n                #print \"split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f\" % (i, threshVal, inequal, weightedError)\n                if weightedError < minError:\n                    minError = weightedError\n                    bestClasEst = predictedVals.copy()\n                    bestStump['dim'] = i\n                    bestStump['thresh'] = threshVal\n                    bestStump['ineq'] = inequal\n    return bestStump,minError,bestClasEst\n\n```\n\n\n## 4.AdaBoost算法的实现\n\n整个实现的伪代码如下：\n\n\n\t对每次迭代：\n\t\t利用buildStump()函数找到最佳的单层决策树\n\t\t将最佳单层决策树加入到单层决策树数据中\n\t\t计算alpha\n\t\t计算心的权重向量D\n\t\t更新累计类别估计值\n\t\t如果错误率低于0.0 则退出循环\n\n基于单层决策树的AdaBoost训练过程\n\n```python\ndef adaBoostTrainDS(dataArr,classLabels,numIt=40):\n    weakClassArr = []\n    m = shape(dataArr)[0]\n    D = mat(ones((m,1))/m)   #init D to all equal\n    aggClassEst = mat(zeros((m,1)))\n    for i in range(numIt):\n        bestStump,error,classEst = buildStump(dataArr,classLabels,D)#build Stump\n        #print \"D:\",D.T\n        alpha = float(0.5*log((1.0-error)/max(error,1e-16)))#calc alpha, throw in max(error,eps) to account for error=0\n        bestStump['alpha'] = alpha  \n        weakClassArr.append(bestStump)                  #store Stump Params in Array\n        #print \"classEst: \",classEst.T\n        expon = multiply(-1*alpha*mat(classLabels).T,classEst) #exponent for D calc, getting messy\n        D = multiply(D,exp(expon))                              #Calc New D for next iteration\n        D = D/D.sum()\n        #calc training error of all classifiers, if this is 0 quit for loop early (use break)\n        aggClassEst += alpha*classEst\n        #print \"aggClassEst: \",aggClassEst.T\n        aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T,ones((m,1)))\n        errorRate = aggErrors.sum()/m\n        print \"total error: \",errorRate\n        if errorRate == 0.0: break\n    return weakClassArr,aggClassEst\n\n```\n\n## 5.测试算法\n\n\n拥有了多个若分类器以及其对应的alpha值，进行测试就方便了。\n\nAdaBoost分类函数:利用训练处的多个若分类器进行分类的函数。\n\n```python\ndef adaClassify(datToClass,classifierArr):\n    dataMatrix = mat(datToClass)#do stuff similar to last aggClassEst in adaBoostTrainDS\n    m = shape(dataMatrix)[0]\n    aggClassEst = mat(zeros((m,1)))\n    for i in range(len(classifierArr)):\n        classEst = stumpClassify(dataMatrix,classifierArr[i]['dim'],\\\n                                 classifierArr[i]['thresh'],\\\n                                 classifierArr[i]['ineq'])#call stump classify\n        aggClassEst += classifierArr[i]['alpha']*classEst\n        print aggClassEst\n    return sign(aggClassEst)\n```\n\n\n\nOK，文章简单粗略的讲解了下Adaboost，主要从实现中讲解，如果要知道原理，请看文献二，Wikipedia中讲解的比较清楚，由于能力有限，以后再回头补充吧。\n\n## References\n\n\n[1] Machine Learning in Action 机器学习实战 第七章   \n[2] [AdaBoost](https://en.wikipedia.org/wiki/AdaBoost)\n\n------\n<br>\n\n","source":"_posts/2015-07-05-ML-algorithm-Adaboost.md","raw":"---\nlayout: post\ntitle: \"机器学习算法-Adaboost\"\ndate: 2015-07-05 22:53:12\ntag: \n\t- Machine Learning\n\t- Adaboost\n\t- 组合算法\nexcerpt: bagging:基于数据随机重抽样的分类器构建方法\ncomments: true\ncategories: ML\n---\n\nGithub源码实现:[链接](https://github.com/csuldw/MachineLearning/tree/master/Adaboost)\n\n\n## **本章内容**\n\n- 组合算法\n- AdaBoost算法的使用\n- 非均衡数据集分类\n\n<!-- more -->\n\n\n## **主题：**\n\n本文主要介绍的是Adaboost算法，**利用AdaBoost元算法来提高分类器的性能**，主要参考《机器学习实战》来学习Adaboost，同时结合Wikipedia以及网上各位童鞋的资料分享等等。希望通过总结达到学习效果。\n\n\n## 1.基于数据集多重抽样的分类器\n\n先来看看Adaboost的优缺点。\n\n| Feature |AdaBoost  |\n| -- | -- |\n| 优点 |  泛化错误率低，易编码，可以应用在大部分分类器上，无需参数调整 |\n| 缺点 |  对离群点敏感 |\n| 数据 | 数值型和标称型数据 |\n\n\n再来看看bagging和boosting的不同：\n\n- bagging: 基于数据随机重抽样的分类器构建方法\n\n自举汇聚法(bootstrap aggregating),也叫做bagging方法，是从原始数据集选择S次（有放回的抽取）后得到S个新数据集的一种技术。新数据集和原始数据集的大小相等（<font color=\"#007FFF\">**维数和列数都相等**</font>）。每个数据集都是通过在原始数据集中随机选择一个来进行替换而得到的。\n\n在S个数据集建好之后，将某个机器学习算法分别作用域每个数据集就可以得到S个分类器。当我们对新数据进行分类时，就可以应用S个分类器进行分类。与此同时，选择分类器<font color=\"#007fff\">**投票结果最多的类别作为最后的分类结果**</font>。\n\n目前，有一种改进的bagging方法，如**随机森林**（RF,随机森林不同的是，它对列也进行采样），它在一定程度上可以防止过拟合，也是对决策树的一种改进。\n\nboosting是一种与bagging很类似的技术。不论是boosting还是bagging当中，当使用的多个分类器的类型都是一致的。但是在前者当中，不同的分类器是通过串行训练而获得的，每个新分类器都根据已训练出的分类器的性能来进行训练。boosting是通过训练集中关注被已有分类器错分的那些数据来获得新的分类器。\n\nboosting方法有多个版本，当前最流行便属于<font color=\"#007fff\">**AdaBoost**</font>。\n\n**AdaBoost的一般流程**\n\n```\n收集数据：可以使用任何方法；  \n准备数据：依赖于所使用的若分类器类型；  \n分析数据：可以使用任意方法  \n训练算法：AdaBoost的大部分时间都用在训练上，分类器将多次在同一数据集上训练若分类器；  \n测试算法：计算分类的错误率；  \n使用算法：同SVM一样，AdaBoost预测的两个类别中的一个，如果是多类，与其SVM一样。\n```\n\n## 2.训练算法：基于错误提升分类器的性能\n\nAdaBoost是adaptive boosting（自适应boosting）的缩写，其运行过程：训练集中的每个样本，赋予其一个权重，这些权重构成向量D。一开始，这些权重都初试化成相等值。首先在训练数据上训练处一个若分类器并计算该分类器的错误率，然后在同一数据集上再次训练若分类器。在分类器的第二次训练当中，将会重新调整每个样本的权重，其中第一次分队的样本的权重值将会降低，而第一次分错的样本的权重将会提高。为了从所有分类器中得到最终的分类结果，AdaBoost为每个分类器都分配了一个权重值alpha，这些alpha值是基于每个分类器的错误率进行计算的。其中错误率定义为\n\n$$\\epsilon=\\dfrac{为正确分类的样本数目}{所有样本数目}$$\n\nalpha计算公式\n\n![$$\\alpha=\\dfrac{1}{2}ln(\\dfrac{1-\\epsilon}{\\epsilon})$$](http://latex.codecogs.com/gif.latex?%24%24%5Calpha%3D%5Cdfrac%7B1%7D%7B2%7Dln%28%5Cdfrac%7B1-%5Cepsilon%7D%7B%5Cepsilon%7D%29%24%24)\n\n从上式可以看出，$\\alpha$和$\\epsilon$是成反比的（你可以求导试试），所以当$\\epsilon$越大，$\\alpha$就越小，也就是说建立的这个模型应该赋予更少的权值。计算出alpha值之后，可以对权重向量D进行更新，使得正确分类的样本的权重值降低而分错的样本权重值升高，D的计算方法如下\n如果某个样本被正确分类，更新该样本权重值为：\n\n![$$D^{(t+1)}_i=\\dfrac{D_i^{(t)} e^{-\\alpha}}{Sum(D)}$$](http://latex.codecogs.com/gif.latex?%24%24D%5E%7B%28t&plus;1%29%7D_i%3D%5Cdfrac%7BD_i%5E%7B%28t%29%7D%20e%5E%7B-%5Calpha%7D%7D%7BSum%28D%29%7D%24%24)\n\n如果某个样本被错误分类，更新该样本的权重值为：\n\n![$$D^{(t+1)}_i=\\dfrac{D_i^{(t)} e^{\\alpha}}{Sum(D)}$$](http://latex.codecogs.com/gif.latex?%24%24D%5E%7B%28t&plus;1%29%7D_i%3D%5Cdfrac%7BD_i%5E%7B%28t%29%7D%20e%5E%7B%5Calpha%7D%7D%7BSum%28D%29%7D%24%24)\n\n计算出D后，AdaBoost接着开始下一轮的迭代。AdaBoost算法会不断地重复训练和调整权重的过程，知道训练错误率为0或者若分类器的数目达到用户指定值为止。\n\n因此，Adaboost算法是一种加和模型，最终的到的分类器可以表示成这样：\n\n![](https://upload.wikimedia.org/math/5/4/a/54a5bff707b9188fd81d1a725d63643a.png)\n\n在建立完整的AdaBoost算法之前，需要通过一些代码建立若分类器及保存数据集的权重。\n\n\n## 3.基于单层决策树构建若分类器\n\n\n单层决策树是一种简单的决策树。首先构建一个简单的数据集,建立一个adaboost.py文件并加入下列代码：\n\n```python\ndef loadSimpData():\n    datMat = matrix([[ 1. ,  2.1],\n        [ 2. ,  1.1],\n        [ 1.3,  1. ],\n        [ 1. ,  1. ],\n        [ 2. ,  1. ]])\n    classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]\n    return datMat,classLabels\n```\n导入数据\n\n```\n>>> import adaboost\n>>> datMat,classLabels=adaboost.loadSimpData()\n```\n\n下面两个函数，一个用于测试是否某个值小于或者大于我们正在测试的阈值，一个会在一个加权数据集中循环，并找到具有最低错误率的单层决策树。\n\n伪代码如下：<br>\n\n\t将最小错误率minError设为无穷大\n\t对数据及中的每一个特征（第一层循环）：\n\t\t对每个步长（第二层循环）：\n\t\t\t对每个不等号（第三层循环）：\n\t\t\t\t建立一颗单层决策树并利用加权数据集对它进行测试\n\t\t\t\t如果错误率低于minError，则将当前单层决策树设置为最佳单层决策树\n\t返回最佳单层决策树\n\n\n单层决策树生成函数代码：\n\n```python\ndef stumpClassify(dataMatrix,dimen,threshVal,threshIneq):#just classify the data\n    retArray = ones((shape(dataMatrix)[0],1))\n    if threshIneq == 'lt':\n        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0\n    else:\n        retArray[dataMatrix[:,dimen] > threshVal] = -1.0\n    return retArray\n    \n\ndef buildStump(dataArr,classLabels,D):\n    dataMatrix = mat(dataArr); labelMat = mat(classLabels).T\n    m,n = shape(dataMatrix)\n    numSteps = 10.0; bestStump = {}; bestClasEst = mat(zeros((m,1)))\n    minError = inf #init error sum, to +infinity\n    for i in range(n):#loop over all dimensions\n        rangeMin = dataMatrix[:,i].min(); rangeMax = dataMatrix[:,i].max();\n        stepSize = (rangeMax-rangeMin)/numSteps\n        for j in range(-1,int(numSteps)+1):#loop over all range in current dimension\n            for inequal in ['lt', 'gt']: #go over less than and greater than\n                threshVal = (rangeMin + float(j) * stepSize)\n                predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)#call stump classify with i, j, lessThan\n                errArr = mat(ones((m,1)))\n                errArr[predictedVals == labelMat] = 0\n                weightedError = D.T*errArr  #calc total error multiplied by D\n                #print \"split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f\" % (i, threshVal, inequal, weightedError)\n                if weightedError < minError:\n                    minError = weightedError\n                    bestClasEst = predictedVals.copy()\n                    bestStump['dim'] = i\n                    bestStump['thresh'] = threshVal\n                    bestStump['ineq'] = inequal\n    return bestStump,minError,bestClasEst\n\n```\n\n\n## 4.AdaBoost算法的实现\n\n整个实现的伪代码如下：\n\n\n\t对每次迭代：\n\t\t利用buildStump()函数找到最佳的单层决策树\n\t\t将最佳单层决策树加入到单层决策树数据中\n\t\t计算alpha\n\t\t计算心的权重向量D\n\t\t更新累计类别估计值\n\t\t如果错误率低于0.0 则退出循环\n\n基于单层决策树的AdaBoost训练过程\n\n```python\ndef adaBoostTrainDS(dataArr,classLabels,numIt=40):\n    weakClassArr = []\n    m = shape(dataArr)[0]\n    D = mat(ones((m,1))/m)   #init D to all equal\n    aggClassEst = mat(zeros((m,1)))\n    for i in range(numIt):\n        bestStump,error,classEst = buildStump(dataArr,classLabels,D)#build Stump\n        #print \"D:\",D.T\n        alpha = float(0.5*log((1.0-error)/max(error,1e-16)))#calc alpha, throw in max(error,eps) to account for error=0\n        bestStump['alpha'] = alpha  \n        weakClassArr.append(bestStump)                  #store Stump Params in Array\n        #print \"classEst: \",classEst.T\n        expon = multiply(-1*alpha*mat(classLabels).T,classEst) #exponent for D calc, getting messy\n        D = multiply(D,exp(expon))                              #Calc New D for next iteration\n        D = D/D.sum()\n        #calc training error of all classifiers, if this is 0 quit for loop early (use break)\n        aggClassEst += alpha*classEst\n        #print \"aggClassEst: \",aggClassEst.T\n        aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T,ones((m,1)))\n        errorRate = aggErrors.sum()/m\n        print \"total error: \",errorRate\n        if errorRate == 0.0: break\n    return weakClassArr,aggClassEst\n\n```\n\n## 5.测试算法\n\n\n拥有了多个若分类器以及其对应的alpha值，进行测试就方便了。\n\nAdaBoost分类函数:利用训练处的多个若分类器进行分类的函数。\n\n```python\ndef adaClassify(datToClass,classifierArr):\n    dataMatrix = mat(datToClass)#do stuff similar to last aggClassEst in adaBoostTrainDS\n    m = shape(dataMatrix)[0]\n    aggClassEst = mat(zeros((m,1)))\n    for i in range(len(classifierArr)):\n        classEst = stumpClassify(dataMatrix,classifierArr[i]['dim'],\\\n                                 classifierArr[i]['thresh'],\\\n                                 classifierArr[i]['ineq'])#call stump classify\n        aggClassEst += classifierArr[i]['alpha']*classEst\n        print aggClassEst\n    return sign(aggClassEst)\n```\n\n\n\nOK，文章简单粗略的讲解了下Adaboost，主要从实现中讲解，如果要知道原理，请看文献二，Wikipedia中讲解的比较清楚，由于能力有限，以后再回头补充吧。\n\n## References\n\n\n[1] Machine Learning in Action 机器学习实战 第七章   \n[2] [AdaBoost](https://en.wikipedia.org/wiki/AdaBoost)\n\n------\n<br>\n\n","slug":"2015-07-05-ML-algorithm-Adaboost","published":1,"updated":"2016-03-13T05:59:28.639Z","photos":[],"link":"","_id":"cimigpz0i008o6cuj9e4zcsgq"},{"layout":"post","date":"2015-06-10T12:03:00.000Z","title":"Python模拟ls命令","_content":"\n模拟控制台命令\n\n写一个程序 lsrm 要求如下:\n\n\t模拟linux的命令ls部分功能\n\t当使用命令\n\tlsrm -ll\n\t显示目录下所有 py 结尾的文件\n\t增加难度 (1.使用递归 显示所有目录里的 py 结尾文件)\n\n<!--more-->\n\n---\n\n首先定义一个outputFile函数，参数只设置一个infile，表示的是文件名或者目录名，然后进行判断，如果是文件，而且以py结尾，则输出；否则，如果是目录，则循环遍历每个每个文件。代码如下：\n\n\n```Python\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Wed Oct 28 19:25:20 2015\n\n@author: liudiwei\n\"\"\"\n\nimport os\n\ndef outputFile(infile):\n    if os.path.isdir(infile):\n        filelist = getFileList(infile)\n        for eachfile in filelist:\n            os.chdir(infile)\n            outputFile(eachfile)\n            os.chdir(\"..\")\n    else:\n        if \".py\" in infile:\n            print infile\n\n\nif __name__=='__main__':\n    filepath = r\"F:\\CSU\\Academic\\analysis\\experiment\\code\"; \n    filelist = getFileList(filepath)\n    while True:\n        command = raw_input('# ' )\n        if command == 'lsrm -ll':    \n            outputFile(filepath)\n        elif command == \"stop\":\n            break\n```\n\n运行结果如下图所示：\n\n<center>\n![output](/assets/images/20151029094653.png)\n</center>\n\n\n注意：在寻找子目录的文件时，需将工作目切换到子目录，档子目录遍历完毕后，再前换到上一层目录os.chdir(\"..\").\n\n---\n\n","source":"_posts/2015-06-10 Python-simulate-command.md","raw":"---\nlayout: post\ndate: 2015-06-10 20:03\ntitle: \"Python模拟ls命令\" \ntags:\n\t- Python\ncategories: Python\n---\n\n模拟控制台命令\n\n写一个程序 lsrm 要求如下:\n\n\t模拟linux的命令ls部分功能\n\t当使用命令\n\tlsrm -ll\n\t显示目录下所有 py 结尾的文件\n\t增加难度 (1.使用递归 显示所有目录里的 py 结尾文件)\n\n<!--more-->\n\n---\n\n首先定义一个outputFile函数，参数只设置一个infile，表示的是文件名或者目录名，然后进行判断，如果是文件，而且以py结尾，则输出；否则，如果是目录，则循环遍历每个每个文件。代码如下：\n\n\n```Python\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Wed Oct 28 19:25:20 2015\n\n@author: liudiwei\n\"\"\"\n\nimport os\n\ndef outputFile(infile):\n    if os.path.isdir(infile):\n        filelist = getFileList(infile)\n        for eachfile in filelist:\n            os.chdir(infile)\n            outputFile(eachfile)\n            os.chdir(\"..\")\n    else:\n        if \".py\" in infile:\n            print infile\n\n\nif __name__=='__main__':\n    filepath = r\"F:\\CSU\\Academic\\analysis\\experiment\\code\"; \n    filelist = getFileList(filepath)\n    while True:\n        command = raw_input('# ' )\n        if command == 'lsrm -ll':    \n            outputFile(filepath)\n        elif command == \"stop\":\n            break\n```\n\n运行结果如下图所示：\n\n<center>\n![output](/assets/images/20151029094653.png)\n</center>\n\n\n注意：在寻找子目录的文件时，需将工作目切换到子目录，档子目录遍历完毕后，再前换到上一层目录os.chdir(\"..\").\n\n---\n\n","slug":"2015-06-10 Python-simulate-command","published":1,"updated":"2016-03-13T06:41:14.831Z","comments":1,"photos":[],"link":"","_id":"cimigpz0n008u6cujtjuu313e"},{"layout":"post","title":"机器学习算法-Apriori关联分析","date":"2015-06-04T13:53:12.000Z","comments":1,"_content":"\n**引文：** 学习一个算法，我们最关心的并不是算法本身，而是一个算法能够干什么，能应用到什么地方。很多的时候，我们都需要从大量数据中提取出有用的信息，从大规模数据中寻找物品间的隐含关系叫做关联分析(association analysis)或者关联规则学习(association rule learning)。比如在平时的购物中，那些商品一起捆绑购买销量会比较好，又比如购物商城中的那些推荐信息，都是根据用户平时的搜索或者是购买情况来生成的。如果是蛮力搜索的话代价太高了，所以Apriori就出现了，就是为了解决这类问题的。\n\n<!-- more -->\n\n**内容纲要**\n\n- 关联分析\n- Apriori算法理论\n- Apriori实现\n\t- 频繁项集生成\n\t- 关联规则生成\n\n- reference\n\n**Apriori算法**\n\n- 优点：易编码实现\n- 缺点：在大数据集上可能较慢\n- 适合数据类型：数值型或者标称型数据\n\n### **1 关联分析**\n\n说到关联分析，顾名思义的就可以联想到，所谓关联就是两个东西之间存在的某种联系。关联分析最有名的例子是“尿布和啤酒”，以前在美国西部的一家连锁店，店家发现男人们在周四购买尿布后还会购买啤酒。于是他便得出一个推理，尿布和啤酒存在某种关联。但是具体怎么来评判呢？\n\n那么，这里用的是**支持度**和**可信度**来评判!\n\n一个项集的支持度（support）被定义为数据集中包含该数据集的记录所占的比例。可信度或置信度（confidence）是正对一条关联规则来定义的，比如{尿布}->{啤酒}，这条规则的可信度定义为“支持度{尿布，啤酒}/支持度{尿布}”\n\n\n比如有规则X=>Y，它的**支持度**可以计算为包含XUY所有商品的交易量相对所有交易量的比例（也就是X和Y同时出现一次交易的概率）。**可信度**定义为包含XUY所有物品的交易量相对仅包含X的交易量的比值，也就是说可信度对应给定X时的条件概率。关联规则挖掘，其目的是自动发起这样的规则，同时计算这些规则的质量。\n\n计算公式如下：\n\n$$支持度=\\frac{交易量包含XUY}{交易量}$$\n\n$$可信度=\\frac{交易量包含XUY}{交易量包含X}$$\n\n支持度和可信度是用来量化关联分析是否成功的方法。关联分析的目的包括两个：发现频繁项集和发现关联规则。首先我们要找到频繁项集，然后根据频繁项集找出关联规则。下面使用apriori算法来发现频繁项集。\n\n### **2 Apriori理论**\n\n**算法的一般过程：**\n\n- 收集数据：使用任何方法\n- 准备数据：任意数据类型都可以，因为我们只保存集合\n- 分析数据：使用任何方法\n- 训练算法：使用Apriori算法来找到频繁项集\n- 测试算法：不需要测试过程\n- 使用算法：用于发现频繁项集以及物品之间的关联规则\n\n**使用Apriori算法，首先计算出单个元素的支持度，然后选出单个元素置信度大于我们要求的数值，比如0.5或是0.7等。然后增加单个元素组合的个数，只要组合项的支持度大于我们要求的数值就把它加到我们的频繁项集中，依次递归。**\n\n然后根据计算的支持度选出来的频繁项集来生成关联规则。\n\n### **3 Apriori实现**\n\n首先定义一些算法的辅助函数\n加载数据集的\n\n```\nfrom numpy import *\n\ndef loadDataSet():\n    list = [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]\n    return list\n```\n\n根据数据集构建集合C1，该集合是大小为1的所有候选集的集合。\n\n```\ndef createC1(dataSet):\n    C1 = [] #C1是大小为1的所有候选项集的集合\n    for transaction in dataSet:\n        for item in transaction:\n            if not [item] in C1:\n                C1.append([item])             \n    C1.sort()\n    return map(frozenset, C1)#use frozen set so we can use it as a key in a dict    \n```\n\n根据构建出来的频繁项集，选出满足我们需要的大于我们给定的支持度的项集\n\n```\n#D表示数据集，CK表示候选项集，minSupport表示最小的支持度，自己设定\ndef scanD(D, Ck, minSupport):\n    ssCnt = {}\n    for tid in D:\n        for can in Ck:\n            if can.issubset(tid):\n                if not ssCnt.has_key(can): ssCnt[can]=1\n                else: ssCnt[can] += 1\n    numItems = float(len(D))\n    retList = [] #存储满足最小支持度要求的项集\n    supportData = {} #每个项集的支持度字典\n    for key in ssCnt:  #计算所有项集的支持度\n        support = ssCnt[key]/numItems\n        if support >= minSupport:\n            retList.insert(0,key)\n        supportData[key] = support\n    return retList, supportData\n```\n\n#### **3.1 频繁项集**\n\n关于频繁项集的产生，我们单独的抽取出来\n首先需要一个生成合并项集的函数，将两个子集合并的函数\n\n```\n#LK是频繁项集列表，K表示接下来合并的项集中的单个想的个数{1,2,3}表示k=3\ndef aprioriGen(Lk, k): #creates Ck\n    retList = []\n    lenLk = len(Lk)\n    for i in range(lenLk):\n        for j in range(i+1, lenLk): \n            L1 = list(Lk[i])[:k-2]; L2 = list(Lk[j])[:k-2] #前k-2个项相同时，将两个集合合并\n            L1.sort(); L2.sort()\n            if L1==L2: #if first k-2 elements are equal\n                retList.append(Lk[i] | Lk[j]) #set union\n    return retList \n```\n\n\n接着定义生成频繁项集的函数\n\n```\n#只需要输入数据集和支持度即可\ndef apriori(dataSet, minSupport = 0.5):\n    C1 = createC1(dataSet)\n    D = map(set, dataSet)\n    L1, supportData = scanD(D, C1, minSupport)\n    L = [L1]\n    k = 2\n    while (len(L[k-2]) > 0):\n        Ck = aprioriGen(L[k-2], k)\n        Lk, supK = scanD(D, Ck, minSupport)#scan DB to get Lk\n        supportData.update(supK)\n        L.append(Lk)\n        k += 1\n    return L, supportData#返回频繁项集和每个项集的支持度值\n```\n\n\n#### **3.2 关联规则生成**\n\n通过频繁项集，我们可以得到相应的规则，但是具体规则怎么得出来的呢？下面给出一个规则生成函数，具体原理参考注释\n\n\n```\n#输入的参数分别为：频繁项集、支持度数据字典、自定义的最小支持度，返回的是可信度规则列表\ndef generateRules(L, supportData, minConf=0.7):  #支持度是通过scanD得到的字典\n    bigRuleList = []\n    for i in range(1, len(L)):#只去频繁项集中元素个数大于2的子集，如{1,2}{1,2,3}，不取{2}{3},etc...\n        for freqSet in L[i]:\n            H1 = [frozenset([item]) for item in freqSet]\n            if (i > 1):\n                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n            else:\n                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n    return bigRuleList         \n```\n\n下面定义一个用来计算置信度的函数，通过该函数抽取出符合我们要求的规则，如freqSet为{1,2}，H为{1}，{2}，可以计算出{1}-->{2}和{2}-->{1}的质心度，即下面的conf变量，然后用if语句判断是否符合我们的要求。代码如下：\n\n\n```\n#计算可信度，找到满足最小可信度的要求规则\ndef calcConf(freqSet, H, supportData, brl, minConf=0.7):\n    prunedH = [] #create new list to return\n    for conseq in H:\n        conf = supportData[freqSet]/supportData[freqSet-conseq] #calc confidence\n        if conf >= minConf: \n            print freqSet-conseq,'-->',conseq,'conf:',conf\n            brl.append((freqSet-conseq, conseq, conf))\n            prunedH.append(conseq)\n    return prunedH\n```\n\n下面的函数是用来合并子集的，比如我现在的频繁项集是{2,3,5},它的构造元素是{2},{3},{5}，所以需要将{2},{3},{5}两两合并然后再根据上面的calcConf函数计算置信度。代码如下：\n\n\n```\n#从最初的项集中生成更多的规则\ndef rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):\n    m = len(H[0])\n    if (len(freqSet) > (m + 1)): #进一步合并项集\n        Hmp1 = aprioriGen(H, m+1)#create Hm+1 new candidates\n        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)\n        if (len(Hmp1) > 1):    #need at least two sets to merge\n            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)\n```\n\n#### **3.3 测试**\n\n```\ndataSet = loadDataSet()\t\t\t \t#加载数据集\nL,suppoData = apriori(dataSet)\t\t#计算频繁项集\nrules = generateRules(L,suppoData,minConf=0.7) #抽取规则\n```\n\n\n得到的结果为：\n![这里写图片描述](http://img.blog.csdn.net/20150604094036589)\n\nL表示的是符合条件的频繁项集，rules表示最后抽取出来的符合条件的规则；还可以查看各个项集的支持度，如下所示。\n![这里写图片描述](http://img.blog.csdn.net/20150604094213762)\n\n\n### **Reference**\n\n[1]**《机器学习实战》**书籍第11章\n\n<br>\n\n------\n","source":"_posts/2015-06-04-Apriori.md","raw":"---\nlayout: post\ntitle: \"机器学习算法-Apriori关联分析\"\ndate: 2015-06-04 21:53:12\ncomments: true\ncategories: ML\ntags: \n\t- Machine Learning\n\t- Apriori\n\t- 关联分析\n---\n\n**引文：** 学习一个算法，我们最关心的并不是算法本身，而是一个算法能够干什么，能应用到什么地方。很多的时候，我们都需要从大量数据中提取出有用的信息，从大规模数据中寻找物品间的隐含关系叫做关联分析(association analysis)或者关联规则学习(association rule learning)。比如在平时的购物中，那些商品一起捆绑购买销量会比较好，又比如购物商城中的那些推荐信息，都是根据用户平时的搜索或者是购买情况来生成的。如果是蛮力搜索的话代价太高了，所以Apriori就出现了，就是为了解决这类问题的。\n\n<!-- more -->\n\n**内容纲要**\n\n- 关联分析\n- Apriori算法理论\n- Apriori实现\n\t- 频繁项集生成\n\t- 关联规则生成\n\n- reference\n\n**Apriori算法**\n\n- 优点：易编码实现\n- 缺点：在大数据集上可能较慢\n- 适合数据类型：数值型或者标称型数据\n\n### **1 关联分析**\n\n说到关联分析，顾名思义的就可以联想到，所谓关联就是两个东西之间存在的某种联系。关联分析最有名的例子是“尿布和啤酒”，以前在美国西部的一家连锁店，店家发现男人们在周四购买尿布后还会购买啤酒。于是他便得出一个推理，尿布和啤酒存在某种关联。但是具体怎么来评判呢？\n\n那么，这里用的是**支持度**和**可信度**来评判!\n\n一个项集的支持度（support）被定义为数据集中包含该数据集的记录所占的比例。可信度或置信度（confidence）是正对一条关联规则来定义的，比如{尿布}->{啤酒}，这条规则的可信度定义为“支持度{尿布，啤酒}/支持度{尿布}”\n\n\n比如有规则X=>Y，它的**支持度**可以计算为包含XUY所有商品的交易量相对所有交易量的比例（也就是X和Y同时出现一次交易的概率）。**可信度**定义为包含XUY所有物品的交易量相对仅包含X的交易量的比值，也就是说可信度对应给定X时的条件概率。关联规则挖掘，其目的是自动发起这样的规则，同时计算这些规则的质量。\n\n计算公式如下：\n\n$$支持度=\\frac{交易量包含XUY}{交易量}$$\n\n$$可信度=\\frac{交易量包含XUY}{交易量包含X}$$\n\n支持度和可信度是用来量化关联分析是否成功的方法。关联分析的目的包括两个：发现频繁项集和发现关联规则。首先我们要找到频繁项集，然后根据频繁项集找出关联规则。下面使用apriori算法来发现频繁项集。\n\n### **2 Apriori理论**\n\n**算法的一般过程：**\n\n- 收集数据：使用任何方法\n- 准备数据：任意数据类型都可以，因为我们只保存集合\n- 分析数据：使用任何方法\n- 训练算法：使用Apriori算法来找到频繁项集\n- 测试算法：不需要测试过程\n- 使用算法：用于发现频繁项集以及物品之间的关联规则\n\n**使用Apriori算法，首先计算出单个元素的支持度，然后选出单个元素置信度大于我们要求的数值，比如0.5或是0.7等。然后增加单个元素组合的个数，只要组合项的支持度大于我们要求的数值就把它加到我们的频繁项集中，依次递归。**\n\n然后根据计算的支持度选出来的频繁项集来生成关联规则。\n\n### **3 Apriori实现**\n\n首先定义一些算法的辅助函数\n加载数据集的\n\n```\nfrom numpy import *\n\ndef loadDataSet():\n    list = [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]\n    return list\n```\n\n根据数据集构建集合C1，该集合是大小为1的所有候选集的集合。\n\n```\ndef createC1(dataSet):\n    C1 = [] #C1是大小为1的所有候选项集的集合\n    for transaction in dataSet:\n        for item in transaction:\n            if not [item] in C1:\n                C1.append([item])             \n    C1.sort()\n    return map(frozenset, C1)#use frozen set so we can use it as a key in a dict    \n```\n\n根据构建出来的频繁项集，选出满足我们需要的大于我们给定的支持度的项集\n\n```\n#D表示数据集，CK表示候选项集，minSupport表示最小的支持度，自己设定\ndef scanD(D, Ck, minSupport):\n    ssCnt = {}\n    for tid in D:\n        for can in Ck:\n            if can.issubset(tid):\n                if not ssCnt.has_key(can): ssCnt[can]=1\n                else: ssCnt[can] += 1\n    numItems = float(len(D))\n    retList = [] #存储满足最小支持度要求的项集\n    supportData = {} #每个项集的支持度字典\n    for key in ssCnt:  #计算所有项集的支持度\n        support = ssCnt[key]/numItems\n        if support >= minSupport:\n            retList.insert(0,key)\n        supportData[key] = support\n    return retList, supportData\n```\n\n#### **3.1 频繁项集**\n\n关于频繁项集的产生，我们单独的抽取出来\n首先需要一个生成合并项集的函数，将两个子集合并的函数\n\n```\n#LK是频繁项集列表，K表示接下来合并的项集中的单个想的个数{1,2,3}表示k=3\ndef aprioriGen(Lk, k): #creates Ck\n    retList = []\n    lenLk = len(Lk)\n    for i in range(lenLk):\n        for j in range(i+1, lenLk): \n            L1 = list(Lk[i])[:k-2]; L2 = list(Lk[j])[:k-2] #前k-2个项相同时，将两个集合合并\n            L1.sort(); L2.sort()\n            if L1==L2: #if first k-2 elements are equal\n                retList.append(Lk[i] | Lk[j]) #set union\n    return retList \n```\n\n\n接着定义生成频繁项集的函数\n\n```\n#只需要输入数据集和支持度即可\ndef apriori(dataSet, minSupport = 0.5):\n    C1 = createC1(dataSet)\n    D = map(set, dataSet)\n    L1, supportData = scanD(D, C1, minSupport)\n    L = [L1]\n    k = 2\n    while (len(L[k-2]) > 0):\n        Ck = aprioriGen(L[k-2], k)\n        Lk, supK = scanD(D, Ck, minSupport)#scan DB to get Lk\n        supportData.update(supK)\n        L.append(Lk)\n        k += 1\n    return L, supportData#返回频繁项集和每个项集的支持度值\n```\n\n\n#### **3.2 关联规则生成**\n\n通过频繁项集，我们可以得到相应的规则，但是具体规则怎么得出来的呢？下面给出一个规则生成函数，具体原理参考注释\n\n\n```\n#输入的参数分别为：频繁项集、支持度数据字典、自定义的最小支持度，返回的是可信度规则列表\ndef generateRules(L, supportData, minConf=0.7):  #支持度是通过scanD得到的字典\n    bigRuleList = []\n    for i in range(1, len(L)):#只去频繁项集中元素个数大于2的子集，如{1,2}{1,2,3}，不取{2}{3},etc...\n        for freqSet in L[i]:\n            H1 = [frozenset([item]) for item in freqSet]\n            if (i > 1):\n                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n            else:\n                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n    return bigRuleList         \n```\n\n下面定义一个用来计算置信度的函数，通过该函数抽取出符合我们要求的规则，如freqSet为{1,2}，H为{1}，{2}，可以计算出{1}-->{2}和{2}-->{1}的质心度，即下面的conf变量，然后用if语句判断是否符合我们的要求。代码如下：\n\n\n```\n#计算可信度，找到满足最小可信度的要求规则\ndef calcConf(freqSet, H, supportData, brl, minConf=0.7):\n    prunedH = [] #create new list to return\n    for conseq in H:\n        conf = supportData[freqSet]/supportData[freqSet-conseq] #calc confidence\n        if conf >= minConf: \n            print freqSet-conseq,'-->',conseq,'conf:',conf\n            brl.append((freqSet-conseq, conseq, conf))\n            prunedH.append(conseq)\n    return prunedH\n```\n\n下面的函数是用来合并子集的，比如我现在的频繁项集是{2,3,5},它的构造元素是{2},{3},{5}，所以需要将{2},{3},{5}两两合并然后再根据上面的calcConf函数计算置信度。代码如下：\n\n\n```\n#从最初的项集中生成更多的规则\ndef rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):\n    m = len(H[0])\n    if (len(freqSet) > (m + 1)): #进一步合并项集\n        Hmp1 = aprioriGen(H, m+1)#create Hm+1 new candidates\n        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)\n        if (len(Hmp1) > 1):    #need at least two sets to merge\n            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)\n```\n\n#### **3.3 测试**\n\n```\ndataSet = loadDataSet()\t\t\t \t#加载数据集\nL,suppoData = apriori(dataSet)\t\t#计算频繁项集\nrules = generateRules(L,suppoData,minConf=0.7) #抽取规则\n```\n\n\n得到的结果为：\n![这里写图片描述](http://img.blog.csdn.net/20150604094036589)\n\nL表示的是符合条件的频繁项集，rules表示最后抽取出来的符合条件的规则；还可以查看各个项集的支持度，如下所示。\n![这里写图片描述](http://img.blog.csdn.net/20150604094213762)\n\n\n### **Reference**\n\n[1]**《机器学习实战》**书籍第11章\n\n<br>\n\n------\n","slug":"2015-06-04-Apriori","published":1,"updated":"2016-03-13T05:59:48.624Z","photos":[],"link":"","_id":"cimigpz0r008x6cujudpkpjsu"},{"layout":"post","title":"机器学习算法-K-means聚类","date":"2015-06-03T04:30:00.000Z","comments":1,"_content":"  \n\n原文地址：http://www.csuldw.com/2015/06/03/2015-06-03-ml-algorithm-K-means/  \nGithub源码:https://github.com/csuldw/MachineLearning/tree/master/Kmeans\n\nk-Means算法是一种聚类算法，它是一种无监督学习算法，目的是将相似的对象归到同一个蔟中。蔟内的对象越相似，聚类的效果就越好。聚类和分类最大的不同在于，分类的目标事先已知，而聚类则不一样。其产生的结果和分类相同，而只是类别没有预先定义。\n\n<!-- more -->\n\n## 算法原理\n\n\n设计的目的：<font color=\"#1986C7\">**使各个样本与所在类均值的误差平方和达到最小**</font>（这也是评价K-means算法最后聚类效果的评价标准）。\n\n![$$SSE = \\sum_{i=1}^k  \\sum_{x \\epsilon C_{i} } ||x-\\mu_i||_{2}^2$$](http://latex.codecogs.com/gif.latex?%24%24SSE%20%3D%20%5Csum_%7Bi%3D1%7D%5Ek%20%5Csum_%7Bx%20%5Cepsilon%20C_%7Bi%7D%20%7D%20%7C%7Cx-%5Cmu_i%7C%7C_%7B2%7D%5E2%24%24)\n\n**K-均值聚类**\n\n- 优点：容易实现\n- 缺点：可能收敛到局部最小值，在大规模数据上收敛较慢\n- 适合数据类型：数值型数据\n\n原理：\n\n1. 创建k个点作为k个簇的起始质心（经常随机选择）。\n2. 分别计算剩下的元素到k个簇中心的相异度（距离），将这些元素分别划归到相异度最低的簇。\n3. 根据聚类结果，重新计算k个簇各自的中心，计算方法是取簇中所有元素各自维度的算术平均值。\n4. 将D中全部元素按照新的中心重新聚类。\n5. 重复第4步，直到聚类结果不再变化。\n6. 最后，输出聚类结果。\n\n\n## 算法实现\n\n**伪代码**\n\n```python\n创建k个点作为K个簇的起始质心（经常随机选择）\n当任意一个点的蔟分配结果发生变化时（初始化为True）\n\t对数据集中的每个数据点，重新分配质心\n\t\t对每个质心\n\t\t\t计算质心到数据点之间的距离\n\t\t将数据点分配到距其最近的蔟\n\t对每个蔟，计算蔟中所有点的均值并将均值作为新的质心\n```\n\n**实现**\n\n因为我们用到的是数值类型数据，这里需要编写一个加载数据集的函数，其返回值是一个矩阵。下面代码应写在一个py文件里，我这里写在kMeans.py文件中。\n\n首先引入相关的头文件：numpy\n\n```\nfrom numpy import *\n```\n\n**数据集加载代码**\n\n```\n# 加载数据集文件，没有返回类标号的函数\ndef loadDataSet(fileName):\n    dataMat = []\n    openfile = open(fileName)    \n    for line in openfile.readlines():\n        curLine = line.strip().split('\\t')\n        floatLine = map(float,curLine)\n        dataMat.append(floatLine)\n    return dataMat\n```\n\n因为在k均值算法中要计算点到质心的距离，所以这里将距离计算写成一个函数，计算欧几里得距离公式：\n\n$$d=\\sqrt{(x_1-z_1)^2+...+(x_n-z_n)^2}$$\n\n**函数代码如下：**\n\n```\n# 计算两个向量的欧氏距离\ndef distEclud(vecA,vecB):\n    return sqrt(sum(power(vecA-vecB,2)))\n```\n\n**接下来初始化k个蔟的质心函数centroid**\n\n\n```\n# 传入的数据时numpy的矩阵格式\ndef randCent(dataMat, k):\n    n = shape(dataMat)[1]\n    centroids = mat(zeros((k,n)))  \n    for j in range(n):\n        minJ = min(dataMat[:,j]) # 找出矩阵dataMat第j列最小值\n        rangeJ = float(max(dataMat[:,j]) - minJ) #计算第j列最大值和最小值的差\n        #赋予一个随机质心，它的值在整个数据集的边界之内\n        centroids[:,j] = minJ + rangeJ * random.rand(k,1) \n    return centroids #返回一个随机的质心矩阵\n```\n\n**K-means算法实现**\n\n```\n#返回的第一个变量时质心，第二个是各个簇的分布情况\ndef kMeans(dataMat,k,distE = distEclud , createCent=randCent):\n    m = shape(dataMat)[0]    # 获得行数m\n    clusterAssment = mat(zeros((m,2))) # 初试化一个矩阵，用来记录簇索引和存储误差                               \n    centroids = createCent(dataMat,k) # 随机的得到一个质心矩阵蔟\n    clusterChanged = True\n    while clusterChanged:\n        clusterChanged = False\n        for i in range(m):    #对每个数据点寻找最近的质心\n            minDist = inf; minIndex = -1\n            for j in range(k): # 遍历质心蔟，寻找最近的质心    \n                distJ1 = distE(centroids[j,:],dataMat[i,:]) #计算数据点和质心的欧式距离\n                if distJ1 < minDist: \n                    minDist = distJ1\n                    minIndex = j\n            if clusterAssment[i,0] != minIndex:\n                clusterChanged = True\n            clusterAssment[i,:] = minIndex, minDist**2\n        print centroids\n        for ci in range(k):   #更新质心，将每个族中的点的均值作为质心\n            index_all = clusterAssment[:,0].A   #取出样本所属簇的索引值\n            value = nonzero(index_all==ci)    #取出所有属于第ci个簇的索引值\n            sampleInClust = dataMat[value[0]]     #取出属于第i个簇的所有样本点\n            centroids[cent,:] = mean(sampleInClust, axis=0) \n    return centroids, clusterAssment   \n```\n\n虽然K-Means算法原理简单，但是也有自身的缺陷：\n\n- 首先，聚类的簇数K值需要事先给定，但在实际中这个 K 值的选定是非常难以估计的，很多时候，事先并不知道给定的数据集应该分成多少个类别才最合适。\n- Kmeans需要人为地确定初始聚类中心，不同的初始聚类中心可能导致完全不同的聚类结果，不能保证Ｋ-Means算法收敛于全局最优解。\n\t- 针对此问题，在K-Means的基础上提出了二分K-means算法。该算法首先将所有点看做是一个簇，然后一分为二，找到最小SSE的聚类质心。接着选择其中一个簇继续一分为二，此处哪一个簇需要根据划分后的SSE值来判断。\n- 对离群点敏感。\n- 结果不稳定 （受输入顺序影响）。\n- 时间复杂度高O(nkt)，其中n是对象总数，k是簇数，t是迭代次数。\n\n## 测试\n\n在控制台调用上述函数，执行下列命令：\n\n```\ndataMat = mat(loadDataSet('testSet.txt'))\nkMeans(dataMat, 4)\n```\n\n运行上面代码后，可以看到`print`处输出的结果：\n\n<pre><code class=\"markdown\">[[-3.66087851  2.30869657]\n [ 3.24377288  3.04700412]\n [ 2.52577861 -3.12485493]\n [-2.79672694  3.19201596]]\n[[-3.78710372 -1.66790611]\n [ 2.6265299   3.10868015]\n [ 1.62908469 -2.92689085]\n [-2.18799937  3.01824781]]\n[[-3.53973889 -2.89384326]\n [ 2.6265299   3.10868015]\n [ 2.65077367 -2.79019029]\n [-2.46154315  2.78737555]]\n</code></pre>\n\n\n测试的时候取的k值为4，即簇的个数为4，所以经过3次迭代之后K-均值算法就收敛了。质心会保存在第一个返回值中，第二个是每个点的簇分布情况。k=4是，聚类结果如下：\n\n![](/assets/articleImg/k_clusters4.png)\n\n附数据集：https://github.com/csuldw/MachineLearning/blob/master/Kmeans/data/testSet.txt\n\n\n## 讨论\n\n### 1.K-Means算法K值如何选择？\n\n《大数据》中提到：给定一个合适的类簇指标，比如平均半径或直径，只要我们假设的类簇的数目等于或者高于真实的类簇的数目时，该指标上升会很缓慢，而一旦试图得到少于真实数目的类簇时，该指标会急剧上升。\n\n- 簇的直径是指簇内任意两点之间的最大距离。\n- 簇的半径是指簇内所有点到簇中心距离的最大值。\n\n### 2. 如何优化K-Means算法搜索的时间复杂度？\n\n可以使用K-D树来缩短最近邻的搜索时间（NN算法都可以使用K-D树来优化时间复杂度）。\n\n### 3. 如何确定K个簇的初始质心？\n\n1) 选择批次距离尽可能远的K个点\n\n首先随机选择一个点作为第一个初始类簇中心点，然后选择距离该点最远的那个点作为第二个初始类簇中心点，然后再选择距离前两个点的最近距离最大的点作为第三个初始类簇的中心点，以此类推，直至选出K个初始类簇中心点。\n\n2) 选用层次聚类或者Canopy算法进行初始聚类，然后利用这些类簇的中心点作为KMeans算法初始类簇中心点。\n\n\n聚类扩展：密度聚类、层次聚类。\n\n##　参考文献\n\n- http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006910.html\n- http://www.cs.cmu.edu/~guestrin/Class/10701-S07/Slides/clustering.pdf\n\n---","source":"_posts/2015-06-03-ml-algorithm-K-means.md","raw":"---\nlayout: post\ntitle: \"机器学习算法-K-means聚类\"\ndate: 2015-06-03 12:30\ncomments: true\ncategories: ML\ntags: \n\t- Machine Learning\n\t- K-Means\n\t- 聚类\n---\n  \n\n原文地址：http://www.csuldw.com/2015/06/03/2015-06-03-ml-algorithm-K-means/  \nGithub源码:https://github.com/csuldw/MachineLearning/tree/master/Kmeans\n\nk-Means算法是一种聚类算法，它是一种无监督学习算法，目的是将相似的对象归到同一个蔟中。蔟内的对象越相似，聚类的效果就越好。聚类和分类最大的不同在于，分类的目标事先已知，而聚类则不一样。其产生的结果和分类相同，而只是类别没有预先定义。\n\n<!-- more -->\n\n## 算法原理\n\n\n设计的目的：<font color=\"#1986C7\">**使各个样本与所在类均值的误差平方和达到最小**</font>（这也是评价K-means算法最后聚类效果的评价标准）。\n\n![$$SSE = \\sum_{i=1}^k  \\sum_{x \\epsilon C_{i} } ||x-\\mu_i||_{2}^2$$](http://latex.codecogs.com/gif.latex?%24%24SSE%20%3D%20%5Csum_%7Bi%3D1%7D%5Ek%20%5Csum_%7Bx%20%5Cepsilon%20C_%7Bi%7D%20%7D%20%7C%7Cx-%5Cmu_i%7C%7C_%7B2%7D%5E2%24%24)\n\n**K-均值聚类**\n\n- 优点：容易实现\n- 缺点：可能收敛到局部最小值，在大规模数据上收敛较慢\n- 适合数据类型：数值型数据\n\n原理：\n\n1. 创建k个点作为k个簇的起始质心（经常随机选择）。\n2. 分别计算剩下的元素到k个簇中心的相异度（距离），将这些元素分别划归到相异度最低的簇。\n3. 根据聚类结果，重新计算k个簇各自的中心，计算方法是取簇中所有元素各自维度的算术平均值。\n4. 将D中全部元素按照新的中心重新聚类。\n5. 重复第4步，直到聚类结果不再变化。\n6. 最后，输出聚类结果。\n\n\n## 算法实现\n\n**伪代码**\n\n```python\n创建k个点作为K个簇的起始质心（经常随机选择）\n当任意一个点的蔟分配结果发生变化时（初始化为True）\n\t对数据集中的每个数据点，重新分配质心\n\t\t对每个质心\n\t\t\t计算质心到数据点之间的距离\n\t\t将数据点分配到距其最近的蔟\n\t对每个蔟，计算蔟中所有点的均值并将均值作为新的质心\n```\n\n**实现**\n\n因为我们用到的是数值类型数据，这里需要编写一个加载数据集的函数，其返回值是一个矩阵。下面代码应写在一个py文件里，我这里写在kMeans.py文件中。\n\n首先引入相关的头文件：numpy\n\n```\nfrom numpy import *\n```\n\n**数据集加载代码**\n\n```\n# 加载数据集文件，没有返回类标号的函数\ndef loadDataSet(fileName):\n    dataMat = []\n    openfile = open(fileName)    \n    for line in openfile.readlines():\n        curLine = line.strip().split('\\t')\n        floatLine = map(float,curLine)\n        dataMat.append(floatLine)\n    return dataMat\n```\n\n因为在k均值算法中要计算点到质心的距离，所以这里将距离计算写成一个函数，计算欧几里得距离公式：\n\n$$d=\\sqrt{(x_1-z_1)^2+...+(x_n-z_n)^2}$$\n\n**函数代码如下：**\n\n```\n# 计算两个向量的欧氏距离\ndef distEclud(vecA,vecB):\n    return sqrt(sum(power(vecA-vecB,2)))\n```\n\n**接下来初始化k个蔟的质心函数centroid**\n\n\n```\n# 传入的数据时numpy的矩阵格式\ndef randCent(dataMat, k):\n    n = shape(dataMat)[1]\n    centroids = mat(zeros((k,n)))  \n    for j in range(n):\n        minJ = min(dataMat[:,j]) # 找出矩阵dataMat第j列最小值\n        rangeJ = float(max(dataMat[:,j]) - minJ) #计算第j列最大值和最小值的差\n        #赋予一个随机质心，它的值在整个数据集的边界之内\n        centroids[:,j] = minJ + rangeJ * random.rand(k,1) \n    return centroids #返回一个随机的质心矩阵\n```\n\n**K-means算法实现**\n\n```\n#返回的第一个变量时质心，第二个是各个簇的分布情况\ndef kMeans(dataMat,k,distE = distEclud , createCent=randCent):\n    m = shape(dataMat)[0]    # 获得行数m\n    clusterAssment = mat(zeros((m,2))) # 初试化一个矩阵，用来记录簇索引和存储误差                               \n    centroids = createCent(dataMat,k) # 随机的得到一个质心矩阵蔟\n    clusterChanged = True\n    while clusterChanged:\n        clusterChanged = False\n        for i in range(m):    #对每个数据点寻找最近的质心\n            minDist = inf; minIndex = -1\n            for j in range(k): # 遍历质心蔟，寻找最近的质心    \n                distJ1 = distE(centroids[j,:],dataMat[i,:]) #计算数据点和质心的欧式距离\n                if distJ1 < minDist: \n                    minDist = distJ1\n                    minIndex = j\n            if clusterAssment[i,0] != minIndex:\n                clusterChanged = True\n            clusterAssment[i,:] = minIndex, minDist**2\n        print centroids\n        for ci in range(k):   #更新质心，将每个族中的点的均值作为质心\n            index_all = clusterAssment[:,0].A   #取出样本所属簇的索引值\n            value = nonzero(index_all==ci)    #取出所有属于第ci个簇的索引值\n            sampleInClust = dataMat[value[0]]     #取出属于第i个簇的所有样本点\n            centroids[cent,:] = mean(sampleInClust, axis=0) \n    return centroids, clusterAssment   \n```\n\n虽然K-Means算法原理简单，但是也有自身的缺陷：\n\n- 首先，聚类的簇数K值需要事先给定，但在实际中这个 K 值的选定是非常难以估计的，很多时候，事先并不知道给定的数据集应该分成多少个类别才最合适。\n- Kmeans需要人为地确定初始聚类中心，不同的初始聚类中心可能导致完全不同的聚类结果，不能保证Ｋ-Means算法收敛于全局最优解。\n\t- 针对此问题，在K-Means的基础上提出了二分K-means算法。该算法首先将所有点看做是一个簇，然后一分为二，找到最小SSE的聚类质心。接着选择其中一个簇继续一分为二，此处哪一个簇需要根据划分后的SSE值来判断。\n- 对离群点敏感。\n- 结果不稳定 （受输入顺序影响）。\n- 时间复杂度高O(nkt)，其中n是对象总数，k是簇数，t是迭代次数。\n\n## 测试\n\n在控制台调用上述函数，执行下列命令：\n\n```\ndataMat = mat(loadDataSet('testSet.txt'))\nkMeans(dataMat, 4)\n```\n\n运行上面代码后，可以看到`print`处输出的结果：\n\n<pre><code class=\"markdown\">[[-3.66087851  2.30869657]\n [ 3.24377288  3.04700412]\n [ 2.52577861 -3.12485493]\n [-2.79672694  3.19201596]]\n[[-3.78710372 -1.66790611]\n [ 2.6265299   3.10868015]\n [ 1.62908469 -2.92689085]\n [-2.18799937  3.01824781]]\n[[-3.53973889 -2.89384326]\n [ 2.6265299   3.10868015]\n [ 2.65077367 -2.79019029]\n [-2.46154315  2.78737555]]\n</code></pre>\n\n\n测试的时候取的k值为4，即簇的个数为4，所以经过3次迭代之后K-均值算法就收敛了。质心会保存在第一个返回值中，第二个是每个点的簇分布情况。k=4是，聚类结果如下：\n\n![](/assets/articleImg/k_clusters4.png)\n\n附数据集：https://github.com/csuldw/MachineLearning/blob/master/Kmeans/data/testSet.txt\n\n\n## 讨论\n\n### 1.K-Means算法K值如何选择？\n\n《大数据》中提到：给定一个合适的类簇指标，比如平均半径或直径，只要我们假设的类簇的数目等于或者高于真实的类簇的数目时，该指标上升会很缓慢，而一旦试图得到少于真实数目的类簇时，该指标会急剧上升。\n\n- 簇的直径是指簇内任意两点之间的最大距离。\n- 簇的半径是指簇内所有点到簇中心距离的最大值。\n\n### 2. 如何优化K-Means算法搜索的时间复杂度？\n\n可以使用K-D树来缩短最近邻的搜索时间（NN算法都可以使用K-D树来优化时间复杂度）。\n\n### 3. 如何确定K个簇的初始质心？\n\n1) 选择批次距离尽可能远的K个点\n\n首先随机选择一个点作为第一个初始类簇中心点，然后选择距离该点最远的那个点作为第二个初始类簇中心点，然后再选择距离前两个点的最近距离最大的点作为第三个初始类簇的中心点，以此类推，直至选出K个初始类簇中心点。\n\n2) 选用层次聚类或者Canopy算法进行初始聚类，然后利用这些类簇的中心点作为KMeans算法初始类簇中心点。\n\n\n聚类扩展：密度聚类、层次聚类。\n\n##　参考文献\n\n- http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006910.html\n- http://www.cs.cmu.edu/~guestrin/Class/10701-S07/Slides/clustering.pdf\n\n---","slug":"2015-06-03-ml-algorithm-K-means","published":1,"updated":"2016-03-26T00:35:02.921Z","photos":[],"link":"","_id":"cimigpz0y00946cuj30auvacu"},{"layout":"post","title":"sklearn训练模型的保存与恢复（Python）","date":"2015-05-31T12:52:00.000Z","_content":"\n\n## 描述\n\n在做模型训练的时候，尤其是在训练集上做交叉验证，通常想要将模型保存下来，然后放到独立的测试集上测试，下面介绍的是Python中训练模型的保存和再使用。\n\nscikit-learn已经有了模型持久化的操作，导入joblib即可\n\n```\nfrom sklearn.externals import joblib\n```\n<!-- more -->\n\n---\n\n### **模型保存**\n\n```python\n>>> os.chdir(\"workspace/model_save\")\n>>> from sklearn import svm\n>>> X = [[0, 0], [1, 1]]\n>>> y = [0, 1]\n>>> clf = svm.SVC()\n>>> clf.fit(X, y)  \n>>> clf.fit(train_X,train_y)\n>>> joblib.dump(clf, \"train_model.m\")\n```\n\n通过joblib的dump可以将模型保存到本地，clf是训练的分类器\n\n### **模型从本地调回**\n\n```python\n>>> clf = joblib.load(\"train_model.m\")\n```\n\n通过joblib的load方法，加载保存的模型。\n\n然后就可以在测试集上测试了\n\n```\nclf.predit(test_X，test_y)\n```\n\n\n\n---\n\n<br>\n\n\n\n","source":"_posts/2015-05-31 scikit-learn training model's save and reused.md","raw":"---\nlayout: post\ntitle: \"sklearn训练模型的保存与恢复（Python）\"\ndate: 2015-05-31 20:52\ncategories: Python\ntag: \n\t- scikit-learn\n\t- Python\n\t- 持久化\n---\n\n\n## 描述\n\n在做模型训练的时候，尤其是在训练集上做交叉验证，通常想要将模型保存下来，然后放到独立的测试集上测试，下面介绍的是Python中训练模型的保存和再使用。\n\nscikit-learn已经有了模型持久化的操作，导入joblib即可\n\n```\nfrom sklearn.externals import joblib\n```\n<!-- more -->\n\n---\n\n### **模型保存**\n\n```python\n>>> os.chdir(\"workspace/model_save\")\n>>> from sklearn import svm\n>>> X = [[0, 0], [1, 1]]\n>>> y = [0, 1]\n>>> clf = svm.SVC()\n>>> clf.fit(X, y)  \n>>> clf.fit(train_X,train_y)\n>>> joblib.dump(clf, \"train_model.m\")\n```\n\n通过joblib的dump可以将模型保存到本地，clf是训练的分类器\n\n### **模型从本地调回**\n\n```python\n>>> clf = joblib.load(\"train_model.m\")\n```\n\n通过joblib的load方法，加载保存的模型。\n\n然后就可以在测试集上测试了\n\n```\nclf.predit(test_X，test_y)\n```\n\n\n\n---\n\n<br>\n\n\n\n","slug":"2015-05-31 scikit-learn training model's save and reused","published":1,"updated":"2016-03-08T08:48:07.491Z","comments":1,"photos":[],"link":"","_id":"cimigpz15009b6cujfpi09dar"},{"layout":"post","title":"机器学习算法-朴素贝叶斯Python实现","date":"2015-05-28T04:59:00.000Z","comments":1,"_content":"\n\n源码：[Github-MachineLearning](https://github.com/csuldw/MachineLearning/tree/master/NaiveBayes)\n\n\n**引文：**前面提到的K最近邻算法和决策树算法，数据实例最终被明确的划分到某个分类中，下面介绍一种不能完全确定数据实例应该划分到哪个类别，或者说只能给数据实例属于给定分类的概率。\n\n<!-- more -->\n\n### **基于贝叶斯决策理论的分类方法之朴素贝叶斯**\n\n- 优点：在数据较少的情况下仍然有效，可以处理多类别问题\n- 缺点：对于输入数据的准备方式较为敏感 \n- 适用数据类型：标称型数据。\n\n### **朴素贝叶斯的一般过程**\n\n- 收集数据：可以使用任何方式\n- 准备数据：需要数据型或是布尔型数据\n- 分类数据：有大量特征时，绘制特征作用不大，此时使用直方图效果更好\n- 训练算法：计算不同的独立特征的条件概率\n- 测试算法：计算错误率\n- 使用算法：文档分类\n\n### **原理**\n\n主要是运用**贝叶斯定理**\n\n$$ P(H|X) = \\dfrac{P(X|H) p(H)}{P(X)} $$\n\n### **算法实现**\n\n下面做一个简单的留言板分类，自动判别留言类别：侮辱类和非侮辱类，分别使用1和0表示。下面来做一下这个实验。以下函数全部写在一个叫bayes.py文件中，后面的实验室通过导入bayes.py，调用里面的函数来做的。\n\n导入numpy包\n\n```python\nfrom numpy import *\n```\n\n#### **1.加载数据集**\n\n```python\ndef loadDataSet():\n    postingList=[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n                 ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n                 ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n                 ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n                 ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n                 ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n    classVec = [0,1,0,1,0,1]    #1 is abusive, 0 not\n    return postingList,classVec      \n```\n\n该函数返回的是**词条切分集合**和**类标签**。\n\n####**2.根据样本创建一个词库**\n\n下面的函数是根据上面给出来的样本数据所创建出来的一个词库。\n\n```python\ndef createVocabList(dataSet):\n    vocabSet = set([])  #create empty set\n    for document in dataSet:\n        vocabSet = vocabSet | set(document) #union of the two sets\n    return list(vocabSet)\n```\n\n#### **3.统计每个样本在词库中的出现情况**\n\n下面的函数功能是把单个样本映射到词库中去，统计单个样本在词库中的出现情况，1表示出现过，0表示没有出现，函数如下：\n\n```\ndef setOfWords2Vec(vocabList, inputSet):\n    returnVec = [0]*len(vocabList)\n    for word in inputSet:\n        if word in vocabList:\n            returnVec[vocabList.index(word)] = 1\n        else: print \"the word: %s is not in my Vocabulary!\" % word\n    return returnVec\n```\n\n#### **4.计算条件概率和类标签概率**\n\n```\ndef trainNB0(trainMatrix,trainCategory):\n    numTrainDocs = len(trainMatrix)\n    numWords = len(trainMatrix[0])\n    pAbusive = sum(trainCategory)/float(numTrainDocs) #计算某个类发生的概率\n    p0Num = ones(numWords); p1Num = ones(numWords) #初始样本个数为1，防止条件概率为0，影响结果       \n    p0Denom = 2.0; p1Denom = 2.0  #作用同上                      \n    for i in range(numTrainDocs):\n        if trainCategory[i] == 1:\n            p1Num += trainMatrix[i]\n            p1Denom += sum(trainMatrix[i])\n        else:\n            p0Num += trainMatrix[i]\n            p0Denom += sum(trainMatrix[i])\n    p1Vect = log(p1Num/p1Denom)         #计算类标签为1时的其它属性发生的条件概率\n    p0Vect = log(p0Num/p0Denom)         #计算标签为0时的其它属性发生的条件概率\n    return p0Vect,p1Vect,pAbusive       #返回条件概率和类标签为1的概率\n```\n\n说明：\n\n#### **5.训练贝叶斯分类算法**\n\n该算法包含四个输入，vec2Classify表示待分类的样本在词库中的映射集合，p0Vec表示条件概率$P(w_i|c=0)$，p1Vec表示条件概率$P(w_i|c=1)$，pClass1表示类标签为1时的概率$P(c=1)$。\n\n```\ndef classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):\n    p1 = sum(vec2Classify * p1Vec) + log(pClass1)    #element-wise mult\n    p0 = sum(vec2Classify * p0Vec) + log(1.0 - pClass1)\n    if p1 > p0:\n        return 1\n    else: \n        return 0\n```\n\n其中p1和p0表示的是\n\n$$lnp(w_1|c=1)p(w_2|c=1)...p(w_n|c=1)*p(c=1)$$\n\n和\n\n$$lnp(w_1|c=0)p(w_2|c=0)...p(w_n|c=0)*p(c=0)$$\n\n取对数是因为防止p(w_1|c=1)p(w_2|c=1)p(w_3|c=1)...p(w_n|c=1)多个小于1的数相乘结果值下溢。\n\n#### **6.文档词袋模型,修改函数setOfWords2Vec**\n\n词袋模型主要修改上面的第三个步骤，因为有的词可能出现多次，所以在单个样本映射到词库的时候需要多次统计。\n\n```\ndef bagOfWords2VecMN(vocabList, inputSet):\n    returnVec = [0]*len(vocabList)\n    for word in inputSet:\n        if word in vocabList:\n            returnVec[vocabList.index(word)] += 1\n    return returnVec\n```\n\n\n#### **7.测试函数**\n\n下面给出一个测试函数，直接调用该测试函数就可以实现简单的分类，测试结果看下个部分。\n\n```\ndef testingNB():\n\t#step1：加载数据集和类标号\n    listOPosts,listClasses = loadDataSet()\n    #step2：创建词库\n    myVocabList = createVocabList(listOPosts)\n    # step3：计算每个样本在词库中的出现情况\n    trainMat=[]\n    for postinDoc in listOPosts:\n        trainMat.append(setOfWords2Vec(myVocabList, postinDoc))\n    #step4：调用第四步函数，计算条件概率\n    p0V,p1V,pAb = trainNB0(array(trainMat),array(listClasses))\n    # step5\n    # 测试1 \n    testEntry = ['love', 'my', 'dalmation']\n    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))\n    print testEntry,'classified as: ',classifyNB(thisDoc,p0V,p1V,pAb)\n    # 测试2\n    testEntry = ['stupid', 'garbage']\n    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))\n    print testEntry,'classified as: ',classifyNB(thisDoc,p0V,p1V,pAb)\n```\n\n#### **8.实验**\n\n首先导入库，然后导入bayes.py文件\n\n```\nimport os\nos.chdir(r\"E:\\3-CSU\\Academic\\Machine Leaning\\机器学习实战\\src\\machinelearninginaction\\Ch04\")\nimport bayes\n```\n\n![这里写图片描述](http://img.blog.csdn.net/20150528122404620)\n\n可以看出，贝叶斯算法将['love', 'my', 'dalmation']分为“无侮辱”一类，将['stupid', 'garbage']分为“侮辱”性质的一类。\n\n\n\n### **Reference**\n\n**[1]《Machine Learning in Action 》机器学习实战**\n\n\n\n------\n\n","source":"_posts/2015-05-28-NB.md","raw":"---\nlayout: post\ntitle: \"机器学习算法-朴素贝叶斯Python实现\"\ndate: 2015-05-28 12:59\ntags: \n\t- Machine Learning\n\t- Python\n\t- Naive Bayes\ncomments: true\ncategories: ML\n---\n\n\n源码：[Github-MachineLearning](https://github.com/csuldw/MachineLearning/tree/master/NaiveBayes)\n\n\n**引文：**前面提到的K最近邻算法和决策树算法，数据实例最终被明确的划分到某个分类中，下面介绍一种不能完全确定数据实例应该划分到哪个类别，或者说只能给数据实例属于给定分类的概率。\n\n<!-- more -->\n\n### **基于贝叶斯决策理论的分类方法之朴素贝叶斯**\n\n- 优点：在数据较少的情况下仍然有效，可以处理多类别问题\n- 缺点：对于输入数据的准备方式较为敏感 \n- 适用数据类型：标称型数据。\n\n### **朴素贝叶斯的一般过程**\n\n- 收集数据：可以使用任何方式\n- 准备数据：需要数据型或是布尔型数据\n- 分类数据：有大量特征时，绘制特征作用不大，此时使用直方图效果更好\n- 训练算法：计算不同的独立特征的条件概率\n- 测试算法：计算错误率\n- 使用算法：文档分类\n\n### **原理**\n\n主要是运用**贝叶斯定理**\n\n$$ P(H|X) = \\dfrac{P(X|H) p(H)}{P(X)} $$\n\n### **算法实现**\n\n下面做一个简单的留言板分类，自动判别留言类别：侮辱类和非侮辱类，分别使用1和0表示。下面来做一下这个实验。以下函数全部写在一个叫bayes.py文件中，后面的实验室通过导入bayes.py，调用里面的函数来做的。\n\n导入numpy包\n\n```python\nfrom numpy import *\n```\n\n#### **1.加载数据集**\n\n```python\ndef loadDataSet():\n    postingList=[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n                 ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n                 ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n                 ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n                 ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n                 ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n    classVec = [0,1,0,1,0,1]    #1 is abusive, 0 not\n    return postingList,classVec      \n```\n\n该函数返回的是**词条切分集合**和**类标签**。\n\n####**2.根据样本创建一个词库**\n\n下面的函数是根据上面给出来的样本数据所创建出来的一个词库。\n\n```python\ndef createVocabList(dataSet):\n    vocabSet = set([])  #create empty set\n    for document in dataSet:\n        vocabSet = vocabSet | set(document) #union of the two sets\n    return list(vocabSet)\n```\n\n#### **3.统计每个样本在词库中的出现情况**\n\n下面的函数功能是把单个样本映射到词库中去，统计单个样本在词库中的出现情况，1表示出现过，0表示没有出现，函数如下：\n\n```\ndef setOfWords2Vec(vocabList, inputSet):\n    returnVec = [0]*len(vocabList)\n    for word in inputSet:\n        if word in vocabList:\n            returnVec[vocabList.index(word)] = 1\n        else: print \"the word: %s is not in my Vocabulary!\" % word\n    return returnVec\n```\n\n#### **4.计算条件概率和类标签概率**\n\n```\ndef trainNB0(trainMatrix,trainCategory):\n    numTrainDocs = len(trainMatrix)\n    numWords = len(trainMatrix[0])\n    pAbusive = sum(trainCategory)/float(numTrainDocs) #计算某个类发生的概率\n    p0Num = ones(numWords); p1Num = ones(numWords) #初始样本个数为1，防止条件概率为0，影响结果       \n    p0Denom = 2.0; p1Denom = 2.0  #作用同上                      \n    for i in range(numTrainDocs):\n        if trainCategory[i] == 1:\n            p1Num += trainMatrix[i]\n            p1Denom += sum(trainMatrix[i])\n        else:\n            p0Num += trainMatrix[i]\n            p0Denom += sum(trainMatrix[i])\n    p1Vect = log(p1Num/p1Denom)         #计算类标签为1时的其它属性发生的条件概率\n    p0Vect = log(p0Num/p0Denom)         #计算标签为0时的其它属性发生的条件概率\n    return p0Vect,p1Vect,pAbusive       #返回条件概率和类标签为1的概率\n```\n\n说明：\n\n#### **5.训练贝叶斯分类算法**\n\n该算法包含四个输入，vec2Classify表示待分类的样本在词库中的映射集合，p0Vec表示条件概率$P(w_i|c=0)$，p1Vec表示条件概率$P(w_i|c=1)$，pClass1表示类标签为1时的概率$P(c=1)$。\n\n```\ndef classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):\n    p1 = sum(vec2Classify * p1Vec) + log(pClass1)    #element-wise mult\n    p0 = sum(vec2Classify * p0Vec) + log(1.0 - pClass1)\n    if p1 > p0:\n        return 1\n    else: \n        return 0\n```\n\n其中p1和p0表示的是\n\n$$lnp(w_1|c=1)p(w_2|c=1)...p(w_n|c=1)*p(c=1)$$\n\n和\n\n$$lnp(w_1|c=0)p(w_2|c=0)...p(w_n|c=0)*p(c=0)$$\n\n取对数是因为防止p(w_1|c=1)p(w_2|c=1)p(w_3|c=1)...p(w_n|c=1)多个小于1的数相乘结果值下溢。\n\n#### **6.文档词袋模型,修改函数setOfWords2Vec**\n\n词袋模型主要修改上面的第三个步骤，因为有的词可能出现多次，所以在单个样本映射到词库的时候需要多次统计。\n\n```\ndef bagOfWords2VecMN(vocabList, inputSet):\n    returnVec = [0]*len(vocabList)\n    for word in inputSet:\n        if word in vocabList:\n            returnVec[vocabList.index(word)] += 1\n    return returnVec\n```\n\n\n#### **7.测试函数**\n\n下面给出一个测试函数，直接调用该测试函数就可以实现简单的分类，测试结果看下个部分。\n\n```\ndef testingNB():\n\t#step1：加载数据集和类标号\n    listOPosts,listClasses = loadDataSet()\n    #step2：创建词库\n    myVocabList = createVocabList(listOPosts)\n    # step3：计算每个样本在词库中的出现情况\n    trainMat=[]\n    for postinDoc in listOPosts:\n        trainMat.append(setOfWords2Vec(myVocabList, postinDoc))\n    #step4：调用第四步函数，计算条件概率\n    p0V,p1V,pAb = trainNB0(array(trainMat),array(listClasses))\n    # step5\n    # 测试1 \n    testEntry = ['love', 'my', 'dalmation']\n    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))\n    print testEntry,'classified as: ',classifyNB(thisDoc,p0V,p1V,pAb)\n    # 测试2\n    testEntry = ['stupid', 'garbage']\n    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))\n    print testEntry,'classified as: ',classifyNB(thisDoc,p0V,p1V,pAb)\n```\n\n#### **8.实验**\n\n首先导入库，然后导入bayes.py文件\n\n```\nimport os\nos.chdir(r\"E:\\3-CSU\\Academic\\Machine Leaning\\机器学习实战\\src\\machinelearninginaction\\Ch04\")\nimport bayes\n```\n\n![这里写图片描述](http://img.blog.csdn.net/20150528122404620)\n\n可以看出，贝叶斯算法将['love', 'my', 'dalmation']分为“无侮辱”一类，将['stupid', 'garbage']分为“侮辱”性质的一类。\n\n\n\n### **Reference**\n\n**[1]《Machine Learning in Action 》机器学习实战**\n\n\n\n------\n\n","slug":"2015-05-28-NB","published":1,"updated":"2016-03-08T09:01:43.043Z","photos":[],"link":"","_id":"cimigpz1d009h6cujp3k70b0s"},{"layout":"post","title":"机器学习算法-K最近邻从原理到实现","date":"2015-05-21T12:34:00.000Z","comments":1,"_content":"\n源码：[Github-MachineLearning](https://github.com/csuldw/MachineLearning/tree/master/KNN)\n\n**引文**：决策树和基于规则的分类器都是**积极学习方法**（eager learner）的例子，因为一旦训练数据可用，他们就开始学习从输入属性到类标号的映射模型。一个相反的策略是推迟对训练数据的建模，直到需要分类测试样例时再进行。采用这种策略的技术被称为**消极学习法**（lazy learner）。**最近邻分类器**就是这样的一种方法。\n\n<!-- more -->\n\n### **1.K最近邻分类器原理**\n\n首先给出一张图，根据这张图来理解最近邻分类器，如下：\n\n<center>![这里写图片描述](http://img.blog.csdn.net/20150521201557111)\n</center>\n\n根据上图所示，有两类不同的样本数据，分别用**蓝色的小正方形**和**红色的小三角形**表示，而图正中间的那个**绿色的圆**所标示的数据则是待分类的数据。也就是说，现在， 我们不知道中间那个绿色的数据是从属于哪一类（蓝色小正方形or红色小三角形），下面，我们就要解决这个问题：给这个绿色的圆分类。\n\n　　我们常说，物以类聚，人以群分，判别一个人是一个什么样品质特征的人，常常可以从他or她身边的朋友入手，所谓观其友，而识其人。我们不是要判别上图中那个绿色的圆是属于哪一类数据么，好说，从它的邻居下手。但一次性看多少个邻居呢？从上图中，你还能看到：\n\n- 如果K=3，绿色圆点的最近的3个邻居是2个红色小三角形和1个蓝色小正方形，少数从属于多数，基于统计的方法，判定绿色的这个待分类点属于红色的三角形一类。\n- 如果K=5，绿色圆点的最近的5个邻居是2个红色三角形和3个蓝色的正方形，还是少数从属于多数，基于统计的方法，判定绿色的这个待分类点属于蓝色的正方形一类。\n\n于此我们看到，当无法判定当前待分类点是从属于已知分类中的哪一类时，我们可以依据统计学的理论看它所处的位置特征，衡量它周围邻居的权重，而把它归为(或分配)到权重更大的那一类。这就是K近邻算法的核心思想。\n\nKNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。\n\nKNN 算法本身简单有效，它是一种 lazy-learning 算法，分类器不需要使用训练集进行训练，训练时间复杂度为0。KNN 分类的计算复杂度和训练集中的文档数目成正比，也就是说，如果训练集中文档总数为 n，那么 KNN 的分类时间复杂度为O(n)。\n\n前面的例子中强调了选择合适的K值的重要性。如果太小，则最近邻分类器容易受到训练数据的噪声而产生的过分拟合的影响；相反，如果K太大，最近分类器可能会误会分类测试样例，因为最近邻列表中可能包含远离其近邻的数据点。（如下图所示）\n\n<center>![这里写图片描述](http://img.blog.csdn.net/20150521203027253) \n\n**K较大时的最近邻分类**\n\n</center>\n\n\n可见，K值的选取还是非常关键。\n\n--------------\n\n\n### **2.算法**\n\n算法步骤如下所示：\n\n<center>![这里写图片描述](http://img.blog.csdn.net/20150521203212596)</center>\n\n对每个测试样例$z = (x',y')$，算法计算它和所有训练样例$（x,y）属于D$之间的距离（或相似度），以确定其最近邻列表$D_z$。如果训练样例的数目很大，那么这种计算的开销就会很大。不过，可以使索引技术降低为测试样例找最近邻是的计算量。\n\n一旦得到最近邻列表，测试样例就可以根据最近邻的多数类进行分类，使用多数表决方法。\n\n\n--------------\n\n### **3.K最邻近算法实现（Python）**\nKNN.py\n\n```python\nfrom numpy import *\nimport operator\n\nclass KNN:\n    def createDataset(self):\n        group = array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]])\n        labels = ['A','A','B','B']\n        return group,labels\n\n    def KnnClassify(self,testX,trainX,labels,K):\n        [N,M]=trainX.shape\n    \n    #calculate the distance between testX and other training samples\n        difference = tile(testX,(N,1)) - trainX # tile for array and repeat for matrix in Python, == repmat in Matlab\n        difference = difference ** 2 # take pow(difference,2)\n        distance = difference.sum(1) # take the sum of difference from all dimensions\n        distance = distance ** 0.5\n        sortdiffidx = distance.argsort()\n    \n    # find the k nearest neighbours\n        vote = {} #create the dictionary\n        for i in range(K):\n            ith_label = labels[sortdiffidx[i]];\n            vote[ith_label] = vote.get(ith_label,0)+1 #get(ith_label,0) : if dictionary 'vote' exist key 'ith_label', return vote[ith_label]; else return 0\n        sortedvote = sorted(vote.iteritems(),key = lambda x:x[1], reverse = True)\n        # 'key = lambda x: x[1]' can be substituted by operator.itemgetter(1)\n        return sortedvote[0][0]\n\nk = KNN() #create KNN object\ngroup,labels = k.createDataset()\ncls = k.KnnClassify([0,0],group,labels,3)\nprint cls\n\n```\n-------------------\n运行：\n1. 在Python Shell 中可以运行KNN.py\n\n```python\n>>>import os\n>>>os.chdir(\"/home/liudiwei/code/data_miningKNN/\")\n>>>execfile(\"KNN.py\")\n```\n输出:B\n（B表示类别）\n\n2.或者terminal中直接运行\n\n```python\n$ python KNN.py\n```\n\n3.也可以不在KNN.py中写输出，而选择在Shell中获得结果，i.e.,\n\n```python\n>>>import KNN\n>>> KNN.k.KnnClassify([0,0],KNN.group,KNN.labels,3)\n```\n\n### **References**\n\n【1】Introduction to Data Mining <a href=\"http://vdisk.weibo.com/s/akTUdytgliZM8\">数据挖掘导论</a>\n【2】<a href=\"http://blog.csdn.net/abcjennifer/article/details/19757987\">Rachel Zhang-K近邻分类算法实现 in Python</a>\n\n\n-----\n\n附件（两张自己的计算过程图）：\n<center>![这里写图片描述](http://img.blog.csdn.net/20150524192410343)\n**图1 KNN算法核心部分**\n</center>\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20150524192640924)\n**图2 简易计算过程**\n</center>\n说明：上述图片仅供参考，看不懂就自己测试一组数据如[0,1]慢慢推导一下吧\n\n-------\n\n<center>**本栏目机器学习算法持续更新中……**</center>","source":"_posts/2015-05-21-KNN.md","raw":"---\nlayout: post\ntitle: \"机器学习算法-K最近邻从原理到实现\"\ndate: 2015-05-21 20:34\ntags: \n\t- Machine Learning\n\t- KNN\n\t- 最近邻\ncomments: true\ncategories: ML\n---\n\n源码：[Github-MachineLearning](https://github.com/csuldw/MachineLearning/tree/master/KNN)\n\n**引文**：决策树和基于规则的分类器都是**积极学习方法**（eager learner）的例子，因为一旦训练数据可用，他们就开始学习从输入属性到类标号的映射模型。一个相反的策略是推迟对训练数据的建模，直到需要分类测试样例时再进行。采用这种策略的技术被称为**消极学习法**（lazy learner）。**最近邻分类器**就是这样的一种方法。\n\n<!-- more -->\n\n### **1.K最近邻分类器原理**\n\n首先给出一张图，根据这张图来理解最近邻分类器，如下：\n\n<center>![这里写图片描述](http://img.blog.csdn.net/20150521201557111)\n</center>\n\n根据上图所示，有两类不同的样本数据，分别用**蓝色的小正方形**和**红色的小三角形**表示，而图正中间的那个**绿色的圆**所标示的数据则是待分类的数据。也就是说，现在， 我们不知道中间那个绿色的数据是从属于哪一类（蓝色小正方形or红色小三角形），下面，我们就要解决这个问题：给这个绿色的圆分类。\n\n　　我们常说，物以类聚，人以群分，判别一个人是一个什么样品质特征的人，常常可以从他or她身边的朋友入手，所谓观其友，而识其人。我们不是要判别上图中那个绿色的圆是属于哪一类数据么，好说，从它的邻居下手。但一次性看多少个邻居呢？从上图中，你还能看到：\n\n- 如果K=3，绿色圆点的最近的3个邻居是2个红色小三角形和1个蓝色小正方形，少数从属于多数，基于统计的方法，判定绿色的这个待分类点属于红色的三角形一类。\n- 如果K=5，绿色圆点的最近的5个邻居是2个红色三角形和3个蓝色的正方形，还是少数从属于多数，基于统计的方法，判定绿色的这个待分类点属于蓝色的正方形一类。\n\n于此我们看到，当无法判定当前待分类点是从属于已知分类中的哪一类时，我们可以依据统计学的理论看它所处的位置特征，衡量它周围邻居的权重，而把它归为(或分配)到权重更大的那一类。这就是K近邻算法的核心思想。\n\nKNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。\n\nKNN 算法本身简单有效，它是一种 lazy-learning 算法，分类器不需要使用训练集进行训练，训练时间复杂度为0。KNN 分类的计算复杂度和训练集中的文档数目成正比，也就是说，如果训练集中文档总数为 n，那么 KNN 的分类时间复杂度为O(n)。\n\n前面的例子中强调了选择合适的K值的重要性。如果太小，则最近邻分类器容易受到训练数据的噪声而产生的过分拟合的影响；相反，如果K太大，最近分类器可能会误会分类测试样例，因为最近邻列表中可能包含远离其近邻的数据点。（如下图所示）\n\n<center>![这里写图片描述](http://img.blog.csdn.net/20150521203027253) \n\n**K较大时的最近邻分类**\n\n</center>\n\n\n可见，K值的选取还是非常关键。\n\n--------------\n\n\n### **2.算法**\n\n算法步骤如下所示：\n\n<center>![这里写图片描述](http://img.blog.csdn.net/20150521203212596)</center>\n\n对每个测试样例$z = (x',y')$，算法计算它和所有训练样例$（x,y）属于D$之间的距离（或相似度），以确定其最近邻列表$D_z$。如果训练样例的数目很大，那么这种计算的开销就会很大。不过，可以使索引技术降低为测试样例找最近邻是的计算量。\n\n一旦得到最近邻列表，测试样例就可以根据最近邻的多数类进行分类，使用多数表决方法。\n\n\n--------------\n\n### **3.K最邻近算法实现（Python）**\nKNN.py\n\n```python\nfrom numpy import *\nimport operator\n\nclass KNN:\n    def createDataset(self):\n        group = array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]])\n        labels = ['A','A','B','B']\n        return group,labels\n\n    def KnnClassify(self,testX,trainX,labels,K):\n        [N,M]=trainX.shape\n    \n    #calculate the distance between testX and other training samples\n        difference = tile(testX,(N,1)) - trainX # tile for array and repeat for matrix in Python, == repmat in Matlab\n        difference = difference ** 2 # take pow(difference,2)\n        distance = difference.sum(1) # take the sum of difference from all dimensions\n        distance = distance ** 0.5\n        sortdiffidx = distance.argsort()\n    \n    # find the k nearest neighbours\n        vote = {} #create the dictionary\n        for i in range(K):\n            ith_label = labels[sortdiffidx[i]];\n            vote[ith_label] = vote.get(ith_label,0)+1 #get(ith_label,0) : if dictionary 'vote' exist key 'ith_label', return vote[ith_label]; else return 0\n        sortedvote = sorted(vote.iteritems(),key = lambda x:x[1], reverse = True)\n        # 'key = lambda x: x[1]' can be substituted by operator.itemgetter(1)\n        return sortedvote[0][0]\n\nk = KNN() #create KNN object\ngroup,labels = k.createDataset()\ncls = k.KnnClassify([0,0],group,labels,3)\nprint cls\n\n```\n-------------------\n运行：\n1. 在Python Shell 中可以运行KNN.py\n\n```python\n>>>import os\n>>>os.chdir(\"/home/liudiwei/code/data_miningKNN/\")\n>>>execfile(\"KNN.py\")\n```\n输出:B\n（B表示类别）\n\n2.或者terminal中直接运行\n\n```python\n$ python KNN.py\n```\n\n3.也可以不在KNN.py中写输出，而选择在Shell中获得结果，i.e.,\n\n```python\n>>>import KNN\n>>> KNN.k.KnnClassify([0,0],KNN.group,KNN.labels,3)\n```\n\n### **References**\n\n【1】Introduction to Data Mining <a href=\"http://vdisk.weibo.com/s/akTUdytgliZM8\">数据挖掘导论</a>\n【2】<a href=\"http://blog.csdn.net/abcjennifer/article/details/19757987\">Rachel Zhang-K近邻分类算法实现 in Python</a>\n\n\n-----\n\n附件（两张自己的计算过程图）：\n<center>![这里写图片描述](http://img.blog.csdn.net/20150524192410343)\n**图1 KNN算法核心部分**\n</center>\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20150524192640924)\n**图2 简易计算过程**\n</center>\n说明：上述图片仅供参考，看不懂就自己测试一组数据如[0,1]慢慢推导一下吧\n\n-------\n\n<center>**本栏目机器学习算法持续更新中……**</center>","slug":"2015-05-21-KNN","published":1,"updated":"2016-03-13T06:00:40.457Z","photos":[],"link":"","_id":"cimigpz1i009n6cuj8red0nje"},{"layout":"post","title":"机器学习算法-决策树理论","date":"2015-05-08T13:53:12.000Z","comments":1,"_content":"\n源码下载：[Github-MachineLearning](https://github.com/csuldw/MachineLearning/tree/master/DecisionTree)\n\n\n在决策树理论中，有这样一句话，“**用较少的东西，同样可以做好的事情。越是小的决策树，越优于大的决策树**”。数据分类是一个两阶段过程，包括模型学习阶段（构建分类模型）和分类预测阶段（使用模型预测给定数据的类标号）。决策树分类算法属于监督学习（Supervised learning），即样本数据中有类别标号。下面是两个阶段的简单描述：\n\n - 第一阶段（以分类为例），可以看做是根据样本来学习一个映射或函数`y=f(x)`表达式，能够使用它预测给定元组X的类标号y。\n - 第二阶段，使用第一阶段学习得到的模型进行分类。首先评估分类器的预测准确率。这个过程要**尽量减少过拟合**（为什么是尽量减少？因为过拟合是避免不了的，再好的模型也会有过拟合的情况的）。\n\n<!-- more -->\n\n## **一、简介**\n\n 决策树归纳是从有类标号的训练元组中学习决策模型。常用的决策树算法有ID3，C4.5和CART。它们都是采用贪心（即非回溯的）方法，自顶向下递归的分治方法构造。这几个算法选择属性划分的方法各不相同，<font color=\"#1986C7\">**ID3使用的是信息增益，C4.5使用的是信息增益率，而CART使用的是Gini基尼指数**</font>。下面来简单介绍下决策树的理论知识。内容包含**熵**、**信息增益**、**信息增益率**以及**Gini指数**的概念及公式。\n \n---\n\n## **二、决策树原理**\n\n决策树原理很简单，通俗易懂，最简单的就是二元划分，类似于二叉树。例如只考虑某一层某个节点的划分，如果年龄大于18，就表示成年人，如果年龄小于18就表示未成年人。\n\n### **2.1 算法优点**\n\n 决策树算法的优点如下：  \n\n- 算法简单；  \n- 易于理解；  \n- 对噪声数据有很好的健壮性。  \n\n它是目前应用最为广泛的归纳推理算法之一，在数据挖掘中受到研究者的广泛关注。很多集成算法，如随机森林、adaboost、GBDT都是基于决策树的模型。\n  \n### **2.2 算法一般流程**\n\n（1）收集数据：任意方法和途径。  \n（2）准备数据：书构造算法只适用于标称型数据，因此数据必须离散化。  \n（3）分析数据：构造树完成后，检查图形是否符合预测。  \n（4）训练算法：决策树的数据构造。  \n（5）测试算法：一般将决策树用于分类，可以用错误率衡量，而错误率使用经验率计算。  \n（6）使用算法：决策树可以用于任何监督学习算法。  \n\n### **2.3 实例分析**\n\n**信息增益和熵（克劳德.香农提出）**\n\n#### **1.使用信息增益作为划分属性**\n\n**信息增益度量属性选择**\n\n熵被用来衡量一个随机变量出现的期望值。熵越大，一个变量的不确定性就越大（也就是可取的值很多），把它搞清楚所需要的信息量也就越大，熵是整个系统的平均消息量。 信息熵是信息论中用于度量信息量的一个概念。<font color=\"#1986C7\">**一个系统越是有序，信息熵就越低；反之，一个系统越是混乱，信息熵就越高**</font>。所以，信息熵也可以说是系统有序化程度的一个度量。\n\n**熵（Entropy）的计算公式**\n\n熵定义为**信息的期望值**。先看看信息的定义：\n\n$$l(x_i)=-log_2p(x_i)$$\n\n其中，$p(x_i)$是选择该分类的概率。对$D$中的元组所有分类所有可能值的信息期望，即熵，计算公式如下：\n\n$$Entropy=H(D)=E(I(D))=-\\sum_i^{n} p_ilog_2(p_i)，p_i是D中任意元组属于类C_i非零概率。$$\n\n<font color=\"#1986C7\">**熵越大，说明系统越混乱，携带的信息就越少。熵越小，说明系统越有序，携带的信息就越多**</font>。信息的作用就是在于消除不确定性。\n\n\nID3划分特征使用的就是信息增益IG。<font color=\"#1986C7\">**一个属性的信息增益越大，表明属性对样本的熵减少的能力就更强，该属性使得数据所属类别的不确定性变为确定性的能力越强**</font>。信息增益在统计学中称为互信息，互信息是条件概率与后验概率的比值，化简之后就可以得到信息增益。所以说互信息其实就是信息增益。计算方法【互信息=熵-条件熵】。熵描述的是不确定性。熵越大，不确定性就越大，条件熵H（B|A）描述的是在A给定的条件下B的不确定性，如果条件熵越小，表示不确定性就越小，那么B就越容易确定结果。所以使用熵减去条件熵，就得到了信息增益，他描述的不确定性的降低程度，可以用来度量两个变量的相关性。比如，在给定一个变量的条件下，另一个变量它的不确定性能够降低多少，如果不确定性降低得越多，那么它的确定性就越大，就越容易区分，两者就越相关。注：**期望信息越小，分区的纯度越高。**\n\n**信息增益计算**\n\n首先计算特征A对数据集D的经验**条件熵**$H(D|A)$,在数学上就是条件概率分布（Condition Probability）.\n\n$$H(D|A)=\\sum_j\\dfrac{|D_j|}{|D|}\\times H(D_j)，项\\dfrac{|D_i|}{|D|}充当第j个分区的权重$$\n\n引入条件熵，在信息论中主要是为了消除结果的不确定性。然后计算信息增益\n\n$$Gain(A) = H(D) - H(D|A)$$\n\n其中，$Gain(A)$即为所求的信息增益。下面来应用一个实例，**训练元组数据D**\n\n![这里写图片描述](http://img.blog.csdn.net/20150513110022176)\n\n在这里\n\n$$H(D)=-\\dfrac{9}{14}log_2\\dfrac{9}{14}-\\dfrac{5}{14}log_2\\dfrac{5}{14}=0.940位$$\n\n$$H(D|age)=\\dfrac{5}{14}\\times(-\\dfrac{2}{5}log_2\\dfrac{2}{5}-\\dfrac{3}{5}log_2 \\dfrac{3}{5})+\\dfrac{4}{14}\\times(-\\dfrac{4}{4}log_2\\dfrac{0}{4}-\\dfrac{0}{4}log_2 \\dfrac{0}{4})+\\dfrac{5}{14}\\times(-\\dfrac{3}{5}log_2\\dfrac{3}{5}-\\dfrac{2}{5}log_2 \\dfrac{2}{5})=0.694位$$\n\n根据计算出来的条件熵，计算按$age$划分的信息增益，计算方法如下：\n\n$$Gain(age)=H(D)-H(D|age)=0.940-0.964=0.246位$$\n\n类似的可以计算出其它属性的信息增益：\n\n$$ Gain(income)=0.029位，\nGain(student)=0.151位，Gain(credit\\_rating)=0.048位 $$\n\n由于$age$在属性中具有最高的信息增益，所以它被选作分裂特征。下面再进行递归计算信息增益，在此就不展示了。ID3采用的就是就是IG，算法步骤如下：\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20150921091028096)\n![这里写图片描述](http://img.blog.csdn.net/20150921091053471)\n</center>\n\n#### **2.使用增益率计算**\n\n在决策树中，**ID3属性划分标准使用的是信息增益，C4.5使用的是信息增益率。**\n\nC4.5算法继承了ID3算法的优点，并在以下几方面对ID3算法进行了改进：  \n\n- 用信息增益率来选择属性，克服了用信息增益选择属性时偏向选择取值多的属性的不足；  \n- 在树构造过程中进行剪枝；  \n- 能够完成对连续属性的离散化处理；  \n- 能够对不完整数据进行处理。  \n\nC4.5算法有如下优点：**产生的分类规则易于理解，准确率较高**。其缺点是：**在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效**。另外，C4.5只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时程序无法运行。\n\n另外，无论是ID3还是C4.5最好在小数据集上使用，决策树分类一般只试用于小数据。当属性取值很多时最好选择C4.5算法，ID3得出的效果会非常差，因为使用信息增益划分时它倾向于取值多的属性。\n\n计算信息增益率时，用到了**分裂信息计算公式：**\n\n$$Split\\_H(D|A)=-∑\\dfrac{|D_j|}{|D|}\\times log_2(\\dfrac{|D_j|}{|D|})$$\n\n信息增益率定义为：\n\n$$Gain\\_Rate(A)=\\dfrac{Gain(A)}{Split\\_H(D|A)}$$\n\n选择具有最大增益率的特征作为分裂特征。\n\n#### **3.基尼指数Gini index**\n\n基尼指数主要在CART算法中用到，随机森林中用到的属性划分标准也是它。Gini index划分是二元的，**它度量的是数据分区或训练元组集D的不纯度，表示的是一个随机选中的样本在子集中被分错的可能性**。计算方式如下：\n\n$$Gini(D)=1-\\sum p^{2}_i ，其中，p_i 是D中元组数以C_i 类的概率，对m个类计算和。$$\n\nGini指数越大，不纯度越大，越不容易区分。假设A有v个不同的值出现在特征D中，它的二元划分有$2^v - 2$种（除去自己和空集）。当考虑二元划分裂时，计算每个结果分区的不纯度加权和。比如A有两个值，则特征D被划分成D1和D2,这时Gini指数为：\n\n![$$Gini_A(D) = \\frac{D_1}{D} Gini(D_1) + \\frac{D_2}{D} Gini(D_2)$$](http://latex.codecogs.com/gif.latex?Gini_A%28D%29%20%3D%20%5Cfrac%7BD_1%7D%7BD%7D%20Gini%28D_1%29%20&plus;%20%5Cfrac%7BD_2%7D%7BD%7D%20Gini%28D_2%29)\n\n上面的式子表示的是不确定性的大小。对于每个属性，考虑每种可能的二元划分，对于离散值属性，**选择该属性产生最小Gini指数的自己作为它的分裂信息**。\n\n---\n\n## **三、学习推介**\n\nAndrew W. Moore PPT [DTree](http://www.autonlab.org/tutorials/dtree18.pdf)  \n决策树Python实现，单独成文，网址：[决策树实现](http://blog.csdn.net/dream_angel_z/article/details/45965463)  \nWikipedia维基百科-[Decision Tree决策树](https://en.wikipedia.org/wiki/Decision_tree)\n\n最后，附一张决策树的优点和缺点图：\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20150921094738621)\n</center>\n\n\n## **四、参考文献**\n\n- [1]数据挖掘概念与技术 Third Edition,韩家伟.  \n- [2]机器学习实战 ,Peter Harrington.  \n\n------\n<br>\n","source":"_posts/2015-05-08-decision tree.md","raw":"---\nlayout: post\ntitle: \"机器学习算法-决策树理论\"\ndate: 2015-05-08 21:53:12\ntags: \n\t- Machine Learning\n\t- Decision Tree\ncomments: true\ncategories: ML\n---\n\n源码下载：[Github-MachineLearning](https://github.com/csuldw/MachineLearning/tree/master/DecisionTree)\n\n\n在决策树理论中，有这样一句话，“**用较少的东西，同样可以做好的事情。越是小的决策树，越优于大的决策树**”。数据分类是一个两阶段过程，包括模型学习阶段（构建分类模型）和分类预测阶段（使用模型预测给定数据的类标号）。决策树分类算法属于监督学习（Supervised learning），即样本数据中有类别标号。下面是两个阶段的简单描述：\n\n - 第一阶段（以分类为例），可以看做是根据样本来学习一个映射或函数`y=f(x)`表达式，能够使用它预测给定元组X的类标号y。\n - 第二阶段，使用第一阶段学习得到的模型进行分类。首先评估分类器的预测准确率。这个过程要**尽量减少过拟合**（为什么是尽量减少？因为过拟合是避免不了的，再好的模型也会有过拟合的情况的）。\n\n<!-- more -->\n\n## **一、简介**\n\n 决策树归纳是从有类标号的训练元组中学习决策模型。常用的决策树算法有ID3，C4.5和CART。它们都是采用贪心（即非回溯的）方法，自顶向下递归的分治方法构造。这几个算法选择属性划分的方法各不相同，<font color=\"#1986C7\">**ID3使用的是信息增益，C4.5使用的是信息增益率，而CART使用的是Gini基尼指数**</font>。下面来简单介绍下决策树的理论知识。内容包含**熵**、**信息增益**、**信息增益率**以及**Gini指数**的概念及公式。\n \n---\n\n## **二、决策树原理**\n\n决策树原理很简单，通俗易懂，最简单的就是二元划分，类似于二叉树。例如只考虑某一层某个节点的划分，如果年龄大于18，就表示成年人，如果年龄小于18就表示未成年人。\n\n### **2.1 算法优点**\n\n 决策树算法的优点如下：  \n\n- 算法简单；  \n- 易于理解；  \n- 对噪声数据有很好的健壮性。  \n\n它是目前应用最为广泛的归纳推理算法之一，在数据挖掘中受到研究者的广泛关注。很多集成算法，如随机森林、adaboost、GBDT都是基于决策树的模型。\n  \n### **2.2 算法一般流程**\n\n（1）收集数据：任意方法和途径。  \n（2）准备数据：书构造算法只适用于标称型数据，因此数据必须离散化。  \n（3）分析数据：构造树完成后，检查图形是否符合预测。  \n（4）训练算法：决策树的数据构造。  \n（5）测试算法：一般将决策树用于分类，可以用错误率衡量，而错误率使用经验率计算。  \n（6）使用算法：决策树可以用于任何监督学习算法。  \n\n### **2.3 实例分析**\n\n**信息增益和熵（克劳德.香农提出）**\n\n#### **1.使用信息增益作为划分属性**\n\n**信息增益度量属性选择**\n\n熵被用来衡量一个随机变量出现的期望值。熵越大，一个变量的不确定性就越大（也就是可取的值很多），把它搞清楚所需要的信息量也就越大，熵是整个系统的平均消息量。 信息熵是信息论中用于度量信息量的一个概念。<font color=\"#1986C7\">**一个系统越是有序，信息熵就越低；反之，一个系统越是混乱，信息熵就越高**</font>。所以，信息熵也可以说是系统有序化程度的一个度量。\n\n**熵（Entropy）的计算公式**\n\n熵定义为**信息的期望值**。先看看信息的定义：\n\n$$l(x_i)=-log_2p(x_i)$$\n\n其中，$p(x_i)$是选择该分类的概率。对$D$中的元组所有分类所有可能值的信息期望，即熵，计算公式如下：\n\n$$Entropy=H(D)=E(I(D))=-\\sum_i^{n} p_ilog_2(p_i)，p_i是D中任意元组属于类C_i非零概率。$$\n\n<font color=\"#1986C7\">**熵越大，说明系统越混乱，携带的信息就越少。熵越小，说明系统越有序，携带的信息就越多**</font>。信息的作用就是在于消除不确定性。\n\n\nID3划分特征使用的就是信息增益IG。<font color=\"#1986C7\">**一个属性的信息增益越大，表明属性对样本的熵减少的能力就更强，该属性使得数据所属类别的不确定性变为确定性的能力越强**</font>。信息增益在统计学中称为互信息，互信息是条件概率与后验概率的比值，化简之后就可以得到信息增益。所以说互信息其实就是信息增益。计算方法【互信息=熵-条件熵】。熵描述的是不确定性。熵越大，不确定性就越大，条件熵H（B|A）描述的是在A给定的条件下B的不确定性，如果条件熵越小，表示不确定性就越小，那么B就越容易确定结果。所以使用熵减去条件熵，就得到了信息增益，他描述的不确定性的降低程度，可以用来度量两个变量的相关性。比如，在给定一个变量的条件下，另一个变量它的不确定性能够降低多少，如果不确定性降低得越多，那么它的确定性就越大，就越容易区分，两者就越相关。注：**期望信息越小，分区的纯度越高。**\n\n**信息增益计算**\n\n首先计算特征A对数据集D的经验**条件熵**$H(D|A)$,在数学上就是条件概率分布（Condition Probability）.\n\n$$H(D|A)=\\sum_j\\dfrac{|D_j|}{|D|}\\times H(D_j)，项\\dfrac{|D_i|}{|D|}充当第j个分区的权重$$\n\n引入条件熵，在信息论中主要是为了消除结果的不确定性。然后计算信息增益\n\n$$Gain(A) = H(D) - H(D|A)$$\n\n其中，$Gain(A)$即为所求的信息增益。下面来应用一个实例，**训练元组数据D**\n\n![这里写图片描述](http://img.blog.csdn.net/20150513110022176)\n\n在这里\n\n$$H(D)=-\\dfrac{9}{14}log_2\\dfrac{9}{14}-\\dfrac{5}{14}log_2\\dfrac{5}{14}=0.940位$$\n\n$$H(D|age)=\\dfrac{5}{14}\\times(-\\dfrac{2}{5}log_2\\dfrac{2}{5}-\\dfrac{3}{5}log_2 \\dfrac{3}{5})+\\dfrac{4}{14}\\times(-\\dfrac{4}{4}log_2\\dfrac{0}{4}-\\dfrac{0}{4}log_2 \\dfrac{0}{4})+\\dfrac{5}{14}\\times(-\\dfrac{3}{5}log_2\\dfrac{3}{5}-\\dfrac{2}{5}log_2 \\dfrac{2}{5})=0.694位$$\n\n根据计算出来的条件熵，计算按$age$划分的信息增益，计算方法如下：\n\n$$Gain(age)=H(D)-H(D|age)=0.940-0.964=0.246位$$\n\n类似的可以计算出其它属性的信息增益：\n\n$$ Gain(income)=0.029位，\nGain(student)=0.151位，Gain(credit\\_rating)=0.048位 $$\n\n由于$age$在属性中具有最高的信息增益，所以它被选作分裂特征。下面再进行递归计算信息增益，在此就不展示了。ID3采用的就是就是IG，算法步骤如下：\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20150921091028096)\n![这里写图片描述](http://img.blog.csdn.net/20150921091053471)\n</center>\n\n#### **2.使用增益率计算**\n\n在决策树中，**ID3属性划分标准使用的是信息增益，C4.5使用的是信息增益率。**\n\nC4.5算法继承了ID3算法的优点，并在以下几方面对ID3算法进行了改进：  \n\n- 用信息增益率来选择属性，克服了用信息增益选择属性时偏向选择取值多的属性的不足；  \n- 在树构造过程中进行剪枝；  \n- 能够完成对连续属性的离散化处理；  \n- 能够对不完整数据进行处理。  \n\nC4.5算法有如下优点：**产生的分类规则易于理解，准确率较高**。其缺点是：**在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效**。另外，C4.5只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时程序无法运行。\n\n另外，无论是ID3还是C4.5最好在小数据集上使用，决策树分类一般只试用于小数据。当属性取值很多时最好选择C4.5算法，ID3得出的效果会非常差，因为使用信息增益划分时它倾向于取值多的属性。\n\n计算信息增益率时，用到了**分裂信息计算公式：**\n\n$$Split\\_H(D|A)=-∑\\dfrac{|D_j|}{|D|}\\times log_2(\\dfrac{|D_j|}{|D|})$$\n\n信息增益率定义为：\n\n$$Gain\\_Rate(A)=\\dfrac{Gain(A)}{Split\\_H(D|A)}$$\n\n选择具有最大增益率的特征作为分裂特征。\n\n#### **3.基尼指数Gini index**\n\n基尼指数主要在CART算法中用到，随机森林中用到的属性划分标准也是它。Gini index划分是二元的，**它度量的是数据分区或训练元组集D的不纯度，表示的是一个随机选中的样本在子集中被分错的可能性**。计算方式如下：\n\n$$Gini(D)=1-\\sum p^{2}_i ，其中，p_i 是D中元组数以C_i 类的概率，对m个类计算和。$$\n\nGini指数越大，不纯度越大，越不容易区分。假设A有v个不同的值出现在特征D中，它的二元划分有$2^v - 2$种（除去自己和空集）。当考虑二元划分裂时，计算每个结果分区的不纯度加权和。比如A有两个值，则特征D被划分成D1和D2,这时Gini指数为：\n\n![$$Gini_A(D) = \\frac{D_1}{D} Gini(D_1) + \\frac{D_2}{D} Gini(D_2)$$](http://latex.codecogs.com/gif.latex?Gini_A%28D%29%20%3D%20%5Cfrac%7BD_1%7D%7BD%7D%20Gini%28D_1%29%20&plus;%20%5Cfrac%7BD_2%7D%7BD%7D%20Gini%28D_2%29)\n\n上面的式子表示的是不确定性的大小。对于每个属性，考虑每种可能的二元划分，对于离散值属性，**选择该属性产生最小Gini指数的自己作为它的分裂信息**。\n\n---\n\n## **三、学习推介**\n\nAndrew W. Moore PPT [DTree](http://www.autonlab.org/tutorials/dtree18.pdf)  \n决策树Python实现，单独成文，网址：[决策树实现](http://blog.csdn.net/dream_angel_z/article/details/45965463)  \nWikipedia维基百科-[Decision Tree决策树](https://en.wikipedia.org/wiki/Decision_tree)\n\n最后，附一张决策树的优点和缺点图：\n\n<center>\n![这里写图片描述](http://img.blog.csdn.net/20150921094738621)\n</center>\n\n\n## **四、参考文献**\n\n- [1]数据挖掘概念与技术 Third Edition,韩家伟.  \n- [2]机器学习实战 ,Peter Harrington.  \n\n------\n<br>\n","slug":"2015-05-08-decision tree","published":1,"updated":"2016-05-10T16:00:33.820Z","_id":"cimigpz1o009u6cuj3msd00b0","photos":[],"link":""},{"layout":"post","title":"Git小结-同步一个fork","date":"2015-04-15T05:14:54.000Z","_content":"\n\n## 如何使用搜索引擎\n\n其实这个问题并不难，我又被坑了。百度搜的东西不靠谱啊，以后这种问题一定要用**英文**在 [Google](http://www.google.com) 或者 [Bing](http://cn.bing.com/) 上搜索，这样才能搜到原汁原味的答案。就当是一个教训吧。   \n\n搜索 fork sync，就可以看到 GitHub 自己的帮助文档 [Syncing a fork](https://help.github.com/articles/syncing-a-fork/) 点进去看这篇的时候，注意到有一个 Tip: Before you can sync your fork with an upstream repository, you must [configure a remote that points to the upstream repository](https://help.github.com/articles/configuring-a-remote-for-a-fork/) in Git.    \n根据这两篇文章，问题迎刃而解！ \n  \n<!-- more -->\n\n---\n\n## 具体方法\n\n---\n\n### Configuring a remote for a fork\n\n* 给 fork 配置一个 remote   \n\n* 主要使用 `git remote -v` 查看远程状态。   \n\n\n<pre><code>git remote -v\n# origin  https://github.com/YOUR_USERNAME/YOUR_FORK.git (fetch)\n# origin  https://github.com/YOUR_USERNAME/YOUR_FORK.git (push)\n</code></pre>\n\n* 添加一个将被同步给 fork 远程的上游仓库      \n\n\n<pre><code>git remote add upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git\n</code></pre>\n\n\n* 再次查看状态确认是否配置成功。   \n\n<pre><code>git remote -v\n# origin    https://github.com/YOUR_USERNAME/YOUR_FORK.git (fetch)\n# origin    https://github.com/YOUR_USERNAME/YOUR_FORK.git (push)\n# upstream  https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git (fetch)\n# upstream  https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git (push)\n</code></pre>\n\n---\n\n### Syncing a fork\n\n* 从上游仓库 fetch 分支和提交点，传送到本地，并会被存储在一个本地分支 upstream/master   \n`git fetch upstream`    \n\n<pre><code>git fetch upstream\n# remote: Counting objects: 75, done.\n# remote: Compressing objects: 100% (53/53), done.\n# remote: Total 62 (delta 27), reused 44 (delta 9)\n# Unpacking objects: 100% (62/62), done.\n# From https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY\n#  * [new branch]      master     -> upstream/master\n</code></pre>\n\n* 切换到本地主分支(如果不在的话)    \n`git checkout master`    \n\n<pre><code>git checkout master\n# Switched to branch 'master'\n</code></pre>\n\n* 把 upstream/master 分支合并到本地 master 上，这样就完成了同步，并且不会丢掉本地修改的内容。    \n`git merge upstream/master`      \n\n<pre><code>git merge upstream/master\n# Updating a422352..5fdff0f\n# Fast-forward\n#  README                    |    9 -------\n#  README.md                 |    7 ++++++\n#  2 files changed, 7 insertions(+), 9 deletions(-)\n#  delete mode 100644 README\n#  create mode 100644 README.md\n</code></pre>\n\n* 如果想更新到 GitHub 的 fork 上，直接 `git push origin master` 就好了。\n\n---","source":"_posts/2015-04-12-Syncing-a-fork.md","raw":"---\nlayout: post\ntitle:  \"Git小结-同步一个fork\"\ndate:   2015-04-15 13:14:54\ncategories: GitHub\ntags: \n\t- GitHub\n\t- fork\n\t- 同步\n---\n\n\n## 如何使用搜索引擎\n\n其实这个问题并不难，我又被坑了。百度搜的东西不靠谱啊，以后这种问题一定要用**英文**在 [Google](http://www.google.com) 或者 [Bing](http://cn.bing.com/) 上搜索，这样才能搜到原汁原味的答案。就当是一个教训吧。   \n\n搜索 fork sync，就可以看到 GitHub 自己的帮助文档 [Syncing a fork](https://help.github.com/articles/syncing-a-fork/) 点进去看这篇的时候，注意到有一个 Tip: Before you can sync your fork with an upstream repository, you must [configure a remote that points to the upstream repository](https://help.github.com/articles/configuring-a-remote-for-a-fork/) in Git.    \n根据这两篇文章，问题迎刃而解！ \n  \n<!-- more -->\n\n---\n\n## 具体方法\n\n---\n\n### Configuring a remote for a fork\n\n* 给 fork 配置一个 remote   \n\n* 主要使用 `git remote -v` 查看远程状态。   \n\n\n<pre><code>git remote -v\n# origin  https://github.com/YOUR_USERNAME/YOUR_FORK.git (fetch)\n# origin  https://github.com/YOUR_USERNAME/YOUR_FORK.git (push)\n</code></pre>\n\n* 添加一个将被同步给 fork 远程的上游仓库      \n\n\n<pre><code>git remote add upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git\n</code></pre>\n\n\n* 再次查看状态确认是否配置成功。   \n\n<pre><code>git remote -v\n# origin    https://github.com/YOUR_USERNAME/YOUR_FORK.git (fetch)\n# origin    https://github.com/YOUR_USERNAME/YOUR_FORK.git (push)\n# upstream  https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git (fetch)\n# upstream  https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git (push)\n</code></pre>\n\n---\n\n### Syncing a fork\n\n* 从上游仓库 fetch 分支和提交点，传送到本地，并会被存储在一个本地分支 upstream/master   \n`git fetch upstream`    \n\n<pre><code>git fetch upstream\n# remote: Counting objects: 75, done.\n# remote: Compressing objects: 100% (53/53), done.\n# remote: Total 62 (delta 27), reused 44 (delta 9)\n# Unpacking objects: 100% (62/62), done.\n# From https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY\n#  * [new branch]      master     -> upstream/master\n</code></pre>\n\n* 切换到本地主分支(如果不在的话)    \n`git checkout master`    \n\n<pre><code>git checkout master\n# Switched to branch 'master'\n</code></pre>\n\n* 把 upstream/master 分支合并到本地 master 上，这样就完成了同步，并且不会丢掉本地修改的内容。    \n`git merge upstream/master`      \n\n<pre><code>git merge upstream/master\n# Updating a422352..5fdff0f\n# Fast-forward\n#  README                    |    9 -------\n#  README.md                 |    7 ++++++\n#  2 files changed, 7 insertions(+), 9 deletions(-)\n#  delete mode 100644 README\n#  create mode 100644 README.md\n</code></pre>\n\n* 如果想更新到 GitHub 的 fork 上，直接 `git push origin master` 就好了。\n\n---","slug":"2015-04-12-Syncing-a-fork","published":1,"updated":"2016-03-08T08:46:56.581Z","comments":1,"photos":[],"link":"","_id":"cimigpz1v009z6cuj7bzbzbj3"},{"layout":"post","title":"代码校验工具 SublimeLinter 的安装与使用","date":"2015-03-26T07:14:54.000Z","_content":"\n## 序   \n\n本文我将讲述一下 SublimeLinter 的安装过程。   \n其组件 jshint 的安装与使用。   \n其组件 csslint 的安装与使用。   \n我将基于 [Sublime Text 3](http://sublimetext.com/3) 来安装。   \n使用 Sublime Text 2 的用户阅读本文是没有帮助的。   \n\nSublimeLinter 是 Sublime 的插件，它的作用是检查代码语法是否有错误，并提示。习惯了 IDE 下写代码的人一定需要一款在 Sublime 上类似的语法检查工具。下面我们开始。   \n\n<!-- more -->\n\n---\n\n## 安装 SublimeLinter   \n\n如同其他插件一样使用 Package Control 来安装。   \n\n1. 按下 `Ctrl+Shift+p` 进入 Command Palette   \n2. 输入`install`进入 Package Control: Install Package   \n3. 输入`SublimeLinter`。进行安装.   \n\n![SublimeLinter](http://7q5cdt.com1.z0.glb.clouddn.com/SublimeLinter-sublimeLinter.jpg)   \n\n安装完成后可以看到这样一段话：   \n\n<pre><code class=\"markdown\">Welcome to SublimeLinter, a linter framework for Sublime Text 3.\n \n                  * * * IMPORTANT! * * *\n\n         SublimeLinter 3 is NOT a drop-in replacement for\n        earlier versions.\n\n         Linters *NOT* included with SublimeLinter 3, \n         they must be installed separately.\n \n         The settings are different.\n \n                 * * * READ THE DOCS! * * *\n \n Otherwise you will never know how to install linters, nor will\n you know about all of the great new features in SublimeLinter 3.\n \n For complete documentation on how to install and use SublimeLinter,\n please see:\n \n http://www.sublimelinter.com</code></pre>   \n\n可以看到具体的 Linters 组件**不**被包含在 SublimeLinter 3 中，所以我们要额外独立安装组件。   \n可以针对不同的语言安装不同的组件。   \n\n---\n\n## JavaScript 语法检查   \n\nSublimeLinter-jshint 是基于 nodeJS 下的 jshint 的插件，实际上 SublimeLinter-jshint 调用了 nodeJS 中 jshint 的接口来进行语法检查的。   \n\n---\n\n### 安装 SublimeLinter-jshint\n\n为了让 JavaScript 代码有语法检查，我们安装 SublimeLinter-jshint   \n同样的方法，我们安装 SublimeLinter-jshint    \n\n1. 按下 `Ctrl+Shift+p` 进入 Command Palette   \n2. 输入`install`进入 Package Control: Install Package   \n3. 输入`SublimeLinter-jshint`。进行安装.   \n\n如下图   \n\n![SublimeLinter-jshint](http://7q5cdt.com1.z0.glb.clouddn.com/SublimeLinter-jshint.jpg)   \n\n安装完成后我们可以看到下面的一段话   \n\n<pre><code class=\"markdown\">SublimeLinter-jshint\n  -------------------------------\n  This linter plugin for SublimeLinter provides an interface to jshint.\n  \n  ** IMPORTANT! **\n  \n  Before this plugin will activate, you *must*\n  follow the installation instructions here:\n  \n  https://github.com/SublimeLinter/SublimeLinter-jshint\n</code></pre>\n\n---\n\n### 安装 nodeJS 和 jshint\n\n在插件开始工作之前，我们必须再看一下上述插件的[安装说明](https://github.com/SublimeLinter/SublimeLinter-jshint)   \n通过 [SublimeLinter-jshint 的说明](https://github.com/SublimeLinter/SublimeLinter-jshint) 我们可以看到，这个组件依赖于 nodeJS 下的 jshint，所以我们安装 nodeJS 环境和 nodeJS 下的 jshint。   \n\n1. 安装 [Node.js](https://nodejs.org/)   \n2. 通过 npm 安装`jshint`   \n\n在命令行下输入如下代码，完成安装   \n\n\tnpm install -g jshint\n\n安装完成后命令行中出现如下的信息   \n\n\tC:\\Users\\Administrator\\AppData\\Roaming\\npm\\jshint -> C:\\Users\\Administrator\\AppData\\Roaming\\npm\\node_modules\\jshint\\bin\\jshint\n\tjshint@2.6.3 C:\\Users\\Administrator\\AppData\\Roaming\\npm\\node_modules\\jshint\n\t├── strip-json-comments@1.0.2\n\t├── underscore@1.6.0\n\t├── exit@0.1.2\n\t├── shelljs@0.3.0\n\t├── console-browserify@1.1.0 (date-now@0.1.4)\n\t├── htmlparser2@3.8.2 (domelementtype@1.3.0, entities@1.0.0, domhandler@2.3.0, readable-stream@1.1.13, domutils@1.5.1)\n\t├── minimatch@1.0.0 (sigmund@1.0.0, lru-cache@2.5.0)\n\t└── cli@0.6.6 (glob@3.2.11)\n\n可以查看 jshint 版本，已确认安装完成。  \n\n\tC:\\Users\\Administrator>jshint -v\n\tjshint v2.6.3\n\n现在，恭喜你，我们使用 Sublime 编辑 JavaScript 文件，就会有语法检查了！   \n\n在编辑过程中，会有如下提示   \n\n![SublimeLinter-jshint-test](http://7q5cdt.com1.z0.glb.clouddn.com/SublimeLinter-jshint-test.jpg)\n\n点击提示点后，Sublime 状态栏也会有相应的说明   \n\n![SublimeLinter-jshint-test2](http://7q5cdt.com1.z0.glb.clouddn.com/SublimeLinter-jshint-test2.jpg)\n\n---\n\n## css 语法检查 \n\n与 jshint 同理，SublimeLinter-csslint 也是基于 nodeJS 下的 csslint 的插件，实际上 SublimeLinter-csslint 调用了 nodeJS 中 csslint 的接口来进行语法检查的。   \n\n---\n\n### 安装 SublimeLinter-csslint   \n\n同样的方法。   \n\n1. 按下 `Ctrl+Shift+p` 进入 Command Palette   \n2. 输入`install`进入 Package Control: Install Package   \n3. 输入`SublimeLinter-csslint`。进行安装.   \n\n如下图   \n\n![SublimeLinter-csslint](http://7q5cdt.com1.z0.glb.clouddn.com/SublimeLinter-csslint.jpg)   \n\n安装完成后我们可以看到下面的一段话   \n\n\tSublimeLinter-csslint\n\t-------------------------------\n\tThis linter plugin for SublimeLinter provides an interface to csslint.\n\n\t** IMPORTANT! **\n\n\tBefore this plugin will activate, you *must*\n\tfollow the installation instructions here:\n\n\thttps://github.com/SublimeLinter/SublimeLinter-csslint\n\n在使用插件之前，必须遵循上述网址中的[安装说明](https://github.com/SublimeLinter/SublimeLinter-csslint)   \n\n---\n\n### 在 nodeJS 下安装 csslint   \n\n进入上述的 GitHub 地址，csslint 的说明页。我们知道了和 jshint 一样，csslint 也是基于 nodeJS 下的 csslint 来使用的。   \n\n这里安装 nodeJS 过程省略。   \n只需用 npm 安装 csslint 即可。   \n\n在命令行中输入     \n\n\tnpm install -g csslint   \n\n安装完成后命令行中出现如下的信息     \n\n\tC:\\Users\\Administrator\\AppData\\Roaming\\npm\\csslint -> C:\\Users\\Administrator\\AppData\\Roaming\\npm\\node_modules\\csslint\\cli.js\n\tcsslint@0.10.0 C:\\Users\\Administrator\\AppData\\Roaming\\npm\\node_modules\\csslint\n\t└── parserlib@0.2.5\n\n可以查看 csslint 版本，已确认安装完成。   \n\n\tC:\\Users\\Administrator>csslint --version\n\tv0.10.0\n\n现在，恭喜你，我们使用 Sublime 编辑 css 文件，就会有语法检查了！     \n\n在编辑过程中，会有如下提示   \n\n![SublimeLinter-csslint-test](http://7q5cdt.com1.z0.glb.clouddn.com/SublimeLinter-csslint-test.jpg)\n\n点击提示点后，Sublime 状态栏也会有相应的说明   \n\n![SublimeLinter-csslint-test2](http://7q5cdt.com1.z0.glb.clouddn.com/SublimeLinter-csslint-test2.jpg)\n\n---","source":"_posts/2015-03-26-sublimeLinter.md","raw":"---\nlayout: post\ntitle:  \"代码校验工具 SublimeLinter 的安装与使用\"\ndate:   2015-03-26 15:14:54\ntags: \n\t- SublimeLinter\ncategories: 工具\n---\n\n## 序   \n\n本文我将讲述一下 SublimeLinter 的安装过程。   \n其组件 jshint 的安装与使用。   \n其组件 csslint 的安装与使用。   \n我将基于 [Sublime Text 3](http://sublimetext.com/3) 来安装。   \n使用 Sublime Text 2 的用户阅读本文是没有帮助的。   \n\nSublimeLinter 是 Sublime 的插件，它的作用是检查代码语法是否有错误，并提示。习惯了 IDE 下写代码的人一定需要一款在 Sublime 上类似的语法检查工具。下面我们开始。   \n\n<!-- more -->\n\n---\n\n## 安装 SublimeLinter   \n\n如同其他插件一样使用 Package Control 来安装。   \n\n1. 按下 `Ctrl+Shift+p` 进入 Command Palette   \n2. 输入`install`进入 Package Control: Install Package   \n3. 输入`SublimeLinter`。进行安装.   \n\n![SublimeLinter](http://7q5cdt.com1.z0.glb.clouddn.com/SublimeLinter-sublimeLinter.jpg)   \n\n安装完成后可以看到这样一段话：   \n\n<pre><code class=\"markdown\">Welcome to SublimeLinter, a linter framework for Sublime Text 3.\n \n                  * * * IMPORTANT! * * *\n\n         SublimeLinter 3 is NOT a drop-in replacement for\n        earlier versions.\n\n         Linters *NOT* included with SublimeLinter 3, \n         they must be installed separately.\n \n         The settings are different.\n \n                 * * * READ THE DOCS! * * *\n \n Otherwise you will never know how to install linters, nor will\n you know about all of the great new features in SublimeLinter 3.\n \n For complete documentation on how to install and use SublimeLinter,\n please see:\n \n http://www.sublimelinter.com</code></pre>   \n\n可以看到具体的 Linters 组件**不**被包含在 SublimeLinter 3 中，所以我们要额外独立安装组件。   \n可以针对不同的语言安装不同的组件。   \n\n---\n\n## JavaScript 语法检查   \n\nSublimeLinter-jshint 是基于 nodeJS 下的 jshint 的插件，实际上 SublimeLinter-jshint 调用了 nodeJS 中 jshint 的接口来进行语法检查的。   \n\n---\n\n### 安装 SublimeLinter-jshint\n\n为了让 JavaScript 代码有语法检查，我们安装 SublimeLinter-jshint   \n同样的方法，我们安装 SublimeLinter-jshint    \n\n1. 按下 `Ctrl+Shift+p` 进入 Command Palette   \n2. 输入`install`进入 Package Control: Install Package   \n3. 输入`SublimeLinter-jshint`。进行安装.   \n\n如下图   \n\n![SublimeLinter-jshint](http://7q5cdt.com1.z0.glb.clouddn.com/SublimeLinter-jshint.jpg)   \n\n安装完成后我们可以看到下面的一段话   \n\n<pre><code class=\"markdown\">SublimeLinter-jshint\n  -------------------------------\n  This linter plugin for SublimeLinter provides an interface to jshint.\n  \n  ** IMPORTANT! **\n  \n  Before this plugin will activate, you *must*\n  follow the installation instructions here:\n  \n  https://github.com/SublimeLinter/SublimeLinter-jshint\n</code></pre>\n\n---\n\n### 安装 nodeJS 和 jshint\n\n在插件开始工作之前，我们必须再看一下上述插件的[安装说明](https://github.com/SublimeLinter/SublimeLinter-jshint)   \n通过 [SublimeLinter-jshint 的说明](https://github.com/SublimeLinter/SublimeLinter-jshint) 我们可以看到，这个组件依赖于 nodeJS 下的 jshint，所以我们安装 nodeJS 环境和 nodeJS 下的 jshint。   \n\n1. 安装 [Node.js](https://nodejs.org/)   \n2. 通过 npm 安装`jshint`   \n\n在命令行下输入如下代码，完成安装   \n\n\tnpm install -g jshint\n\n安装完成后命令行中出现如下的信息   \n\n\tC:\\Users\\Administrator\\AppData\\Roaming\\npm\\jshint -> C:\\Users\\Administrator\\AppData\\Roaming\\npm\\node_modules\\jshint\\bin\\jshint\n\tjshint@2.6.3 C:\\Users\\Administrator\\AppData\\Roaming\\npm\\node_modules\\jshint\n\t├── strip-json-comments@1.0.2\n\t├── underscore@1.6.0\n\t├── exit@0.1.2\n\t├── shelljs@0.3.0\n\t├── console-browserify@1.1.0 (date-now@0.1.4)\n\t├── htmlparser2@3.8.2 (domelementtype@1.3.0, entities@1.0.0, domhandler@2.3.0, readable-stream@1.1.13, domutils@1.5.1)\n\t├── minimatch@1.0.0 (sigmund@1.0.0, lru-cache@2.5.0)\n\t└── cli@0.6.6 (glob@3.2.11)\n\n可以查看 jshint 版本，已确认安装完成。  \n\n\tC:\\Users\\Administrator>jshint -v\n\tjshint v2.6.3\n\n现在，恭喜你，我们使用 Sublime 编辑 JavaScript 文件，就会有语法检查了！   \n\n在编辑过程中，会有如下提示   \n\n![SublimeLinter-jshint-test](http://7q5cdt.com1.z0.glb.clouddn.com/SublimeLinter-jshint-test.jpg)\n\n点击提示点后，Sublime 状态栏也会有相应的说明   \n\n![SublimeLinter-jshint-test2](http://7q5cdt.com1.z0.glb.clouddn.com/SublimeLinter-jshint-test2.jpg)\n\n---\n\n## css 语法检查 \n\n与 jshint 同理，SublimeLinter-csslint 也是基于 nodeJS 下的 csslint 的插件，实际上 SublimeLinter-csslint 调用了 nodeJS 中 csslint 的接口来进行语法检查的。   \n\n---\n\n### 安装 SublimeLinter-csslint   \n\n同样的方法。   \n\n1. 按下 `Ctrl+Shift+p` 进入 Command Palette   \n2. 输入`install`进入 Package Control: Install Package   \n3. 输入`SublimeLinter-csslint`。进行安装.   \n\n如下图   \n\n![SublimeLinter-csslint](http://7q5cdt.com1.z0.glb.clouddn.com/SublimeLinter-csslint.jpg)   \n\n安装完成后我们可以看到下面的一段话   \n\n\tSublimeLinter-csslint\n\t-------------------------------\n\tThis linter plugin for SublimeLinter provides an interface to csslint.\n\n\t** IMPORTANT! **\n\n\tBefore this plugin will activate, you *must*\n\tfollow the installation instructions here:\n\n\thttps://github.com/SublimeLinter/SublimeLinter-csslint\n\n在使用插件之前，必须遵循上述网址中的[安装说明](https://github.com/SublimeLinter/SublimeLinter-csslint)   \n\n---\n\n### 在 nodeJS 下安装 csslint   \n\n进入上述的 GitHub 地址，csslint 的说明页。我们知道了和 jshint 一样，csslint 也是基于 nodeJS 下的 csslint 来使用的。   \n\n这里安装 nodeJS 过程省略。   \n只需用 npm 安装 csslint 即可。   \n\n在命令行中输入     \n\n\tnpm install -g csslint   \n\n安装完成后命令行中出现如下的信息     \n\n\tC:\\Users\\Administrator\\AppData\\Roaming\\npm\\csslint -> C:\\Users\\Administrator\\AppData\\Roaming\\npm\\node_modules\\csslint\\cli.js\n\tcsslint@0.10.0 C:\\Users\\Administrator\\AppData\\Roaming\\npm\\node_modules\\csslint\n\t└── parserlib@0.2.5\n\n可以查看 csslint 版本，已确认安装完成。   \n\n\tC:\\Users\\Administrator>csslint --version\n\tv0.10.0\n\n现在，恭喜你，我们使用 Sublime 编辑 css 文件，就会有语法检查了！     \n\n在编辑过程中，会有如下提示   \n\n![SublimeLinter-csslint-test](http://7q5cdt.com1.z0.glb.clouddn.com/SublimeLinter-csslint-test.jpg)\n\n点击提示点后，Sublime 状态栏也会有相应的说明   \n\n![SublimeLinter-csslint-test2](http://7q5cdt.com1.z0.glb.clouddn.com/SublimeLinter-csslint-test2.jpg)\n\n---","slug":"2015-03-26-sublimeLinter","published":1,"updated":"2016-03-08T09:01:57.155Z","comments":1,"photos":[],"link":"","_id":"cimigpz2200a66cujhvgxjgp2"},{"layout":"post","date":"2015-03-18T02:24:00.000Z","title":"机器学习算法Top10","comment":true,"_content":"\n以下就是从参加评选的18种候选算法中，最终决选出来的十大经典算法：\n\n### 一、C4.5\n\nC4.5，是机器学习算法中的一个分类决策树算法，\n它是决策树(决策树也就是做决策的节点间的组织方式像一棵树，其实是一个倒树)核心算法\nID3的改进算法，所以基本上了解了一半决策树构造方法就能构造它。\n决策树构造方法其实就是每次选择一个好的特征以及分裂点作为当前节点的分类条件。\n\nC4.5相比于ID3改进的地方有：\n\n<!-- more -->\n\n- 1.用信息增益率来选择属性。ID3选择属性用的是子树的信息增益，这里可以用很多方法来定义信息，ID3使用的是熵(entropy，熵是一种不纯度度量准则),也就是熵的变化值.而C4.5用的是信息增益率。区别就在于<font color=\"#007FFF\">**一个是信息增益，一个是信息增益率**</font>。一般来说率就是用来取平衡用的，就像方差起的作用差不多，比如有两个跑步的人，一个起点是10m/s的人、其10s后为20m/s；另一个人起速是1m/s、其1s后为2m/s。如果紧紧算差值那么两个差距就很大了，如果使用速度增加率(加速度，即都是为1m/s^2)来衡量，2个人就是一样的加速度。因此，C4.5克服了ID3用信息增益选择属性时偏向选择取值多的属性的不足。\n- 2.在树构造过程中进行剪枝，在构造决策树的时候，那些挂着几个元素的节点，不考虑最好，不然容易导致overfitting。\n- 3.对非离散数据也能处理。\n- 4.能够对不完整数据进行处理。\n\n\n### 二、The k-means algorithm 即K-Means算法\n\nk-means algorithm算法是一个聚类算法，<font color=\"#007FFF\">**把n的对象根据他们的属性分为k个分割(k < n)**</font>。它与处理混合正态分布的最大期望算法(本十大算法第五条)很相似，因为他们都试图找到数据中自然聚类的中心。\n它假设对象属性来自于空间向量，并且目标是使各个群组内部的均方误差总和最小。\n\n\n### 三、 Support vector machines\n\n支持向量机，英文为Support Vector Machine，简称SV机（论文中一般简称SVM）。\n\n它是一种监督式学习的方法，它广泛的应用于统计分类以及回归分析中。\n<font color=\"#007FFF\">**支持向量机将向量映射到一个更高维的空间里，在这个空间里建立有一个最大间隔超平面**</font>。在分开数据的超平面的两边建有两个互相平行的超平面，分隔超平面使两个平行超平面的距离最大化。假定平行超平面间的距离或差距越大，分类器的总误差越小。\n\n一个极好的指南是C.J.C Burges的《模式识别支持向量机指南》。van der Walt 和 Barnard 将支持向量机和其他分类器进行了比较。\n\n\n### 四、The Apriori algorithm\n\nApriori算法是一种最有影响的<font color=\"#007FFF\">**挖掘布尔关联规则频繁项集**</font>的算法。其核心是基于两阶段频集思想的递推算法。该关联规则在分类上属于单维、单层、布尔关联规则。在这里，<font color=\"#007FFF\">**所有支持度大于最小支持度的项集称为频繁项集，简称频集**</font>。\n\n\n### 五、最大期望(EM)算法\n\n在统计计算中，最大期望 （EM，Expectation–Maximization）算法是在概率（probabilistic）模型中寻找参数最大似然估计的算法，其中概率模型依赖于无法观测的隐藏变量（Latent Variabl）。\n\n最大期望经常用在机器学习和计算机视觉的数据集聚（Data Clustering）领域。\n\n\n### 六、 PageRank\n\nPageRank是Google算法的重要内容。2001年9月被授予美国专利，专利人是Google创始人之一拉里•佩奇（Larry Page）。因此，PageRank里的page不是指网页，而是指佩奇，即这个等级方法是以佩奇来命名的。PageRank根据网站的外部链接和内部链接的数量和质量，衡量网站的价值。PageRank背后的概念是，每个到页面的链接都是对该页面的一次投票， 被链接的越多，就意味着被其他网站投票越多。\n\n这个就是所谓的“链接流行度”——衡量多少人愿意将他们的网站和你的网站挂钩。PageRank这个概念引自学术中一篇论文的被引述的频度——即被别人引述的次数越多，一般判断这篇论文的权威性就越高。\n\n\n### 七、AdaBoost\n\nAdaboost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器 (强分类器)。其算法本身是通过改变数据分布来实现的，它根据每次训练集之中每个样本的分类是否正确，以及上次的总体分类的准确率，来确定每个样本的权值。将修改过权值的新数据集送给下层分类器进行训练，最后将每次训练得到的分类器融合起来，作为最后的决策分类器。\n\n\n### 八、 kNN: k-nearest neighbor classification\n\nK最近邻(k-Nearest Neighbor，KNN)分类算法，是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。KNN方法的思路：<font color=\"#007FFF\">**如果一个样本在特征空间中的k个最相似的(即特征空间中最邻近的K个)样本中的大多数属于某一个类别，则该样本也属于这个类别**</font>。\n\n\n### 九、 Naive Bayes\n\n在众多的分类模型中，应用最为广泛的两种分类模型是<font color=\"#007FFF\">**决策树模型(Decision Tree Model)和朴素贝叶斯模型（Naive Bayesian Model，NBC）**</font>。 朴素贝叶斯模型发源于古典数学理论，有着坚实的数学基础，以及稳定的分类效率。同时，NBC模型所需估计的参数很少，对缺失数据不太敏感，算法也比较简单。理论上，NBC模型与其他分类方法相比具有最小的误差率。但是实际上并非总是如此，这是因为NBC模型假设属性之间相互独立，这个假设在实际应用中往往是不成立的，这给NBC模型的正确分类带来了一定影响。在属性个数比较多或者属性之间相关性较大时，NBC模型的分类效率比不上决策树模型。而在属性相关性较小时，NBC模型的性能最为良好。\n\n\n### 十、 CART: 分类与回归树\n\nCART, Classification and Regression Trees。 在分类树下面有两个关键的思想：**第一个是关于递归地划分自变量空间的想法；第二个想法是用验证数据进行剪枝**。\n\n\n至于18种候选算法，可参考这里：http://www.cs.uvm.edu/~icdm/algorithms/CandidateList.shtml\n\n---\n\n","source":"_posts/2015-03-18-machine-learning-top10-algorithms.md","raw":"---\nlayout: post\ndate: 2015-03-18 10:24\ntitle: \"机器学习算法Top10\"\ncategories: ML\ntag: \n\t- Machine Learning\n\t- 汇总\ncomment: true\n---\n\n以下就是从参加评选的18种候选算法中，最终决选出来的十大经典算法：\n\n### 一、C4.5\n\nC4.5，是机器学习算法中的一个分类决策树算法，\n它是决策树(决策树也就是做决策的节点间的组织方式像一棵树，其实是一个倒树)核心算法\nID3的改进算法，所以基本上了解了一半决策树构造方法就能构造它。\n决策树构造方法其实就是每次选择一个好的特征以及分裂点作为当前节点的分类条件。\n\nC4.5相比于ID3改进的地方有：\n\n<!-- more -->\n\n- 1.用信息增益率来选择属性。ID3选择属性用的是子树的信息增益，这里可以用很多方法来定义信息，ID3使用的是熵(entropy，熵是一种不纯度度量准则),也就是熵的变化值.而C4.5用的是信息增益率。区别就在于<font color=\"#007FFF\">**一个是信息增益，一个是信息增益率**</font>。一般来说率就是用来取平衡用的，就像方差起的作用差不多，比如有两个跑步的人，一个起点是10m/s的人、其10s后为20m/s；另一个人起速是1m/s、其1s后为2m/s。如果紧紧算差值那么两个差距就很大了，如果使用速度增加率(加速度，即都是为1m/s^2)来衡量，2个人就是一样的加速度。因此，C4.5克服了ID3用信息增益选择属性时偏向选择取值多的属性的不足。\n- 2.在树构造过程中进行剪枝，在构造决策树的时候，那些挂着几个元素的节点，不考虑最好，不然容易导致overfitting。\n- 3.对非离散数据也能处理。\n- 4.能够对不完整数据进行处理。\n\n\n### 二、The k-means algorithm 即K-Means算法\n\nk-means algorithm算法是一个聚类算法，<font color=\"#007FFF\">**把n的对象根据他们的属性分为k个分割(k < n)**</font>。它与处理混合正态分布的最大期望算法(本十大算法第五条)很相似，因为他们都试图找到数据中自然聚类的中心。\n它假设对象属性来自于空间向量，并且目标是使各个群组内部的均方误差总和最小。\n\n\n### 三、 Support vector machines\n\n支持向量机，英文为Support Vector Machine，简称SV机（论文中一般简称SVM）。\n\n它是一种监督式学习的方法，它广泛的应用于统计分类以及回归分析中。\n<font color=\"#007FFF\">**支持向量机将向量映射到一个更高维的空间里，在这个空间里建立有一个最大间隔超平面**</font>。在分开数据的超平面的两边建有两个互相平行的超平面，分隔超平面使两个平行超平面的距离最大化。假定平行超平面间的距离或差距越大，分类器的总误差越小。\n\n一个极好的指南是C.J.C Burges的《模式识别支持向量机指南》。van der Walt 和 Barnard 将支持向量机和其他分类器进行了比较。\n\n\n### 四、The Apriori algorithm\n\nApriori算法是一种最有影响的<font color=\"#007FFF\">**挖掘布尔关联规则频繁项集**</font>的算法。其核心是基于两阶段频集思想的递推算法。该关联规则在分类上属于单维、单层、布尔关联规则。在这里，<font color=\"#007FFF\">**所有支持度大于最小支持度的项集称为频繁项集，简称频集**</font>。\n\n\n### 五、最大期望(EM)算法\n\n在统计计算中，最大期望 （EM，Expectation–Maximization）算法是在概率（probabilistic）模型中寻找参数最大似然估计的算法，其中概率模型依赖于无法观测的隐藏变量（Latent Variabl）。\n\n最大期望经常用在机器学习和计算机视觉的数据集聚（Data Clustering）领域。\n\n\n### 六、 PageRank\n\nPageRank是Google算法的重要内容。2001年9月被授予美国专利，专利人是Google创始人之一拉里•佩奇（Larry Page）。因此，PageRank里的page不是指网页，而是指佩奇，即这个等级方法是以佩奇来命名的。PageRank根据网站的外部链接和内部链接的数量和质量，衡量网站的价值。PageRank背后的概念是，每个到页面的链接都是对该页面的一次投票， 被链接的越多，就意味着被其他网站投票越多。\n\n这个就是所谓的“链接流行度”——衡量多少人愿意将他们的网站和你的网站挂钩。PageRank这个概念引自学术中一篇论文的被引述的频度——即被别人引述的次数越多，一般判断这篇论文的权威性就越高。\n\n\n### 七、AdaBoost\n\nAdaboost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器 (强分类器)。其算法本身是通过改变数据分布来实现的，它根据每次训练集之中每个样本的分类是否正确，以及上次的总体分类的准确率，来确定每个样本的权值。将修改过权值的新数据集送给下层分类器进行训练，最后将每次训练得到的分类器融合起来，作为最后的决策分类器。\n\n\n### 八、 kNN: k-nearest neighbor classification\n\nK最近邻(k-Nearest Neighbor，KNN)分类算法，是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。KNN方法的思路：<font color=\"#007FFF\">**如果一个样本在特征空间中的k个最相似的(即特征空间中最邻近的K个)样本中的大多数属于某一个类别，则该样本也属于这个类别**</font>。\n\n\n### 九、 Naive Bayes\n\n在众多的分类模型中，应用最为广泛的两种分类模型是<font color=\"#007FFF\">**决策树模型(Decision Tree Model)和朴素贝叶斯模型（Naive Bayesian Model，NBC）**</font>。 朴素贝叶斯模型发源于古典数学理论，有着坚实的数学基础，以及稳定的分类效率。同时，NBC模型所需估计的参数很少，对缺失数据不太敏感，算法也比较简单。理论上，NBC模型与其他分类方法相比具有最小的误差率。但是实际上并非总是如此，这是因为NBC模型假设属性之间相互独立，这个假设在实际应用中往往是不成立的，这给NBC模型的正确分类带来了一定影响。在属性个数比较多或者属性之间相关性较大时，NBC模型的分类效率比不上决策树模型。而在属性相关性较小时，NBC模型的性能最为良好。\n\n\n### 十、 CART: 分类与回归树\n\nCART, Classification and Regression Trees。 在分类树下面有两个关键的思想：**第一个是关于递归地划分自变量空间的想法；第二个想法是用验证数据进行剪枝**。\n\n\n至于18种候选算法，可参考这里：http://www.cs.uvm.edu/~icdm/algorithms/CandidateList.shtml\n\n---\n\n","slug":"2015-03-18-machine-learning-top10-algorithms","published":1,"updated":"2016-03-13T06:01:19.923Z","comments":1,"photos":[],"link":"","_id":"cimigpz2800ab6cuj82no2lv5"},{"layout":"post","date":"2015-02-14T04:12:00.000Z","title":"腾讯笔试题-字符串匹配","_content":"\n## 题目\n\n假设两个字符串中所含有的字符和个数都相同我们就叫这两个字符串匹配，比如：abcda和adabc,由于出现的字符个数都是相同，只是顺序不同，所以这两个字符串是匹配的。要求高效。\n\n<!-- more -->\n\n## 思路\n\n假定字符串中都是ASCII字符。用一个数组来计数，前者加，后者减，全部为0则匹配。\n\n## 代码\n\n\n```\n/*---------------------------------------------\n*   date：2015-02-14\n*   author：LDW\n*   title: 字符串匹配\n*   From：腾讯\n*   Blog：http://csuldw.github.io\n-----------------------------------------------*/\n#include <iostream>\n#include <cstring>\nusing namespace std;\n\nclass Solution {\npublic:\n    bool StrMatch(string str1,string str2){\n        int size1 = str1.size();\n        int size2 = str2.size();\n        if(size1 <= 0 || size2 <= 0 || size1 != size2){\n            return false;\n        }\n        int count[256];\n        // 初始化数组\n        memset(count,0,sizeof(count));\n        // 前者加\n        for(int i = 0; i < size1; ++i){\n            ++count[str1[i]];\n        }\n        //后者减\n        for(int i = 0; i < size2; ++i){\n            --count[str2[i]];\n        }\n        //全部为0则匹配\n        for(int i = 0; i < 256; ++i){\n            if(count[i] != 0){\n                return false;\n            }\n        }\n        return true;\n    }\n};\n\n\nint main() {\n    Solution solution;\n    string str1(\"afafafa\");\n    string str2(\"afafaf\");\n    cout<<solution.StrMatch(str1,str2)<<endl;\n}\n```","source":"_posts/2015-02-14-string-match.md","raw":"---\nlayout: post\ndate: 2015-02-14 12:12\ntitle: \"腾讯笔试题-字符串匹配\"\ntag:\n\t- 字符串匹配\n\t- 数据结构\n\t- 笔试\ncategories: 算法与数据结构\n---\n\n## 题目\n\n假设两个字符串中所含有的字符和个数都相同我们就叫这两个字符串匹配，比如：abcda和adabc,由于出现的字符个数都是相同，只是顺序不同，所以这两个字符串是匹配的。要求高效。\n\n<!-- more -->\n\n## 思路\n\n假定字符串中都是ASCII字符。用一个数组来计数，前者加，后者减，全部为0则匹配。\n\n## 代码\n\n\n```\n/*---------------------------------------------\n*   date：2015-02-14\n*   author：LDW\n*   title: 字符串匹配\n*   From：腾讯\n*   Blog：http://csuldw.github.io\n-----------------------------------------------*/\n#include <iostream>\n#include <cstring>\nusing namespace std;\n\nclass Solution {\npublic:\n    bool StrMatch(string str1,string str2){\n        int size1 = str1.size();\n        int size2 = str2.size();\n        if(size1 <= 0 || size2 <= 0 || size1 != size2){\n            return false;\n        }\n        int count[256];\n        // 初始化数组\n        memset(count,0,sizeof(count));\n        // 前者加\n        for(int i = 0; i < size1; ++i){\n            ++count[str1[i]];\n        }\n        //后者减\n        for(int i = 0; i < size2; ++i){\n            --count[str2[i]];\n        }\n        //全部为0则匹配\n        for(int i = 0; i < 256; ++i){\n            if(count[i] != 0){\n                return false;\n            }\n        }\n        return true;\n    }\n};\n\n\nint main() {\n    Solution solution;\n    string str1(\"afafafa\");\n    string str2(\"afafaf\");\n    cout<<solution.StrMatch(str1,str2)<<endl;\n}\n```","slug":"2015-02-14-string-match","published":1,"updated":"2016-03-08T08:46:15.136Z","comments":1,"photos":[],"link":"","_id":"cimigpz2d00ag6cujt8xgsmar"},{"layout":"post","date":"2014-12-26T04:24:00.000Z","title":"排序算法-归并排序","comment":true,"_content":"\n**注：代码均使用C++编写.**\n\n## 介绍\n\n对于数据较大的输入，归并排序是比较快的一个算法。该算法采用的是分治法的思想。\n\n原理：将数据分开排序，然后进行合并，最后形成一个排好的序列。\n\n<!--more-->\n\n![](/assets/articleImg/2014-12-21-mergeSort-1.png)\n\n\n将其合并输出，如下图所示：\n\n![](/assets/articleImg/2014-12-21-mergeSort-2.png)\n\n\n归并排序有一个关键步骤：合并两个排序好的序列。方法是：两个序列中的数相互比较，将较小的数先插入新的序列中。\n\n\n归并过程：比较a[i]和a[j]的大小，若a[i]≤a[j]，则将第一个有序表中的元素a[i]复制到r[k]中，并令i和k分别加上1；否则将第二个有序表中的元素a[j]复制到r[k]中，并令j和k分别加上1，如此循环下去，直到其中一个有序表取完，然后再将另一个有序表中剩余的元素复制到r中从下标k到下标t的单元。归并排序的算法我们通常用递归实现，先把待排序区间[s,t]以中点二分，接着把左边子区间排序，再把右边子区间排序，最后把左区间和右区间用一次归并操作合并成有序的区间[s,t]。\n\n- 发明者：约翰·冯·诺伊曼\n- 时间复杂度：O(nlogn)\n- 空间复杂度 O（n)\n- 稳定的算法\n\n\n## 一次合并\n\n在代码实现部分，需要进行递归进行合并，因此，先编写一个合并的方法。\n\n归并操作的工作原理如下：\n\n一次归并函数传递的参数有：一个数组名、数组的起始位置、数组的末尾位置以及数组的中点位置。\n\n- 第一步：申请空间，初始化起点中点和中点到末尾位置两个变量(nl,nr)，同时设定两个指针p和q，空间大小分别为nl和nr;\n- 第二步：将数组分别输入到两个空间中;\n- 第三步：合并两个数组。操作：比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置;\n- 重复步骤3直到某一指针超出序列尾;\n- 将另一序列剩下的所有元素直接复制到合并序列尾.\n\n在第三步的时候，需要注意的是，不额外的开辟辅助数组，直接通过两个指针的值将原数组的数值进行修改。此处需要设置一个变量`k`，起始位置为数组的起始位置,方便在合并时同时增加指针的下标和数组下标值.\n\n注：使用`malloc`时，需要引入`#include <stdlib.h>`头文件。\n\n代码如下:\n\n```\nvoid mergeOne(int nums[], int l, int m, int r){\n    int nl = m - l + 1;\n    int nr = r - m;\n    int *p = NULL, *q = NULL;\n    p = (int *) malloc (nl * sizeof(int));\n    q = (int *) malloc (nr * sizeof(int));\n\n    //将数组输入到两个空间中\n    for(int i = 0; i < nl; i++) {\n        p[i] = nums[l + i];\n    }\n    for(int j = 0; j < nr; j++) {\n        q[j] = nums[m + 1 + j];\n    }\n\n    //合并两个数组\n    int i = 0;\n    int j = 0;\n    int k = l;\n    while(i < nl && j < nr) {\n        if(p[i] < q[j]) {\n            nums[k++] = p[i++];\n        }else{\n            nums[k++] = q[j++];\n        }\n    }\n\n    //将剩余的元素合并\n    while(i < nl) {\n        nums[k++]  = p[i++];\n    }\n    while(j <nr) {\n        nums[k++] = q[j++];\n    }\n}\n```\n\n\n## 归并排序\n\n通过合并函数来实现归并排序的算法\n\n```\n//注意：此处的left和right必须是数组下标能取到的有效值\nvoid mergeSort(int nums[], int left, int right) {\n    int mid = (left + right) >> 1;\n    if(left < right) {\n        mergeSort(nums, left, mid);\n        mergeSort(nums, mid+1, right);\n        mergeOne(nums, left, mid, right);\n    }\n}\n```\n\n## 测试\n\n```\n#include <iostream>\n#include <stdlib.h>\nvoid print_array(int nums[], int n);\nusing namespace std;\nint main()\n{\n    int nums[]={9, 3, 5, 2, 7, 6, 4, 1};\n    int n = sizeof(nums)/sizeof(nums[0]);\n    mergeSort(nums, 0, n - 1);\n    print_array(nums,n);\n    return 0;\n}\nvoid print_array(int nums[], int n) {\n    for(int i = 0; i<n; i++){\n        cout<<nums[i]<<\" \";\n    }\n    cout<<endl;\n}\n\n```\n\n最后输出：\n\n<pre><code class=\"markdown\">1 2 3 4 5 6 7 9\n\nProcess returned 0 (0x0)   execution time : 0.097 s\nPress any key to continue.\n</code></pre>\n\n---\n\n","source":"_posts/2014-12-26-MergeSort.md","raw":"---\nlayout: post\ndate: 2014-12-26 12:24\ntitle: \"排序算法-归并排序\"\ncategories: 算法与数据结构\ntag: \n\t- 归并\n\t- 数据结构\n\t- 排序\n\t- C++\ncomment: true\n---\n\n**注：代码均使用C++编写.**\n\n## 介绍\n\n对于数据较大的输入，归并排序是比较快的一个算法。该算法采用的是分治法的思想。\n\n原理：将数据分开排序，然后进行合并，最后形成一个排好的序列。\n\n<!--more-->\n\n![](/assets/articleImg/2014-12-21-mergeSort-1.png)\n\n\n将其合并输出，如下图所示：\n\n![](/assets/articleImg/2014-12-21-mergeSort-2.png)\n\n\n归并排序有一个关键步骤：合并两个排序好的序列。方法是：两个序列中的数相互比较，将较小的数先插入新的序列中。\n\n\n归并过程：比较a[i]和a[j]的大小，若a[i]≤a[j]，则将第一个有序表中的元素a[i]复制到r[k]中，并令i和k分别加上1；否则将第二个有序表中的元素a[j]复制到r[k]中，并令j和k分别加上1，如此循环下去，直到其中一个有序表取完，然后再将另一个有序表中剩余的元素复制到r中从下标k到下标t的单元。归并排序的算法我们通常用递归实现，先把待排序区间[s,t]以中点二分，接着把左边子区间排序，再把右边子区间排序，最后把左区间和右区间用一次归并操作合并成有序的区间[s,t]。\n\n- 发明者：约翰·冯·诺伊曼\n- 时间复杂度：O(nlogn)\n- 空间复杂度 O（n)\n- 稳定的算法\n\n\n## 一次合并\n\n在代码实现部分，需要进行递归进行合并，因此，先编写一个合并的方法。\n\n归并操作的工作原理如下：\n\n一次归并函数传递的参数有：一个数组名、数组的起始位置、数组的末尾位置以及数组的中点位置。\n\n- 第一步：申请空间，初始化起点中点和中点到末尾位置两个变量(nl,nr)，同时设定两个指针p和q，空间大小分别为nl和nr;\n- 第二步：将数组分别输入到两个空间中;\n- 第三步：合并两个数组。操作：比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置;\n- 重复步骤3直到某一指针超出序列尾;\n- 将另一序列剩下的所有元素直接复制到合并序列尾.\n\n在第三步的时候，需要注意的是，不额外的开辟辅助数组，直接通过两个指针的值将原数组的数值进行修改。此处需要设置一个变量`k`，起始位置为数组的起始位置,方便在合并时同时增加指针的下标和数组下标值.\n\n注：使用`malloc`时，需要引入`#include <stdlib.h>`头文件。\n\n代码如下:\n\n```\nvoid mergeOne(int nums[], int l, int m, int r){\n    int nl = m - l + 1;\n    int nr = r - m;\n    int *p = NULL, *q = NULL;\n    p = (int *) malloc (nl * sizeof(int));\n    q = (int *) malloc (nr * sizeof(int));\n\n    //将数组输入到两个空间中\n    for(int i = 0; i < nl; i++) {\n        p[i] = nums[l + i];\n    }\n    for(int j = 0; j < nr; j++) {\n        q[j] = nums[m + 1 + j];\n    }\n\n    //合并两个数组\n    int i = 0;\n    int j = 0;\n    int k = l;\n    while(i < nl && j < nr) {\n        if(p[i] < q[j]) {\n            nums[k++] = p[i++];\n        }else{\n            nums[k++] = q[j++];\n        }\n    }\n\n    //将剩余的元素合并\n    while(i < nl) {\n        nums[k++]  = p[i++];\n    }\n    while(j <nr) {\n        nums[k++] = q[j++];\n    }\n}\n```\n\n\n## 归并排序\n\n通过合并函数来实现归并排序的算法\n\n```\n//注意：此处的left和right必须是数组下标能取到的有效值\nvoid mergeSort(int nums[], int left, int right) {\n    int mid = (left + right) >> 1;\n    if(left < right) {\n        mergeSort(nums, left, mid);\n        mergeSort(nums, mid+1, right);\n        mergeOne(nums, left, mid, right);\n    }\n}\n```\n\n## 测试\n\n```\n#include <iostream>\n#include <stdlib.h>\nvoid print_array(int nums[], int n);\nusing namespace std;\nint main()\n{\n    int nums[]={9, 3, 5, 2, 7, 6, 4, 1};\n    int n = sizeof(nums)/sizeof(nums[0]);\n    mergeSort(nums, 0, n - 1);\n    print_array(nums,n);\n    return 0;\n}\nvoid print_array(int nums[], int n) {\n    for(int i = 0; i<n; i++){\n        cout<<nums[i]<<\" \";\n    }\n    cout<<endl;\n}\n\n```\n\n最后输出：\n\n<pre><code class=\"markdown\">1 2 3 4 5 6 7 9\n\nProcess returned 0 (0x0)   execution time : 0.097 s\nPress any key to continue.\n</code></pre>\n\n---\n\n","slug":"2014-12-26-MergeSort","published":1,"updated":"2016-03-26T03:09:46.295Z","comments":1,"photos":[],"link":"","_id":"cimigpz2k00an6cujn58oehkv"},{"layout":"post","date":"2014-12-25T02:24:00.000Z","title":"排序算法-交换排序","comment":true,"_content":"\n**注：代码均使用C++编写.**\n\n再次回顾下各个排序算法的时间复杂度和空间复杂度的表格：\n\n![](http://www.csuldw.com/assets/articleImg/2014-12-21-performances-of-sort-algs.png)\n\n<!-- more-->\n\n## 冒泡排序\n\n冒泡排序---从前往后冒泡，临近的数字两两进行比较,按照从小到大或者从大到小的顺序进行交换，每轮得到一个最大值\n\n```\n//传入的n是数组长度\nvoid bubbleSort(int nums[], int n){\n    for(int i=n-1; i>=0; --i){\n        for(int j=0; j<i; j++){\n            if(nums[j]>nums[j+1]){\n                swap(nums[j],nums[j+1]);   //交换两个元素\n            }\n        }\n    }\n}\n```\n\n\n## 快速排序\n\n思想：首先任意选取一个数据（一般情况下都是选用数组的第一个数）作为关键数据，然后将所有比它小的数都放到它的前面，所有比它大的数都放到它的后面，此过程叫做一趟快速排序。快速排序不是一种稳定的排序算法，多个相同的值的相对位置也许会在算法结束时产生变动。\n\n一趟快速排序算法如下：\n\n- 首先，设置两个变量i、j，排序开始的时候：i=0，j=N-1；\n- 以第一个数组元素作为关键数据，赋值给pirot，即pirot=nums[0]；\n- 从j开始向前搜索，即由后开始向前搜索(j--)，找到第一个小于pirot的值nums[j]，将nums[j]和nums[i]互换；\n- 从i开始向后搜索，即由前开始向后搜索(i++)，找到第一个大于pirot的nums[i]，将nums[i]和nums[j]互换；\n- 重复第3、4步，直到i=j； (3,4步中，没找到符合条件的值，即3中nums[j]不小于pirot,4中nums[i]不大于pirot的时候改变j、i的值，使得j=j-1，i=i+1，直至找到为止。如果找到符合条件的值，进行交换时i， j指针位置不变。另外，i==j这一过程一定正好是i+或j-完成的时候，此时令循环结束即可）。\n\n快速排序---注意：传入的left为数组起点下标，right为数组末点下标。\n\n```\nvoid quikSort(int nums[], int left, int right){\n    int first = left;\n    int last = right;\n    int pirot = nums[first]; \n    if(first < last){\n        while(first < last){\n            while(first < last && nums[last] >= pirot) last--;\n            nums[first] = nums[last];\n            while(first < last && nums[first] <= pirot) first++;\n            nums[last] = nums[first];\n        }\n        nums[first] = pirot;\n        quikSort(nums, left, first-1);    //对左侧快排\n        quikSort(nums, first+1, right);   //对右侧快排\n    }\n}\n```\n\n\n## 测试\n\n下面简单的测试下快速排序：\n\n```\n#include<iostream>\nusing namespace std;\nvoid bubbleSort(int nums[], int n);\nvoid quikSort(int nums[], int left, int right);\nvoid print_array(int nums[], int n);\nint main()\n{\n    int nums[]={2, 5, 4, 3, 7, 6, 9, 21, 22, 121, 10, 8, 1};    //quikSort(nums,0,sizeof(nums)/sizeof(nums[0])-1);\n    int n = sizeof(nums)/sizeof(nums[0]);\n    //bubbleSort(nums, n);\n    quikSort(nums, 0, n-1);\n    print_array(nums, n);\n    return 0;\n}\n\n//将遍历数组写在了一个函数里，方便调用\nvoid print_array(int nums[], int n) {\n    for(int i = 0; i<n; i++){\n        cout<<nums[i]<<\" \";\n    }\n    cout<<endl;\n}\n```\n\n输出结果：\n<pre><code class=\"markdown\">1 2 3 4 5 6 7 8 9 10 21 22 121  \nProcess returned 0 (0x0)   execution time : 0.132 s\nPress any key to continue.\n</code></pre>\n\n\n---\n\n","source":"_posts/2014-12-25-exchangeSort.md","raw":"---\nlayout: post\ndate: 2014-12-25 10:24\ntitle: \"排序算法-交换排序\"\ncategories: 算法与数据结构\ntag: \n\t- 数据结构\n\t- 排序\n\t- C++\n\t- 冒泡排序\n\t- 快速排序\ncomment: true\n---\n\n**注：代码均使用C++编写.**\n\n再次回顾下各个排序算法的时间复杂度和空间复杂度的表格：\n\n![](http://www.csuldw.com/assets/articleImg/2014-12-21-performances-of-sort-algs.png)\n\n<!-- more-->\n\n## 冒泡排序\n\n冒泡排序---从前往后冒泡，临近的数字两两进行比较,按照从小到大或者从大到小的顺序进行交换，每轮得到一个最大值\n\n```\n//传入的n是数组长度\nvoid bubbleSort(int nums[], int n){\n    for(int i=n-1; i>=0; --i){\n        for(int j=0; j<i; j++){\n            if(nums[j]>nums[j+1]){\n                swap(nums[j],nums[j+1]);   //交换两个元素\n            }\n        }\n    }\n}\n```\n\n\n## 快速排序\n\n思想：首先任意选取一个数据（一般情况下都是选用数组的第一个数）作为关键数据，然后将所有比它小的数都放到它的前面，所有比它大的数都放到它的后面，此过程叫做一趟快速排序。快速排序不是一种稳定的排序算法，多个相同的值的相对位置也许会在算法结束时产生变动。\n\n一趟快速排序算法如下：\n\n- 首先，设置两个变量i、j，排序开始的时候：i=0，j=N-1；\n- 以第一个数组元素作为关键数据，赋值给pirot，即pirot=nums[0]；\n- 从j开始向前搜索，即由后开始向前搜索(j--)，找到第一个小于pirot的值nums[j]，将nums[j]和nums[i]互换；\n- 从i开始向后搜索，即由前开始向后搜索(i++)，找到第一个大于pirot的nums[i]，将nums[i]和nums[j]互换；\n- 重复第3、4步，直到i=j； (3,4步中，没找到符合条件的值，即3中nums[j]不小于pirot,4中nums[i]不大于pirot的时候改变j、i的值，使得j=j-1，i=i+1，直至找到为止。如果找到符合条件的值，进行交换时i， j指针位置不变。另外，i==j这一过程一定正好是i+或j-完成的时候，此时令循环结束即可）。\n\n快速排序---注意：传入的left为数组起点下标，right为数组末点下标。\n\n```\nvoid quikSort(int nums[], int left, int right){\n    int first = left;\n    int last = right;\n    int pirot = nums[first]; \n    if(first < last){\n        while(first < last){\n            while(first < last && nums[last] >= pirot) last--;\n            nums[first] = nums[last];\n            while(first < last && nums[first] <= pirot) first++;\n            nums[last] = nums[first];\n        }\n        nums[first] = pirot;\n        quikSort(nums, left, first-1);    //对左侧快排\n        quikSort(nums, first+1, right);   //对右侧快排\n    }\n}\n```\n\n\n## 测试\n\n下面简单的测试下快速排序：\n\n```\n#include<iostream>\nusing namespace std;\nvoid bubbleSort(int nums[], int n);\nvoid quikSort(int nums[], int left, int right);\nvoid print_array(int nums[], int n);\nint main()\n{\n    int nums[]={2, 5, 4, 3, 7, 6, 9, 21, 22, 121, 10, 8, 1};    //quikSort(nums,0,sizeof(nums)/sizeof(nums[0])-1);\n    int n = sizeof(nums)/sizeof(nums[0]);\n    //bubbleSort(nums, n);\n    quikSort(nums, 0, n-1);\n    print_array(nums, n);\n    return 0;\n}\n\n//将遍历数组写在了一个函数里，方便调用\nvoid print_array(int nums[], int n) {\n    for(int i = 0; i<n; i++){\n        cout<<nums[i]<<\" \";\n    }\n    cout<<endl;\n}\n```\n\n输出结果：\n<pre><code class=\"markdown\">1 2 3 4 5 6 7 8 9 10 21 22 121  \nProcess returned 0 (0x0)   execution time : 0.132 s\nPress any key to continue.\n</code></pre>\n\n\n---\n\n","slug":"2014-12-25-exchangeSort","published":1,"updated":"2016-03-26T03:10:06.016Z","comments":1,"photos":[],"link":"","_id":"cimigpz2t00aw6cujj5y41v9s"},{"layout":"post","date":"2014-12-22T10:24:00.000Z","title":"排序算法-选择排序","comment":true,"_content":"\n**注：代码均使用C++编写.**\n\n继续回顾下各个排序算法的时间复杂度和空间复杂度的表格：\n\n![](http://www.csuldw.com/assets/articleImg/2014-12-21-performances-of-sort-algs.png)\n\n<!-- more-->\n\n## 直接选择排序\n\n原理：每轮比较之后都会记录最大值的下标，最后将该位置的元素与当前最后一个元素交换。\n\n```\n//传入的n是数组长度\nvoid choiceSort(int nums[], int n){\n    for(int i = n-1; i >= 0; --i){\n        int t = i;\n        for(int j = 0; j < i; j++){\n            if(nums[j] > nums[t]){\n                t = j;\n            }\n        }\n        swap(nums[i], nums[t]);\n    }\n}\n```\n\n\n## 堆排序（大根堆）\n\n思想：需要建立大根堆。首先初始化大根堆，然后将堆顶元素和最后一个元素交换；接着使用剩下的n-1个元素重新建立大根堆，然后又将堆顶元素与第n-1个元素交换，依次循环，直到剩下最后一个元素为止。\n\n对的存储，使用数组，需要注意：\n\n- 如果数组下标从0开始，则第i个节点的左孩子是`2 * i +1`，右孩子是`2* i + 2`;\n- 如果数组下标从1开始，则第i个节点的左孩子是`2 * i `，右孩子是`2* i +１`.\n\n\n首先需要建立一个堆调整函数。\n\n```\n//7.堆排序（大根堆）[数组下标从0开始],m表示起始下标，n表示终止数字的下标\nvoid HeapAdjust(int nums[], int j, int n){\n    int value = nums[j];\n    int i = 2 * j + 1;\n    while(i <= n){\n        //left孩子为2i+1,right孩子为2i+2\n        if(i < n && nums[i] < nums[i+1]){//找到孩子中较大的那个下标\n            ++i;\n        }\n        if(value > nums[i]){             //左右孩子中获胜者与父亲的比较\n            break;\n        }\n        //将孩子结点上位，则以孩子结点的位置进行下一轮的筛选\n        nums[j]= nums[i];\n        j = i;\n        i = 2 * i + 1;  //因为下标是零开始，所以左孩子这里是2*i+1\n    }\n    nums[j]= value; //插入最开始不和谐的元素\n}\n```\n\n```\n//堆排序\nvoid HeapSort(int *nums, int n){\n    int i;\n    //初始化大根堆\n    for(int i = n/2; i >= 0; i--){\n        HeapAdjust(nums, i, n-1); //注意，下标从0开始，所以是n-1\n    }\n    for(i = n-1; i >= 0; i--){\n        //cout<<nums[0]<<\" \"<<endl;\n        swap(nums[0], nums[i]);      //交换堆顶和最后一个元素，即每次将剩余元素中的最大者放到最后面\n        HeapAdjust(nums, 0, i-1);    //重新调整堆顶节点成为大顶堆\n    }\n}\n```\n\n## 测试\n\n下面简单的测试下快速排序：\n\n```\n#include<iostream>\nusing namespace std;\nvoid choiceSort(int nums[], int n);\nvoid HeapSort(int *a,int len);\nvoid print_array(int nums[], int n);\nint main()\n{\n    int nums[]={2, 5, 4, 3, 7, 6, 9, 21, 22, 121, 10, 8, 1};    //quikSort(nums,0,sizeof(nums)/sizeof(nums[0])-1);\n    int n = sizeof(nums)/sizeof(nums[0]);\n    //choiceSort(nums, n);\n    HeapSort(nums, 0, n-1);\n    print_array(nums, n);\n    return 0;\n}\n\n//将遍历数组写在了一个函数里，方便调用\nvoid print_array(int nums[], int n) {\n    for(int i = 0; i<n; i++){\n        cout<<nums[i]<<\" \";\n    }\n    cout<<endl;\n}\n```\n\n输出结果：\n<pre><code class=\"markdown\">1 2 3 4 5 6 7 8 9 10 21 22 121  \nProcess returned 0 (0x0)   execution time : 0.083 s\nPress any key to continue.\n</code></pre>\n\n\n---\n\n","source":"_posts/2014-12-22-choiceSort.md","raw":"---\nlayout: post\ndate: 2014-12-22 18:24\ntitle: \"排序算法-选择排序\"\ncategories: 算法与数据结构\ntag: \n\t- 数据结构\n\t- 排序\n\t- C++\n\t- 直接选择排序\n\t- 堆排序\ncomment: true\n---\n\n**注：代码均使用C++编写.**\n\n继续回顾下各个排序算法的时间复杂度和空间复杂度的表格：\n\n![](http://www.csuldw.com/assets/articleImg/2014-12-21-performances-of-sort-algs.png)\n\n<!-- more-->\n\n## 直接选择排序\n\n原理：每轮比较之后都会记录最大值的下标，最后将该位置的元素与当前最后一个元素交换。\n\n```\n//传入的n是数组长度\nvoid choiceSort(int nums[], int n){\n    for(int i = n-1; i >= 0; --i){\n        int t = i;\n        for(int j = 0; j < i; j++){\n            if(nums[j] > nums[t]){\n                t = j;\n            }\n        }\n        swap(nums[i], nums[t]);\n    }\n}\n```\n\n\n## 堆排序（大根堆）\n\n思想：需要建立大根堆。首先初始化大根堆，然后将堆顶元素和最后一个元素交换；接着使用剩下的n-1个元素重新建立大根堆，然后又将堆顶元素与第n-1个元素交换，依次循环，直到剩下最后一个元素为止。\n\n对的存储，使用数组，需要注意：\n\n- 如果数组下标从0开始，则第i个节点的左孩子是`2 * i +1`，右孩子是`2* i + 2`;\n- 如果数组下标从1开始，则第i个节点的左孩子是`2 * i `，右孩子是`2* i +１`.\n\n\n首先需要建立一个堆调整函数。\n\n```\n//7.堆排序（大根堆）[数组下标从0开始],m表示起始下标，n表示终止数字的下标\nvoid HeapAdjust(int nums[], int j, int n){\n    int value = nums[j];\n    int i = 2 * j + 1;\n    while(i <= n){\n        //left孩子为2i+1,right孩子为2i+2\n        if(i < n && nums[i] < nums[i+1]){//找到孩子中较大的那个下标\n            ++i;\n        }\n        if(value > nums[i]){             //左右孩子中获胜者与父亲的比较\n            break;\n        }\n        //将孩子结点上位，则以孩子结点的位置进行下一轮的筛选\n        nums[j]= nums[i];\n        j = i;\n        i = 2 * i + 1;  //因为下标是零开始，所以左孩子这里是2*i+1\n    }\n    nums[j]= value; //插入最开始不和谐的元素\n}\n```\n\n```\n//堆排序\nvoid HeapSort(int *nums, int n){\n    int i;\n    //初始化大根堆\n    for(int i = n/2; i >= 0; i--){\n        HeapAdjust(nums, i, n-1); //注意，下标从0开始，所以是n-1\n    }\n    for(i = n-1; i >= 0; i--){\n        //cout<<nums[0]<<\" \"<<endl;\n        swap(nums[0], nums[i]);      //交换堆顶和最后一个元素，即每次将剩余元素中的最大者放到最后面\n        HeapAdjust(nums, 0, i-1);    //重新调整堆顶节点成为大顶堆\n    }\n}\n```\n\n## 测试\n\n下面简单的测试下快速排序：\n\n```\n#include<iostream>\nusing namespace std;\nvoid choiceSort(int nums[], int n);\nvoid HeapSort(int *a,int len);\nvoid print_array(int nums[], int n);\nint main()\n{\n    int nums[]={2, 5, 4, 3, 7, 6, 9, 21, 22, 121, 10, 8, 1};    //quikSort(nums,0,sizeof(nums)/sizeof(nums[0])-1);\n    int n = sizeof(nums)/sizeof(nums[0]);\n    //choiceSort(nums, n);\n    HeapSort(nums, 0, n-1);\n    print_array(nums, n);\n    return 0;\n}\n\n//将遍历数组写在了一个函数里，方便调用\nvoid print_array(int nums[], int n) {\n    for(int i = 0; i<n; i++){\n        cout<<nums[i]<<\" \";\n    }\n    cout<<endl;\n}\n```\n\n输出结果：\n<pre><code class=\"markdown\">1 2 3 4 5 6 7 8 9 10 21 22 121  \nProcess returned 0 (0x0)   execution time : 0.083 s\nPress any key to continue.\n</code></pre>\n\n\n---\n\n","slug":"2014-12-22-choiceSort","published":1,"updated":"2016-03-26T03:10:10.671Z","comments":1,"photos":[],"link":"","_id":"cimigpz3100b56cujrk86uria"},{"layout":"post","date":"2014-12-21T03:24:00.000Z","title":"排序算法-插入排序","comment":true,"_content":"\n**注：代码均使用C++编写.**\n\n首先介绍一个常用排序算法的时间复杂度和空间复杂度的表格：\n\n![](/assets/articleImg/2014-12-21-performances-of-sort-algs.png)\n\n<!--more-->\n\n对于插入排序，本文简单介绍两种：简单插入排序和希尔排序。同时，会附上实现源码。\n\n## 1.知识点小记\n\n- 使用`sizeof(nums)/sizeof(nums[0])`获得数组的长度；\n\n- 数组作为参数有两种方法，一种是以数组名本身，一种是以指针；\n\n- 如果要给一个函数传入一个数组，一般都是传入两个参数，一个数组指针或数组名，另一个是数组大小；\n\n\n## 2.简单插入排序\n\n\n直接插入排序(Insertion Sort)的基本思想是：每次将一个待排序的记录，按其关键字大小插入到前面已经排好序的子序列中的适当位置，直到全部记录插入完成为止。\n\n实现：从头到尾遍历数组，设置一个变量作为哨兵，记录当前元素；然后从当前位置依次往前寻找插入点，如果哨兵元素值要小，就将前面的元素往后移动一位，直到哨兵元素大于前面的元素为止。\n\n设数组为a[0…n-1]。\n\n- 初始时，a[0]自成1个有序区，无序区为a[1..n-1]。令i=1\n- 将a[i]并入当前的有序区a[0…i-1]中形成a[0…i]的有序区间。\n- i++，并重复第二步直到i==n-1。\n\n简单插入排序方法实现：\n\n```\n//insert sort\nvoid insertSort(int nums[], int n){\n    for(int i=1;i<n;i++){\n        int temp = nums[i];\n        int j=i-1;\n        while(nums[j]>temp && j>=0){\n            nums[j+1] = nums[j];\n            j--;\n        }\n        nums[j+1] = temp;\n    }\n}\n```\n\n\n下面是一个完整的例子：\n\n```\n#include <iostream>\nusing namespace std;\nvoid insertSort(int nums[], int n)；\nint main()\n{\n    int nums[] = {9,2,7,4,5};\n    int n = sizeof(nums)/sizeof(nums[0]);\n    insertSort(nums, n);\n    for(int i =0; i< (sizeof(nums)/sizeof(nums[0])); i++){\n        cout<<nums[i]<<\" \";\n    }\n    return 0;\n}\n\n//insert sort\nvoid insertSort(int nums[], int n){\n    for(int i=1;i<n;i++){\n        int temp = nums[i];\n        int j=i-1;\n        while(nums[j]>temp && j>=0){\n            nums[j+1] = nums[j];\n            j--;\n        }\n        nums[j+1] = temp;\n    }\n}\n```\n\n简单插入排序最坏和平均时间复杂度都为O($n^2$),空间复杂度为O(1)，最好的时间复杂度为O(n).属于稳定的排序算法。\n\n---\n\n## 3.希尔排序\n\n\n希尔排序思路：先将整个待排元素序列分割成若干个子序列（由相隔某个“增量”的元素组成的）分别进行直接插入排序，然后依次缩减增量再进行排序，待整个序列中的元素基本有序（增量足够小）时，再对全体元素进行一次直接插入排序。因为直接插入排序在元素基本有序的情况下（接近最好情况），效率是很高的，因此希尔排序在时间效率上比前两种方法有较大提高。\n\n希尔排序方法：\n\n```\n//希尔排序\nvoid shellSort(int nums[], int n){\n    int d = n>>1;\n    while(d>=1){\n        for(int i=0; i<n-d; i++){\n            for(int j=i+d; j<n; j+=d){\n                if(nums[j-d]>nums[j]){\n                    int temp = nums[j-d];\n                    nums[j-d] = nums[j];\n                    nums[j] = temp;\n                }\n            }\n        }\n        d = d>>1;\n        print_array(nums,n);\n    }\n}\n```\n\n下面是一个完整的例子：\n\n```\n#include <iostream>\nusing namespace std;\nvoid shellSort(int nums[], int n);\nvoid print_array(int nums[], int n);\nint main()\n{\n    int nums[] = {9,2,7,4,5};\n    int n = sizeof(nums)/sizeof(nums[0]);\n    shellSort(nums, n);\n    for(int i =0; i< (sizeof(nums)/sizeof(nums[0])); i++){\n        cout<<nums[i]<<\" \";\n    }\n    return 0;\n}\n\n//希尔排序\nvoid shellSort(int nums[], int n){\n    int d = n>>1;\n    while(d>=1){\n        for(int i=0; i<n-d; i++){\n            for(int j=i+d; j<n; j+=d){\n                if(nums[j-d]>nums[j]){\n                    int temp = nums[j-d];\n                    nums[j-d] = nums[j];\n                    nums[j] = temp;\n                }\n            }\n        }\n        d = d>>1;\n        print_array(nums,n);\n    }\n}\n\nvoid print_array(int nums[], int n){\n    for(int i = 0; i<n; i++){\n        cout<<nums[i]<<\" \";\n    }\n    cout<<endl;\n}\n```\n\n输出结果：\n\n![](/assets/articleImg/2014-12-21-insert-sort.png)\n\n简单插入排序平均时间复杂度为O($n^{1.3}$),空间复杂度为O(1)。最坏情况下的时间复杂度为O($n^2$),最好的时间复杂度为O(n).\n\n---\n\n## 4.补充知识点\n\n\n**将数组作为参数传递**\n\n两种形式：\n\n- 使用数组名本身,如上方的函数形式：\n\n```\nvoid insertSort(int nums[], int n)\n```\n\n- 用指针作为参数,这就简单了,只需将上面方法中的数组修改成指针形式:\n\n\n```\nvoid insertSort(int *nums, int n)\n```\n\n---\n\n","source":"_posts/2014-12-21-InsertSort.md","raw":"---\nlayout: post\ndate: 2014-12-21 11:24\ntitle: \"排序算法-插入排序\"\ncategories: 算法与数据结构\ntag: \n\t- C++\n\t- 数据结构\n\t- 排序\n\t- 希尔排序\n\t- 插入排序\ncomment: true\n---\n\n**注：代码均使用C++编写.**\n\n首先介绍一个常用排序算法的时间复杂度和空间复杂度的表格：\n\n![](/assets/articleImg/2014-12-21-performances-of-sort-algs.png)\n\n<!--more-->\n\n对于插入排序，本文简单介绍两种：简单插入排序和希尔排序。同时，会附上实现源码。\n\n## 1.知识点小记\n\n- 使用`sizeof(nums)/sizeof(nums[0])`获得数组的长度；\n\n- 数组作为参数有两种方法，一种是以数组名本身，一种是以指针；\n\n- 如果要给一个函数传入一个数组，一般都是传入两个参数，一个数组指针或数组名，另一个是数组大小；\n\n\n## 2.简单插入排序\n\n\n直接插入排序(Insertion Sort)的基本思想是：每次将一个待排序的记录，按其关键字大小插入到前面已经排好序的子序列中的适当位置，直到全部记录插入完成为止。\n\n实现：从头到尾遍历数组，设置一个变量作为哨兵，记录当前元素；然后从当前位置依次往前寻找插入点，如果哨兵元素值要小，就将前面的元素往后移动一位，直到哨兵元素大于前面的元素为止。\n\n设数组为a[0…n-1]。\n\n- 初始时，a[0]自成1个有序区，无序区为a[1..n-1]。令i=1\n- 将a[i]并入当前的有序区a[0…i-1]中形成a[0…i]的有序区间。\n- i++，并重复第二步直到i==n-1。\n\n简单插入排序方法实现：\n\n```\n//insert sort\nvoid insertSort(int nums[], int n){\n    for(int i=1;i<n;i++){\n        int temp = nums[i];\n        int j=i-1;\n        while(nums[j]>temp && j>=0){\n            nums[j+1] = nums[j];\n            j--;\n        }\n        nums[j+1] = temp;\n    }\n}\n```\n\n\n下面是一个完整的例子：\n\n```\n#include <iostream>\nusing namespace std;\nvoid insertSort(int nums[], int n)；\nint main()\n{\n    int nums[] = {9,2,7,4,5};\n    int n = sizeof(nums)/sizeof(nums[0]);\n    insertSort(nums, n);\n    for(int i =0; i< (sizeof(nums)/sizeof(nums[0])); i++){\n        cout<<nums[i]<<\" \";\n    }\n    return 0;\n}\n\n//insert sort\nvoid insertSort(int nums[], int n){\n    for(int i=1;i<n;i++){\n        int temp = nums[i];\n        int j=i-1;\n        while(nums[j]>temp && j>=0){\n            nums[j+1] = nums[j];\n            j--;\n        }\n        nums[j+1] = temp;\n    }\n}\n```\n\n简单插入排序最坏和平均时间复杂度都为O($n^2$),空间复杂度为O(1)，最好的时间复杂度为O(n).属于稳定的排序算法。\n\n---\n\n## 3.希尔排序\n\n\n希尔排序思路：先将整个待排元素序列分割成若干个子序列（由相隔某个“增量”的元素组成的）分别进行直接插入排序，然后依次缩减增量再进行排序，待整个序列中的元素基本有序（增量足够小）时，再对全体元素进行一次直接插入排序。因为直接插入排序在元素基本有序的情况下（接近最好情况），效率是很高的，因此希尔排序在时间效率上比前两种方法有较大提高。\n\n希尔排序方法：\n\n```\n//希尔排序\nvoid shellSort(int nums[], int n){\n    int d = n>>1;\n    while(d>=1){\n        for(int i=0; i<n-d; i++){\n            for(int j=i+d; j<n; j+=d){\n                if(nums[j-d]>nums[j]){\n                    int temp = nums[j-d];\n                    nums[j-d] = nums[j];\n                    nums[j] = temp;\n                }\n            }\n        }\n        d = d>>1;\n        print_array(nums,n);\n    }\n}\n```\n\n下面是一个完整的例子：\n\n```\n#include <iostream>\nusing namespace std;\nvoid shellSort(int nums[], int n);\nvoid print_array(int nums[], int n);\nint main()\n{\n    int nums[] = {9,2,7,4,5};\n    int n = sizeof(nums)/sizeof(nums[0]);\n    shellSort(nums, n);\n    for(int i =0; i< (sizeof(nums)/sizeof(nums[0])); i++){\n        cout<<nums[i]<<\" \";\n    }\n    return 0;\n}\n\n//希尔排序\nvoid shellSort(int nums[], int n){\n    int d = n>>1;\n    while(d>=1){\n        for(int i=0; i<n-d; i++){\n            for(int j=i+d; j<n; j+=d){\n                if(nums[j-d]>nums[j]){\n                    int temp = nums[j-d];\n                    nums[j-d] = nums[j];\n                    nums[j] = temp;\n                }\n            }\n        }\n        d = d>>1;\n        print_array(nums,n);\n    }\n}\n\nvoid print_array(int nums[], int n){\n    for(int i = 0; i<n; i++){\n        cout<<nums[i]<<\" \";\n    }\n    cout<<endl;\n}\n```\n\n输出结果：\n\n![](/assets/articleImg/2014-12-21-insert-sort.png)\n\n简单插入排序平均时间复杂度为O($n^{1.3}$),空间复杂度为O(1)。最坏情况下的时间复杂度为O($n^2$),最好的时间复杂度为O(n).\n\n---\n\n## 4.补充知识点\n\n\n**将数组作为参数传递**\n\n两种形式：\n\n- 使用数组名本身,如上方的函数形式：\n\n```\nvoid insertSort(int nums[], int n)\n```\n\n- 用指针作为参数,这就简单了,只需将上面方法中的数组修改成指针形式:\n\n\n```\nvoid insertSort(int *nums, int n)\n```\n\n---\n\n","slug":"2014-12-21-InsertSort","published":1,"updated":"2016-03-26T02:52:59.019Z","comments":1,"photos":[],"link":"","_id":"cimigpz3b00be6cuj53aaa1qt"},{"layout":"post","date":"2014-12-19T06:24:00.000Z","title":"Python元组与列表的区别","comment":true,"_content":"\n\n## list和tuple区别\n\n列表和元组非常类似，有时候他们都干一样的事情。他们最大的区别是:\n\n* **元组一旦被赋值，值不可以被改变，一旦改变就会出错；列表可以任意的更改**。\n\n* **他们用不同的符号表示，赋值的时候，列表用方括号\"[]\"，而元组用小括号\"（）\"**。\n\n<!--more-->\n\n列表：列表中的元素应该包括在方括号中，你可以添加、删除或是搜索列表中的元素。由于你可以增加或删除项目，所以列表是可变的数据类型，即这种类型是可以被改变的。\n\n元组：元组和列表十分类似，但是元组是不可变的.也就是说你不能修改元组。元组通过圆括号中用逗号分割的项目定义。元组通常用在使语句或用户定义的函数能够安全地采用一组值的时候，即被使用的元组的值不会改变。\n\n\n## 用法\n\n### 1.list\n\n\n```\nli = [1,2,3,4,5] #赋值，使用中括号\nli[1] = 11 #修改li[1]的值,此时li变成[1, 11, 3, 4, 5]\nli[0] = \"LOVE\" #此时li变成['LOVE', 11, 3, 4, 5]\n```\n\n\n- List（列表） 是 Python 中使用最频繁的数据类型。\n\n- 列表可以完成大多数集合类的数据结构实现。它支持字符，数字，字符串甚至可以包含列表（所谓嵌套）。\n\n- 列表用[ ]标识。是python最通用的复合数据类型。看这段代码就明白。\n\n- 列表中的值得分割也可以用到变量[头下标:尾下标]，就可以截取相应的列表，从左到右索引默认0开始的，从右到左索引默认-1开始，下标可以为空表示取到头或尾。\n\n加号（+）是列表连接运算符，星号（*）是重复操作。如下实例：\n\n```\n#!/usr/bin/python\n# -*- coding: UTF-8 -*-\n\nlist = [ 'abcd', 786 , 2.23, 'john', 70.2 ]\ntinylist = [123, 'john']\n\nprint list # 输出完整列表\nprint list[0] # 输出列表的第一个元素\nprint list[1:3] # 输出第二个至第三个的元素 \nprint list[2:] # 输出从第三个开始至列表末尾的所有元素\nprint tinylist * 2 # 输出列表两次\nprint list + tinylist # 打印组合的列表\n```\n\n以上实例输出结果：\n\n<pre><code class=\"markdown\">['abcd', 786, 2.23, 'john', 70.2]\nabcd\n[786, 2.23]\n[2.23, 'john', 70.2]\n[123, 'john', 123, 'john']\n['abcd', 786, 2.23, 'john', 70.2, 123, 'john']\n</code></pre>\n\n\n### 2.tuple\n\n- 元组是另一个数据类型，类似于List（列表）。\n\n- 元组用\"()\"标识。内部元素用逗号隔开。但是元素不能二次赋值，相当于只读列表。\n\n```\n#!/usr/bin/python\n# -*- coding: UTF-8 -*-\n\ntuple = ( 'abcd', 786 , 2.23, 'john', 70.2 )\ntinytuple = (123, 'john')\n\nprint tuple # 输出完整元组\nprint tuple[0] # 输出元组的第一个元素\nprint tuple[1:3] # 输出第二个至第三个的元素 \nprint tuple[2:] # 输出从第三个开始至列表末尾的所有元素\nprint tinytuple * 2 # 输出元组两次\nprint tuple + tinytuple # 打印组合的元组\n```\n\n以上实例输出结果：\n\n```\n('abcd', 786, 2.23, 'john', 70.2)\nabcd\n(786, 2.23)\n(2.23, 'john', 70.2)\n(123, 'john', 123, 'john')\n('abcd', 786, 2.23, 'john', 70.2, 123, 'john')\n```\n\ntuple不可修改，否则会报错。\n\n---\n\n","source":"_posts/2014-12-19-The-difference-of-list-and-tupple.md","raw":"---\nlayout: post\ndate: 2014-12-19 14:24\ntitle: \"Python元组与列表的区别\"\ncategories: Python \ntag: \n\t- Python\ncomment: true\n---\n\n\n## list和tuple区别\n\n列表和元组非常类似，有时候他们都干一样的事情。他们最大的区别是:\n\n* **元组一旦被赋值，值不可以被改变，一旦改变就会出错；列表可以任意的更改**。\n\n* **他们用不同的符号表示，赋值的时候，列表用方括号\"[]\"，而元组用小括号\"（）\"**。\n\n<!--more-->\n\n列表：列表中的元素应该包括在方括号中，你可以添加、删除或是搜索列表中的元素。由于你可以增加或删除项目，所以列表是可变的数据类型，即这种类型是可以被改变的。\n\n元组：元组和列表十分类似，但是元组是不可变的.也就是说你不能修改元组。元组通过圆括号中用逗号分割的项目定义。元组通常用在使语句或用户定义的函数能够安全地采用一组值的时候，即被使用的元组的值不会改变。\n\n\n## 用法\n\n### 1.list\n\n\n```\nli = [1,2,3,4,5] #赋值，使用中括号\nli[1] = 11 #修改li[1]的值,此时li变成[1, 11, 3, 4, 5]\nli[0] = \"LOVE\" #此时li变成['LOVE', 11, 3, 4, 5]\n```\n\n\n- List（列表） 是 Python 中使用最频繁的数据类型。\n\n- 列表可以完成大多数集合类的数据结构实现。它支持字符，数字，字符串甚至可以包含列表（所谓嵌套）。\n\n- 列表用[ ]标识。是python最通用的复合数据类型。看这段代码就明白。\n\n- 列表中的值得分割也可以用到变量[头下标:尾下标]，就可以截取相应的列表，从左到右索引默认0开始的，从右到左索引默认-1开始，下标可以为空表示取到头或尾。\n\n加号（+）是列表连接运算符，星号（*）是重复操作。如下实例：\n\n```\n#!/usr/bin/python\n# -*- coding: UTF-8 -*-\n\nlist = [ 'abcd', 786 , 2.23, 'john', 70.2 ]\ntinylist = [123, 'john']\n\nprint list # 输出完整列表\nprint list[0] # 输出列表的第一个元素\nprint list[1:3] # 输出第二个至第三个的元素 \nprint list[2:] # 输出从第三个开始至列表末尾的所有元素\nprint tinylist * 2 # 输出列表两次\nprint list + tinylist # 打印组合的列表\n```\n\n以上实例输出结果：\n\n<pre><code class=\"markdown\">['abcd', 786, 2.23, 'john', 70.2]\nabcd\n[786, 2.23]\n[2.23, 'john', 70.2]\n[123, 'john', 123, 'john']\n['abcd', 786, 2.23, 'john', 70.2, 123, 'john']\n</code></pre>\n\n\n### 2.tuple\n\n- 元组是另一个数据类型，类似于List（列表）。\n\n- 元组用\"()\"标识。内部元素用逗号隔开。但是元素不能二次赋值，相当于只读列表。\n\n```\n#!/usr/bin/python\n# -*- coding: UTF-8 -*-\n\ntuple = ( 'abcd', 786 , 2.23, 'john', 70.2 )\ntinytuple = (123, 'john')\n\nprint tuple # 输出完整元组\nprint tuple[0] # 输出元组的第一个元素\nprint tuple[1:3] # 输出第二个至第三个的元素 \nprint tuple[2:] # 输出从第三个开始至列表末尾的所有元素\nprint tinytuple * 2 # 输出元组两次\nprint tuple + tinytuple # 打印组合的元组\n```\n\n以上实例输出结果：\n\n```\n('abcd', 786, 2.23, 'john', 70.2)\nabcd\n(786, 2.23)\n(2.23, 'john', 70.2)\n(123, 'john', 123, 'john')\n('abcd', 786, 2.23, 'john', 70.2, 123, 'john')\n```\n\ntuple不可修改，否则会报错。\n\n---\n\n","slug":"2014-12-19-The-difference-of-list-and-tupple","published":1,"updated":"2016-03-13T06:02:09.663Z","comments":1,"photos":[],"link":"","_id":"cimigpz3i00bn6cuj4bmtkbwr"},{"layout":"post","date":"2014-11-19T02:24:00.000Z","title":"Linx学习笔记-tree命令","comment":true,"_content":"\n\n## 安装\n\n有时候，我们想要知道一个目录下面的详细情况，那么有什么好的方法呢？\n\n很幸运，Linux shell 有一个tree 命令，专门用来打印目录树。\n\n如果你没有安装，可以使用`yum`来安装，命令如下：\n\n```shell\nyum -y install tree\n```\n<!-- more-->\n## 使用\n\n此时如果想打印某个目录下的所有文件，可以使用`tree`命令：\n\n<pre><code class=\"markdown\">[liudiwei@master _code]$ tree\n.\n`-- preprocessing\n    |-- compareTwoFile.py\n    |-- download.py\n    |-- extractChainFromSeq.py\n    |-- extractSeqByChain.py\n    |-- formatChain.py\n    |-- generateSeqFromDSSP.py\n    |-- getProteinFromChain.py\n    |-- getProteinNameFromDir.py\n    |-- pdbToDSSP.py\n    `-- _README.txt\n</code></pre>\n\n\n此外，如果只想要显示目录的话，可以使用添加`-d`参数：\n\n<pre><code class=\"markdown\">[liudiwei@master DNA_BP]$ tree -d\n.\n|-- _code\n|   `-- preprocessing\n|-- _data\n|   `-- Exp_DBPI\n|       |-- DBPI_Datasets\n|       |-- dssp_testset\n|       |   `-- format\n|       |-- dssp_trainset\n|       |   `-- format\n|       |-- pdb_testset\n|       `-- pdb_trainset\n|-- _feature\n|   `-- feature_extraction\n`-- paper_Graham\n\n14 directories\n</code></pre>\n\n如果你不想看到全部的文件？可以加上“-P 通配符”的方法来只列出某种文件：\n\n<pre><code class=\"markdown\">[liudiwei@master DNA_BP]$ tree -P \"*.py\"\n.\n|-- _code\n|   `-- preprocessing\n|       |-- compareTwoFile.py\n|       |-- download.py\n|       |-- extractChainFromSeq.py\n|       |-- extractSeqByChain.py\n|       |-- formatChain.py\n|       |-- generateSeqFromDSSP.py\n|       |-- getProteinFromChain.py\n|       |-- getProteinNameFromDir.py\n|       `-- pdbToDSSP.py\n|-- _data\n|   `-- Exp_DBPI\n|       |-- DBPI_Datasets\n|       |-- dssp_testset\n|       |   `-- format\n|       |-- dssp_trainset\n|       |   `-- format\n|       |-- pdb_testset\n|       `-- pdb_trainset\n|-- _feature\n|   `-- feature_extraction\n`-- paper2015_Graham\n</code></pre>\n\n## 详细参数\n\n`tree`常用参数：\n\n<pre><code class=\"markdown\">\n-a 显示所有文件和目录。\n\n-A 使用ASNI绘图字符显示树状图而非以ASCII字符组合。\n\n-C 在文件和目录清单加上色彩，便于区分各种类型。\n\n-d 显示目录名称而非内容。\n\n-D 列出文件或目录的更改时间。\n\n-f 在每个文件或目录之前，显示完整的相对路径名称。\n\n-F 在执行文件，目录，Socket，符号连接，管道名称名称，各自加上”*“,”/“,”=“,”@“,”|“号。\n\n-g 列出文件或目录的所属群组名称，没有对应的名称时，则显示群组识别码。\n\n-i 不以阶梯状列出文件或目录名称。\n\n-I <范本样式> 不显示符合范本样式的文件或目录名称。\n\n-l 如遇到性质为符号连接的目录，直接列出该连接所指向的原始目录。\n\n-n 不在文件和目录清单加上色彩。\n\n-N 直接列出文件和目录名称，包括控制字符。\n\n-p 列出权限标示。\n\n-P <范本样式> 只显示符合范本样式的文件或目录名称。\n\n-q 用”?“号取代控制字符，列出文件和目录名称。\n\n-s 列出文件或目录大小。\n\n-t 用文件和目录的更改时间排序。\n\n-u 列出文件或目录的拥有者名称，没有对应的名称时，则显示用户识别码。\n\n-x 将范围局限在现行的文件系统中，若指定目录下的某些子目录，其存放于另一个文件系统上，则将该子目录予以排除在寻找范围外。\n</code></pre>\n\n---\n\n","source":"_posts/2014-11-19-linux-tree-command.md","raw":"---\nlayout: post\ndate: 2014-11-19 10:24\ntitle: \"Linx学习笔记-tree命令\"\ncategories: Linux\ntag: \n\t- Linux\n\t- Shell\ncomment: true\n---\n\n\n## 安装\n\n有时候，我们想要知道一个目录下面的详细情况，那么有什么好的方法呢？\n\n很幸运，Linux shell 有一个tree 命令，专门用来打印目录树。\n\n如果你没有安装，可以使用`yum`来安装，命令如下：\n\n```shell\nyum -y install tree\n```\n<!-- more-->\n## 使用\n\n此时如果想打印某个目录下的所有文件，可以使用`tree`命令：\n\n<pre><code class=\"markdown\">[liudiwei@master _code]$ tree\n.\n`-- preprocessing\n    |-- compareTwoFile.py\n    |-- download.py\n    |-- extractChainFromSeq.py\n    |-- extractSeqByChain.py\n    |-- formatChain.py\n    |-- generateSeqFromDSSP.py\n    |-- getProteinFromChain.py\n    |-- getProteinNameFromDir.py\n    |-- pdbToDSSP.py\n    `-- _README.txt\n</code></pre>\n\n\n此外，如果只想要显示目录的话，可以使用添加`-d`参数：\n\n<pre><code class=\"markdown\">[liudiwei@master DNA_BP]$ tree -d\n.\n|-- _code\n|   `-- preprocessing\n|-- _data\n|   `-- Exp_DBPI\n|       |-- DBPI_Datasets\n|       |-- dssp_testset\n|       |   `-- format\n|       |-- dssp_trainset\n|       |   `-- format\n|       |-- pdb_testset\n|       `-- pdb_trainset\n|-- _feature\n|   `-- feature_extraction\n`-- paper_Graham\n\n14 directories\n</code></pre>\n\n如果你不想看到全部的文件？可以加上“-P 通配符”的方法来只列出某种文件：\n\n<pre><code class=\"markdown\">[liudiwei@master DNA_BP]$ tree -P \"*.py\"\n.\n|-- _code\n|   `-- preprocessing\n|       |-- compareTwoFile.py\n|       |-- download.py\n|       |-- extractChainFromSeq.py\n|       |-- extractSeqByChain.py\n|       |-- formatChain.py\n|       |-- generateSeqFromDSSP.py\n|       |-- getProteinFromChain.py\n|       |-- getProteinNameFromDir.py\n|       `-- pdbToDSSP.py\n|-- _data\n|   `-- Exp_DBPI\n|       |-- DBPI_Datasets\n|       |-- dssp_testset\n|       |   `-- format\n|       |-- dssp_trainset\n|       |   `-- format\n|       |-- pdb_testset\n|       `-- pdb_trainset\n|-- _feature\n|   `-- feature_extraction\n`-- paper2015_Graham\n</code></pre>\n\n## 详细参数\n\n`tree`常用参数：\n\n<pre><code class=\"markdown\">\n-a 显示所有文件和目录。\n\n-A 使用ASNI绘图字符显示树状图而非以ASCII字符组合。\n\n-C 在文件和目录清单加上色彩，便于区分各种类型。\n\n-d 显示目录名称而非内容。\n\n-D 列出文件或目录的更改时间。\n\n-f 在每个文件或目录之前，显示完整的相对路径名称。\n\n-F 在执行文件，目录，Socket，符号连接，管道名称名称，各自加上”*“,”/“,”=“,”@“,”|“号。\n\n-g 列出文件或目录的所属群组名称，没有对应的名称时，则显示群组识别码。\n\n-i 不以阶梯状列出文件或目录名称。\n\n-I <范本样式> 不显示符合范本样式的文件或目录名称。\n\n-l 如遇到性质为符号连接的目录，直接列出该连接所指向的原始目录。\n\n-n 不在文件和目录清单加上色彩。\n\n-N 直接列出文件和目录名称，包括控制字符。\n\n-p 列出权限标示。\n\n-P <范本样式> 只显示符合范本样式的文件或目录名称。\n\n-q 用”?“号取代控制字符，列出文件和目录名称。\n\n-s 列出文件或目录大小。\n\n-t 用文件和目录的更改时间排序。\n\n-u 列出文件或目录的拥有者名称，没有对应的名称时，则显示用户识别码。\n\n-x 将范围局限在现行的文件系统中，若指定目录下的某些子目录，其存放于另一个文件系统上，则将该子目录予以排除在寻找范围外。\n</code></pre>\n\n---\n\n","slug":"2014-11-19-linux-tree-command","published":1,"updated":"2016-03-08T08:44:39.758Z","comments":1,"photos":[],"link":"","_id":"cimigpz3p00bq6cujj4qcnb9m"},{"date":"2016-04-02T03:04:00.000Z","type":"picture","_content":"\n{% gp 4-2 %}\n\n![](/assets/articleImg/2016-04-02-0.jpg)\n\n![](/assets/articleImg/2016-04-02-3.jpg)\n\n![](/assets/articleImg/2016-04-02-1.jpg)\n\n![](/assets/articleImg/2016-04-02-2.jpg)\n\n{% endgp %}\n\n","source":"_posts/2016-04-02-some-day.md","raw":"---\ndate: 2016-04-02 11:04\ntype: \"picture\"    \n---\n\n{% gp 4-2 %}\n\n![](/assets/articleImg/2016-04-02-0.jpg)\n\n![](/assets/articleImg/2016-04-02-3.jpg)\n\n![](/assets/articleImg/2016-04-02-1.jpg)\n\n![](/assets/articleImg/2016-04-02-2.jpg)\n\n{% endgp %}\n\n","slug":"2016-04-02-some-day","published":1,"updated":"2016-04-02T07:06:00.150Z","_id":"cimikyu900000dwuj97j0f0mj","title":"","comments":1,"layout":"post","photos":[],"link":""},{"layout":"post","date":"2014-12-21T04:24:00.000Z","title":"排序算法-归并排序","comment":true,"_content":"\n**注：代码均使用C++编写.**\n\n## 介绍\n\n对于数据较大的输入，归并排序是比较快的一个算法。该算法采用的是分治法的思想。\n\n原理：将数据分开排序，然后进行合并，最后形成一个排好的序列。\n\n<!--more-->\n\n![](/assets/articleImg/2014-12-21-mergeSort-1.png)\n\n\n将其合并输出，如下图所示：\n\n![](/assets/articleImg/2014-12-21-mergeSort-2.png)\n\n\n归并排序有一个关键步骤：合并两个排序好的序列。方法是：两个序列中的数相互比较，将较小的数先插入新的序列中。\n\n\n归并过程：比较a[i]和a[j]的大小，若a[i]≤a[j]，则将第一个有序表中的元素a[i]复制到r[k]中，并令i和k分别加上1；否则将第二个有序表中的元素a[j]复制到r[k]中，并令j和k分别加上1，如此循环下去，直到其中一个有序表取完，然后再将另一个有序表中剩余的元素复制到r中从下标k到下标t的单元。归并排序的算法我们通常用递归实现，先把待排序区间[s,t]以中点二分，接着把左边子区间排序，再把右边子区间排序，最后把左区间和右区间用一次归并操作合并成有序的区间[s,t]。\n\n- 发明者：约翰·冯·诺伊曼\n- 时间复杂度：O(nlogn)\n- 空间复杂度 O（n)\n- 稳定的算法\n\n\n## 一次合并\n\n在代码实现部分，需要进行递归进行合并，因此，先编写一个合并的方法。\n\n归并操作的工作原理如下：\n\n一次归并函数传递的参数有：一个数组名、数组的起始位置、数组的末尾位置以及数组的中点位置。\n\n- 第一步：申请空间，初始化起点中点和中点到末尾位置两个变量(nl,nr)，同时设定两个指针p和q，空间大小分别为nl和nr;\n- 第二步：将数组分别输入到两个空间中;\n- 第三步：合并两个数组。操作：比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置;\n- 重复步骤3直到某一指针超出序列尾;\n- 将另一序列剩下的所有元素直接复制到合并序列尾.\n\n在第三步的时候，需要注意的是，不额外的开辟辅助数组，直接通过两个指针的值将原数组的数值进行修改。此处需要设置一个变量`k`，起始位置为数组的起始位置,方便在合并时同时增加指针的下标和数组下标值.\n\n注：使用`malloc`时，需要引入`#include <stdlib.h>`头文件。\n\n代码如下:\n\n```\nvoid mergeOne(int nums[], int l, int m, int r){\n    int nl = m - l + 1;\n    int nr = r - m;\n    int *p = NULL, *q = NULL;\n    p = (int *) malloc (nl * sizeof(int));\n    q = (int *) malloc (nr * sizeof(int));\n\n    //将数组输入到两个空间中\n    for(int i = 0; i < nl; i++) {\n        p[i] = nums[l + i];\n    }\n    for(int j = 0; j < nr; j++) {\n        q[j] = nums[m + 1 + j];\n    }\n\n    //合并两个数组\n    int i = 0;\n    int j = 0;\n    int k = l;\n    while(i < nl && j < nr) {\n        if(p[i] < q[j]) {\n            nums[k++] = p[i++];\n        }else{\n            nums[k++] = q[j++];\n        }\n    }\n\n    //将剩余的元素合并\n    while(i < nl) {\n        nums[k++]  = p[i++];\n    }\n    while(j <nr) {\n        nums[k++] = q[j++];\n    }\n}\n```\n\n\n## 归并排序\n\n通过合并函数来实现归并排序的算法\n\n```\n//注意：此处的left和right必须是数组下标能取到的有效值\nvoid mergeSort(int nums[], int left, int right) {\n    int mid = (left + right) >> 1;\n    if(left < right) {\n        mergeSort(nums, left, mid);\n        mergeSort(nums, mid+1, right);\n        mergeOne(nums, left, mid, right);\n    }\n}\n```\n\n## 测试\n\n```\n#include <iostream>\n#include <stdlib.h>\nvoid print_array(int nums[], int n);\nusing namespace std;\nint main()\n{\n    int nums[]={9, 3, 5, 2, 7, 6, 4, 1};\n    int n = sizeof(nums)/sizeof(nums[0]);\n    mergeSort(nums, 0, n - 1);\n    print_array(nums,n);\n    return 0;\n}\nvoid print_array(int nums[], int n) {\n    for(int i = 0; i<n; i++){\n        cout<<nums[i]<<\" \";\n    }\n    cout<<endl;\n}\n\n```\n\n最后输出：\n\n<pre><code class=\"markdown\">1 2 3 4 5 6 7 9\n\nProcess returned 0 (0x0)   execution time : 0.097 s\nPress any key to continue.\n</code></pre>\n\n---\n\n","source":"_posts/2014-12-21-MergeSort.md","raw":"---\nlayout: post\ndate: 2014-12-21 12:24\ntitle: \"排序算法-归并排序\"\ncategories: 算法与数据结构\ntag: \n\t- 归并\n\t- 数据结构\n\t- 排序\n\t- C++\ncomment: true\n---\n\n**注：代码均使用C++编写.**\n\n## 介绍\n\n对于数据较大的输入，归并排序是比较快的一个算法。该算法采用的是分治法的思想。\n\n原理：将数据分开排序，然后进行合并，最后形成一个排好的序列。\n\n<!--more-->\n\n![](/assets/articleImg/2014-12-21-mergeSort-1.png)\n\n\n将其合并输出，如下图所示：\n\n![](/assets/articleImg/2014-12-21-mergeSort-2.png)\n\n\n归并排序有一个关键步骤：合并两个排序好的序列。方法是：两个序列中的数相互比较，将较小的数先插入新的序列中。\n\n\n归并过程：比较a[i]和a[j]的大小，若a[i]≤a[j]，则将第一个有序表中的元素a[i]复制到r[k]中，并令i和k分别加上1；否则将第二个有序表中的元素a[j]复制到r[k]中，并令j和k分别加上1，如此循环下去，直到其中一个有序表取完，然后再将另一个有序表中剩余的元素复制到r中从下标k到下标t的单元。归并排序的算法我们通常用递归实现，先把待排序区间[s,t]以中点二分，接着把左边子区间排序，再把右边子区间排序，最后把左区间和右区间用一次归并操作合并成有序的区间[s,t]。\n\n- 发明者：约翰·冯·诺伊曼\n- 时间复杂度：O(nlogn)\n- 空间复杂度 O（n)\n- 稳定的算法\n\n\n## 一次合并\n\n在代码实现部分，需要进行递归进行合并，因此，先编写一个合并的方法。\n\n归并操作的工作原理如下：\n\n一次归并函数传递的参数有：一个数组名、数组的起始位置、数组的末尾位置以及数组的中点位置。\n\n- 第一步：申请空间，初始化起点中点和中点到末尾位置两个变量(nl,nr)，同时设定两个指针p和q，空间大小分别为nl和nr;\n- 第二步：将数组分别输入到两个空间中;\n- 第三步：合并两个数组。操作：比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置;\n- 重复步骤3直到某一指针超出序列尾;\n- 将另一序列剩下的所有元素直接复制到合并序列尾.\n\n在第三步的时候，需要注意的是，不额外的开辟辅助数组，直接通过两个指针的值将原数组的数值进行修改。此处需要设置一个变量`k`，起始位置为数组的起始位置,方便在合并时同时增加指针的下标和数组下标值.\n\n注：使用`malloc`时，需要引入`#include <stdlib.h>`头文件。\n\n代码如下:\n\n```\nvoid mergeOne(int nums[], int l, int m, int r){\n    int nl = m - l + 1;\n    int nr = r - m;\n    int *p = NULL, *q = NULL;\n    p = (int *) malloc (nl * sizeof(int));\n    q = (int *) malloc (nr * sizeof(int));\n\n    //将数组输入到两个空间中\n    for(int i = 0; i < nl; i++) {\n        p[i] = nums[l + i];\n    }\n    for(int j = 0; j < nr; j++) {\n        q[j] = nums[m + 1 + j];\n    }\n\n    //合并两个数组\n    int i = 0;\n    int j = 0;\n    int k = l;\n    while(i < nl && j < nr) {\n        if(p[i] < q[j]) {\n            nums[k++] = p[i++];\n        }else{\n            nums[k++] = q[j++];\n        }\n    }\n\n    //将剩余的元素合并\n    while(i < nl) {\n        nums[k++]  = p[i++];\n    }\n    while(j <nr) {\n        nums[k++] = q[j++];\n    }\n}\n```\n\n\n## 归并排序\n\n通过合并函数来实现归并排序的算法\n\n```\n//注意：此处的left和right必须是数组下标能取到的有效值\nvoid mergeSort(int nums[], int left, int right) {\n    int mid = (left + right) >> 1;\n    if(left < right) {\n        mergeSort(nums, left, mid);\n        mergeSort(nums, mid+1, right);\n        mergeOne(nums, left, mid, right);\n    }\n}\n```\n\n## 测试\n\n```\n#include <iostream>\n#include <stdlib.h>\nvoid print_array(int nums[], int n);\nusing namespace std;\nint main()\n{\n    int nums[]={9, 3, 5, 2, 7, 6, 4, 1};\n    int n = sizeof(nums)/sizeof(nums[0]);\n    mergeSort(nums, 0, n - 1);\n    print_array(nums,n);\n    return 0;\n}\nvoid print_array(int nums[], int n) {\n    for(int i = 0; i<n; i++){\n        cout<<nums[i]<<\" \";\n    }\n    cout<<endl;\n}\n\n```\n\n最后输出：\n\n<pre><code class=\"markdown\">1 2 3 4 5 6 7 9\n\nProcess returned 0 (0x0)   execution time : 0.097 s\nPress any key to continue.\n</code></pre>\n\n---\n\n","slug":"2014-12-21-MergeSort","published":1,"updated":"2016-05-03T15:33:20.166Z","comments":1,"photos":[],"link":"","_id":"cinrllkq5000gw8uj02u31fqc"},{"layout":"post","title":"Linux环境下非root用户安装Python及相关库","date":"2016-05-06T08:24:14.000Z","_content":"\n以前在使用python的时候，都是使用root用户安装好的全局python，现在，因为root用户安装的Python版本太低，同时自己没有root权限去对全局Python升级，所以要在非root用户下安装自己指定的Python。因此，就重新整理了一份如何在Linux环境下使用非root用户安装python及其相关的库，以备不时之需。\n\n<!-- more -->\n\n## 安装python\n\npython版本库[https://www.python.org/ftp/python/](https://www.python.org/ftp/python/)，此处我选择2.7.5版本的，在安装python的时候，使用`--prefix`指定安装路径即可，命令如下：\n\n\n```\nwget https://www.python.org/ftp/python/2.7.5/Python-2.7.5.tgz\ntar -xzf Python-2.7.5.tgz\ncd Python-2.7.5\nmkdir -p /home/liudiwei/software/python27 \n./configure --prefix=\"/home/liudiwei/software/python27\"\nmake\nmake install\n```\n\n\n## 安装setuptools\n\nsetuptools主要是为安装pip做准备的，下面是从下载到安装的全部命令,使用上面安装的指定路径的python`/home/liudiwei/software/python27/bin/python`进行安装：\n\n```\nwget --no-check-certificate http://pypi.python.org/packages/source/s/setuptools/setuptools-2.0.tar.gz\ntar -xzvf setuptools-2.0.tar.gz\ncd setuptools-2.0\n/home/liudiwei/software/python27/bin/python setup.py install\n```\n\n## 安装pip\n\n使用pip来安装python相关库，方便简单，此处将`python setup.py install`的python换成自己安装的指定路径下的python`/home/liudiwei/software/python27/bin/python setup.py install`.\n\n```\nwget --no-check-certificate https://pypi.python.org/packages/41/27/9a8d24e1b55bd8c85e4d022da2922cb206f183e2d18fee4e320c9547e751/pip-8.1.1.tar.gz#md5=6b86f11841e89c8241d689956ba99ed7\ntar -xzf pip-8.1.1.tar.gz\ncd pip-8.1.1\n/home/liudiwei/software/python27/bin/python setup.py install\n```\n\n## 安装相关库\n\n进入python安装目录的bin路径下，安装下面相关库，经测试，下列库均可安装。\n\n\n- simplejson\n- redis\n- numpy\n- scipy\n- sklearn\n\n安装命令：\n\n```\ncd /home/liudiwei/software/python27/bin/\n./pip install simplejson\n./pip install redis\n./pip install numpy\n./pip install scipy\n./pip install sklearn\n```\n\n关于matplotlib的安装，因为系统有些依赖包没有安装而导致matplotlib安装失败，如libpng， freetype等，待后续安装完成后，再来完善。\n\n\n## 附\n\n如果想将自己安装的python使用指定的变量运行，比如使用`mypython`来运行python，只需配置一下`~/.bashrc`文件即可，如下：\n\n```\nvim ~/.bashrc\n```\n\n在文件末尾追加下列内容:\n\n\talias mypython='/home/liudiwei/software/python27/bin/python'\n\n然后使用`source ~/.bashrc`让该配置生效。接着就可以使用`mypython`进入python控制台了。","source":"_posts/2016-05-06-python-and-pip.md","raw":"---\nlayout: post\ntitle: \"Linux环境下非root用户安装Python及相关库\"\ndate: 2016-05-06 16:24:14\ncategories: Python\ntags:\n\t- Python\n\t- pip\n---\n\n以前在使用python的时候，都是使用root用户安装好的全局python，现在，因为root用户安装的Python版本太低，同时自己没有root权限去对全局Python升级，所以要在非root用户下安装自己指定的Python。因此，就重新整理了一份如何在Linux环境下使用非root用户安装python及其相关的库，以备不时之需。\n\n<!-- more -->\n\n## 安装python\n\npython版本库[https://www.python.org/ftp/python/](https://www.python.org/ftp/python/)，此处我选择2.7.5版本的，在安装python的时候，使用`--prefix`指定安装路径即可，命令如下：\n\n\n```\nwget https://www.python.org/ftp/python/2.7.5/Python-2.7.5.tgz\ntar -xzf Python-2.7.5.tgz\ncd Python-2.7.5\nmkdir -p /home/liudiwei/software/python27 \n./configure --prefix=\"/home/liudiwei/software/python27\"\nmake\nmake install\n```\n\n\n## 安装setuptools\n\nsetuptools主要是为安装pip做准备的，下面是从下载到安装的全部命令,使用上面安装的指定路径的python`/home/liudiwei/software/python27/bin/python`进行安装：\n\n```\nwget --no-check-certificate http://pypi.python.org/packages/source/s/setuptools/setuptools-2.0.tar.gz\ntar -xzvf setuptools-2.0.tar.gz\ncd setuptools-2.0\n/home/liudiwei/software/python27/bin/python setup.py install\n```\n\n## 安装pip\n\n使用pip来安装python相关库，方便简单，此处将`python setup.py install`的python换成自己安装的指定路径下的python`/home/liudiwei/software/python27/bin/python setup.py install`.\n\n```\nwget --no-check-certificate https://pypi.python.org/packages/41/27/9a8d24e1b55bd8c85e4d022da2922cb206f183e2d18fee4e320c9547e751/pip-8.1.1.tar.gz#md5=6b86f11841e89c8241d689956ba99ed7\ntar -xzf pip-8.1.1.tar.gz\ncd pip-8.1.1\n/home/liudiwei/software/python27/bin/python setup.py install\n```\n\n## 安装相关库\n\n进入python安装目录的bin路径下，安装下面相关库，经测试，下列库均可安装。\n\n\n- simplejson\n- redis\n- numpy\n- scipy\n- sklearn\n\n安装命令：\n\n```\ncd /home/liudiwei/software/python27/bin/\n./pip install simplejson\n./pip install redis\n./pip install numpy\n./pip install scipy\n./pip install sklearn\n```\n\n关于matplotlib的安装，因为系统有些依赖包没有安装而导致matplotlib安装失败，如libpng， freetype等，待后续安装完成后，再来完善。\n\n\n## 附\n\n如果想将自己安装的python使用指定的变量运行，比如使用`mypython`来运行python，只需配置一下`~/.bashrc`文件即可，如下：\n\n```\nvim ~/.bashrc\n```\n\n在文件末尾追加下列内容:\n\n\talias mypython='/home/liudiwei/software/python27/bin/python'\n\n然后使用`source ~/.bashrc`让该配置生效。接着就可以使用`mypython`进入python控制台了。","slug":"2016-05-06-python-and-pip","published":1,"updated":"2016-05-17T14:15:14.864Z","_id":"cinxb4jv80000q0uj81jkiu0d","comments":1,"photos":[],"link":""},{"layout":"post","date":"2016-05-07T07:04:00.000Z","title":"随机森林和mRMR特征选择","comment":true,"_content":"\n\n\n算法性能的好坏跟数据是密不可分的，因此找到一组更具代表性的特征子集显得更加重要。在实际项目中，因为有的特征对模型而言是冗余的，它对算法的性能会产生负面影响，此时就需要做特征选择。特征选择的目的就是从一组特征集合中去除冗余或不相关的特征从而达到降维的目的。说到降维，它不仅包括特征选择，还包括了特征提取，而本文主要介绍两种常用的特征选择方法。\n\n<!-- more -->\n\n对于一个包含n个特征的特征集合，搜索空间高达$2^n - 1$种可能的子集，所以如果是使用穷举法，不得不说下，穷举法的结果确实很好，特征少的时候或许可以考虑，但特征多的时候必将带来不可估量的计算量。所以我们需要找一种相对折衷的方法。也就是下面谈到的RF和mRMR。\n\n## Random Forest\n\n<font color=\"#007ff\">**注意：随机森林使用的CART算法的方法增长树，也就是使用Gini指数来划分**</font>。Gini指数度量的是数据分区或训练集D的不纯度（注意，这里是不纯度，跟熵有点不同）。基尼不纯度表示的是一个随机选中的样本在子集中被分错的可能性。基尼不纯度为这个样本被选中的概率乘上它被分错的概率。当一个节点中所有样本都是一个类时，基尼不纯度为零。 定义为：\n\n![$$Gini(D) = 1 - \\sum_{i=1}^m p_i^2$$](http://latex.codecogs.com/gif.latex?%24%24Gini%28D%29%20%3D%201%20-%20%5Csum_%7Bi%3D1%7D%5Em%20p_i%5E2%24%24)\n\n假设A有v个不同的值出现在特征D中，它的二元划分有$2^v - 2$种（除去自己和空集）。当考虑二元划分裂时，计算每个结果分区的不纯度加权和。比如A有两个值，则特征D被划分成D1和D2,这时Gini指数为：\n\n![$$Gini_A(D) = \\frac{D_1}{D} Gini(D_1) + \\frac{D_2}{D} Gini(D_2)$$](http://latex.codecogs.com/gif.latex?Gini_A%28D%29%20%3D%20%5Cfrac%7BD_1%7D%7BD%7D%20Gini%28D_1%29%20&plus;%20%5Cfrac%7BD_2%7D%7BD%7D%20Gini%28D_2%29)\n\nGini指数偏向于多值属性，并且当类的数量很大时会有困难，而且它还倾向于导致相等大小的分区和纯度。但实践效果不错。\n\n如果训练数据集有m维,样本个数为n,则 CART算法的时间复杂度为$ Ο (m n logn^2)$ 。\n\n互信息是条件概率与后验概率的比值，化简之后就可以得到信息增益。所以说互信息其实就是信息增益。计算方法【互信息=熵-条件熵】。熵描述的是不确定性。熵越大，不确定性就越大，条件熵H（B|A）描述的是在A给定的条件下B的不确定性，如果条件熵越小，表示不确定性就越小，那么B就越容易确定结果。所以使用熵减去条件熵，就得到了信息增益，他描述的不确定性的降低程度，可以用来度量两个变量的相关性。比如，在给定一个变量的条件下，另一个变量它的不确定性能够降低多少，如果不确定性降低得越多，那么它的确定性就越大，就越容易区分，两者就越相关。\n\n$$IG(D, A) = H(D) - H(D|A)$$\n\n\n随机森林对于每一棵决策树，首先对列（特征）进行采样，然后计算当前的Gini指数，随后进行全分裂过程，每棵树的非叶节点都有一个Gini指数，一棵树建立之后可以得到该树各个节点的重要性，通过对其按照Gini指数作为特征相关性来排序，接着一次建立多棵决策树，并且生成多个特征相关性排名，最后对这些特征选平均值，得到最终排好序的特征重要性排名。\n\n\n随机森林OOB特征选择：\n\n- 首先建立m棵决策树，然后分别计算每棵树的OOB袋外误差errOOBj。\n- 计算特征$x_i $的重要性。随机的修改OOB中的每个特征$x_i $的值，再次计算它的袋外误差errOOBi；$x_i 的重要性=\\sum\\frac{errOOBi-errOOBj}{Ntree}$.\n- 按照特征的重要性排序，然后剔除后面不重要的特征；\n- 然后重复以上步骤，直到选出m个特征。\n\n\n在scikit-learn中封装了random forest特征选择方法：\n\n```\nfrom sklearn.datasets import load_boston\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\n#Load boston housing dataset as an example\nboston = load_boston()\nX = boston[\"data\"]\nY = boston[\"target\"]\nnames = boston[\"feature_names\"]\nrf = RandomForestRegressor()\nrf.fit(X, Y)\nprint \"Features sorted by their score:\"\nprint sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n             reverse=True)\n\n```\n\n最后输出的是：\n\n>Features sorted by their score:\n[(0.5298, 'LSTAT'), (0.4116, 'RM'), (0.0252, 'DIS'), (0.0172, 'CRIM'), (0.0065, 'NOX'), (0.0035, 'PTRATIO'), (0.0021, 'TAX'), (0.0017, 'AGE'), (0.0012, 'B'), (0.0008, 'INDUS'), (0.0004, 'RAD'), (0.0001, 'CHAS'), (0.0, 'ZN')]\n\n## mRMR\n\n最大相关最小冗余（mRMR），顾名思义，我们可以知道，它不仅考虑到了特征和label之间的相关性，还考虑到了特征和特征之间的相关性。度量标准使用的是互信息(Mutual information)。对于mRMR方法，<font color=\"#007FFF\">**特征子集与类别的相关性通过各个特征与类别的信息增益的均值来计算，而特征与特征的冗余使用的是特征和特征之间的互信息加和再除以子集中特征个数的平方**</font>，因为I(xi,xj)计算了两次。\n\n**No.1 最大相关性**\n\n目的：保证特征和类别的相关性最大。\n\n![$$max \\ D(S, c),\\  D = \\frac{1}{|S|} \\sum_{x_i \\epsilon S } I(x_i; c)$$](http://latex.codecogs.com/gif.latex?max%20%5C%20D%28S%2C%20c%29%2C%5C%20D%20%3D%20%5Cfrac%7B1%7D%7B%7CS%7C%7D%20%5Csum_%7Bx_i%20%5Cepsilon%20S%20%7D%20I%28x_i%3B%20c%29)\n \n\n**No.2 最小冗余性**\n\n目的：确保特征之间的冗余性最小。\n\n![min\\ R(S, c),\\ \\ R = \\frac{1}{|S|^2} \\sum_{x_i,x_j \\epsilon S } I(x_i; x_j)](http://latex.codecogs.com/gif.latex?min%5C%20R%28S%2C%20c%29%2C%5C%20%5C%20R%20%3D%20%5Cfrac%7B1%7D%7B%7CS%7C%5E2%7D%20%5Csum_%7Bx_i%2Cx_j%20%5Cepsilon%20S%20%7D%20I%28x_i%3B%20x_j%29)\n\n两个式子中，S表示已经选择的特征子集，c表示classs\\_label，x表示特征。最后选择标准是：\n\n$$max \\  \\Phi(D,R) , \\Phi = D - R$$\n\n得到的子集在保证特征与类别的相关性较大的同时，还保证了特征的冗余性最小。\n\n\n关于mRMR实现，可以到github上面去下载：[网址链接](https://github.com/csuldw/MachineLearning/tree/master/mRMR)\n\n\n\n\n## 小结\n\n使用RF和mRMR进行特征选择后，都会得到一个重要性排名。接下来通常需要结合交叉验证来选择结果性能最好的特征子集。比较原始的方法就是，根据排名对特征子集从`top1-topn`一个个进行交叉验证测试，然后选择结果最好的一组特征即可。\n\n\n## 文献\n\n- 《数据挖掘概念与技术》，韩家炜；\n- [Minimum Redundancy and Maximum Relevance Feature selection](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwitzvCwpMzLAhUFUaYKHQi8A5IQFggmMAE&url=http%3A%2F%2Fpenglab.janelia.org%2Fproj%2FmRMR%2FBIBM07_mRMR_071103_handout.pdf&usg=AFQjCNFh9Rqy1qlJjqUABlFuaY4yvBsPTA&sig2=YxQvuBTk64GkAaZ560gznQ)\n- [Variable selection using Random Forests ](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=5&cad=rja&uact=8&sqi=2&ved=0ahUKEwiWho6tpczLAhWEppQKHdr0BdEQFgg7MAQ&url=https%3A%2F%2Fhal.archives-ouvertes.fr%2Fhal-00755489%2Ffile%2FPRLv4.pdf&usg=AFQjCNGq5RLaeyLLQXzBbsKvL_UUn-mflw&sig2=XuJTB29C5kU1f0WAtJwwfg)\n- [Selecting good features – Part III: random forests](http://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n- [mRMR (minimum Redundancy Maximum Relevance Feature Selection)](http://penglab.janelia.org/proj/mRMR/)","source":"_posts/2016-05-07-feature-selection.md","raw":"---\nlayout: post\ndate: 2016-05-07 15:04\ntitle: \"随机森林和mRMR特征选择\"\ncategories: ML\ntag:\n\t- Machine Learning\n\t- mRMR\n\t- 特征选择\n\t- Random Forest\ncomment: true\n---\n\n\n\n算法性能的好坏跟数据是密不可分的，因此找到一组更具代表性的特征子集显得更加重要。在实际项目中，因为有的特征对模型而言是冗余的，它对算法的性能会产生负面影响，此时就需要做特征选择。特征选择的目的就是从一组特征集合中去除冗余或不相关的特征从而达到降维的目的。说到降维，它不仅包括特征选择，还包括了特征提取，而本文主要介绍两种常用的特征选择方法。\n\n<!-- more -->\n\n对于一个包含n个特征的特征集合，搜索空间高达$2^n - 1$种可能的子集，所以如果是使用穷举法，不得不说下，穷举法的结果确实很好，特征少的时候或许可以考虑，但特征多的时候必将带来不可估量的计算量。所以我们需要找一种相对折衷的方法。也就是下面谈到的RF和mRMR。\n\n## Random Forest\n\n<font color=\"#007ff\">**注意：随机森林使用的CART算法的方法增长树，也就是使用Gini指数来划分**</font>。Gini指数度量的是数据分区或训练集D的不纯度（注意，这里是不纯度，跟熵有点不同）。基尼不纯度表示的是一个随机选中的样本在子集中被分错的可能性。基尼不纯度为这个样本被选中的概率乘上它被分错的概率。当一个节点中所有样本都是一个类时，基尼不纯度为零。 定义为：\n\n![$$Gini(D) = 1 - \\sum_{i=1}^m p_i^2$$](http://latex.codecogs.com/gif.latex?%24%24Gini%28D%29%20%3D%201%20-%20%5Csum_%7Bi%3D1%7D%5Em%20p_i%5E2%24%24)\n\n假设A有v个不同的值出现在特征D中，它的二元划分有$2^v - 2$种（除去自己和空集）。当考虑二元划分裂时，计算每个结果分区的不纯度加权和。比如A有两个值，则特征D被划分成D1和D2,这时Gini指数为：\n\n![$$Gini_A(D) = \\frac{D_1}{D} Gini(D_1) + \\frac{D_2}{D} Gini(D_2)$$](http://latex.codecogs.com/gif.latex?Gini_A%28D%29%20%3D%20%5Cfrac%7BD_1%7D%7BD%7D%20Gini%28D_1%29%20&plus;%20%5Cfrac%7BD_2%7D%7BD%7D%20Gini%28D_2%29)\n\nGini指数偏向于多值属性，并且当类的数量很大时会有困难，而且它还倾向于导致相等大小的分区和纯度。但实践效果不错。\n\n如果训练数据集有m维,样本个数为n,则 CART算法的时间复杂度为$ Ο (m n logn^2)$ 。\n\n互信息是条件概率与后验概率的比值，化简之后就可以得到信息增益。所以说互信息其实就是信息增益。计算方法【互信息=熵-条件熵】。熵描述的是不确定性。熵越大，不确定性就越大，条件熵H（B|A）描述的是在A给定的条件下B的不确定性，如果条件熵越小，表示不确定性就越小，那么B就越容易确定结果。所以使用熵减去条件熵，就得到了信息增益，他描述的不确定性的降低程度，可以用来度量两个变量的相关性。比如，在给定一个变量的条件下，另一个变量它的不确定性能够降低多少，如果不确定性降低得越多，那么它的确定性就越大，就越容易区分，两者就越相关。\n\n$$IG(D, A) = H(D) - H(D|A)$$\n\n\n随机森林对于每一棵决策树，首先对列（特征）进行采样，然后计算当前的Gini指数，随后进行全分裂过程，每棵树的非叶节点都有一个Gini指数，一棵树建立之后可以得到该树各个节点的重要性，通过对其按照Gini指数作为特征相关性来排序，接着一次建立多棵决策树，并且生成多个特征相关性排名，最后对这些特征选平均值，得到最终排好序的特征重要性排名。\n\n\n随机森林OOB特征选择：\n\n- 首先建立m棵决策树，然后分别计算每棵树的OOB袋外误差errOOBj。\n- 计算特征$x_i $的重要性。随机的修改OOB中的每个特征$x_i $的值，再次计算它的袋外误差errOOBi；$x_i 的重要性=\\sum\\frac{errOOBi-errOOBj}{Ntree}$.\n- 按照特征的重要性排序，然后剔除后面不重要的特征；\n- 然后重复以上步骤，直到选出m个特征。\n\n\n在scikit-learn中封装了random forest特征选择方法：\n\n```\nfrom sklearn.datasets import load_boston\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\n#Load boston housing dataset as an example\nboston = load_boston()\nX = boston[\"data\"]\nY = boston[\"target\"]\nnames = boston[\"feature_names\"]\nrf = RandomForestRegressor()\nrf.fit(X, Y)\nprint \"Features sorted by their score:\"\nprint sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n             reverse=True)\n\n```\n\n最后输出的是：\n\n>Features sorted by their score:\n[(0.5298, 'LSTAT'), (0.4116, 'RM'), (0.0252, 'DIS'), (0.0172, 'CRIM'), (0.0065, 'NOX'), (0.0035, 'PTRATIO'), (0.0021, 'TAX'), (0.0017, 'AGE'), (0.0012, 'B'), (0.0008, 'INDUS'), (0.0004, 'RAD'), (0.0001, 'CHAS'), (0.0, 'ZN')]\n\n## mRMR\n\n最大相关最小冗余（mRMR），顾名思义，我们可以知道，它不仅考虑到了特征和label之间的相关性，还考虑到了特征和特征之间的相关性。度量标准使用的是互信息(Mutual information)。对于mRMR方法，<font color=\"#007FFF\">**特征子集与类别的相关性通过各个特征与类别的信息增益的均值来计算，而特征与特征的冗余使用的是特征和特征之间的互信息加和再除以子集中特征个数的平方**</font>，因为I(xi,xj)计算了两次。\n\n**No.1 最大相关性**\n\n目的：保证特征和类别的相关性最大。\n\n![$$max \\ D(S, c),\\  D = \\frac{1}{|S|} \\sum_{x_i \\epsilon S } I(x_i; c)$$](http://latex.codecogs.com/gif.latex?max%20%5C%20D%28S%2C%20c%29%2C%5C%20D%20%3D%20%5Cfrac%7B1%7D%7B%7CS%7C%7D%20%5Csum_%7Bx_i%20%5Cepsilon%20S%20%7D%20I%28x_i%3B%20c%29)\n \n\n**No.2 最小冗余性**\n\n目的：确保特征之间的冗余性最小。\n\n![min\\ R(S, c),\\ \\ R = \\frac{1}{|S|^2} \\sum_{x_i,x_j \\epsilon S } I(x_i; x_j)](http://latex.codecogs.com/gif.latex?min%5C%20R%28S%2C%20c%29%2C%5C%20%5C%20R%20%3D%20%5Cfrac%7B1%7D%7B%7CS%7C%5E2%7D%20%5Csum_%7Bx_i%2Cx_j%20%5Cepsilon%20S%20%7D%20I%28x_i%3B%20x_j%29)\n\n两个式子中，S表示已经选择的特征子集，c表示classs\\_label，x表示特征。最后选择标准是：\n\n$$max \\  \\Phi(D,R) , \\Phi = D - R$$\n\n得到的子集在保证特征与类别的相关性较大的同时，还保证了特征的冗余性最小。\n\n\n关于mRMR实现，可以到github上面去下载：[网址链接](https://github.com/csuldw/MachineLearning/tree/master/mRMR)\n\n\n\n\n## 小结\n\n使用RF和mRMR进行特征选择后，都会得到一个重要性排名。接下来通常需要结合交叉验证来选择结果性能最好的特征子集。比较原始的方法就是，根据排名对特征子集从`top1-topn`一个个进行交叉验证测试，然后选择结果最好的一组特征即可。\n\n\n## 文献\n\n- 《数据挖掘概念与技术》，韩家炜；\n- [Minimum Redundancy and Maximum Relevance Feature selection](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwitzvCwpMzLAhUFUaYKHQi8A5IQFggmMAE&url=http%3A%2F%2Fpenglab.janelia.org%2Fproj%2FmRMR%2FBIBM07_mRMR_071103_handout.pdf&usg=AFQjCNFh9Rqy1qlJjqUABlFuaY4yvBsPTA&sig2=YxQvuBTk64GkAaZ560gznQ)\n- [Variable selection using Random Forests ](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=5&cad=rja&uact=8&sqi=2&ved=0ahUKEwiWho6tpczLAhWEppQKHdr0BdEQFgg7MAQ&url=https%3A%2F%2Fhal.archives-ouvertes.fr%2Fhal-00755489%2Ffile%2FPRLv4.pdf&usg=AFQjCNGq5RLaeyLLQXzBbsKvL_UUn-mflw&sig2=XuJTB29C5kU1f0WAtJwwfg)\n- [Selecting good features – Part III: random forests](http://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n- [mRMR (minimum Redundancy Maximum Relevance Feature Selection)](http://penglab.janelia.org/proj/mRMR/)","slug":"2016-05-07-feature-selection","published":1,"updated":"2016-05-10T16:01:52.695Z","comments":1,"photos":[],"link":"","_id":"cio1mmulg0000k4ujpdzz53si"}],"PostAsset":[],"PostCategory":[{"post_id":"cimigpyuo003f6cuju3oxlk3l","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpyuq003g6cujob3wohel"},{"post_id":"cimigpyv4003w6cuj73dchwah","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpyv5003x6cuj4wbk4r6r"},{"post_id":"cimigpyvb00456cujmqn5kks5","category_id":"cimigpyuy003o6cuj3zmo8gss","_id":"cimigpyvc00466cujmzwe4bgd"},{"post_id":"cimigpyvf004c6cujixcvrys0","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpyvg004d6cuj2hbjdv4k"},{"post_id":"cimigpyvk004h6cujor1ya83u","category_id":"cimigpyvl004i6cuj7vott2cg","_id":"cimigpyvm004l6cujeoxxtouz"},{"post_id":"cimigpyvn004m6cujjjrgqfrz","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpyvp004n6cujnxbidlg8"},{"post_id":"cimigpyvu004s6cujfv70tpf4","category_id":"cimigpyvy004t6cujcxi7gqbb","_id":"cimigpyw0004w6cuj8g1loup1"},{"post_id":"cimigpyw2004z6cujkbzlolvy","category_id":"cimigpyuy003o6cuj3zmo8gss","_id":"cimigpyw400506cujmnycqp2p"},{"post_id":"cimigpyw700526cujo8lw5ang","category_id":"cimigpyuy003o6cuj3zmo8gss","_id":"cimigpywa00536cuj1sdym20p"},{"post_id":"cimigpywe00556cujx3n5iqug","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpywf00566cuj4bysy7bk"},{"post_id":"cimigpywk005a6cujvdylxajh","category_id":"cimigpywl005b6cujx4qv8mn3","_id":"cimigpywm005e6cujz3new5ki"},{"post_id":"cimigpywp005f6cuj84z90vn9","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpywq005g6cuj6iuk1fxh"},{"post_id":"cimigpywt005j6cuj45ppr6gt","category_id":"cimigpywv005k6cujyh1pcxa2","_id":"cimigpyww005n6cujizokp6xy"},{"post_id":"cimigpywz005s6cuj1uckijs7","category_id":"cimigpywv005k6cujyh1pcxa2","_id":"cimigpyx0005t6cujc67jlnfn"},{"post_id":"cimigpyx2005w6cujlur1slca","category_id":"cimigpywv005k6cujyh1pcxa2","_id":"cimigpyx9005x6cuj89kgomfb"},{"post_id":"cimigpyxd00616cuj8dvob89d","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpyxg00626cujs5nm1fua"},{"post_id":"cimigpyxp00686cujeo4kd4ot","category_id":"cimigpyuy003o6cuj3zmo8gss","_id":"cimigpyxq00696cujk7i4h1rc"},{"post_id":"cimigpyxs006b6cuj8nsu98fg","category_id":"cimigpyuy003o6cuj3zmo8gss","_id":"cimigpyxu006c6cuj3ghfzljr"},{"post_id":"cimigpyxx006h6cujautwevr4","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpyy0006i6cujp8l5odlr"},{"post_id":"cimigpyy5006n6cujg9mdus4b","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpyy7006o6cuj0qn8tb4n"},{"post_id":"cimigpyyi006x6cujo3mibo7p","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpyyk006y6cujwxgvgqqf"},{"post_id":"cimigpyyn00706cuj58ohd4wl","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpyyp00716cujjzs8gbqe"},{"post_id":"cimigpyyt00776cujo0do57cd","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpyyw00786cujhfoawqk7"},{"post_id":"cimigpyz4007g6cujgdtrbcmb","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpyz6007h6cujgpk7mpdf"},{"post_id":"cimigpyz9007n6cujp5ohti3n","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpyzb007o6cuj9l5mjhes"},{"post_id":"cimigpyzf007s6cujmmlyts1a","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpyzi007t6cuj7sbyk44z"},{"post_id":"cimigpyzo007y6cuj1xfeu6yc","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpyzq007z6cujaer7y1tn"},{"post_id":"cimigpyzu00836cuja3ego36g","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpyzy00846cujs6oxmzep"},{"post_id":"cimigpz03008b6cujcrftv7r6","category_id":"cimigpyuy003o6cuj3zmo8gss","_id":"cimigpz05008c6cuj9ih9wvk8"},{"post_id":"cimigpz0d008j6cuj5b49oxml","category_id":"cimigpywv005k6cujyh1pcxa2","_id":"cimigpz0g008k6cuj4ug6p51d"},{"post_id":"cimigpz0i008o6cuj9e4zcsgq","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpz0k008p6cuj7gphh8gw"},{"post_id":"cimigpz0n008u6cujtjuu313e","category_id":"cimigpyuy003o6cuj3zmo8gss","_id":"cimigpz0p008v6cuj7yqzyw97"},{"post_id":"cimigpz0r008x6cujudpkpjsu","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpz0t008y6cujw1v80fl8"},{"post_id":"cimigpz0y00946cuj30auvacu","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpz1000956cujzrj0mkfv"},{"post_id":"cimigpz15009b6cujfpi09dar","category_id":"cimigpyuy003o6cuj3zmo8gss","_id":"cimigpz17009c6cujqopkm3x8"},{"post_id":"cimigpz1d009h6cujp3k70b0s","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpz1f009i6cujhz36ebcx"},{"post_id":"cimigpz1i009n6cuj8red0nje","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpz1k009o6cujv98rczyy"},{"post_id":"cimigpz1v009z6cuj7bzbzbj3","category_id":"cimigpyye006t6cujvfe76ulx","_id":"cimigpz1y00a06cujvf7zu1db"},{"post_id":"cimigpz2200a66cujhvgxjgp2","category_id":"cimigpz2400a76cujfb0saqy9","_id":"cimigpz2600aa6cuj4867plji"},{"post_id":"cimigpz2800ab6cuj82no2lv5","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cimigpz2a00ac6cujcz9t2iym"},{"post_id":"cimigpz2d00ag6cujt8xgsmar","category_id":"cimigpyvy004t6cujcxi7gqbb","_id":"cimigpz2f00ah6cujy67rkot2"},{"post_id":"cimigpz2k00an6cujn58oehkv","category_id":"cimigpyvy004t6cujcxi7gqbb","_id":"cimigpz2m00ao6cuj5p9k0wdl"},{"post_id":"cimigpz2t00aw6cujj5y41v9s","category_id":"cimigpyvy004t6cujcxi7gqbb","_id":"cimigpz2v00ax6cujff5lfpok"},{"post_id":"cimigpz3100b56cujrk86uria","category_id":"cimigpyvy004t6cujcxi7gqbb","_id":"cimigpz3400b66cujgpzqwy2e"},{"post_id":"cimigpz3b00be6cuj53aaa1qt","category_id":"cimigpyvy004t6cujcxi7gqbb","_id":"cimigpz3d00bf6cuja9sw30p1"},{"post_id":"cimigpz3i00bn6cuj4bmtkbwr","category_id":"cimigpyuy003o6cuj3zmo8gss","_id":"cimigpz3m00bo6cujkzoxupx3"},{"post_id":"cimigpz3p00bq6cujj4qcnb9m","category_id":"cimigpz3r00br6cuj5j4wnook","_id":"cimigpz3t00bu6cujzll0wrue"},{"post_id":"cinrllkq5000gw8uj02u31fqc","category_id":"cimigpyvy004t6cujcxi7gqbb","_id":"cinrllkq7000hw8uj4hzwuv2o"},{"post_id":"cio1mmulg0000k4ujpdzz53si","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cio1mmulz0001k4ujb1i3ed2t"},{"post_id":"cimigpz1o009u6cuj3msd00b0","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cio1mmup40006k4uj8o9dos7n"},{"post_id":"cimigpyug00346cuja5g5fono","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cio1n5vxs0000bkujrfr0qvqj"},{"post_id":"cimigpyu8002x6cuj3awrm2j5","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cio1n5vyr0002bkujv4yy51f4"},{"post_id":"cinxb4jv80000q0uj81jkiu0d","category_id":"cimigpyuy003o6cuj3zmo8gss","_id":"ciobiv3tg00005sujrcsfzz5j"},{"post_id":"cimigpytq002j6cujs6njxuqa","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cip7nu7a50000v4ujdijz8z5m"},{"post_id":"cimigpyu2002q6cuje9mgs8ik","category_id":"cimigpytv002k6cujkorl1pbd","_id":"cip7oo17c00005oujypjz2yfk"},{"post_id":"cimigpyuw003n6cuj1vethrc5","category_id":"cimigpyuy003o6cuj3zmo8gss","_id":"cip7oxrln0000vwujcd9m2iaa"},{"post_id":"cimigpyv1003t6cuj2dkipeh8","category_id":"cimigpyuy003o6cuj3zmo8gss","_id":"cip7ozsqo0000vcuji4g32iz0"},{"post_id":"cimigpyyb006s6cujhny2fhya","category_id":"cimigpyye006t6cujvfe76ulx","_id":"cip7p1cyd0000w4uj6virzssh"}],"PostTag":[{"post_id":"cimigpytq002j6cujs6njxuqa","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpyu0002o6cujt5xaix1q"},{"post_id":"cimigpytq002j6cujs6njxuqa","tag_id":"cimigpytz002m6cujh7x4py7z","_id":"cimigpyu1002p6cujn251m402"},{"post_id":"cimigpyu2002q6cuje9mgs8ik","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpyu6002u6cuj8n1hlxky"},{"post_id":"cimigpyu2002q6cuje9mgs8ik","tag_id":"cimigpyu4002s6cujjj2ivgf6","_id":"cimigpyu6002v6cujo09nvy7v"},{"post_id":"cimigpyu2002q6cuje9mgs8ik","tag_id":"cimigpyu5002t6cujpxk4yk8i","_id":"cimigpyu7002w6cujp2o05u87"},{"post_id":"cimigpyu8002x6cuj3awrm2j5","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpyud00316cujaon4cn2m"},{"post_id":"cimigpyu8002x6cuj3awrm2j5","tag_id":"cimigpyua002z6cujdbu1jyqo","_id":"cimigpyue00326cujdkwxgk6o"},{"post_id":"cimigpyu8002x6cuj3awrm2j5","tag_id":"cimigpyud00306cujyf64tc2z","_id":"cimigpyue00336cujt30a6f36"},{"post_id":"cimigpyug00346cuja5g5fono","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpyul003a6cujrrzwb4wk"},{"post_id":"cimigpyug00346cuja5g5fono","tag_id":"cimigpyui00366cuj6i4n20nf","_id":"cimigpyul003b6cujj5twar4f"},{"post_id":"cimigpyug00346cuja5g5fono","tag_id":"cimigpyuj00376cuj64twd25a","_id":"cimigpyul003c6cuj4iey2af4"},{"post_id":"cimigpyug00346cuja5g5fono","tag_id":"cimigpyuj00386cujt0afya7o","_id":"cimigpyum003d6cujw6jkwvem"},{"post_id":"cimigpyug00346cuja5g5fono","tag_id":"cimigpyuk00396cujwek631mr","_id":"cimigpyun003e6cujmjl86of3"},{"post_id":"cimigpyuo003f6cuju3oxlk3l","tag_id":"cimigpyuq003h6cujd8425hwp","_id":"cimigpyus003k6cujmy15n1la"},{"post_id":"cimigpyuo003f6cuju3oxlk3l","tag_id":"cimigpyuq003i6cujajdizz6h","_id":"cimigpyut003l6cuju6h8re66"},{"post_id":"cimigpyuo003f6cuju3oxlk3l","tag_id":"cimigpyur003j6cujdcu2lnxp","_id":"cimigpyuu003m6cujmdm1xs07"},{"post_id":"cimigpyuw003n6cuj1vethrc5","tag_id":"cimigpyur003j6cujdcu2lnxp","_id":"cimigpyuz003q6cuj5ji8tnzu"},{"post_id":"cimigpyuw003n6cuj1vethrc5","tag_id":"cimigpyuz003p6cujjjnm6byo","_id":"cimigpyv0003s6cuj7abuubed"},{"post_id":"cimigpyv1003t6cuj2dkipeh8","tag_id":"cimigpyur003j6cujdcu2lnxp","_id":"cimigpyv3003v6cujpwv55rw1"},{"post_id":"cimigpyv4003w6cuj73dchwah","tag_id":"cimigpyv5003y6cujjc85b4y9","_id":"cimigpyv700416cujxyhndagx"},{"post_id":"cimigpyv4003w6cuj73dchwah","tag_id":"cimigpyv6003z6cujax72xvfq","_id":"cimigpyv800426cujemc7zzpy"},{"post_id":"cimigpyv4003w6cuj73dchwah","tag_id":"cimigpyv700406cujh8av4on7","_id":"cimigpyv800436cujxieqxeiz"},{"post_id":"cimigpyv4003w6cuj73dchwah","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpyv900446cuj9bwmczfw"},{"post_id":"cimigpyvb00456cujmqn5kks5","tag_id":"cimigpyvc00476cuj0g3tzuwp","_id":"cimigpyvd00496cuj1vpilcff"},{"post_id":"cimigpyvb00456cujmqn5kks5","tag_id":"cimigpyur003j6cujdcu2lnxp","_id":"cimigpyve004a6cuj9ttdlpbb"},{"post_id":"cimigpyvb00456cujmqn5kks5","tag_id":"cimigpyvd00486cuj2epin3dz","_id":"cimigpyve004b6cuj4likn7tj"},{"post_id":"cimigpyvf004c6cujixcvrys0","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpyvi004f6cujed62v0rs"},{"post_id":"cimigpyvf004c6cujixcvrys0","tag_id":"cimigpyvh004e6cuj95qj7sbu","_id":"cimigpyvi004g6cujuo0150r4"},{"post_id":"cimigpyvk004h6cujor1ya83u","tag_id":"cimigpyvl004j6cujwr7show2","_id":"cimigpyvm004k6cuj1yvlfwgi"},{"post_id":"cimigpyvn004m6cujjjrgqfrz","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpyvr004p6cujn7tmmsx1"},{"post_id":"cimigpyvn004m6cujjjrgqfrz","tag_id":"cimigpyvh004e6cuj95qj7sbu","_id":"cimigpyvr004q6cujpre9wee6"},{"post_id":"cimigpyvn004m6cujjjrgqfrz","tag_id":"cimigpyvq004o6cuj2q1pii3z","_id":"cimigpyvr004r6cujsd8ezrku"},{"post_id":"cimigpyvu004s6cujfv70tpf4","tag_id":"cimigpyvy004u6cuj8kqo4lbs","_id":"cimigpyw1004x6cujm3x5am72"},{"post_id":"cimigpyvu004s6cujfv70tpf4","tag_id":"cimigpyvz004v6cuj17ui6rq3","_id":"cimigpyw1004y6cujpyfr2epe"},{"post_id":"cimigpyw2004z6cujkbzlolvy","tag_id":"cimigpyur003j6cujdcu2lnxp","_id":"cimigpyw500516cujqhsi5rcz"},{"post_id":"cimigpyw700526cujo8lw5ang","tag_id":"cimigpyur003j6cujdcu2lnxp","_id":"cimigpywb00546cuj2j6bjr8b"},{"post_id":"cimigpywe00556cujx3n5iqug","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpywh00586cuj891qbdqq"},{"post_id":"cimigpywe00556cujx3n5iqug","tag_id":"cimigpywg00576cuj00xwdb1k","_id":"cimigpywi00596cuj0jujqy0y"},{"post_id":"cimigpywk005a6cujvdylxajh","tag_id":"cimigpywl005c6cuj0s3q9x3p","_id":"cimigpywm005d6cujq7xs6bso"},{"post_id":"cimigpywp005f6cuj84z90vn9","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpywr005h6cujyo86df2j"},{"post_id":"cimigpywp005f6cuj84z90vn9","tag_id":"cimigpyur003j6cujdcu2lnxp","_id":"cimigpyws005i6cuj3k1e7jl1"},{"post_id":"cimigpywt005j6cuj45ppr6gt","tag_id":"cimigpywv005l6cujfn9bk75g","_id":"cimigpywx005p6cuj4ejijju7"},{"post_id":"cimigpywt005j6cuj45ppr6gt","tag_id":"cimigpyww005m6cujh2lsq0xy","_id":"cimigpywy005q6cujnje1r4jk"},{"post_id":"cimigpywt005j6cuj45ppr6gt","tag_id":"cimigpyww005o6cujkec1rek6","_id":"cimigpywy005r6cujs6q37wm0"},{"post_id":"cimigpywz005s6cuj1uckijs7","tag_id":"cimigpywv005l6cujfn9bk75g","_id":"cimigpyx0005u6cujno94cz4n"},{"post_id":"cimigpywz005s6cuj1uckijs7","tag_id":"cimigpyur003j6cujdcu2lnxp","_id":"cimigpyx1005v6cuja4wz8j7l"},{"post_id":"cimigpyx2005w6cujlur1slca","tag_id":"cimigpywv005l6cujfn9bk75g","_id":"cimigpyxb005z6cujgfscyfx2"},{"post_id":"cimigpyx2005w6cujlur1slca","tag_id":"cimigpyxa005y6cuj2bg5jqwv","_id":"cimigpyxb00606cujds728hwy"},{"post_id":"cimigpyxd00616cuj8dvob89d","tag_id":"cimigpyxh00636cuj0jyzcedl","_id":"cimigpyxk00656cujzaijqlpn"},{"post_id":"cimigpyxd00616cuj8dvob89d","tag_id":"cimigpyxj00646cujm6psigch","_id":"cimigpyxm00666cujfm2mxr3n"},{"post_id":"cimigpyxd00616cuj8dvob89d","tag_id":"cimigpyww005o6cujkec1rek6","_id":"cimigpyxm00676cujgah9c969"},{"post_id":"cimigpyxp00686cujeo4kd4ot","tag_id":"cimigpyur003j6cujdcu2lnxp","_id":"cimigpyxr006a6cujqera59qe"},{"post_id":"cimigpyxs006b6cuj8nsu98fg","tag_id":"cimigpyur003j6cujdcu2lnxp","_id":"cimigpyxv006e6cujsg91g2cr"},{"post_id":"cimigpyxs006b6cuj8nsu98fg","tag_id":"cimigpyvd00486cuj2epin3dz","_id":"cimigpyxw006f6cujparscume"},{"post_id":"cimigpyxs006b6cuj8nsu98fg","tag_id":"cimigpyxv006d6cuj7fo25mw9","_id":"cimigpyxw006g6cujq04o29po"},{"post_id":"cimigpyxx006h6cujautwevr4","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpyy3006k6cujck8zm5lw"},{"post_id":"cimigpyxx006h6cujautwevr4","tag_id":"cimigpyww005o6cujkec1rek6","_id":"cimigpyy3006l6cujwe2d0pzx"},{"post_id":"cimigpyxx006h6cujautwevr4","tag_id":"cimigpyy1006j6cuju95xovxi","_id":"cimigpyy4006m6cujmijs5pue"},{"post_id":"cimigpyy5006n6cujg9mdus4b","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpyy9006q6cujrinnp4to"},{"post_id":"cimigpyy5006n6cujg9mdus4b","tag_id":"cimigpyy8006p6cujnhhr28by","_id":"cimigpyya006r6cujsqv51oqm"},{"post_id":"cimigpyyb006s6cujhny2fhya","tag_id":"cimigpyyf006u6cuj6d75mdhe","_id":"cimigpyyf006v6cujtngdiz9b"},{"post_id":"cimigpyyi006x6cujo3mibo7p","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpyyl006z6cuj8xyfdr22"},{"post_id":"cimigpyyn00706cuj58ohd4wl","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpyyr00746cujvk1tti29"},{"post_id":"cimigpyyn00706cuj58ohd4wl","tag_id":"cimigpyyp00726cujsshhubhp","_id":"cimigpyyr00756cujranv9iut"},{"post_id":"cimigpyyn00706cuj58ohd4wl","tag_id":"cimigpyyq00736cujmk7it4tq","_id":"cimigpyys00766cuj6i0048ei"},{"post_id":"cimigpyyt00776cujo0do57cd","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpyz1007b6cuj0o81bxt5"},{"post_id":"cimigpyyt00776cujo0do57cd","tag_id":"cimigpyvq004o6cuj2q1pii3z","_id":"cimigpyz1007c6cujyntqljyo"},{"post_id":"cimigpyyt00776cujo0do57cd","tag_id":"cimigpyvh004e6cuj95qj7sbu","_id":"cimigpyz2007d6cujrbdo8nvw"},{"post_id":"cimigpyyt00776cujo0do57cd","tag_id":"cimigpyyx00796cuj77fev4v1","_id":"cimigpyz2007e6cujjj53xeov"},{"post_id":"cimigpyyt00776cujo0do57cd","tag_id":"cimigpyyz007a6cujigrw6m5y","_id":"cimigpyz3007f6cujdqfkeuvk"},{"post_id":"cimigpyz4007g6cujgdtrbcmb","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpyz7007k6cuj3kkfvhbp"},{"post_id":"cimigpyz4007g6cujgdtrbcmb","tag_id":"cimigpyz6007i6cujh6249a03","_id":"cimigpyz8007l6cuj56ed5pl5"},{"post_id":"cimigpyz4007g6cujgdtrbcmb","tag_id":"cimigpyz7007j6cuj6sylv2cs","_id":"cimigpyz8007m6cujoxynvlje"},{"post_id":"cimigpyz9007n6cujp5ohti3n","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpyzb007p6cujecnspaxc"},{"post_id":"cimigpyz9007n6cujp5ohti3n","tag_id":"cimigpyz6007i6cujh6249a03","_id":"cimigpyzc007q6cujko94qc8c"},{"post_id":"cimigpyz9007n6cujp5ohti3n","tag_id":"cimigpyz7007j6cuj6sylv2cs","_id":"cimigpyzc007r6cujrhy9ui0x"},{"post_id":"cimigpyzf007s6cujmmlyts1a","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpyzk007v6cujtwkhzpay"},{"post_id":"cimigpyzf007s6cujmmlyts1a","tag_id":"cimigpyyq00736cujmk7it4tq","_id":"cimigpyzl007w6cujdypr99yo"},{"post_id":"cimigpyzf007s6cujmmlyts1a","tag_id":"cimigpyzj007u6cuj15nlcx1k","_id":"cimigpyzl007x6cujlu3flk26"},{"post_id":"cimigpyzo007y6cuj1xfeu6yc","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpyzr00806cujj922xa3h"},{"post_id":"cimigpyzo007y6cuj1xfeu6yc","tag_id":"cimigpyvh004e6cuj95qj7sbu","_id":"cimigpyzr00816cujox3otmlw"},{"post_id":"cimigpyzo007y6cuj1xfeu6yc","tag_id":"cimigpyy1006j6cuju95xovxi","_id":"cimigpyzr00826cuju3v709ap"},{"post_id":"cimigpyzu00836cuja3ego36g","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpz0100876cuj5rkeki54"},{"post_id":"cimigpyzu00836cuja3ego36g","tag_id":"cimigpyvh004e6cuj95qj7sbu","_id":"cimigpz0100886cujf97rnkof"},{"post_id":"cimigpyzu00836cuja3ego36g","tag_id":"cimigpyzz00856cuj7hxy4g72","_id":"cimigpz0100896cujudjil0u8"},{"post_id":"cimigpyzu00836cuja3ego36g","tag_id":"cimigpz0000866cujj4ji4fvo","_id":"cimigpz02008a6cuj3pedtvbi"},{"post_id":"cimigpz03008b6cujcrftv7r6","tag_id":"cimigpz05008d6cujoiw9mh5x","_id":"cimigpz06008e6cujtpvotn1b"},{"post_id":"cimigpz03008b6cujcrftv7r6","tag_id":"cimigpyur003j6cujdcu2lnxp","_id":"cimigpz07008f6cujq8hs4vpj"},{"post_id":"cimigpz08008g6cujjwuzehkx","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpz0a008h6cuj4st3h3nk"},{"post_id":"cimigpz08008g6cujjwuzehkx","tag_id":"cimigpyvh004e6cuj95qj7sbu","_id":"cimigpz0a008i6cujdq8nhxmr"},{"post_id":"cimigpz0d008j6cuj5b49oxml","tag_id":"cimigpywv005l6cujfn9bk75g","_id":"cimigpz0g008l6cujesu8too7"},{"post_id":"cimigpz0d008j6cuj5b49oxml","tag_id":"cimigpyxa005y6cuj2bg5jqwv","_id":"cimigpz0h008m6cujr7all4ve"},{"post_id":"cimigpz0d008j6cuj5b49oxml","tag_id":"cimigpyww005o6cujkec1rek6","_id":"cimigpz0h008n6cujyi3f38gu"},{"post_id":"cimigpz0i008o6cuj9e4zcsgq","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpz0l008r6cujlxzwpdne"},{"post_id":"cimigpz0i008o6cuj9e4zcsgq","tag_id":"cimigpz0k008q6cuj5mf4w8pt","_id":"cimigpz0m008s6cuj3zjz6fvq"},{"post_id":"cimigpz0i008o6cuj9e4zcsgq","tag_id":"cimigpyyq00736cujmk7it4tq","_id":"cimigpz0m008t6cuj8nrpphgv"},{"post_id":"cimigpz0n008u6cujtjuu313e","tag_id":"cimigpyur003j6cujdcu2lnxp","_id":"cimigpz0q008w6cujmiyta1c7"},{"post_id":"cimigpz0r008x6cujudpkpjsu","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpz0w00916cuj9pz3ixuz"},{"post_id":"cimigpz0r008x6cujudpkpjsu","tag_id":"cimigpz0t008z6cujym16eygk","_id":"cimigpz0w00926cujx6jys3av"},{"post_id":"cimigpz0r008x6cujudpkpjsu","tag_id":"cimigpz0v00906cuj30s8nak1","_id":"cimigpz0w00936cuj12v53tyr"},{"post_id":"cimigpz0y00946cuj30auvacu","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpz1200986cuj3bheq1j8"},{"post_id":"cimigpz0y00946cuj30auvacu","tag_id":"cimigpz1100966cuj73quxami","_id":"cimigpz1300996cujsab4of4i"},{"post_id":"cimigpz0y00946cuj30auvacu","tag_id":"cimigpz1200976cujuif48zx1","_id":"cimigpz13009a6cujc05e1q62"},{"post_id":"cimigpz15009b6cujfpi09dar","tag_id":"cimigpyy1006j6cuju95xovxi","_id":"cimigpz19009e6cujwciw6ofr"},{"post_id":"cimigpz15009b6cujfpi09dar","tag_id":"cimigpyur003j6cujdcu2lnxp","_id":"cimigpz19009f6cuj6vgvz333"},{"post_id":"cimigpz15009b6cujfpi09dar","tag_id":"cimigpz18009d6cujb4lcb0m3","_id":"cimigpz1a009g6cujt7pvyl1p"},{"post_id":"cimigpz1d009h6cujp3k70b0s","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpz1g009k6cujoll3ejny"},{"post_id":"cimigpz1d009h6cujp3k70b0s","tag_id":"cimigpyur003j6cujdcu2lnxp","_id":"cimigpz1g009l6cujg27nd4ci"},{"post_id":"cimigpz1d009h6cujp3k70b0s","tag_id":"cimigpz1f009j6cujaeb3era0","_id":"cimigpz1h009m6cujtyf57ask"},{"post_id":"cimigpz1i009n6cuj8red0nje","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpz1m009r6cujp44v1j70"},{"post_id":"cimigpz1i009n6cuj8red0nje","tag_id":"cimigpz1k009p6cujbvbr7e3h","_id":"cimigpz1m009s6cuje3wn1m6d"},{"post_id":"cimigpz1i009n6cuj8red0nje","tag_id":"cimigpz1l009q6cujo09trw9e","_id":"cimigpz1n009t6cuj4orphtvb"},{"post_id":"cimigpz1o009u6cuj3msd00b0","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpz1s009x6cuj3idhte9j"},{"post_id":"cimigpz1o009u6cuj3msd00b0","tag_id":"cimigpz1q009w6cujdvjxh27o","_id":"cimigpz1t009y6cuj08ufv12n"},{"post_id":"cimigpz1v009z6cuj7bzbzbj3","tag_id":"cimigpyyf006u6cuj6d75mdhe","_id":"cimigpz2000a36cujj3ven3m1"},{"post_id":"cimigpz1v009z6cuj7bzbzbj3","tag_id":"cimigpz1z00a16cujw0i4t33s","_id":"cimigpz2100a46cuj8y8ic1uy"},{"post_id":"cimigpz1v009z6cuj7bzbzbj3","tag_id":"cimigpz2000a26cujowzd48dj","_id":"cimigpz2100a56cuj6otzlyuk"},{"post_id":"cimigpz2200a66cujhvgxjgp2","tag_id":"cimigpz2400a86cujv4vqthos","_id":"cimigpz2500a96cujggohkuqx"},{"post_id":"cimigpz2800ab6cuj82no2lv5","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cimigpz2b00ae6cujfkekkofr"},{"post_id":"cimigpz2800ab6cuj82no2lv5","tag_id":"cimigpz2a00ad6cujet7ry3ge","_id":"cimigpz2b00af6cuj5ypqcmjg"},{"post_id":"cimigpz2d00ag6cujt8xgsmar","tag_id":"cimigpz2g00ai6cujlv7xkvw3","_id":"cimigpz2j00ak6cujaplfnj27"},{"post_id":"cimigpz2d00ag6cujt8xgsmar","tag_id":"cimigpyvz004v6cuj17ui6rq3","_id":"cimigpz2j00al6cuj8247j0hm"},{"post_id":"cimigpz2d00ag6cujt8xgsmar","tag_id":"cimigpz2i00aj6cujbx28iv71","_id":"cimigpz2j00am6cujzq6vkl1m"},{"post_id":"cimigpz2k00an6cujn58oehkv","tag_id":"cimigpz2n00ap6cujh8jp7xy7","_id":"cimigpz2q00as6cujmpl7mq7z"},{"post_id":"cimigpz2k00an6cujn58oehkv","tag_id":"cimigpyvz004v6cuj17ui6rq3","_id":"cimigpz2r00at6cujigl7bw88"},{"post_id":"cimigpz2k00an6cujn58oehkv","tag_id":"cimigpz2o00aq6cujnb9ucg6s","_id":"cimigpz2r00au6cujslx38kx0"},{"post_id":"cimigpz2k00an6cujn58oehkv","tag_id":"cimigpz2p00ar6cuj5yj1rzqh","_id":"cimigpz2r00av6cujq8rolhyv"},{"post_id":"cimigpz2t00aw6cujj5y41v9s","tag_id":"cimigpyvz004v6cuj17ui6rq3","_id":"cimigpz2y00b06cuj2ywwgbro"},{"post_id":"cimigpz2t00aw6cujj5y41v9s","tag_id":"cimigpz2o00aq6cujnb9ucg6s","_id":"cimigpz2z00b16cuj84b2f6or"},{"post_id":"cimigpz2t00aw6cujj5y41v9s","tag_id":"cimigpz2p00ar6cuj5yj1rzqh","_id":"cimigpz3000b26cujvau2s2ad"},{"post_id":"cimigpz2t00aw6cujj5y41v9s","tag_id":"cimigpz2w00ay6cujviyudost","_id":"cimigpz3000b36cujsmugguxt"},{"post_id":"cimigpz2t00aw6cujj5y41v9s","tag_id":"cimigpz2x00az6cuj97gfh0im","_id":"cimigpz3000b46cujlrluixcu"},{"post_id":"cimigpz3100b56cujrk86uria","tag_id":"cimigpyvz004v6cuj17ui6rq3","_id":"cimigpz3700b96cujy09cn6cp"},{"post_id":"cimigpz3100b56cujrk86uria","tag_id":"cimigpz2o00aq6cujnb9ucg6s","_id":"cimigpz3800ba6cuj4c8gvysc"},{"post_id":"cimigpz3100b56cujrk86uria","tag_id":"cimigpz2p00ar6cuj5yj1rzqh","_id":"cimigpz3800bb6cujcn6x7qo4"},{"post_id":"cimigpz3100b56cujrk86uria","tag_id":"cimigpz3500b76cujva32bl1p","_id":"cimigpz3900bc6cuj06aag3h6"},{"post_id":"cimigpz3100b56cujrk86uria","tag_id":"cimigpz3600b86cujcwmerzeh","_id":"cimigpz3900bd6cuj3iuoi13y"},{"post_id":"cimigpz3b00be6cuj53aaa1qt","tag_id":"cimigpz2p00ar6cuj5yj1rzqh","_id":"cimigpz3g00bi6cujlwp32k7u"},{"post_id":"cimigpz3b00be6cuj53aaa1qt","tag_id":"cimigpyvz004v6cuj17ui6rq3","_id":"cimigpz3g00bj6cujbplp9k5f"},{"post_id":"cimigpz3b00be6cuj53aaa1qt","tag_id":"cimigpz2o00aq6cujnb9ucg6s","_id":"cimigpz3g00bk6cujgn17xdv1"},{"post_id":"cimigpz3b00be6cuj53aaa1qt","tag_id":"cimigpz3e00bg6cujhu44fmas","_id":"cimigpz3h00bl6cujncgf9swn"},{"post_id":"cimigpz3b00be6cuj53aaa1qt","tag_id":"cimigpz3f00bh6cuj7rdp2cy9","_id":"cimigpz3h00bm6cujsj19sjca"},{"post_id":"cimigpz3i00bn6cuj4bmtkbwr","tag_id":"cimigpyur003j6cujdcu2lnxp","_id":"cimigpz3n00bp6cuj3vlb6czt"},{"post_id":"cimigpz3p00bq6cujj4qcnb9m","tag_id":"cimigpz3r00bs6cujdb5mt1bb","_id":"cimigpz3t00bv6cujgpvg9a3g"},{"post_id":"cimigpz3p00bq6cujj4qcnb9m","tag_id":"cimigpz3s00bt6cujgb7nmbzz","_id":"cimigpz3u00bw6cujkv8j15z0"},{"post_id":"cinrllkq5000gw8uj02u31fqc","tag_id":"cimigpz2n00ap6cujh8jp7xy7","_id":"cinrllkq8000iw8ujh2j0oukh"},{"post_id":"cinrllkq5000gw8uj02u31fqc","tag_id":"cimigpyvz004v6cuj17ui6rq3","_id":"cinrllkq9000jw8uj0adkantu"},{"post_id":"cinrllkq5000gw8uj02u31fqc","tag_id":"cimigpz2o00aq6cujnb9ucg6s","_id":"cinrllkq9000kw8ujozx6ipfs"},{"post_id":"cinrllkq5000gw8uj02u31fqc","tag_id":"cimigpz2p00ar6cuj5yj1rzqh","_id":"cinrllkqa000lw8uj9ed6tk0u"},{"post_id":"cinxb4jv80000q0uj81jkiu0d","tag_id":"cimigpyur003j6cujdcu2lnxp","_id":"cinxb4jxe0003q0ujfa6obyx0"},{"post_id":"cinxb4jv80000q0uj81jkiu0d","tag_id":"cinxb4jvo0002q0ujtv4kmh72","_id":"cinxb4jxe0004q0ujouebgiyz"},{"post_id":"cio1mmulg0000k4ujpdzz53si","tag_id":"cimigpytw002l6cujiidsjgjs","_id":"cio1mmum10002k4ujhqnrq6wu"},{"post_id":"cio1mmulg0000k4ujpdzz53si","tag_id":"cinxbosx90002zsuj29mhyqw5","_id":"cio1mmum20003k4ujqjtflgkg"},{"post_id":"cio1mmulg0000k4ujpdzz53si","tag_id":"cinxbto730001xoujvnq2kgha","_id":"cio1mmum30004k4uj0m5964gl"},{"post_id":"cio1mmulg0000k4ujpdzz53si","tag_id":"cinxbosy40004zsujnda1phj3","_id":"cio1mmum40005k4ujbzo87pyo"}],"Tag":[{"name":"Machine Learning","_id":"cimigpytw002l6cujiidsjgjs"},{"name":"损失函数","_id":"cimigpytz002m6cujh7x4py7z"},{"name":"ROC","_id":"cimigpyu4002s6cujjj2ivgf6"},{"name":"AUC","_id":"cimigpyu5002t6cujpxk4yk8i"},{"name":"PCA","_id":"cimigpyua002z6cujdbu1jyqo"},{"name":"主成分分析","_id":"cimigpyud00306cujyf64tc2z"},{"name":"算法选择","_id":"cimigpyui00366cuj6i4n20nf"},{"name":"偏差","_id":"cimigpyuj00376cuj64twd25a"},{"name":"方差","_id":"cimigpyuj00386cujt0afya7o"},{"name":"LR","_id":"cimigpyuk00396cujwek631mr"},{"name":"MNIST","_id":"cimigpyuq003h6cujd8425hwp"},{"name":"dataset","_id":"cimigpyuq003i6cujajdizz6h"},{"name":"Python","_id":"cimigpyur003j6cujdcu2lnxp"},{"name":"编码规范","_id":"cimigpyuz003p6cujjjnm6byo"},{"name":"牛顿方法","_id":"cimigpyv5003y6cujjc85b4y9"},{"name":"指数分布族","_id":"cimigpyv6003z6cujax72xvfq"},{"name":"GLM","_id":"cimigpyv700406cujh8av4on7"},{"name":"数据提取","_id":"cimigpyvc00476cuj0g3tzuwp"},{"name":"正则表达式","_id":"cimigpyvd00486cuj2epin3dz"},{"name":"译文","_id":"cimigpyvh004e6cuj95qj7sbu"},{"name":"总结","_id":"cimigpyvl004j6cujwr7show2"},{"name":"框架&库","_id":"cimigpyvq004o6cuj2q1pii3z"},{"name":"LeetCode","_id":"cimigpyvy004u6cuj8kqo4lbs"},{"name":"数据结构","_id":"cimigpyvz004v6cuj17ui6rq3"},{"name":"EM","_id":"cimigpywg00576cuj00xwdb1k"},{"name":"Data Science","_id":"cimigpywl005c6cuj0s3q9x3p"},{"name":"BioInfo","_id":"cimigpywv005l6cujfn9bk75g"},{"name":"DSSP","_id":"cimigpyww005m6cujh2lsq0xy"},{"name":"预处理","_id":"cimigpyww005o6cujkec1rek6"},{"name":"PDB","_id":"cimigpyxa005y6cuj2bg5jqwv"},{"name":"normalization","_id":"cimigpyxh00636cuj0jyzcedl"},{"name":"标准化","_id":"cimigpyxj00646cujm6psigch"},{"name":"RegEx","_id":"cimigpyxv006d6cuj7fo25mw9"},{"name":"scikit-learn","_id":"cimigpyy1006j6cuju95xovxi"},{"name":"特征工程","_id":"cimigpyy8006p6cujnhhr28by"},{"name":"GitHub","_id":"cimigpyyf006u6cuj6d75mdhe"},{"name":"GBDT","_id":"cimigpyyp00726cujsshhubhp"},{"name":"组合算法","_id":"cimigpyyq00736cujmk7it4tq"},{"name":"Theano","_id":"cimigpyyx00796cuj77fev4v1"},{"name":"Lasagne","_id":"cimigpyyz007a6cujigrw6m5y"},{"name":"交叉验证","_id":"cimigpyz6007i6cujh6249a03"},{"name":"Cross-Validation","_id":"cimigpyz7007j6cuj6sylv2cs"},{"name":"ensemble","_id":"cimigpyzj007u6cuj15nlcx1k"},{"name":"Precision","_id":"cimigpyzz00856cuj7hxy4g72"},{"name":"Recall","_id":"cimigpz0000866cujj4ji4fvo"},{"name":"计时器","_id":"cimigpz05008d6cujoiw9mh5x"},{"name":"Adaboost","_id":"cimigpz0k008q6cuj5mf4w8pt"},{"name":"Apriori","_id":"cimigpz0t008z6cujym16eygk"},{"name":"关联分析","_id":"cimigpz0v00906cuj30s8nak1"},{"name":"K-Means","_id":"cimigpz1100966cuj73quxami"},{"name":"聚类","_id":"cimigpz1200976cujuif48zx1"},{"name":"持久化","_id":"cimigpz18009d6cujb4lcb0m3"},{"name":"Naive Bayes","_id":"cimigpz1f009j6cujaeb3era0"},{"name":"KNN","_id":"cimigpz1k009p6cujbvbr7e3h"},{"name":"最近邻","_id":"cimigpz1l009q6cujo09trw9e"},{"name":"Decision Tree","_id":"cimigpz1q009w6cujdvjxh27o"},{"name":"fork","_id":"cimigpz1z00a16cujw0i4t33s"},{"name":"同步","_id":"cimigpz2000a26cujowzd48dj"},{"name":"SublimeLinter","_id":"cimigpz2400a86cujv4vqthos"},{"name":"汇总","_id":"cimigpz2a00ad6cujet7ry3ge"},{"name":"字符串匹配","_id":"cimigpz2g00ai6cujlv7xkvw3"},{"name":"笔试","_id":"cimigpz2i00aj6cujbx28iv71"},{"name":"归并","_id":"cimigpz2n00ap6cujh8jp7xy7"},{"name":"排序","_id":"cimigpz2o00aq6cujnb9ucg6s"},{"name":"C++","_id":"cimigpz2p00ar6cuj5yj1rzqh"},{"name":"冒泡排序","_id":"cimigpz2w00ay6cujviyudost"},{"name":"快速排序","_id":"cimigpz2x00az6cuj97gfh0im"},{"name":"直接选择排序","_id":"cimigpz3500b76cujva32bl1p"},{"name":"堆排序","_id":"cimigpz3600b86cujcwmerzeh"},{"name":"希尔排序","_id":"cimigpz3e00bg6cujhu44fmas"},{"name":"插入排序","_id":"cimigpz3f00bh6cuj7rdp2cy9"},{"name":"Linux","_id":"cimigpz3r00bs6cujdb5mt1bb"},{"name":"Shell","_id":"cimigpz3s00bt6cujgb7nmbzz"},{"name":"pip","_id":"cinxb4jvo0002q0ujtv4kmh72"},{"name":"mRMR","_id":"cinxbosx90002zsuj29mhyqw5"},{"name":"Feature Selection","_id":"cinxbosy40003zsuj0qdjxvy1"},{"name":"Random Forest","_id":"cinxbosy40004zsujnda1phj3"},{"name":"特征选择","_id":"cinxbto730001xoujvnq2kgha"}]}}