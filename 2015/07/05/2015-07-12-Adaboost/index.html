<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>机器学习算法-Adaboost | 刘帝伟-技术博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="本章内容

组合相似的分类器来提高分类性能
应用AdaBoost算法
处理非均衡分类问题

主题：利用AdaBoost元算法提高分类性能">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习算法-Adaboost">
<meta property="og:url" content="http://csuldw.github.io/2015/07/05/2015-07-12-Adaboost/index.html">
<meta property="og:site_name" content="刘帝伟-技术博客">
<meta property="og:description" content="本章内容

组合相似的分类器来提高分类性能
应用AdaBoost算法
处理非均衡分类问题

主题：利用AdaBoost元算法提高分类性能">
<meta property="og:updated_time" content="2015-07-23T02:29:24.423Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习算法-Adaboost">
<meta name="twitter:description" content="本章内容

组合相似的分类器来提高分类性能
应用AdaBoost算法
处理非均衡分类问题

主题：利用AdaBoost元算法提高分类性能">
  
    <link rel="alternative" href="/atom.xml" title="刘帝伟-技术博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  <script>
  var _hmt = _hmt || [];
  (function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?0b8e8ee87e4708173f00d9048c309301";
    var s = document.getElementsByTagName("script")[0]; 
    s.parentNode.insertBefore(hm, s);
  })();
  </script>
</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img src="/assets/blogImg/devin.png" class="js-avatar" style="width: 100%;height: 100%;opacity: 1;">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">刘帝伟</a></h1>
		</hgroup>

		
		<p class="header-subtitle">爱上一匹野马，可我的家里没有草原。</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/csuldw" title="github">github</a>
					        
								<a class="weibo" target="_blank" href="http://weibo.com/liudiwei210" title="weibo">weibo</a>
					        
								<a class="rss" target="_blank" href="/atom.xml" title="rss">rss</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/BioInfo-Python/" style="font-size: 10px;">BioInfo Python</a> <a href="/tags/Machine-Learning-Python/" style="font-size: 15px;">Machine-Learning Python</a> <a href="/tags/Machine-Learning-python/" style="font-size: 20px;">Machine-Learning python</a> <a href="/tags/SublimeLinter/" style="font-size: 10px;">SublimeLinter</a> <a href="/tags/machine-learning/" style="font-size: 10px;">machine-learning</a> <a href="/tags/machine-learning-CV-AI/" style="font-size: 10px;">machine-learning CV AI</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">中南大学在读硕士，关注机器学习，数据挖掘和生物信息</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">刘帝伟</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="/assets/blogImg/devin.png" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">刘帝伟</h1>
			</hgroup>
			
			<p class="header-subtitle">爱上一匹野马，可我的家里没有草原。</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/csuldw" title="github">github</a>
			        
						<a class="weibo" target="_blank" href="http://weibo.com/liudiwei210" title="weibo">weibo</a>
			        
						<a class="rss" target="_blank" href="/atom.xml" title="rss">rss</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-2015-07-12-Adaboost" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/07/05/2015-07-12-Adaboost/" class="article-date">
  	<time datetime="2015-07-05T14:53:12.000Z" itemprop="datePublished">Jul 5</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      机器学习算法-Adaboost
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning-Python/">Machine-Learning Python</a></li></ul>
	</div>

        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Machine-Learning/">Machine-Learning</a>
	</div>


        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>本章内容</strong></p>
<ul>
<li>组合相似的分类器来提高分类性能</li>
<li>应用AdaBoost算法</li>
<li>处理非均衡分类问题</li>
</ul>
<p><strong>主题：</strong>利用AdaBoost元算法提高分类性能</p>
<a id="more"></a>
<h3 id="1-基于数据集多重抽样的分类器">1.基于数据集多重抽样的分类器</h3><table>
<thead>
<tr>
<th>Feature</th>
<th>AdaBoost</th>
</tr>
</thead>
<tbody>
<tr>
<td>优点</td>
<td>泛化错误率低，易编码，可以应用在大部分分类器上，无需参数调整</td>
</tr>
<tr>
<td>缺点</td>
<td>对离群点敏感</td>
</tr>
<tr>
<td>数据</td>
<td>数值型和标称型数据</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>bagging:基于数据随机重抽样的分类器构建方法</p>
<p>自举汇聚法(bootstrap aggregating),也称为bagging方法，是从原始数据集选择S次后得到S个新数据集的一种技术。新数据集和原始数据集的大小相等。每个数据集都是通过在原始数据集中随机选择一个本来进行替换而得到的。</p>
<p>在S个数据集建好之后，将某个学习算法分别作用域每个数据集得到了S个分类器。当我们对新数据进行分类时，就可以应用S个分类器进行分类。与此同时，选择分类器投票结果最多的类别作为最后的分类结果。</p>
<p>有一些比较先进的bagging方法，如<strong>随机森林</strong>（RF）。</p>
<p>boosting是一种与bagging很类似的技术。不论是boosting还是bagging当中，当使用的多个分类器的类型都是一致的。但是在前者当中，不同的分类器是通过串行训练而获得的，每个新分类器都根据已训练出的分类器的性能来进行训练。boosting是通过训练集中关注被已有分类器错分的那些数据来获得新的分类器。</p>
<p>boosting方法有多个版本，当前最流行便属于<strong>AdaBoost</strong>。</p>
<p><strong>AdaBoost的一般流程</strong></p>
<p>（1）收集数据：可以使用任何方法；<br><br>（2）准备数据：依赖于所使用的若分类器类型；<br><br>（3）分析数据：可以使用任意方法<br><br>（4）训练算法：AdaBoost的大部分时间都用在训练上，分类器将多次在同一数据集上训练若分类器；<br><br>（5）测试算法：计算分类的错误率；<br><br>（6）使用算法：同SVM一样，AdaBoost预测的两个类别中的一个，如果想要把它应用到多个类的场合，那么就像多类SVM中的做法一样对AdaBoost进行修改。</p>
<h3 id="2-训练算法：基于错误提升分类器的性能">2.训练算法：基于错误提升分类器的性能</h3><p>AdaBoost是adaptive boosting（自适应boosting）的缩写，其运行过程：训练集中的每个样本，赋予其一个权重，这些权重构成向量D。一开始，这些权重都初试化成相等值。首先在训练数据上训练处一个若分类器并计算该分类器的错误率，然后在同一数据集上再次训练若分类器。在分类器的第二次训练当中，将会重新调整每个样本的权重，其中第一次分队的样本的权重值将会降低，而第一次分错的样本的权重将会提高。为了从所有分类器中得到最终的分类结果，AdaBoost为每个分类器都分配了一个权重值alpha，这些alpha值是基于每个分类器的错误率进行计算的。其中错误率定义为</p>
<p>$$\epsilon=\dfrac{为正确分类的样本数目}{所有样本数目}$$</p>
<p>alpha计算公式</p>
<p>$$\alpha=\dfrac{1}{2}ln(\dfrac{1-\epsilon}{\epsilon})$$</p>
<p>计算出alpha值之后，可以对权重向量D进行更新，使得正确分类的样本的权重值降低而分错的样本权重值升高，D的计算方法如下<br>如果某个样本被正确分类，更新该样本权重值为：</p>
<p>$$D^{(t+1)}_i=\dfrac{D_i^{(t)} e^{-\alpha}}{Sum(D)}$$</p>
<p>如果某个样本被错误分类，更新该样本的权重值为：</p>
<p>$$D^{(t+1)}_i=\dfrac{D_i^{(t)} e^{\alpha}}{Sum(D)}$$</p>
<p>计算出D后，AdaBoost接着开始下一轮的迭代。AdaBoost算法会不断地重复训练和调整权重的过程，知道训练错误率为0或者若分类器的数目达到用户指定值为止。</p>
<p>在建立完整的AdaBoost算法之前，需要通过一些代码建立若分类器及保存数据集的权重。</p>
<h3 id="3-基于单层决策树构建若分类器">3.基于单层决策树构建若分类器</h3><p>单层决策树是一种简单的决策树。首先构建一个简单的数据集,建立一个adaboost.py文件并加入下列代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadSimpData</span><span class="params">()</span>:</span></span><br><span class="line">    datMat = matrix([[ <span class="number">1.</span> ,  <span class="number">2.1</span>],</span><br><span class="line">        [ <span class="number">2.</span> ,  <span class="number">1.1</span>],</span><br><span class="line">        [ <span class="number">1.3</span>,  <span class="number">1.</span> ],</span><br><span class="line">        [ <span class="number">1.</span> ,  <span class="number">1.</span> ],</span><br><span class="line">        [ <span class="number">2.</span> ,  <span class="number">1.</span> ]])</span><br><span class="line">    classLabels = [<span class="number">1.0</span>, <span class="number">1.0</span>, -<span class="number">1.0</span>, -<span class="number">1.0</span>, <span class="number">1.0</span>]</span><br><span class="line">    <span class="keyword">return</span> datMat,classLabels</span><br></pre></td></tr></table></figure>
<p>导入数据</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="prompt">&gt;&gt;</span>&gt; import adaboost</span><br><span class="line"><span class="prompt">&gt;&gt;</span>&gt; datMat,classLabels=adaboost.loadSimpData()</span><br></pre></td></tr></table></figure>
<p>下面两个函数，一个用于测试是否某个值小于或者大于我们正在测试的阈值，一个会在一个加权数据集中循环，并找到具有最低错误率的单层决策树。</p>
<p>伪代码如下：<br></p>
<pre><code>将最小错误率<span class="keyword">min</span>Error设为无穷大
对数据及中的每一个特征（第一层循环）：
    对每个步长（第二层循环）：
        对每个不等号（第三层循环）：
            建立一颗单层决策树并利用加权数据集对它进行测试
            如果错误率低于<span class="keyword">min</span>Error，则将当前单层决策树设置为最佳单层决策树
返回最佳单层决策树
</code></pre><p>单层决策树生成函数代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stumpClassify</span><span class="params">(dataMatrix,dimen,threshVal,threshIneq)</span>:</span><span class="comment">#just classify the data</span></span><br><span class="line">    retArray = ones((shape(dataMatrix)[<span class="number">0</span>],<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">if</span> threshIneq == <span class="string">'lt'</span>:</span><br><span class="line">        retArray[dataMatrix[:,dimen] &lt;= threshVal] = -<span class="number">1.0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        retArray[dataMatrix[:,dimen] &gt; threshVal] = -<span class="number">1.0</span></span><br><span class="line">    <span class="keyword">return</span> retArray</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">buildStump</span><span class="params">(dataArr,classLabels,D)</span>:</span></span><br><span class="line">    dataMatrix = mat(dataArr); labelMat = mat(classLabels).T</span><br><span class="line">    m,n = shape(dataMatrix)</span><br><span class="line">    numSteps = <span class="number">10.0</span>; bestStump = &#123;&#125;; bestClasEst = mat(zeros((m,<span class="number">1</span>)))</span><br><span class="line">    minError = inf <span class="comment">#init error sum, to +infinity</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):<span class="comment">#loop over all dimensions</span></span><br><span class="line">        rangeMin = dataMatrix[:,i].min(); rangeMax = dataMatrix[:,i].max();</span><br><span class="line">        stepSize = (rangeMax-rangeMin)/numSteps</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(-<span class="number">1</span>,int(numSteps)+<span class="number">1</span>):<span class="comment">#loop over all range in current dimension</span></span><br><span class="line">            <span class="keyword">for</span> inequal <span class="keyword">in</span> [<span class="string">'lt'</span>, <span class="string">'gt'</span>]: <span class="comment">#go over less than and greater than</span></span><br><span class="line">                threshVal = (rangeMin + float(j) * stepSize)</span><br><span class="line">                predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)<span class="comment">#call stump classify with i, j, lessThan</span></span><br><span class="line">                errArr = mat(ones((m,<span class="number">1</span>)))</span><br><span class="line">                errArr[predictedVals == labelMat] = <span class="number">0</span></span><br><span class="line">                weightedError = D.T*errArr  <span class="comment">#calc total error multiplied by D</span></span><br><span class="line">                <span class="comment">#print "split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f" % (i, threshVal, inequal, weightedError)</span></span><br><span class="line">                <span class="keyword">if</span> weightedError &lt; minError:</span><br><span class="line">                    minError = weightedError</span><br><span class="line">                    bestClasEst = predictedVals.copy()</span><br><span class="line">                    bestStump[<span class="string">'dim'</span>] = i</span><br><span class="line">                    bestStump[<span class="string">'thresh'</span>] = threshVal</span><br><span class="line">                    bestStump[<span class="string">'ineq'</span>] = inequal</span><br><span class="line">    <span class="keyword">return</span> bestStump,minError,bestClasEst</span><br></pre></td></tr></table></figure>
<h3 id="4-AdaBoost算法的实现">4.AdaBoost算法的实现</h3><p>整个实现的伪代码如下：</p>
<pre><code>对每次迭代：
    利用<span class="function"><span class="title">buildStump</span><span class="params">()</span></span>函数找到最佳的单层决策树
    将最佳单层决策树加入到单层决策树数据中
    计算alpha
    计算心的权重向量D
    更新累计类别估计值
    如果错误率低于<span class="number">0.0</span> 则退出循环
</code></pre><p>基于单层决策树的AdaBoost训练过程</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">adaBoostTrainDS</span><span class="params">(dataArr,classLabels,numIt=<span class="number">40</span>)</span>:</span></span><br><span class="line">    weakClassArr = []</span><br><span class="line">    m = shape(dataArr)[<span class="number">0</span>]</span><br><span class="line">    D = mat(ones((m,<span class="number">1</span>))/m)   <span class="comment">#init D to all equal</span></span><br><span class="line">    aggClassEst = mat(zeros((m,<span class="number">1</span>)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numIt):</span><br><span class="line">        bestStump,error,classEst = buildStump(dataArr,classLabels,D)<span class="comment">#build Stump</span></span><br><span class="line">        <span class="comment">#print "D:",D.T</span></span><br><span class="line">        alpha = float(<span class="number">0.5</span>*log((<span class="number">1.0</span>-error)/max(error,<span class="number">1e-16</span>)))<span class="comment">#calc alpha, throw in max(error,eps) to account for error=0</span></span><br><span class="line">        bestStump[<span class="string">'alpha'</span>] = alpha  </span><br><span class="line">        weakClassArr.append(bestStump)                  <span class="comment">#store Stump Params in Array</span></span><br><span class="line">        <span class="comment">#print "classEst: ",classEst.T</span></span><br><span class="line">        expon = multiply(-<span class="number">1</span>*alpha*mat(classLabels).T,classEst) <span class="comment">#exponent for D calc, getting messy</span></span><br><span class="line">        D = multiply(D,exp(expon))                              <span class="comment">#Calc New D for next iteration</span></span><br><span class="line">        D = D/D.sum()</span><br><span class="line">        <span class="comment">#calc training error of all classifiers, if this is 0 quit for loop early (use break)</span></span><br><span class="line">        aggClassEst += alpha*classEst</span><br><span class="line">        <span class="comment">#print "aggClassEst: ",aggClassEst.T</span></span><br><span class="line">        aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T,ones((m,<span class="number">1</span>)))</span><br><span class="line">        errorRate = aggErrors.sum()/m</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"total error: "</span>,errorRate</span><br><span class="line">        <span class="keyword">if</span> errorRate == <span class="number">0.0</span>: <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> weakClassArr,aggClassEst</span><br></pre></td></tr></table></figure>
<h3 id="5-测试算法">5.测试算法</h3><p>拥有了多个若分类器以及其对应的alpha值，进行测试就方便了。</p>
<p>AdaBoost分类函数:利用训练处的多个若分类器进行分类的函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">adaClassify</span><span class="params">(datToClass,classifierArr)</span>:</span></span><br><span class="line">    dataMatrix = mat(datToClass)<span class="comment">#do stuff similar to last aggClassEst in adaBoostTrainDS</span></span><br><span class="line">    m = shape(dataMatrix)[<span class="number">0</span>]</span><br><span class="line">    aggClassEst = mat(zeros((m,<span class="number">1</span>)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(classifierArr)):</span><br><span class="line">        classEst = stumpClassify(dataMatrix,classifierArr[i][<span class="string">'dim'</span>],\</span><br><span class="line">                                 classifierArr[i][<span class="string">'thresh'</span>],\</span><br><span class="line">                                 classifierArr[i][<span class="string">'ineq'</span>])<span class="comment">#call stump classify</span></span><br><span class="line">        aggClassEst += classifierArr[i][<span class="string">'alpha'</span>]*classEst</span><br><span class="line">        <span class="keyword">print</span> aggClassEst</span><br><span class="line">    <span class="keyword">return</span> sign(aggClassEst)</span><br></pre></td></tr></table></figure>
<h3 id="6-绘制ROC曲线">6.绘制ROC曲线</h3><p>ROC曲线绘制代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotROC</span><span class="params">(predStrengths, classLabels)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">    cur = (<span class="number">1.0</span>,<span class="number">1.0</span>) <span class="comment">#cursor</span></span><br><span class="line">    ySum = <span class="number">0.0</span> <span class="comment">#variable to calculate AUC</span></span><br><span class="line">    numPosClas = sum(array(classLabels)==<span class="number">1.0</span>)</span><br><span class="line">    yStep = <span class="number">1</span>/float(numPosClas); xStep = <span class="number">1</span>/float(len(classLabels)-numPosClas)</span><br><span class="line">    sortedIndicies = predStrengths.argsort()<span class="comment">#get sorted index, it's reverse</span></span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    fig.clf()</span><br><span class="line">    ax = plt.subplot(<span class="number">111</span>)</span><br><span class="line">    <span class="comment">#loop through all the values, drawing a line segment at each point</span></span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> sortedIndicies.tolist()[<span class="number">0</span>]:</span><br><span class="line">        <span class="keyword">if</span> classLabels[index] == <span class="number">1.0</span>:</span><br><span class="line">            delX = <span class="number">0</span>; delY = yStep;</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            delX = xStep; delY = <span class="number">0</span>;</span><br><span class="line">            ySum += cur[<span class="number">1</span>]</span><br><span class="line">        <span class="comment">#draw line from cur to (cur[0]-delX,cur[1]-delY)</span></span><br><span class="line">        ax.plot([cur[<span class="number">0</span>],cur[<span class="number">0</span>]-delX],[cur[<span class="number">1</span>],cur[<span class="number">1</span>]-delY], c=<span class="string">'b'</span>)</span><br><span class="line">        cur = (cur[<span class="number">0</span>]-delX,cur[<span class="number">1</span>]-delY)</span><br><span class="line">    ax.plot([<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">1</span>],<span class="string">'b--'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'False positive rate'</span>); plt.ylabel(<span class="string">'True positive rate'</span>)</span><br><span class="line">    plt.title(<span class="string">'ROC curve for AdaBoost horse colic detection system'</span>)</span><br><span class="line">    ax.axis([<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">    plt.show()</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"the Area Under the Curve is: "</span>,ySum*xStep</span><br></pre></td></tr></table></figure>
<h3 id="References">References</h3><p>【1】Machine Learning in Action 机器学习实战 第七章</p>
<hr>
<p><br></p>
<p><center><strong>本栏目Machine Learning持续更新中，欢迎关注：<a href="http://blog.csdn.net/dream_angel_z" target="_blank" rel="external">Dream_Angel_Z博客</a></strong></center><br><br></p>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2015/07/07/2015-07-07-PDB/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          数据预处理-PDB文件
        
      </div>
    </a>
  
  
    <a href="/2015/06/04/2015-06-04-Apriori/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">机器学习算法-Apriori关联分析</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>


<div class="share">
	<!-- JiaThis Button BEGIN -->
	<div class="jiathis_style">
		<span class="jiathis_txt">分享到：</span>
		<a class="jiathis_button_tsina"></a>
		<a class="jiathis_button_cqq"></a>
		<a class="jiathis_button_douban"></a>
		<a class="jiathis_button_weixin"></a>
		<a class="jiathis_button_tumblr"></a>
		<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	</div>
	<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1405949716054953" charset="utf-8"></script>
	<!-- JiaThis Button END -->
</div>



<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="2015-07-12-Adaboost" data-title="机器学习算法-Adaboost" data-url="http://csuldw.github.io/2015/07/05/2015-07-12-Adaboost/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"litten-hexo"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>




</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2015 刘帝伟
    	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: undefined,
		animate: undefined,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: undefined
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>






  </div>
</body>
</html>