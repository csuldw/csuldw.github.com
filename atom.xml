<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>机器学习算法技术分享</title>
  <icon>https://www.gravatar.com/avatar/6323907c99e15f4a7066d2cf4da67518</icon>
  <subtitle>——悄悄是别离的笙箫，沉默是今晚的康桥.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.csuldw.com/"/>
  <updated>2020-08-02T07:30:13.154Z</updated>
  <id>https://www.csuldw.com/</id>
  
  <author>
    <name>刘帝伟</name>
    <email>csu.ldw@csu.edu.cn</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>携手同行观山海，两天一夜外伶仃</title>
    <link href="https://www.csuldw.com/2020/07/31/2020-07-31-the-travel-diary/"/>
    <id>https://www.csuldw.com/2020/07/31/2020-07-31-the-travel-diary/</id>
    <published>2020-07-31T15:44:00.000Z</published>
    <updated>2020-08-02T07:30:13.154Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><img src="/assets/articleImg/2020/20200801-1.png" width="100%"><p>距离海岛之行已经过去近二十天了，就在清理手机存储空间的时候，忽然翻到了相册里的照片，这才决定开始整理这篇海岛游记。此次前往的外伶仃岛，也是期待许久的海岛之一，可能是因为沉寂太久了吧。早在去年的端午节，就有这个计划，只是当时船票售罄，车票时间点不行，加上六月那会周末时间凑不齐，就推延至七月，等七月真正来了之后，台风也随之而来，自然因素再次致使计划推延，久而久之，这事也就不了了之了。一场说走就走的旅行，其实没那么容易，但也没那么难。这一年，心里还一直惦记着，毕竟工作之余，总要有些盼头，心心念念的事情总归还是要有所期待才行。就在六月下旬的某个夜晚，脑海里忽然浮现出一个想法，那就是利用周末的时间前往外伶仃岛。所以，外伶仃岛，我来了。</p><a id="more"></a><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>起初，并不打算自己组织出行，因为人太多意见反而很难一致，很容易出现分歧。当时只想约个好朋友一起去海边吹吹风，漫步在沙滩之上，欣赏下落日的晚霞，以及那黎明破晓时的朝阳，在安静的小岛上，静静地享受周围带来的一切。只是后来，不知不觉地就聚齐了八个人，大概是因为缘分到了，大家就这么巧的凑在一块了。正好，人多也热闹些，或许也会有另一番味道。作为出行游玩的发起人，还是有责任去整理一些事项，比如行程安排，需要携带的物品等等，都需要适当地跟大家提醒一下。还有买船票、订酒店，也不能单单只考虑个人想法，得看看大家能够接受的时间点以及能够承受的消费空间有多大。几番讨论之后，也算是定下来了。一切准备就绪之后，剩下的便只是等待了。</p><!-- <img src="/assets/articleImg/2020/伶仃湾.png" width="100%"> --><img src="/assets/articleImg/2020/DSC_2449.jpg" width="100%"><div class="caption">Fig 1.出海当然少不了船只，就用伶仃湾外的凑个数</div><h2 id="行程路线"><a href="#行程路线" class="headerlink" title="行程路线"></a>行程路线</h2><p>关于路线，由于是两天一夜，所以行程安排并没有太过复杂，去之前只是稍微整理了一下，最后的契合度大概80%+，路线如下：</p><blockquote><p>Day 1</p><ul><li>12:30 到达深圳蛇口，换取船票。</li><li>13:50 抵达蛇口邮轮中心，乘船前往外伶仃岛。</li><li>15:00 抵达后前往酒店办理入住，卸下行李稍作休息，等太阳略微小点之后，再出去游玩。参考伶仃八景：玉带环腰、拱桥渡水、摩崖石刻、石景公园(雾海仙槎)、伶峰揽胜、北帝晨钟、香江海市、碧海飞霞。</li><li>17:00 傍晚沿着海岸线行走，徒步玉带环腰、漫步伶仃湾沙滩。一路看着夕阳、海浪、礁石，观赏海岛的异样风景！傍晚时分，在伶仃沙滩上看日落，玩海边项目，或是下海游泳，当然少不了的还有拍照。</li><li>20:00 正式开启海鲜晚宴。</li><li>23:00 再来一顿海边烧烤，走的都是步骤，吃的全是情怀。</li></ul><p>Day 2</p><ul><li>4:00 早上四点起床登山，前往伶仃峰看日出，欣赏黎明前的曙光，下山之后略微补补觉；</li><li>9:00 前往沙滩进行潜水，或者其他娱乐项目；</li><li>12:00 前往海鲜市场海鲜一条街，购买海鲜，享受一次新鲜的海鲜午宴。</li></ul></blockquote><!-- <img src="/assets/articleImg/2020/071101.png" width="100%"> --><!-- <div class="caption">Fig .海鲜大餐</div> --><h2 id="整装待发"><a href="#整装待发" class="headerlink" title="整装待发"></a>整装待发</h2><p>期待了很久的海岛游，这次终于要出发了。看到乘船时间有70分钟，心里当时还真有些没底。对于我来说，乘过高铁，坐过飞机，也并没有丝毫不适，只是这70分钟的海上航行，的确是第一次，以前乘船也就几分钟的事情，这次万一晕船那可就不好哇。担心归担心，好在自己各方面还算OK，最后下了船也就跟没事一样，真是难得。</p><img src="/assets/articleImg/2020/伶仃湾.png" width="100%"><div class="caption">Fig 2.安静的伶仃湾口岸</div><h2 id="伶仃日落"><a href="#伶仃日落" class="headerlink" title="伶仃日落"></a>伶仃日落</h2><p>日落是沉静而美好的，它能抚平人心中浮躁的情绪，安慰人受伤的心灵。以前在山里，看到的都是太阳从山上落下去，海边的日落当然不一样，或许是因为看到的次数屈指可数，所以才显得别致起来吧。脑海中，每每回忆起，都有一种舒适的感觉，那种感觉就跟《肖申克的救赎》里面，安迪在监狱房顶喝啤酒露出的微笑一样。记忆里，伶仃沙滩上，落日的余晖打在每个人的脸庞，漫无边际的晚霞映在整个海平面上，绯红的海浪一次又一次的翻滚着，香蕉船在游艇的拉力之下随波荡漾，两边的潮水从脸上肆意打过，一丝咸咸的海水味道在舌尖泛起，海风吹拂着海面，波光粼粼，金光闪闪，海天一色，犹如成千上万面红装粉黛的镜子，看着那漫无边际的海域，心中不由得露出了一丝欣喜，浅浅的微笑也从脸上轻盈浮现！</p><img src="/assets/articleImg/2020/DSC_2515.jpg" width="100%"><div class="caption">Fig 3.夕阳下的海面，波光粼粼</div><p>夜幕下的外伶仃岛也是美的让人沉醉，海面徜徉在落日的余晖之下，一层层的波光在微光的点缀下显得分外明朗，宛如一幅美丽的星海画卷。</p><img src="/assets/articleImg/2020/night.png" width="100%"><div class="caption">Fig 4.夜幕伶仃</div><h2 id="舌尖下的外伶仃"><a href="#舌尖下的外伶仃" class="headerlink" title="舌尖下的外伶仃"></a>舌尖下的外伶仃</h2><p>关于美食，自己虽然谈不上是吃货，但也是对其毫无抵抗力的，号称伶仃三宝的将军帽、狗爪螺、海胆，比较好吃的还属将军帽，狗爪螺就跟嗑瓜子一样，太费劲，也吃不习惯，不推荐，至于海胆，因为量比较少，吃不出什么感觉，但是海胆炒饭还是很好吃的。</p><img src="/assets/articleImg/2020/food01.png" width="100%"><div class="caption">Fig 5.海鲜大餐</div><h2 id="登山望日：伶峰揽胜​"><a href="#登山望日：伶峰揽胜​" class="headerlink" title="登山望日：伶峰揽胜​"></a>登山望日：伶峰揽胜​</h2><p>看日出本是在计划之内，然而因为第一天晚上吃烧烤的时候已经接近零晨，大家都异口同声的说太累了，第二天不去看日出了。但是对于我来说，计划要做的事情是不会轻易改变的，就算累点也值得。虽然晚上零晨一点才睡着，但是早上四点还是怀揣着一股热情，从睡梦中醒来，朦朦胧胧的打起手电筒，从酒店前往伶仃峰，后来一起去的还有一个师弟跟他女朋友。爬山本就是我喜欢的一项运动，所以爬伶仃峰，也就没有那么困难，只是早晨路太黑，要是一个人，还真有些后怕呀。</p><p>日出的时间大概是五点五十，大家都起这么早，应该就是为了占个好位置哇。从山上朝着海平面望去，守候着太阳透过云层从海平面升起的瞬间。</p><p><img src="/assets/articleImg/2020/%E5%A4%95%E9%98%B3.png" alt=""></p><div class="caption">Fig 6.伶仃峰上看日出，水中霞光映日红</div><p>从伶仃峰下山时，在山腰上，望着安静的拱桥渡水和伶仃湾，整个人也感觉分外清爽，大概是清晨的露水将我这只睡了三个小时左右的人脑中的睡意全都洗净了。从上往下，一眼望去，视野内碧海蓝天，真想多待一些时日。</p><p><img src="/assets/articleImg/2020/IMG_6416.jpg" alt=""></p><div class="caption">Fig 7.清晨的海岛，静的让人喜欢</div><h2 id="娱乐体验​：香蕉船与潜水​"><a href="#娱乐体验​：香蕉船与潜水​" class="headerlink" title="娱乐体验​：香蕉船与潜水​"></a>娱乐体验​：香蕉船与潜水​</h2><p>关于娱乐，在岛上玩了两个付费项目：香蕉船和潜水。玩香蕉船项目，图的也就是个刺激，因为以前没玩过，就当是放纵下自己。幸福的是在香蕉船上看到了夕阳最美的一幕，以至于下了船之后，再也找不到那一刻的感觉。潜水项目也是初次接触，为了体验一次，觉都没补好就赶着过去下海了，当时还真担心自己会抗不住，毕竟只睡了三个小时左右，好在身体还透支得住。在海底还体验了一次给鱼喂食，也算是大开眼界，值得。</p><img src="/assets/articleImg/2020/fish-food.png" width="100%"><div class="caption">Fig 8.体验了一把亲手给鱼喂食，原来鱼吃食物也是这么快的，刷新认知</div><p>两天一夜的旅行，虽然短暂匆促，但却让人很满足，毕竟在这个疫情横行的时间点，安全第一呐。</p><h2 id="期待一直都在"><a href="#期待一直都在" class="headerlink" title="期待一直都在"></a>期待一直都在</h2><p>生活在大城市的我们，每天都在为生活和工作奔波，忙碌的我们还会经常听到有人说着：“生活不止眼前的苟且，还有诗和远方”。或许我们会思索着，远方究竟在何处呢？在我们的内心深处，也慢慢的开始向往着去不同的地方，看不同的风景，接触不同的事物，感受不一样的人生。当我们知道目的地在哪儿的时候，这些期待甚至还会成为我们长久以来努力坚持下去的理由。是的，不管是在多远的未来，只要结局是美好的，过程苦一点又有何妨呢！不是么？期待下一次的行动，那些筹备已久的计划，也终将有完成的一天，不会沉埋心底，消声遗迹，而当前要做的，仅仅是——不忘初心。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/assets/articleImg/2020/20200801-1.png&quot; width=&quot;100%&quot;&gt;

&lt;p&gt;距离海岛之行已经过去近二十天了，就在清理手机存储空间的时候，忽然翻到了相册里的照片，这才决定开始整理这篇海岛游记。此次前往的外伶仃岛，也是期待许久的海岛之一，可能是因为沉寂太久了吧。早在去年的端午节，就有这个计划，只是当时船票售罄，车票时间点不行，加上六月那会周末时间凑不齐，就推延至七月，等七月真正来了之后，台风也随之而来，自然因素再次致使计划推延，久而久之，这事也就不了了之了。一场说走就走的旅行，其实没那么容易，但也没那么难。这一年，心里还一直惦记着，毕竟工作之余，总要有些盼头，心心念念的事情总归还是要有所期待才行。就在六月下旬的某个夜晚，脑海里忽然浮现出一个想法，那就是利用周末的时间前往外伶仃岛。所以，外伶仃岛，我来了。&lt;/p&gt;
    
    </summary>
    
      <category term="生活" scheme="https://www.csuldw.com/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="生活" scheme="https://www.csuldw.com/tags/%E7%94%9F%E6%B4%BB/"/>
    
      <category term="旅行" scheme="https://www.csuldw.com/tags/%E6%97%85%E8%A1%8C/"/>
    
      <category term="外伶仃岛" scheme="https://www.csuldw.com/tags/%E5%A4%96%E4%BC%B6%E4%BB%83%E5%B2%9B/"/>
    
      <category term="海岛" scheme="https://www.csuldw.com/tags/%E6%B5%B7%E5%B2%9B/"/>
    
  </entry>
  
  <entry>
    <title>六月书</title>
    <link href="https://www.csuldw.com/2020/06/20/2020-06-20-personal-word/"/>
    <id>https://www.csuldw.com/2020/06/20/2020-06-20-personal-word/</id>
    <published>2020-06-20T15:44:00.000Z</published>
    <updated>2020-08-01T16:09:50.474Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/assets/articleImg/2020/rainbow.png" alt=""></p><p>吾本山间人士，地处湘西五溪之内，性内，为寻世之奥秘，立念于心底，破斧沉舟，誓出之。经学二十余载，辗转伏枕，唯风雨伴行，虽厉江湖之险恶，然未有大事临身，行之幸之。忆往昔，盖追三年有余，于故土则渐而远之，心之所念亦随之朦胧也，泪捂矣。愚以为心中有梦，行为之者奋，则亦有不负人之果也，奈时不我与，夙夜忧叹，悲者如斯哉！</p><a id="more"></a><p>今从业已有三载，观周身之故友，是以默者加之，心中之事，事有大小，大则只身顾之，或诉之于雪矣，小则叹于昊、沛、亮三人，此皆良友，常娱之。昊，入深之初，亦非绝世之才，然苦勤于暮朝之间，数月之下，终不负有心人也。今已入福厂，且得有一子，家和业兴，可贺矣。另有如昆、勇等人于京都者，自别后经年未见，相之甚远，仅言于偶然之间，浮尘随之，然情未淡矣。</p><p>年三，庚子年，余心常念于而立之年日渐临之，虽未有大责降身，然家业未成，身负之重亦未有所轻，不敢有所怠慢，缓而行之。前夕，与长者围于桌，谈当今之房者，皆有喜色露于嘴角，然吾心之羡固有所增，沉于静思之内，须臾之间，叹之，盖来之迟矣。六月，侧目望外，高楼林立，万里晴空，百木葱茏，诚宜登高望远或临水观海，然冠毒横行，势态岌危，不宜远行，唯日坐家中以防冠毒入侵，遂更往日之计划也。</p><p>于今，大局已定，百业正兴，人谓之稳者亦为不稳矣。哀者有所期，悲者有所弃，智者亦有所追也。至时，事三年，余心之所得甚微，寝不安席，食不甘味，若以此行复度数年，唯予以庸者之名而鄙弃之，此乃古今之律不可更也，或以自省而解之。大疆上下，当既律己以严则，待人以诚明，至于成败，乃命之定数，可计日而待也。夫天下之人，不论男女，皆有为其而倾心诉衷之人，诚以明心而待之，实属人之幸也。若交之有悖，心诚而意孤者，谓之难矣。今端午将至，节者必有为。少时，或行于闹市之间，或嬉于河岸之上，赛龙舟观山海，由是感激，乐而不倦矣，然此行亦远而不可复得也。</p><p>末，今当安分守己，严以律行，不以人之乐而乐己，不以人之哀而自艾，行必因，然必果。此则，诚矣！</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/assets/articleImg/2020/rainbow.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;吾本山间人士，地处湘西五溪之内，性内，为寻世之奥秘，立念于心底，破斧沉舟，誓出之。经学二十余载，辗转伏枕，唯风雨伴行，虽厉江湖之险恶，然未有大事临身，行之幸之。忆往昔，盖追三年有余，于故土则渐而远之，心之所念亦随之朦胧也，泪捂矣。愚以为心中有梦，行为之者奋，则亦有不负人之果也，奈时不我与，夙夜忧叹，悲者如斯哉！&lt;/p&gt;
    
    </summary>
    
      <category term="生活" scheme="https://www.csuldw.com/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="生活" scheme="https://www.csuldw.com/tags/%E7%94%9F%E6%B4%BB/"/>
    
      <category term="自白" scheme="https://www.csuldw.com/tags/%E8%87%AA%E7%99%BD/"/>
    
  </entry>
  
  <entry>
    <title>Moviedata-10M电影数据集统计分析之源码分享（Python）</title>
    <link href="https://www.csuldw.com/2020/05/05/2020-05-05-data-analysis-demo/"/>
    <id>https://www.csuldw.com/2020/05/05/2020-05-05-data-analysis-demo/</id>
    <published>2020-05-04T16:44:00.000Z</published>
    <updated>2020-05-21T15:06:17.642Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>之前写过一篇电影数据分析的文章”<a href="https://www.csuldw.com/2019/08/12/2019-08-12-douban-movies-statistics/">豆瓣13万电影数据统计与分析</a>“，引起了一些读者的关注，并且在后台咨询我是否可以分享下源码。为了满足大家的需要，我在五一期间将源码略作整理了下，并从中筛选了几个绘图源码在这里分享给大家，如有疑问，可在评论区留言。特别说明下，文中分析的数据来自电影数据集<a href="http://moviedata.csuldw.com/" target="_blank" rel="noopener">Moviedata-10M</a>中的movies.csv文件，需要的童鞋可以按照官方的说明进行下载即可。</p><a id="more"></a><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>在进行源码分享之前，这里先说说我们的运行环境吧，我是使用jupyter进行实验的（强烈推荐），python 3.6版本，依赖的相关库如下：</p><ul><li>pandas</li><li>matplotlib</li><li>seaborn</li><li>numpy</li><li>WordCloud</li><li>imageio</li><li>squarify</li></ul><p>如果对上面的库不了解或者不会安装的，请自行查阅，这里就不一一细说了。</p><h2 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h2><p>由于文件是csv文件，所以加载数据只需要使用python里面的pandas库即可，采用pandas中的read_csv就可以将csv中的数据加载到内存中，代码如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line">movies = pd.read_csv(<span class="string">"../data/movies.csv"</span>, encoding=<span class="string">"utf-8"</span>)</span><br></pre></td></tr></tbody></table></figure><h2 id="统计分析"><a href="#统计分析" class="headerlink" title="统计分析"></a>统计分析</h2><p>在<a href="https://www.csuldw.com/2019/08/12/2019-08-12-douban-movies-statistics/">豆瓣13万电影数据统计与分析</a>一文，我从不同的维度对电影数据进行了分析，在这里不会将全部的源码分享出来，但是会将核心内容贴出来。</p><h3 id="按上映年份统计电影"><a href="#按上映年份统计电影" class="headerlink" title="按上映年份统计电影"></a>按上映年份统计电影</h3><p>首先导入相关依赖库，主要是matplotlib，如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.matplotlib_fname()</span><br></pre></td></tr></tbody></table></figure><p>下面这几行代码是为了解决图表中的中文乱码问题，仅供参考：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#解决matplotlib 乱码</span></span><br><span class="line">matplotlib.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'SimHei'</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">'font.family'</span>]=<span class="string">'sans-serif'</span></span><br><span class="line"><span class="comment">#解决负号'-'显示为方块的问题</span></span><br><span class="line">matplotlib.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span></span><br><span class="line"><span class="keyword">from</span> matplotlib.font_manager <span class="keyword">import</span> _rebuild</span><br><span class="line">_rebuild()</span><br></pre></td></tr></tbody></table></figure><p>在绘制图表之前，我们需要对数据进行处理，构造我们需要的数据格式：</p><figure class="highlight processing"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#如果<span class="built_in">year</span>字段为空，就从release_date进行截取</span><br><span class="line">def map_year(x):</span><br><span class="line">    <span class="built_in">year</span> = x[<span class="string">"year"</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">year</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">year</span> = <span class="built_in">str</span>(x[<span class="string">"release_date"</span>]).<span class="built_in">split</span>(<span class="string">"-"</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">str</span>(<span class="built_in">year</span>)</span><br><span class="line">    </span><br><span class="line">movies[<span class="string">"year2"</span>] = movies.apply(lambda x: map_year(x), axis=<span class="number">1</span>)</span><br><span class="line">#获取<span class="number">2020</span>年之前上映的电影</span><br><span class="line">movies = movies[movies[<span class="string">"year2"</span>]&lt;<span class="string">"2020"</span>]</span><br></pre></td></tr></tbody></table></figure><p>得到2020年之前的电影之后，我们再分组统计每年上映的电影数量</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">year_grp = movies.groupby(<span class="string">"year2"</span>).size().reset_index(<span class="attribute">name</span>=<span class="string">"num"</span>) \</span><br><span class="line">                 .sort_values(<span class="attribute">by</span>=<span class="string">"year2"</span>, <span class="attribute">ascending</span>=<span class="literal">True</span>)</span><br><span class="line">year_grp = year_grp.rename(columns={<span class="string">"year2"</span>:<span class="string">"year"</span>})</span><br></pre></td></tr></tbody></table></figure><p>接着，按照年份和上映的电影量进行绘图，首先分享下散点图的绘制方法，代码如下：</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">import seaborn as sns</span><br><span class="line"><span class="comment">#散点图</span></span><br><span class="line">def draw_stripplot(df, df_x, df_y, <span class="attribute">title</span>=<span class="string">"Title"</span>, <span class="attribute">ylabel</span>=<span class="string">"Y"</span>, <span class="attribute">savepath</span>=<span class="string">"defalt.png"</span>):</span><br><span class="line">    # draw stripplot start</span><br><span class="line">    fig, ax = plt.subplots(figsize=(20,10), dpi= 80)    </span><br><span class="line">    sns.stripplot(df_x, df_y, <span class="attribute">jitter</span>=0.25, <span class="attribute">size</span>=8, <span class="attribute">ax</span>=ax, <span class="attribute">linewidth</span>=.5)</span><br><span class="line"></span><br><span class="line">    # decoration</span><br><span class="line">    plt.gca().set_xticklabels(df_x, <span class="attribute">rotation</span>=90, horizontalalignment= <span class="string">'right'</span>)</span><br><span class="line">    plt.title(title, <span class="attribute">fontsize</span>=16)</span><br><span class="line">    plt.ylabel(ylabel)</span><br><span class="line">    plt.savefig(savepath)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">draw_stripplot(year_grp, year_grp.year, year_grp.num, </span><br><span class="line">            <span class="attribute">title</span>=<span class="string">"Number Of Movies Released Each Year(1873-2019)"</span>, </span><br><span class="line">            <span class="attribute">ylabel</span>=<span class="string">'# Number'</span>, </span><br><span class="line">            <span class="attribute">savepath</span>=<span class="string">"result/movies_number_of_each_year_stripplot.png"</span>)</span><br></pre></td></tr></tbody></table></figure><p>draw_stripplot方法是可以共用的，如果其他的聚合数据生成了，也可以调用上面的方法。得到的图表如下所示：</p><p><img src="/assets/articleImg/2020/movie-stat-by-year.png" alt=""></p><div class="caption">Fig 1.每年上映的电影数（趋势图）</div><h3 id="按评分统计电影"><a href="#按评分统计电影" class="headerlink" title="按评分统计电影"></a>按评分统计电影</h3><p>首先分组统计出每个评分的电影数量</p><figure class="highlight prolog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = movies.groupby(<span class="string">'douban_score'</span>).size().reset_index(name=<span class="string">'counts'</span>)</span><br><span class="line">df = df[df[<span class="string">"douban_score"</span>]&gt;<span class="number">0</span>]</span><br><span class="line">df[<span class="string">"douban_score"</span>] = df.douban_score.astype(<span class="string">"str"</span>)</span><br></pre></td></tr></tbody></table></figure><p>采用<code>movies[movies["douban_score"] &gt; 0]["douban_score"].mean()</code>可以统计出电影的平均得分为6.63。</p><p>接着编写柱状图绘制函数，代码如下：</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#柱状图</span></span><br><span class="line">def draw_barplot(df, df_x, df_y, <span class="attribute">title</span>=<span class="string">"Title"</span>, <span class="attribute">ylabel</span>=<span class="string">"# Y"</span>, </span><br><span class="line">                <span class="attribute">savepath</span>=<span class="string">"default.png"</span>, <span class="attribute">fontsize</span>=5, <span class="attribute">x_fontsize</span>=10):</span><br><span class="line">    all_colors = list(plt.cm.colors.cnames.keys())</span><br><span class="line">    random.seed(100)</span><br><span class="line">    c = random.choices(all_colors, <span class="attribute">k</span>=df_x.shape[0])</span><br><span class="line"></span><br><span class="line">    # Plot Bars柱状</span><br><span class="line">    plt.figure(figsize=(20,10), dpi= 200)</span><br><span class="line">    plt.bar(df_x, df_y, <span class="attribute">color</span>=c, <span class="attribute">width</span>=.5)</span><br><span class="line">    <span class="keyword">for</span> i, val <span class="keyword">in</span> enumerate(df_y.values):</span><br><span class="line">        plt.text(i, val, int(val), <span class="attribute">horizontalalignment</span>=<span class="string">'center'</span>, </span><br><span class="line">                <span class="attribute">verticalalignment</span>=<span class="string">'bottom'</span>, </span><br><span class="line">                fontdict={<span class="string">'fontweight'</span>:200, <span class="string">'size'</span>:fontsize})</span><br><span class="line"></span><br><span class="line">    # Decoration</span><br><span class="line">    plt.gca().set_xticklabels(df_x, <span class="attribute">rotation</span>=90, horizontalalignment= <span class="string">'right'</span>, </span><br><span class="line">                            fontdict={<span class="string">"size"</span>:x_fontsize})</span><br><span class="line">    plt.title(title, <span class="attribute">fontsize</span>=16)</span><br><span class="line">    plt.ylabel(ylabel)</span><br><span class="line">    plt.savefig(savepath)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></tbody></table></figure><p>将数据采用上面别写函数进行渲染：</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">draw_barplot(df, df.douban_score, df.counts, </span><br><span class="line">            <span class="attribute">title</span>=<span class="string">"Movie Statistics For Each Score"</span>, </span><br><span class="line">            <span class="attribute">ylabel</span>=<span class="string">'# Score'</span>, <span class="attribute">savepath</span>=<span class="string">"result/movie_stat_by_score.png"</span>, <span class="attribute">fontsize</span>=10)</span><br></pre></td></tr></tbody></table></figure><p>得到的柱状图如下所示：</p><p><img src="/assets/articleImg/2020/movie-stat-by-score.png" alt=""></p><div class="caption">Fig 2.各个评分下的电影数统计</div><h3 id="按照国家进行统计"><a href="#按照国家进行统计" class="headerlink" title="按照国家进行统计"></a>按照国家进行统计</h3><p>首先根据国家进行聚合，</p><figure class="highlight prolog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">movies_regions = movies</span><br><span class="line">movies_regions[<span class="string">"regions"</span>] = movies_regions.regions  \</span><br><span class="line">                .apply(lambda x: x.split(<span class="string">"/"</span>)[<span class="number">0</span>].split(<span class="string">" "</span>)[<span class="number">0</span>].strip())</span><br><span class="line">df = movies_regions.groupby(<span class="string">'regions'</span>).size().reset_index(name=<span class="string">'counts'</span>)</span><br><span class="line">df = df[df[<span class="string">"regions"</span>]!=<span class="string">""</span>].sort_values(by=[<span class="string">"counts"</span>], ascending=<span class="symbol">False</span>)[:<span class="number">50</span>]</span><br></pre></td></tr></tbody></table></figure><p>然后调用<code>draw_barplot</code>函数即可：</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">draw_barplot(df, df.regions, df.counts, </span><br><span class="line">            <span class="attribute">title</span>=<span class="string">"Movie Statistics For Each Region"</span>, <span class="attribute">ylabel</span>=<span class="string">'# Number'</span>, </span><br><span class="line">            <span class="attribute">savepath</span>=<span class="string">"result/movies_stat_by_regions.png"</span>, <span class="attribute">fontsize</span>=8,x_fontsize=12)</span><br></pre></td></tr></tbody></table></figure><p>结果图如下：</p><p><img src="/assets/articleImg/2020/movie-stat-by-region.png" alt=""></p><div class="caption">Fig 3.按发行地域统计电影数（Top 50的发行地域）</div><h3 id="按语言进行统计"><a href="#按语言进行统计" class="headerlink" title="按语言进行统计"></a>按语言进行统计</h3><p>数据构建</p><figure class="highlight prolog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df = movies.groupby(<span class="string">'languages'</span>).size().reset_index(name=<span class="string">'counts'</span>)</span><br><span class="line">df = df[df[<span class="string">"languages"</span>]!=<span class="string">""</span>]</span><br><span class="line">df = movies.languages.apply(lambda x: x.split(<span class="string">"/"</span>)[<span class="number">-1</span>].split(<span class="string">" "</span>)[<span class="number">0</span>])   \</span><br><span class="line">         .reset_index(name=<span class="string">"languages"</span>).drop(columns=<span class="string">"id"</span>)</span><br><span class="line">df = df.groupby(<span class="string">"languages"</span>).size().reset_index(name=<span class="string">'counts'</span>)</span><br><span class="line">df = df[df[<span class="string">"languages"</span>]!=<span class="string">""</span>]</span><br><span class="line">df = df.sort_values(by=[<span class="string">"counts"</span>], ascending=<span class="symbol">False</span>)[:<span class="number">20</span>]</span><br></pre></td></tr></tbody></table></figure><p>绘制饼状图，并进行渲染：</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">def draw_pieplot(df, df_x, df_y, </span><br><span class="line">                <span class="attribute">title</span>=<span class="string">"Title"</span>, </span><br><span class="line">                <span class="attribute">subtitle</span>=<span class="string">"subtitle"</span>, </span><br><span class="line">                <span class="attribute">savepath</span>=<span class="string">"default.png"</span>):</span><br><span class="line">    # Draw Plot</span><br><span class="line">    fig, ax = plt.subplots(figsize=(12, 7), <span class="attribute">subplot_kw</span>=dict(aspect="equal"), dpi= 80)</span><br><span class="line"></span><br><span class="line">    data = df_y</span><br><span class="line">    categories = df_x</span><br><span class="line">    explode = np.zeros(df_x.shape[0])</span><br><span class="line">    explode[3] = 0.1</span><br><span class="line"></span><br><span class="line">    def func(pct, allvals):</span><br><span class="line">        absolute = int(pct/100.*np.sum(allvals))</span><br><span class="line">        return <span class="string">"{:.1f}% ({:d} )"</span>.format(pct, absolute)</span><br><span class="line"></span><br><span class="line">    wedges, texts, autotexts = ax.pie(data,</span><br><span class="line">                                      <span class="attribute">autopct</span>=lambda pct: func(pct, data),</span><br><span class="line">                                      <span class="attribute">textprops</span>=dict(color="w"),</span><br><span class="line">                                      <span class="attribute">colors</span>=plt.cm.Dark2.colors,</span><br><span class="line">                                     <span class="attribute">startangle</span>=140)</span><br><span class="line"></span><br><span class="line">    # Decoration</span><br><span class="line">    ax.legend(wedges, categories, </span><br><span class="line">            <span class="attribute">title</span>=subtitle, <span class="attribute">loc</span>=<span class="string">"center left"</span>, </span><br><span class="line">            bbox_to_anchor=(1, 0, 0.5, 1))</span><br><span class="line">    plt.setp(autotexts, <span class="attribute">size</span>=10, <span class="attribute">weight</span>=700)</span><br><span class="line">    ax.set_title(title)</span><br><span class="line">    plt.savefig(savepath)</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">draw_pieplot(df, df.languages, df.counts, </span><br><span class="line">            <span class="attribute">title</span>=<span class="string">"Statistics By Languages: Pie Chart"</span>, </span><br><span class="line">            <span class="attribute">subtitle</span>=<span class="string">"Languages"</span>, </span><br><span class="line">            <span class="attribute">savepath</span>=<span class="string">"result/movie_language_stat_pieplot.png"</span>)</span><br></pre></td></tr></tbody></table></figure><p>结果图如下：</p><p><img src="/assets/articleImg/2020/movie-stat-by-lang.png" alt=""></p><div class="caption">Fig 4.按语言统计电影数</div><h3 id="对中国的电影进行分析"><a href="#对中国的电影进行分析" class="headerlink" title="对中国的电影进行分析"></a>对中国的电影进行分析</h3><p>同理，首先构造数据格式：</p><figure class="highlight ini"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">movies_china</span> = movies[movies.regions.str.startswith(<span class="string">"中国"</span>) |  \</span><br><span class="line">                      movies.regions.str.startswith(<span class="string">"香港"</span>) |  \</span><br><span class="line">                      movies.regions.str.startswith(<span class="string">"台湾"</span>) |  \</span><br><span class="line">                      movies.regions.str.startswith(<span class="string">"澳门"</span>)]</span><br><span class="line"></span><br><span class="line"><span class="attr">df</span> = movies_china.reset_index().groupby(<span class="string">'year'</span>).size().reset_index(name=<span class="string">"counts"</span>)</span><br><span class="line"><span class="attr">df</span> = df[df[<span class="string">"year"</span>]!=<span class="string">""</span>][df[<span class="string">"year"</span>]!=<span class="number">0</span>]</span><br><span class="line"><span class="attr">df</span> = df.sort_values(by=<span class="string">"year"</span>, ascending=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#df["counts"] = df.counts.astype("str")</span></span><br></pre></td></tr></tbody></table></figure><p>接着绘制线性趋势图：</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">def draw_plot_liner2(df, df_x, df_y, </span><br><span class="line">                    x_name, </span><br><span class="line">                    y_name, </span><br><span class="line">                    <span class="attribute">title</span>=<span class="string">"Title"</span>, </span><br><span class="line">                    <span class="attribute">ylabel</span>=<span class="string">"Y"</span>, </span><br><span class="line">                    <span class="attribute">savepath</span>=<span class="string">"defalt.png"</span>):</span><br><span class="line">    # Draw Plot - liner</span><br><span class="line">    plt.figure(figsize=(16,10), dpi= 80)</span><br><span class="line">    plt.plot(x_name, y_name, <span class="attribute">data</span>=df, <span class="attribute">color</span>=<span class="string">'tab:red'</span>)</span><br><span class="line"></span><br><span class="line">    plt.yticks(<span class="attribute">fontsize</span>=12, <span class="attribute">alpha</span>=.7)</span><br><span class="line">    plt.title(title, <span class="attribute">fontsize</span>=22)</span><br><span class="line">    plt.ylabel(ylabel)</span><br><span class="line">    plt.grid(<span class="attribute">axis</span>=<span class="string">'both'</span>, <span class="attribute">alpha</span>=.3)</span><br><span class="line"></span><br><span class="line">    # <span class="builtin-name">Remove</span> borders</span><br><span class="line">    plt.gca().spines[<span class="string">"top"</span>].set_alpha(0.0)    </span><br><span class="line">    plt.gca().spines[<span class="string">"bottom"</span>].set_alpha(0.3)</span><br><span class="line">    plt.gca().spines[<span class="string">"right"</span>].set_alpha(0.0)    </span><br><span class="line">    #plt.gca().spines[<span class="string">"left"</span>].set_alpha(0.3)   </span><br><span class="line">    plt.savefig(savepath)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">draw_plot_liner2(df, df.year, df.counts,<span class="string">'year'</span>,<span class="string">'counts'</span>, </span><br><span class="line">                <span class="attribute">title</span>=<span class="string">"Statistics of Movie_China For Each Year"</span>, </span><br><span class="line">                <span class="attribute">ylabel</span>=<span class="string">'# Number'</span>, <span class="attribute">savepath</span>=<span class="string">"result//movies_china_each_year.png"</span>)</span><br></pre></td></tr></tbody></table></figure><p>最后得到的趋势图如下：</p><p><img src="/assets/articleImg/2020/stat-by-year-for-china.png" alt=""></p><div class="caption">Fig 5.中国每年的电影数量统计</div><p>如果需要渲染多个国家进行对比，只需要将多个国家的数据进行聚合然后一个个绘制到图上即可。</p><h2 id="词云"><a href="#词云" class="headerlink" title="词云"></a>词云</h2><h3 id="电影类型词云"><a href="#电影类型词云" class="headerlink" title="电影类型词云"></a>电影类型词云</h3><p>如果想要绘制类型词云，需要上面提到的WordCloud库。</p><figure class="highlight elm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">import</span> imageio</span><br></pre></td></tr></tbody></table></figure><p>当具备这些之后，我们首先要准备数据，取出电影标签，然后进行词频统计,</p><figure class="highlight livecodeserver"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">object_list = movies.genres.tolist()</span><br><span class="line">word_list = []</span><br><span class="line"><span class="keyword">for</span> <span class="keyword">words</span> <span class="keyword">in</span> object_list:</span><br><span class="line">    word_list.extend(<span class="keyword">words</span>.<span class="built_in">split</span>(<span class="string">"/"</span>))</span><br><span class="line">word_counts = collections.Counter(word_list) <span class="comment"># 对分词做词频统计</span></span><br></pre></td></tr></tbody></table></figure><p>接着调用WordCloud库进行分析</p><figure class="highlight mipsasm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">b_mask </span>= imageio.imread(<span class="string">"./data/bg_my.jpeg"</span>) <span class="comment">#如果运行到这里找不到图片，请自行替换图片即可</span></span><br><span class="line"></span><br><span class="line">wc = WordCloud(font_path=<span class="string">"Hiragino Sans GB.ttc"</span>, <span class="comment"># 字体</span></span><br><span class="line">               <span class="keyword">background_color </span>= <span class="string">'white'</span>, <span class="comment"># 背景色</span></span><br><span class="line">               max_words = <span class="number">2000</span>, <span class="comment"># 最大显示单词数</span></span><br><span class="line">               <span class="comment">#width=1000,</span></span><br><span class="line">               <span class="comment">#height=500,</span></span><br><span class="line">               max_font_size = <span class="number">160</span>, <span class="comment"># 频率最大单词字体大小</span></span><br><span class="line">               mask=<span class="keyword">b_mask</span></span><br><span class="line"><span class="keyword"> </span>              <span class="comment">#stopwords = stopwords # 过滤噪声词</span></span><br><span class="line">              ).generate_from_frequencies(word_counts)</span><br><span class="line"></span><br><span class="line">wc.to_file(<span class="string">"genres_cloud.png"</span>)</span><br><span class="line">plt.imshow(wc, interpolation=<span class="string">"bilinear"</span>)</span><br><span class="line">plt.axis(<span class="string">"off"</span>)</span><br><span class="line">plt.<span class="keyword">show()</span></span><br></pre></td></tr></tbody></table></figure><p>如果词库比较大的话，时间需要久一点，最后得到的图片如下：</p><p><img src="/assets/articleImg/2020/type-wordcloud.png" alt=""></p><div class="caption">Fig 6.电影类型词云</div><p>标签词云也是类似的，只需hexo要重新渲染下数据即可。</p><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>文章共介绍了散点图、线性图、柱状图、饼状图、词云这几个核心图表的绘制，只要下载了相关库，那么构造出相应的数据格式之后，代码可以直接运行，后续我会考虑以jupyter文件分享出来，大家可以关注下我的公众号：【斗码小院】，相关内容会第一时间发布到公众号中，如果相关问题，也可以在公众号的“关于小院”一栏进行留言。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前写过一篇电影数据分析的文章”&lt;a href=&quot;https://www.csuldw.com/2019/08/12/2019-08-12-douban-movies-statistics/&quot;&gt;豆瓣13万电影数据统计与分析&lt;/a&gt;“，引起了一些读者的关注，并且在后台咨询我是否可以分享下源码。为了满足大家的需要，我在五一期间将源码略作整理了下，并从中筛选了几个绘图源码在这里分享给大家，如有疑问，可在评论区留言。特别说明下，文中分析的数据来自电影数据集&lt;a href=&quot;http://moviedata.csuldw.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Moviedata-10M&lt;/a&gt;中的movies.csv文件，需要的童鞋可以按照官方的说明进行下载即可。&lt;/p&gt;
    
    </summary>
    
      <category term="数据分析" scheme="https://www.csuldw.com/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Python" scheme="https://www.csuldw.com/tags/Python/"/>
    
      <category term="数据分析" scheme="https://www.csuldw.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="电影数据集" scheme="https://www.csuldw.com/tags/%E7%94%B5%E5%BD%B1%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    
      <category term="源码" scheme="https://www.csuldw.com/tags/%E6%BA%90%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>浅谈图的连通性探测</title>
    <link href="https://www.csuldw.com/2020/04/30/2020-04-30-graph-connectivity/"/>
    <id>https://www.csuldw.com/2020/04/30/2020-04-30-graph-connectivity/</id>
    <published>2020-04-30T15:50:00.000Z</published>
    <updated>2020-04-30T15:57:28.786Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>五一假期快到了，终于有时间写文章了😁。这篇文章启发于年前在工作中碰到的一个任务，其实是一个比较简单的算法题。有一次，业务方有个功能点需要我们支撑，大致意思就是给出几个实体（图谱数据中的实体），判断这几个实体之间是否存在某种联系，如果有孤立的实体，那么就是非关联的。针对这个问题，大致分析下，首先我们的数据底层是知识图谱数据库，这些实体以及实体与实体之间的关系构成了整个庞大的知识图谱，现在的目的就是从这张图谱中判断节点之间是否存在连接（直接或者间接），我们称之为图的连通性探测。</p><a id="more"></a><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>上面讲到，我们的数据底层是知识图谱数据库，而这些数据都是采用三元组形式存储的。针对图谱数据库，还对应的提供了一个图谱搜索服务，当我们输入关键字之后，就会返回我们我们想要的子图，包括不同的条件，比如1-hop，2-hop，同时还可以限制搜索范围，是搜实体还是搜属性，亦或是搜索关系。如下图所示（工作数据当然是看不到的，下图是自己用Neo4j构建的电影图谱数据），演员芭芭拉·赫希出演了《黑天鹅》电影，那么他们之间就存在一条关系，即一个三元组数据（芭芭拉·赫希，出演，黑天鹅），在这里面，演员和电影都是一个实体，只是实体类型不一样。所以当用户输入黑天鹅和芭芭拉赫希，同时我们将hop取值等于1，那么就会得到下面的这张子图。假设你想知道他们两是否存在<strong>直接联系</strong>，那么只需要判断两个节点是否存在关系即可，但是在实际情况里，我们往往想知道的是两个节点是否存在间接联系，如果不存在，则两者是没有关联的。</p><img src="/assets/articleImg/2020/graph-node-data.png" width="100%"><div class="caption">『图谱样例数据，来自Neo4j』</div><h2 id="两个节点的关系"><a href="#两个节点的关系" class="headerlink" title="两个节点的关系"></a>两个节点的关系</h2><p>针对一个子图而言，如果两个节点存在一条边将两者连接起来，那么他们就是有直接关系，如果两个节点通过中间的一个节点将两者串起来，那么它们也是有关系的，这种关系视业务场景而定。在实际当中，我们往往会对搜索出来的子图做一个限制，比如刘德华和梁朝伟都演过《无间道》，他们是存在直接联系的，但是如果加上限制条件，比如说刘德华和张学友是否在同时出现在一部喜剧之中，或者伦理剧，那么结果肯定会不一样。所以这种关系，也是在特定业务场景下的关系。</p><h2 id="连通性探测"><a href="#连通性探测" class="headerlink" title="连通性探测"></a>连通性探测</h2><p>针对上面这种场景，当我们输入两个关键字之后，我们可以得到一个子图，在得到这个子图之后，如果想要限定某种条件，我们还需要对结果数据进行删减，去掉不符合条件的节点和边，这一步称之为<strong>图的裁剪</strong>，最后留下的子图才是用来判断两个节点是否连通的真实子图。关于连通性的定义，在大学的时候，我们在数据结构课程中都学到过。假设给定一个子图，如果图中的任意两个节点都是连通的（直接或者间接），那么这个图就是连通的，我们称之为连通图，或者连通子图。</p><p>现在，我们碰到的场景是，给定一个子图，然后根据某种条件删掉一些节点和边，省下n个节点，m条边，要求是判断子图的n1（n1 &lt; n） 个节点是否是连通的。是不是有点绕，如果是的话，请您回头在读一遍。换句话说，就是判断裁剪后的子图里某n1个节点是否位于一个连通子图中。</p><p>分析到这里，想必也可以知道要做的功能是什么意思了。其实方法也有多种，第一种就是从n1个节点中的某一个节点开始进行DFS遍历，当第一个连通子图遍历完之后，判断这n1个节点是否都在其中，如果有一个不再，那么他们就是非连通的。第二种就是随机的从某个节点开始遍历，当所有节点都遍历完之后，会得到s(s&gt;=1)个连通子图，遍历过程中，我们将每个节点都打上连通子图的序号，表示属于第几个连通子图的节点，最后得到的s如果恒等于1，那么毫无疑问，这些节点就是连通的，如果大于1，那么就判断这n1个节点是否都属于同一个连通子图，如果是，则是连通的，如果否，则是非连通的。</p><p>方法出来了，那么代码应该怎么写呢？这里分享一种思路吧，具体的逻辑这里就不写了。我们在做图的遍历的时候，会常用到DFS和BFS，这两种算法的非递归实现在图的遍历中是非常重要和常用的，而且也会经常延伸到其他算法当中，其核心就在于借助了栈和队列作为辅助数据结构。比如DFS（深度优先遍历），借助队列实现。首先初始化的时候将第一个节点入队，然后循环判断，当队列不为空的时候，进行内部逻辑实现，首先队列的队首数据出队，然后将与队首节点有关联的第二和第三个节点入队，同时遍历第一个节点，接着重新回到循环体中判断队列是否为空，依次循环，直到辅助队列为空为止。如果是想计算出连通子图的数量，那么就设置一个辅助数组，下表表示节点编号，值为是否遍历过，初始化所有的节点都没有遍历，然后对数组的元素进行DFS遍历，如果遍历过的，就跳过，没有遍历过的就采用DFS进行遍历，最后统计使用DFS的次数，这个次数就是连通子图的个数。</p><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>当时在做这个时候，一开始是交给一个合作方的同事去弄，来来回回折腾了好几天，就是没做出来，原因是他对于图这种数据结构并不了解，不知道DFS，也不知道采用栈和队列作为辅助数据结构，最后还是得自己动手实现。之所以在这里提到众多工作中的这一话题，其实是想说数据结构的重要性。以前在学校的时候，潜意识的以为应该不会用到DFS和BFS这种算法，以及这些和图相关的东西，现在真的遇上了，才感到庆幸，有种柳暗花明又一村的舒适感。</p><p>好了，假期终于开始，祝大家五一节日快乐，明天开开心心的搞卫生，做大扫除吧！！！</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;五一假期快到了，终于有时间写文章了😁。这篇文章启发于年前在工作中碰到的一个任务，其实是一个比较简单的算法题。有一次，业务方有个功能点需要我们支撑，大致意思就是给出几个实体（图谱数据中的实体），判断这几个实体之间是否存在某种联系，如果有孤立的实体，那么就是非关联的。针对这个问题，大致分析下，首先我们的数据底层是知识图谱数据库，这些实体以及实体与实体之间的关系构成了整个庞大的知识图谱，现在的目的就是从这张图谱中判断节点之间是否存在连接（直接或者间接），我们称之为图的连通性探测。&lt;/p&gt;
    
    </summary>
    
      <category term="知识图谱" scheme="https://www.csuldw.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="数据结构" scheme="https://www.csuldw.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
      <category term="连通图" scheme="https://www.csuldw.com/tags/%E8%BF%9E%E9%80%9A%E5%9B%BE/"/>
    
      <category term="图" scheme="https://www.csuldw.com/tags/%E5%9B%BE/"/>
    
  </entry>
  
  <entry>
    <title>一路丢失的二零二零</title>
    <link href="https://www.csuldw.com/2020/04/19/2020-04-19-thinking-something/"/>
    <id>https://www.csuldw.com/2020/04/19/2020-04-19-thinking-something/</id>
    <published>2020-04-19T15:44:00.000Z</published>
    <updated>2020-04-19T10:49:17.795Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最近一个劲地开始怀旧起来，可能真的是年纪大了，不知不觉就快要到了而立之年，就连某宝也开始推荐我要准备养老了🤣。前段时间，刚看完《念书的孩子》和《遥望南方的童年》两部电影，之后的一段时间里，心里面总感觉热腾腾的难以平复。这两部影片都是豆瓣高评却冷门的国内电影，剧情朴实，画面感人，内容也非常真实，典型的回忆杀，影片的很多镜头都能让人回想起童年时候的自己，山坡、绿林、青草、池蛙、还有那田间小路，仿佛昨日一般，渐渐地将自己带入到童年的生活之中，沉睡的心也随之苏醒，就连听的歌，也都可以追溯到上个世纪了。罢了罢了，言归正传，谈谈这一路丢失的2020吧！</p><!-- ![](/assets/articleImg/2020/xiyang.png) --><img src="/assets/articleImg/2020/sz-night.png" width="100%"><div class="caption">『夜幕来临前的深圳湾——with XL』</div><a id="more"></a><p>今年的春季走的有些猝不及防，静悄悄的就到了四月下旬，眼看2020年都快过去三分之一了，现在的形势对我来说，有兴奋，也有惶恐，更多的是疫情对自己计划之内的事情影响之后的焦虑。年初的plan，大概百分之三十都被打乱了，以至于这段时间过得有些浑浑噩噩，揪心！话说回来，与其纠结于先前的计划不能如愿进展而停滞不前，不如开始更改自己的计划吧！“业精于勤荒于嬉，行成于思毁于随”，这种局势下，如能开辟新径，独树一帜，或许也会收获另一番风景！</p><!-- ![](/assets/articleImg/2020/xiyang.png) --><img src="/assets/articleImg/2020/xiyang.png" width="70%"><div class="caption">『阳台之外的夕阳，落日之下的晚霞』</div><p>先从to do list开始吧，“山不在高，有仙则名。水不在深，有龙则灵。”，目标也不在多，能与自身情况match上就行，量力而为，随心而事。根据去年的情况，简单分析了下，可以将时间划分到生活、工作、学习、业余休闲几个方面，尽量各方面都能涵盖到，比例大概控制在2:5:2:1。如此看来，工作占据了自身一半的时间，必须要好好控制才好。另外，对于现阶段来说，除了工作，学习和生活也是首选的要做好的两件大事。学习是为了让自己不断的升值，放低点说就是保值吧；而生活，说白了则是让自己去学会怎样接受社会的毒打🤣、去适应周围的环境、去体验美妙的人生、去享受得之不易的当下等等。经历的越多，看的也会越淡吧，慢慢应该就习惯了。疫情期间，自己投入到学习的时间确实略微不足。一开始是原本的计划扑空，一时间自己仿佛变成了无头苍蝇，原地打转；紧接着，投入到工作和生活上的时间比例加大了，反过来没多少精力投入到学习上。事情放的越久，忘记的概率就越大，后续的抵触心理也就会越浓，这的确是一个糟糕的习惯。人不自省而不自知，适当的复盘还是很有必要的，真正要努力去学会的还是控制好自己的时间，不能顾此失彼，忘却本心！</p><img src="/assets/articleImg/2020/fly-one.png" width="100%"><div class="caption">『坐在电脑前面发呆，随手折起的千纸鹤』</div><p>这段时间，收获最大的应该是自己的厨艺提升了，当然是相对于去年或者之前来说。比起在公司食堂吃饭，在家里吃饭的胃口的确好很多，主要是饭菜的味道都符合自己的口味，就算有时候“翻车”了，也算是一个失败的经验呢，下次调整过来就好了，容错率大，所以吃的也就非常happy😊。平时下班回到家里，因为时间有限，就弄些小菜吃，土豆莴笋小白菜、茄子豆角西红柿之类的，周末则会弄几个大菜，香辣虾、红烧鱼、红烧肉，或者是湖南人都爱的辣椒炒肉。这些菜里面，红烧肉就特别耗时间，偶尔做一餐也还OK呢。当然，厨艺这事也是自己年初计划之内的事情，算是在践行计划吧！</p><img src="/assets/articleImg/2020/food-list.png" width="100%"><div class="caption">『自己下厨的结果就是，不知不觉的就胖了好几斤😁，得控制』</div><p>马上就要到五一了，后续的时间安排可能也会更加紧凑，同时要把更多的时间投入到学习上去，包括读书、学琴、公众号维护、summary等等，那么设置阶段性的小目标则尤为关键了。在软件开发里面，常用的一种开发模式就是敏捷开发，也可以将这种思维方式移入到自己的个人计划当中，将目标拆分为不同的子目标，然后循序渐进，逐个去完成。计划是思想的产物，但计划的事情如果不去做，那么它就永远只是计划，很多时候我们缺少的不是想法，而是为之付出的行动。有些事做着做着就有结果了，但是不做，它就永远没有进展。虚虚实实，真真假假，真相也往往只有个中人知道罢了。有些事情现在不去做，可能这辈子也就不会去做了。当然，万事除了开头难之外，还有贵在坚持！以前在学校，有老师督促，在家里有家长督促，在实验室，有导师督促；现在到了社会上，虽然离开了这些场地，没有了束缚，就好比一匹脱了缰的野马，终于自由了，但是也不能放荡不羁、任意妄为，要学会自我约束，适可而止。十年前，自己怎么也想不到会来深圳发展，十年后，又会是怎样的情景呢？确实值得自己去深思！</p><p>这两天，【<strong>CodeMainFun</strong>】公众号的关注人数已经达到450+，很快就要突破500了，的确是一件值得欣慰的事。这个公众号是去年九月份开始维护的，半年时间里，还放养了好几个月，有这个数据，也还算好的，其中很多用户都是冲着电影数据集和QA来的。只是自己也略感愧疚，因为后台消息太多，有些内容就忽略掉了，在这里真挚的对各位朋友说声抱歉。年后的这段时间，自己也在整理自己的事情，有些东西也没发表出来，如果有需要帮助的童鞋，可以前往公众号，点击右下方的【关于小院】，进入【<a href="https://mp.weixin.qq.com/s/UL44kJIWnmYss1dPm2wH5Q" target="_blank" rel="noopener">小院简介</a>】中留言，能帮到的，业余时间里定尽力而为。</p><p>OK，新的计划也出来了，随之而来的就是行动了，一路丢失的2020，希望您走的慢点儿。</p><img src="/assets/articleImg/2020/prince.jpg" width="100%"><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近一个劲地开始怀旧起来，可能真的是年纪大了，不知不觉就快要到了而立之年，就连某宝也开始推荐我要准备养老了🤣。前段时间，刚看完《念书的孩子》和《遥望南方的童年》两部电影，之后的一段时间里，心里面总感觉热腾腾的难以平复。这两部影片都是豆瓣高评却冷门的国内电影，剧情朴实，画面感人，内容也非常真实，典型的回忆杀，影片的很多镜头都能让人回想起童年时候的自己，山坡、绿林、青草、池蛙、还有那田间小路，仿佛昨日一般，渐渐地将自己带入到童年的生活之中，沉睡的心也随之苏醒，就连听的歌，也都可以追溯到上个世纪了。罢了罢了，言归正传，谈谈这一路丢失的2020吧！&lt;/p&gt;
&lt;!-- ![](/assets/articleImg/2020/xiyang.png) --&gt;
&lt;img src=&quot;/assets/articleImg/2020/sz-night.png&quot; width=&quot;100%&quot;&gt;
&lt;div class=&quot;caption&quot;&gt;『夜幕来临前的深圳湾——with XL』&lt;/div&gt;
    
    </summary>
    
      <category term="生活" scheme="https://www.csuldw.com/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="时年" scheme="https://www.csuldw.com/tags/%E6%97%B6%E5%B9%B4/"/>
    
      <category term="杂谈" scheme="https://www.csuldw.com/tags/%E6%9D%82%E8%B0%88/"/>
    
  </entry>
  
  <entry>
    <title>2019，黑与白的旅行</title>
    <link href="https://www.csuldw.com/2019/12/31/2019-12-31-annual-summary/"/>
    <id>https://www.csuldw.com/2019/12/31/2019-12-31-annual-summary/</id>
    <published>2019-12-31T15:44:00.000Z</published>
    <updated>2020-04-15T15:05:04.020Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><img src="/assets/articleImg/2019/princes.png" width="100%"><p>2019年，正式步入了工作的第三个年头，也是踏入社会的第二个完整年，没有风风火火，也没有冷冷清清，一切平静而安详，似乎“山雨欲来风满楼”。放下手中的手机，停下眼前的键盘，翻阅着过去这些年的经历，零零碎碎的画面又在脑子里浮现而开，有无数个难忘的瞬间，也有模糊的已经记不清的镜头。2019，注定是一场黑与白的旅行。</p><a id="more"></a><p>夜，很深，空气里弥漫着一股凉意，月光从窗户顺着浅黄的窗帘打落在阳台上，阳台的一旁正在点着白色透明的精油熏香，一股淡淡的薰衣草清香顺着空气的流动扑鼻而来，闭上眼睛，聆听着低沉的心跳声，脑海里一遍又一遍的回旋着这一年发生的事情，夜难眠……</p><p>对于略微有点强迫症的自己，真是没法了！先来一段小文总结一下吧，折煞自身。</p><center><p>一月风气清，开门喜迎新。<br>二月新春到，灯下醉人行。<br>三月庭树嫩，奈何腿闪胫。<br>四月清和雨，葵花向日倾。<br>五月初游港，尔后梧桐行。<br>六月苦作粥，闲看夕阳红。<br>七月周年至，回首汗漓淋。<br>八月宴席庆，生后入菩提。<br>九月天空静，初秋万景清。<br>十月遇雪莲，心似夏日暖。<br>十一枫又红，华大普天兴。<br>十二更鼓急，回梦寻初心。</p></center><h2 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h2><p>年初的时候，互联网上出现了一波996-ICU的风波，最后也是不了了之。对我来说，可能还算幸运，没有完全的过上996或是9117的生活，只是偶尔周末加加班，不过对于工作，该尽的责任还是不会推脱。今年在工作上的变化比较大，上半年因为工作性质的改变，需要带外包做项目，每天早上晨会再加上小组内部长时间的讨论会，时常还会拉Espace会议，一个个Welcome to join the conference，真的让人有些无法自拔。回头想想，这应该也算是华为人的一种磨炼吧！下半年，切换了小组，工作氛围比起之前要好一些，少了很多浮躁、争执、吵闹的画面，周围也清净了许多，做事情反而感觉轻松了很多。可能我本身就是一个不喜争执的人，遇到说话大声或是吵架的场面，通常都会敬而远之，怼人这种事，还是留给别人来做好了，自己做好本职工作就行！关于公司或是工作的其他事情，就不在这里阔阔而谈了，一直都是在变化中前进。总的来说，还是希望2020年，自己能够独当一面，遇事不慌。也希望公司，能够走的更好。</p><h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><p>经常看到有人调侃说，程序员除了工作，基本没有生活。工作996，穿的是格子衫，背的是黑色电脑包，戴的的黑框眼镜，另外牛仔加白袜，一双运动鞋，画面感十足。还有就是在北京西二旗的地铁上，从上往下一眼看去，头部一半黑一半秃，想想还有点搞笑，真是这么现实。说到自己，与同学聚餐的时候，时常也有人会问起，“你们公司目前怎么样了？”，“你们今年是不是特别忙？”，“你们是不是人均发了@）w？”，嗯，姚明跟潘长江的平均身高1米93呢。[敲黑板]，好了，实话说，一切都还好，对于我来说，或许就是少一些仪式感。所谓仪式感，就是让某一天显得不同，使某一时刻比其他时刻更为重要。工作需要仪式感，节日需要仪式感，生活也同样需要仪式感。只是这仅仅是在理想的状态下，现实生活中的我们，变化的东西实在太多了。就我自己而言，今年也在慢慢得从变化的节奏中形成一些自己的习惯，比如跑步、去书店看书、写博文等，坚持下来的东西，坚持下来的东西，一旦不做了，心里都会有一种“负罪感”（严重了）。</p><img src="/assets/articleImg/2019/weekend.png" width="90%"><div class="caption">『周末的时候，偶尔也会出去转一转，深圳湾公园、梧桐山、咖啡厅...』</div><p>“读史使人明智，读诗使人灵秀”，今年的书籍清单中，除了专业书籍之后，还多了几本床头读物。印象比较深的还是《肖申克的救赎》，电影已经不记得是第几遍了。前段时间在公司心声里面，有同事引用了肖里面的一句话“有些鸟注定是不会被关在笼子里的，因为它们的每一片羽毛都闪烁着自由的光辉”。的确，这或许也是这本书带来很多人希望的一面。不管世界多么不堪，不管生活多么艰辛，总有人会仰望着星空，抬头也总会有见到阳光的一天，希望也总在牵引着你变得更好。《肖申克的救赎》里面还有一个叫做“体制化”的东西。说到体制化，最典型的就是肖里面的图书馆老头布鲁克斯了，什么是体制化呢？里面有这样一段话，”<strong>这些墙很有趣。刚入狱的时候，你痛恨周围的高墙；慢慢地，你习惯了生活在其中；最终你会发现自己不得不依靠它而生存。这就叫体制化。</strong>“，布鲁克斯最终有幸离开了监狱，却不知自己早已习惯了监狱里的生活，因为无法适应外面的世界而选择了自杀！看到这里，或许该有所感触，或许算是一种警惕！不管是在工作中，还是生活里，一定不要让自己过得太舒适了，只有心存危机感，才能在这个世界上活的更久更长，才能不被这个时代所淘汰，才能适应多变的社会环境。当然除了《肖申克的救赎》，还看了《黎明之街》、《一只独立独行的猪》、《偷影子的人》等等等等。</p><p>今年让自己比较满意的是，坚持了技术博文的总结，写了20+篇技术文章，公众号也发布了几十篇源码分享类文章。关于文章写作，还是得自己先学点东西，然后才有方向，才有内容可以去写，写出来的东西才是干货。上半年的时候，由于学习范围和目标比较广，所以没有固定的学习领域。下半年，由于工作性质的变化，对知识图谱的接触比较多，因此便开始了KG的学习。八月初的时候，就开始制定学习计划，从数据爬取，到数据分析，然后再构建知识图谱，最后落地到知识图谱应用：如QA问答和图谱搜索等。为了能够自己做出点东西，八月份花了几千买了一台三年的服务器，用起来还比较顺手，就是感觉内存有点不足。在数据爬取这块，来来回回算起来有将近3个周末的时间，从豆瓣爬取了将近千万的电影电影影评数据，后来基于这个影评数据做了一系列的分析，包括基本的统计、情感分类、图谱问答，源码已经分享到了Github上面，star数量也在逐步增加，算是打上了一个圆满的句号。一路实践过来，确实得到了不少锻炼。在图谱应用这一块，由于自身能力和时间的限制，导致文章和知识的深度有些不够。至于QA问答，做的还比较简单，主要是基于KG与模板的电影QA，当前能够回答的类型还比较少，有待进一步改进，后续有想法将其改成基于知识图谱的搜索问答。关于图谱搜索这块，现在也还没有很好的工程落地，前端页面已经设计好了，并且也采用vue框架搭建了整体的布局，目前为止关于图谱接口这块一直没有想到很好的方法来实现，有待2020年继续深研。这阵子，经常在公众号后台收到很多同学的留言，大多都是关于QA问答的源码，在这里跟大家说声抱歉，QA问答模块一直想将其整理出来，只是下半年忙着其他的事情，同时因为代码结构比较粗糙，有点撒不出手。2020年，一定将其整理成文，公布出来，比较急的童鞋可以参考下这篇文章<a href="https://www.csuldw.com/2019/08/25/2019-08-25-kb-and-gb-movieqa/">基于知识库与知识图谱构建电影问答系统</a>,核心部分已经在文章中发布出来了，接口采用的是flask发布的RESTful API，模板分类算法采用的是简单的NB，其他的都比较简单了，希望能够帮到各位童鞋。</p><p>关于文章发布，今年又增加了一个出口。以前都是在自己的站点domain下进行发布，今年下半年很幸运的将自动注销几年的公众号重新找回来了，带有评论功能（新注册的公众号都不带评论），文章的首发地址也就多了一个。关于用户运营，的确是一门艺术，以前并不care这些，因为只care功能是否实现。今年九月的时候，想到将文章放在公众号上会比较方便查看，于是就有了运营公众号的想法。目前为止，公众号订阅人数有170+，因为想要搞一个原创的公众号，所以内容还比较少，更新也比较慢。其实做这种，真的得花费很多精力，很想拉几个小伙伴一起来运营这个，每个月一人一篇，确保每周公众号内容不间断，而且要保证内容的质量，如此周而复始，一段时间之后肯定会有所成果的。</p><p>今年心态也好了很多，不再像刚来深圳那会，做事有些心急。在学校的时候，计划往往都是短期的，现在，计划的东西往往不能短期完成。主要是明白了贵在坚持的重要性，能够不间断的持续做一件事才是最难得的，也希望自己能够一直坚持下去。因为学无止境，所以自我总结也是无止境的！突然想到了自己的域名，<code>csuldw.com</code>这个域名已经维护了将近5年多了，坚持维护下来的东西，自己都舍不得抛弃他。就像是你自己亲手培养起来的孩子，看着一点点的成长起来，内容逐渐的丰富起来，偶尔点开，也会满怀喜悦，高兴不已。话说回来，应该也有很多熟客了。前两天，在公司的w3里面搜索自己，发现自己以前的文章在自己还没来公司的时候就转到公司平台了，看到之后真的有些兴奋。知识在于分享，虽然自己文笔一般，但分享出来的东西，回过头来温故的时候，还是很激动的！今年还开了几个二级域名，折腾的小心思又萌动了。</p><p>今年与朋友同学的聚餐比去年多了很多，一方面是时间宽松一些，另外是自己去南山的次数也多了些，有时则是去朋友那边蹭饭吃，顺便再聊聊近况或是吐槽一下周边的事情。端午的时候，本来是准备组织去澳门，结果好几个通行证过期了，然后准备去广州，看看小蛮腰，因为票比较紧张也没去成，又准备去海岛游，结果蛇口那边的船票不够，实在无奈，最后就一起去爬了梧桐山。六月的时候，说是七月去一趟伶仃岛或是东澳岛，后来因为台风来临，也是将所有行程都取消了。再后来，因为周末的计划都已定下，也就没有出去旅行的计划了。</p><p>今年又正式get了一个新技能——熏香。不管是学习还是工作，时间久了都会让人感觉有些疲惫。忙碌一天回去之后，开始尝试使用精油来缓减自身的疲劳。晚上或是周末，打开熏香机，加入少许水，再滴上几滴精油，在一定程度上也是可以缓减一下疲劳的。除了这种方式，还可以将精油稀释之后放在精油滚珠瓶中，这样出去之后就方便携带了。关于精油，种类比较多，用途也比较广，自己用的比较多的还是薰衣草、薄荷、茶树、柠檬等。薰衣草可以说是居家出行必备良品，不仅可以帮助睡眠，还有抗感染、抗炎、安抚神经、舒缓的特性；茶树的特性则比较特殊，有抗真菌的作用，对于皮肤过敏和皮肤再生有帮助，同时对于祛疤有好处；薄荷的好处就是对于运动之后的肌肉不适有舒缓作用，同时在抗炎和呼吸道感染方面有效果。不过精油的种类太多，自己了解的东西还比较少，有时间再请教下那位良师益友<span class="github-emoji" style="color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f604.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png?v8">😄</span>。</p><img src="/assets/articleImg/2019/xunxiang.png" width="60%"><div class="caption">『周日的下午，滴上几滴薰衣草精油放入熏香机，放松一下，缓解一下脑部压力』</div><h2 id="休闲"><a href="#休闲" class="headerlink" title="休闲"></a>休闲</h2><p>首先来说说跑步，自从三月份脚扭到之后，持续了大半年没有去跑步，直到国庆回来，才开始逐步恢复原有的状态。从最开始的2km，到3km，再到4km，最后稳定在5km，时长大概半小时，每周三次，如果加班稍微晚了点，也会尽量完成当天的运动，如果超过两天没去跑了，那第三天一定得去完成任务。目前坚持了近三个月，算是打破了自己有史以来最长的记录了。以前在学校的时候，并没有这么统计过，整体上悠闲很多，在图书馆看完书想去跑就去操场跑几圈，少了一些自我督促。关于看书，主要还是在周末。今年还是有着懒床的坏习惯，说是懒床，不如说是熬夜吧！仔细回想一下，熬夜的习惯似乎并不是今年形成的，2018年的时候，不知不觉的每天晚上熬到了很晚，习惯也就形成了。周末只要熬了夜，第二天上午基本上会睡到将近九点，有时则会持续到十点。醒来之后，如果感觉不累，就会去菜市场买点菜，然后中午自己开锅。想起之前在学校，不管是节假日，还是周末，自己都会在八点之前起来，现在真是改变了不少。下半年，为了换一种方式生活，周末便开启了自己的读书计划。以前待在家里，靠着意志力来监督自己完成相应的任务项，后来为了更有学习氛围，周末通常都会去书店待上一下午，书店的氛围的确好很多。在那里，有人在备战英语，有人在移动办公，有人则在读一些文学作品，还有一些学生（其中也包括小学初中的小朋友），在书店看书写作业，也有一些小朋友约在了咖啡厅玩游戏。说实话，打心底我还挺羡慕这群孩子的，可以在这种氛围下成长，学习资源如此丰富，真的很难得。像他们这个年纪，自己应该还在玩过家家！说到这里，突然想到了两部电影，看过《钢琴家》和《辛德勒的名单》的朋友应该都知道，犹太人在里面真的毫无地位可言，战争带给他们的痛苦和无奈是我们无法感同身受的，真的很庆幸能够生活在现在这个和平的世界里。</p><img src="/assets/articleImg/2019/keep-data.png" width="80%"><div class="caption">『十月开始，每周三次，跑前拉伸8min，跑步近30min，大概5.2公里，跑后再拉伸5min，很欣慰的是腿部的扭伤在渐渐消退，所谓的“伤筋动骨一百天”，真的不止一百天，“一朝被蛇咬十年怕井绳”，以后赶时间的时候还是小心跑为妙。以前，跑步并没有特别的注意服装之类的，十二月天气转凉，自己也开始讲究了起来，顺手入手了一套夜跑服装，认真起来的感觉真的不错，继续保持~smile:』</div><p>关于读书的地点，今年去的比较多的地方还是宝安中心壹方城的覔书店。一杯咖啡、一台电脑、一本书、一支笔，一本笔记本、一个下午足矣。在覔书店，唯一的缺点就是网速太慢，连服务器的体验真的太差。明年，应该会转向其他地方，大致罗列了一下，按照星级程度来选择吧，如有朋友在2020年的书店里偶遇，一定请你喝杯咖啡：</p><ol><li>深圳书城（福中一路店）：五号线到深圳北转四号线，少年宫下车，D口出门右转，走100米可达深圳书城，二楼有24小时书吧，优点是环境好，周围吃的多，氛围也好，对着窗户下午的时候可以看到夕阳的余晖，很惬意……路程时长40分钟，缺点是需要中转（好感指数：★★★★☆）。</li><li>覔书店（壹方城）：五号线直达宝安中心，进入三层，走到尽头就可以看到覔书店，优点是直达，缺点是网速不佳（好感指数：★★★★☆，保留）。</li><li>覔书店（九方购物中心）：五号线到深圳北转四号线，到红山站下车，A出口，步行800米左右，到达九方购物中心，覔书店在B1，有点是与朋友隔得近，缺点是地方在负一楼，空气不是很好（好感指数：★★★☆☆）。</li><li>西西弗书店（壹方天地）：五号线到深圳北转四号线，到龙华站下车，步行到壹方天地A区，L1西西弗书店，优点同上，缺点是咖啡厅的地方有点西晒（好感指数：★★★☆☆）。</li><li>深圳书城（罗湖店）：五号线到黄贝岭，转十号线到地王大厦，出地铁口就是，附近可以到万象城，里面就还有西西弗书店（好感指数：★★★☆☆）。</li></ol><p>今年没去很远的地方旅行，唯一出行游玩的地方，就属香港了。当时正是五一，好在没什么其他的事情，就跟朋友一起去了趟香港，脑门子一热买了一台Mac，2w+人民币，真是有点大放血，算是目前为止自己买过最贵的电子产品。印象中的香港，并没有多么吸引人，东西比内地贵，大排档随随便便就是五六百，吃起来也不合口味，如果真要我选择，我还是愿意待在内地，比如深圳或是长沙。选择深圳，是因为这里发展很快，环境适宜；选择长沙，是因为待得很久，很熟悉，适合生活，节奏平缓。虽然远行的计划并没有，但多了一点户外运动。两次梧桐山，一次塘朗山。去梧桐山的时候，同行的朋友/同学都说很累，到了梧桐山好汉坡的坡脚下时，就望而生畏，止步不前了，也是唯一的一点遗憾，两次都没有爬上大梧桐。不过话说回来，爬山也是在于放松，释放自己，能够一起开开心心的边走边玩，也不失为一种乐趣。</p><img src="/assets/articleImg/2019/tanglang1.png" width="80%"><div class="caption">塘朗山，候鸟飞，虫草戏山涧。<br>金秋月，三人行，杯酒话深林。</div><p>国庆回家的时候，翻出了好多年前买的笛子，只是笛膜已经干化了，这次回深也将它带了出来。重新添上笛膜之后，发现音质并不是很好。说来也是惭愧，能够脱离曲谱的曲子寥寥无几。自己比较熟悉D调，对着曲谱吹奏还算OK。在卧室里，因为笛子声音太大，自娱自乐的时间也比较有限，太晚了吹奏还是感觉会有点扰民，如果是在山上那种空旷的地方，感觉或许更好！不经意间，想到了另一种乐器——陶笛。这种乐器声音不是很大，之前去桂林的时候，在阳朔的小街道上看到一家店铺的外面有人在吹奏，声音甚是好听，那歌曲好像是《斯卡布罗集市》吧。念头如火苗般慢慢变大，于是在双十二的时候，便入手了陶笛。原本是想直接学习十二孔陶笛，结果店家送了我一个六孔的，于是就从六孔的开始了。对着曲谱，一首《成都》也可以随之而来……整体感觉就是，六孔陶笛的指法比较简单，而十二孔的真的有点难了，打算先练习六孔的，熟悉之后再学习十二孔的，后面找机会再看看是不是可以学习下埙。这种音色古朴、低沉、沧桑、神秘而哀婉，似乎一出声就有一种悲情在里面，说到这里莫名的又想到了二胡。那个戴着墨镜，坐在石头上，衣衫破旧但却不失整洁的人会不会是我呢<span class="github-emoji" style="color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f603.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f603.png?v8">😃</span>，嗯，或许曾经他是个程序猿[捂嘴笑]。[敲黑板]开个玩笑，回到正题来。今年学习了几节课的乐理知识，对陶笛、笛子的吹奏还是有一定的帮助，因为没有制定这个计划，算是临时加上的，就当是体验课吧，明年好好计划一下，工作大概率比今年要忙一点，可能还会去拉美出差，也不一定，先计划着吧！</p><p>电影方面，今年去电影院看的电影还算好，相比去年要看的多一些，除了公司OEC组织的，大多都是跟朋友一起去看的，当然也有一些好电影自己一个人也会去看。以前在北京实习的时候，每个周末都会去看电影，有时候是自己去，有时候跟同事去，现在去的次数少很多了。今年比较喜欢的有《复仇者联盟4：终局之战》，三个小时，一句“I love you three thousand times”，画面真的太感人，可惜钢铁侠再也回不来了；《调音师》，一个让人猜不到结局的悬疑类电影，强烈推荐下；《哪吒之魔童降世》，有种童年的影子；还有《流浪地球》、《海上钢琴师》、《中国机长》等，也许是因为年纪大了，变得容易感动了起来，看到有些画面，也会顿生感触而流下眼泪，甚至是在家里看《小欢喜》的时候，也是被感动的满满都是泪水<span class="github-emoji" style="color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f602.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f602.png?v8">😂</span>！有的电影则因为没有赶上档期，后来只好用VIP看了。另外，不知是何原因，今年突然又迷上了动漫，以前喜欢看，追过《柯南》、《网球王子》、《海贼王》、《东京喰种》等等等等，有的追到一半就没追了，今年首先是《斗破苍穹》，目前第三季已经结束了，期待番外篇的到来，一时兴起把原著给看完了，可惜五帝破空之后没得看了。接着就是《斗罗大陆》、《武动乾坤》、《天行九歌》，动漫里面的男主光环真的是特别厉害，目前比较期待的就是《斗破苍穹》和《武动乾坤》的下一季，希望2020年不负期待。对于电视剧，今年都是断断续续在APP上看一些，比如一直追到今年剧终的《权力的游戏第八季》，一些国产电视剧《都挺好》、《小欢喜》、《破冰行动》、《老酒馆》等，偶尔也会看看韩剧悬疑类的，像《监狱医生》，还有一些整体上感觉不是很好，纯当打磨时间了！</p><p>对于游戏，自己并没有沉迷在上面，只是偶尔想玩一下。比较有意思的是过年的时候被自己三四岁的侄子带着，一起玩起了吃鸡<span class="github-emoji" style="color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f60a.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f60a.png?v8">😊</span>，小侄子真的是有意思，头脑转的贼快，还要指挥队友跟他走，真的服呐<span class="github-emoji" style="color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png?v8">👍</span>，不听他的他还说不跟你玩了，真的是可爱！对我来说，吃鸡真的有点飘，落地成盒也不是不可能的！！另外就是王者荣耀，单排上王者基本上没什么压力，但是两人双排，就很难了。并不是说两个人水平不行，而是双排碰到的对面也是多排，容错率就会低很多。说到游戏，突然想到有一次，跟亮亮和沛公一起去游戏厅寻找童年，走了好几个商场，去过好几个电玩城，都没找到《三国战纪》、《西游记》、《恐龙》之类的游戏。讲真，90后的童年在大城市已经找不到了，都是10后的小朋友的游戏了<span class="github-emoji" style="color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f602.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f602.png?v8">😂</span>。很多东西，也只能存在回忆里了，罢了罢了！对了，下半年小组组团去打了一次保龄球，手感还不错，拿过几次满贯<span class="github-emoji" style="color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f604.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png?v8">😄</span>，就是差点把腿给闪到，好在有惊无险！也算是GET到了一个新技能。</p><h2 id="余年：Grow-up，not-grow-old"><a href="#余年：Grow-up，not-grow-old" class="headerlink" title="余年：Grow up，not grow old"></a>余年：Grow up，not grow old</h2><p>周围的同学里面，今年没有结婚的，朋友圈里倒是有许多结婚的。值得庆祝的是好同学昊子在中秋前当爸爸了，从16年的平安夜里求婚，到17年国庆结婚，再到现在，三年时间，真是不容易。身份转换之后，明显的感觉到这位大佬跟之前不太一样了。或许是因为责任大了，或许是因为负担大了，又或许是因为身份不一样了。家家有本难念的经，再次祝贺一下这位连手机号码尾号都跟我一样的好哥们、好同学、好损友，祝阖家欢乐，平平安安。</p><p>2019年，选择性的沉默起来，有些话，有些事，止于唇齿，掩于岁月。情感方面，今年并没有什么变化。虽然比较期待开始一段美好的生活，但自己的性格一直在督促自己，不要因为家里面的催促而去将就。当然，如果在生活中有很合得来的人，自己肯定会去努力的。在家中，自己是最小的一个，以前在学校读书的时候家里并没有催促。自去年过年开始，父母就会偶尔提醒一下，亲戚也会顺着问一下，今年提醒的次数多了很多，不过每次都被自己笑着搪塞了过去。未来的事情，不确定太大，所以自己也在努力去朝着某个目标前进，去提前了解一些事情，比如社保、医保、转户、买房、买车之类。之前有个关系很好的同学问我，工作之后，是打算先买房还是先买车，当时我的回答是买房。现在想想，对于目前的自己来说，在深圳买房真的有点困难。如果选择二线城市，如何去选择又是一个问题。话说回来，此刻的想法或许在以后看来都会显得比较幼稚，写下来就当是自己一时的观点吧，因为人的想法是会改变的！Grow up，not grow old！</p><img src="/assets/articleImg/2019/the-setting-sun.png" width="80%"><div class="caption">最美的黄会后，是最黑的夜</div><p><em>不管云有多高 都是灵魂的精彩</em><br><em>不管雨有多大 都浇不灭</em><br><em>这颗炙热的心 和微笑</em></p><p>现在是2019年12月31日零晨，预祝大家新年快乐，元旦节快乐！2020年，希望自己能够应对不同的挑战和变化，也希望能将计划的事情做的更好，不负年华。</p><p>History Summary：</p><ul><li><a href="http://www.csuldw.com/2018/12/31/2018-12-31-treat-yourself/">2018，善待自己</a></li><li><a href="http://www.csuldw.com/2018/01/02/2018-01-02-annual-summary/">2017，不再见</a></li><li><a href="http://www.csuldw.com/2016/12/31/2016-12-31-annual-review/">2016，明天你好</a></li><li><a href="http://www.csuldw.com/2015/12/31/2015-12-31-annual-summary/">2015，稳稳地幸福</a></li><li><a href="http://www.csuldw.com/2014/12/31/2014-12-31-keep-silence/">2014，静下来</a></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/assets/articleImg/2019/princes.png&quot; width=&quot;100%&quot;&gt;


&lt;p&gt;2019年，正式步入了工作的第三个年头，也是踏入社会的第二个完整年，没有风风火火，也没有冷冷清清，一切平静而安详，似乎“山雨欲来风满楼”。放下手中的手机，停下眼前的键盘，翻阅着过去这些年的经历，零零碎碎的画面又在脑子里浮现而开，有无数个难忘的瞬间，也有模糊的已经记不清的镜头。2019，注定是一场黑与白的旅行。&lt;/p&gt;
    
    </summary>
    
      <category term="年度总结" scheme="https://www.csuldw.com/categories/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="总结" scheme="https://www.csuldw.com/tags/%E6%80%BB%E7%BB%93/"/>
    
      <category term="2019" scheme="https://www.csuldw.com/tags/2019/"/>
    
      <category term="年度总结" scheme="https://www.csuldw.com/tags/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>关于域名与Nginx反向代理的一些事儿</title>
    <link href="https://www.csuldw.com/2019/11/10/2019-11-10-nginx-reverse-proxy/"/>
    <id>https://www.csuldw.com/2019/11/10/2019-11-10-nginx-reverse-proxy/</id>
    <published>2019-11-10T07:31:00.000Z</published>
    <updated>2019-11-10T07:31:46.584Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>前几天，tx云的客服突然打电话给我，说我的域名备案有问题，一是域名绑定解析的服务器非tx云服务器；二是网站内容带有评论，属于交互式类型，与备案不符。限一天之内整改，否则域名将无法接入tx云。当时还在上班，也没多谈。晚上回去之后，没时间去修改，第二天直接被邮件通知说已上报管局。这波操作真的是有点蛮横霸道，不讲情面，毫无商量的余地啊！原本我的一级域名托管在Github是没有问题的，只是想开通下二级域名，而将二级域名绑定到tx云服务器，需要备案才行。现在备案不成，一级域名也被将被列入“黑名单”了。可能是因为与处女座隔得太近的原因，心里面对这个事情一直放不下，趁着周末时间充足，就想着抓紧时间把这个问题给了结了。</p><a id="more"></a><h2 id="问题回顾"><a href="#问题回顾" class="headerlink" title="问题回顾"></a>问题回顾</h2><p>上面提到的主要有两个问题，第二个问题属于内容上的，对于网站来说，解决起来不是很麻烦，关键是想不想撤掉评论了。目前自己使用的是disqus，纯粹嵌入进来的，暂且不管吧。后续如果站点被封了，再想其他的方法解决好了。对于第一个问题，其实也有个方法，就是在服务器上部署一套编译hexo的node环境。但这对于服务器来说，不是很好，毕竟服务器的内存有限，上面还部署了neo4j来构建图谱QA，以及一些python服务等。能节省资源就节省下，毕竟都是穷孩子。那么，有没有更好的方法呢？</p><p>晚上睡觉前，仔细想了想，若要自己的站点内容不变，并且还要满足域名绑定的是tx云服务器，能够想到的就是采用反向代理，将一级域名绑定到tx云，然后再通过nginx转发到github上去。说起来好像有点道理，真要实现起来，还是需要点工程能力才行。前段时间，刚好在服务器上配置了二级域名的转发，这次基于之前的配置稍作修改应该就OK了。实际上，说简单也不简单，说不简单其实也比较简单，关键就是在于是否了解它。闲话不多说了，下面来看看具体实现！</p><h2 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h2><p>上面提到了反向代理，那么究竟什么是反向代理呢？举个栗子吧。</p><p>对于铁路来说，大家都比较熟悉，铁路客户服务中心的客服电话是12306，它是一个统一的客服电话入口，当我们需要咨询或是投诉铁路订票、退票相关问题时，只需要拨打12306电话，然后按0进入人工服务台即可，对面究竟是谁来接，我们不care，我们唯一需要确定的是，对面会有人来回应我们的电话（相当于服务器响应客户端请求），即使是很多人在同一时刻拨打12306（并发），也能得到响应。这个场景里面，拨打电话的我们，就是Client（客户端），而12306的客服就是Server（服务端），服务端采用了统一的入口，具体如何分发或转接，对于Client来说就类似一个黑盒。反向代理就是这个道理，如Fig 1所示，它代理的就是Server端。</p><!-- ![](/assets/articleImg/2019/reverse-proxy.png) --><img src="/assets/articleImg/2019/reverse-proxy.png" width="60%"><div class="caption">Fig 1.反向代理原理图（source: https://dev.to/remyg/nginx-reverse-proxy-54d7）</div><p>了解什么是反向代理之后，下面来看看在我这个场景里面如何应用。</p><h2 id="反向代理的实现"><a href="#反向代理的实现" class="headerlink" title="反向代理的实现"></a>反向代理的实现</h2><h3 id="方法一：反向代理至Github"><a href="#方法一：反向代理至Github" class="headerlink" title="方法一：反向代理至Github"></a>方法一：反向代理至Github</h3><p><strong>链路</strong>：一级域名-&gt;云服务器(proxy)-&gt;Github。</p><p>一级域名绑定服务器的具体方法这里就不一一展开了，如Fig 2所示，通过下面的配置绑定之后，就可以通过<a href="http://www.csuldw.com">http://www.csuldw.com</a>直接访问服务器的80端口了。想要进一步进行转发，就需要nginx来的协助了。  </p><p><img src="/assets/articleImg/2019/domain-parsing-1.png" alt=""></p><div class="caption">Fig 2.一级域名解析</div><p>nginx代理配置如下，它监听的是80端口，同时域名为一级域名，在location上面，首先配置的是“/”，设置它的<code>proxy_set_header</code>和<code>proxy_pass</code>为<code>github.io</code>的子域名，该子域名能够直接访问我托管在github上面的项目。配置完了之后，整条链路就已经打通了，不过图片之类的还是无法显示，还需要将图片之类的转发到github上。</p><figure class="highlight nginx"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">server</span> {</span><br><span class="line">    <span class="attribute">listen</span> <span class="number">80</span>;</span><br><span class="line">    <span class="attribute">server_name</span> csuldw.com www.csuldw.com;</span><br><span class="line">    <span class="attribute">root</span> html;</span><br><span class="line">    <span class="attribute">location</span> / {</span><br><span class="line">        <span class="attribute">proxy_set_header</span> Host csuldw.github.io;</span><br><span class="line">        <span class="attribute">proxy_pass</span> http://csuldw.github.io;        <span class="comment">#转发到github</span></span><br><span class="line">        <span class="attribute">proxy_set_header</span> X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">        <span class="attribute">proxy_set_header</span> X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="attribute">location</span><span class="regexp"> ^~/assets/</span> { </span><br><span class="line">        <span class="attribute">proxy_pass</span> http://csuldw.github.io/assets/;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>通过上面的配置之后，一级域名解析的就是tx服务器了，同时项目的内容还是托管在github，变动的地方不大。然而让人愁的是访问速度太慢，于是便想到了下面这条链路。</p><h3 id="方法二：反向代理至二级域名"><a href="#方法二：反向代理至二级域名" class="headerlink" title="方法二：反向代理至二级域名"></a>方法二：反向代理至二级域名</h3><p><strong>链路</strong>：一级域名-&gt;云服务器(proxy)-&gt;二级域名（通过CNAME绑定到csuldw.github.io）</p><p>首先通过CNAME方式将blog.csuldw.com子域名绑定到csuldw.github.io，然后我们将之前nginx配置的直接转发到github的地方改成blog.csuldw.com就OK了。具体的配置内容如下：</p><figure class="highlight nginx"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">server</span> {</span><br><span class="line">    <span class="attribute">listen</span> <span class="number">80</span>;</span><br><span class="line">    <span class="attribute">server_name</span> csuldw.com www.csuldw.com;</span><br><span class="line">    <span class="attribute">root</span> html;</span><br><span class="line">    <span class="attribute">location</span> / {</span><br><span class="line">        <span class="attribute">proxy_set_header</span> Host blog.csuldw.com;</span><br><span class="line">        <span class="attribute">proxy_pass</span> http://blog.csuldw.com;        <span class="comment">#转发到github</span></span><br><span class="line">        <span class="attribute">proxy_set_header</span> X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">        <span class="attribute">proxy_set_header</span> X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="attribute">location</span><span class="regexp"> ^~/assets/</span> {</span><br><span class="line">        <span class="attribute">proxy_pass</span> http://blog.csuldw.com/assets/;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>这两条链路差别不大，但是效果却不一样，要是没尝试真的很难相信。做了上面的配置之后，顺便在nginx中添加了https（证书目前用的tx云解析的），配置如下，就当做个笔记，后续需要再来查看下！</p><figure class="highlight nginx"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">server</span> {</span><br><span class="line">    <span class="attribute">listen</span> <span class="number">443</span> ssl;  </span><br><span class="line">    <span class="attribute">server_name</span> www.csuldw.com csuldw.com; <span class="comment">#填写绑定证书的域名</span></span><br><span class="line">    <span class="attribute">ssl_certificate</span> /usr/local/nginx/conf/1_csuldw.com_bundle.crt;  <span class="comment"># 指定证书的位置，绝对路径</span></span><br><span class="line">    <span class="attribute">ssl_certificate_key</span> /usr/local/nginx/conf/2_csuldw.com.key;  <span class="comment"># 绝对路径，同上</span></span><br><span class="line">    <span class="attribute">ssl_session_timeout</span> <span class="number">5m</span>; </span><br><span class="line">    <span class="attribute">ssl_protocols</span> TLSv1 TLSv1.<span class="number">1</span> TLSv1.<span class="number">2</span>; <span class="comment">#按照这个协议配置</span></span><br><span class="line">    <span class="attribute">ssl_ciphers</span> ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;<span class="comment">#按照这个套件配置</span></span><br><span class="line">    <span class="attribute">ssl_prefer_server_ciphers</span> <span class="literal">on</span>; </span><br><span class="line">    <span class="attribute">location</span> / {</span><br><span class="line">        <span class="attribute">proxy_set_header</span> Host blog.csuldw.com;</span><br><span class="line">        <span class="attribute">proxy_pass</span> https://blog.csuldw.com;        <span class="comment">#转发请求</span></span><br><span class="line">        <span class="attribute">proxy_set_header</span> X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">        <span class="attribute">proxy_set_header</span> X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="attribute">location</span><span class="regexp"> ^~/assets/</span> {</span><br><span class="line">        <span class="attribute">proxy_pass</span> https://blog.csuldw.com/assets/;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>经过这番折腾之后，目前一级域名<code>csuldw.com</code>绑定的是自己的tx云服务器，经过nginx路由之后，会将一级域名指向二级域名<code>blog.csuldw.com</code>，而二级域名绑定的是<code>csuldw.github.io</code>，所以当我们直接访问一级域名的时候，实际上响应的页面就是<code>csuldw.github.io</code>。整个链路可能有点绕，很多童鞋可能也不会用到，这篇文章就当是一篇小结吧，后续如有用到，再来回顾下。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li>Nginx Reverse Proxy：<a href="https://dev.to/remyg/nginx-reverse-proxy-54d7" target="_blank" rel="noopener">https://dev.to/remyg/nginx-reverse-proxy-54d7</a></li><li><a href="https://en.wikipedia.org/wiki/Reverse_proxy" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Reverse_proxy</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前几天，tx云的客服突然打电话给我，说我的域名备案有问题，一是域名绑定解析的服务器非tx云服务器；二是网站内容带有评论，属于交互式类型，与备案不符。限一天之内整改，否则域名将无法接入tx云。当时还在上班，也没多谈。晚上回去之后，没时间去修改，第二天直接被邮件通知说已上报管局。这波操作真的是有点蛮横霸道，不讲情面，毫无商量的余地啊！原本我的一级域名托管在Github是没有问题的，只是想开通下二级域名，而将二级域名绑定到tx云服务器，需要备案才行。现在备案不成，一级域名也被将被列入“黑名单”了。可能是因为与处女座隔得太近的原因，心里面对这个事情一直放不下，趁着周末时间充足，就想着抓紧时间把这个问题给了结了。&lt;/p&gt;
    
    </summary>
    
      <category term="其他" scheme="https://www.csuldw.com/categories/%E5%85%B6%E4%BB%96/"/>
    
    
      <category term="nginx" scheme="https://www.csuldw.com/tags/nginx/"/>
    
      <category term="反向代理 - 二级域名" scheme="https://www.csuldw.com/tags/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86-%E4%BA%8C%E7%BA%A7%E5%9F%9F%E5%90%8D/"/>
    
  </entry>
  
  <entry>
    <title>NL2SQL概述：一文了解NL2SQL</title>
    <link href="https://www.csuldw.com/2019/10/20/2019-10-20-nl2sql-introduction/"/>
    <id>https://www.csuldw.com/2019/10/20/2019-10-20-nl2sql-introduction/</id>
    <published>2019-10-20T10:10:00.000Z</published>
    <updated>2019-10-20T10:46:16.610Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>对于NL2SQL，也许在以前很多人会比较陌生。自从今年6月天池出现首届中文NL2SQL挑战赛之后，算是掀起了一股浪潮，中文NL2SQL也可以说是得到了进一步的发展。NL2SQL是CUI（Conversation User Interface）的新兴研究热点，其研究目的是将用户输入的自然语言转为可用的SQL语句，提高用户查询数据的效率。笔者接触NL2SQL方向并不长，所以也不敢在各位大神面前班门弄斧。比起情感分析、推荐系统、知识图谱这些领域，NL2SQL的文章真是少到可怜。本文也是出于学习目的对NL2SQL方向进行概括和总结，要是相关童鞋也在做这个方向，我们不妨一起交流交流。</p><a id="more"></a><h2 id="什么是NL2SQL？"><a href="#什么是NL2SQL？" class="headerlink" title="什么是NL2SQL？"></a>什么是NL2SQL？</h2><p>NL2SQL(Natural Language to SQL)， 顾名思义，是将自然语言转为SQL语句。它可以充当数据库的智能接口，让不熟悉数据库的用户能够快速地找到自己想要的数据。举个例子来说吧，在某个周五的晚上，业务人员小李想写份工作报告，总结下这个月的工作情况。在内容上，有一处需要查看某个产品本月的销售总额，但公司却没有这方面的具体报表数据。小李心里琢磨着，好歹自己也学过数据库，要是知道这个数据在那张表里面就好了。为此，他给开发人员小王打了个电话，本想让他帮忙从后台数据库里查一下，可谁知小王已经趁着周末去度蜜月去了，然后又给另一个开发小夏打了个电话，结果无人接听，真是让小李愁的寝食难安呀！这时候，如果能够有一个搜索框，小李只需要输入”我想查看A产品9月份的销售总额”，最后返回给小李一个SQL语句或是查询结果，岂不大快人心哇。</p><p>上面这个例子就是NL2SQL的一个应用场景，无论结果是返回数字，还是将其以报表的形式展示给用户，都要经过NL2SQL这一过程。其实基于图谱的QA问答，本质上也与其类似，知识图谱问答是将用户的query转化为SPARQL，然后从图谱中搜索结果返回给用户。举个栗子，如图Fig 1所示，用户以文本的形式提出Question：“what ‘s the total number of songs originally performed by anna nalick？”，经过开发的系统解析之后，最后返回给用户的是一串SQL语句“𝑆𝐸𝐿𝐸𝐶𝑇 𝐶𝑂𝑈𝑁𝑇 𝑆𝑜𝑛𝑔 𝑐h𝑜𝑖𝑐𝑒 𝑊𝐻𝐸𝑅𝐸 𝑂𝑟𝑖𝑔𝑖𝑛𝑎𝑙 𝑎𝑟𝑡𝑖𝑠𝑡 = 𝑎𝑛𝑛𝑎 𝑐h𝑟𝑖𝑠𝑡𝑖𝑛𝑒 𝑛𝑎𝑙𝑖𝑐𝑘”，或是返回执行结果：1。</p><p><img src="/assets/articleImg/2019/brief-illustration-of-nl2sql.png" alt=""></p><div class="caption">Fig 1.NL2SQL图示[3]</div><h2 id="NL2SQL发展史"><a href="#NL2SQL发展史" class="headerlink" title="NL2SQL发展史"></a>NL2SQL发展史</h2><p>NL2SQL的历史悠久，早在1973年，Woods等人就开发了一个名为LUNAR的系统，可以回答关于从月球带回的岩石样本的问题。到了1978年，Hendrix设计了一个连接美国海军舰艇信息数据库的自然语言接口，名为LIFER/LADDER。这些系统仅仅支持特定数据库的单表操作。</p><p>近年来，研究人员也在尝试开发一个能够生成不同查询语句的复杂系统。在2008年，Siasar等人基于句法和语义知识的基本概念提出了专家系统，并提出一个能够从多个结果中选择一个合适查询语句的算法。随后，在2010年，Rao等人提出了一个包含简单和隐式查询的系统。2013年，Chaudhari使用原型技术实现了一个能够处理简单查询和聚合函数的系统。这两个系统也尚未发展到多表关联操作。2014年，Ghosh等人基于Chaudhari的研究成果，在其基础上又开发了一个自动查询生成器，它采用语音或自然语言文本作为输入，支持简单的嵌套查询和聚合操作，同时系统还能够处理那些明确指出的属性。同年，Reinaldha和Widagdo使用了不同的方法来研究用户不同形式的输入，他们采用语义规则来找出问题中出现的词与数据库中的属性之间的关系。2015年，Palakurthi等人提供了与属性类型和分类特征相关的信息，描述了不同属性出现在句子中的处理方式也是不一样的。2016年，Ghosal等人提出了一个系统，能够很好地处理多表简单查询，不过系统使用的数据字典有限。同年，Kaur and J, Jan 强化了系统的简单查询和连接操作，但不支持聚合函数、GROUPBY和HAVING等高级子句。Singh and Solanki也提出了一种将自然语言转为sql查询的算法。他们使用动词表、名词表和规则将属性和表映射到句子中的单词，系统还灵巧地处理了文本的模糊输入。2017年，Google开发了Analyza系统，一个以自然语言为人机交互的接口的系统，支持用户用自然语言做数据探索与数据分析。该系统已在Google两个产品中投入使用，一是Online Sheet产品的QA问答模块，二是提供了一个库存和收入数据数据库的一个访问入口。同年，Sukthankar, Nandan等人开发了nQuery系统，一个自然语言到SQL的查询生成器，支持聚合函数，以及where子句中的多个条件、高级子句（如order by、group by和having）操作。2018年，Utama, Prasetya等人开发了DBPal工具，一个面向数据库的端到端的自然语言接口。DBPal主要有两大特性，一是采用深度模型将自然语言语句转为SQL，二是在用户不知道数据库模式和查询特性的情况下，支持短语提问，同时支持用户查询扩展提示，有助于提高查询效果。</p><p>上述研究都是基于英文句子进行分析，中文NL2SQL的研究一直未有公开的进展。直到2019年6月，追一科技在天池平台举行中文NL2SQL比赛，这才有了中文NL2SQL的一席之地。</p><h2 id="业界数据集介绍"><a href="#业界数据集介绍" class="headerlink" title="业界数据集介绍"></a>业界数据集介绍</h2><p>关于数据集，目前比较火的英文数据集有WikiSQL、Spider、WikiTableQuestions、ATIS等，各个数据集都有各自的特点，下面简单介绍下这几个数据集。</p><ul><li>WikiSQL：该数据集是Salesforce在2017年提出的大型标注NL2SQL数据集，也是目前规模最大的NL2SQL数据集。它包含了 24,241张表，80,645条自然语言问句及相应的SQL语句。目前学术界的预测准确率可达91.8%。</li><li>Spider：Spider数据集是耶鲁大学于2018年新提出的一个较大规模的NL2SQL数据集。该数据集包含了10,181条自然语言问句，分布在200个独立数据库中的5,693条SQL，内容覆盖了138个不同的领域。虽然在数据数量上不如WikiSQL，但Spider引入了更多的SQL用法，例如Group By、Order By、Having等高阶操作，甚至需要Join不同表，更贴近真实场景，所以难度也更大。目前准确率最高只有54.7%。</li><li>WikiTableQuestions：该数据集是斯坦福大学于2015年提出的一个针对维基百科中那些半结构化表格问答的数据集，内部包含22,033条真实问句以及2,108张表格。由于数据的来源是维基百科，因此表格中的数据是真实且没有经过归一化的，一个cell内可能包含多个实体或含义，比如「Beijing, China」或「200 km」；同时，为了很好地泛化到其它领域的数据，该数据集测试集中的表格主题和实体之间的关系都是在训练集中没有见到过的。</li><li>The Air Travel Information System (ATIS)：ATIS是一个年代较为久远的经典数据集，由德克萨斯仪器公司在1990年提出。该数据集获取自关系型数据库Official Airline Guide (OAG, 1990)，包含27张表以及不到2,000次的问询，每次问询平均7轮，93%的情况下需要联合3张以上的表才能得到答案，问询的内容涵盖了航班、费用、城市、地面服务等信息。</li></ul><p>Github地址：</p><ul><li>WikiSQL：<a href="https://github.com/salesforce/WikiSQL" target="_blank" rel="noopener">https://github.com/salesforce/WikiSQL</a></li><li>Spider：<a href="https://yale-lily.github.io/spider" target="_blank" rel="noopener">https://yale-lily.github.io/spider</a></li><li>ATIS：<a href="https://www.kaggle.com/siddhadev/ms-cntk-atis" target="_blank" rel="noopener">https://www.kaggle.com/siddhadev/ms-cntk-atis</a></li><li>WikiTableQuestions：<a href="https://github.com/ppasupat/WikiTableQuestions" target="_blank" rel="noopener">https://github.com/ppasupat/WikiTableQuestions</a></li></ul><p>中文数据集目前只有追一科技在天池发布的比赛数据集，包括4万条有标签数据作为训练集，1万条无标签数据作为测试集。目前比赛第一名的成绩，准确率达到了92%。</p><h2 id="NL2SQL三层架构"><a href="#NL2SQL三层架构" class="headerlink" title="NL2SQL三层架构"></a>NL2SQL三层架构</h2><p>在学术界，NL2SQL技术已经形成了一套模式，Fig 2就是NL2SQL经典的三层架构。</p><!-- ![](/assets/articleImg/2019/three-tier-architecture-of-nl2sql.png) --><img src="/assets/articleImg/2019/three-tier-architecture-of-nl2sql.png" width="90%"><div class="caption">Fig 2.NL2SQL三层架构[9]</div><p>如上图所示，NL2SQL分为User query interface、Processing Unit、Database三部分，其中Processing Unit是整个架构的中心，也是语义解析的核心所在，打通了User与Database的交互通道，囊括智能分词、实体识别、知识检索等各个技术要点。在上述研究中，Processing Unit的内部算法也在逐步朝着深度学习的方向进展。下面，我们一起来看看几个经典的NL2SQL系统结构。</p><h2 id="Analyza系统结构"><a href="#Analyza系统结构" class="headerlink" title="Analyza系统结构"></a>Analyza系统结构</h2><p>Google在2017年，针对自身的业务特点开发了Analyza系统，整个系统结构如Fig 3所示。</p><!-- ![](/assets/articleImg/2019/google-analyza-system.png) --><img src="/assets/articleImg/2019/google-analyza-system.png" width="60%"><div class="caption">Fig 3.Google Analyza系统[7]</div><p>Analyza系统由四个组成部分：用户UI、Parser、Answering Engine和Storage。将三层架构的Processing Unit划分成Parser和Answering Engine两部分。下面我们来看看各个部分的作用。</p><ol><li>用户UI：用户交互界面，包括问句自动提示（如Fig 4所示）、可视化选择等功能。</li><li>Storage：Storage是数据存储中心，对应的是图中的Metadata，包括了Knowledge Graph、Intent words以及database schema信息。同时也会将用户的搜索log存储起来。</li><li>Parser：主要负责对user query进行parsing，包括了annotator(字符串匹配+NER+意图识别等一系列操作)、grammar（语法检测）、semantic predict（语义预测）、ranking（评分排序）。这部分会调用借助图谱来提高实体和关系识别精度。</li><li>Answering Engine：用于将语义解析的结果转换成SQL，包括表识别、查询语句生成器等，最终将结果（数据、可视化结果、SQL等）返回给user。</li></ol><p><img src="/assets/articleImg/2019/analyza-suggestion-in-user-interface.png" alt=""></p><div class="caption">Fig 4. The use of suggestions in a prototype user interface.[7]</div><h2 id="DBPal系统结构"><a href="#DBPal系统结构" class="headerlink" title="DBPal系统结构"></a>DBPal系统结构</h2><p>DBPal与Analyza的系统结构都有着NL2SQL三层架构的影子，只是细节上略微不同。与Analyza不同的是，DBPal主要由两部分组成，分别是神经查询翻译器（Neural Query Translator）和交互式的自动完成特性(Interactive Auto-Completion)。</p><img src="/assets/articleImg/2019/system-overview-of-DBPal.png" width="90%"><div class="caption">Fig 5.DBPal系统[4]</div><p>如Fig 5所示，左上部分集成了Query Suggestion &amp; Auto-Completion自动问句提示功能，不仅给用户提供更好的体验，更是引导用户得到更精确的回答。在Fig 4右侧，即Server-side，是DBPal的核心，它的主要目的是将用户query转为SQL，实现上将其看做是翻译任务，采用的是sequence-to-sequence 深度学习模型，数据也是通过RNN模型训练生成的，并在模型前后增加了许多预处理和后处理操作。</p><h2 id="NL2SQL实现简述"><a href="#NL2SQL实现简述" class="headerlink" title="NL2SQL实现简述"></a>NL2SQL实现简述</h2><p>对于NL2SQL的各个系统，在内部实现上，整体结构都大同小异，只是技术不同罢了。Fig 5描述了从Question到SQL生成的核心细节，简单来说，整个系统将NL2SQL分成了SQL几个子句的识别，包括SELECT clause、WHERE clause,当然可能还有group by、limit等等。每个部分又会牵扯很多的细节，比如table识别，属性识别，适当的添加索引等等。Fig 5是采用深度学习方法，通过encoder-decoder的方式进行NL2SQL的实现。Google的Analyza采用的则是语义解析和规则的方式构建的，paper中解释主要还是因为数据的问题。</p><p><img src="/assets/articleImg/2019/illustration-of-nl2sql-approach.png" alt=""></p><div class="caption">Fig 5.NL2SQL实现图示[3]</div><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>对于NL2SQL，笔者在工作中也深深感受到它的难度，通过这些Paper的指引，大致做出了一个NL2SQL的雏形，后续还需要不断提升。本文主要是对NL2SQL做一个大致的总结，内容比较随性，浅尝辄止，如果针对相关的内容有疑问，可以看看对应的论文。最后，各位看官如是对NL2SQL感兴趣或是正在研究这方面的东西，不妨加个微信，一起探讨下中文NL2SQL的工业实践!</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li>Dar, Hafsa Shareef, et al. “Frameworks for Querying Databases Using Natural Language: A Literature Review.” arXiv preprint arXiv:1909.01822 (2019).</li><li>Hiregoudar, Shravankumar, Manjunath Gonal, and K. G. Karibasappa. “Speech to SQL Generator-A Voice Based Approach.”</li><li>Sun, Yibo, et al. “Semantic parsing with syntax-and table-aware sql generation.” arXiv preprint arXiv:1804.08338 (2018).</li><li>Utama, Prasetya, et al. “An End-to-end Neural Natural Language Interface for Databases.” arXiv preprint arXiv:1804.00401 (2018).</li><li>Xu, Xiaojun, Chang Liu, and Dawn Song. “Sqlnet: Generating structured queries from natural language without reinforcement learning.” arXiv preprint arXiv:1711.04436 (2017).</li><li>Sukthankar, Nandan, et al. “nQuery-A Natural Language Statement to SQL Query Generator.” Proceedings of ACL 2017, Student Research Workshop. 2017.</li><li>Dhamdhere, Kedar, et al. “Analyza: Exploring data with conversation.” Proceedings of the 22nd International Conference on Intelligent User Interfaces. ACM, 2017.</li><li>Liang, Percy. “Learning executable semantic parsers for natural language understanding.” arXiv preprint arXiv:1603.06677 (2016).</li><li>Singh, Garima, and Arun Solanki. “An algorithm to transform natural language into SQL queries for relational databases.” Selforganizology 3.3 (2016): 100-116.</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对于NL2SQL，也许在以前很多人会比较陌生。自从今年6月天池出现首届中文NL2SQL挑战赛之后，算是掀起了一股浪潮，中文NL2SQL也可以说是得到了进一步的发展。NL2SQL是CUI（Conversation User Interface）的新兴研究热点，其研究目的是将用户输入的自然语言转为可用的SQL语句，提高用户查询数据的效率。笔者接触NL2SQL方向并不长，所以也不敢在各位大神面前班门弄斧。比起情感分析、推荐系统、知识图谱这些领域，NL2SQL的文章真是少到可怜。本文也是出于学习目的对NL2SQL方向进行概括和总结，要是相关童鞋也在做这个方向，我们不妨一起交流交流。&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="https://www.csuldw.com/categories/NLP/"/>
    
    
      <category term="NLP" scheme="https://www.csuldw.com/tags/NLP/"/>
    
      <category term="NL2SQL" scheme="https://www.csuldw.com/tags/NL2SQL/"/>
    
      <category term="文本分析 - CUI" scheme="https://www.csuldw.com/tags/%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90-CUI/"/>
    
  </entry>
  
  <entry>
    <title>电影短评情感分析：各大模型江湖再见</title>
    <link href="https://www.csuldw.com/2019/10/19/2019-10-19-comment-analysis/"/>
    <id>https://www.csuldw.com/2019/10/19/2019-10-19-comment-analysis/</id>
    <published>2019-10-19T11:10:00.000Z</published>
    <updated>2019-10-20T04:31:43.009Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>倒腾豆瓣电影短评情感分析也有一阵时间了，一直抓着这个不放也不是个事，得赶紧腾出时间去总结下KG。本文算是笔者对情感分析的进阶篇，也是关于情感分类模型覆盖最全的文章。首先，从传统的特征提取方面对比了BOW、TF-IDF、N-Gram技术，并使用不同的机器学习算法构建了不同的子模型，然后又采用了Stacking模型融合技术对短评情感进行了进一步的探索，最后进阶到深度学习，构建神经网络模型进行文本分类。全文各个模型并不是参数最优，但也有一定的参考价值，因为针对不同的数据集，模型的预测结果都是不尽相同的。言归正传，下面一起来看看电影短评情感分析的结果吧！</p><a id="more"></a><h2 id="往期回顾"><a href="#往期回顾" class="headerlink" title="往期回顾"></a>往期回顾</h2><p>首先介绍下笔者先前写的几篇关于电影短评的文章：第一篇文章介绍的是如何构建高质量的情感分析数据集，第二篇是采用MNB做的一个baseline模型，第三篇是数据集的原始来源。本文使用的数据集来自文章[1]，整个训练集正负样本各220000条，测试集正负样本各24912条。</p><ol><li><a href="http://www.csuldw.com/2019/10/11/2019-10-11-rebuild-sa-dataset/">浅谈影评情感分析数据集的构建</a></li><li><a href="http://www.csuldw.com/2019/09/28/2019-09-28-comment-sentiment-analysis/">豆瓣电影短评数据情感分析Baseline</a></li><li><a href="http://www.csuldw.com/2019/09/08/2019-09-08-moviedata-10m/">14万电影800万影评数据集介绍</a></li></ol><p>这三篇文章主要是情感分析初始篇，模型层面的东西基本上没有涉及。本篇则是从模型出发分析短评情感。在文章内容篇幅上，笔者将从以下几个大方向构建电影短评情感分析模型：</p><ul><li>基于Bag-Of-Words特征的文本分类模型</li><li>基于TF-IDF特征的文本分类模型</li><li>基于Stacking模型融合的情感分析</li><li>基于深度学习的短评情感分析</li></ul><h2 id="基于Bag-Of-Words特征的文本分类模型"><a href="#基于Bag-Of-Words特征的文本分类模型" class="headerlink" title="基于Bag-Of-Words特征的文本分类模型"></a>基于Bag-Of-Words特征的文本分类模型</h2><p>笔者首先对短评数据进行了分词，然后算出每个短评的bow特征，并在此基础上训练了LR、MMB、RF、GBDT四个模型，当然各个模型都没有进行很深程度的调优。从Table 1可以看出，bow-LR模型整体上预测结果最好，AUC达到了0.9399，其他预测指标也达到了0.87。</p><center>Table 1 测试集预测结果对比(BoW)</center><!-- MORE --><table><thead><tr><th>模型名称</th><th>Accuracy</th><th>Precision</th><th>Recall</th><th>F1-Score</th><th>AUC</th></tr></thead><tbody><tr><td><strong>bow-LR</strong></td><td><strong>0.868</strong></td><td><strong>0.87</strong></td><td><strong>0.87</strong></td><td><strong>0.87</strong></td><td><strong>0.9399</strong></td></tr><tr><td>bow-MNB</td><td>0.865</td><td>0.86</td><td>0.86</td><td>0.86</td><td>0.9342</td></tr><tr><td>bow-RF</td><td>0.818</td><td>0.82</td><td>0.82</td><td>0.82</td><td>0.8902</td></tr><tr><td>bow-GBDT</td><td>0.7557</td><td>0.76</td><td>0.76</td><td>0.76</td><td>0.8535</td></tr></tbody></table><p>核心代码如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">transformer = CountVectorizer(analyzer=process.process_line)</span><br><span class="line">transformer.fit(X)X = transformer.transform(X)</span><br></pre></td></tr></tbody></table></figure><h2 id="基于TF-IDF特征的文本分类"><a href="#基于TF-IDF特征的文本分类" class="headerlink" title="基于TF-IDF特征的文本分类"></a>基于TF-IDF特征的文本分类</h2><p>TF-IDF在文本处理中经常用到，至少在我的工作中是用到的较多，比如计算文本相似度的时候，比较简单而且常用的做法就是，先将句子的TF-IDF值算出来，然后根据欧式距离计算相似度。TF-IDF（词频-逆文档频率）技术，是文本向量化的常用做法，从文本中提取特征以供后续的算法使用。</p><p>在这一小节里，特征方面最开始尝试了基于word的tfidf，然后又尝试了word-ngram-tfidf，后来将word-level替换成char-level，基于char构建n-gram。当然，关于ngram的n究竟该怎么取，也是一个值得考量的因子，读者如有兴趣，可以尝试下3-gram to 6-gram。针对不同的特征，笔者对比了LR、RF、MNB、GBDT四个算法，四个模型除了RF和GBDT是基于tree的，其他的都是不同类型的，以示区分。共训练了12个模型，各个模型的结果如Table 2所示。</p><center>Table 2 测试集预测结果对比(TF-IDF)</center><!-- MORE --><table><thead><tr><th>模型名称</th><th>Accuracy</th><th>Precision</th><th>Recall</th><th>F1-Score</th><th>AUC</th></tr></thead><tbody><tr><td>word-level-tfidf-LR</td><td>0.872</td><td>0.87</td><td>0.87</td><td>0.87</td><td>0.9438</td></tr><tr><td>word-level-tfidf-MNB</td><td>0.862</td><td>0.86</td><td>0.86</td><td>0.86</td><td>0.9394</td></tr><tr><td>word-level-tfidf-RF</td><td>0.8219</td><td>0.82</td><td>0.82</td><td>0.82</td><td>0.8930</td></tr><tr><td>word-level-tfidf-GBDT</td><td>0.723</td><td>0.72</td><td>0.72</td><td>0.71</td><td>0.8183</td></tr><tr><td>word-ngram-tfidf-LR</td><td>0.8724</td><td>0.87</td><td>0.87</td><td>0.87</td><td>0.9439</td></tr><tr><td>word-ngram-tfidf-MNB</td><td>0.8642</td><td>0.86</td><td>0.86</td><td>0.86</td><td>0.9399</td></tr><tr><td>word-ngram-tfidf-RF</td><td>0.8212</td><td>0.82</td><td>0.82</td><td>0.82</td><td>0.8925</td></tr><tr><td>word-ngram-tfidf-GBDT</td><td>0.7630</td><td>0.77</td><td>0.76</td><td>0.76</td><td>0.8588</td></tr><tr><td><strong>char-ngram-tfidf-LR</strong></td><td><strong>0.8866</strong></td><td><strong>0.89</strong></td><td><strong>0.89</strong></td><td><strong>0.89</strong></td><td><strong>0.9552</strong></td></tr><tr><td>char-ngram-tfidf-MNB</td><td>0.8657</td><td>0.87</td><td>0.87</td><td>0.87</td><td>0.9410</td></tr><tr><td>char-ngram-tfidf-RF</td><td>0.8276</td><td>0.83</td><td>0.83</td><td>0.83</td><td>0.9009</td></tr><tr><td>char-ngram-tfidf-GBDT</td><td>0.7686</td><td>0.78</td><td>0.77</td><td>0.77</td><td>0.8613</td></tr></tbody></table><div class="caption"></div><p>让笔者比较意外的是，GBDT和RF的结果居然比LR还要差，不过稍微想了下也感觉正常，主要是没有经过细致的调参。在上述12个模型中，基于char的ngram特征结合LR，测试集的预测结果，不管是precision还是recall、F1，都达到了0.89，AUC也高达0.9552，相对其他的模型，确实要高出一筹。说明一下，上述模型中基于word的ngram取得是[1,2,3]-gram，基于char的ngram是[2,3]-gram。</p><p>在算法上，笔者没有尝试SVM、xgboost、LightGBM等大众算法，一方面是SVM训练的速度过慢；另一方面是后面还会构建其他算法模型，传统的仅做参考吧。不过，虽然现在很多企业都转向了做深度学习模型，但传统的特征提取构建模型的方式还是值得学习一下的，毕竟知识掌握了就是自己的，缕清之后也就多了一份自信，没掌握的存放在电脑上的，那都是资料！！</p><h2 id="基于Stacking模型融合的情感分类模型"><a href="#基于Stacking模型融合的情感分类模型" class="headerlink" title="基于Stacking模型融合的情感分类模型"></a>基于Stacking模型融合的情感分类模型</h2><p>关于stacking融合技术，整个过程如Fig 1所示。首先将数据集划分为训练集和测试集，训练集主要用于sub-Model训练，训练方式有两种，一种基于cross-validation，一种是单纯的训练。两种方式具体的过程如下：</p><ul><li>Stacking-CV-Model：将训练集分成k份，在使用算法A进行交叉验证过程中，分别将每份作为测试集其余4分作为训练集训练分类模型，最后得到5个模型和5个测试集的预测结果，我们将算法A交叉验证得到的Out-Of-Fold结果作为一个特征集。如果有5个算法，每个算法得到的oof结果都是一个特征集，最后将其合并作为新的训练集（Meta Feature）。</li><li>Stacking-Model：将训练集分成k份，假设有5个算法用于stacking子模型中，那么算法1采用第5份作为测试集，其余4份作为训练集，依此论推，算法2采用采用第4份作为测试机，算法3采用第3份作为测试集，算法4采用第2份作为测试集，算法1采用第5份作为测试机，其余作为训练集，最后将每个算法预测的测试集的结果合并，作为新的特征，即新的训练集（Meta Feature）。</li></ul><p>如果有新的数据需要预测，那么都需要按照上述过程预测出新的特征，然后使用Meta algorithm预测出最终的结果。Stacking融合模型的代码已上传至github，仅供参考：<a href="https://github.com/csuldw/MachineLearning/blob/master/stacking/stacking.py" target="_blank" rel="noopener">https://github.com/csuldw/MachineLearning/blob/master/stacking/stacking.py</a></p><p><img src="/assets/articleImg/2019/stacking-framework.png" alt=""></p><div class="caption">Fig 1. stacking策略模型（分为两个阶段，第一阶段是model 1-model 5，用于训练出新的特征，第二阶段是Meta Algorithm，训练最终的分类模型）</div><p>在短评情感分类中，关于stacking模型，笔者尝试了几个，如Table 3所示。从数据上可以看出，在特征都为bag-of-words的情况下，bow（lr+MNB+RF）+xgboost 融合的结果的确比Table 1的各个子模型预测的结果好。单独从Table 3来看，xgboost作为layer 2的Meta算法比LR作为meta Algorithm 要稍微好一些。而针对不同的特征，基于char的ngram仍然要高出bow和word-tfidf特征，其AUC达到了0.9592。</p><center>Table 3 测试集模型预测结果对比(Stacking模型融合)</center><table><thead><tr><th>子模型</th><th>Meta_Classifier</th><th>Accuracy</th><th>Precision</th><th>Recall</th><th>F1-Score</th><th>AUC</th></tr></thead><tbody><tr><td>char-ngram-tfidf（lr+MNB+RF）</td><td>LR</td><td>0.8830</td><td>0.88</td><td>0.88</td><td>0.88</td><td>0.9539</td></tr><tr><td><strong>char-ngram-tfidf（lr+MNB+RF）</strong></td><td><strong>xgboost</strong></td><td><strong>0.8934</strong></td><td><strong>0.89</strong></td><td><strong>0.89</strong></td><td><strong>0.89</strong></td><td><strong>0.9592</strong></td></tr><tr><td>bow（lr+MNB+RF）</td><td>xgboost</td><td>0.8751</td><td>0.89</td><td>0.88</td><td>0.88</td><td>0.9444</td></tr><tr><td>word-tfidf（lr+MNB+RF）</td><td>xgboost</td><td>0.8739</td><td>0.87</td><td>0.87</td><td>0.87</td><td>0.9465</td></tr></tbody></table><h2 id="基于深度学习的情感分析"><a href="#基于深度学习的情感分析" class="headerlink" title="基于深度学习的情感分析"></a>基于深度学习的情感分析</h2><p>上面采用了传统机器学习方法构建了文本分类模型，接下来将使用深度学习技术进行文本分类。至于两者到底谁更好，我们大可不必太过较真。记得去年公司内部的多语言情感分类比赛，第一名是将BERT、fastText与传统机器学习算法进行融合而构建的stacking模型，第二名则是采用纯粹的传统机器学习方法进行融合。比赛当中，对数据的处理真的比算法更重要，有时候看起不起眼的算法，只要特征工程做的好，结果都是出乎意料的。说这些并不是指深度学习不行，只是想让大家以客观的心态去看待它，不要将其神话了。对于文本分类，之前使用比较多的深度学习算法还属RNN，比如LSTM、GRU等。在BERT出来之后，对文本分类的精度又提升了一个level。笔者在做情感分析的时候，并没有尝试去使用BERT算法，仅仅是将深度学习模型框架搭建了起来，后续要使用的话，直接调用就行了!关于深度学习模型的调参，笔者也没有花太多的时间，主要是在Mac上训练一个网络速度太慢了，一个LSTM，跑几十万的训练数据，一个epoch差不多20多分钟，整个模型训练下来也要好几个小时，真的是耗不起！基于LSTM的模型框架Fig 2所示：</p><!-- ![](/assets/articleImg/2019/simple-model-framework.png) --><img src="/assets/articleImg/2019/simple-model-framework.png" width="70%"><div class="caption">Fig 2. LSTM深度学习文本分类模型框架</div><p>下面是笔者采用训练LSTM的核心代码(人生苦短，我用keras, v2.2.5)，注意一下，这里采用了多分类的方式来做二分类，所以调用的是<code>categorical_crossentropy</code>.</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span><span class="params">(X_train, y_train, X_test, y_test, n_words, batch_size, n_class=<span class="number">2</span>)</span>:</span></span><br><span class="line">    embedding_layer = Embedding(n_words + <span class="number">1</span>, EMBEDDING_DIM,</span><br><span class="line">                            <span class="comment"># weights=[embedding_matrix],</span></span><br><span class="line">                            input_length=MAX_SEQUENCE_LENGTH, dropout=<span class="number">0.2</span>)</span><br><span class="line">    print(<span class="string">'Build model...'</span>)</span><br><span class="line">    model = Sequential()</span><br><span class="line">    model.add(embedding_layer)</span><br><span class="line">    model.add(SpatialDropout1D(<span class="number">0.4</span>))</span><br><span class="line">    model.add(LSTM(<span class="number">64</span>, dropout=<span class="number">0.2</span>, recurrent_dropout=<span class="number">0.2</span>))  <span class="comment"># try using a GRU </span></span><br><span class="line">    model.add(Dense(n_class, activation=<span class="string">'softmax'</span>))</span><br><span class="line">    <span class="comment"># try using different parameters</span></span><br><span class="line">    model.compile(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">    print(model.summary())</span><br><span class="line">    model.fit(X_train, y_train, batch_size=batch_size, epochs=<span class="number">5</span>, validation_data=(X_test, y_test))</span><br><span class="line">    score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)</span><br><span class="line">    print(<span class="string">'Test score:{}, accuracy:{}'</span>.format(score, acc))</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></tbody></table></figure><p>LSTM Model结构与参数数量如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Model: <span class="string">"sequential_1"</span></span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param <span class="comment">#   </span></span><br><span class="line">=================================================================</span><br><span class="line">embedding_1 (Embedding)      (<span class="literal">None</span>, <span class="number">50</span>, <span class="number">128</span>)           <span class="number">12800128</span>  </span><br><span class="line">_________________________________________________________________</span><br><span class="line">spatial_dropout1d_1 (Spatial (<span class="literal">None</span>, <span class="number">50</span>, <span class="number">128</span>)           <span class="number">0</span>         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">lstm_1 (LSTM)                (<span class="literal">None</span>, <span class="number">64</span>)                <span class="number">49408</span>     </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense)              (<span class="literal">None</span>, <span class="number">2</span>)                 <span class="number">130</span>       </span><br><span class="line">=================================================================</span><br><span class="line">Total params: <span class="number">12</span>,<span class="number">849</span>,<span class="number">666</span></span><br><span class="line">Trainable params: <span class="number">12</span>,<span class="number">849</span>,<span class="number">666</span></span><br><span class="line">Non-trainable params: <span class="number">0</span></span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></tbody></table></figure><p>关于LSTM算法，这里不扩展了，感兴趣的童鞋可以参考下这篇文章<a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">Understanding LSTM Networks</a>。其内部结构如Fig 3 (中)所示，：</p><!-- ![](/assets/articleImg/2019/rnn-lstm-gru.png) --><img src="/assets/articleImg/2019/rnn-lstm-gru.png" width="70%"><div class="caption">Fig 3. RNN-vs-LSTM-vs-GRU 内部结构</div><p>最终的模型预测结果如Table 4所示，在没有细致的调参情况下，LSTM模型的预测能力与上述传统的机器学习模型相差不大，GRU则与LSTM几乎持平：</p><center>Table 4. 测试集模型预测结果对比(深度学习)</center><table><thead><tr><th>模型名称</th><th>Accuracy</th><th>Precision</th><th>Recall</th><th>F1-Score</th><th>AUC</th></tr></thead><tbody><tr><td>LSTM-Model</td><td>0.8685</td><td>0.87</td><td>0.87</td><td>0.87</td><td>0.9392</td></tr><tr><td>GRU-Model</td><td>0.8685</td><td>0.87</td><td>0.88</td><td>0.87</td><td>0.9404</td></tr><tr><td>BiLSTM-Model</td><td>0.8660</td><td>0.87</td><td>0.87</td><td>0.87</td><td>0.9380</td></tr></tbody></table><div class="caption"></div><p>上面只是简单的采用了LSTM和GRU来构建深度学习模型，针对分类任务，还有很多的方法可以实施。比如基于BERT预训练模型构建分类模型，或是CNN、fastText等，亦或是不同的深度网络结构，都可以用来优化模型的最终预测性能。另外，我们还可以将深度学习模型与传统的机器学习模型进行融合，构建基于深度学习和机器学习的stacking模型等等等等。当然，只追求模型的种类是绝对不行的，要深入到一个模型里面，将参数调制最优，才是学习之根本。比如深度学习模型，模型何时会收敛，如何尽量避免过拟合等等，都是一大学问。读者如有相关的问题，可以关注笔者的公众号[斗码小院]，在后台或是文章中留言都可以。</p><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>本文针对豆瓣电影短评数据集，构建了四大分类模型：基于BOW特征的分类模型、基于TF-IDF特征的分类模型、基于Stacking模型融合技术的情感分类模型、基于深度学习的短评情感分析模型，共训练了20+个文本分类模型，其中传统的基于char-level-ngram-tfidf特征构建的模型，在相同的算法下，不亚于其他的word-level特征。在深度学习模型上，由于一个模型训练的时间过长，笔者并未花费太多的时间去优化。后续如果有新的进展，也会第一时间在本文的留言栏中说明。OK，关于情感分析，就到此为止吧，感谢各位读者的捧场！<strong>需要数据集的童鞋可关注[<span style="color:blue">斗码小院</span>]公众号，回复”情感分析数据集”即可</strong>。</p><p>本文的所有代码已上传至GitHub：<a href="https://github.com/csuldw/comment-sentiment-analysis" target="_blank" rel="noopener">https://github.com/csuldw/comment-sentiment-analysis</a>，代码如有错误，还望读者指出，多谢！</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li><a href="http://www.csuldw.com">http://www.csuldw.com</a></li><li><a href="https://scikit-learn.org" target="_blank" rel="noopener">https://scikit-learn.org</a></li><li><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></li><li><a href="https://www.kaggle.com/ngyptr/lstm-sentiment-analysis-keras" target="_blank" rel="noopener">https://www.kaggle.com/ngyptr/lstm-sentiment-analysis-keras</a></li><li><a href="http://dprogrammer.org/rnn-lstm-gru" target="_blank" rel="noopener">http://dprogrammer.org/rnn-lstm-gru</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;倒腾豆瓣电影短评情感分析也有一阵时间了，一直抓着这个不放也不是个事，得赶紧腾出时间去总结下KG。本文算是笔者对情感分析的进阶篇，也是关于情感分类模型覆盖最全的文章。首先，从传统的特征提取方面对比了BOW、TF-IDF、N-Gram技术，并使用不同的机器学习算法构建了不同的子模型，然后又采用了Stacking模型融合技术对短评情感进行了进一步的探索，最后进阶到深度学习，构建神经网络模型进行文本分类。全文各个模型并不是参数最优，但也有一定的参考价值，因为针对不同的数据集，模型的预测结果都是不尽相同的。言归正传，下面一起来看看电影短评情感分析的结果吧！&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="https://www.csuldw.com/categories/NLP/"/>
    
    
      <category term="豆瓣影评" scheme="https://www.csuldw.com/tags/%E8%B1%86%E7%93%A3%E5%BD%B1%E8%AF%84/"/>
    
      <category term="情感分析" scheme="https://www.csuldw.com/tags/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"/>
    
      <category term="评论" scheme="https://www.csuldw.com/tags/%E8%AF%84%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>浅谈影评情感分析数据集的构建</title>
    <link href="https://www.csuldw.com/2019/10/11/2019-10-11-rebuild-sa-dataset/"/>
    <id>https://www.csuldw.com/2019/10/11/2019-10-11-rebuild-sa-dataset/</id>
    <published>2019-10-10T16:10:00.000Z</published>
    <updated>2019-10-14T15:31:32.961Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>前段时间国庆，回家休息了几天，每天熬夜玩手机，整个人算是有点颓废了。回来工作之后，渐渐地又过上了有规律的生活，说到底，还是自制力不够呀！本想着国庆的时候好好分析下影评数据，结果只是跑了个模型，其他啥也没干成，想想就真的有点浪费时间了。人生苦短，转眼间很多熟悉的人都结婚了，而自己却终究还是过不去那个坎。不过现在无所谓了，压力不是很大，抓紧时间不断学习和总结才是王道。言归正传，在国庆前，针对豆瓣的电影评论数据做了一个比较简单的情感分析，效果不是很好，最近又进行了进一步尝试，发现了一点点关于情感分析数据集的小门道，这里简单的总结下，后续做文本分析，或许还可以使用上。</p><a id="more"></a><h2 id="往期回首"><a href="#往期回首" class="headerlink" title="往期回首"></a>往期回首</h2><p>在9月底的时候，写了一篇有关情感分析的文章<a href="http://www.csuldw.com/2019/09/28/2019-09-28-comment-sentiment-analysis/">豆瓣电影短评数据情感分析Baseline</a>，文章采用的数据集比较粗糙，笔者最开始采集的电影评论数据有4428475条，去掉RATING为NaN的数据之后，还剩4166704条。当时看着这416万数据，确实有点棘手，毕竟没有很好的服务器去跑模型。为此，做了一些数据清洗和过滤操作，包括长度过长、去重等操作，最后剩下了3582251条。评论中自带用户对电影的评分，分值为为1-5星（1-很差，2-较差，3-还行，4-推荐，5-力荐），所以最后笔者将评论划分为了三个：1-2星为消极negative（700572条），3星为正常neutral（1215485条），4-5星为正向positive（1666194条）。最后笔者也没有对数据进行采样，直接采用MNB进行多分类，最后各个class的平均precision和recall都接近0.6。效果不能说好，但也不能说非常差，毕竟也超过了0.5了。</p><p>国庆节当天在车上，思来想去，没理由这么差，回去之后仔细看了看数据集，发现数据集的区分度不是很好，主要的原因还是在于评分在2星、3星、4星的数据，很多意思口吻相近的数据，评分却不尽相同，比如</p><ol><li>“搞笑片哈哈哈哈哈哈哈哈哈”评分为2星，</li><li>“好搞笑哈哈哈哈哈”评分是3星</li><li>“很搞笑哈哈哈” 评分4星</li></ol><p>仔细查阅了下，这种数据不只是上面这一种形式，当然还存在其他类型的，该怎么来做呢？</p><h2 id="数据新探索"><a href="#数据新探索" class="headerlink" title="数据新探索"></a>数据新探索</h2><p>首先表示下，因为是自己构建数据集，当然想要弄一份比较好、数据质量高点的，那么什么才算质量高呢？坊间有这样一句话，“数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已”。也就是说，即使算法再不济，数据质量上去了，算法得到的结果都不会很差。有了这个念头，也就不管那么多了，首先在类别不调整的情况下，将1星归为negative，3星归为neutral，5星归为positive。如此之下，数据的区分度算是上去了。使用MNB训练之后，得到的结果差不多在0.68左右，效果比之前的0.6好了点，不过数据还是不纯，区分度不明显，主要在于3星的数据里面，有的倾向于negative，有的倾向于positive，这也就导致了模型训练之后，效果不佳。此时的数据量各个class的数据量差别还比较大，negative的24w，positive的51w，neutral的有117万，差距太大了。</p><p>考虑到后续要在自己单机上构建深度学习模型，所以在提高数据质量的同时，也要将数据量给降下去。说白了，就是以数量换取质量的意思，数据再多，杂乱无章也不是什么好事，如果有一份质量较高的数据，即使数据量降下来了，也还是说得过去的，何况数据量本来就比较多。再三思考之后，笔者做了最极端的做法，原本是三分类，直接改成了二分类，negative选择的是1星评论，positive选择的是5星评论。如此以来，区分度肯定是上去了。结果如何呢，接下来来看看结果。</p><h2 id="探索下的结果"><a href="#探索下的结果" class="headerlink" title="探索下的结果"></a>探索下的结果</h2><p>上面的都是想法，目的就是使得数据集各个类的区分度更加明显。有了这种想法之后，笔者就进行了进一步的验证。1星数据244912条，5星数据517218条，两倍多的差距，对于二分类来说数据集呈现出类别不均衡现象。所以，笔者进一步构建了训练集和测试机，训练集正负样本各220000条，测试集正负样本各24912条。之前取全部数据分3类跑MNB需要30min，去掉2星和4星的跑MNB需要16min左右，现在训练集44万数据，交叉验证训练时间大概5min不到，结果如下：</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">                <span class="string">precision</span>    <span class="string">recall</span>  <span class="string">f1-score</span>   <span class="string">support</span></span><br><span class="line"></span><br><span class="line">          <span class="number">-1</span>       <span class="number">0.86</span>      <span class="number">0.88</span>      <span class="number">0.87</span>     <span class="number">22073</span></span><br><span class="line">           <span class="number">1</span>       <span class="number">0.88</span>      <span class="number">0.85</span>      <span class="number">0.87</span>     <span class="number">21927</span></span><br><span class="line"></span><br><span class="line">    <span class="string">accuracy</span>                           <span class="number">0.87</span>     <span class="number">44000</span></span><br><span class="line">   <span class="string">macro</span> <span class="string">avg</span>       <span class="number">0.87</span>      <span class="number">0.87</span>      <span class="number">0.87</span>     <span class="number">44000</span></span><br><span class="line"><span class="string">weighted</span> <span class="string">avg</span>       <span class="number">0.87</span>      <span class="number">0.87</span>      <span class="number">0.87</span>     <span class="number">44000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">CPU times:</span> <span class="string">user</span> <span class="number">56.4</span> <span class="string">ms,</span> <span class="attr">sys:</span> <span class="number">2.12</span> <span class="string">ms,</span> <span class="attr">total:</span> <span class="number">58.6</span> <span class="string">ms</span></span><br><span class="line"><span class="attr">Wall time:</span> <span class="number">60.5</span> <span class="string">ms</span></span><br></pre></td></tr></tbody></table></figure><p>对于测试集，预测结果也很不错，如下，平均都达到0.86，说明测试集与训练集的分布大致一样。</p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">                precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">          <span class="number">-1</span>       <span class="number">0.85</span>      <span class="number">0.88</span>      <span class="number">0.87</span>     <span class="number">24912</span></span><br><span class="line">           <span class="number">1</span>       <span class="number">0.88</span>      <span class="number">0.85</span>      <span class="number">0.86</span>     <span class="number">24912</span></span><br><span class="line"></span><br><span class="line">    accuracy                           <span class="number">0.86</span>     <span class="number">49824</span></span><br><span class="line">   macro avg       <span class="number">0.86</span>      <span class="number">0.86</span>      <span class="number">0.86</span>     <span class="number">49824</span></span><br><span class="line">weighted avg       <span class="number">0.86</span>      <span class="number">0.86</span>      <span class="number">0.86</span>     <span class="number">49824</span></span><br></pre></td></tr></tbody></table></figure><p>这只是一个开始，简单的模型，未加任何参数调优过程，单纯是为了构造数据集。有这样的结果，确实挺满意的，后续对于中文文本分类的研究数据算是不用愁了吧！</p><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>笔者写这篇文章，主要是记录下自己构建数据的过程。实践证明，数据量并不是越多就越好，而是数据各个类别的区分度越高越好。数据量的增加对于模型来说，无疑是锦上添花，可以使模型的泛化能力得到很好的提升，但是区分度对于模型的精度来说也是至关重要，如果添加了一份比较杂乱无章的数据，还不如没有呢。OK，既然数据已经备好了，后续做模型也就省事了，虽然讲多分类变成了二分类，但整体上来说可行性还是可以的，都是个人实践，少个label也不是什么不可以的事情。关于情感分析，笔者会继续采用不同的算法进行剖析，后续也会将其做成服务，就当做是一种实践方式吧！如有需要数据的，请关注[斗码小院]公众号，后台回复【情感分析数据集】即可。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li>豆瓣影评数据集：<a href="http://moviedata.csuldw.com" target="_blank" rel="noopener">http://moviedata.csuldw.com</a></li><li><a href="http://www.csuldw.com">http://www.csuldw.com</a></li><li><a href="https://scikit-learn.org" target="_blank" rel="noopener">https://scikit-learn.org</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前段时间国庆，回家休息了几天，每天熬夜玩手机，整个人算是有点颓废了。回来工作之后，渐渐地又过上了有规律的生活，说到底，还是自制力不够呀！本想着国庆的时候好好分析下影评数据，结果只是跑了个模型，其他啥也没干成，想想就真的有点浪费时间了。人生苦短，转眼间很多熟悉的人都结婚了，而自己却终究还是过不去那个坎。不过现在无所谓了，压力不是很大，抓紧时间不断学习和总结才是王道。言归正传，在国庆前，针对豆瓣的电影评论数据做了一个比较简单的情感分析，效果不是很好，最近又进行了进一步尝试，发现了一点点关于情感分析数据集的小门道，这里简单的总结下，后续做文本分析，或许还可以使用上。&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="https://www.csuldw.com/categories/NLP/"/>
    
    
      <category term="豆瓣影评" scheme="https://www.csuldw.com/tags/%E8%B1%86%E7%93%A3%E5%BD%B1%E8%AF%84/"/>
    
      <category term="情感分析" scheme="https://www.csuldw.com/tags/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"/>
    
      <category term="评论" scheme="https://www.csuldw.com/tags/%E8%AF%84%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>豆瓣电影短评数据情感分析Baseline</title>
    <link href="https://www.csuldw.com/2019/09/28/2019-09-28-comment-sentiment-analysis/"/>
    <id>https://www.csuldw.com/2019/09/28/2019-09-28-comment-sentiment-analysis/</id>
    <published>2019-09-28T15:00:00.000Z</published>
    <updated>2019-10-19T02:18:07.185Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>先前已经爬取了豆瓣400w+的电影评论数据（地址：<a href="http://moviedata.csuldw.com" target="_blank" rel="noopener">http://moviedata.csuldw.com</a>），为了进一步发挥数据的价值，这次将介绍下如何基于豆瓣影评数据进行评论情感分析，分享一个比较简单的情感分析baseline，后续有机会再将进一步的优化结果分享出来。</p><a id="more"></a><h2 id="数据集处理"><a href="#数据集处理" class="headerlink" title="数据集处理"></a>数据集处理</h2><p>原始的电影评论数据共4428475条，样例数据如Fig 1所示，数据里面还夹着一些没有评分的数据，将这些RATING为NaN的过滤掉之后，剩下来的数据有4166704条。</p><!-- ![](/assets/articleImg/2019/comment-dataset-sample.png) --><img src="/assets/articleImg/2019/comment-dataset-sample.png"><div class="caption">Fig 1. 数据集样例</div><p>除了数据评分取值的问题，CONTENT里的文本有的还是繁体，所以在进行情感分析之前，我们还需要对文本的格式统一起来，代码核心部分如下（仅供参考）：</p><figure class="highlight livecodeserver"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">from</span> langconv import *</span><br><span class="line">def traditional2simplified(<span class="keyword">text</span>):</span><br><span class="line">    <span class="keyword">text</span> = Converter(<span class="string">'zh-hans'</span>).<span class="built_in">convert</span>(<span class="keyword">text</span>)</span><br><span class="line">    <span class="literal">return</span> <span class="keyword">text</span></span><br><span class="line">dataset[<span class="string">"CONTENT"</span>] = dataset.CONTENT.apply(lambda x: traditional2simplified(x))</span><br></pre></td></tr></tbody></table></figure><p>对400多万的文本数据进行分类，乍一看也还算OK，不过在单机上还是有些吃力，所以我们需要对数据进行进一步的去脏以达到缩放的效果，而这一阶段需要做的工作量还是比较多的。</p><h3 id="去除干扰评论数据"><a href="#去除干扰评论数据" class="headerlink" title="去除干扰评论数据"></a>去除干扰评论数据</h3><p>影评数据的评分RATING评分值为1-5星，这些评分跟评论的相关性还是比较大的。虽然如此，评论里面还是存在很多的干扰数据，笔者对数据集的进行了简单的比较，发现相同的评论，其RATING值居然不一样，这类数据还占了15%以上，真是恐怖如斯！！考虑到数据集的数据量本来就比较大，所以索性对这部分数据直接去掉了，最后剩下3795251条影评数据。</p><h3 id="去除过短或过长的数据"><a href="#去除过短或过长的数据" class="headerlink" title="去除过短或过长的数据"></a>去除过短或过长的数据</h3><p>在这份电影评论数据集里，文本长度从1-3000+不等，长度过于波动，不太符合短评数据的长度规范。为此，笔者将文本长度限制在了[5,140]，上下都取闭区间（豆瓣的短评数据集长度为140），最后得到的数据集3582251条。</p><h3 id="情感类别定义"><a href="#情感类别定义" class="headerlink" title="情感类别定义"></a>情感类别定义</h3><p>先前提到豆瓣电影评论携带的评分在1-5星，仔细看了评论内容你会发现，1-2星的评论以及4-5星的评论确实很难区分，好在豆瓣给出了1-5星每个星值的意义（1-很差，2-较差，3-还行，4-推荐，5-力荐），所以最后将评论划分为三个：1-2星为消极negative，3星为正常normal，4-5星为正向positive，如此以来，就将评论划分成三个类别了，各个类别的数据量如Fig 2所示。接下来就可以对这个label取值为3类的文本数据进行模型训练与预测了。</p><!-- ![](/assets/articleImg/2019/comment-label-3class.png) --><img src="/assets/articleImg/2019/comment-label-3class.png" width="70%"><div class="caption">Fig 2. 评论Label数据量统计</div><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>对于中文文本分词，这里采用的jieba，同时文本数据进行了去停留词处理，代码如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_stopwords</span><span class="params">()</span>:</span></span><br><span class="line">    stopwords = [line.strip() <span class="keyword">for</span> line <span class="keyword">in</span> open(<span class="string">'data/stopwords/stopword_normal.txt'</span>,encoding=<span class="string">'UTF-8'</span>).readlines()]</span><br><span class="line">    <span class="keyword">return</span> stopwords</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">stopwords = get_stopwords()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">text_process</span><span class="params">(text)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    按照下面方式处理字符串</span></span><br><span class="line"><span class="string">    1. 去除标点符号</span></span><br><span class="line"><span class="string">    2. 去掉无用词</span></span><br><span class="line"><span class="string">    3. 返回剩下的词的list</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    text = re.sub(<span class="string">"[\s+\.\!\/_,$%^*(+\"\']+|[+——！，。？、~@#￥%……&amp;*（）]"</span>, <span class="string">""</span>,text)</span><br><span class="line">​</span><br><span class="line">    ltext = jieba.lcut(text)</span><br><span class="line">    res_text = []</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> ltext:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stopwords:</span><br><span class="line">            res_text.append(word)</span><br><span class="line">    <span class="keyword">return</span> res_text</span><br><span class="line">​</span><br><span class="line">X = dataset.CONTENT</span><br><span class="line">y = dataset.label</span><br><span class="line">bow_transformer = CountVectorizer(analyzer=text_process).fit(X)</span><br><span class="line">X = bow_transformer.transform(X)</span><br></pre></td></tr></tbody></table></figure><p>通过上面的处理之后，我们可以得到X和y，接下来，可以用这部分数据进行模型训练了。</p><h2 id="模型训练与评估"><a href="#模型训练与评估" class="headerlink" title="模型训练与评估"></a>模型训练与评估</h2><p>采用sklearn将数据集划分为训练集和测试集，即使比例为9:1，测试数据也有358226t条，一个demo足够了。</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection import train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, <span class="attribute">test_size</span>=0.1, <span class="attribute">random_state</span>=99)</span><br></pre></td></tr></tbody></table></figure><p>由于是多分类，所以就直接采用了MultinomialNB作为baseline，核心代码如下：</p><figure class="highlight armasm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">from</span> sklearn.naive_bayes <span class="meta">import</span> <span class="keyword">MultinomialNB</span></span><br><span class="line"><span class="keyword">nb </span>= <span class="keyword">MultinomialNB()</span></span><br><span class="line"><span class="keyword">nb.fit(X_train, </span>y_train)</span><br><span class="line"><span class="symbol">preds</span> = nb.predict(X_test)</span><br></pre></td></tr></tbody></table></figure><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><p>得到了预测的preds值之后，直接调用sklearn的metrics里面的方法，就可以轻松地将相关的模型评估指标值计算，代码如下：</p><figure class="highlight coffeescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix, classification_report</span><br><span class="line"><span class="comment">#根据预测值和真实值计算相关指标</span></span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, preds))</span><br></pre></td></tr></tbody></table></figure><p>输出结果：</p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">                precision    recall  f1-score   support</span><br><span class="line">​</span><br><span class="line">          <span class="number">-1</span>       <span class="number">0.56</span>      <span class="number">0.56</span>      <span class="number">0.56</span>     <span class="number">70406</span></span><br><span class="line">           <span class="number">0</span>       <span class="number">0.50</span>      <span class="number">0.44</span>      <span class="number">0.47</span>    <span class="number">121276</span></span><br><span class="line">           <span class="number">1</span>       <span class="number">0.66</span>      <span class="number">0.72</span>      <span class="number">0.69</span>    <span class="number">166544</span></span><br><span class="line">​</span><br><span class="line">    accuracy                           <span class="number">0.59</span>    <span class="number">358226</span></span><br><span class="line">   macro avg       <span class="number">0.57</span>      <span class="number">0.57</span>      <span class="number">0.57</span>    <span class="number">358226</span></span><br><span class="line">weighted avg       <span class="number">0.59</span>      <span class="number">0.59</span>      <span class="number">0.59</span>    <span class="number">358226</span></span><br></pre></td></tr></tbody></table></figure><p>可以看出，三个label的平均precision和recall都接近0.6，整体上还是OK的，后续再进一步优化吧，预测方法封装如下：</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">sentiment_pred</span><span class="params">(<span class="built_in">text</span>)</span>:</span></span><br><span class="line"><span class="function">    text_transformed </span>= bow_transformer.transform([<span class="built_in">text</span>])</span><br><span class="line">    score = nb.predict(text_transformed)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> score</span><br></pre></td></tr></tbody></table></figure><p>预测结果如下Fig 3，测试数据样例不要太当真，仅仅作为参考：</p><img src="/assets/articleImg/2019/comment_predict-result.png" width="100%"><div class="caption">Fig 3. 影评预测结果</div><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>各位看客如有需要数据集的可见参考文献[1]，其他的就不多说了，情感分类内部细节还有很多待处理，本文仅仅是一个简单的baseline，如果采用深度学习如LSTM进行分类的话，单机上内存可能会不够，所以还需要对数据集进行进一步的处理。OK，就将这个当做是下一个任务项吧！</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li>豆瓣影评数据集：<a href="http://moviedata.csuldw.com" target="_blank" rel="noopener">http://moviedata.csuldw.com</a></li><li><a href="http://www.csuldw.com">http://www.csuldw.com</a></li><li><a href="https://scikit-learn.org" target="_blank" rel="noopener">https://scikit-learn.org</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;先前已经爬取了豆瓣400w+的电影评论数据（地址：&lt;a href=&quot;http://moviedata.csuldw.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://moviedata.csuldw.com&lt;/a&gt;），为了进一步发挥数据的价值，这次将介绍下如何基于豆瓣影评数据进行评论情感分析，分享一个比较简单的情感分析baseline，后续有机会再将进一步的优化结果分享出来。&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="https://www.csuldw.com/categories/NLP/"/>
    
    
      <category term="豆瓣影评" scheme="https://www.csuldw.com/tags/%E8%B1%86%E7%93%A3%E5%BD%B1%E8%AF%84/"/>
    
      <category term="情感分析" scheme="https://www.csuldw.com/tags/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"/>
    
      <category term="评论" scheme="https://www.csuldw.com/tags/%E8%AF%84%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>14万电影800万影评数据集介绍</title>
    <link href="https://www.csuldw.com/2019/09/08/2019-09-08-moviedata-10m/"/>
    <id>https://www.csuldw.com/2019/09/08/2019-09-08-moviedata-10m/</id>
    <published>2019-09-07T16:00:00.000Z</published>
    <updated>2019-10-22T12:44:46.227Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/assets/articleImg/2019/moviedata-avator.png" alt=""></p><h1 id="数据集概况"><a href="#数据集概况" class="headerlink" title="数据集概况"></a>数据集概况</h1><p>本数据集采集于豆瓣电影，电影与明星数据收集于2019年8月上旬，影评数据(用户、评分、评论)收集于2019年9月初，共945万数据，其中包含14万部电影，7万演员，63万用户，416万条电影评分，442万条影评，该数据集正好弥补下国内公开电影​数据集的空缺。数据已经过初步清洗，可用于推荐系统、情感分析、QA问答、知识图谱等多个领域。</p><a id="more"></a><p>数据集共有5个文件: movies.csv、person.csv、users.csv、comments.csv、ratings.csv，关于各个文件的具体内容将在下文介绍。</p><h1 id="使用许可"><a href="#使用许可" class="headerlink" title="使用许可"></a>使用许可</h1><p>该数据集只为方便各位研究人员，<strong>如涉及侵犯个人或团体利益，请与我们联系，我们将主动撤销一切相关数据，谢谢</strong>！</p><p>数据使用需遵循<a href="https://accounts.douban.com/passport/agreement" target="_blank" rel="noopener">豆瓣使用协议 &amp; 豆瓣隐私政策</a>,</p><p>该数据集仅限用于研究目的，我们不能保证数据的正确性以及任何场景的适用性。对于使用这份数据的用户，必须严格遵循下列条件: </p><ol><li>未经许可，用户不得将此数据集用于任何商业或收入交易用途。</li><li>未经单独许可，用户不得重新转发数据。</li><li>用户在使用数据集时，必须声明数据来源。</li></ol><p>在任何情况下，我们均不对因使用这些数据而造成的任何损失承担责任（包括但不限于数据丢失或数据不准确）。如果您有任何其他问题或意见，请发送电子邮件至: <a href="mailto:csu.ldw@csu.edu.cn" target="_blank" rel="noopener">csu.ldw@csu.edu.cn</a></p><h1 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a>数据格式</h1><h2 id="Movie数据格式"><a href="#Movie数据格式" class="headerlink" title="Movie数据格式"></a>Movie数据格式</h2><p>电影数据共140502部，2019年之前的电影有139129，当前未上映的有1373部，包含21个字段，部分字段数据为空，字段说明如下: </p><ul><li>MOVIE_ID: 电影ID，对应豆瓣的DOUBAN_ID</li><li>NAME: 电影名称</li><li>ALIAS: 别名</li><li>ACTORS: 主演</li><li>COVER: 封面图片地址</li><li>DIRECTORS: 导演</li><li>GENRES: 类型</li><li>OFFICIAL_SITE: 官方地址</li><li>REGIONS: 制片国家/地区</li><li>LANGUAGES: 语言</li><li>RELEASE_DATE: 上映日期</li><li>MINS: 片长</li><li>IMDB_ID: IMDbID</li><li>DOUBAN_SCORE: 豆瓣评分</li><li>DOUBAN_VOTES: 豆瓣投票数</li><li>TAGS: 标签</li><li>STORYLINE: 电影描述</li><li>SLUG: 加密的url，可忽略</li><li>YEAR: 年份</li><li>ACTOR_IDS: 演员与PERSON_ID的对应关系,多个演员采用“|”符号分割，格式“演员A:ID|演员B:ID”；</li><li>DIRECTOR_IDS: 导演与PERSON_ID的对应关系,多个导演采用“|”符号分割，格式“导演A:ID|导演B:ID”；</li></ul><h2 id="Person数据格式"><a href="#Person数据格式" class="headerlink" title="Person数据格式"></a>Person数据格式</h2><p>Person文件只包括演员和导演，不包含豆瓣用户数据，共72959个名人数据，包含10个字段，每个PERSON_ID都会对应一个name，不存在PERSON_ID的数据已过滤，各个字段说明如下: </p><ul><li>PERSON_ID: 名人ID</li><li>NAME: 演员名称</li><li>SEX: 性别</li><li>NAME_EN: 更多英文名</li><li>NAME_ZH: 更多中文名</li><li>BIRTH: 出生日期</li><li>BIRTHPLACE: 出生地</li><li>CONSTELLATORY: 星座</li><li>PROFESSION: 职业</li><li>BIOGRAPHY: 简介，存在简介数据的名人只有15135个。</li></ul><h2 id="User数据格式"><a href="#User数据格式" class="headerlink" title="User数据格式"></a>User数据格式</h2><p>users.csv数据为豆瓣用户的脱敏信息，主要是与评论和评分绑定在一起，共获取了639125用户数据，包含2个字段（已删除两个），具体的字段如下：</p><ul><li>USER_MD5：USER_ID加密的MD5,去敏处理</li><li>USER_NICKNAME: 评论用户昵称</li><li><del>USER_AVATAR: 评论用户头像</del>（已删除）</li><li><del>USER_URL: 评论用户url</del>（已删除）</li></ul><h2 id="Rating数据格式"><a href="#Rating数据格式" class="headerlink" title="Rating数据格式"></a>Rating数据格式</h2><p>评分数据从评论数据中获得，由于豆瓣限制了未登录用户查看的数据量，所以每部电影最多320个评分，最终得到600384个用户的4169420条评分数据，涉及电影68471部，评分值为1-5分（1-很差，2-较差，3-还行，4-推荐，5-力荐），共包含5个字段，数据格式如下：</p><ul><li>RATING_ID: 评分ID</li><li>USER_MD5：USER_ID加密的MD5</li><li>MOVIE_ID: 电影ID，对应豆瓣的DOUBAN_ID</li><li>RATING: 评分</li><li>RATING_TIME: 评分时间</li></ul><h2 id="Comment数据格式"><a href="#Comment数据格式" class="headerlink" title="Comment数据格式"></a>Comment数据格式</h2><p>评论数据共4428475 条，用户638963个，电影68887包含7个字段，各个字段说明如下: </p><ul><li>COMMENT_ID: 评论ID</li><li>USER_MD5：USER_ID加密的MD5</li><li>MOVIE_ID: 电影ID，对应豆瓣的DOUBAN_ID</li><li>CONTENT: 评论内容</li><li>VOTES: 评论赞同数</li><li>RATINGS: 评论携带的分数</li><li>COMMENT_TIME: 评论时间</li></ul><h1 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h1><p>样例数据每个文件1000条数据，下载地址：<a href="http://moviedata.csuldw.com/dataset/moviedata_small.tar.gz" target="_blank" rel="noopener">moviedata_small.tar.gz</a>。完整的数据集有1G+，需要的用户可以点击后面的链接进行下载：<a href="https://pan.baidu.com/s/1YdCTPOcnowJuP5XZrjOiVA" target="_blank" rel="noopener">moviedata-10m.tar.gz</a>，密码获取方式如下(不定期更换): </p><ol><li>微信搜索<strong>【斗码小院】</strong>公众号并点击关注;</li><li>后台回复<strong>【电影数据集】</strong>获取密码.</li></ol><p>数据采集不易，为了初步了解多少人使用该数据，还请各位使用人员不要进行二次转发！”授人以鱼不如授人以渔”，<br>如果您对爬虫技术感兴趣，可前往Github参考笔者的<a href="https://github.com/csuldw/AntSpider" target="_blank" rel="noopener">AntSpider</a>项目源码。如果数据对您有用，可关注下公众号<a href="http://www.csuldw.com/assets/articleImg/2019/code-main-fun.png">斗码小院</a>，里面有数据收集、数据处理、数据建模等多篇文章，您的关注就是对我们最好的支持，另外，还可以在下方的Github的Star中点击一下。</p><h1 id="相关数据集推荐"><a href="#相关数据集推荐" class="headerlink" title="相关数据集推荐"></a>相关数据集推荐</h1><p>之前也有用户公开过豆瓣电影数据，这里提供下链接给大家参考下，同时提供一下movielens电影数据集的下载地址：</p><ol><li><a href="https://www.kaggle.com/utmhikari/doubanmovieshortcomments" target="_blank" rel="noopener">Douban Movie Short Comments Dataset</a></li><li><a href="https://www.kesci.com/home/dataset/58acf6f1d2445916845b4033" target="_blank" rel="noopener">豆瓣电影评分数据集</a></li><li><a href="https://grouplens.org/datasets/movielens/" target="_blank" rel="noopener">movielens-dataset</a></li></ol><h1 id="Contributor"><a href="#Contributor" class="headerlink" title="Contributor"></a>Contributor</h1><!-- [MIT](LICENSE) &copy;  --><ol><li><a href="http://www.csuldw.com">Diwei Liu</a></li><li><a href="">Yong Gao</a></li><li><a href="">Yina Xu</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/assets/articleImg/2019/moviedata-avator.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;数据集概况&quot;&gt;&lt;a href=&quot;#数据集概况&quot; class=&quot;headerlink&quot; title=&quot;数据集概况&quot;&gt;&lt;/a&gt;数据集概况&lt;/h1&gt;&lt;p&gt;本数据集采集于豆瓣电影，电影与明星数据收集于2019年8月上旬，影评数据(用户、评分、评论)收集于2019年9月初，共945万数据，其中包含14万部电影，7万演员，63万用户，416万条电影评分，442万条影评，该数据集正好弥补下国内公开电影​数据集的空缺。数据已经过初步清洗，可用于推荐系统、情感分析、QA问答、知识图谱等多个领域。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="豆瓣电影" scheme="https://www.csuldw.com/tags/%E8%B1%86%E7%93%A3%E7%94%B5%E5%BD%B1/"/>
    
      <category term="电影数据集" scheme="https://www.csuldw.com/tags/%E7%94%B5%E5%BD%B1%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    
      <category term="电影评分" scheme="https://www.csuldw.com/tags/%E7%94%B5%E5%BD%B1%E8%AF%84%E5%88%86/"/>
    
  </entry>
  
  <entry>
    <title>350万豆瓣电影评论数据爬取</title>
    <link href="https://www.csuldw.com/2019/09/05/2019-09-05-douban-comment-stat/"/>
    <id>https://www.csuldw.com/2019/09/05/2019-09-05-douban-comment-stat/</id>
    <published>2019-09-05T14:30:00.000Z</published>
    <updated>2019-10-22T12:44:34.977Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在八月上旬，爬取了13万电影数据和28万影评数据，并在后续的日子中对13万豆瓣电影做了系统的分析，并根据电影数据构建知识图谱，建立QA问答系统。近期，查看评论数据的时候发现，数据严重缺失，每个电影最多只有5条评论，同时缺少评论评分的字段，为此重新修改了爬虫模型，并重新爬取了350万的评论数据。本文，主要除了介绍评论的爬取方法以外，还对评论做了初步的分析，方便后续的实践工作。</p><a id="more"></a><p>系列文章：</p><ol><li><a href="http://www.csuldw.com/2019/08/29/2019-08-29-douban-spider/">13万豆瓣电影数据爬取原理剖析</a></li><li><a href="http://www.csuldw.com/2019/08/12/2019-08-12-douban-movies-statistics/">豆瓣13万电影数据统计与分析</a></li><li><a href="http://www.csuldw.com/2019/08/18/2019-08-18-building-knowledge-graph-based-on-douban-movie-data/">基于豆瓣电影数据构建知识图谱</a></li><li><a href="http://www.csuldw.com/2019/08/25/2019-08-25-kb-and-gb-movieqa/">基于知识库与知识图谱构建电影问答系统</a></li></ol><h2 id="评论数据爬取原理"><a href="#评论数据爬取原理" class="headerlink" title="评论数据爬取原理"></a>评论数据爬取原理</h2><p>评论数据的爬取是基于Scrapy框架的，本次修改的主要地方是将之前的爬虫API链接改成了评论详情页<code>https://movie.douban.com/subject/26709258/comments?status=P</code>,如Fig 1所示：</p><img src="/assets/articleImg/2019/douban-comment-page.png" width="80%" height="100%"><div class="caption">Fig 1. 豆瓣电影评论详情页</div><p>通过F12我们可以清楚的看到这个评论的源码细节，每条comment的都是在一个div里面，并且div的class为comment-item，如Fig 2所示。</p><p><img src="/assets/articleImg/2019/douban-comment-html.png" alt=""></p><div class="caption">Fig 2. 豆瓣电影评论详情页</div><p>对于这种有规律的html页面，使用scrapy进行处理真的太方便了，我们可以先把comment-item匹配出来，得到的是一个list，然后通过遍历这个list，将每条评论的细节信息抠出来，提取的信息包括：用户名、用户url、用户头像图片url、投票数、评分数、评论内容、评论ID、豆瓣电影ID。提取评论的核心匹配代码如下：</p><figure class="highlight golo"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#先获取item</span></span><br><span class="line">item_regx = '//div[<span class="meta">@class</span>=<span class="string">"comment-item"</span>]'</span><br><span class="line">comment_item_list = response.xpath(item_regx).extract()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> len(comment_item_list) &gt; <span class="number">1</span>:</span><br><span class="line">    <span class="keyword">for</span> resp_item <span class="keyword">in</span> comment_item_list:</span><br><span class="line">        <span class="keyword">print</span>(<span class="string">"resp_item======:"</span>,resp_item)</span><br><span class="line">        resp_item = etree.HTML(resp_item)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#用户url</span></span><br><span class="line">        url_regx = '//div[<span class="meta">@class</span>=<span class="string">"avatar"</span>]/a/<span class="meta">@href</span>'        </span><br><span class="line">        url_list = resp_item.xpath(url_regx)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#用户</span></span><br><span class="line">        username_regx = '//div[<span class="meta">@class</span>=<span class="string">"avatar"</span>]/a/<span class="meta">@title</span>'        </span><br><span class="line">        username_list = resp_item.xpath(username_regx)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#头像路径</span></span><br><span class="line">        avator_regx = '//div[<span class="meta">@class</span>=<span class="string">"avatar"</span>]/a/img/<span class="meta">@src</span>'        </span><br><span class="line">        avator_list = resp_item.xpath(avator_regx)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#投票数量</span></span><br><span class="line">        vote_regx = '//div[<span class="meta">@class</span>=<span class="string">"comment"</span>]/h3/span/span[<span class="meta">@class</span>=<span class="string">"votes"</span>]/text()'        </span><br><span class="line">        vote_list = resp_item.xpath(vote_regx)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#评分</span></span><br><span class="line">        rating_regx = '//div[<span class="meta">@class</span>=<span class="string">"comment"</span>]/h3/span[<span class="meta">@class</span>=<span class="string">"comment-info"</span>]/span[contains(<span class="meta">@class</span>,<span class="string">"allstar"</span>)]/<span class="meta">@class</span>'        </span><br><span class="line">        rating_list = resp_item.xpath(rating_regx)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 内容</span></span><br><span class="line">        comment_regx = '//div[<span class="meta">@class</span>=<span class="string">"comment"</span>]/p/span[<span class="meta">@class</span>=<span class="string">"short"</span>]/text()'        </span><br><span class="line">        comment_list = resp_item.xpath(comment_regx)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#评论ID</span></span><br><span class="line">        comment_id_regx = '//div[<span class="meta">@class</span>=<span class="string">"comment"</span>]/h3/span/input/<span class="meta">@value</span>'        </span><br><span class="line">        comment_id_list = resp_item.xpath(comment_id_regx)</span><br><span class="line"></span><br><span class="line">        comment = Comment()</span><br><span class="line">        comment['douban_id'] = douban_id</span><br><span class="line">        comment['douban_comment_id'] = comment_id_list[<span class="number">0</span>] <span class="keyword">if</span> len(comment_id_list) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line">        comment['douban_user_nickname'] = username_list[<span class="number">0</span>] <span class="keyword">if</span> len(username_list) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line">        comment['douban_user_avatar'] = avator_list[<span class="number">0</span>] <span class="keyword">if</span> len(avator_list) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line">        comment['douban_user_url'] = url_list[<span class="number">0</span>] <span class="keyword">if</span> len(url_list) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line">        comment['content'] = comment_list[<span class="number">0</span>] <span class="keyword">if</span> len(comment_list) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line">        comment['votes'] = vote_list[<span class="number">0</span>] <span class="keyword">if</span> len(vote_list) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line">        comment['rating'] = rating_list[<span class="number">0</span>] <span class="keyword">if</span> len(rating_list) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line">        yield comment</span><br></pre></td></tr></tbody></table></figure><p>当我们提取万当前页面之后，还需要找到下一页,如果存在下一页评论，就将下一页放入到Scrapy的Downloader里面，依次循环。这里说一下，由于在没登录状态下，豆瓣只允许翻100页，所以最后电影数据里面每部电影最多的也就220条。</p><figure class="highlight cs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#下一页</span></span><br><span class="line">regx = <span class="string">'//a[@class="next"]/@href'</span></span><br><span class="line">next_url = response.xpath(regx).extract()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">if</span> <span class="title">len</span>(<span class="params">next_url</span>)&gt;0:</span></span><br><span class="line"><span class="function">    url</span> = <span class="string">"https://movie.douban.com/subject/%s/comments%s"</span> %(douban_id, next_url[<span class="number">0</span>])</span><br><span class="line">    print(<span class="string">"=====request Next url================:"</span>, url)</span><br><span class="line">    bid = <span class="string">''</span>.<span class="keyword">join</span>(random.choice(<span class="keyword">string</span>.ascii_letters + <span class="keyword">string</span>.digits) <span class="function"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="title">range</span>(<span class="params"><span class="number">11</span></span>))</span></span><br><span class="line"><span class="function">    cookies</span> = {</span><br><span class="line">        <span class="string">'bid'</span>: bid,</span><br><span class="line">        <span class="string">'dont_redirect'</span>: True,</span><br><span class="line">        <span class="string">'handle_httpstatus_list'</span>: [<span class="number">302</span>],</span><br><span class="line">    }</span><br><span class="line">    <span class="function"><span class="keyword">yield</span> <span class="title">Request</span>(<span class="params">url, cookies=cookies,meta={<span class="string">'main_url'</span>:url}</span>)</span></span><br></pre></td></tr></tbody></table></figure><p>编写完上面的爬虫逻辑之后，配置好代理，启动程序，最后一晚上爬取了350万数据，差不多1G。样例数据如Fig 3所示：</p><p><img src="/assets/articleImg/2019/douban-comment-sample-1.png" alt=""></p><div class="caption">Fig 3. 豆瓣电影评论样例数据</div><h2 id="评论数据分析"><a href="#评论数据分析" class="headerlink" title="评论数据分析"></a>评论数据分析</h2><p>爬取到这么多数据，到底有多少可以用呢？为此笔者对数据进行了简单的探索。在笔者爬取的数据中，存在评论的电影数有7w+部，评论的用户数量有39w+，电影评论总数有350w+。 当然并不是所有的评论都是有效的，长度大于5的评论只有314w，大部分评论都是在30以内，属于短评数据。</p><p>这份数据，对于笔者来说，价值还是蛮大的，比如rating评分字段。虽然我们的数据有350w，但是带有rating的数据只有327w+，少了23w+。在这327w的评分里面，由于每部电影最多只能爬取220条，为此笔者对这份数据进行了统计，如Fig 4所示：</p><img src="/assets/articleImg/2019/douban-rating-graph.png" width="80%" height="100%"><div class="caption">Fig 4. 豆瓣评分分布图</div><p>整体上与我们的猜想差不多，呈现一个类似正太分布的图，两端小中间大。通过这部分数据统计，笔者也更加有信心相信这份评论具有代表性。相当于从每部电影里面采样数据，然后得到这些评论，数据量大，基本上也就接近实际的评论分布了。顺手做了张评论词云，没有去掉停留词（看起来没啥感觉），先凑合吧。</p><img src="/assets/articleImg/2019/douban-comment-word-cloud.png" width="80%" height="100%"><div class="caption">Fig 5. 豆瓣评论词云</div><p>最后爬取的数据量如Fig 6所示。</p><img src="/assets/articleImg/2019/douban_data_count.png" width="80%" height="100%"><div class="caption">Fig 6. 豆瓣电影与爬虫数据量截图</div><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>OK，关于豆瓣评论数据的细节到此为止吧，具体的源码已经上传到笔者的Github中：<a href="https://github.com/csuldw" target="_blank" rel="noopener">https://github.com/csuldw/AntSpider</a>，如有需要的，可以参考下，爬虫代码注释还需进一步完善，读者如有任何疑问可以关注下我的公众号【斗码小院】，<strong>如需要电影与影评数据的，在公众号中留言即可</strong>（13万电影+7万演员+350万影评数据，花重金买代理爬的数据，实在是不忍心一下子就分享出来哇，各位见谅！！！）。</p><img src="/assets/articleImg/2019/code-main-fun.png" width="70%" height="80%"><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="https://github.com/csuldw/AntSpider" target="_blank" rel="noopener">https://github.com/csuldw/AntSpider</a></li><li><a href="http://www.csuldw.com/2019/08/18/2019-08-18-building-knowledge-graph-based-on-douban-movie-data/">http://www.csuldw.com/2019/08/18/2019-08-18-building-knowledge-graph-based-on-douban-movie-data/</a></li><li><a href="http://www.csuldw.com/2019/08/12/2019-08-12-douban-movies-statistics/">http://www.csuldw.com/2019/08/12/2019-08-12-douban-movies-statistics/</a></li><li><a href="http://doc.scrapy.org/en/latest/topics/architecture.html" target="_blank" rel="noopener">http://doc.scrapy.org/en/latest/topics/architecture.html</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在八月上旬，爬取了13万电影数据和28万影评数据，并在后续的日子中对13万豆瓣电影做了系统的分析，并根据电影数据构建知识图谱，建立QA问答系统。近期，查看评论数据的时候发现，数据严重缺失，每个电影最多只有5条评论，同时缺少评论评分的字段，为此重新修改了爬虫模型，并重新爬取了350万的评论数据。本文，主要除了介绍评论的爬取方法以外，还对评论做了初步的分析，方便后续的实践工作。&lt;/p&gt;
    
    </summary>
    
      <category term="爬虫" scheme="https://www.csuldw.com/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="爬虫" scheme="https://www.csuldw.com/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="scrapy" scheme="https://www.csuldw.com/tags/scrapy/"/>
    
      <category term="豆瓣影评" scheme="https://www.csuldw.com/tags/%E8%B1%86%E7%93%A3%E5%BD%B1%E8%AF%84/"/>
    
  </entry>
  
  <entry>
    <title>13万豆瓣电影数据爬取原理剖析</title>
    <link href="https://www.csuldw.com/2019/08/29/2019-08-29-douban-spider/"/>
    <id>https://www.csuldw.com/2019/08/29/2019-08-29-douban-spider/</id>
    <published>2019-08-29T14:30:00.000Z</published>
    <updated>2019-10-22T12:45:03.951Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在前几篇文章，我们对豆瓣电影数据进行了一系列地处理、分析，并进行了QA问答建模等操作，有的童鞋可能对数据获取环节感兴趣。为此，本文将重点分享下我是如何构建豆瓣电影数据爬取模型，如何处理爬虫过程中遇到的问题，最终得到13w+电影数据加上28w+的影评数据。闲话少说，我们来看细节吧！</p><a id="more"></a><h2 id="Scrapy框架介绍"><a href="#Scrapy框架介绍" class="headerlink" title="Scrapy框架介绍"></a>Scrapy框架介绍</h2><p>本文介绍的爬虫模型是基于Scrapy框架构建的，Scrapy框架主要由五部分组成，如Fig 1所示，典型的东西南北中布局，分别为核心引擎Scrapy Engine、请求调度器Scheduler、网页下载器Downloader、数据提取与解析模块Spider以及数据存储Item Pipline。Scrapy这五个部分每部分都非常重要，同时还给了用户很大的设计空间，包括Middlemine的集成等。以前在编写微博数据爬虫模型的时候，采用的是原始urllib，编写代码确实耗费了不少时间。只是今非昔比，对于我们这种已经工作的时间非常宝贵的童鞋来说，确实耗不起了呀。</p><img src="/assets/articleImg/2019/scrapy_architecture_02.png" width="70%" height="600%"><div class="caption">Fig 1.Scrapy Data Flow(http://doc.scrapy.org/en/latest/topics/architecture.html)</div><h2 id="电影爬虫框架"><a href="#电影爬虫框架" class="headerlink" title="电影爬虫框架"></a>电影爬虫框架</h2><p>豆瓣电影数据爬虫框架如Fig 2所示，整体上与Scrapy相差无几，只是在使用Scrapy时进行了自定义，在请求和数据处理方面都做了新的集成。当然，并不是原始创新啦，只是实现并优化了这部分功能。</p><img src="/assets/articleImg/2019/spider-framework2.png" width="70%" height="80%"><div class="caption">Fig 2.豆瓣影评数据爬虫框架</div><p>既然谈到了框架，大致介绍下爬取豆瓣电影数据时的思路。整个模型有三个spider，第一个是爬取douban_id的spider，爬虫引擎通过种子url发起请求，然后经spider将豆瓣ID（电影ID）解析出来写入到数据库中，然后基于新的douban_id继续爬取子ID页面的内容，依次循环。第二个爬虫是movie_spider，用于从数据库中读取没有爬取过页面详情的douban_id，通过spider爬取数据然后写入到MySQL数据库。第三个是爬取评论的comment_spider，根据douban_id来爬取电影评论数据。</p><h3 id="三大核心"><a href="#三大核心" class="headerlink" title="三大核心"></a>三大核心</h3><p>总的来说，对不需要登录的网站做数据爬取非常简单，因为只需要将网页提取出来，然后解析入库就OK了，从网页中发现的新种子又重新插入到请求队列中即可！通过爬虫的编写，自己对爬虫的了解也更深了。总结一下爬虫过程中需要注意的三大要点:</p><ol><li><strong>灵活选取初始种子</strong>。爬虫的第一个核心就是起始种子，如果我们的种子选的不好，或是路径非法，那么爬虫很可能就夭折了，所以一定要再三确认第一个请求url是否靠谱。 </li><li><strong>绕开反爬虫机制</strong>。第二个核心点是如何绕开反爬虫检测，爬虫三大奇技：UA、Cookie、Proxy。如果你没设置这些，导致小爬虫被检测出来了，那么你可能就祸害了一群人，因为这将直接导致你的外网IP会被ban一段时间，期间，你所在的网络区域都将受到这台服务器的限制，好在豆瓣没有这么狠，第二天就好了。在编写爬虫模型的过程中，我是怎么处理的呢？首先，User-Agent随机获取，并不是单一的UA，而是从User-Agent Pool大文件中读取。其次，针对性的改造Cookie，这得具体情况具体分析了。最后，动态切换Proxy代理，在每次发起请求时，都从MySQL里随机读取proxy ip，而关于MySQL的proxy数据，则通过额外的定时任务定期从代理商获取，获取时会将失效的代理置为无效。</li><li><strong>优化爬虫性能</strong>。第三个核心要点是如何提高爬虫性能。首当其冲的就是多线程或是分布式，由于我是单机跑的，只用到了多线程。其次是对爬虫请求的去重，如果一个请求之前请求过了，那么下一次就不要浪费流量再次发送请求了！这个对于豆瓣数据的爬取真的很有用呀！</li></ol><h3 id="两大爬虫策略"><a href="#两大爬虫策略" class="headerlink" title="两大爬虫策略"></a>两大爬虫策略</h3><p>Scrapy支持两种数据爬取策略，分别为： 深度优先和广度优先，通过参数进行配置即可。但是这个地方值得注意一下，如果你采用广度优先，当爬虫异常退出之后，不做任何改动重启，由于你的初始种子不变，这将致使你的爬虫很长一段时间没有新的数据入库，因为一直爬取的都是上一次爬取过的！反过来，如果你采用深度优先进行爬取，你也会碰到同样的影响，因为种子的顺序是不变的！这个问题也就是上面提到的三大核心的第一大点，解决方法就是：可以随机的从数据库获取初始种子，或者从数据库获取最后一次入库的请求id作为新的种子。</p><h2 id="爬虫部署"><a href="#爬虫部署" class="headerlink" title="爬虫部署"></a>爬虫部署</h2><p>在爬虫的部署上，也碰到一些问题，不过都得到了很好的解决。最开始的时候，没有设置proxy，只是加了Cookie和UA，结果没到一个小时，IP就被禁了，整个局域网内都需要登录豆瓣才能访问具体的电影了，爬到的电影ID（douban_id）大概1000+。第二天，改写了proxy代理的获取方式，最开始尝试的是从proxy ip文件中获取，然后需要隔一段时间更新下proxy文件内容，比较繁琐，就将手动修改文件的方法改成了自动修改，然后运行了一段时间之后，更新的代理无法得到实时的获取，于是又将这种方法pass了。最后，想到的是从数据库中查询有效代理，而数据库的代理通过定时模型进行更改，无效的IP则及时清理掉。通过这种方式部署之后，效果马上就上去了。将scrapy的并发数调制100都没问题。最开始每分钟可爬取100+的电影数据，到后面每分钟只能爬取60+左右，影响这个数据的因素大概是网速以及到后期很多电影都已经爬取完了，数据对比的次数增加了。代理修改期间，有试过编写代码获取免费代理进行爬取，结果太慢了，而且免费的都不好用哇，最后选择了付费的代理。</p><h2 id="爬虫优化"><a href="#爬虫优化" class="headerlink" title="爬虫优化"></a>爬虫优化</h2><p>通过上面的方式，已经可以很好的部署一个爬虫模型了。但是，速度还是比较慢！！！尤其是douban_id的爬取，到后面就太慢了，更新的速度简直让人看着难受，几乎是几s一个，让我这种有强迫症的看着真是一种煎熬呀！为此，仔细查看了点击豆瓣电影时请求的数据接口，意外的发现了一个接口，这里分享一下，大家千万万万别说是我告诉你们的，如下：</p><pre><code>https://movie.douban.com/j/new_search_subjects?sort=T&amp;range=0,10&amp;tags=%E7%94%B5%E5%BD%B1&amp;start=1&amp;genres=剧情&amp;countries=中国大陆</code></pre><p>通过这个接口，我就可以很轻松的得到douban_id了呀，数据样例Fig 3所示：</p><!-- ![](/assets/articleImg/2019/douban_id_interface.png) --><img src="/assets/articleImg/2019/douban_id_interface.png" width="90%" height="80%"><div class="caption">Fig 3.豆瓣电影数据接口样例</div><p>通过这个接口，我们再根据豆瓣电影的分类来实现豆瓣电影ID的获取，类型提取页面为<a href="https://movie.douban.com/tag/#/" target="_blank" rel="noopener">https://movie.douban.com/tag/#/</a>：</p><img src="/assets/articleImg/2019/douban_movie_type.png" width="90%" height="80%"><div class="caption">Fig 4.豆瓣电影数据接口样例</div><p>获取的代码片段如下(仅供参考)：</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#按照分页来</span></span><br><span class="line">movie_type = [<span class="string">'剧情'</span>, <span class="string">'喜剧'</span>, <span class="string">'动作'</span>, <span class="string">'爱情'</span>, <span class="string">'科幻'</span>, <span class="string">'动画'</span>, <span class="string">'悬疑'</span>, </span><br><span class="line">              <span class="string">'惊悚'</span>, <span class="string">'恐怖'</span>, <span class="string">'犯罪'</span>, <span class="string">'同性'</span>, <span class="string">'音乐'</span>, <span class="string">'歌舞'</span>, <span class="string">'传记'</span>, </span><br><span class="line">              <span class="string">'历史'</span>, <span class="string">'战争'</span>, <span class="string">'西部'</span>, <span class="string">'奇幻'</span>, <span class="string">'冒险'</span>, <span class="string">'灾难'</span>, <span class="string">'武侠'</span>]</span><br><span class="line">movie_zone = [<span class="string">'中国大陆'</span>, <span class="string">'美国'</span>, <span class="string">'香港'</span>, <span class="string">'台湾'</span>, <span class="string">'日本'</span>, </span><br><span class="line">              <span class="string">'韩国'</span>, <span class="string">'英国'</span>, <span class="string">'法国'</span>, <span class="string">'德国'</span>, <span class="string">'意大利'</span>, </span><br><span class="line">              <span class="string">'西班牙'</span>, <span class="string">'印度'</span>, <span class="string">'泰国'</span>, <span class="string">'俄罗斯'</span>, <span class="string">'伊朗'</span>, </span><br><span class="line">              <span class="string">'加拿大'</span>, <span class="string">'澳大利亚'</span>, <span class="string">'爱尔兰'</span>, <span class="string">'瑞典'</span>, <span class="string">'巴西'</span>, <span class="string">'丹麦'</span>]</span><br><span class="line"><span class="keyword">for</span><span class="built_in"> type </span><span class="keyword">in</span> movie_type:</span><br><span class="line">    <span class="keyword">for</span> zone <span class="keyword">in</span> movie_zone:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(0,10000,20):</span><br><span class="line">            <span class="builtin-name">print</span>(<span class="string">"i is:"</span>, i)</span><br><span class="line">            url = str(<span class="string">"https://movie.douban.com/j/new_search_subjects?sort=T&amp;range=0,10&amp;tags=%E7%94%B5%E5%BD%B1&amp;start={页面}&amp;genres="</span>+<span class="built_in"> type </span>+ <span class="string">"&amp;countries="</span>+ zone +<span class="string">""</span>).format(页面 = i) </span><br><span class="line">            <span class="builtin-name">print</span>(url)</span><br><span class="line">            try:</span><br><span class="line">                txt = requests.<span class="builtin-name">get</span>(url)</span><br><span class="line">                data = json.loads(txt.text)[<span class="string">"data"</span>]</span><br><span class="line">            except:</span><br><span class="line">                <span class="builtin-name">print</span>(<span class="string">"over size:"</span>)</span><br><span class="line">                break</span><br><span class="line">            <span class="keyword">if</span> len(data) == 0:</span><br><span class="line">                break;</span><br><span class="line">            <span class="keyword">for</span> each <span class="keyword">in</span> data:</span><br><span class="line">                #save data</span><br></pre></td></tr></tbody></table></figure><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>OK，关于豆瓣影评数据爬取的细节内容，也差不多讲完了，代码层面涉及的不多，实现方面如果有疑问的可以公众号私聊我，希望对爬虫感兴趣的您有所帮助。至于代码何时开放出来，还请读者持续等待下，后续定会放到github中去的。有兴趣的，可以先关注下我的Github：<a href="https://github.com/csuldw" target="_blank" rel="noopener">csuldw</a>，或者关注我的公众号【斗码大陆】吧！</p><img src="/assets/articleImg/2019/wx_code.jpg" width="30%" height="80%"><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="http://www.csuldw.com/2019/08/25/2019-08-25-kb-and-gb-movieqa/">http://www.csuldw.com/2019/08/25/2019-08-25-kb-and-gb-movieqa/</a></li><li><a href="http://www.csuldw.com/2019/08/18/2019-08-18-building-knowledge-graph-based-on-douban-movie-data/">http://www.csuldw.com/2019/08/18/2019-08-18-building-knowledge-graph-based-on-douban-movie-data/</a></li><li><a href="http://www.csuldw.com/2019/08/12/2019-08-12-douban-movies-statistics/">http://www.csuldw.com/2019/08/12/2019-08-12-douban-movies-statistics/</a></li><li><a href="http://doc.scrapy.org/en/latest/topics/architecture.html" target="_blank" rel="noopener">http://doc.scrapy.org/en/latest/topics/architecture.html</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在前几篇文章，我们对豆瓣电影数据进行了一系列地处理、分析，并进行了QA问答建模等操作，有的童鞋可能对数据获取环节感兴趣。为此，本文将重点分享下我是如何构建豆瓣电影数据爬取模型，如何处理爬虫过程中遇到的问题，最终得到13w+电影数据加上28w+的影评数据。闲话少说，我们来看细节吧！&lt;/p&gt;
    
    </summary>
    
      <category term="爬虫" scheme="https://www.csuldw.com/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="爬虫" scheme="https://www.csuldw.com/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="豆瓣电影" scheme="https://www.csuldw.com/tags/%E8%B1%86%E7%93%A3%E7%94%B5%E5%BD%B1/"/>
    
      <category term="scrapy" scheme="https://www.csuldw.com/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>基于知识库与知识图谱构建电影问答系统</title>
    <link href="https://www.csuldw.com/2019/08/25/2019-08-25-kb-and-gb-movieqa/"/>
    <id>https://www.csuldw.com/2019/08/25/2019-08-25-kb-and-gb-movieqa/</id>
    <published>2019-08-25T14:00:00.000Z</published>
    <updated>2019-10-22T12:46:09.121Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在上一篇文章<a href="http://www.csuldw.com/2019/08/18/2019-08-18-building-knowledge-graph-based-on-douban-movie-data/">基于豆瓣电影数据构建知识图谱</a>里面，讲到如何采用Neo4j来构建电影图谱，并且掌握了Neo4j里面的初级查询功能（搜索实体属性、实体间的关系等）。接下来，将进入电影图谱问答系统的学习，通过知识库和知识图谱来构建电影问答系统。针对QA问答系统，由于笔者当前能力有限，本文仅介绍基于模板的知识库问答，讲解过程中如果有阐述不周之处，还请读者指出！下面，我们来看看如何对问题进行解析，并将图谱应用到电影问答系统。</p><a id="more"></a><p>往期回顾：</p><ul><li><a href="http://www.csuldw.com/2019/08/12/2019-08-12-douban-movies-statistics/">豆瓣13万电影数据统计与分析</a></li><li><a href="http://www.csuldw.com/2019/08/18/2019-08-18-building-knowledge-graph-based-on-douban-movie-data/">基于豆瓣电影数据构建知识图谱</a></li></ul><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>本文的电影QA问答系统工作流程如Fig 1所示，当接受到一个问题之后，我们首先对问题进行解析，包括分词、词性标注、关键字提取等预处理操作，并根据训练好的分类模型对问题进行分类，得到问题所属类之后，再根据图谱知识库搜索答案。在整个工作流程中，知识库在上一篇文章已经构建好了，并且已经存储到neo4j中。本文的主要工作是从问题到答案，端到端的实现。重点在如何对问题进行解析和分类，其次是借助neo4j进行答案检索。</p><img src="/assets/articleImg/2019/qa-system.png" width="80%" height="80%"><div class="caption">Fig 1.QA问答系统工作流程</div><h2 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h2><p>当用户提出一个问题：”张国荣演过哪些电影？”时，我们需要对文本数据进行处理。在这里可以采用jieba进行分词、词性标注等操作，然后提取关键字。比如上面的问句，通过jieba进行词性标注的结果会是什么样子的呢？结果如下：</p><pre><code>['张国荣/nr', '演/v', '过/ug', '哪些/r', '电影/n']</code></pre><p>我们看到“张国荣”被标记为nr，属于人名，演是动词，后面还有一些其他的，得到这个结果之后，接下来该怎么处理呢？我们再看看Fig 1，当问题解析完之后，我们需要对问题进行分类。说到分类，就必须得有个训练模型才行！下面就是一个问题多分类模型。基于问题模板数据来训练问题分类模型。</p><h2 id="基于NB的问题分类模型"><a href="#基于NB的问题分类模型" class="headerlink" title="基于NB的问题分类模型"></a>基于NB的问题分类模型</h2><p>在这个章节中，我们将采用简单的NB算法来训练我们的分类模型，感兴趣的童鞋可以试试其他的分类算法。</p><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>首先，来说说我们的数据集，样例数据如下，数据集包括三列，第一列是label（多分类），第二列是text（问题模板文本），第三列是描述（可忽略）。由于是实验demo，数据样例比较少，后续会根据需求不断扩展。</p><img src="/assets/articleImg/2019/template-train-dataset.png" width="40%" height="40%"><div class="caption">Fig 2.问题分类数据集样例</div><p>对于上面的数据集，可能有的童鞋会有点问题，nm表示什么？这里简单说一下，nm表示的电影的词性标注。在问题解析阶段，会对jieba的分词注入用户个人字典，每个电影的词性标注均为nm。这样，在分词之后，得到的结果也是nm。</p><p>例如：“红海行动讲的是什么故事？”，解析后的词与词性如下：</p><pre><code>['红海行动/nm', '讲/v', '的/uj', '是/v', '什么/r', '故事/n']</code></pre><h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><p>关于模型部分，，其中用到了sklearn、pandas、jieba库，完整的代码如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Sat Aug 24 14:38:04 2019</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: liudiwei</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line">jieba.load_userdict(<span class="string">"./data/userdict3.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuestionPrediction</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    问题预测: 采用NB进行多分类</span></span><br><span class="line"><span class="string">    数据集：template_train.csv</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 训练模板数据</span></span><br><span class="line">        self.train_file = <span class="string">"./data/template_train.csv"</span></span><br><span class="line">        <span class="comment"># 读取训练数据</span></span><br><span class="line">        self.train_x, self.train_y=self.read_train_data(self.train_file)</span><br><span class="line">        <span class="comment"># 训练模型</span></span><br><span class="line">        self.model=self.train_model_NB()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取训练数据</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">read_train_data</span><span class="params">(self,template_train_file)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        可改写为读取一个文件</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        train_x=[]</span><br><span class="line">        train_y=[]</span><br><span class="line">        train_data = pd.read_csv(template_train_file)</span><br><span class="line">        train_x = train_data[<span class="string">"text"</span>].apply(<span class="keyword">lambda</span> x: <span class="string">" "</span>.join(list(jieba.cut(str(x))))).tolist()</span><br><span class="line">        train_y = train_data[<span class="string">"label"</span>].tolist()</span><br><span class="line">        <span class="keyword">return</span> train_x,train_y</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train_model_NB</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        采用NB训练模板数据，用于问题分类到某个模板</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        X_train, y_train = self.train_x, self.train_y</span><br><span class="line">        self.tv = TfidfVectorizer()</span><br><span class="line"></span><br><span class="line">        train_data = self.tv.fit_transform(X_train).toarray()</span><br><span class="line">        clf = MultinomialNB(alpha=<span class="number">0.01</span>)</span><br><span class="line">        clf.fit(train_data, y_train)</span><br><span class="line">        <span class="keyword">return</span> clf</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self,question)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        问题预测，返回结果为label</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        question=[<span class="string">" "</span>.join(list(jieba.cut(question)))]</span><br><span class="line">        print(<span class="string">"question:"</span>, question)</span><br><span class="line">        test_data=self.tv.transform(question).toarray()</span><br><span class="line">        y_pred = self.model.predict(test_data)[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    question_model=QuestionPrediction()</span><br><span class="line">    print(question_model.predict(<span class="string">"红海行动讲的是什么故事？"</span>))</span><br></pre></td></tr></tbody></table></figure><p>通过<code>read_train_data</code>方法，我们得到的分词后的<code>x_train</code>如Fig 3的value字段所示。</p><img src="/assets/articleImg/2019/train-data-template.png" width="70%" height="70%"><div class="caption">Fig 3.训练数据样例</div><h3 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h3><p>单独执行上面的代码，最后返回的结果如Fig 4所示。最终将”红海行动讲的是什么故事？”划分到第三个类别。</p><img src="/assets/articleImg/2019/question-classification-result.png" width="80%" height="80%"><div class="caption">Fig 4.问题预测结果</div><h2 id="基于图谱的搜索"><a href="#基于图谱的搜索" class="headerlink" title="基于图谱的搜索"></a>基于图谱的搜索</h2><p>通过预测模型，我们可以将问题划分到某个模板中，接下来，再基于问题模板构造图谱搜索，比如上面的问题，我们将其划分到第三类问题：电影简介。接下来就可以采用py2neo连接neo4j图数据库，然后从图数据库中搜索出想要的答案。</p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3:nm 电影简介</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_movie_introduction</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">    movie_name = <span class="keyword">self</span>.get_movie_name()</span><br><span class="line">    cql = f<span class="string">"match(m:Movie)-[]-&gt;() where m.title=~'.*{movie_name}.*' return m.storyline"</span></span><br><span class="line">    print(cql)</span><br><span class="line">    answer = <span class="keyword">self</span>.graph.run(cql)[<span class="number">0</span>]</span><br><span class="line">    final_answer = movie_name + <span class="string">"主要讲述了"</span> + str(answer) + <span class="string">"！"</span></span><br><span class="line">    <span class="keyword">return</span> final_answer</span><br></pre></td></tr></tbody></table></figure><p>最后得到的结果如下：</p><img src="/assets/articleImg/2019/movie-qa-answer.png" width="100%" height="100%"><div class="caption">Fig 5.问题预测结果</div><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>本文主要讲解了如何端到端的构建QA系统，方法虽然比较简单，但可以让读者了解整个工作流，对后续的学习也会有很好的帮助。为了将结果更好的展示出来，笔者将QA问答做成了服务，部署到了服务器中，并在服务器中搭建neo4j，构建电影图谱，最后将QA问答与微信公众号进行了集成，结果如Fig 6所示。感兴趣的童鞋，可以到公众号里【斗码大陆】体验一下，由于知识库不全，答非所问之事还请多多包涵哈。文中代码仅供参考，具体的源码等整理完之后再发布到github中吧。关于如何发布QA服务和微信公众号自动问答的集成，我们下期再见！</p><img src="/assets/articleImg/2019/qa-result-wx.png" width="90%" height="90%"><div class="caption">Fig 6.电影QA集成微信公众号</div><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="http://www.csuldw.com/2019/08/12/2019-08-12-douban-movies-statistics/">豆瓣13万电影数据统计与分析</a></li><li><a href="http://www.csuldw.com/2019/08/18/2019-08-18-building-knowledge-graph-based-on-douban-movie-data/">基于豆瓣电影数据构建知识图谱</a></li><li><a href="https://en.wikipedia.org/wiki/Knowledge_Graph" target="_blank" rel="noopener">Knowledge Graph - Wikipedia</a></li><li><a href="https://neo4j.com/developer/guide-import-csv/" target="_blank" rel="noopener">Importing CSV Data into Neo4j</a>    </li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在上一篇文章&lt;a href=&quot;http://www.csuldw.com/2019/08/18/2019-08-18-building-knowledge-graph-based-on-douban-movie-data/&quot;&gt;基于豆瓣电影数据构建知识图谱&lt;/a&gt;里面，讲到如何采用Neo4j来构建电影图谱，并且掌握了Neo4j里面的初级查询功能（搜索实体属性、实体间的关系等）。接下来，将进入电影图谱问答系统的学习，通过知识库和知识图谱来构建电影问答系统。针对QA问答系统，由于笔者当前能力有限，本文仅介绍基于模板的知识库问答，讲解过程中如果有阐述不周之处，还请读者指出！下面，我们来看看如何对问题进行解析，并将图谱应用到电影问答系统。&lt;/p&gt;
    
    </summary>
    
      <category term="知识图谱" scheme="https://www.csuldw.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="知识图谱" scheme="https://www.csuldw.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
      <category term="豆瓣电影" scheme="https://www.csuldw.com/tags/%E8%B1%86%E7%93%A3%E7%94%B5%E5%BD%B1/"/>
    
      <category term="知识库问答" scheme="https://www.csuldw.com/tags/%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94/"/>
    
      <category term="电影问答" scheme="https://www.csuldw.com/tags/%E7%94%B5%E5%BD%B1%E9%97%AE%E7%AD%94/"/>
    
  </entry>
  
  <entry>
    <title>基于豆瓣电影数据构建知识图谱</title>
    <link href="https://www.csuldw.com/2019/08/18/2019-08-18-building-knowledge-graph-based-on-douban-movie-data/"/>
    <id>https://www.csuldw.com/2019/08/18/2019-08-18-building-knowledge-graph-based-on-douban-movie-data/</id>
    <published>2019-08-18T12:00:00.000Z</published>
    <updated>2019-10-22T12:46:03.257Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在上一篇文章<a href="http://www.csuldw.com/2019/08/12/2019-08-12-douban-movies-statistics/">豆瓣13万电影数据统计与分析</a>里面，笔者对豆瓣的电影数据进行了基本的统计和分析，通过数据我们对电影的整体情况有了初步认识。为了进一步利用好这份数据，本文将开启本博客新的知识领域——知识图谱。基于这13w豆瓣电影数据，提取出图谱数据，并以此建立图谱数据库，构建电影知识图谱。</p><a id="more"></a><h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p>从豆瓣爬取下来的电影数据比较丰富，包括电影名称、上映日期、国家、语种、导演、演员、标签、豆瓣评分、投票数量等信息，为了构建图谱数据库，我们需要对这张表进行转换，将其改造成图谱数据的形式。原始数据movie信息包括:name、alias、year、regions、genres、languages、release_date、directors、actors、storyline、mins、tags等，接下来，我们将从这份数据中抽取出电影表、演员表、电影类型表、电影与类型关系表、演员与电影关系表五张数据结构表（3张节点属性+2张关系）。</p><h3 id="电影类型表"><a href="#电影类型表" class="headerlink" title="电影类型表"></a>电影类型表</h3><p>在爬取的豆瓣电影数据中，一部电影对应了多种类型，内容采用“/”进行连接，如“剧情/同性”。为了更好地表示电影与类型的关系，我们需要将类型抽取出来，做成单表<code>genres.csv</code>，最终的类型共54种。字段如下：</p><ul><li><code>genre_id:ID(genre_id)</code>:类型ID</li><li><code>name</code>:电影类型名称</li><li><code>:LABEL</code>: 标记，取值为”Genre”</li></ul><p>类型样例数据如下：</p><img src="/assets/articleImg/2019/genres-head.png" width="35%" height="50%"><div class="caption">Fig 1.类型样例数据</div><h3 id="演员信息表"><a href="#演员信息表" class="headerlink" title="演员信息表"></a>演员信息表</h3><p>得到电影类型数据之后，接下来我们提取演员信息。演员人名也是从爬取的数据里面提取出来的，演员的个人信息从网上检索了一些，作为参考，后续继续补全。最后的演员表字段如下（actors.csv，10w+）：</p><ul><li><code>actor_id:ID(actor_id)</code>: 演员ID；</li><li><code>name</code>: 演员姓名；</li><li><code>birth</code>: 出生日期；</li><li><code>death</code>: 去世日期；</li><li><code>biography</code>: 个人介绍； </li><li><code>birthplace</code>: 出生日期；</li><li><code>:LABEL</code>: 演员表的标记，取值“Actor”。</li></ul><p>下图是演员表的样例数据：</p><img src="/assets/articleImg/2019/actor_info.png" width="100%" height="100%"><div class="caption">Fig 2.演员样例数据</div><h3 id="电影信息表"><a href="#电影信息表" class="headerlink" title="电影信息表"></a>电影信息表</h3><p>电影信息表基本保持原样，增加了电影表的标记<code>:LABEL</code>，便于neo4j图谱数据的识别，同时对原有的字段进行简单更换。如将<code>douban_id</code>作为<code>movie_id</code>,将<code>name</code>改成<code>title</code>等。电影表的字段如下（movies.csv）：</p><ul><li><code>movie_id:ID(movie_id)</code>: 电影ID</li><li><code>title</code>: 电影标题</li><li><code>actors</code>: 电影演员列表</li><li><code>alias</code>: 别名</li><li><code>directors</code>: 导演</li><li><code>rating</code>: 豆瓣评分</li><li><code>douban_votes</code>: 豆瓣投票人数</li><li><code>genres</code>: 电影类型</li><li><code>languages</code>: 电影语种</li><li><code>mins</code>: 电影时长</li><li><code>regions</code>: 发布区域</li><li><code>release_date</code>上映日期</li><li><code>storyline</code>：电影故事描述</li><li><code>tags</code>： 电影标签</li><li><code>year</code>：发行年份</li><li><code>:LABEL</code>: 电影表标记</li></ul><p>样例数据如下：</p><h3 id="电影-类型关系表"><a href="#电影-类型关系表" class="headerlink" title="电影-类型关系表"></a>电影-类型关系表</h3><p>对于豆瓣电影数据，电影与类型的关系是one-vs-more，为此我们对每部电影建立电影与类型的关系表数据（29w+），结果如下：</p><img src="/assets/articleImg/2019/movie2genre.png" width="40%" height="50%"><div class="caption">Fig 3.电影类型关系样例数据</div><h3 id="演员-电影关系表"><a href="#演员-电影关系表" class="headerlink" title="演员-电影关系表"></a>演员-电影关系表</h3><p>对于豆瓣电影数据，演员与电影的关系也是one-vs-more，为此我们对每个演员建立演员与电影的关系表数据（22w+）。结果如下：</p><img src="/assets/articleImg/2019/actor2movie.png" width="40%" height="50%"><div class="caption">Fig 4.演员与电影样例数据</div><h2 id="基于neo4j构建图谱"><a href="#基于neo4j构建图谱" class="headerlink" title="基于neo4j构建图谱"></a>基于neo4j构建图谱</h2><p>上面五张表有三张属性表，两张关系表，接下来我们将这些数据输入到neo4j图谱数据库里面。关于neo4j，不了解的可以自行去官方网站里查看下，本文不做过多的介绍。neo4j导入数据的方式有多种，由于我们的电影数据有10w+，关系数据有百万，所以采用的是官方指定的<code>neo4j-amin import</code>方式。步骤如下：</p><p>1）首先将数据放入neo4j目录下的<code>import</code>目录下；</p><img src="/assets/articleImg/2019/neo4j-import.png" width="80%" height="80%"><div class="caption">Fig 5.neo4j数据存放</div><p>2)如果neo4j处于启动状态，则进入neo4j的bin目录下执行<code>neo4j stop</code>将其关闭。然后执行下面命令，将node和关系录入到图数据库中。</p><figure class="highlight livescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">neo4j-admin <span class="keyword">import</span> --mode csv <span class="string">\</span></span><br><span class="line">--database movie_graph.db <span class="string">\</span></span><br><span class="line">--id-type INTEGER <span class="string">\</span></span><br><span class="line">--nodes ../<span class="keyword">import</span>/actors.csv <span class="string">\</span></span><br><span class="line">--nodes ../<span class="keyword">import</span>/movies.csv <span class="string">\</span></span><br><span class="line">--nodes ../<span class="keyword">import</span>/genres.csv <span class="string">\</span></span><br><span class="line">--relationships ../<span class="keyword">import</span>/movie2genre.csv <span class="string">\</span></span><br><span class="line">--relationships ../<span class="keyword">import</span>/actor2movie.csv <span class="string">\</span></span><br><span class="line">--ignore-extra-columns=<span class="literal">true</span>  <span class="string">\</span></span><br><span class="line">--ignore-missing-nodes=<span class="literal">true</span> <span class="string">\</span></span><br><span class="line">--ignore-duplicate-nodes=<span class="literal">true</span></span><br></pre></td></tr></tbody></table></figure><p>参数说明：</p><ul><li>id-type：将各个表的id数值类型进行初始化，上面设置的是INTEGER;</li><li>nodes：表示的节点；</li><li>relationships：表示的是关系表</li><li>database: 表示的是创建的数据库，默认是graph.db，如果存在则无法创建，需要删除方可。</li></ul><p>3）修改neo4j默认数据库。neo4j默认启动的图数据库为graph.db，因此如果创建了一个新的图数据库，直接启动neo4j是无法看到图数据库的相关信息，处理方式有多种，其一是在<code>$NEO4J_HOME/conf/neo4j.conf</code>中修改<code>dbms.active_database</code>参数。其二是将<code>$NEO4J_HOME/data/database/</code>目录下的graph.db文件换名，然后采用软连接将新库链接到graph.db上。</p><figure class="highlight stata"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cd</span> <span class="variable">$NEO4J_HOME</span>/data/database</span><br><span class="line">mv <span class="keyword">graph</span>.<span class="keyword">db</span> <span class="keyword">graph</span>.<span class="keyword">db</span>.bak</span><br><span class="line">ln -s movie_graph.<span class="keyword">db</span> <span class="keyword">graph</span>.<span class="keyword">db</span></span><br></pre></td></tr></tbody></table></figure><p>4）进入bin目录，采用<code>neo4j start</code>启动neo4j。</p><img src="/assets/articleImg/2019/neo4j-start.png" width="90%" height="90%"><div class="caption">Fig 6.neo4j启动结果</div><p>5)可视化结果查看。neo4j默认采用的是7474端口，当启动完成之后，我们可以在浏览器中输入<code>http://localhost:7474/</code>进入neo4j可视化界面，首先点击下图左上方的图标，然后选择一个relationship，即可查看图谱样例，如下：</p><img src="/assets/articleImg/2019/neo4j-visualization.png" width="90%" height="90%"><div class="caption">Fig 7.neo4j图谱结果</div><p>6）图谱搜索</p><p>通过neo4j图谱，我们可以搜索出很多有用的东西，比如通过下面的命令我们可以搜索到张国荣演过的电影（LIMIST 25Î），当我们双击东邪西毒时，还可以得到东邪西毒的相关演员：</p><figure class="highlight xl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">match</span>(n:Actor)-[]-&gt;</span>(m:Movie) <span class="keyword">where</span> n.<span class="keyword">name</span>=<span class="string">'张国荣'</span> return n,m LIMIT <span class="number">25</span></span><br></pre></td></tr></tbody></table></figure><img src="/assets/articleImg/2019/actor-movie-zgr.png" width="100%" height="100%"><div class="caption">Fig 8.neo4j 搜索样例</div><p>OK，其他的demo这里就不展示了，感兴趣的可以玩一下neo4j。</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>本文主要以实践为主，根据已有的电影数据提取出neo4j需要的图谱节点数据和节点关系，整体上比较简单。值得注意的是，通过neo4j-admin import 方法来导入csv，表头名称需要格外注意，neo4j有其特定的表头识别能力。对于图中的节点关系，实验中的设计的比较简单，后续还会将director抽取出来，以此引入movie与director的关系。另外，为了进一步的将图谱应用起来，接下来将会实现一个基于图谱的QA问答功能，具体细节，我们下周再见。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="http://www.csuldw.com/2019/08/12/2019-08-12-douban-movies-statistics/">豆瓣13万电影数据统计与分析</a></li><li><a href="https://en.wikipedia.org/wiki/Knowledge_Graph" target="_blank" rel="noopener">Knowledge Graph - Wikipedia</a></li><li><a href="https://neo4j.com/developer/guide-import-csv/" target="_blank" rel="noopener">Importing CSV Data into Neo4j</a>    </li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在上一篇文章&lt;a href=&quot;http://www.csuldw.com/2019/08/12/2019-08-12-douban-movies-statistics/&quot;&gt;豆瓣13万电影数据统计与分析&lt;/a&gt;里面，笔者对豆瓣的电影数据进行了基本的统计和分析，通过数据我们对电影的整体情况有了初步认识。为了进一步利用好这份数据，本文将开启本博客新的知识领域——知识图谱。基于这13w豆瓣电影数据，提取出图谱数据，并以此建立图谱数据库，构建电影知识图谱。&lt;/p&gt;
    
    </summary>
    
      <category term="知识图谱" scheme="https://www.csuldw.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="知识图谱" scheme="https://www.csuldw.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
      <category term="豆瓣电影" scheme="https://www.csuldw.com/tags/%E8%B1%86%E7%93%A3%E7%94%B5%E5%BD%B1/"/>
    
      <category term="数据分析" scheme="https://www.csuldw.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="Neo4j" scheme="https://www.csuldw.com/tags/Neo4j/"/>
    
  </entry>
  
  <entry>
    <title>豆瓣13万电影数据统计与分析</title>
    <link href="https://www.csuldw.com/2019/08/12/2019-08-12-douban-movies-statistics/"/>
    <id>https://www.csuldw.com/2019/08/12/2019-08-12-douban-movies-statistics/</id>
    <published>2019-08-11T17:00:00.000Z</published>
    <updated>2019-10-22T12:46:38.997Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>早在2016年，写过几篇关于爬虫的文章，并且针对新浪微博编写了一个小爬虫<a href="https://github.com/csuldw/WSpider/tree/master/SinaWSpider" target="_blank" rel="noopener">WSpider</a>，用于爬取用户信息和评论内容，可惜的是相关数据没保留下来，有点遗憾。最近，为了完善和巩固自己的知识体系，于是又动了动手爬取数据的念头。又考虑在NLP、推荐系统、深度学习业余项目中也能使用，最终选择了豆瓣电影，总共从豆瓣里爬取了13w+的电影，外加28万+影评（截止2019年8月上旬），电影内容包括电影名称、上映日期、国家、语种、导演、演员、标签、豆瓣评分、投票数量等条目。看到这些数据，真是让人心潮澎湃，为了探索电影数据背后的意义，本文将从各个不同的维度对电影数据进行分析。关于爬虫相关的内容，后续有时间再分享出来吧！</p><a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>从豆瓣爬取下来的电影数据横跨147年（1873年-2019年，部分年份未收录），共收集了131356部，电影包括剧情、喜剧、动作、爱情、科幻、动画、悬疑、惊悚、恐怖、犯罪等种类。如此漫长的电影历史，也再次刷新了自己对影视行业的认知。这么多年以来，电影的历史发展情况究竟如何？用户对电影的喜好程度又是何种现状？想必能说出详情的的人少之又少。没关系，本文将从数据里为你挖掘出更多的知识，让数据告诉我们真相。</p><h2 id="全量电影数据分析"><a href="#全量电影数据分析" class="headerlink" title="全量电影数据分析"></a>全量电影数据分析</h2><p>为了更好的利用数据，首先将对爬取到的全量数据进行分析，电影数据里面包含了多个字段，少量电影在部分字段取值为空，对整体影响不大，统计阶段暂且忽略不计。下面，将从上映日期、评分、发行国家、语种等方面进行进一步的探讨。</p><h3 id="基于上映日期统计"><a href="#基于上映日期统计" class="headerlink" title="基于上映日期统计"></a>基于上映日期统计</h3><p>从Fig 1可以看出，随着时代的推移，电影的整体数量呈现上升趋势，并在2017年达到了峰值，从数据上可以看出影视行业也随着时代的进步而逐渐走向繁荣。2019年由于还有一个季度未录入，因此在数据上呈现下降趋势。</p><img src="/assets/articleImg/2019/movies_number_of_each_year_stripplot.png"><div class="caption">Fig 1.每年上映的电影数（趋势图）</div><!-- <img src="/assets/articleImg/2019/movies_number_of_each_year_line.png"><div class="caption">Fig 1. 每年上映的电影数（趋势图）</div> --><h3 id="基于评分统计"><a href="#基于评分统计" class="headerlink" title="基于评分统计"></a>基于评分统计</h3><p>如此多的电影，对于用户来说，其价值如何呢？笔者根据豆瓣评分对电影进行了分析。豆瓣评分从0-10，由于评分为0的记录有可能是没有用户评分，因此这里将评分限制在大于0的区域。针对这13w电影，存在评分的电影仅38492部，近70%的电影都没有评分或者评分为0，这些有评分的电影里，2000年以后上映的电影有24865部，可以看出，过去生活水平比较低，对电影的关注也比较至少，近年来，生活质量提高了，对电影的关注度也开始活跃起来了。总的来讲，平均评分为6.6分，根据各个评分的数据，绘制了如下分布图。如Fig 2所示，电影评分整体上还是呈现出正态分布的形式，中心在7.0左右。</p><img src="/assets/articleImg/2019/movie_stat_by_score.png"><div class="caption">Fig 2.各个评分下的电影数统计</div><h3 id="基于发行地域统计"><a href="#基于发行地域统计" class="headerlink" title="基于发行地域统计"></a>基于发行地域统计</h3><p>评分可以直接看出用户对电影的偏爱程度，而从电影发行地域出发，可以看出这个地区电影行业的发展形势。从Fig 3可以看出，美国是电影发行量最大的区域，接近30%。其次为中国大陆、日本等地域。排名中香港、台湾单独列出来了，主要是按照地域进行划分来着。后面按照国家进行统计的地方，会将香港、澳门、台湾合并为中国。总的来说，美国的电影质量确实很高，当然国内电影也在逐渐朝着好的方向发展，比如今年出来的《哪吒》、《流浪地球》和之前的《让子弹飞》，在豆瓣的热度都比较大，很是不错，也期待后续能有更好的国内电影出品吧！</p><img src="/assets/articleImg/2019/movies_stat_by_regions.png"><div class="caption">Fig 3.按发行地域统计电影数（Top 50的发行地域）</div><h3 id="部分国家电影形势分析"><a href="#部分国家电影形势分析" class="headerlink" title="部分国家电影形势分析"></a>部分国家电影形势分析</h3><p>从发行地域来看，美国属于电影行业巨头，为了了解这些国家的历史影视情况，笔者筛选了部分国家，对候选国家的电影数进行统计分析，结果如Fig 4所示。从发行量来看，美国在上世纪50年代之前是要优于其他国家，在20世纪50年代到八十年代之间，整体的电影发行量不相上下，之后的30多年美国一直要领先了其他国家，直到2016年，中国的电影发行数量才超于美国。从图上可以看出，国内的电影从2010年才开始逐步提升的。</p><img src="/assets/articleImg/2019/movie_compare_each_country.png"><div class="caption">Fig 4. 各个国家每年发行的电影量</div><p>为了进一步了解用户对各个国家出品的电影的喜爱情况，笔者筛选最近30年的电影数据（1990-2019），对部分国家每年的平均评分进行了对比（豆瓣评分），如Fig 5所示。让人惊讶的是，随着电影数量增多的同时，电影整体的评分却在逐年下降，这难道意味着烂片越来越多了么？还是意味着以往评分的人数少，偏差太大？真是百思不得其解。仔细看看，发现中国从2016年开始，后续几年的电影评分整体上呈现一个上升趋势，看来国内电影形势真的是有好转呀。</p><img src="/assets/articleImg/2019/movie_score_stat_by_country.png"><div class="caption">Fig 5.不同国家每年发行的电影的平均评分（1990-2009）</div><h3 id="基于语种统计"><a href="#基于语种统计" class="headerlink" title="基于语种统计"></a>基于语种统计</h3><p>国家有语言之分，影片也有语种之分，笔者针对这些电影，还做了语种统计，如Fig 5所示，排名Top 3的分别为：英语、汉语普通话、日语。其中英语的数量几乎是汉语的3倍。</p><img src="/assets/articleImg/2019/movie_stat_by_language.png"><div class="caption">Fig 6.按语言统计电影数</div><p>为了便于观看，可以采用饼状图的形式描绘各个语种下的电影占比，如Fig 7所示，英语占比42%，汉语普通话仅13%！</p><img src="/assets/articleImg/2019/movie_language_stat_pieplot.png"><div class="caption">Fig 7.各个语种下的电影比例图</div><h3 id="电影类型词云"><a href="#电影类型词云" class="headerlink" title="电影类型词云"></a>电影类型词云</h3><p>这么多电影，都是什么类型的呢？由于一部电影可以划分成多个类型，因此为了更直观一点查看类型的整体情况，笔者采用了词云的方式，将影评类型先分词然后表现出来。如Fig 8所示。第一眼看到的当然就是剧情了，其次是喜剧、爱情、动作等类型。</p><img src="/assets/articleImg/2019/genres_cloud.png" width="65%" height="50%"><div class="caption">Fig 8.电影类型词云</div><h3 id="标签词云"><a href="#标签词云" class="headerlink" title="标签词云"></a>标签词云</h3><p> 每个电影除了上述属性外，还有一个比较好的数据——标签。对于笔者来说，标签数据真是太有用了。通过标签可以制作一个很好的标签云，如Fig 9所示（该图片的人物可是庄周，捂手笑）。</p><img src="/assets/articleImg/2019/tag_cloud_zg.png" width="65%" height="50%"><div class="caption">Fig 9. 电影标签云</div><h2 id="不同维度的Top-K电影分析"><a href="#不同维度的Top-K电影分析" class="headerlink" title="不同维度的Top K电影分析"></a>不同维度的Top K电影分析</h2><p>上面对电影整体上有了一个了解，下面从不同的维度看看Top K的电影都是哪些。</p><h3 id="豆瓣评分Top20电影"><a href="#豆瓣评分Top20电影" class="headerlink" title="豆瓣评分Top20电影"></a>豆瓣评分Top20电影</h3><p>首先，基于评分数据，筛选出Top 20，发现很多都是张国荣的演唱会之类的（香港），也算是最真诚的缅怀了。除了演唱会，就是德国的《梦工厂》、《肖申克的救赎》、《控方证人》、《平安结祈》等。没有看的同学，强烈推荐去看看呀，尤其是《肖申克的救赎》。</p><img src="/assets/articleImg/2019/movie_score_top20.png"><div class="caption">Fig 10. 豆瓣评分Top20的电影</div><h3 id="投票数Top-20的电影"><a href="#投票数Top-20的电影" class="headerlink" title="投票数Top 20的电影"></a>投票数Top 20的电影</h3><p>评分高不一定属于热评电影，因此笔者将投票数Top 20的电影也筛选了出来，这下可以看出排名第一的便是《肖申克的救赎》，其次是《这个杀手不太冷》，国内的《流浪地球》今年上映的，如今已经排名第三了，真是不错！之后便是《千与千寻》、《盗梦空间》、《我不是药神》、《泰坦尼克号》、《霸王别姬》、《三傻大闹宝莱坞》、《怦然心动》。这20部热评影片的评分基本在9分以上，除了国内的两部《流浪地球》、《让子弹飞》和美国的《头号玩家》，整体上投票多的电影评分都不会太低。在Top 10里面美国有4部、国内占了3部，其中2部是近2年，可见国内的电影近年来确实不错！</p><img src="/assets/articleImg/2019/movie_votes_top20.png"><div class="caption">Fig 11.投票数Top 20的电影</div><!-- ### 中国大陆电影豆瓣评分Top 20<img src="/assets/articleImg/2019/movie_china_top20_score.png"><div class="caption">Fig .</div> --><h3 id="中国大陆电影投票数Top-20"><a href="#中国大陆电影投票数Top-20" class="headerlink" title="中国大陆电影投票数Top 20"></a>中国大陆电影投票数Top 20</h3><p>趁着这股子劲，我们看看国内投票Top 20都有哪些，可以看出电影大多都是15年之后的，跟前面统计的电影数和平分数也对上了。</p><img src="/assets/articleImg/2019/movie_china_top20_votes.png"><div class="caption">Fig 12.中国大陆电影投票数Top 20</div><h3 id="美国电影投票数Top-20"><a href="#美国电影投票数Top-20" class="headerlink" title="美国电影投票数Top 20"></a>美国电影投票数Top 20</h3><p>最后，给大家看看美国电影投票数Top 20的都有哪些，业余时间，感兴趣的可以去看看，算是给大家分享的一点福利吧！</p><img src="/assets/articleImg/2019/movie_usa_votes_top20.png"><div class="caption">Fig 13.美国电影投票数Top 20</div><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>OK，关于豆瓣电影的数据分析，暂且先这样吧！很多细节部分尚未深入分析，后续有机会再进行补充下。之前看视频时，弹幕好多都说国内电影的水平提升了，现在看到这份数据，也确实证实了这一点，希望国内的电影能够持续进步！关于评论数据，主要用在NLP实践中，这次就不涉及了，后续有机会在分享出来。看到这些热评电影，真是有点振奋，有些已经录入到了自己的候选观影清单中，有时间去观赏一下。文中所有的图表均采用Python绘制，有兴趣的可以交流一下！最后，祝自己🎂，后续多总结，少熬夜，多锻炼身体，fighting！</p><span style="color:#999999;font-size: 1em">温馨提示：为防止博文被自动转发，相关读者可进入笔者首发网站进行阅读 <a href="https://www.csuldw.com/2019/08/12/2019-08-12-douban-movies-statistics/">https://www.csuldw.com/2019/08/12/2019-08-12-douban-movies-statistics/</a>。</span><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="https://pandas.pydata.org/pandas-docs/stable/" target="_blank" rel="noopener">pandas: powerful Python data analysis toolkit</a></li><li><a href="https://matplotlib.org/3.1.1/contents.html" target="_blank" rel="noopener">matplotlib doc</a></li><li><a href="https://www.csuldw.com">www.csuldw.com</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;早在2016年，写过几篇关于爬虫的文章，并且针对新浪微博编写了一个小爬虫&lt;a href=&quot;https://github.com/csuldw/WSpider/tree/master/SinaWSpider&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;WSpider&lt;/a&gt;，用于爬取用户信息和评论内容，可惜的是相关数据没保留下来，有点遗憾。最近，为了完善和巩固自己的知识体系，于是又动了动手爬取数据的念头。又考虑在NLP、推荐系统、深度学习业余项目中也能使用，最终选择了豆瓣电影，总共从豆瓣里爬取了13w+的电影，外加28万+影评（截止2019年8月上旬），电影内容包括电影名称、上映日期、国家、语种、导演、演员、标签、豆瓣评分、投票数量等条目。看到这些数据，真是让人心潮澎湃，为了探索电影数据背后的意义，本文将从各个不同的维度对电影数据进行分析。关于爬虫相关的内容，后续有时间再分享出来吧！&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="豆瓣电影" scheme="https://www.csuldw.com/tags/%E8%B1%86%E7%93%A3%E7%94%B5%E5%BD%B1/"/>
    
      <category term="数据分析" scheme="https://www.csuldw.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="数据挖掘" scheme="https://www.csuldw.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
  </entry>
  
  <entry>
    <title>Wide &amp; Deep与DeepFM模型</title>
    <link href="https://www.csuldw.com/2019/07/26/2019-07-25-introduction-of-deepFM/"/>
    <id>https://www.csuldw.com/2019/07/26/2019-07-25-introduction-of-deepFM/</id>
    <published>2019-07-25T17:00:00.000Z</published>
    <updated>2019-10-22T12:46:36.752Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>关于排序模型，可以采用传统的<a href="https://www.csuldw.com/2019/07/15/2019-07-15-gbdt-lr-framework/">GBDT+LR模型</a>，也可以采用<a href="https://www.csuldw.com/2019/02/08/2019-02-08-fm-algorithm-theory/">FM</a>系列算法，这两种模型笔者先前也有介绍，读者如有疑问，可花点时间前去回顾下。本文主要针对排序任务，介绍两种排序模型：Wide &amp; Deep 和 DeepFM。原本打算将两个模型分开单独成文，后来考虑到内容上的相关性，就将这两种模型写在一起了。文章编写时间紧凑，文中如有不对的地方，还请读者指出。另外，本文的所有截图和数据均来自DeepFM的相关paper。</p><a id="more"></a><h2 id="推荐系统结构"><a href="#推荐系统结构" class="headerlink" title="推荐系统结构"></a>推荐系统结构</h2><p>图一是Google app推荐系统的整体结构，当用户在app store上进行浏览的时候，就会产生相应的行为，包括用户、item、behavior等信息，这些信息都会逐一地写入log中。与此同时，这些用户行为也会伴随着queries和impression的产生。针对这些queries，首先app会针对用户的行为进行检索（Retrieval）。检索的结果是将相关的item list放入候选池（candidate pool），这一步通常是不同的机器学习模型+人为规则产生。接下来，优于候选池的结果是要大于我们推荐的item数量的，因此需要一个ranking系统对这些item进行打分。通常分数都是以概率的形式表示，即$p(y|x)$，其中$x$表示用户的特征，通常有用户特征、item特征、上下文特征等。$y$表示用户做出的某种动作，如购买或者下载等行为，$p$表示产生这种行为的概率。本文介绍的模型主要应用于第二阶段：ranking。</p><img src="/assets/articleImg/2019/recommendation-system-overview.png" width="65%" height="50%"><div class="caption">Fig 1：推荐系统整体结构.</div><h2 id="Wide-amp-Deep"><a href="#Wide-amp-Deep" class="headerlink" title="Wide &amp; Deep"></a>Wide &amp; Deep</h2><p>2016年，Google针对Google Play的业务场景，提出了Wide &amp; Deep模型。Paper开篇表示：广义线性模型结合非线性变换广泛的应用在大规模的输入数据稀疏的分类和回归任务中，特征交叉构建新特征的方法的确非常有效，但是却需要大量的特征工程。另外，基于DNN的方法虽然可以生成更多无法预见的高维特征，但是这种方法预测结果过于泛化，以至于推荐出来的物品相关性太弱。所以，Wide &amp; Deep也就相应的诞生了。实验结果也表明，Wide &amp; Deep方法要显著的优于wide-only和deep-only方法。下面来看看Wide &amp; Deep内部细节。</p><p>推荐系统与搜索排序面临的一大共同挑战就是：如何让模型的结果具有更好的memorization 和 generalization。也就是说，模型需要对用户的历史行为有记忆性，同时模型也要具有更好的泛化能力。记忆性可以通过主题信息或者与已有item更相关的信息进行反馈，泛化能力则是让推荐结果更具多样性。那么，有没有一种方法能够同时让模型具备这两个优点呢？当然，Wide &amp; Deep就是很好的模型。结构上，Wide &amp; Deep其实是LR和DNN的结合，其LR部分仍然需要人工特征工程以体现特征的组合，Deep部分属于DNN。</p><img src="/assets/articleImg/2019/wide-deep-structure.png" width="95%" height="50%"><div class="caption">Fig 2：Wide &amp; Deep层次结构图.</div><p>Wide &amp; Deep的层次结构图如Fig 2所示，左边为Wide部分$y=w^Tx$,输入不仅包括原始特征，还包括特征工程得来的转换特征（如cross-product transformation），右侧为Deep部分，本质上是一个feed-forward neural network。Wide部分为低阶特征（LR）模型，Deep部分属于带embedding的DNN模型，内部是独立的，但在output阶段再将Wide和Deep进行joint training，整个模型同时训练wide和deep部分。训练阶段的时候采用的是FTRL+L1来优化wide部分，deep部分则采用AdaGrad。    </p><p>$$<br>P(Y =1|x)=σ(\underbrace{w^T_{wide} [x,\phi(x)]}_{wide部分}+ \underbrace{w^T_{deep} a^{(lf)} }_{deep部分}+b)<br>\tag{1}\label{1}<br>$$</p><p>公式\eqref{1}中的$Y$为label，$\sigma$为sigmoid函数，$x$为原始特征，<strong>$\phi(x)$为cross product transformations特征，$b$为偏置项</strong>。$w_{wide}$为wide部分的权重，$w_deep$为应用于最终激活函数$a^{(lf)}$的权重。</p><p>Deep &amp; Wide确实是一大进步，但是对于wide部分，需要大量的人工进行特征工程，对于“想偷懒”的程序员来说，特征工程真的太麻烦了，为此DeepFM就随之诞生了。</p><h2 id="DeepFM"><a href="#DeepFM" class="headerlink" title="DeepFM"></a>DeepFM</h2><p>DeepFM源自华为，设计上主要源自2016年Wide &amp; Deep的启发。关于DeepFM的paper，2017年和2018年都发表了一篇，不过本文主要介绍DeepFM的结构，其他的暂且不论吧。其结构如Fig 3所示：</p><img src="/assets/articleImg/2019/wide-deep-framework-of-deepfm.png" width="98%" height="50%"><div class="caption">Fig 3：deepFM结构图（左图）.右图为DNN的两种形式，右上为DeepFM-D（集成DNN），右下为DeepFM-P（集成PNN）</div><p>DeepFM属于Wide &amp; Deep的变形，原始的Wide &amp; Deep模型Wide部分集成了人工特征工程得到的特征，DeepFM为了优化这一复杂的人工操作，将Wide部分替换成了FM，使其可以自动学习特征间的2阶组合。首先,有一个Dense Embedding层，对每个filed通过FM训练得到embedding的权值向量V，其中$V_{ij}$表示第$i$个特征embedding之后的隐向量的第$j$维值。FM部分和Deep部分共享相同的输入。Wide &amp; Deep中LR部分和Deep部分是完全独立的，LR部分的输入是稀疏特征，Deep部分稀疏特征先经过embeding层变成embeding向量，再传入隐层。DeepFM中每一个feature field经过embeding层转化为一个隐向量，多个特征field concat成一个密集向量分别作为FM部分和Deep部分的输入。FM部分将每个field的隐向量两两组合，最后在输出层和Deep部分输出concat成最终的输出层。整体上来说，DeepFM有以下三大优点：</p><ol><li>DeepFM可以end-to-end训练，不需要任何的特征工程。FM作为低阶特征，DNN作为高阶特征。</li><li>训练更加高效，Wide和Deep两者共享同一个输入和embedding向量。与Wide &amp; Deep相比，由于Wide &amp; Deep需要人工的进行特征工程，因此增加了模型的复杂度。</li><li>CTR预测结果更准确。</li></ol><p>在预测结果上，表达式如下：</p><p>$$<br>\hat{y}=sigmoid(y_{FM}(x) +y_{DNN}(x))<br>\tag{2}\label{2}<br>$$</p><p>其中$\hat{y}$为label，$y{FM}$为FM部分，$y_{DNN}$为DNN部分，下面分别介绍下FM和Deep部分。</p><h3 id="FM部分"><a href="#FM部分" class="headerlink" title="FM部分"></a>FM部分</h3><p>deepFM的wide部分是FM，即factorization machine，Rendle于2010年提出，用于构建推荐场景的相互作用特征，具体细节可以参考笔者之前的一片文章<a href="https://www.csuldw.com/2019/02/08/2019-02-08-fm-algorithm-theory/">FM算法原理分析与实践</a>。在deepFM中，FM主要用于学习低阶特征，其目标表达式如下：</p><p>$$<br>y_{FM}(x) = &lt;w, x&gt; + \sum_{i=1}^{d} \sum_{j=i+1}^{d} &lt;V_i, V_j&gt; x_i \cdot x_j<br>\tag{3}\label{3}<br>$$</p><h3 id="Deep部分"><a href="#Deep部分" class="headerlink" title="Deep部分"></a>Deep部分</h3><p>deepFM中的deep部分是一个前馈神经网络，主要用于学习高阶特征。但是与2016年原生的Wide &amp; Deep相比，其输入大有不同，原生的Wide &amp; Deep中DNN的输入可能极度稀疏，同时连续特征和类别特征夹杂在一起，并以field进行分组，在deepFM里，DNN的输入时连续的数值,并且与Wide部分共享输入。</p><img src="/assets/articleImg/2019/deepfm-dnn.png" width="65%" height="50%"><div class="caption">Fig 4：deepFM模型deep部分的结构（DeepFM-D）</div><p>其输出表达式如下：</p><p>$$<br>y_{DNN}(x) = W^{|H|+1} · a^{|H|} + b^{|H|+1}<br>\tag{4}\label{4}<br>$$</p><h2 id="模型对比"><a href="#模型对比" class="headerlink" title="模型对比"></a>模型对比</h2><p>本文的核心在于DeepFM，那么DeepFM与其他模型相比，性能究竟如何呢？如Fig 5所示，DeepFM与Wide &amp; Deep的区别在上面已经概括的差不多了，那么与FNN和PNN相比又有什么不同呢？首先简单介绍下什么是FNN和PNN。FNN是一个使用FM进行初始化的前馈神经网络，它采用FM进行pre-training，因此其精度和性能必然收到了FM阶段参数的影响，除此之外，FNN只能学习高阶特征，无法学习低阶特征。对于PNN，全称为Product-based Neural Network，为了获取高阶特征，PNN在embedding层和hidden layer之间增加了product layer。根据不同的product type，将其又划分为IPNN,OPNN,PNN*。与FNN一样，PNN忽略了低阶特征的信息，不过PNN不需要预排序。整体的对比结果如TABLE 1所示。</p><img src="/assets/articleImg/2019/deep-model-for-ctr-predictoin.png" width="98%" height="50%"><div class="caption">Fig 5：已有的基于深度学习的CTR预测模型：FNN、PNN、Wide &amp; Deep</div><img src="/assets/articleImg/2019/ctr-prediction-of-different-model.png" width="68%" height="50%"><div class="caption">TABLE 1: 不同的深度学习CTR预测模型比较</div><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>本文主要介绍了Wide &amp; Deep 和DeepFM，并对两者的结构进行了分析。从大的方向来看，两者都集成了低阶特征，相比之下，DeepFM少了人工构建特征的步骤，则显得更加地灵活。如果读者在细节上有疑问，可以参考原始paper，参考文献中均已给出。后续的文章中，将逐步增加相应模型的实践案例，敬请期待。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="https://arxiv.org/pdf/1703.04247.pdf" target="_blank" rel="noopener">DeepFM: A Factorization-Machine based Neural Network for CTR Prediction</a></li><li><a href="https://arxiv.org/pdf/1804.04950" target="_blank" rel="noopener">DeepFM: An End-to-End Wide &amp; Deep Learning Framework for CTR Prediction</a></li><li><a href="https://arxiv.org/pdf/1606.07792.pdf" target="_blank" rel="noopener">Wide &amp; Deep Learning for Recommender Systems</a></li><li><a href="https://www.csuldw.com/2019/07/15/2019-07-15-gbdt-lr-framework/">CTR预估经典模型：GBDT+LR</a></li><li><a href="https://www.csuldw.com/2019/02/08/2019-02-08-fm-algorithm-theory/">FM算法原理分析与实践</a></li><li><a href="https://www.cnblogs.com/arachis/p/FTRL.html" target="_blank" rel="noopener">https://www.cnblogs.com/arachis/p/FTRL.html</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于排序模型，可以采用传统的&lt;a href=&quot;https://www.csuldw.com/2019/07/15/2019-07-15-gbdt-lr-framework/&quot;&gt;GBDT+LR模型&lt;/a&gt;，也可以采用&lt;a href=&quot;https://www.csuldw.com/2019/02/08/2019-02-08-fm-algorithm-theory/&quot;&gt;FM&lt;/a&gt;系列算法，这两种模型笔者先前也有介绍，读者如有疑问，可花点时间前去回顾下。本文主要针对排序任务，介绍两种排序模型：Wide &amp;amp; Deep 和 DeepFM。原本打算将两个模型分开单独成文，后来考虑到内容上的相关性，就将这两种模型写在一起了。文章编写时间紧凑，文中如有不对的地方，还请读者指出。另外，本文的所有截图和数据均来自DeepFM的相关paper。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="推荐系统" scheme="https://www.csuldw.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="Deep Learning" scheme="https://www.csuldw.com/tags/Deep-Learning/"/>
    
      <category term="DeepFM" scheme="https://www.csuldw.com/tags/DeepFM/"/>
    
      <category term="Wide &amp; Deep" scheme="https://www.csuldw.com/tags/Wide-Deep/"/>
    
  </entry>
  
  <entry>
    <title>Boosting模型：lightGBM 算法原理</title>
    <link href="https://www.csuldw.com/2019/07/24/2019-07-24-an-introduction-tolightGBM-explained/"/>
    <id>https://www.csuldw.com/2019/07/24/2019-07-24-an-introduction-tolightGBM-explained/</id>
    <published>2019-07-24T15:01:00.000Z</published>
    <updated>2019-10-22T12:46:30.777Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在上篇文章<a href="https://www.csuldw.com/2019/07/20/2019-07-20-xgboost-theory/">Boosting模型：XGBoost原理剖析</a>一文中，详细介绍了陈天奇等人于2014年发布的XGBoost的内在原理，同时阐述了其特有的几大优点。然时代变化之迅速，新技术如春笋般应运而生，与日俱进。继xgboost之后，2016年微软进一步发布了GBDT的另一个实现：lightGBM。据悉，与XGBoost相比，在相同的运行时间下能够得到更好的预测性能。同时，在multi-class classification、click prediction和排序（learning to rank）都有很好的效果。本文将基于lightGBM的原始paper，对其原理进行归纳总结，以供后续参详，温习之用。</p><a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>为了确保文章的连续性，读者需对Boosting系列有一定的理解，在阅读本文核心内容之前，还读者预先在心里回答下下面几个问题：</p><ol><li>XGBoost的目标函数表达式？</li><li>XGBoost在GBDT的基础上做了哪些优化？</li><li>XGBoost的exact greedy Algorithm for split finding是什么？</li><li>XGBoost寻找分裂点的增益计算方法？</li><li>XGBoost的近似算法原理？</li><li>解释下Weighted Quantile Sketch原理？</li></ol><p>如果对上面的问题模棱两可的，可前往上一篇文章:<a href="http://www.csuldw.com/2019/07/20/2019-07-20-xgboost-theory/">Boosting模型：XGBoost原理剖析</a>，回顾一下。接下来将会针对XGBoost的不足进一步探讨lightGBM模型，相对于GBDT，lightGBM的精度与它相差不大，但是速度可以提升20倍。By the way，在学习lightGBM的时候，可以思考下下面几个问题（本文不会直接给出结论，读完之后，读者自然就明白了）：</p><ol><li>Adaboost、GBDT、XGBoost的样本梯度都是什么？</li><li>XGBoost的不足之处在哪里（lightGBM因何诞生，解决了什么问题）？</li><li>XGBoost的近似算法与lightGBM的histogram-based方法的区别？</li><li>什么是lightGBM？</li><li>lightGBM与XGBoost的结构有什么区别？</li></ol><p>不管是XGBoost还是lightGBM，模型的优化方向上必不可少的就是决策树的分裂上。下面，将重点介绍lightGBM算法在寻找最佳切分点上所做出的努力。</p><h2 id="寻找最佳分裂点"><a href="#寻找最佳分裂点" class="headerlink" title="寻找最佳分裂点"></a>寻找最佳分裂点</h2><p>lightGBM引入的核心思想包括两个方面：</p><ol><li>Histogram: 基于特征的数值进行分bin，然后基于bin的值寻找最佳分裂的bin值。</li><li>GOSS(Gradient based One Side Sampling): 移除小梯度样本，使用余留的样本做增益计算；</li><li>EFB(exclusive Feature Bundling)：bundle不会同时为零的特征（互斥），达到减少特征数量的目的。</li></ol><h3 id="Histogram分桶策略"><a href="#Histogram分桶策略" class="headerlink" title="Histogram分桶策略"></a>Histogram分桶策略</h3><p>GBDT是以决策树为基学习器的ensemble模型，在每次迭代中，GBDT都通过拟合负梯度来学习决策树，其中代价最大最耗时的就是寻找最佳切分点过程。一种方法是采用了预排序的算法，然后枚举所有可能的切分点，再寻找到增益最大的分裂点；另一中方法是基于histogram的算法，如下图所示。histogram算法并不是在预排序的特征值当中寻找最佳切分点，而是将连续的特征值进行离散化bin并放入不同的bucket，在训练的时候基于这些bin来构建特征histogram。这种做法效率更高，速度更快。如Algorithm 1所示，构建histogram的时间复杂度为O(#data $\times$ #feature)，寻找最佳分裂点的时间复杂度O(#bin $\times$ #feature)。</p><img src="/assets/articleImg/2019/histogram-and-goss.png" width="95%" height="50%"><div class="caption">左侧为histogram分桶策略，右侧为GOSS采样方法</div><h3 id="GOSS采样策略"><a href="#GOSS采样策略" class="headerlink" title="GOSS采样策略"></a>GOSS采样策略</h3><p>样本的梯度越小，则样本的训练误差越小，表示样本已经训练的很好了。最直接的做法就是丢掉这部分样本，然而直接扔掉会影响数据的分布，因此lightGBM采用了one-side 采样的方式来适配：GOSS。GOSS保留了所有的大梯度样本，对小梯度样本进行随机采样，同时为了保证分布的一致性，在计算信息增益的时候，将采样的小梯度样本乘以一个常量：$\frac{1-a}{b}$，$a$表示Top $a \times 100\%$的大梯度样本比例值，$b$表示小梯度样本的采样比值（很多文章里面理解成从省下的小梯度样本中采样b%的比例，其实是有误解的，这里的百分比是相对于全部样本而言的，即$b \% \times N$）。例如：100个样本中，大梯度样本有20个，小梯度样本80个，小梯度样本量是大梯度样本数据量的$4$倍，则大样本采样比率$a$等于$0.2$，假设小梯度样本的采样率为$30\%$，则$b=0.3$，那么小梯度样本的采样数目等于$b \times 100=30$个，为了保证采样前后样本的分布保持一致，最后小梯度样本采样得到的数据在计算梯度时需要乘以$\frac{1-a}{b}=\frac{1-0.2}{0.3}=\frac{8}{3}$(解释一下，乘以$1-a$是因为大梯度样本采样的整体是整个样本集$N$，小梯度样本采样的候选样本集为$(1-a)N$，除以$b$是因为采样导致小梯度样本的整体分布减少，为此需要将权重放大$\frac{1}{b}$倍)。整个过程如上图Algorithm 2所示。</p><p>原始情况下，在第$j$个特征，值为$d$处进行分裂带来的增益可以定义为：</p><p>$$<br>V_{j|O}(d) = \frac{1}{n_O}\left(\frac{(\sum_{x_i\in O:x_{ij} \le d}g_i)^2}{n_{l|O}^j(d)} + \frac{(\sum_{x_i\in O:x_{ij} \gt d}g_i)^2}{n_{r|O}^j(d)} \right)<br>\tag{1}\label{1}<br>$$</p><p>其中O为在决策树待分裂节点的训练集，$n_o = \sum I(x_i \in O)$，$n_{l|O}^j(d) = \sum I[x_i \in O: x_{ij} \le d]\ $ 并且$\ n_{r|O}^j(d) = \sum I[x_i \in O: x_{ij} \gt d]$。</p><p>采用GOSS之后，分裂的增益可表示为为：</p><p>$$<br>V_{j|O}(d) = \frac{1}{n_O}\left(\frac{(\sum_{x_i\in A_l} g_i + \frac{1-a}{b} \sum_{x_i\in B_l} g_i)^2 }{n_{l}^j(d)} + \frac{(\sum_{x_i\in A_r} g_i + \frac{1-a}{b} \sum_{x_i\in B_l} g_r)^2 }{n_{r}^j(d)} \right)<br>\tag{2}\label{2}<br>$$</p><p>其中$A_l = {x_i \in A: x_{ij} \le d}, A_r = {x_i \in A: x_{ij} \gt d}$，$B_l = {x_i \in B: x_{ij} \le d}, B_r = {x_i \in B: x_{ij} \gt d}$.</p><h3 id="EFB特征合并"><a href="#EFB特征合并" class="headerlink" title="EFB特征合并"></a>EFB特征合并</h3><p>高维数据通常是非常稀疏的，而且很多特征是互斥的（即两个或多个特征列不会同时为0），lightGBM对这类数据采用了名为EFB（exclusive feature bundling）的优化策略，将这些互斥特征分组合并为#bundle个维度。通过这种方式，可以将特征的维度降下来，相应的，构建histogram所耗费的时间复杂度也从O(#data $\times$ #feature)变为O(#data $\times$ #bundle)，其中#feature &lt;&lt; #bundle。方法说起来虽然简单，但是实现起来将面临两大难点：</p><ol><li>哪些特征可以bundle在一起；</li><li>如何构建bundle，实现特征降维。</li></ol><p>针对这两个问题，paper里面提到了两种算法：Greedy Bundling和Merge Exclusive feature。</p><p>对于第一个问题，将特征划分为最少数量的Bundle本质上属于NP-hard problem。原理与图着色相同，给定一个图G，定点为$V$，表示特征，边为$E$，表示特征之间的互斥关系，接着采用贪心算法对图进行着色，以此来生成bundle。不过论文中指出，对于特征值得互斥在一定程度上是可以容忍的，具体的读者可以参考下原paper(文献1)。具体的算法流程如Algorithm 3所示。</p><ol><li>首先构建一张带权重的图，权重为特征间的总冲突数；</li><li>对特征按照在图内的度进行降序排序；</li><li>检查排好序的特征，并将其划分到一个冲突较小的bundle里，如果没有就创建一个bundle。</li></ol><p>采用这种方法对于特征数目不大的数据，还算OK，但是对于超大规模的特征将会出现性能瓶颈。一个优化的方向就是：采用非0值得个数作为排序的值，因为非零值越多通常冲突就越大。</p><img src="/assets/articleImg/2019/greedy-bundling.png" width="50%" height="50%"><p>对于第二个问题：应该如何如何构建bundle？关键在于<strong>构建前的特征的值在构建后的bundle中能够识别</strong>。由于基于histogram的方法存储的是离散的bin而不是连续的数值，因此我们可以将不同特征的bin值设定为不同的区间即可。例如，特征A的bin值为[0,10)，特征B的bin值为[0,20)，要想将两个特征bin合并，我们可以将特征B的特征bin的值加上10，其取值区间将变为[0,30)。整个方法描述如下图所示。</p><img src="/assets/articleImg/2019/merge-exclusive-feature.png" width="50%" height="50%"><h3 id="leaf-wise生长策略"><a href="#leaf-wise生长策略" class="headerlink" title="leaf-wise生长策略"></a>leaf-wise生长策略</h3><p>另外，在树的生成方式上，lightGBM与XGBoost也是有区别的。lightGBM的生长策略是leaf-wise，XGBoost中决策树的生长策略是level-wise。对比之下，level-wise策略维持的是一颗平衡树，leaf-wise策略以降低模型损失最大化为目的，对当前level中切分增益最大的leaf节点进行切分。不过leaf-wise存在一个弊端，就是最后会得到一颗非常深的决策树，为了防止过拟合，可以在模型参数中设置决策树的深度。</p><img src="/assets/articleImg/2019/level-wise-and-leaf-wise.png" width="80%" height="50%"><div class="caption">左侧为level-wise（XGBoost），右侧为leaf-wise（lightGBM）</div><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>lightGBM主要提出了两个新颖的方法：GOSS和EFB。两者都对算法性能的提升有着重要的贡献，其中GOSS是针对分裂时样本的数目进行采样优化（行优化），EFB是针对特征进行合并，达到特征减少的目的（列优化）。实际上，XGBoost和lightGBM都属于GBDT的一种实现，旨在优化算法的性能，提升算法的训练速度，与XGBoost相比，lightGBM更适应于数据量更大的场景。从GBDT-&gt;XGBoost-&gt;lightGBM，在模型训练阶段，是不能百分百地断定lightGBM就比GBDT和XGBoost好，因为数据量的大小也决定了模型的可行性。所以实际场景中，还是建议一一尝试之后再做抉择，因为训练一个XGBoost或lightGBM，都是非常简单的事情。OK，基于Boosting模型的学习终于告一段落，后续将对基于深度学习的排序方法或CTR预估方法进行探讨，感谢读者耐心读完本文。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li>Ke, Guolin, et al. “<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/11/lightgbm.pdf" target="_blank" rel="noopener">Lightgbm: A highly efficient gradient boosting decision tree.</a>“ Advances in Neural Information Processing Systems. 2017.</li><li>Chen, Tianqi, and Carlos Guestrin. “<a href="https://arxiv.org/pdf/1603.02754" target="_blank" rel="noopener">Xgboost: A scalable tree boosting system.</a>“ Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. ACM, 2016.</li><li><a href="https://mlexplained.com/2018/01/05/lightgbm-and-xgboost-explained/" target="_blank" rel="noopener">LightGBM and XGBoost Explained</a></li><li><a href="https://xgboost.readthedocs.io/en/latest/" target="_blank" rel="noopener">xgboost docs</a></li><li><a href="https://lightgbm.readthedocs.io/en/latest/Features.html" target="_blank" rel="noopener">lightGBM docs</a></li><li><a href="http://www.csuldw.com/2019/07/20/2019-07-20-xgboost-theory/">Boosting模型：XGBoost原理剖析</a></li><li><a href="https://www.csuldw.com/2019/07/12/2019-07-12-an-introduction-to-gbdt/">Boosting模型：GBDT原理介绍</a></li><li><a href="https://towardsdatascience.com/lightgbm-vs-xgboost-which-algorithm-win-the-race-1ff7dd4917d" target="_blank" rel="noopener">XGBOOST vs LightGBM: Which algorithm wins the race</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在上篇文章&lt;a href=&quot;https://www.csuldw.com/2019/07/20/2019-07-20-xgboost-theory/&quot;&gt;Boosting模型：XGBoost原理剖析&lt;/a&gt;一文中，详细介绍了陈天奇等人于2014年发布的XGBoost的内在原理，同时阐述了其特有的几大优点。然时代变化之迅速，新技术如春笋般应运而生，与日俱进。继xgboost之后，2016年微软进一步发布了GBDT的另一个实现：lightGBM。据悉，与XGBoost相比，在相同的运行时间下能够得到更好的预测性能。同时，在multi-class classification、click prediction和排序（learning to rank）都有很好的效果。本文将基于lightGBM的原始paper，对其原理进行归纳总结，以供后续参详，温习之用。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="排序" scheme="https://www.csuldw.com/tags/%E6%8E%92%E5%BA%8F/"/>
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="推荐系统" scheme="https://www.csuldw.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="lightGBM" scheme="https://www.csuldw.com/tags/lightGBM/"/>
    
  </entry>
  
  <entry>
    <title>Boosting模型：XGBoost原理剖析</title>
    <link href="https://www.csuldw.com/2019/07/20/2019-07-20-xgboost-theory/"/>
    <id>https://www.csuldw.com/2019/07/20/2019-07-20-xgboost-theory/</id>
    <published>2019-07-20T09:01:00.000Z</published>
    <updated>2019-10-29T15:24:34.486Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>继前两篇文章<a href="https://www.csuldw.com/2019/07/12/2019-07-12-an-introduction-to-gbdt/">Boosting模型：GBDT原理介绍</a>和<a href="https://www.csuldw.com/2019/07/15/2019-07-15-gbdt-lr-framework/">CTR预估经典模型：GBDT+LR</a>之后，本文将继续探究下一个Boosting模型：XGBoost，全称eXtreme Gradient Boosting。XGBoost，听着名子就觉得特霸气，给人一种威风四面、震慑八方的实觉。事实上，其在实际比赛和项目实践中的效果也绝不含糊，名副其实呀！具体的数据这里就不展开了，明白就行。XGBoost本身是GBDT的一个高性能的开源库，是陈天奇等人于2014年开发，即可用于分类，也可用于回归。本文主要是介绍XGBoost的原理，同时深入分析下其在GBDT的基础上做了哪些改进点。关于XGBoost的实践，可以参考<a href="https://towardsdatascience.com/a-beginners-guide-to-xgboost-87f5d4c30ed7" target="_blank" rel="noopener">A Beginner’s guide to XGBoost</a>，是一篇很好的入门级应用教程。</p><a id="more"></a><p>阅读本文之前如果对决策树相关算法不太了解，可以参考笔者以前写的文章（仅供参考）：</p><ol><li><a href="http://www.csuldw.com/2015/05/08/2015-05-08-decision%20tree/">机器学习算法-决策树理论</a></li><li><a href="http://www.csuldw.com/2016/05/07/2016-05-07-feature-selection/">随机森林和mRMR特征选择</a></li><li><a href="http://www.csuldw.com/2015/07/22/2015-07-22%20%20ensemble/">机器学习-组合算法总结</a></li><li><a href="http://www.csuldw.com/2016/08/28/2016-08-28-adaboost-algorithm-theory/">Adaboost - 新的角度理解权值更新策略</a></li><li><a href="https://www.csuldw.com/2019/07/12/2019-07-12-an-introduction-to-gbdt/">Boosting模型：GBDT原理介绍</a></li></ol><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>XGBoost的原始paper将XGBoost的各个点都介绍的非常详细，有耐心的可以细细品味一下：<a href="https://arxiv.org/pdf/1603.02754" target="_blank" rel="noopener">XGBoost: A Scalable Tree Boosting System</a>。本文可以说是一篇paper读后小结，顺便为了内容实用点，顺便附上自己的小demo，便于后续回顾，如有杠精者，还请绕道而行哈。OK，下面进入正文吧！</p><h2 id="原理剖析"><a href="#原理剖析" class="headerlink" title="原理剖析"></a>原理剖析</h2><p>本章节将从以下几个方面介绍XGBoost：</p><ol><li>Tree Ensemble Model： 提升树模型</li><li>Object Function：XGBoost 目标函数及其求解</li><li>Optimization：寻找最佳分裂点</li></ol><h3 id="Tree-Ensemble-Model"><a href="#Tree-Ensemble-Model" class="headerlink" title="Tree Ensemble Model"></a>Tree Ensemble Model</h3><p>首先，XGBoost与GBDT一样，也是boosting模型，对于boosting decision tree, 下面这张图片可以很好的表达出来（引自XGBoost paper）：</p><img src="/assets/articleImg/2019/xgboost-tree-ensemble-model.png" width="70%" height="50%"><div class="caption">Tree Ensemble Model.输入样本的最终预测值等于各个树的预测值之和.</div><p>给定$n$个样本，$m$个特征的数据集$D= \left \{ (X_i, y_i) \right \} (|D|=n, X_i \in \mathbb{R}^m, y_i \in \mathbb{R})$，提升树模型采用K次迭代的结果作为输出结果。对于$X_i$的输出为$\hat{y}_i$，表达式为：<br>$$<br>\hat{y}_i = \phi(X_i) = \sum_{k=1}^K f_{k}(X_i), \ \ \ f_k \in F<br>\tag{1}\label{1}<br>$$</p><p>其中$F= \left \{ f(X)=w_{q(X)} \right \} (q:\mathbb{R} ^m \rightarrow T, w \in \mathbb{R}^T)$，表示提升树结构空间集，各个变量的含义如下：</p><ul><li>$q$表示树的结构，可以将样本映射到相应的叶子节点；</li><li>$T$表示提升树叶子节点的数量；</li><li>每个$f_k$都对应独立的树结构$q$和权重$w$，</li></ul><h3 id="Object-Function"><a href="#Object-Function" class="headerlink" title="Object Function"></a>Object Function</h3><p>XGBoost的目标函数表达式与GBDT不一样，有着进一步的优化，如下：</p><p>$$<br>L(\phi) = \underbrace{\sum_{i} l(\hat{y}_i, y_i)}_{损失函数项} + \underbrace{\sum_k \Omega(f_k)}_{正则项}<br>\tag{2}\label{2}<br>$$</p><p>上式看起来很简单，分两部分，第一部分为loss function，第二部分为regularization。各个变量的含义：$y_i$为true label，$\hat{y}_i$为predicted label，$l$为损失函数，$f_k$则表示第k颗树的结构，$\Omega$为正则项，表达式如下：</p><p>$$<br>\Omega(f) = \gamma T + \frac{1}{2} \lambda \parallel w \parallel ^2<br>\tag{3}\label{3}<br>$$</p><p>在XBGoost里面，正则项又包含两部分：一部分是提升树叶子节点的数量$T$，用于控制树的复杂度，可以达到剪枝的效果；另一部分为每颗树的叶子节点的权重$w$的平方和。正则项可以让学习器尽可能的避免over-fitting。    通过上面的目标函数，XGBoost的每颗子树就会倾向于学习比较简单的树，另外，<strong>当正则项参数为0时，目标表达式就会退化为传统的gradient tree boosting模型</strong>。</p><h3 id="目标函数求解"><a href="#目标函数求解" class="headerlink" title="目标函数求解"></a>目标函数求解</h3><p>对于上面的目标函数，如何求取最优解呢？对于损失函数部分，XGBoost采用了二阶泰勒展开式。可能有的童鞋会问，二阶泰勒展开式是什么样的，大学学的都忘记差不多了。没关系，快速传送门进Wiki，仔细回顾下：<a href="https://en.wikipedia.org/wiki/Taylor%27s_theorem" target="_blank" rel="noopener">Taylor’s theorem</a>.</p><p>对于XGBoost模型，对于第$t$次迭代，其表达式可扩展为：</p><p>$$<br>L^{(t)} = \sum_{i}^{n} l(y_{i}, \hat{y_{i}}^{(t-1)}+f_{t}(X_{i})) + \Omega(f_k)<br>\tag{4}\label{4}<br>$$</p><p>我们对上面的式子通过泰勒展开式展开，可以得到如下表达式：</p><p>$$<br>L^{(t)} \simeq \sum_{i}^{n} \left [ \color{red}{l(y_{i}, \hat{y_i}^{(t-1)}) + g_i \ f_t(X_i) + h_i \ f_t^2(X_i))} \right ] +  \Omega(f_t)<br>\tag{5}\label{5}<br>$$</p><p>红色部分为泰勒展开式部分，其中$g_i = \partial _{ \hat{y}^{(t-1)}} \ l(y_{i}, \ \hat{y}^{(t-1)})$, $h_i = \partial^2 _{ \hat{y}^{(t-1)}} \ \ l(y_{i}, \ \hat{y}^{(t-1)})$，分别为损失函数的一阶和二阶梯度。在计算过程中，我们还可以忽略常数项$l(y_i, \hat{y_i}^{(t-1)})$（表示的是目标值与$t-1$次迭代输出的预测值的差，第$t$并不会优化这一项，同时值也是固定的），因此，目标式子可以简化为：</p><p>$$<br>\hat{L}^{(t)}<br>= \sum_{i}^{n} \left [ g_i \ f_t(X_i) + h_i \ f_t^2(X_i)) \right ] +  \Omega(f_t)<br>\tag{6}\label{6}<br>$$</p><p>根据上式可以看出，目标函数会同时依赖每个数据点的在损失函数上的一阶导数和二阶导数。此外，我们看到右侧还有个正则部分，可以将正则项公式\eqref{3}代入进去，扩展公式可以进一步化解：</p><p>$$<br>\begin{aligned}<br>\hat{L}^{(t)}<br>&amp;= \underbrace{\sum_{i}^{n} \left [ g_i \ f_t(X_i) + h_i \ f_t^2(X_i)) \right ]}_{对样本进行积累} +  \color{red}{ \gamma T + \frac{1}{2} \lambda \underbrace{\sum_{j=1}^{T} \parallel w_j \parallel ^2}_{对叶子节点进行积累}} \\<br>&amp;= \sum_{i}^{n} \left [ g_i \ \color{blue}{w_{q(X_i)}} + h_i \color{blue}{\ w_{q(X_i)}^2} \right ] +   \gamma T + \frac{1}{2} \lambda \sum_{j=1}^{T} \parallel w_j \parallel ^2 \\<br>&amp;= \sum_{j=1}^{T}\left[ (\sum_{i \in I_j} g_i) w_j + \frac{1}{2} (\sum_{i\in I_{j}} h_i + \lambda ) w_j^2 \right] + \gamma T<br>\end{aligned}<br>\tag{7}\label{7}<br>$$</p><p>公式\eqref{7}第一行中的$f_t(X_i) 等于w_{q(X_i)}$，表示第$t$次迭代中(下标表示迭代次数)，样本$X_i$落在第$t$个树结构$f_t$中某个叶子节点的叶子权重值，代入后得到第二行，从第二行到第三行只是将各个样本的权重与一阶导和二阶导乘积之和，按照叶子节点进行分组，分组归并到各个叶子节点上的样本之和。最后化解得到第三行表达式，其为参数$w$的函数，为了求解它，我们可以通过求导并令导数等于0来求出$w$的极值点，然后将其回代到公式中，计算出目标表达式的值：</p><p>$$<br>\frac{\partial \hat{L}^{(t)}}{\partial w_j} =  \sum_{i \in I_j} g_i  + (\sum_{i\in I_{j}} h_i + \lambda ) w_j =0<br>\tag{8}\label{8}<br>$$</p><p>可以计算得到：</p><p>$$<br>w_j^{*} = -\frac{\sum_{i \in I_j} g_i}{\sum_{i\in I_{j}} h_i + \lambda }<br>\tag{9}\label{9}<br>$$</p><p>将公式\eqref{9}代入到公式\eqref{7}，可以推导出目标函数的表达式：</p><p>$$<br>\begin{aligned}<br>\hat{L}^{(t)}<br>&amp;= \sum_{j=1}^{T}\left[ (\sum_{i \in I_j} g_i) \color{blue}{(-\frac{\sum_{i \in I_j} g_i}{\sum_{i\in I_{j}} h_i + \lambda })} + \frac{1}{2} (\sum_{i\in I_{j}} h_i + \lambda ) \color{blue}{(-\frac{\sum_{i \in I_j} g_i}{\sum_{i\in I_{j}} h_i + \lambda })^2} \right] + \gamma T \\<br>&amp;= \sum_{j=1}^{T}\left[ (-\frac{(\sum_{i \in I_j} g_i)^2}{\sum_{i\in I_{j}} h_i + \lambda }) + \frac{1}{2} (\frac{(\sum_{i \in I_j} g_i)^2}{\sum_{i\in I_{j}} h_i + \lambda }) \right] + \gamma T \\<br>&amp;= -\frac{1}{2} \sum_{j=1}^{T} \frac{(\sum_{i \in I_j} g_i)^2}{\sum_{i\in I_{j}} h_i + \lambda } + \gamma T \\<br>\end{aligned}<br>\tag{10}\label{10}<br>$$</p><p>公式\eqref{10}表示的就是第$t$次迭代数的结构score，表示各个叶子节点上各个样本的一阶平方和与二阶加和之商的加和再加上树结构复杂度控制项$\gamma T$。应用公式\eqref{10}，只需要计算出每个叶子节点上各个样本的一阶梯度和二阶梯度的统计信息，就可以计算出整颗树的结构score，下图是XGBoost paper里面的图解：</p><img src="/assets/articleImg/2019/xgboost-tree-structure.png" width="80%" height="60%"><div class="caption">树结构score计算图解.</div><p>对公式\eqref{10}进行简化，就可以得到上图的结果：</p><p>$$<br>obj=- \frac{1}{2}\sum_{j=1}^T \left[{\color{red}{\frac{G_j^2}{H_j+\lambda}} } \right] +\gamma T<br>$$</p><p>那么对于决策树的单个节点，该如何进行划分呢？XGBoost与之前的GBDT、RF、ID3等树模型的计算方法都不一样，但是有一个共性就是计算分裂增益，通过比较分裂增益选择特征的切分点。分裂增益大小计算如下(对于单颗树而言，公式\eqref{10}中的$T=1$)，分裂增益值为$L - L_{left} - L_{right} $，推导步骤如下：</p><p>$$<br>\begin{aligned}<br>L_split<br>&amp;= L - L_{left} - L_{right} \\<br>&amp;= \left [ -\frac{1}{2}  \frac{(\sum_{i \in I } g_i)^2}{\sum_{i \in I} h_i + \lambda }   + \gamma \right]  - \left[  -\frac{1}{2}  \frac{(\sum_{i \in I_{L} } g_i)^2}{\sum_{i \in I_{L}} h_i + \lambda }   + \gamma \right ] - \left [\frac{1}{2}  \frac{(\sum_{i \in I_{R} } g_i)^2}{\sum_{i \in I_{R}} h_i + \lambda }   + \gamma\right] \\<br>&amp;= \color{red}{\frac{1}{2}\left [ \frac{(\sum_{i \in I_{L} } g_i)^2}{\sum_{i \in I_{L}} h_i + \lambda } +  \frac{(\sum_{i \in I_{R} } g_i)^2}{\sum_{i \in I_{R}} h_i + \lambda } -  \frac{(\sum_{i \in I } g_i)^2}{\sum_{i \in I} h_i + \lambda } \right] - \gamma}<br>\end{aligned}<br>\tag{11}\label{11}<br>$$</p><p>通过上式就可以计算出分裂的增益，然后确定分裂方式。关键是如何计算出最优分裂点呢？</p><h3 id="寻找最佳分裂点"><a href="#寻找最佳分裂点" class="headerlink" title="寻找最佳分裂点"></a>寻找最佳分裂点</h3><p>第一种是Exact Greedy Algorithm，一种贪心算法，列举出每个特征每个切分点的增益，然后将增益最大的切分点作为分裂点，这种方法固然会寻找到最优点，但是计算量特别大：</p><img src="/assets/articleImg/2019/xgboost-algorithm1-exact-greddy-algorith-for-split-finding.png" width="60%" height="50%"><p>第二种是Approximate Algorithm，近似算法，首先根据特征的百分位数获取候选的划分点（采用的是<a href="https://datascience.stackexchange.com/questions/10997/need-help-understanding-xgboosts-approximate-split-points-proposal" target="_blank" rel="noopener">Weighted Quantile Sketch</a>），然后将连续特征映射到采用候选值划分之后的若干个bucket中，然后基于划分数据数据的切分点采用上面的方式计算出最大的增益点，可在一定程度上提升算法的性能。 </p><img src="/assets/articleImg/2019/xgboost-a2-approximate-algorithm-for-split-finding.png" width="60%" height="50%"><p>在XGBoost paper提到，采用的是样本的二阶梯度$h_i$作为样本的权重，关于Weighted Quantile Sketch为什么采用$h_i$作为权重，可以通过化解目标表达式子\eqref{6}得到(原paper符号有误，请注意)：</p><!-- $$\begin{aligned}\sum_{i=1}^n\frac{1}{2}h_i[f_t(x_i) - (-g_i/h_i)]^2 + constant &= \sum_{i=1}^n\frac{1}{2}h_i[f_t^2(x_i) + 2\frac{f_t(x_i)g_i}{h_i} + (g_i/h_i)^2] \\\\&= \sum_{i=1}^n[g_if_t(x_i) + \frac{1}{2}h_if_t^2(x_i) + \frac{gi^2}{2h_i}]\end{aligned}$$ --><p>$$<br>\begin{aligned}<br>\sum_{i=1}^n[g_if_t(x_i) + \frac{1}{2}h_if_t^2(x_i) ]<br>&amp;= \sum_{i=1}^n\frac{1}{2}h_i[f_t^2(x_i) - 2f_t(x_i)(-\frac{g_i}{h_i}) + \underbrace{\color{blue}{(\frac{g_i}{h_i})^2 - (\frac{g_i}{h_i})^2}}_{构建平方项}] \\<br>&amp;=\sum_{i=1}^n\frac{1}{2}h_i[f_t(x_i) - (-\frac{g_i}{h_i})]^2 + \color{blue}{constant} \\<br>\end{aligned}<br>$$</p><p>关于Weighted Quantile Sketch算法，的确有点复杂，有兴趣的可以参考这篇博文笔记：<a href="https://yxzf.github.io/2017/04/xgboost-v2/" target="_blank" rel="noopener">XGBoost解读(2)–近似分割算法</a>。</p><p>第三种是针对稀疏特征的分裂方式，XGBoost可以自动学习稀疏特征的分裂方向：</p><img src="/assets/articleImg/2019/xgboost-a3-sparsity-aware-split-finding.png" width="60%" height="50%"><p>Sparsity Aware Split Finding算法会对比将特征值为missing的样本分配到左叶子结点和右叶子结点的两种情形，还可以为缺失值或者指定的值指定默认分裂方向，这中方式可以大大提升算法的效率，原paper中给出了具体的量化：50倍。 这种方式对性能的提升确实是非常可观的。</p><h2 id="XGBoost特点"><a href="#XGBoost特点" class="headerlink" title="XGBoost特点"></a>XGBoost特点</h2><p>上面介绍了XGBoost的原理，那么具体跟GBDT有哪些异同点呢？这里来归纳下XGBoost的模型特性：</p><ol><li>目标表达式：XGBoost优化了GBDT的目标函数。一方面，在GBDT的基础上加入了正则项，包括叶子节点的个数和每个叶子节点输出的L2模的平方和，正则项可以控制树的复杂度，让模型倾向于学习简单的模型，防止过拟合；另外，XGBoost还支持线性分类器，传统的GBDT是以CART算法作为基学习器。</li><li>Shrinkage：对每棵树的预测结果采用了shrinkage，相当于学习率，降低模型对单颗树的依赖，提升模型的泛化能力。</li><li>列采样：XGBoost借助了RF的优点，采用了列采样，进一步防止过拟合，加速训练过程，而传统的GBDT则没有列采样。</li><li>优化方法：XGBoost对损失函数的展开采用了一阶梯度和二阶梯度，而传统的GBDT只采用了一阶梯度。</li><li>增益计算：对分裂依据进行了优化。<strong>不同于CART算法</strong>，XGBoost采用了新的基于一阶导数和二阶导数的统计信息作为树的结构score，采用分列前的结构与分裂后的结构score的增益作为分裂依据，选择增益最大的特征值作为分裂点，替代了回归树的误差平方和。</li><li>最佳增益节点查找：XGBoost在寻找最佳分离点的方式上采用了近似算法，基于权重的分位数划分方式（权重为二阶梯度$h_i$）：Weighted Quantile Sketch。主要是对特征取值进行分桶，然后基于桶的值计算增益。</li><li>预排序。在寻找最佳增益节点时，将所有数据放入内存进行计算，得到预排序结果，然后在计算分裂增益的时候直接调用。</li><li>稀疏值处理：XGBoost可以自动学习稀疏值的分裂方向，也可以指定默认方向，这种方式大大可以大大提升模型的性能。</li><li>并行方式：XGBoost的并行在于特征层面，在训练每颗树之前，对特征进行预排序，后续的并行迭代过程中重复使用这个排序结果，可以大大减少计算量，并提升模型性能。在查找最佳分裂点的时候，需要选择增益最大的特征取值作为分裂点，那么各个特征的增益计算就可以采用并行的方式进行计算，采用的是多线程方式计算各个特征的各个值得分裂增益。</li></ol><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>OK，针对XGBoost的原理解析就此结束了，也算是给XGBoost一个交代吧。整篇文章花了不少时间在公式的勘误上面，不过在仔细检查每个公式的过程中，对XGBoost的公式推导又加深了好多遍，并且对公式的推导也有了更进一步的理解。其中有一点是比较突出的，很多人误认为XGBoost的增益是分裂后的减去分裂前，这是不正确的，其实是分裂前减去分裂后，可以通过公式计算出来。回头看看，XGBoost在工程实现上面也花了很大的心思，着实令人佩服，失敬失敬！接下来，将花点时间整理下Boosting的下一个模型：lightGBM。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="https://towardsdatascience.com/a-beginners-guide-to-xgboost-87f5d4c30ed7" target="_blank" rel="noopener">A Beginner’s guide to XGBoost</a></li><li><a href="https://datascience.stackexchange.com/questions/10997/need-help-understanding-xgboosts-approximate-split-points-proposal" target="_blank" rel="noopener">Need help understanding xgboost’s approximate split points proposal</a></li><li><a href="https://www.rose-hulman.edu/~bryan/lottamath/mtaylor.pdf" target="_blank" rel="noopener">Taylor’s Theorem in One and Several Variables</a></li><li><a href="https://yxzf.github.io/2017/04/xgboost-v2/" target="_blank" rel="noopener">XGBoost解读(2)–近似分割算法</a></li><li><a href="https://www.csuldw.com/2019/07/12/2019-07-12-an-introduction-to-gbdt/">Boosting模型：GBDT原理介绍</a></li><li><a href="http://www.csuldw.com/2015/05/08/2015-05-08-decision%20tree/">机器学习算法-决策树理论</a></li><li><a href="https://arxiv.org/pdf/1603.02754" target="_blank" rel="noopener">Xgboost: A scalable tree boosting system.</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;继前两篇文章&lt;a href=&quot;https://www.csuldw.com/2019/07/12/2019-07-12-an-introduction-to-gbdt/&quot;&gt;Boosting模型：GBDT原理介绍&lt;/a&gt;和&lt;a href=&quot;https://www.csuldw.com/2019/07/15/2019-07-15-gbdt-lr-framework/&quot;&gt;CTR预估经典模型：GBDT+LR&lt;/a&gt;之后，本文将继续探究下一个Boosting模型：XGBoost，全称eXtreme Gradient Boosting。XGBoost，听着名子就觉得特霸气，给人一种威风四面、震慑八方的实觉。事实上，其在实际比赛和项目实践中的效果也绝不含糊，名副其实呀！具体的数据这里就不展开了，明白就行。XGBoost本身是GBDT的一个高性能的开源库，是陈天奇等人于2014年开发，即可用于分类，也可用于回归。本文主要是介绍XGBoost的原理，同时深入分析下其在GBDT的基础上做了哪些改进点。关于XGBoost的实践，可以参考&lt;a href=&quot;https://towardsdatascience.com/a-beginners-guide-to-xgboost-87f5d4c30ed7&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;A Beginner’s guide to XGBoost&lt;/a&gt;，是一篇很好的入门级应用教程。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="XGBoost" scheme="https://www.csuldw.com/tags/XGBoost/"/>
    
      <category term="Boosting" scheme="https://www.csuldw.com/tags/Boosting/"/>
    
      <category term="XGoost" scheme="https://www.csuldw.com/tags/XGoost/"/>
    
  </entry>
  
  <entry>
    <title>CTR预估经典模型：GBDT+LR</title>
    <link href="https://www.csuldw.com/2019/07/15/2019-07-15-gbdt-lr-framework/"/>
    <id>https://www.csuldw.com/2019/07/15/2019-07-15-gbdt-lr-framework/</id>
    <published>2019-07-15T15:30:00.000Z</published>
    <updated>2019-07-31T14:17:26.500Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在<a href="http://www.csuldw.com/2019/07/12/2019-07-12-an-introduction-to-gbdt/">上一篇文章</a>，提到了Facebook 2014年发表的一篇采用GBDT构建特征的论文：<a href="https://quinonero.net/Publications/predicting-clicks-facebook.pdf" target="_blank" rel="noopener">Practical lessons from predicting clicks on ads at facebook</a>。为了深入学习GBDT，本文将重点分析这篇文章的思路，即CTR预估经典模型：GBDT+LR，一个曾风靡Kaggle、至今在工业界仍存有余温的传奇模型。同时采用scikit-learn里面的GBDT和LR来完成GBDT+LR的实验。</p><a id="more"></a><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>论文开篇介绍在计算广告领域，Facebook日活用户超过7.5亿，活跃广告超过1百万，这种数据规模对Facebook来说也是一大挑战。在这种情形下，Facebook是怎么做的呢？<strong>引入了一个组合决策树和LR的模型</strong>，该模型比单一的LR或GBDT的效果都要好，不仅将点击率提升了3%，还大大提升了整个系统的性能。除此之外，Facebook还在online learning、data freshness, 学习率等参数上进行了探索。</p><h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p>Facebook论文的Section 1给出了一个重要结论：<strong>只要有正确的特征和正确的模型，其他因素对模型结果的影响就非常小</strong>。那么，正确的特征是什么呢？论文对比了两类特征，一类是用户或广告的历史信息特征(historical features)，另一类是contextual features(上下文特征)，相比之下historical features要优于contextual features。正确的模型指的<strong>boosted decision tree + LR</strong>，其中boosted decision tree又相当于对重要的特征做了feature selection。</p><p>在Section 3描述了论文的核心模型，整个hybird模型框架示意图如下：</p><img src="/assets/articleImg/2019/gbdt-lr-hybird-model.png" width="70%" height="50%"><div class="caption">图1：混合模型框架.输入特征经提升树转换，而单颗树的输出又被当作LR的输入.</div><p>对于线性分类器，有两种特征转换方式可以提升分类器的精度。</p><ol><li>对于连续特征，可以对特征分bin，然后将bin的index作为类别特征，如此线性分类器就可以学习特征的非线性映射，这种方式里，学习有效的bin边界非常重要。</li><li>对于类别特征，可以采用笛卡尔积（Cartesian product）枚举出所有的二元特征组合。缺点是得到的特征会包含冗余特征。</li></ol><p>为此，基于GBDT的特征转换方法诞生了。</p><blockquote><p>基于GBDT的特征转换：将单棵决策树的结果看作是一个类别特征，取值为样本落入在决策树的叶子节点的编号。例如，图1中提升树包含两棵子树，第一棵子树包含3个叶子节点，第二棵树包含2个叶子节点。对于输入样本x（包含多个特征），采用提升决策树（GBDT）进行训练，最终对于第一棵子树上，样本分裂之后落到第二个叶子节点，对于第二棵子树，样本落到了第1个叶子节点，那么通过特征进行转化之后就是<code>[0,1,0,1,0]</code>。</p></blockquote><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>下面通过封装scikit-learn中的GBDT和LR，来实现GBDT+LR的实验。为了代码展示的更美观，这里将GBDT+LR封装到一个类里面<code>GradientBoostingWithLR</code>，输入数据集的格式与scikit-learn的iris数据格式一致（为了方便，后面也采取iris数据集进行训练和预测）。</p><h3 id="GBDT-LR核心方法"><a href="#GBDT-LR核心方法" class="headerlink" title="GBDT+LR核心方法"></a>GBDT+LR核心方法</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble.gradient_boosting <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model.logistic <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.ranking <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing.data <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GradientBoostingWithLR</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.gbdt_model = <span class="literal">None</span></span><br><span class="line">        self.lr_model = <span class="literal">None</span></span><br><span class="line">        self.gbdt_encoder = <span class="literal">None</span></span><br><span class="line">        self.X_train_leafs = <span class="literal">None</span></span><br><span class="line">        self.X_test_leafs = <span class="literal">None</span></span><br><span class="line">        self.X_trans = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gbdt_train</span><span class="params">(self, X_train, y_train)</span>:</span></span><br><span class="line">        <span class="string">"""定义GBDT模型</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        gbdt_model = GradientBoostingClassifier(n_estimators=<span class="number">10</span>, </span><br><span class="line">                                          max_depth=<span class="number">6</span>, </span><br><span class="line">                                          verbose=<span class="number">0</span>,</span><br><span class="line">                                          max_features=<span class="number">0.5</span>)</span><br><span class="line">        <span class="comment"># 训练学习</span></span><br><span class="line">        gbdt_model.fit(X_train, y_train)</span><br><span class="line">        <span class="keyword">return</span> gbdt_model</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">lr_train</span><span class="params">(self, X_train, y_train)</span>:</span></span><br><span class="line">        <span class="string">"""定义LR模型</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        lr_model = LogisticRegression()</span><br><span class="line">        lr_model.fit(X_train, y_train)    <span class="comment"># 预测及AUC评测</span></span><br><span class="line">        <span class="keyword">return</span> lr_model</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gbdt_lr_train</span><span class="params">(self,X_train, y_train,X_test)</span>:</span></span><br><span class="line">        <span class="string">"""训练gbdt+lr模型</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.gbdt_model = self.gbdt_train(X_train, y_train)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 使用GBDT的apply方法对原有特征进行编码</span></span><br><span class="line">        self.X_train_leafs = self.gbdt_model.apply(X_train)[:,:,<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 对特征进行ont-hot编码</span></span><br><span class="line">        self.gbdt_encoder = OneHotEncoder(categories=<span class="string">'auto'</span>)</span><br><span class="line">        self.gbdt_encoder.fit(self.X_train_leafs)</span><br><span class="line">        self.X_trans = self.gbdt_encoder.fit_transform(self.X_train_leafs)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#采用LR进行训练</span></span><br><span class="line">        self.lr_model = self.lr_train(self.X_trans, y_train)</span><br><span class="line">        <span class="keyword">return</span> self.lr_model</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gbdt_lr_pred</span><span class="params">(self, model, X_test, y_test)</span>:</span></span><br><span class="line">        <span class="string">"""预测及AUC评估</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.X_test_leafs = self.gbdt_model.apply(X_test)[:,:,<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        (train_rows, cols) =self.X_train_leafs.shape</span><br><span class="line">        X_trans_all = self.gbdt_encoder.fit_transform(np.concatenate((self.X_train_leafs, self.X_test_leafs), axis=<span class="number">0</span>))</span><br><span class="line">        </span><br><span class="line">        y_pred = model.predict_proba(X_trans_all[train_rows:])[:, <span class="number">1</span>]</span><br><span class="line">        auc_score = roc_auc_score(y_test, y_pred)</span><br><span class="line">        print(<span class="string">'GBDT+LR AUC score: %.5f'</span> % auc_score)</span><br><span class="line">        <span class="keyword">return</span> auc_score</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">model_assessment</span><span class="params">(self, model, X_test, y_test, model_name=<span class="string">"GBDT"</span>)</span>:</span></span><br><span class="line">        <span class="string">"""模型评估</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        y_pred = model.predict_proba(X_test)[:,<span class="number">1</span>]</span><br><span class="line">        auc_score = roc_auc_score(y_test, y_pred)</span><br><span class="line">        print(<span class="string">"%s AUC score: %.5f"</span> % (model_name,auc_score))</span><br><span class="line">        <span class="keyword">return</span> auc_score</span><br></pre></td></tr></tbody></table></figure><h3 id="训练与预测"><a href="#训练与预测" class="headerlink" title="训练与预测"></a>训练与预测</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    调用sklearn的iris数据集，将多类数据构造成2分类数据,同时切分训练测试数据集</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    iris_data = load_iris()</span><br><span class="line">    X = iris_data[<span class="string">'data'</span>]</span><br><span class="line">    y = iris_data[<span class="string">'target'</span>] == <span class="number">2</span></span><br><span class="line">    </span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.4</span>, random_state=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> X_train,X_test,y_train, y_test</span><br><span class="line"></span><br><span class="line">X_train,X_test,y_train, y_test = load_data()</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">gblr = GradientBoostingWithLR()</span><br><span class="line">gbdt_lr_model = gblr.gbdt_lr_train(X_train, y_train, X_test)</span><br><span class="line">gblr.model_assessment(gblr.gbdt_model, X_test, y_test)</span><br><span class="line">gblr.gbdt_lr_pred(gbdt_lr_model, X_test, y_test)</span><br></pre></td></tr></tbody></table></figure><p>训练样本落入的叶子节点情况如下（head 10）：</p><p><img src="/assets/articleImg/2019/gbdt_lr_output_leafs.png" alt=""></p><p>采用ont-hot编码之后，结果如下（1条样例）：</p><p><img src="/assets/articleImg/2019/gbdt_lr_output_leafs_one_hot.png" alt=""></p><p>由于数据集较小，最后预测的结果随机性比较大，在参数没有优化的情况下，有时候GBDT的结果反而好于GBDT+LR，所以调参的重要性也是非常大的。</p><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>OK，对于GBDT+LR的介绍到此结束，本文主要是补充一下GBDT的应用以及如何构建GBDT+LR模型（当然你也可以采用其他方式），文中如有纰漏，还望指出。接下来，将介绍boosting模型的下一个进阶算法：XGBoost。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="https://www.csuldw.com/2019/07/12/2019-07-12-an-introduction-to-gbdt/">Boosting模型：GBDT原理介绍</a></li><li>He, Xinran, et al. “<a href="https://quinonero.net/Publications/predicting-clicks-facebook.pdf" target="_blank" rel="noopener">Practical lessons from predicting clicks on ads at facebook.</a>“ Proceedings of the Eighth International Workshop on Data Mining for Online Advertising. ACM, 2014.</li><li>Friedman, Jerome H. “Greedy function approximation: a gradient boosting machine.” Annals of statistics (2001): 1189-1232.</li><li><a href="https://www.analyticsvidhya.com/blog/2015/11/quick-introduction-boosting-algorithms-machine-learning/" target="_blank" rel="noopener">Quick Introduction to Boosting Algorithms in Machine Learning</a></li><li><a href="https://medium.com/@eaifundoffical/gbdt-lr-code-practice-81f42dec6411" target="_blank" rel="noopener">GBDT+LR code practice</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在&lt;a href=&quot;http://www.csuldw.com/2019/07/12/2019-07-12-an-introduction-to-gbdt/&quot;&gt;上一篇文章&lt;/a&gt;，提到了Facebook 2014年发表的一篇采用GBDT构建特征的论文：&lt;a href=&quot;https://quinonero.net/Publications/predicting-clicks-facebook.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Practical lessons from predicting clicks on ads at facebook&lt;/a&gt;。为了深入学习GBDT，本文将重点分析这篇文章的思路，即CTR预估经典模型：GBDT+LR，一个曾风靡Kaggle、至今在工业界仍存有余温的传奇模型。同时采用scikit-learn里面的GBDT和LR来完成GBDT+LR的实验。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="GBDT" scheme="https://www.csuldw.com/tags/GBDT/"/>
    
      <category term="LR - 推荐系统" scheme="https://www.csuldw.com/tags/LR-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Boosting模型：GBDT原理介绍</title>
    <link href="https://www.csuldw.com/2019/07/12/2019-07-12-an-introduction-to-gbdt/"/>
    <id>https://www.csuldw.com/2019/07/12/2019-07-12-an-introduction-to-gbdt/</id>
    <published>2019-07-12T15:50:00.000Z</published>
    <updated>2019-07-25T16:59:31.709Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>说到GBDT，很多人都熟悉，那么我为什么还要在这里编写这篇文章呢？原因很简单，对我来说，在算法学习过程中，喜欢探究算法背后的公式推导，有时候自己也是一头雾水，但目的就是把每个步骤弄清楚，而每次重新回顾算法的时候，或多或少都会领悟到一些与之前不一样的东西，然后惊叹：噢，原来这里是这样，之前怎么就没领悟到，“书读百遍其义自见”大概就是这个道理！这篇文章其实很早之前就写了一部分，只是一直没有完整的整理出来，每次看到这篇文章放到draft里面，就总觉得有种有始无终的感觉。这回，在文章后面引入了实例解析部分，主要是希望后续回来温习的时候，能够快速地理解。</p><a id="more"></a><h2 id="引文"><a href="#引文" class="headerlink" title="引文"></a>引文</h2><p>在李航博士的《统计学习方法》里面讲到统计学习方法由三要素组成：模型、策略和算法。细的来讲，模型就是所要学习的条件概率分布或决策函数；策略指的是按照什么样的准则进行学习或者选择最优的模型；算法是学习模型的具体计算方法，本质上属于最优化问题。那么，对于GBDT算法来说，三要素又是什么呢？笔者的理解是（此处请读者保留自己的观点，如有误导，还请大神赐教）：模型表示的是Boosting模型，加法模型；策略指的是通过迭代来近似拟合残差以达到降低模型偏差的目的，算法则是基于梯度（一阶倒数）进行优化。</p><p>GBDT是基于决策树的，各类算法的大致时间线如下（从CART开始）：</p><ul><li>1984：CART “Classification &amp; Regression Trees” (Breiman)</li><li>1986：ID3（Quinlan）</li><li>1993：C4.5（Quinlan）</li><li>1995：Adaboost（Freund and Schapire）</li><li>1996：Bagging（Freund and Schapire）</li><li>2001：Random Forests（Breiman）</li><li>2001：Freund 在“Greedy function approximation: A gradient boosting machine”中，提出了Gradient Boosting 思想。</li><li>2014: XGBoost是陈天奇于2014年提出的一套并行boost算法工具库，2016年发表论文“XGBoost: A Scalable Tree Boosting System”。</li><li>2016：LightGBM是微软推出的boosting框架，并与2017年发表论文“LightGBM: A Highly Efficient Gradient Boosting Decision Tree”。</li></ul><p>从CART算法到boosting思想的提出，历时约11年，而从boosting思想到现在的lightGBM转眼又是21年，加起来都超出了我的年纪了呐。好了，闲话少说，直奔主题吧，这篇文章介绍的就是GBDT，对于xgboost和lightGBM，暂且不表。说到底，GBDT也是xgboost和lightGBM的基础中的基础，核心中的核心。</p><h2 id="GBDT三大核心"><a href="#GBDT三大核心" class="headerlink" title="GBDT三大核心"></a>GBDT三大核心</h2><p>GBDT这个名字非常有深意：G-gradient（表示该算法是基于梯度的），B-Boosting（表示该算法是boosting模型），DT-decision tree（表示算法内部使用的是决策树）。在这篇文章，主要也是从这三个要点进行细化：</p><ol><li>提升方法（加法模型+前向分步算法）；</li><li>梯度提升：梯度与残差；</li><li>决策树：CART回归树。</li></ol><h3 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h3><p>在进入GBDT理论推导之前，必须得聊聊Boosting思想。Boosting方法本质上属于加法模型$\eqref{1}$（各个基分类器的线性组合），同时属于前向分步算法，它每轮训练的模型都是在上一个模型的基础上进行进一步优化，通过不断迭代来降低整个模型的偏差，所以Boosting模型的一个特点就是低偏差、高方差，最典型的代表就是Adaboost算法。与其相反的就是Bagging算法，最典型的代表就是RF。Bagging模型的各个子模型之间互不影响，最后通过加权的方式组合到一起，以达到降低方差的效果，所以说Bagging是高偏差、低方差的模型。</p><p>$$<br>f_M(x)=\sum^M_{m=1}T(x,θ_m)<br>\tag{1}\label{1}<br>$$</p><p>对Boosting和Bagging模型原理模糊的童鞋可以参阅下笔者几年前的文章<a href="http://www.csuldw.com/2015/07/22/2015-07-22%20%20ensemble/">机器学习-组合算法总结</a>。</p><p>下面来看看梯度提升过程中的梯度和残差。</p><h3 id="梯度与残差"><a href="#梯度与残差" class="headerlink" title="梯度与残差"></a>梯度与残差</h3><p>在RF、Adaboost等加法模型中，都是通过直接拟合真实值来构建模型的，而在GBDT里面（下面这句话是重点，认真理解，并且多读几遍）：非首轮迭代的模型拟合的目标值不再是真实值，而是一个梯度值，主要是<strong>通过拟合损失函数的负梯度值在当前模型的值</strong>来构建模型。其梯度值表达式如下：</p><p>$$<br>\large {r_{mi}} = -\left[\frac{\partial L(y_i,f(x_i))}{\partial f(x_i)} \right]_{f(x)=f_{m-1}(x)}<br>\tag{2}\label{2}<br>$$</p><p>当损失函数为平方损失的时候，损失函数可以表示为：$L(y_i,f(x_i)) = \frac{1}{2}(y_i - f(x_i))^2$，此时当前模型下损失函数的负梯度值正好等于残差：$r_{mi} = y_i - f(x_i)$。了解到GBDT的这一特性之后，下面我们来看看第三个要点：CART决策树。</p><h3 id="DT：CART"><a href="#DT：CART" class="headerlink" title="DT：CART"></a>DT：CART</h3><p>GBDT属于Boosting模型，对于boosting模型而言，都存在基模型，那么GBDT的基模型是什么呢？CART。CART分类回归树，是决策树的一种，它即可用于分类也可用于回归。在分类任务中，树的分裂准则采用Gini index（基尼指数），而在回归任务中采用MSE（均方误差）。关于Gini Index的描述如下：</p><blockquote><p>在分类任务中，假设当前样本集中有$k$个类别，样本点属于第$k$类的概率为$p_k$,那么样本概率分布的基尼指数为：<br>$$<br>Gini(p) = 1-\sum_{k=1} p_{k}^2<br>\label{3}\tag{3}<br>$$</p></blockquote><h2 id="原理剖析"><a href="#原理剖析" class="headerlink" title="原理剖析"></a>原理剖析</h2><p>在2001年的论文<a href="https://statweb.stanford.edu/~jhf/ftp/trebst.pdf" target="_blank" rel="noopener">Greedy function approximation: A gradient boosting machine</a>中，介绍了梯度提升的基本思想，本文仅仅摘录了论文gradient boosting思想部分（如果想要全面了解GBDT，还请读者移步到原始paper中），梯度提升的算法流程如下：</p><p><img src="/assets/articleImg/2019/gbdt-algorithm1-gradient-boost.png" alt=""></p><p><strong>算法解析</strong>：</p><ol><li>第1行初始化模型，估计损失函数极小化的常数值；</li><li>第2行迭代的训练M个子模型；</li><li>第3-6行为子模型的训练细节，<ul><li>首先第3行是计算损失函数$L(y_i, F(x_i))$在当前模型$F(x_i)$的负梯度值，将其作为残差的估计值；</li><li>第4行是使用负梯度值$\hat{y}_i$作为目标值，拟合一颗回归树模型$h(x_i;a)$，从而得到当前模型的参数$a_m$。</li><li>第5行是一个线性搜索过程，论文中将其成为Shrinkage($ρ_m$,学习率)。</li><li>第6行是利用加法模型，更新回归树，得到$F_m(x)$；</li></ul></li></ol><p>对于上面的算法，损失函数不一样就会产生不同变形算法，具体内容读者可以参考原paper，这里暂且举一个例子来说明一下。当损失函数为平方损失时，各个阶段的变换为：</p><p>当$L(y,F) = \frac{1}{2}(y-F)^2$，Algorithm 1中第3行的$\hat{y}_i = y_i - F_{m-1}(x_i)$，即残差（真实值-当前模型的值）。那么，第4行就相当于用一个回归树模型来拟合残差。第5行的参数$ρ_m$即为第4行的$\beta$，即$ρ_m=\beta_m$。由此，便得出基于平方损失函数的gradient boosting算法模型。</p><p><img src="/assets/articleImg/2019/gbdt-algorithm2-LS_Boost.png" alt=""></p><p>Algorithm 2只提及了整个算法的过程，细节如何呢？前面说到GBDT采用的是CART算法来拟合模型（损失函数在当前模型的负梯度值），既然如此，<strong>每次拟合之后每颗树叶子节点的取值是多少呢</strong>？Algorithm 3中展示的是LAD（Least-absolute-deviation）回归的regression tree的具体原理。在LAD_TreeBoost里面，算法的第4行表示的是以$(\hat{y}_i,x_i)^N_1$为训练样本来拟合一颗回归树模型，最终得到叶子节点区域。第5行则表示如何计算第$m$轮迭代中，第$j$个叶子节点的值$\gamma_{jm}$。其值与损失函数有关，不同的损失函数，会致使叶子节点的值也不一样。当损失函数为MSE时，$\gamma_{jm}=ave_{x_i \in R_{jm}} \hat{y}_i$，其中$\hat{y}_i$为负梯度值。下图为LAD损失函数的梯度提升回归树模型算法思想。</p><p><img src="/assets/articleImg/2019/gbdt-algorithm3-LAD_TreeBoost.png" alt=""></p><h2 id="实例解析"><a href="#实例解析" class="headerlink" title="实例解析"></a>实例解析</h2><p>上面对原理进行了分析之后，大致对GBDT有了进一步的认识，为了更加形象的解释GBDT的内部执行过程，这里引用《统计学习方法》里面的数据来进行进一步分析。</p><p>假设有数据集如下：</p><table><thead><tr><th>$xi$</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th></tr></thead><tbody><tr><td>$y_i$</td><td>5.56</td><td>5.7</td><td>5.91</td><td>6.4</td><td>6.8</td><td>7.05</td><td>8.9</td><td>8.7</td><td>9.</td><td>9.05</td></tr></tbody></table><p>采用GBDT进行训练，为了方便，我们采用MSE作为损失函数，并且将树的深度置为1</p><p>根据Algorithm 2，首先初始化$F_{0}(x)$,可以计算出$F_{0}(x)=7.307$.其次，计算出损失函数在当前模型的负梯度值: $\hat{y}_i = y_i - F_{m-1}(x_i)$，结果如下：</p><table><thead><tr><th>$xi$</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th></tr></thead><tbody><tr><td>$y_i$</td><td>-1.747</td><td>-1.607</td><td>-1.397</td><td>-0.907</td><td>-0.507</td><td>-0.257</td><td>1.593</td><td>1.393</td><td>1.693</td><td>1.743</td></tr></tbody></table><p>接下来，通过构建回归树来拟合损失函数在当前模型的负梯度值$\hat{y}_i$。</p><p>对于决策树来说，最关键的步骤就是如何选择最优的划分标准，在回归树里面，我们采用MSE来进行评估，通过对比不同切分点两个分支的MSE加和，来选择最优的切分点（加和MSE最小的点）。根据所给的数据，可以考虑的切分点为1.5、2.5、3.5、4.5、5.5、6.5、7.5、8.5、9.5.分别计算$y_i - F_{0}(x_i)$的值，并计算出切分后的左右两侧加和MSE最小的切分，最后得到的是6.5，此时的MSE=0.3276.找到最佳的切分点之后，我们可以得到各个叶子节点区域，并计算出$R_{jm}$和$\gamma_{jm}$.此时，$R_{11}$为x小于6.5的数据，$R_{21}$为x大于6.5的数据。同时，</p><p>$$r_{11} = \frac{1}{6} \sum_{x_i \in R_{11}} y_{i}=−1.0703$$</p><p>$$r_{21} = \frac{1}{4} \sum_{x_i \in R_{21}} y_{i}=1.6055$$</p><p>最后，更新$F_{1}(x_i)$的值，$F_1(x_i)=F_{0}(x_i)+ \rho_m \sum^2_{j=1} \gamma_{j1} I(x_i \in R_{j1})$，其中$\rho_m$为学习率，或称shrinkage，目的是防止预测结果发生过拟合。</p><p>至此第一轮迭代便完成，后面的迭代方式与上面一样，迭代$m$次后，第$m$次的$F_{m}(x)$即为最终的预测结果。</p><p>$$<br>F_{m}(x) = F_{m-1}(x) + \rho_{m} h(x; a_m)<br>\label{4}\tag{4}<br>$$</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>写到这里，关于GBDT的文章也算结束了，在RS或者CTR预估中，GBDT也曾占据一席之地，至今也留有使用GBDT+LR来构建排序模型。感兴趣的可以看看Facebook发出的这篇paper: <a href="https://quinonero.net/Publications/predicting-clicks-facebook.pdf" target="_blank" rel="noopener">Practical lessons from predicting clicks on ads at facebook</a>。</p><p>最后的最后，小小的感叹一下，对于工作后的自己来说，写一片质量略好的文章真的并非一朝一夕之事。从最初的构思到组织语言，每个句子每行公式都离不开精心的编纂和检查。读者如果觉得这篇文章对您有作用，欢迎多来光顾；如果觉得文章中理解不对，存在误人子弟之处，还望能在评论区中指出文中不足，笔者在此深表感谢。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li>统计学习方法，第二版，李航</li><li>Friedman, Jerome H. “Greedy function approximation: a gradient boosting machine.” Annals of statistics (2001): 1189-1232.</li><li>Freund, Yoav, and Robert E. Schapire. “Experiments with a new boosting algorithm.” icml. Vol. 96. 1996.</li><li>Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learningand an application to boosting. Journal of Computer and System Sciences, 55(1):119–139, August 1997.</li><li>2001：Random Forests（Breiman），Breiman, L. (2001). Random forests. Machine learning, 45(1), 5-32.</li><li>He, Xinran, et al. “Practical lessons from predicting clicks on ads at facebook.” Proceedings of the Eighth International Workshop on Data Mining for Online Advertising. ACM, 2014.</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;说到GBDT，很多人都熟悉，那么我为什么还要在这里编写这篇文章呢？原因很简单，对我来说，在算法学习过程中，喜欢探究算法背后的公式推导，有时候自己也是一头雾水，但目的就是把每个步骤弄清楚，而每次重新回顾算法的时候，或多或少都会领悟到一些与之前不一样的东西，然后惊叹：噢，原来这里是这样，之前怎么就没领悟到，“书读百遍其义自见”大概就是这个道理！这篇文章其实很早之前就写了一部分，只是一直没有完整的整理出来，每次看到这篇文章放到draft里面，就总觉得有种有始无终的感觉。这回，在文章后面引入了实例解析部分，主要是希望后续回来温习的时候，能够快速地理解。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="GBDT" scheme="https://www.csuldw.com/tags/GBDT/"/>
    
  </entry>
  
  <entry>
    <title>神经网络之激活函数</title>
    <link href="https://www.csuldw.com/2019/05/26/2019-05-26-activation-function/"/>
    <id>https://www.csuldw.com/2019/05/26/2019-05-26-activation-function/</id>
    <published>2019-05-25T16:01:00.000Z</published>
    <updated>2019-07-14T14:25:53.829Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在神经网络里面，会经常用到activation function，不管是<a href="http://www.csuldw.com/2018/05/16/2018-05-16-cnn-theory/">CNN</a>还是<a href="http://www.csuldw.com/2018/06/28/2018-06-28-recurrent-neural-networks/">RNN</a>亦或是其他带有神经元的网络，activation function都扮演着重要角色。刚接触神经网络的时候，脑子里总会浮现很多问题。为什么会有这么多activation function?为何这个函数就比另一个效果好？这么多函数，我们该使用哪一个？出于学习目的，本文将对activation function进行简要的归纳，旨在屡清各个函数的应用场景。</p><a id="more"></a><h2 id="前言介绍"><a href="#前言介绍" class="headerlink" title="前言介绍"></a>前言介绍</h2><p>一个神经网络包含很多的神经元，每个神经元上都伴随着一个Activation Function，而神经元将Activation Function的值作为其输出（同时作为下一层的输入）。Activation Function译名叫做激活函数，通常将其划分为线性激活函数（linear Activation Function）和非线性激活函数（Non-linear Activation Function）。一般情况下，如果神经网络中使用的是linear Activation Function，那么每一层都相当于是上一层的线性组合，其输入和输出均是线性的，此时就类似于感知机模型，那么hidden layer就没有存在的意义了，同时这种线性函数对于复杂的非线性问题拟合效果欠缺。当我们使用非线性激活函数时，模型可以拟合任意函数的输出，表现空间更大、使用范围更广、且效果更佳。</p><p>激活函数的类型特别多，本文主要介绍下面几个常用的非线性激活函数：</p><ol><li>sigmoid</li><li>tanh（Hyperbolic tangent）</li><li>ReLU (Rectified Linear Unit)</li><li>Leaky ReLU</li></ol><p><img src="/assets/articleImg/2019/activation_function_framework.png" alt=""></p><p>下面根据激活函数的演进来看看各大激活函数的优缺点。</p><h2 id="Sigmoid-Activation-Function"><a href="#Sigmoid-Activation-Function" class="headerlink" title="Sigmoid Activation Function"></a>Sigmoid Activation Function</h2><p>sigmoid函数是一个有界可导的实函数，同时sigmoid函数还是单调的，其表达式如下：</p><p>$$<br>\sigma(x) = \frac{1}{1+e^{-x}}<br>\label{1}\tag{1}<br>$$</p><p>根据表达式，我们可以使用Python绘制出sigmoid曲线：</p><p><img src="/assets/articleImg/2019/sigmoid-function.png" alt=""></p><p>从上图我们看出，sigmoid函数取值在0到1，因此我们一般使用sigmoid的值作为概率输出，如LR：</p><p>特点：</p><ol><li>导数$\sigma’ = \sigma (1- \sigma)$</li><li>sigmoid单调，导数非单调；</li><li>值域0到1之间，可表示概率。线性激活函数的值域在(-inf,+inf)，而sigmoid的值域在(0,1)，能够很好的表示概率。</li></ol><p>缺点：在sigmoid的两端，X的变化对Y的作用不大，以致在训练过程中，位于这部分区间的数据点的梯度会特别小，甚至会产生Vanishing Gradient Problem，从而导致训练速度变慢，难以收敛。</p><p>绘制sigmoid曲线代码：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line">x = np.arange(<span class="number">-5.</span>, <span class="number">5.</span>, <span class="number">0.1</span>)</span><br><span class="line">y_sig = sigmoid(x)</span><br><span class="line">plt.plot(x, y_sig, <span class="string">'b'</span>, label=<span class="string">'sigmoid'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.title(<span class="string">"Sigmoid Activation Function"</span>)</span><br><span class="line">plt.text(<span class="number">6</span>, <span class="number">0.8</span>, <span class="string">r'$\sigma(x)=\frac{1}{1+e^{-x}}$'</span>, fontsize=<span class="number">15</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'lower right'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure><h2 id="tanh-Activation-Function"><a href="#tanh-Activation-Function" class="headerlink" title="tanh Activation Function"></a>tanh Activation Function</h2><p>tanh激活函数跟sigmoid激活函数的图像很像，只是抑制区域不一样。tanh也可以用sigmoid进行表示，如下：</p><p>$$<br>tanh(x) = \frac{1-e^{-2x}}{1+e^{-2x}}=2 \cdot sigmoid(2x)-1<br>\label{2}\tag{2}<br>$$</p><p>图型如下：</p><p><img src="/assets/articleImg/2019/tanh-function.png" alt=""></p><p>tanh函数特点：</p><ol><li>导数为$tanh’(x) = 1- tanh^2(x)$</li><li>tanh属于单调函数，但其导数非单调；</li><li>值域(-1,1)，以0为中心；</li></ol><p>缺点：与sigmoid一样，同样会出现vanishing gradient problem。</p><p>绘制tanh曲线代码：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tanh</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> (<span class="number">1</span>-np.exp(<span class="number">-2</span>*x))/(<span class="number">1</span> + np.exp(<span class="number">-2</span>*x))</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">-5.</span>, <span class="number">5.</span>, <span class="number">0.1</span>)</span><br><span class="line">plt.grid()</span><br><span class="line"></span><br><span class="line">plt.plot(x, tanh(x), <span class="string">'g'</span>, label=<span class="string">'tanh'</span>)</span><br><span class="line">plt.title(<span class="string">"tanh activation function"</span>)</span><br><span class="line">plt.text(<span class="number">6</span>,<span class="number">1</span>, <span class="string">r'$tanh(x)=\frac{1-e^{-2x}}{1+e^{-2x}}$'</span>, fontsize=<span class="number">15</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'lower right'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure><h2 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h2><p>ReLU函数也是非线性激活函数，它很好的避免了 vanishing gradient problem，不过在坐标轴的正侧，它是一个线性函数，表达式如下：</p><p>$$<br>ReLU(x) = max(0, x)<br>\label{3}\tag{3}<br>$$</p><p><img src="/assets/articleImg/2019/relu-function.png" alt=""></p><p>ReLU函数特点：</p><ol><li>导数：当x&lt;=0时，导数为0；当x&gt;0时，导数为1；</li><li>任何函数都可以近似采用ReLU函数的组合进行表示；</li><li>取值[0, inf)，可以放大激活函数，但是负区域会完全的终止神经元的传输，因此出现了ReLU的变体Leaky ReLU等。</li><li>受限于hidden layer使用。</li></ol><p>绘制ReLU曲线代码：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.maximum(<span class="number">0</span>, x)</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">-5.</span>, <span class="number">5.</span>, <span class="number">0.1</span>)</span><br><span class="line">y_relu = relu(x)</span><br><span class="line">plt.plot(x, y_relu, <span class="string">'r'</span>, label=<span class="string">'ReLU'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.title(<span class="string">"ReLU Activation Function"</span>)</span><br><span class="line">plt.text(<span class="number">6</span>, <span class="number">4</span>, <span class="string">r'$relu(x)=max(0, x)$'</span>, fontsize=<span class="number">15</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'lower right'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure><h2 id="Leaky-ReLU"><a href="#Leaky-ReLU" class="headerlink" title="Leaky ReLU"></a>Leaky ReLU</h2><p>Leaky ReLU是ReLU的变体，目的是使得激活函数的梯度不为零，不仅可以抑制神经元，同时还可以恢复神经元的向后传递。表达式如下：</p><p>$$<br>f(x) = max(\alpha x, x)<br>\label{4}\tag{4}<br>$$</p><p><img src="/assets/articleImg/2019/leaky-relu-function.png" alt=""></p><p>绘制Leaky ReLU曲线代码：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">leaky_relu</span><span class="params">(x, a=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.maximum(a*x, x)</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">-5.</span>, <span class="number">5.</span>, <span class="number">0.1</span>)</span><br><span class="line">y_relu = leaky_relu(x)</span><br><span class="line">plt.plot(x, y_relu, <span class="string">'#FFAA00'</span>, label=<span class="string">'Leaky ReLU'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.title(<span class="string">"Leaky ReLU Activation Function"</span>)</span><br><span class="line">plt.text(<span class="number">6</span>, <span class="number">4</span>, <span class="string">r'$f(x)=max(ax, x)$'</span>, fontsize=<span class="number">15</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'lower right'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure><!--more--><h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><p><a href="https://en.wikipedia.org/wiki/Activation_function" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Activation_function</a></p><p><img src="/assets/articleImg/2019/activation-sheet.png" alt=""><br>Fig: Activation Function Cheetsheet</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>上面说到ReLU激活函数及其变体的效果很出色，但是是不是    全部都采用ReLU呢？当然不是，在处理分类任务是，sigmoid还是表现的相当出色的，并且解释性更强，更简单。如果你在训练神经网络模型的时候不知道采用何种激活函数，可以先采用ReLU和tanh进行训练，相信你肯定会得到一个不错的baseline。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="http://www.win-vector.com/dfiles/LogisticRegressionMaxEnt.pdf" target="_blank" rel="noopener">The equivalence of logistic regression and maximum entropy models</a></li><li><a href="https://papers.tinbergen.nl/02119.pdf" target="_blank" rel="noopener">The Origins of Logistic Regression - Tinbergen Institute</a></li><li><a href="https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0" target="_blank" rel="noopener">Understanding Activation Functions in Neural Networks</a></li><li><a href="https://towardsdatascience.com/activation-functions-and-its-types-which-is-better-a9a5310cc8f" target="_blank" rel="noopener">Activation functions and it’s types-Which is better?</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在神经网络里面，会经常用到activation function，不管是&lt;a href=&quot;http://www.csuldw.com/2018/05/16/2018-05-16-cnn-theory/&quot;&gt;CNN&lt;/a&gt;还是&lt;a href=&quot;http://www.csuldw.com/2018/06/28/2018-06-28-recurrent-neural-networks/&quot;&gt;RNN&lt;/a&gt;亦或是其他带有神经元的网络，activation function都扮演着重要角色。刚接触神经网络的时候，脑子里总会浮现很多问题。为什么会有这么多activation function?为何这个函数就比另一个效果好？这么多函数，我们该使用哪一个？出于学习目的，本文将对activation function进行简要的归纳，旨在屡清各个函数的应用场景。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="深度学习" scheme="https://www.csuldw.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="激活函数" scheme="https://www.csuldw.com/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    
      <category term="sigmoid" scheme="https://www.csuldw.com/tags/sigmoid/"/>
    
      <category term="tanh" scheme="https://www.csuldw.com/tags/tanh/"/>
    
      <category term="ReLU" scheme="https://www.csuldw.com/tags/ReLU/"/>
    
  </entry>
  
  <entry>
    <title>八大无监督异常检测技术</title>
    <link href="https://www.csuldw.com/2019/03/24/2019-03-24-anomaly-detection-introduction/"/>
    <id>https://www.csuldw.com/2019/03/24/2019-03-24-anomaly-detection-introduction/</id>
    <published>2019-03-23T18:31:00.000Z</published>
    <updated>2019-06-05T15:22:50.263Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>原文链接：<a href="http://www.csuldw.com/2019/03/24/2019-03-24-anomaly-detection-introduction/">http://www.csuldw.com/2019/03/24/2019-03-24-anomaly-detection-introduction/</a></p><p>“黑中有白，白中有黑，没有绝对的白，也没有绝对的黑，黑可衬白，白可映黑。万物皆可转换”。<br>本文是<a href="https:///www.csuldw.com" target="_blank" rel="noopener">笔者</a>首篇关于异常检测类的文章，主要介绍了八种不同的无监督异常检测方法，篇幅较长，实验部分仅供参考。全文表述中如有不明之处，读者可在下方留言。</p><a id="more"></a><h2 id="何为异常"><a href="#何为异常" class="headerlink" title="何为异常"></a>何为异常</h2><p>在仙侠剧中，有正魔之分，然何为正道，何为魔道，实属难辨。自称正道的人也许某一天会堕入魔道，被众人称为魔头的人，或许内心自始至终都充溢着正义感！所以说，没有绝对的黑，也没有绝对的白。话说回来，对于“异常”这个词，每个人的心里大概都有一个衡量标准，扩展起来的确很广（如异常点、异常交易、异常行为、异常用户、异常事故等等），那么究竟何为异常呢？异常是相对于其他观测数据而言有明显偏离的，以至于怀疑它与正常点不属于同一个数据分布。异常检测是一种<strong>用于识别不符合预期行为的异常模式的技术</strong>，又称之为异常值检测。在商业中也有许多应用，如网络入侵检测（识别可能发出黑客攻击的网络流量中的特殊模式）、系统健康性监测、信用卡交易欺诈检测、设备故障检测、风险识别等。这里，将异常分为三种：</p><ol><li><strong>数据点异常</strong>：如果样本点与其他数据相距太远，则单个数据实例是异常的。业务用例：根据“支出金额”检测信用卡欺诈。</li><li><strong>上下文异常</strong>：在时间序列数据中的异常行为。业务用例：旅游购物期间信用卡的花费比平时高出好多倍属于正常情况，但如果是被盗刷卡，则属于异常。</li><li><strong>集合异常</strong>：单个数据难以区分，只能根据一组数据来确定行为是否异常。业务用例：蚂蚁搬家式的拷贝文件，这种异常通常属于潜在的网络攻击行为。</li></ol><p>异常检测类似于<strong>噪声消除</strong>和<strong>新颖性检测</strong>。<strong>噪声消除（NR）</strong>是从不需要的观察发生中免疫分析的过程; 换句话说，从其他有意义的信号中去除噪声。<strong>新颖性检测</strong>涉及在未包含在训练数据中的新观察中识别未观察到的模式。</p><h2 id="异常检测的难点"><a href="#异常检测的难点" class="headerlink" title="异常检测的难点"></a>异常检测的难点</h2><p>在面对真实的业务场景时，我们往往都是满腹激情、豪情壮志，心里默念着终于可以进入实操，干一番大事业了。然而事情往往都不是那么美好，业务通常比较特殊、背景复杂，对于业务的熟悉过程也会耗掉你大部分的时间。然后在你绞尽脑汁将其转化为异常检测场景后，通常又面临着以下几大挑战：</p><ul><li>不能明确定义何为正常，何为异常，在某些领域正常和异常并没有明确的界限；</li><li>数据本身存在噪声，致使噪声和异常难以区分；</li><li>正常行为并不是一成不变，也会随着时间演化，如正常用户被盗号之后，进行一系列的非法操作； </li><li>标记数据获取难：没有数据，再好的算法也是无用。</li></ul><p>针对上述挑战，下面我们来看看具体的场景和用于异常检测的算法。</p><h2 id="基于统计的异常值检测"><a href="#基于统计的异常值检测" class="headerlink" title="基于统计的异常值检测"></a>基于统计的异常值检测</h2><p>这里将基于统计的作为一类异常检测技术，方法比如多，下面主要介绍MA和3-Sigma。</p><h3 id="MA滑动平均法"><a href="#MA滑动平均法" class="headerlink" title="MA滑动平均法"></a>MA滑动平均法</h3><p>识别数据不规则性的最简单的方法是标记偏离分布的数据点，包括平均值、中值、分位数和模式。假定异常数据点是偏离平均值的某个标准偏差，那么我们可以计算时间序列数据滑动窗口下的局部平均值，通过平均值来确定偏离程度。这被技术称为<strong>滑动平均法</strong>(moving average，MA)，旨在平滑短期波动并突出长期波动。滑动平均还包括累加移动平均、加权移动平均、指数加权移动平均、双指数平滑、三指数平滑等，在数学上，$n$周期简单移动平均也可以定义为“低通滤波器”。</p><p>缺点：</p><ul><li>数据中可能存在与异常行为类似的噪声数据，所以正常行为和异常行为之间的界限通常不明显；</li><li>异常或正常的定义可能经常发生变化，因为恶意攻击者不断适应自己。因此，基于移动平均值的阈值可能并不总是适用。</li></ul><h3 id="3-Sigma"><a href="#3-Sigma" class="headerlink" title="3-Sigma"></a>3-Sigma</h3><p>3-Sigma原则又称为拉依达准则，该准则定义如下：</p><blockquote><p>假设一组检测数据只含有随机误差，对原始数据进行计算处理得到标准差，然后按一定的概率确定一个区间，认为误差超过这个区间的就属于异常值。</p></blockquote><p><img src="/assets/articleImg/2019/3-sigma-all.png" alt=""></p><div class="caption">『source: [Explaining the 68-95-99.7 rule for a Normal Distribution](https://towardsdatascience.com/understanding-the-68-95-99-7-rule-for-a-normal-distribution-b7b7cbf760c2)』</div><p>使用3-Sigma的前提是数据服从正态分布（当然如果x不服从正态分布，可以使用log将其转为正态分布，详细参阅<a href="https://en.wikipedia.org/wiki/Log-normal_distribution" target="_blank" rel="noopener">Log Normal Distribution</a>），满足这个条件之后，在3-Sigma范围$(μ-3σ,μ+3σ)$内<code>99.73%</code>的为正常数据，其中$\sigma$代表标准差,$\mu$代表均值，$x=μ$为图形的对称轴。下面是3-Sigma的Python实现。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#3-sigma识别异常值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">three_sigma</span><span class="params">(df_col)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    df_col：DataFrame数据的某一列</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    rule = (df_col.mean() - <span class="number">3</span> * df_col.std() &gt; df_col) | (df_col.mean() + <span class="number">3</span> * df_col.std() &lt; df_col)</span><br><span class="line">    index = np.arange(df_col.shape[<span class="number">0</span>])[rule]</span><br><span class="line">    outrange = df_col.iloc[index]</span><br><span class="line">    <span class="keyword">return</span> outrange</span><br></pre></td></tr></tbody></table></figure><p>对于异常值检测出来的结果，有多种处理方式，如果是时间序列中的值，那么我们可以认为这个时刻的操作属于异常的；如果是将异常值检测用于数据预处理阶段，处理方法有以下四种：</p><ol><li>删除带有异常值的数据；</li><li>将异常值视为缺失值，交给缺失值处理方法来处理；</li><li>用平均值进行修正；</li><li>当然我们也可以选择不处理。</li></ol><h2 id="基于密度的异常检测"><a href="#基于密度的异常检测" class="headerlink" title="基于密度的异常检测"></a>基于密度的异常检测</h2><p>基于密度的异常检测有一个先决条件，即正常的数据点呈现“物以类聚”的聚合形态，正常数据出现在密集的邻域周围，而异常点偏离较远。对于这种场景，我们可以计算得分来评估最近的数据点集，这种得分可以使用Eucledian距离或其它的距离计算方法，具体情况需要根据数据类型来定：类别型或是数字型。</p><h3 id="局部异常因子算法"><a href="#局部异常因子算法" class="headerlink" title="局部异常因子算法"></a>局部异常因子算法</h3><h4 id="Local-Outlier-Factor原理"><a href="#Local-Outlier-Factor原理" class="headerlink" title="Local Outlier Factor原理"></a>Local Outlier Factor原理</h4><p>局部异常因子算法，全称Local Outlier Factor（简写LOF)。LOF算法是一种无监督的异常检测方法，它计算给定数据点相对于其邻居的局部密度偏差。每个样本的异常分数称为局部异常因子。异常分数是局部的，取决于样本相对于周围邻域的隔离程度。确切地说，局部性由<code>k</code>近邻给出，并使用距离估计局部密度。通过将样本的局部密度与其邻居的局部密度进行比较，可以识别密度明显低于其邻居的样本,，这些样本就被当做是异常样本点。</p><p><strong>算法原理如下</strong>：</p><ol><li>计算k-distance of p：计算点<code>p</code>的第<code>k</code>距离，也就距离样本点<code>p</code>第<code>k</code>远的点的距离，不包括<code>p</code>;</li><li>计算k-distance neighborhood of p：计算点<code>p</code>的第<code>k</code>邻域距离，就是<code>p</code>的第<code>k</code>距离以内的所有点，包括第<code>k</code>距离;</li><li>计算reach-distance：可达距离，若小于第<code>k</code>距离，则可达距离为第<code>k</code>距离，若大于第k距离，则可达距离为真实距离，公式如下(说明:$d(p,o)$为<code>p</code>到<code>o</code>的距离)：<br> $$<br> reach-distance_k(p,o)=max\{k−distance(o),d(p,o)\}<br> \tag{1}\label{1}<br> $$<br> 点<code>o</code>到点<code>p</code>的第<code>k</code>可达距离，至少是点<code>o</code>的第<code>k</code>距离，或者为<code>o</code>与<code>p</code>间的真实距离。</li><li>计算local reachability density：局部可达密度<br> $$<br> lrd_k(p)=\frac{1}{ \frac{1}{|Nk(p)|} \sum _{o \in Nk(p)}reach−distance_k(p,o)}<br> \tag{2}\label{2}<br> $$<br> 表示点<code>p</code>的第<code>k</code>邻域内点到点<code>p</code>的平均可达距离的倒数。</li><li>计算local outlier factor:局部离群因子.<br> $$<br> LOF_k(p)=\frac{1}{ |Nk(p)|} ∑_{o\in Nk(p)} \frac{lrd_k(o) }{lrd_k(p)} = \frac{∑ _{o\in Nk(p)} lrd_k(o)}{|Nk(p)| } \cdot \frac{1}{lrd_k(p)}<br> \tag{3}\label{3}<br> $$<br> 表示点<code>p</code>的邻域点<code>Nk(p)</code>的局部可达密度与点<code>p</code>的局部可达密度之比的平均数。 </li></ol><h4 id="实例Demo"><a href="#实例Demo" class="headerlink" title="实例Demo"></a>实例Demo</h4><p><strong>Step1: 导入数据集</strong>。为了方便起见，这里采用了Kaggle里面的<a href="https://www.kaggle.com/mlg-ulb/creditcardfraud/version/3" target="_blank" rel="noopener">Credit Card Fraud Detection</a>作为实验数据集，其中包含492个正样本（异常样本），284315个正常样本（负样本）。首先，我们先导入数据集（注意：<code>creditcard.csv</code>文件在<a href="https://www.kaggle.com/mlg-ulb/creditcardfraud/version/3" target="_blank" rel="noopener">这里</a>下载)。</p><figure class="highlight elm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="title">creditcard_data</span> = pd.read_csv(<span class="string">"creditcard.csv"</span>)</span><br></pre></td></tr></tbody></table></figure><p><strong>Step2：数据集转换</strong>。加载数据集，我们需要将数据集中的特征数据X提取出来，Y作为类别标签，在无监督算法的训练过程中不需要用到，在模型评估阶段再使用。这里不得不吹捧一下pandas，操作起来真的特别方便，代码如下：</p><figure class="highlight pf"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics import classification_report, accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors import LocalOutlierFactor</span><br><span class="line"></span><br><span class="line"><span class="keyword">state</span> = np.<span class="keyword">random</span>.RandomState(<span class="number">42</span>)</span><br><span class="line">columns = creditcard_data.columns.tolist()</span><br><span class="line">columns = [c <span class="keyword">for</span> c <span class="keyword">in</span> columns if c not <span class="keyword">in</span> [<span class="string">"Class"</span>]]</span><br><span class="line">target = <span class="string">"Class"</span></span><br><span class="line"><span class="keyword">state</span> = np.<span class="keyword">random</span>.RandomState(<span class="number">42</span>)</span><br><span class="line">X = creditcard_data[columns]</span><br><span class="line">Y = creditcard_data[target]</span><br><span class="line">X_outliers = <span class="keyword">state</span>.uniform(low=<span class="number">0</span>, high=<span class="number">1</span>, size=(X.shape[<span class="number">0</span>], X.shape[<span class="number">1</span>]))</span><br></pre></td></tr></tbody></table></figure><p>Step3: <strong>模型训练与预测。</strong>得到了训练数据之后，下面我们通过条用sklearn的算法库来实现模型的训练和预测。</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">classifiers = {</span><br><span class="line">    <span class="string">"Local Outlier Factor"</span>:LocalOutlierFactor(<span class="attribute">n_neighbors</span>=20, <span class="attribute">algorithm</span>=<span class="string">'auto'</span>, </span><br><span class="line">                                       <span class="attribute">leaf_size</span>=30, <span class="attribute">metric</span>=<span class="string">'minkowski'</span>,</span><br><span class="line">                                       <span class="attribute">p</span>=2, <span class="attribute">metric_params</span>=None, <span class="attribute">contamination</span>=0.01)</span><br><span class="line">}</span><br><span class="line">def train_model(clf, train_X):</span><br><span class="line">    #Fit the train data <span class="keyword">and</span> <span class="builtin-name">find</span> outliers</span><br><span class="line">    y_pred = clf.fit_predict(X)</span><br><span class="line">    scores_prediction = clf.negative_outlier_factor_</span><br><span class="line">    return y_pred, clf</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">y_pred, clf = train_model(<span class="attribute">clf</span>=classifiers[<span class="string">"Local Outlier Factor"</span>], <span class="attribute">train_X</span>=X)</span><br></pre></td></tr></tbody></table></figure><p>Step4: <strong>模型评估。</strong>为了验证LOF算法的准确度，我们可以采用预测的异常数据和真实的异常数据进行比对。注意，通过上述模型预测的结果为<code>1</code>（正常样本）和<code>-1</code>（异常样本），所以在模型评估的时候，需要对预测的label进行转换，具体实现如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluation_model</span><span class="params">(y_pred, y_label, clf_name)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    y_pred: prediction label</span></span><br><span class="line"><span class="string">    y_label: true lable</span></span><br><span class="line"><span class="string">    clf_name: string</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment">#transform anomaly label</span></span><br><span class="line">    y_rebuild = [<span class="number">0</span> <span class="keyword">if</span> y == <span class="number">1</span> <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">for</span> y <span class="keyword">in</span> y_pred ]   </span><br><span class="line">    n_errors = (y_rebuild != Y).sum()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#Classification Metrics</span></span><br><span class="line">    print(<span class="string">"{}: {}"</span>.format(clf_name, n_errors))</span><br><span class="line">    print(<span class="string">"Accuracy Score :"</span>, accuracy_score(Y, y_rebuild))</span><br><span class="line">    print(<span class="string">"Classification Report :"</span>)</span><br><span class="line">    print(classification_report(Y, y_rebuild))</span><br><span class="line"></span><br><span class="line">s = y_pred</span><br><span class="line">evaluation_model(y_pred, Y, clf_name=<span class="string">"LOF"</span>)</span><br></pre></td></tr></tbody></table></figure><p>当然，基于密度的还有KNN算法（有监督），kNN是一种简单的非参数化机器学习算法，使用距离来度量相似性进而对数据进行分类，例如Eucledian，Manhattan，Minkowski或Hamming distance等。关于KNN算法，可以参考笔者的另一篇文章：<a href="https://www.csuldw.com/2015/05/21/2015-05-21-KNN/">机器学习算法-K最近邻从原理到实现</a>。那么，怎么将KNN应用到异常检测中呢？比较简单的做法是计算预测数据与最近的K个样本点的距离和，然后根据阈值进行异常样本的判别。这类方法有一种明显的缺点，如果异常样本数据较多，并且单独成簇的话，最后得到的结果则不太乐观。</p><h2 id="基于聚类的异常检测"><a href="#基于聚类的异常检测" class="headerlink" title="基于聚类的异常检测"></a>基于聚类的异常检测</h2><p>通常，类似的数据点往往属于相似的组或簇，由它们与局部簇心的距离决定。正常数据距离簇中心的距离要进，而异常数据要原理簇的中心点。聚类属于无监督学习领域中最受欢迎的算法之一，关于聚类异常检测可分为两步：</p><ol><li>利用聚类算法聚类;</li><li>计算各个样本点的异常程度：每个点的异常程度等于到最近类中心点的距离。</li></ol><p>缺点：</p><ul><li>如果异常数据自己成簇，将难以区分异常；</li></ul><h3 id="基于K-Means聚类的异常检测"><a href="#基于K-Means聚类的异常检测" class="headerlink" title="基于K-Means聚类的异常检测"></a>基于K-Means聚类的异常检测</h3><p>K-Means是一种广泛使用的聚类算法，它创建了<code>k</code>个类似的数据点群体，不属于这些簇（远离簇心）的数据样例则有可能被标记为异常数据。关于聚类的原理，可参考笔者以前的文章<a href="https://www.csuldw.com/2015/06/03/2015-06-03-ml-algorithm-K-means/">机器学习算法-K-means聚类</a>。</p><p>聚类算法较多，如DBSCAN、层次聚类等，这里就不一一介绍了。</p><h2 id="OneClassSVM的异常检测"><a href="#OneClassSVM的异常检测" class="headerlink" title="OneClassSVM的异常检测"></a>OneClassSVM的异常检测</h2><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>SVM（支持向量机）是一种用于检测异常的另一种有效的技术。SVM通常与监督学习相关联，但是存在可以用于将异常识别为无监督问题（其中训练数据未被标记）的扩展（OneClassCVM）。算法学习软边界以便使用训练集对正常数据实例进行聚类，然后，使用测试实例，它调整自身以识别落在学习区域之外的异常。根据使用情况，异常检测器的输出可以是数字标量值，用于过滤特定于域的阈值或文本标签（如二进制/多标签）。</p><h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p>本实例使用的数据与Local Outlier Factor一样，这里暂且不重复写入了。下面，简单介绍下OneClassSVM算法模型训练部分，其余的与上述类似。代码如下：</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">classifiers = {</span><br><span class="line">    <span class="string">"Support Vector Machine"</span>:OneClassSVM(<span class="attribute">kernel</span>=<span class="string">'rbf'</span>, <span class="attribute">degree</span>=3, <span class="attribute">gamma</span>=0.1,nu=0.05, </span><br><span class="line">                                         <span class="attribute">max_iter</span>=-1, <span class="attribute">random_state</span>=state)</span><br><span class="line">}</span><br><span class="line">def train_model(clf, train_X):</span><br><span class="line">    #Fit the train data <span class="keyword">and</span> <span class="builtin-name">find</span> outliers</span><br><span class="line">    clf.fit(X)</span><br><span class="line">    y_pred = clf.predict(X)</span><br><span class="line">    return y_pred,clf</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">y_pred,clf = train_model(<span class="attribute">clf</span>=classifiers[<span class="string">"Support Vector Machine"</span>], <span class="attribute">train_X</span>=X)</span><br></pre></td></tr></tbody></table></figure><p>SVM训练时间较长，具体效果需要看算法与数据集的拟合程度。</p><h2 id="iForest异常检测"><a href="#iForest异常检测" class="headerlink" title="iForest异常检测"></a>iForest异常检测</h2><h3 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h3><p>iForest（isolation forest，孤立森林）算法是一种基于Ensemble的快速异常检测方法，具有线性时间复杂度和高精准度，该算法是刘飞博士在莫纳什大学就读期间由陈开明(Kai-Ming Ting)教授和周志华(Zhi-Hua Zhou)教授指导发表的，与LOF、OneClassSVM相比，其占用的内存更小、速度更快。算法原理如下：</p><p><img src="/assets/articleImg/2019/iforest.png" alt=""></p><div class="caption">『source: [http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf](http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf)』</div><p>异常score计算公式如下：</p><p>$$<br>s(x, n) = 2^{-\frac{E(h(x))}{c(n)}}<br>\tag{4}\label{4}<br>$$</p><p>其中$ h(x)$ 为路径长度，可以通过公式 $ H(k) = ln(k) + \xi $来估计，$\xi$是欧拉常数，其值为<code>0.5772156649</code>。$E(h(x))$是iForest中$x$在不同树中的路径长度$h(x)$的平均值，$c(n)$是样本点为$n$时BST的平均路径长度，$c(n) = 2H(n − 1) − \frac{2(n − 1)}{n}$,用来对结果进行归一化处理.</p><ul><li>当$E(h(x))$趋近于$0$时,s趋近于1，异常的概率越大；</li><li>当$E(h(x))$趋近于$n − 1$时, s趋近于0，正常的概率越大.</li><li>当$E(h(x))$趋近于$c(n)$时, s趋近于0.5；</li></ul><h3 id="实例-1"><a href="#实例-1" class="headerlink" title="实例"></a>实例</h3><p>这里简单介绍下iForest模型训练部分，数据加载和模型评估的方法与上述类似。算法部分的代码如下：</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">classifiers = {</span><br><span class="line">    <span class="string">"Isolation Forest"</span>:IsolationForest(<span class="attribute">n_estimators</span>=100, <span class="attribute">max_samples</span>=len(X), </span><br><span class="line">                                       <span class="attribute">contamination</span>=0.005,random_state=state, <span class="attribute">verbose</span>=0)</span><br><span class="line">}</span><br><span class="line">def train_model(clf, train_X):</span><br><span class="line">    #Fit the train data <span class="keyword">and</span> <span class="builtin-name">find</span> outliers</span><br><span class="line">    clf.fit(X)</span><br><span class="line">    #scores_prediction = clf.decision_function(X)</span><br><span class="line">    y_pred = clf.predict(X)</span><br><span class="line">    return y_pred, clf</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">y_pred,clf = train_model(<span class="attribute">clf</span>=classifiers[<span class="string">"Isolation Forest"</span>], <span class="attribute">train_X</span>=X)</span><br></pre></td></tr></tbody></table></figure><p>使用上面的参数在笔者的笔记本上训练时间只花了1min 12s，相比于SVM的确要快很多。</p><h2 id="PCA-MD异常检测"><a href="#PCA-MD异常检测" class="headerlink" title="PCA+MD异常检测"></a>PCA+MD异常检测</h2><p>PCA（主成分分析）是一种常用的线性降维方法，通过计算数据（中心化后的数据）协方差矩阵的特征值和特征向量来得到数据的主要成分，<strong>最大特征值$\lambda_k$对应的特征向量$\alpha_k$为数据方差最大的方向</strong>，相信很多人都用过，笔者先前的文章<a href="http://www.csuldw.com/2016/02/28/2016-02-28-pca/">PCA主成分分析Python实现</a>中也有介绍，那么如何使用PCA进行异常检测呢？方法如下：</p><ol><li>通过PCA将数据映射到低维特征空间之后，在各个特征空间不同维度上查看每个数据点跟其它数据的偏差，如果数据距离该超平面很远，那么该数据可能属于异常数据.</li><li>对于降维后的数据，通过观察各样本点到样本中心的MD距离来衡量，如果距离太大（可根据实际情况设置阈值），就可以判断是异常值。</li></ol><blockquote><p>对于一个均值为$\mu =(\mu_{1},\mu_{2},\mu_{3},\dots ,\mu_{p})^{T}$，协方差矩阵为$\Sigma$的多变量向量$x=(x_{1},x_{2},x_{3},\dots ,x_{p})^{T}$，其马氏距离为：<br>    $$<br>        D_M(x) = \sqrt{(x-\mu)^T)\Sigma^{-1} (x-\mu)}<br>    $$</p></blockquote><h2 id="AutoEncoder异常检测"><a href="#AutoEncoder异常检测" class="headerlink" title="AutoEncoder异常检测"></a>AutoEncoder异常检测</h2><p>AutoEncoder（自编码器，简称AE）是一种无监督的深度学习模型，原理比较简单：对于输入样本$x$，首先通过encoder编码器$f$将其压缩为维度较低的$y$，然后通过decoder解码器$g$对每个样本点进行重建，还原到原来的维度，得到$z$。整个训练模型的目的就是减少重构error，得到的hidden层的$y$，相当于降维后的数据。整个framework如下：</p><p><img src="/assets/articleImg/2019/autoencoder.png" alt=""></p><div class="caption">『source: [Part 5. An Introduction to Neural Networks and Autoencoders](https://www.alanzucconi.com/2018/03/14/an-introduction-to-autoencoders/)』</div><p>AutoEncoder本质上与PCA类似，AutoEncoder可以用作降维，区别在于PCA属于线性变换，而AutoEncoder属于非线性变换。在异常检测应用上，AE通过计算重建数据与输入数据的重建误差作为异常的衡量，如果样本都是数值型，可以用MSE或MAE作为衡量指标，样本的重建误差越大，则表明异常的可能性越大。关于如何使用autoEncoder，这里暂且不介绍了，后续可能会单独写一篇。</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>本文介绍了八种常用的无监督异常检测方法，主要偏向于理论的说明，对于有label标记的数据，我们还可以采用分类算法进行训练和预测，这里就不横向扩宽了。实际项目中，前期标注数据比较少，我们可以采用无监督方式，随着标注数据的增多，后面可以使用监督学习方法，并将无监督与有监督进行结合。OK，这篇文章暂且到此为止，后续相关的实践，笔者也会逐步分享出来，感谢光顾。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="https://towardsdatascience.com/understanding-the-68-95-99-7-rule-for-a-normal-distribution-b7b7cbf760c2" target="_blank" rel="noopener">Explaining the 68-95-99.7 rule for a Normal Distribution</a></li><li><a href="https://towardsdatascience.com/how-to-use-machine-learning-for-anomaly-detection-and-condition-monitoring-6742f82900d7" target="_blank" rel="noopener">how-to-use-machine-learning-for-anomaly-detection-and-condition-monitoring</a></li><li><a href="https://en.wikipedia.org/wiki/Mahalanobis_distance" target="_blank" rel="noopener">WIKI：Mahalanobis_distance</a></li><li><a href="https://medium.com/@curiousily/credit-card-fraud-detection-using-autoencoders-in-keras-tensorflow-for-hackers-part-vii-20e0c85301bd" target="_blank" rel="noopener">credit-card-fraud-detection-using-autoencoders-in-keras-tensorflow-for-hackers-part-vii</a></li><li><a href="https://www.kaggle.com/mlg-ulb/creditcardfraud/kernels" target="_blank" rel="noopener">creditcardfraud/kernels</a></li><li><a href="http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf" target="_blank" rel="noopener">Isolation Forest</a></li><li><a href="http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/tkdd11.pdf" target="_blank" rel="noopener">Isolation-based Anomaly Detection</a></li><li><a href="https://towardsdatascience.com/outlier-detection-with-isolation-forest-3d190448d45e" target="_blank" rel="noopener">Outlier Detection with Isolation Forest</a></li><li><a href="http://charuaggarwal.net/outlierbook.pdf" target="_blank" rel="noopener">Outlier Analysis-pdf</a></li><li><a href="https://www.jeremyjordan.me/autoencoders/" target="_blank" rel="noopener">Introduction to autoencoders</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;原文链接：&lt;a href=&quot;http://www.csuldw.com/2019/03/24/2019-03-24-anomaly-detection-introduction/&quot;&gt;http://www.csuldw.com/2019/03/24/2019-03-24-anomaly-detection-introduction/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“黑中有白，白中有黑，没有绝对的白，也没有绝对的黑，黑可衬白，白可映黑。万物皆可转换”。&lt;br&gt;本文是&lt;a href=&quot;https:///www.csuldw.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;笔者&lt;/a&gt;首篇关于异常检测类的文章，主要介绍了八种不同的无监督异常检测方法，篇幅较长，实验部分仅供参考。全文表述中如有不明之处，读者可在下方留言。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="异常检测" scheme="https://www.csuldw.com/tags/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/"/>
    
      <category term="机器学习" scheme="https://www.csuldw.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="无监督学习" scheme="https://www.csuldw.com/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="anomaly" scheme="https://www.csuldw.com/tags/anomaly/"/>
    
  </entry>
  
  <entry>
    <title>FreeSky主题访问量统计修复</title>
    <link href="https://www.csuldw.com/2019/02/16/2019-02-16-theme-fixed-notes/"/>
    <id>https://www.csuldw.com/2019/02/16/2019-02-16-theme-fixed-notes/</id>
    <published>2019-02-15T18:31:00.000Z</published>
    <updated>2019-11-10T03:00:09.220Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>首先说明一下，本主题源自Hexo Next主题，经过笔者长期以来的修改，源代码中很多地方都有所变动，因此衍生出一个新的花名<code>FreeSky</code>，目前版本为<code>FreeSky v0.4.0</code>，GitHub地址：<a href="https://github.com/csuldw/FreeSky" target="_blank" rel="noopener">csuldw/FreeSky</a>。起初博主并没有意料到会有其他人也使用这一主题，毕竟修改的地方有点多，而且略微粗糙，没有去仔细修正，适合自用。最近在浏览GitHub的时候，看到用户ooobug提了一个<a href="https://github.com/csuldw/FreeSky/issues/1" target="_blank" rel="noopener">issue</a>，这也让我开始怀疑，这个BUG是否已经存在很久了。</p><a id="more"></a><p>主题涉及的技术有：</p><ul><li>Nodejs</li><li>Swig模板引擎</li><li>yaml</li><li>html</li><li>css</li><li>JavaScript</li><li>其他插件</li></ul><h2 id="访问量修复"><a href="#访问量修复" class="headerlink" title="访问量修复"></a>访问量修复</h2><p>记得06年的时候，本站的访问量已经26w+，比自己的CSDN站点的访问量略大，现在CSDN站点的访问量已经突破百万，而修复之后的站点才29w+，可见这个BUG确实早已诞生，只是因为自己没注意到，就忽略了。其实修复起来很简单，主要是<code>busuanzi</code>的<code>js</code>文件路径引用路径变化了。首先找到<code>Freesky\layout\_partials</code>目录下的<code>footer.swig</code>文件,footer.swig文件内容如下：</p><figure class="highlight twig"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"copyright"</span> &gt;</span></span></span><br><span class="line"><span class="xml">  </span><span class="template-tag">{% <span class="name"><span class="keyword">set</span></span> current = <span class="name">date</span><span class="params">(Date.now()</span>, "YYYY") %}</span></span><br><span class="line"><span class="xml">  <span class="symbol">&amp;copy;</span> </span><span class="template-tag">{% <span class="name"><span class="keyword">if</span></span> theme.since and theme.since != current %}</span><span class="xml"> </span><span class="template-variable">{{ theme.since }}</span><span class="xml"> - </span><span class="template-tag">{% <span class="name"><span class="keyword">endif</span></span> %}</span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">span</span> <span class="attr">itemprop</span>=<span class="string">"copyrightYear"</span>&gt;</span></span><span class="template-variable">{{ current }}</span><span class="xml"><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"with-love"</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"icon-next-heart fa fa-heart"</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span></span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"author"</span> <span class="attr">itemprop</span>=<span class="string">"copyrightHolder"</span>&gt;</span></span><span class="template-variable">{{ config.author }}</span><span class="xml"><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"powered-by"</span>&gt;</span></span></span><br><span class="line"><span class="xml">  </span><span class="template-variable">{{ __('footer.powered', '&lt;a class="theme-link" href="http://hexo.io"&gt;Hexo&lt;/a&gt;') }}</span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"theme-info"</span>&gt;</span></span></span><br><span class="line"><span class="xml">  </span><span class="template-variable">{{ __('footer.theme') }}</span><span class="xml"> -</span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">"theme-link"</span> <span class="attr">href</span>=<span class="string">"#"</span>&gt;</span></span></span><br><span class="line"><span class="xml">    FreeSky</span><span class="template-tag">{% <span class="name"><span class="keyword">if</span></span> theme.scheme %}</span><span class="xml">.</span><span class="template-variable">{{ theme.scheme }}</span><span class="template-tag">{% <span class="name"><span class="keyword">endif</span></span> %}</span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;/<span class="name">a</span>&gt;</span>(Reserved)</span></span><br><span class="line"></span><br><span class="line"><span class="xml">  </span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">"busuanzi_container_site_uv"</span>&gt;</span></span></span><br><span class="line"><span class="xml">     <span class="symbol">&amp;nbsp;</span> | <span class="symbol">&amp;nbsp;</span>  用户量: <span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">"busuanzi_value_site_uv"</span>&gt;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">"busuanzi_container_site_pv"</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="symbol">&amp;nbsp;</span> | <span class="symbol">&amp;nbsp;</span>  总访问量: <span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">"busuanzi_value_site_pv"</span>&gt;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="xml">  </span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="template-tag">{% <span class="name"><span class="keyword">block</span></span> footer %}</span><span class="template-tag">{% <span class="name"><span class="keyword">endblock</span></span> %}</span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">script</span> <span class="attr">async</span> <span class="attr">src</span>=<span class="string">"https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br></pre></td></tr></tbody></table></figure><p>我们将最后一行的内容替换为下面这行就OK了。</p><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">async</span> <span class="attr">src</span>=<span class="string">"//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>最后感谢GitHub用户ooobug的提示，目前本站的总访问量是<code>29w+</code>，访问用户量是<code>16w+</code>，这个统计数漏掉了很长一段时间，不过也没太大关系。在后续的时间里，还是以提高博文质量为首要目标，多总结、多输出，主题的折腾就暂且放下吧，有时间再来集中更新一版(#^.^#)！</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;首先说明一下，本主题源自Hexo Next主题，经过笔者长期以来的修改，源代码中很多地方都有所变动，因此衍生出一个新的花名&lt;code&gt;FreeSky&lt;/code&gt;，目前版本为&lt;code&gt;FreeSky v0.4.0&lt;/code&gt;，GitHub地址：&lt;a href=&quot;https://github.com/csuldw/FreeSky&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;csuldw/FreeSky&lt;/a&gt;。起初博主并没有意料到会有其他人也使用这一主题，毕竟修改的地方有点多，而且略微粗糙，没有去仔细修正，适合自用。最近在浏览GitHub的时候，看到用户ooobug提了一个&lt;a href=&quot;https://github.com/csuldw/FreeSky/issues/1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;issue&lt;/a&gt;，这也让我开始怀疑，这个BUG是否已经存在很久了。&lt;/p&gt;
    
    </summary>
    
      <category term="其他" scheme="https://www.csuldw.com/categories/%E5%85%B6%E4%BB%96/"/>
    
    
      <category term="Hexo" scheme="https://www.csuldw.com/tags/Hexo/"/>
    
      <category term="FreeSky" scheme="https://www.csuldw.com/tags/FreeSky/"/>
    
      <category term="主题" scheme="https://www.csuldw.com/tags/%E4%B8%BB%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>FM算法原理分析与实践</title>
    <link href="https://www.csuldw.com/2019/02/08/2019-02-08-fm-algorithm-theory/"/>
    <id>https://www.csuldw.com/2019/02/08/2019-02-08-fm-algorithm-theory/</id>
    <published>2019-02-07T16:01:00.000Z</published>
    <updated>2019-07-25T17:00:05.705Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>“学而时习之，不亦说乎”，趁着过年几天假期，多写几篇文章。上一篇文章<a href="http://www.csuldw.com/2019/02/06/2019-02-06-recommendation-with-neural-network-embeddings/">基于Embedding的推荐系统召回策略</a>介绍的是一种召回方法，本文将介绍一种用于推荐系统排序阶段的方法FM，全称Factorization Machines，该算法的目的是解决稀疏数据下的特征组合问题，被广泛应用于广告推荐等CTR预估场景。关于FM算法的介绍数不胜数，读者也可以去阅读<a href="https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf" target="_blank" rel="noopener">paper</a>。本文纯粹是笔者实践过程中的个人总结，内容简要浅显，不敢与其他行家媲美，如若读者在阅读过程中发现疑问，还请留言告知，谢谢！</p><a id="more"></a><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>FM是Steffen Rendle在2010年提出的，FM算法的核心在于特征组合，以此来减少人工参与特征组合工作。对于FM，其优势可分以下三点: </p><ol><li>FM能处理数据高度稀疏场景，SVM则不能；</li><li>FM具有线性的计算复杂度，而SVM依赖于support vector。</li><li>FM能够在任意的实数特征向量中生效。</li></ol><h2 id="FM原理"><a href="#FM原理" class="headerlink" title="FM原理"></a>FM原理</h2><p>FM的数据结构如下：</p><p><img src="/assets/articleImg/2019/FM-template.jpg" alt=""></p><div class="caption">FM特征数据结构：User相关、Item相关、类别相关的特征、历史行为数据特征等等，最后一列可看作是User对Item评分</div><p>FM通过不同特征的组合，生成新的含义。然而，特征组合也随之带来一些问题： </p><ol><li>特征之间两两组合容易导致维度灾难； </li><li>组合后的特征未必有效，可能存在特征冗余现象； </li><li>组合后特征样本非常稀疏，如果原始样本中不存在对应的组合，则无法学习参数，那么该组合就显得无效。</li></ol><p>虽然有这些缺点，但是也并不影响FM在广告推荐领域的地位，每个算法都有风靡一时的过去，抱着敬畏之心的态度去学习是没问题的。下面，来看看FM的算法原理。</p><h3 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h3><p>我们知道，线性模型的目标函数为： </p><p>$$<br>y = w_{0} + \sum_{i=1}^{n} w_{i} x_{i}<br>\tag{1} \label{1}<br>$$</p><p>其中$n$表示样本的特征数量，$w_{0}$为偏置，$x_{i}$表示第$i$个特征的值，后面一项为特征的<a href="https://en.wikipedia.org/wiki/Linear_combination" target="_blank" rel="noopener">Linear combination</a>。FM增加了特征交叉组合部分，表达式如下：</p><p>$$<br>y = w_{0} + \sum_{i=1}^{n} w_{i} x_{i} + \color{blue} {\sum_{i=1}^{n-1} \sum_{j=i+1}^{n} w_{ij} x_{i} x_{j}}<br>\tag{2} \label{2}<br>$$</p><p>其中$w_{0}$、$w_{i}$、$w_{ij}$是模型参数。从公式来看，模型前半部分就是普通的LR线性组合[No Problem]，后半部分的交叉项：特征组合。首先，单从模型表达能力上来看，FM是要强于LR的，至少它不会比LR弱，当交叉项参数$w_{ij}$全为0的时候，整个模型就退化为普通的LR模型。对于有$n$个特征的模型，特征组合的参数数量共有$1+2+3+\cdots  + n-1=\frac{n(n-1)}{2}$个，并且任意两个参数之间是独立的。所以说特征数量比较多的时候，特征组合之后，维度自然而然就高了。</p><p>代数知识：</p><blockquote><p>任意一个实对称矩阵（正定矩阵）$W$都存在一个矩阵$V$，使得 $W=V.V^{T}$成立。</p></blockquote><p>类似地，所有二次项参数$\omega_{ij}$可以组成一个对称阵$W$（为了方便说明FM的由来，对角元素可以设置为正实数），那么这个矩阵就可以分解为$W=V^TV$，$V$ 的第$j$列($v_{j}$)便是第$j$维特征($x_{j}$)的隐向量。</p><p>$$<br>\hat{y}(X) = \omega_{0}+\sum_{i=1}^{n}{\omega_{i}x_{i}}+\sum_{i=1}^{n-1}{\sum_{j=i+1}^{n} \color{red}{&lt;v_{i},v_{j}&gt;x_{i}x_{j}}}<br>\tag{3} \label{3}<br>$$</p><p>需要估计的参数有$\omega_{0}∈ R$，$\omega_{i}∈ R$，$V∈ R$，$&lt; \cdot, \cdot&gt;$是长度为$k$的两个向量的点乘，公式如下：</p><p>$$&lt;v_{i},v_{j}&gt; = \sum_{f=1}^{k}{v_{i,f}\cdot v_{j,f}}<br>\tag{4} \label{4}<br>$$</p><p>上面的公式$\eqref{3}$，$\eqref{4}$中， </p><ul><li>$\omega_{0}$为全局偏置；</li><li>$\omega_{i}$是模型第$i$个变量的权重;</li><li>$\omega_{ij} = &lt; v_{i}, v_{j}&gt;$特征$i$和$j$的交叉权重;</li><li>$v_{i} $是第$i$维特征的隐向量;</li><li>$&lt;\cdot, \cdot&gt;$代表向量点积;</li><li>$k(k&lt;&lt;n)$为隐向量的长度，包含 $k$ 个描述特征的因子。</li></ul><p>根据公式$\eqref{2}$，二次项的参数数量减少为 $kn $个，远少于多项式模型的参数数量。另外，参数因子化使得 $x_{h}x_{i}$ 的参数和 $x_{i}x_{j}$ 的参数不再是相互独立的，因此我们可以在样本稀疏的情况下相对合理地估计FM的二次项参数。具体来说，$x_{h}x_{i}$ 和 $x_{i}x_{j}$的系数分别为 $&lt;v_{h},v_{i}&gt;$ 和 $&lt;v_{i},v_{j}&gt;$ ，它们之间有共同项 $v_{i}$ 。也就是说，所有包含“ $x_{i}$ 的非零组合特征”（存在某个 $j \ne i$ ，使得 $x_{i}x_{j}\neq 0$ ）的样本都可以用来学习隐向量$v_{i}$，这很大程度上避免了数据稀疏性造成的影响。而在多项式模型中,$w_{hi}$ 和 $w_{ij}$ 是相互独立的。</p><p>显而易见，公式$\eqref{3}$是一个通用的拟合方程，可以采用不同的损失函数用于解决regression、classification等问题，比如可以采用MSE（Mean Square Error）loss function来求解回归问题，也可以采用Hinge/Cross-Entropy loss来求解分类问题。当然，在进行二元分类时，FM的输出需要使用sigmoid函数进行变换，该原理与LR是一样的。直观上看，FM的复杂度是 $O(kn^2)$ 。但是，通过公式$\eqref{4}$的等式，FM的二次项可以化简，其复杂度可以优化到 $O(kn)$ 。由此可见，FM可以在线性时间对新样本作出预测。</p><p>公式$\eqref{3}$的推导</p><p>$$<br>ab+ac+bc = \frac{1}{2}\left[(a+b+c)^2-(a^2+b^2+c^2) \right]<br>\tag{5} \label{5}<br>$$</p><p>$$<br>\begin{align} \sum_{i=1}^{n-1}{\sum_{j=i+1}^{n}{&lt;v_i,v_j&gt;x_ix_j}}<br>&amp;= \frac{1}{2}\sum_{i=1}^{n}{\sum_{j=1}^{n}{&lt;v_i,v_j&gt;x_ix_j}} - \frac{1}{2} {\sum_{i=1}^{n}{&lt;v_i,v_i&gt;x_ix_i}} \\<br>&amp;= \frac{1}{2} \left( \sum_{i=1}^{n}{\sum_{j=1}^{n}{\sum_{f=1}^{k}{v_{i,f}v_{j,f}x_ix_j}}} - \sum_{i=1}^{n}{\sum_{f=1}^{k}{v_{i,f}v_{i,f}x_ix_i}} \right) \\<br>&amp;= \frac{1}{2}\sum_{f=1}^{k}{\left[ \left( \sum_{i=1}^{n}{v_{i,f}x_i} \right) \cdot \left( \sum_{j=1}^{n}{v_{j,f}x_j} \right) - \sum_{i=1}^{n}{v_{i,f}^2 x_i^2} \right]} \\<br>&amp;= \frac{1}{2}\sum_{f=1}^{k}{\left[ \left( \sum_{i=1}^{n}{v_{i,f}x_i} \right)^2 - \sum_{i=1}^{n}{v_{i,f}^2 x_i^2} \right]} \end{align}<br>\tag{6} \label{6}<br>$$</p><p>解释：</p><ul><li>$v_{i,f}$ 是一个具体的值；</li><li>第1个等号：对称矩阵 $W$ 对角线上半部分；</li><li>第2个等号：把向量内积 $v_{i}$,$v_{j}$ 展开成累加和的形式；</li><li>第3个等号：提出公共部分；</li><li>第4个等号： $i$ 和 $j$ 相当于是一样的，表示成平方过程。</li></ul><h3 id="SGD训练参数"><a href="#SGD训练参数" class="headerlink" title="SGD训练参数"></a>SGD训练参数</h3><p>使用SGD进行训练，可以推导出SGD的参数更新方式：</p><p>$$<br>\begin{equation}<br>\frac{\partial \hat{y}(x)}{\partial \theta} = \left\{\begin{array}<br>{lr} 1, &amp; if \ \theta\ is\ \omega_{0} \\<br>x_{i}, &amp; if\ \theta\ is\ \omega_i \\<br>x_{i} \sum_{j=1}^{n}{v_{j,f} \ x_{j} - v_{i,f} \ x_{i}^2} &amp; if\ \theta\ is\ v_{i,f} \end{array} \right.<br>\end{equation}<br>\tag{7} \label{7}<br>$$</p><p>上式中，$\sum_{j=1}^{n} v_{j,f} \ x_{j}$ 的计算与变量$i$相互独立，因此可以预先计算得到。每个梯度的计算时间复杂度都为$O(1)$，模型的参数总数量为 $nk + n + 1$，在数据稀疏条件下，参数更新所需要的所有时间为$ O(k n)$。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="Windows下安装pyfm"><a href="#Windows下安装pyfm" class="headerlink" title="Windows下安装pyfm"></a>Windows下安装pyfm</h3><p>pyfm install：将<a href="https://github.com/coreylynch/pyFM" target="_blank" rel="noopener">pyFM</a> 下载到本地，解压后去掉setup.py文件里面的libraries=[“m”]一行,然后采用<code>python setup.py install</code>安装即可.</p><h3 id="分类模型"><a href="#分类模型" class="headerlink" title="分类模型"></a>分类模型</h3><p>FM可以用来进行分类，为了方便，这里使用sklearn里面的iris数据集作为实验数据，将target等于2的作为正样本，其余作为负样本，并采用train_test_split方法划分训练集与测试集，然后通过FM构建分类模型，并通过测试集验证FM的效果。完整Demo代码如下（Github地址：<a href="https://github.com/csuldw/MachineLearning/blob/master/Recommendation%20System/pyfm_demo.py" target="_blank" rel="noopener">pyfm_demo.py</a>）：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Sun Jan 27 23:49:24 2019</span></span><br><span class="line"><span class="string">@author: liudiwei</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> pyfm <span class="keyword">import</span> pylibfm</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    调用sklearn的iris数据集，筛选正负样本并构造切分训练测试数据集</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    iris_data = load_iris()</span><br><span class="line">    X = iris_data[<span class="string">'data'</span>]</span><br><span class="line">    y = iris_data[<span class="string">'target'</span>] == <span class="number">2</span></span><br><span class="line">    data = [ {v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> dict(zip(i, range(len(i)))).items()}  <span class="keyword">for</span> i <span class="keyword">in</span> X]</span><br><span class="line">    X_train,X_test,y_train, y_test = train_test_split(data,y, test_size=<span class="number">0.3</span>, random_state=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> X_train,X_test,y_train, y_test</span><br><span class="line"></span><br><span class="line">X_train,X_test,y_train, y_test = load_data()</span><br><span class="line"></span><br><span class="line">v = DictVectorizer()</span><br><span class="line">X_train = v.fit_transform(X_train)</span><br><span class="line">X_test = v.transform(X_test)</span><br><span class="line"></span><br><span class="line">fm = pylibfm.FM(num_factors=<span class="number">2</span>, </span><br><span class="line">                num_iter=<span class="number">200</span>, </span><br><span class="line">                verbose=<span class="literal">True</span>, </span><br><span class="line">                task=<span class="string">"classification"</span>, </span><br><span class="line">                initial_learning_rate=<span class="number">0.001</span>, </span><br><span class="line">                learning_rate_schedule=<span class="string">"optimal"</span>)</span><br><span class="line"></span><br><span class="line">fm.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_preds = fm.predict(X_test)</span><br><span class="line">y_preds_label = y_preds &gt; <span class="number">0.5</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> log_loss,accuracy_score</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Validation log loss: %.4f"</span> % log_loss(y_test, y_preds))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"accuracy: %.4f"</span> % accuracy_score(y_test, y_preds_label))</span><br></pre></td></tr></tbody></table></figure><p>对于上面的FM模型，摘录了pyFM的一部分参数，其它参数可参考官方解释。</p><ol><li>num_factors : int, The dimensionality of the factorized 2-way interactions</li><li>num_iter : int,  迭代次数</li><li>learning_rate_schedule（可选参数） : string类型, 学习率迭代参数值:<ul><li>constant: $\eta = \eta_0$</li><li>optimal: $\eta = \frac{1}{t+t_0}$ [default]</li><li>invscaling: $\eta = \eta_0 / pow(t, power\_t)$</li></ul></li><li>initial_learning_rate : double, 初始时的学习率，默认等于 0.01</li><li>task : 模型任务类型，string<ul><li>regression: Labels 为实数值.</li><li>classification: Labels 为1或0.</li></ul></li><li>verbose : bool，是否需要打印当前迭代时的训练误差（training error）.</li><li>power_t : double, The exponent for inverse scaling learning rate [默认值 0.5].</li><li>t0 : double，learning_rate_schedule的初始值. 默认值 0.001.</li></ol><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>通过上面代码，跑出的结果如下（注：每次实验结果不一定相同）：</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">Training log loss:</span> <span class="number">0.12161</span></span><br><span class="line"><span class="attr">Validation log loss:</span> <span class="number">0.1868</span></span><br><span class="line"><span class="attr">accuracy:</span> <span class="number">0.9778</span></span><br></pre></td></tr></tbody></table></figure><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>OK，关于FM的介绍暂且结束，FM的计算是比较耗内存的，特征维度超过100，两两组合之后，特征维度就达到1w+，维度增加带来的就是计算量的剧增，跑实验的话，还是需要硬件支撑的。所以也因此衍生出FFM算法（Field-aware FM），主要是对特征进行分组然后进行组合。关于FFM的细节，后续在补充吧！</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf" target="_blank" rel="noopener">https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf</a></li><li><a href="https://github.com/csuldw/MachineLearning/blob/master/Recommendation%20System/pyfm_demo.py" target="_blank" rel="noopener">https://github.com/csuldw/MachineLearning/blob/master/Recommendation%20System/pyfm_demo.py</a></li><li><a href="http://www.libfm.org/libfm-1.42.manual.pdf" target="_blank" rel="noopener">http://www.libfm.org/libfm-1.42.manual.pdf</a></li><li><a href="http://d0evi1.com/libfm/" target="_blank" rel="noopener">http://d0evi1.com/libfm/</a></li><li><a href="http://ibayer.github.io/fastFM/guide.html" target="_blank" rel="noopener">http://ibayer.github.io/fastFM/guide.html</a></li><li><a href="http://www.tk4479.net/jiangda_0_0/article/details/77510029" target="_blank" rel="noopener">http://www.tk4479.net/jiangda_0_0/article/details/77510029</a></li></ol><p><span style="color:#CCCCCC; font-size: 0.9em">版权声明：本文为原创文章，转载请注明来源. <a href="https://www.csuldw.com/2019/02/08/2019-02-08-fm-algorithm-theory">https://www.csuldw.com/2019/02/08/2019-02-08-fm-algorithm-theory</a></span></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;“学而时习之，不亦说乎”，趁着过年几天假期，多写几篇文章。上一篇文章&lt;a href=&quot;http://www.csuldw.com/2019/02/06/2019-02-06-recommendation-with-neural-network-embeddings/&quot;&gt;基于Embedding的推荐系统召回策略&lt;/a&gt;介绍的是一种召回方法，本文将介绍一种用于推荐系统排序阶段的方法FM，全称Factorization Machines，该算法的目的是解决稀疏数据下的特征组合问题，被广泛应用于广告推荐等CTR预估场景。关于FM算法的介绍数不胜数，读者也可以去阅读&lt;a href=&quot;https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;paper&lt;/a&gt;。本文纯粹是笔者实践过程中的个人总结，内容简要浅显，不敢与其他行家媲美，如若读者在阅读过程中发现疑问，还请留言告知，谢谢！&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="FM" scheme="https://www.csuldw.com/tags/FM/"/>
    
      <category term="推荐系统 - 预测" scheme="https://www.csuldw.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E9%A2%84%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>基于Embedding的推荐系统召回策略</title>
    <link href="https://www.csuldw.com/2019/02/06/2019-02-06-recommendation-with-neural-network-embeddings/"/>
    <id>https://www.csuldw.com/2019/02/06/2019-02-06-recommendation-with-neural-network-embeddings/</id>
    <published>2019-02-06T03:44:00.000Z</published>
    <updated>2019-07-25T17:00:23.999Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>推荐系统主要试图预测user对item的评分或是偏好，通过评分的高低进行针对性的推荐。纵观各互联网大公司，几乎都会采用使用到推荐服务，比如：新闻推荐、广告推荐、商品推荐、书籍推荐等等。本文主要介绍如何使用keras训练embedding weights进而进行推荐。</p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>关于推荐系统，值得一提的是，推荐系统存在的“冷启动”问题，关于“冷启动”，主要分以下三类：</p><ul><li>用户冷启动：即新来一个用户，如何做个性化推荐；</li><li>物品冷启动：即新的物品如何推荐给可能对它感兴趣的用户。</li><li>系统冷启动：即如何在一个新开发的网站（没有用户，没有用户行为，只有部分物品信息）上设计个性化推荐系统，从而在项目刚发布时就让用户体会到个性化推荐。</li></ul><p>一个推荐系统可分为两个阶段：第一、召回阶段: 因为单个召回算法得到的结果一般都很难满足业务需求，所以通常都采取多路召回方式，如热门推荐、协同过滤、主题模型、内容召回以及模型召回等；第二、排序阶段：对多个召回方法的结果进行统一打分并排序，选出最优Top K。然而本文介绍的方法并不能解决冷启动问题，但是也算是一种召回策略。关于“冷启动”，后续再进行深入探讨。使用神经网络训练Embedding的几个步骤要点:</p><ol><li>收集数据：神经网络需要大量的训练样本；</li><li>数据处理：根据具体问题将数据按照embedding的场景标准进行处理；</li><li>训练weights：建立embedding模型训练weights；</li><li>使用weights：使用Embedding weight进行recommendation和visualizations.</li></ol><p>下面根据这几个步骤进行详细探讨，最终将给出一个推荐结果。</p><h3 id="数据收集"><a href="#数据收集" class="headerlink" title="数据收集"></a>数据收集</h3><p>假设我们获取的已知数据如下：</p><ol><li>doc的相关信息，包括：title、content（部分正文）</li><li>user对doc的点击事件。</li></ol><p>目的：给用户推荐<code>Top N</code>个没有阅读过的doc。</p><h3 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h3><p>Item2vec中把用户浏览的item集合等价于word2vec中的word的序列，即句子（忽略了商品序列空间信息spatial information） 。出现在同一个集合的<em>商品</em>对视为 positive</p><p>本文主要介绍如何给已有的用户进行推荐。用户点击过一篇doc，说明用户对doc产生了一定的兴趣，当我们把每个doc用实体词标签标记之后，就相当于用户对这些实体词感兴趣[user_id, keywords]，其中keywords是用“|”分隔的词的集合。当我们将用户与多篇doc关联起来之后，就可以得到用户与实体词的兴趣。最后可以使用[user_id, keyword, score]进行标记。</p><p>user_keywords.csv文件内容如下，GitHub链接:<a href="https://github.com/csuldw/MachineLearning/blob/master/Recommendation%20System/data_process/user_keywords.csv" target="_blank" rel="noopener">user_keywords.csv</a>：</p><figure class="highlight gherkin"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">user_id                                   keywords</span><br><span class="line">   113  新闻推荐|<span class="string">资讯推荐</span>|<span class="string">内容推荐</span>|<span class="string">文本分类</span>|<span class="string">人工分类</span>|<span class="string">自然语言处理</span>|<span class="string">聚类</span>|<span class="string">分类</span>|<span class="string">冷启动</span></span><br><span class="line"><span class="string">   143                         网络</span>|<span class="string">睡眠</span>|<span class="string">精神衰弱</span>|<span class="string">声音</span>|<span class="string">人工分类</span></span><br><span class="line"><span class="string">   123                          新年愿望</span>|<span class="string">梦想</span>|<span class="string">2018</span>|<span class="string">辞旧迎新</span></span><br><span class="line"><span class="string">   234                      父母</span>|<span class="string">肩头</span>|<span class="string">饺子</span>|<span class="string">蔬菜块</span>|<span class="string">青春叛逆期</span>|<span class="string">声音</span></span><br><span class="line"><span class="string">   117       新闻推荐</span>|<span class="string">内容推荐</span>|<span class="string">文本分类</span>|<span class="string">人工分类</span>|<span class="string">自然语言处理</span>|<span class="string">聚类</span>|<span class="string">分类</span>|<span class="string">冷启动</span></span><br><span class="line"><span class="string">   119            新闻推荐</span>|<span class="string">资讯推荐</span>|<span class="string">人工分类</span>|<span class="string">自然语言处理</span>|<span class="string">聚类</span>|<span class="string">分类</span>|<span class="string">冷启动</span></span><br><span class="line"><span class="string">    12              新闻推荐</span>|<span class="string">资讯推荐</span>|<span class="string">内容推荐</span>|<span class="string">文本分类</span>|<span class="string">聚类</span>|<span class="string">分类</span>|<span class="string">冷启动</span></span><br><span class="line"><span class="string">   122                   机器学习</span>|<span class="string">新闻推荐</span>|<span class="string">梦想</span>|<span class="string">人工分类</span>|<span class="string">自然语言处理</span></span><br></pre></td></tr></tbody></table></figure><p>首先，我们通过pandas加载数据集</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Sat Jan  5 15:34:34 2019</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: liudiwei</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Embedding, Dot, Reshape, Dense</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line">random.seed(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#load dataset</span></span><br><span class="line">user_keywords = pd.read_csv(<span class="string">"user_keywords.csv"</span>)</span><br></pre></td></tr></tbody></table></figure><p>通过数据处理之后可以得到user_keywords, user_index, keyword_index：</p><figure class="highlight vim"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">def date_process(user_item):</span><br><span class="line">    <span class="string">""</span><span class="comment">"user_item is a DataFrame, column=[user_id, keywords]   </span></span><br><span class="line">    <span class="number">1</span>. user_item: user <span class="built_in">and</span> item information, user_id, keywords, keyword_index</span><br><span class="line">    <span class="number">2</span>. user_index: user <span class="keyword">to</span> <span class="built_in">index</span></span><br><span class="line">    <span class="number">3</span>. item_index：item <span class="keyword">to</span> <span class="built_in">index</span></span><br><span class="line">    <span class="string">""</span><span class="comment">"</span></span><br><span class="line">    user_item[<span class="string">"keywords"</span>] = user_item[<span class="string">"keywords"</span>].apply(lambda <span class="keyword">x</span>: <span class="keyword">x</span>.<span class="keyword">split</span>(<span class="string">"|"</span>))</span><br><span class="line">    keyword_list = [] </span><br><span class="line">    <span class="keyword">for</span> i in user_item[<span class="string">"keywords"</span>]:</span><br><span class="line">        keyword_list.<span class="built_in">extend</span>(i)</span><br><span class="line">        </span><br><span class="line">    #word <span class="built_in">count</span></span><br><span class="line">    item_count = pd.DataFrame(pd.Series(keyword_list).value_counts()) </span><br><span class="line">    # <span class="built_in">add</span> <span class="built_in">index</span> <span class="keyword">to</span> word_count</span><br><span class="line">    item_count[<span class="string">'id'</span>] = <span class="keyword">list</span>(<span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(item_count)))</span><br><span class="line">    </span><br><span class="line">    #将word的id对应起来</span><br><span class="line">    map_index = lambda <span class="keyword">x</span>: <span class="keyword">list</span>(item_count[<span class="string">'id'</span>][<span class="keyword">x</span>])</span><br><span class="line">    user_item[<span class="string">'keyword_index'</span>] = user_item[<span class="string">'keywords'</span>].apply(map_index) #速度太慢</span><br><span class="line">    #create user_index, item_index</span><br><span class="line">    user_index = { <span class="variable">v:k</span> <span class="keyword">for</span> <span class="keyword">k</span>,v in user_item[<span class="string">"user_id"</span>].to_dict().<span class="built_in">items</span>()}</span><br><span class="line">    item_index = item_count[<span class="string">"id"</span>].to_dict()</span><br><span class="line">    <span class="keyword">return</span> user_item, user_index, item_index</span><br><span class="line"></span><br><span class="line">user_keywords, user_index, keyword_index = date_process(user_keywords)</span><br></pre></td></tr></tbody></table></figure><p>接下来，需要模拟一个分类或者回归的场景，用于学习embedding的weights。这里，我们模拟一个分类场景！</p><h3 id="训练分类模型"><a href="#训练分类模型" class="headerlink" title="训练分类模型"></a>训练分类模型</h3><p>注意，这里主要是模拟场景，并非做真的分类模型。训练模型的预测结果不是我们的最终目的，我们的目的是得到模型的parameters，即weights，所以，我们不需要真正的care模型结果是否精确。</p><p>对于Embedding的weights，主要有三个作用：</p><ol><li>在embedding Space中找到某个样本点<code>top K</code>的最近邻；</li><li>作为machine learning model的input</li><li>Visualization：低维空间可视化</li></ol><p>这里注重分析第1点和第3点。下面，先来构建正负样本。</p><h4 id="模拟正负样本"><a href="#模拟正负样本" class="headerlink" title="模拟正负样本"></a>模拟正负样本</h4><p>通过数据构造，我们得到了user与keyword的关系，知道每个user对keyword的喜好程度。为了构建分类模型，这里我们将已有的user与keyword的对应关系作为正样本，负样本通过人工的从user集合与keyword集合进行构造，当出现的user与keyword对不在已有的数据内，我们就将其作为负样本。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_pairs</span><span class="params">(user_keywords, user_index)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    generate user, keyword pair list</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    pairs = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">doc2tag</span><span class="params">(pairs, x)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> x[<span class="string">"keyword_index"</span>]:</span><br><span class="line">            pairs.append((user_index[x[<span class="string">"user_id"</span>]], index))</span><br><span class="line">    user_keywords.apply(<span class="keyword">lambda</span> x: doc2tag(pairs, x), axis=<span class="number">1</span>) <span class="comment">#速度太慢</span></span><br><span class="line">    <span class="keyword">return</span> pairs</span><br><span class="line"></span><br><span class="line">pairs = create_pairs(user_keywords, user_index)</span><br></pre></td></tr></tbody></table></figure><p>通过create_pairs方法，可以得到user与keyword的pairs。</p><h4 id="Embedding模型"><a href="#Embedding模型" class="headerlink" title="Embedding模型"></a>Embedding模型</h4><p>Embedding model的五个layer:</p><ol><li>Input: user与keyword同时作为输入；</li><li>Embedding: 每个user和keyword使用同样的embedding size；</li><li>Dot: 使用dot product合并embedding；</li><li>Reshape: 将点积Reshape为一个值；</li><li>Dense: 使用sigmoid激活函数处理output。</li></ol><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">def build_embedding_model(<span class="attr">embedding_size</span> = <span class="number">50</span>, <span class="attr">classification</span> = False):</span><br><span class="line">    <span class="string">""</span><span class="string">"训练embedding模型"</span><span class="string">""</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 输入为1-D</span></span><br><span class="line">    <span class="attr">user</span> = Input(<span class="attr">name</span> = 'user', <span class="attr">shape</span> = [<span class="number">1</span>])</span><br><span class="line">    <span class="attr">keyword</span> = Input(<span class="attr">name</span> = 'keyword', <span class="attr">shape</span> = [<span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># user Embedding 设置:  (None, 1, 50)</span></span><br><span class="line">    <span class="attr">user_embedding</span> = Embedding(<span class="attr">name</span> = 'user_embedding',</span><br><span class="line">                               <span class="attr">input_dim</span> = len(user_index),</span><br><span class="line">                               <span class="attr">output_dim</span> = embedding_size)(user)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># keyword Embedding  设置: (None, 1, 50)</span></span><br><span class="line">    <span class="attr">keyword_embedding</span> = Embedding(<span class="attr">name</span> = 'keyword_embedding',</span><br><span class="line">                               <span class="attr">input_dim</span> = len(keyword_index),</span><br><span class="line">                               <span class="attr">output_dim</span> = embedding_size)(keyword)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 使用dot进行合并</span></span><br><span class="line">    <span class="comment"># (shape will be (None, 1, 1))</span></span><br><span class="line">    <span class="attr">merged</span> = Dot(<span class="attr">name</span> = 'dot_product', <span class="attr">normalize</span> = True,</span><br><span class="line">                 <span class="attr">axes</span> = <span class="number">2</span>)([user_embedding, keyword_embedding])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Reshape 为1个数 (shape 大小为 (None, 1))</span></span><br><span class="line">    <span class="attr">merged</span> = Reshape(<span class="attr">target_shape</span> = [<span class="number">1</span>])(merged)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 分类输出</span></span><br><span class="line">    <span class="attr">out</span> = Dense(<span class="number">1</span>, <span class="attr">activation</span> = 'sigmoid')(merged)</span><br><span class="line">    <span class="attr">model</span> = Model(<span class="attr">inputs</span> = [user, keyword], <span class="attr">outputs</span> = out)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 优化方法和loss </span></span><br><span class="line">    model.compile(<span class="attr">optimizer</span> = 'Adam', <span class="attr">loss</span> = 'binary_crossentropy', </span><br><span class="line">                  <span class="attr">metrics</span> = ['accuracy'])</span><br><span class="line">    <span class="comment">#print(model.summary())</span></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"><span class="attr">model</span> = build_embedding_model(<span class="attr">embedding_size</span> = <span class="number">20</span>, <span class="attr">classification</span> = False)</span><br></pre></td></tr></tbody></table></figure><p>batch训练：</p><figure class="highlight jboss-cli"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">def generate_<span class="keyword">batch</span><span class="params">(pairs, <span class="attr">n_positive</span> = 50, <span class="attr">negative_ratio</span> = 1.0)</span>:</span><br><span class="line">    <span class="keyword">batch</span>_size = n_positive * <span class="params">(1 + negative_ratio)</span></span><br><span class="line">    <span class="keyword">batch</span> = np.zeros<span class="params">((batch_size, 3)</span>)</span><br><span class="line">    </span><br><span class="line">    while True:</span><br><span class="line">        <span class="comment"># Randomly choose positive examples</span></span><br><span class="line">        for idx, <span class="params">(user_id, keyword_id)</span> in enumerate<span class="params">(random.sample(pairs, n_positive)</span>):</span><br><span class="line">            <span class="keyword">batch</span>[idx, :] = <span class="params">(user_id, keyword_id, 1)</span></span><br><span class="line">        idx += 1</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Add negative examples until reach batch size</span></span><br><span class="line">        while idx &lt; <span class="keyword">batch</span>_size:</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Random selection</span></span><br><span class="line">            random_user = random.randrange<span class="params">(len(user_index)</span>)</span><br><span class="line">            random_keyword = random.randrange<span class="params">(len(keyword_index)</span>)</span><br><span class="line">            <span class="comment">#print(random_user, random_keyword)</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Check to make sure this is not a positive example</span></span><br><span class="line">            <span class="keyword">if</span> <span class="params">(random_user, random_keyword)</span> not in pairs:</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># Add to batch and increment index</span></span><br><span class="line">                <span class="keyword">batch</span>[idx, :] = <span class="params">(random_user, random_keyword, 0)</span></span><br><span class="line">                idx += 1</span><br><span class="line">                </span><br><span class="line">        <span class="comment"># Make sure to shuffle order</span></span><br><span class="line">        np.random.shuffle<span class="params">(batch)</span></span><br><span class="line">        yield {'user': <span class="keyword">batch</span>[:, 0], 'keyword': <span class="keyword">batch</span>[:, 1]}, <span class="keyword">batch</span>[:, 2]</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">n_positive = len<span class="params">(pairs)</span></span><br><span class="line">gen = generate_<span class="keyword">batch</span><span class="params">(pairs, n_positive, <span class="attr">negative_ratio</span> = 1)</span></span><br><span class="line"><span class="comment"># Train</span></span><br><span class="line">h = model.fit_generator<span class="params">(gen, <span class="attr">epochs</span> = 100, <span class="attr">steps_per_epoch</span> = len(pairs)</span> <span class="string">//</span> n_positive)</span><br></pre></td></tr></tbody></table></figure><h4 id="提取user-weight"><a href="#提取user-weight" class="headerlink" title="提取user weight"></a>提取user weight</h4><p>当模型训练完之后，我们可以通过下面的方法提取user的weight，提取方法如下：</p><figure class="highlight ini"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Extract embeddings</span></span><br><span class="line"><span class="attr">user_layer</span> = model.get_layer(<span class="string">'user_embedding'</span>)</span><br><span class="line"><span class="attr">user_weights</span> = user_layer.get_weights()[<span class="number">0</span>]</span><br></pre></td></tr></tbody></table></figure><p>user_weights是用户权重集合，每一行表示一个用户，相当于通过embedding训练user的向量表示，接下来可以进一步对用户进行可视化分析，同时可以通过计算相似度得到每个用户最相似的K个用户。</p><h4 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h4><p>对上面训练得到的weights，通过PCA可视化，我们可以看到几个user之间的空间关系，代码如下：</p><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.decomposition <span class="built_in">import</span> PCA</span><br><span class="line"><span class="built_in">import</span> seaborn as sns</span><br><span class="line"></span><br><span class="line"><span class="comment">#PCA可视化</span></span><br><span class="line">def pca_show():</span><br><span class="line">    <span class="attr">pca</span> = PCA(<span class="attr">n_components=2)</span></span><br><span class="line">    <span class="attr">pca_result</span> = pca.fit_transform(user_weights)</span><br><span class="line">    sns.jointplot(<span class="attr">x=pca_result[:,0],</span> <span class="attr">y=pca_result[:,1])</span></span><br><span class="line">pca_show()</span><br></pre></td></tr></tbody></table></figure><p>可视化效果：</p><p><img src="/assets/articleImg/2019/embedding-weights-pca-result.png" alt=""></p><div class="caption">PCA结果：相同的几个样本点有一定的聚合性</div><p>我们可以看到，有着相同keyword喜好的user呈现出一定的聚合性。</p><h3 id="Top-K推荐"><a href="#Top-K推荐" class="headerlink" title="Top K推荐"></a>Top K推荐</h3><p>上面我们假设了每篇doc的keywords就是user对应的keywords，因此，我们可以直接通过计算weights 的cosine相似度进行推荐。</p><figure class="highlight markdown"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">#calculate cosine similarity </span></span><br><span class="line">from sklearn.metrics.pairwise import cosine_similarity</span><br><span class="line">cos = cosine<span class="emphasis">_similarity(user_</span>weights[5:6], user_weights)</span><br><span class="line">recommendations = cos[<span class="string">0</span>].argsort()[<span class="string">-4:</span>][<span class="symbol">::-1</span>]</span><br></pre></td></tr></tbody></table></figure><p>结果为：<code>[5、0、4、6]</code>，去掉第一个为自己本身，我们可以得到推荐下标为<code>0</code>、<code>4</code>、<code>6</code>的三篇用户。然后我们可以从这几个用户的user behavior里面，筛选出最近点击的或者最喜欢的doc给用户119。</p><h3 id="下一步"><a href="#下一步" class="headerlink" title="下一步"></a>下一步</h3><p>上面的方法主要是找到user的向量表示，类似于user-cf，通过表示向量我们可以计算出用户最相似的其它用户，进而进行推荐。下一步的推荐策略还可以进一步扩展：</p><ol><li>如何准确对用户推荐doc：可以采用user_similarity_score * user_doc_score，然后取top N；</li><li>训练基于doc的embedding，对每篇doc进行推荐；</li></ol><p>完整的Demo代码：<a href="https://github.com/csuldw/MachineLearning/blob/master/Recommendation%20System/recommend.py" target="_blank" rel="noopener">recommend.py</a></p><h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><ol><li><a href="https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526" target="_blank" rel="noopener">neural network embeddings explained</a></li><li><a href="http://blog.christianperone.com/2013/09/machine-learning-cosine-similarity-for-vector-space-models-part-iii/" target="_blank" rel="noopener">machine learning cosin similarity for vector space models</a></li><li><a href="https://projector.tensorflow.org/" target="_blank" rel="noopener">Google Tensorflows Embedding Projector</a></li><li><a href="http://www.sfu.ca/~jiaxit/resources/wsdm18caser.pdf" target="_blank" rel="noopener">Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding</a></li><li><a href="https://arxiv.org/vc/arxiv/papers/1603/1603.04259v2.pdf" target="_blank" rel="noopener">Item2vec: Neural Item Embedding for Collaborative Filtering</a></li><li><a href="https://towardsdatascience.com/building-a-recommendation-system-using-neural-network-embeddings-1ef92e5c80c9" target="_blank" rel="noopener">Building a Recommendation System Using Neural Network Embeddings</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;推荐系统主要试图预测user对item的评分或是偏好，通过评分的高低进行针对性的推荐。纵观各互联网大公司，几乎都会采用使用到推荐服务，比如：新闻推荐、广告推荐、商品推荐、书籍推荐等等。本文主要介绍如何使用keras训练embedding weights进而进行推荐。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="推荐系统" scheme="https://www.csuldw.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="深度学习" scheme="https://www.csuldw.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Embedding" scheme="https://www.csuldw.com/tags/Embedding/"/>
    
      <category term="召回" scheme="https://www.csuldw.com/tags/%E5%8F%AC%E5%9B%9E/"/>
    
  </entry>
  
  <entry>
    <title>如何利用机器学习进行异常检测和状态监测</title>
    <link href="https://www.csuldw.com/2019/01/09/2019-01-08-how-to-use-machine-learning-for-anomaly-detection-and-condition-monitoring/"/>
    <id>https://www.csuldw.com/2019/01/09/2019-01-08-how-to-use-machine-learning-for-anomaly-detection-and-condition-monitoring/</id>
    <published>2019-01-08T17:30:00.000Z</published>
    <updated>2019-05-28T16:43:21.647Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最近，在浏览towardsdatascience上面的机器学习相关文章的时候，无意间看到一篇关于异常检测的文章，刚好与自己的工作内容有点契合，文章讲解的是两种分析思路：第一种、PCA + Mahalanobis；第二种、AutoEncoder训练模型进行检测。兴奋之下，决定将这篇文章分享出来，如果内容有理解不当的地方，还请读者指出，深表感谢。</p><p>原文链接： <a href="https://towardsdatascience.com/how-to-use-machine-learning-for-anomaly-detection-and-condition-monitoring-6742f82900d7" target="_blank" rel="noopener">How to use machine learning for anomaly detection and condition monitoring</a></p><a id="more"></a><p>本文，将介绍机器学习和统计分析几种不同的技术和应用，然后展示如何应用这些方法来解决特定场景：异常检测(anomaly detection)和状态监控(condition monitoring)。</p><p><strong>Digital transformation, digitalization, Industry 4.0, etc….</strong></p><p>这些都是你可能听过或读过的专业术语。然而，这些流行语背后的主要目标是使用技术和数据来提高生产力和效率。设备和传感器之间信息的连接和流动会产生大量的数据。关键因素在于能够使用这些大量的可用数据，并真正提取有用的信息，从而使降低成本、容量优化和宕机时间降至最低成为可能。这也是最近围绕机器学习和数据分析讨论其发挥作用的地方。</p><h3 id="Anomaly-detection"><a href="#Anomaly-detection" class="headerlink" title="Anomaly detection"></a>Anomaly detection</h3><p><a href="https://en.wikipedia.org/wiki/Anomaly_detection" target="_blank" rel="noopener">异常检测</a>（或异常值检测）是对稀有物品、事件或观察结果的识别，这些物品、事件或观察结果与大多数数据存在显著差异，从而引起疑虑。通常，异常数据可以关联到某种问题或罕见事件，例如银行欺诈、医疗问题、结构缺陷、故障设备等。这种连接能够有趣地找出哪些数据点可以被视为异常，因为从业务角度来看，识别这些事件通常非常有趣。</p><p>关键目标：如何识别数据点是正常或是异常？简单的情况下，如下图所示，<strong><a href="https://en.wikipedia.org/wiki/Data_visualization" target="_blank" rel="noopener">数据可视化</a></strong>可以比较直观的展示出来。</p><p><img src="/assets/articleImg/2019/1-BaOiTGWAoFi-3_-E-rJGdg.jpeg" alt=""></p><div class="caption">Figure 1 : Anomaly detection for two variables</div><p>在二维空间（x和y）中，通过位于特定分布之外的数据点很直观地被我们识别为异常点。然而从右图来看，不可能直接根据一个变量就识别出异常值：正是X和Y变量的组合使得我们能够容易地识别异常值。当我们从两个变量放大到10-100个变量时，问题就变得非常复杂了，而这种场景经常出现在异常检测的实际应用当中。</p><h3 id="Connection-to-condition-monitoring"><a href="#Connection-to-condition-monitoring" class="headerlink" title="Connection to condition monitoring"></a>Connection to condition monitoring</h3><p>任何机器，无论是旋转机器（泵、压缩机、燃气轮机或蒸汽轮机等）还是非旋转机器（换热器、蒸馏塔、阀门等），最终都会达到不良的健康状态。这一点可能不是实际的故障或停机，而是设备不再以最佳状态运行。这表明可能需要一些维护行为来恢复最佳操作状态。简单地说，识别设备的“健康状态”是状态监控领域。</p><p>执行状态监控的最常见方法是查看机器上的每个传感器测量值，并对其施加最小和最大值进行限制。如果当前值在界限内，则机器正常。如果当前值超出界限，则机器不正常并发出警报。</p><p>设定硬编码告警阈值会产生大量的误报，即针对机器实际处于健康状态的情况发出报警。还可能漏报告警，也就是有问题但没有警报的情况。第一个问题不仅浪费时间和精力，而且浪费设备的可用性。第二个问题更为关键，因为它会导致相关维修成本的实际损失和生产损失。</p><p>这两个问题都是由同一个原因造成的：一个复杂设备的健康状况不能通过对每一个测量本身的分析来可靠地判断（如上图异常检测部分的图1所示）。我们更应该考虑多种测量方法的合并，以获得真实的情况。</p><h3 id="Technical-section"><a href="#Technical-section" class="headerlink" title="Technical section"></a>Technical section</h3><p>在不涉及更多技术方面的情况下，很难涵盖机器学习和异常检测统计分析的主题。我会避免太深入讲解理论背景（但会提供一些链接）。如果您对机器学习和统计分析的实际应用更感兴趣，例如状态监控，可跳到“状态监控用例”部分。</p><h4 id="Approach-1-Multivariate-statistical-analysis"><a href="#Approach-1-Multivariate-statistical-analysis" class="headerlink" title="Approach 1: Multivariate statistical analysis"></a>Approach 1: Multivariate statistical analysis</h4><p><strong>Dimensionality reduction using principal component analysis: PCA</strong></p><p>处理高维数据通常具有挑战性，因此有几种方法可以减少变量的数量（降维）。其中一种技术就是主要成分分析（PCA），它将数据线性映射到低维空间，使数据在低维空间中的方差最大化。在实际应用中，需要构造了数据的协方差矩阵，并计算该矩阵的特征向量。对应于最大特征值（主分量）的特征向量可以用来重建原始数据方差较大的一部分。原来的特征空间已经减少（有一些数据丢失，但会保留最重要的方差）到几个特征向量所跨越的空间。</p><p><strong>Multivariate anomaly detection</strong></p><p>如上所述，为了在处理一个或两个变量时识别异常，数据可视化通常是一个好的起点。然而，当将此扩展到高维数据（在实际应用中经常是这样）时，这种方法变得越来越困难。幸运的是，多元统计数据起到了作用。</p><p>当处理一组数据点时，它们通常具有一定的分布（例如高斯分布）。为了更定量地检测异常，我们首先从数据点计算概率分布$p(x)$。然后，当一个新的例子$x$出现时，我们将$p(x)$与阈值$r$进行比较。如果$p(x)&lt; r$，则将其视为异常。这是因为正常的例子倾向于有一个大的$p(x)$，而异常的例子倾向于有一个小的$p(x)$。</p><p>在状态监测的背景下，这很有趣，因为异常可以告诉我们被监测设备的“健康状态”：当设备接近故障时生成的数据，或次优操作，通常与“健康”设备的数据分布不同。</p><p><strong>The Mahalanobis distance</strong></p><p>如上所述，讨论数据点属于哪种分布的问题。第一步是找到采样点的质心或质心。直观地说，所讨论的点离这个质心越近，它就越有可能属于这个集合。然而，我们还需要知道集合是分布在大范围还是小范围，这样我们就可以决定距中心的给定距离是否值得注意。简单的方法是估计样本点到质心距离的标准偏差。通过将其插入正态分布，我们可以得出数据点属于同一分布的概率。</p><p>上述方法的缺点是，我们假设采样点以球形方式分布在质量中心周围。如果分布确定为非球形，例如椭球形，那么我们期望测试点属于集合的概率不仅取决于与质心的距离，而且取决于方向。在椭球体具有短轴的方向上，试验点必须更近，而在轴较长的方向上，试验点可以远离中心。在数学基础上，通过计算样本的协方差矩阵，可以估计出最能代表集合概率分布的椭球。<a href="https://en.wikipedia.org/wiki/Mahalanobis_distance" target="_blank" rel="noopener">Mahalanobis</a>距离（md）是测试点到质量中心的距离除以试验点方向上的椭球宽度。</p><p>为了使用MD将测试点分类为属于n个类中的一个类，首先要估计每个类的协方差矩阵，通常基于已知属于每个类的样本。在我们的例子中，由于我们只对“正常”与“异常”进行分类感兴趣，因此我们使用只包含正常操作条件的训练数据来计算协方差矩阵。然后，给出一个测试样本，将MD计算为“正常”类，如果距离超过某个阈值，则将测试点分类为“异常”。</p><p>注意：使用MD意味着可以通过均值和协方差矩阵-进行推断，这只是正态分布的一个性质。在我们的例子中，不一定满足这个标准，因为输入变量可能不是正态分布的。不过我们还是可以试试，看看效果如何！</p><h4 id="Approach-2-Artificial-Neural-Network"><a href="#Approach-2-Artificial-Neural-Network" class="headerlink" title="Approach 2: Artificial Neural Network"></a>Approach 2: Artificial Neural Network</h4><p><strong>Autoencoder networks</strong></p><p>第二种方法是使用<a href="https://en.wikipedia.org/wiki/Autoencoder" target="_blank" rel="noopener">自编码器神经网络</a>。这是基于与上述统计分析相似的原则，但有一些细微的差异。</p><p>自编码器是一种<a href="https://en.wikipedia.org/wiki/Artificial_neural_network" target="_blank" rel="noopener">人工神经网络</a>，用于无监督地学习有效的数据编码。自动编码器的目的是学习一组数据的表示（编码），通常用于<a href="https://en.wikipedia.org/wiki/Dimensionality_reduction" target="_blank" rel="noopener">降维</a>。与原边一起，学习重构边，其中自动编码器尝试从简约编码生成尽可能接近其原始输入的表示。</p><p>从结构上讲，AutoEncoder最简单的形式是一个前馈的、非重复性的神经网络，与许多单层感知器非常相似，多层感知器（MLP）具有一个输入层、一个输出层和一个或多个连接多层感知器的隐藏层-，但输出层具有相同数量的节点。作为输入层，目的是重建自己的输入。</p><p><img src="/assets/articleImg/2019/1-QjevZB4Qg5Su7ufVfZ4Rwg.jpeg" alt=""></p><div class="caption">Figure 2: Autoencoder network</div><p>在异常检测和状态监测的背景下，基本思想是使用自动编码器网络将传感器读数“压缩”到较低的尺寸表示，从而捕获各种变量之间的相关性和相互作用。（基本上与PCA模型的原理相同，但这里我们也考虑了变量之间的非线性相互作用）。</p><p>然后，自动编码器网络接受表示“正常”操作状态的数据的训练，其目标是首先压缩然后重建输入变量。在降维过程中，网络学习各种变量之间的相互作用，并能在输出端将它们重新构造回原来的变量。主要想法是，随着被监测设备的退化，这将影响变量之间的相互作用（例如温度、压力、振动等的变化）。当这种情况发生时，人们将开始看到网络重新构造输入变量的错误增加。通过监测重建误差，人们可以得到被监测设备的“健康”指示，因为这种误差会随着设备的退化而增加。与第一种使用Mahalanobis距离的方法类似，我们这里使用重建误差的概率分布来确定数据点是正常的还是异常的。</p><h3 id="Condition-monitoring-use-case-Gear-bearing-failure"><a href="#Condition-monitoring-use-case-Gear-bearing-failure" class="headerlink" title="Condition monitoring use-case: Gear bearing failure"></a>Condition monitoring use-case: Gear bearing failure</h3><p>在这一节中，我将使用上面描述的两种不同的方法，介绍一个用于状态监控的实际用例。由于我们与客户合作的大多数数据都不是公开的，我选择了展示NASA提供的两种数据方法，可以在<a href="http://data-acoustics.com/measurements/bearing-faults/bearing-4/" target="_blank" rel="noopener">这里</a>下载。</p><p>在此用例中，目标是检测发动机上的齿轮轴承退化，并发出警告，允许采取预测措施以避免齿轮故障（例如，设备的计划维护/维修）。</p><h4 id="Experimental-details-and-data-preparation"><a href="#Experimental-details-and-data-preparation" class="headerlink" title="Experimental details and data preparation:"></a>Experimental details and data preparation:</h4><p>三组数据分别由四个轴承组成，在恒负荷和运行条件下运行至失效。振动测量信号在轴承使用寿命期间提供给数据集，直至出现故障。在外座圈出现裂纹的1亿个循环后发生故障（有关实验的更多信息，请参阅下载页中的自述文件）。由设备一直运行直到出现故障，将前两天的运行数据当作训练数据，以代表正常和“健康”的设备。然后将导致轴承故障的时间的数据集的剩余部分用作测试数据，以评估不同的方法是否可以在故障之前检测轴承退化。</p><h4 id="Approach-1-PCA-Mahalanobis-distance"><a href="#Approach-1-PCA-Mahalanobis-distance" class="headerlink" title="Approach 1 : PCA + Mahalanobis distance"></a>Approach 1 : PCA + Mahalanobis distance</h4><p>正如本文“技术部分”中提及的那样，第一种方法是：首先进行主成分分析，然后计算马哈拉诺比距离（MD），以确定数据点是正常的或异常的（设备退化的迹象）。代表“健康”设备的训练数据的MD分布如下图所示。</p><p><img src="/assets/articleImg/2019/1-p-aQy4JuuQu9OsniN1PWwQ.jpeg" alt=""></p><div class="caption">Figure 3: Distribution of Mahalanobis distance for “healthy” equipment</div><p>利用“健康”设备的MD分布，我们可以定义一个考虑异常的阈值。根据上述分布，我们可以将MD&gt;3定义为异常。现在，这种检测设备退化的方法的评估包括计算测试集中所有数据点的MD，并将其与标记为异常的定义阈值进行比较。</p><p><strong>Model evaluation on test data:</strong></p><p>利用上述方法，我们计算了轴承失效前一段时间内试验数据的MD，如下图所示。</p><p><img src="/assets/articleImg/2019/1-gff6BQiMq-eClSXurOknTw.jpeg" alt=""></p><div class="caption">Figure 4: Predicting bearing failure using approach 1</div><p>在上图中，绿点对应于计算得出的MD，而红线代表用于标记异常的定义阈值。轴承故障发生在数据集的末尾，用黑色虚线表示。这说明，第一种建模方法能够在实际故障发生前3天（MD超过阈值）检测到即将发生的设备故障。</p><p>我们现在可以使用第二种建模方法进行类似的练习，以评估哪些方法的性能优于其他方法。</p><h4 id="Approach-2-Artificial-Neural-Network-1"><a href="#Approach-2-Artificial-Neural-Network-1" class="headerlink" title="Approach 2: Artificial Neural Network"></a>Approach 2: Artificial Neural Network</h4><p>如本文“技术部分”中更详细地解释的，第二种方法包括使用自动编码器神经网络来检测异常（通过增加网络的重建损失来识别）。与第一种方法类似，在这里我们使用代表“健康”设备的训练数据的模型输出分布来检测异常。训练数据重建损失（平均绝对误差）分布如下图所示：</p><p><img src="/assets/articleImg/2019/1-CQXfujCTvDfx5s6W37fWZA.jpeg" alt=""></p><div class="caption">Figure 5 : Distribution of reconstruction loss for “healthy” equipment.</div><p>利用“健康”设备重建损失的分布，我们现在可以定义一个考虑异常的阈值。根据上述分布，我们可以将大于0.25的损失定义为异常。设备退化检测方法的评估现在包括计算测试集中所有数据点的重建损失，并将损失与将其标记为异常的定义阈值进行比较。</p><p><strong>Model evaluation on test data:</strong></p><p>利用上述方法，我们计算了轴承失效前一段时间内试验数据的重建损失，如下图所示。</p><p><img src="/assets/articleImg/2019/1-YJqJifMAmGUFD83lbgdzaw.jpeg" alt=""></p><div class="caption">Figure 6: Predicting bearing failure using approach 2</div><p>在上图中，蓝色点对应重建损失，而红色线代表标记异常的定义阈值。轴承故障发生在数据集的末尾，用黑色虚线表示。这也说明，这种建模方法能够在实际故障发生前3天（重建损失超过阈值）检测到即将发生的设备故障。</p><h3 id="Results-summary"><a href="#Results-summary" class="headerlink" title="Results summary"></a>Results summary</h3><p>从以上两个不同的异常检测方法部分可以看出，这两种方法都能在实际故障发生前几天成功检测到即将发生的设备故障。在实际场景中，这将允许在故障发生之前采取预测措施（维护/维修），这意味着既节省了成本，又对设备故障的HSE方面具有潜在的重要性。</p><p>随着通过传感器捕获数据的成本降低，以及设备之间的连接增加，能够从数据中提取有价值的信息变得越来越重要。在大量数据中发现模式是机器学习和统计的领域，在我看来，利用这些数据中隐藏的信息来提高几个不同领域的性能有着很大的潜力。正如本文所述，异常检测和状态监测只是众多可能性之一。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近，在浏览towardsdatascience上面的机器学习相关文章的时候，无意间看到一篇关于异常检测的文章，刚好与自己的工作内容有点契合，文章讲解的是两种分析思路：第一种、PCA + Mahalanobis；第二种、AutoEncoder训练模型进行检测。兴奋之下，决定将这篇文章分享出来，如果内容有理解不当的地方，还请读者指出，深表感谢。&lt;/p&gt;
&lt;p&gt;原文链接： &lt;a href=&quot;https://towardsdatascience.com/how-to-use-machine-learning-for-anomaly-detection-and-condition-monitoring-6742f82900d7&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;How to use machine learning for anomaly detection and condition monitoring&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="深度学习" scheme="https://www.csuldw.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="异常检测" scheme="https://www.csuldw.com/tags/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/"/>
    
      <category term="AutoEncoder" scheme="https://www.csuldw.com/tags/AutoEncoder/"/>
    
  </entry>
  
  <entry>
    <title>2018，善待自己</title>
    <link href="https://www.csuldw.com/2018/12/31/2018-12-31-treat-yourself/"/>
    <id>https://www.csuldw.com/2018/12/31/2018-12-31-treat-yourself/</id>
    <published>2018-12-31T15:22:00.000Z</published>
    <updated>2020-04-15T15:04:59.687Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/assets/articleImg/2018/first.jpg" alt=""></p><div class="caption"></div><p>前阵子，丫姐说18年快过了，看你以前每年都写总结，今年的总结什么时候写，写完告诉我，我去看看！</p><p>的确，一年又要过了。从读研那年起，就开始写年总结，久而久之，便成了一种习惯。记得还是14年的时候，少不经事，懵懵懂懂，写的内容也是东拼西凑，词不尽意，流水般的记录下自己一年的“奇葩”经历，犹如游记一般。现如今，五年过去了，虽然这两年没怎么写博文，但年度总结终归还是不能落下，毕竟，过了今天，又是一年呢！</p><a id="more"></a><p>很多朋友偶尔都会问我，“你怎么那么忙，最近加班是不是特别多？”，“有没有时间，周末一起约一波吃个饭，很久没聚一聚了”，“你今年就跟消失了一样”，“你说话的风格都不一样了……”，而我的回答一直都是，“还好，不算多吧！”。现在回想起来，说实在的，上半年加班倒是比较多，有段时间，连续上班三个星期，确实有点累。只是想到还有人连续加班一个月，两个月，自己也就没什么可抱怨的。每个时间点，都有一些事情发生，而很多事情一经发生便成了过去。于我而言，记录一下自己一年之内的经历，哪些地方做的好，哪些地方做的不足，亦或是普普通通的事情，对自己也都有很大的帮助。</p><h3 id="六宗罪"><a href="#六宗罪" class="headerlink" title="六宗罪"></a>六宗罪</h3><p>先来说说这一年里自己的不足吧！</p><p>工作之后，时间真的开始不受控了。一方面源于自己的惰性；另一方面则是不妥当的时间安排。每天过的倒像是个大忙人，可真要静下来好好聊聊一年内做的事情，又感觉欠缺了点东西。木心曾说：“生活最好的状态是冷冷清清的风风火火”。我这种状态，应该是风风火火的冷冷清清吧~(#^.^#)。当你开始回忆过去一年内发生的事情的时候，很多的画面都会不受控的浮现于脑海里，有些脱口能出，有些却道不出口。</p><ul><li>第一、<strong>缺乏运动</strong>。今年锻炼的很少，以至于在年底体检的时候，心里也是有些惶恐。对于一个在今年体重达到十年内最轻的我来说，体脂率自认为是不会超标的。体检完之后，让自己比较担心的居然是脊椎。医生说平时不要一直坐着，多动动，脊椎有点伸直的趋势。我猜应该是工作的时候，看电脑看多了，或是晚上玩手机，姿势不对，玩的太久入了。</li><li>第二、<strong>没有坚持写博文</strong>。既然是总结，便不能给自己找借口，今年确实是懒惰了许多！以前在学校，即使是周末，早上八点之前基本都会起床。现在，周末于我而言，最大的幸福就是睡一个懒觉了。可能跟自己的作息也有些关系，周一到周五，每天需要七点起来，以至于到周末的时候，就想睡得踏实一些。</li><li>第三、<strong>优柔寡断</strong>。以前大学的时候，室友就说我有一个缺点，也就是优容寡断，做事不果断。“斩不断，理还乱，是离愁，别是一番滋味在心头！”，2018已经过去，新年伊始，愿前路不要过于狼狈就行，希望处事得当一些。</li><li>第四、<strong>逃避</strong>。出于人类的本能，对于那些不利于自己的事，或许会本能的逃避它，会自然而然的选择避开它。而我，也是大千世界中普普通通的一员，“逃避”也成了自己的一个缺点。只希望在2019年，能够将2018年不快乐的事情抛于脑后，能尘封的就埋藏起来吧！</li><li>第五、<strong>读书略少</strong>。“读史使人明智，读诗使人灵秀”。学习可以提升一个人的内涵，可以增加人的知识面，可以让自己在谈吐中，引起别人的注意。在我的书库里，技术类的书籍应该占据了90%左右，后续得稍微改变一下这个现状，增加一些文史类的书籍。</li><li>第六、<strong>心性轻微浮躁</strong>。“往事不堪回首月明中”，渐渐的开始发现，浮躁的并不是周围的事物，而是自己。当你还有一颗不甘心、不认命、不满足于现状的心理，你就会想尽一切办法来改变自己，提升自己，亦或是改变自己所处的环境。每个人都会碰到烦心的事儿，只是每个人的处理方式不一样罢了。而我，习惯于将这些事情埋藏心底，久而久之，或许就酝酿出了另一种味道。静下来，做点想做的事情，专注于事业和学习，不是纸上谈兵，也不能只是给自己“画饼”，！</li></ul><p>《致自己》歌词里有这样一段话：</p><center><p>人生就像一场旅行…<br>繁华之后终将还要独行<br>纷纷扰扰没有谁能够说得清<br>别让遗憾成为我们的曾经</p><!-- 在我们哭的笑的累的岁月里我们是否该好好珍惜自己 --></center><blockquote><p>你的时间有限，不要浪费于重复别人的生活，不要让别人的观点淹没了你内心的声音。</p></blockquote><p>善待自己，多考虑下自己，尽量不要太在意别人的看法。</p><h3 id="睡眠"><a href="#睡眠" class="headerlink" title="睡眠"></a>睡眠</h3><p>先来看看每个月的平均睡眠曲线，</p><p><img src="/assets/articleImg/2018/sleep_line.png" alt=""></p><div class="caption">『来自iPhone的Sleep数据统计曲线』</div><p>相比去年，今年的睡眠时间是在慢慢地变少了，从去年的7~8小时左右逐渐的降到6小时左右。这种晚睡习惯，也不是一两天就能养成的，经历的越多，心里装的事情也就多了起来。记得大学的时候，就跟文静姐说过，让她不要老熬夜，对身体不好。当时的她让我不要跟她学，能够早睡就早点睡。现如今，差不多也是她当时的年纪，感觉已经跟她一样了。以前看到过这样一段话：</p><center><p>直到后来才发现，<br>熬夜是缓解压力的一种方式。<br>爸妈都睡了，老师都睡了；<br>喜欢的人也睡了，全世界都睡了；<br>不用再去担心什么事情了。<br>用这好不容易偷来的时光，赶紧做点自己喜欢的。</p></center><p>看起来就这几句话，字里行间却道出了大多数熬夜者的内心告白。大一大二的时候，基本上都是晚间十点多睡觉，偶尔也会听着午夜电台听到十二点。由于要上早自习，所以每天六点多就起床，还要挨个宿舍的叫同学起来。突然回想起来，还挺还念的。很多朋友都说我要成熟很多，或许是在他们面前，我表现的沉默寡言一点，又或许是自己做事情对自己要求略高一点吧！</p><h3 id="业余生活"><a href="#业余生活" class="headerlink" title="业余生活"></a>业余生活</h3><p>业余时间里，刷微博的次数变少了，朋友圈的消息基本也不看了！这些攒下来的时间，开始了新的生活，音乐和吉他。</p><ul><li>音乐与吉他</li></ul><p>喜欢民谣，喜欢安静的旋律，喜欢它节奏缓慢的音调，喜欢每一首歌背后的故事。“初闻不知曲中意，再听已是曲中人”，大概就是这个道理。对于朴树、赵雷、许巍、宋冬野的歌，最喜欢的便是赵雷了。因为喜欢民谣，所以在七月的时候，脑门子一热买了一把民谣吉他。刚开始练习的时候，有些懵懂，云里雾里般，一个星期没到，手就开始起茧。业余时间练习指法、和弦、试着弹奏简单的曲谱，也算是培养一门业余爱好了。因为听歌，也衍生出自己唱歌的欲望，闲暇之际，去APP里录了几首歌，不料被同学看到，将我录得歌一首首发到群里，真是让人哭笑不得。</p><p><img src="/assets/articleImg/2018/2018-12-31-2.jpg" alt=""></p><div class="caption">『一时的心血来潮，还是打个码』</div><p>2019年，争取早点弹奏一首完整的歌(#^.^#)。</p><ul><li>闲来游戏笑语焉</li></ul><p>说实在的，游戏并非我的兴趣爱好，只不过自己有一份上王者的执着，业余时间里也就跟着一起凑凑热闹。在王者荣耀里面，最喜欢玩的位置便是刺客。独来独往，关键是可以带动节奏，成就感十足哇！最开始喜欢玩法师王昭君，后来转型刺客之后就以兰陵王为主，然后喜欢玩娜可露露（第一次五杀就靠她），再后来开始玩猴子。自从五月份用猴子上了王者之后，也就没再完了。自从上了王者之后，也就没再完了。一是越来越觉得没意思；二是因为自己时间精力有限。以前玩得多，是因为跟同学一起，五连排，输了就互怼一顿，赢了就继续浪，图的就是一个乐字嘛，开心就好~后来，大家都陆续不玩了，也就没那个心思了，真是可怜我那几个皮肤了。</p><p><img src="/assets/articleImg/2018/2018-12-31-3.png" alt=""></p><div class="caption">『一次没有老王的五连排（沛公、昊子、曹、亮亮）』</div><blockquote><p>世界上最永恒的幸福就是平凡，人生中最长久的拥有就是珍惜。</p></blockquote><h3 id="不能游山，但可玩水"><a href="#不能游山，但可玩水" class="headerlink" title="不能游山，但可玩水"></a>不能游山，但可玩水</h3><p>每天都在为琐碎的事情奔波，无论是work、学习、还是感情上，或多或少都会让人疲惫，有时候，甚至会有一种远离深圳的冲动。所以说，适当的周边出行，也会有一种沁人心脾的感觉。真的很怀念16年的时候，不仅充实，更是踏实。今年可以说是是最宅的一年了，除了回家，仅仅出去完了一次，也就是双月湾，也是成本最高的一次。</p><ul><li>行走在暴风雨下的双月湾</li></ul><p>八月上旬的时候，跟同学、师弟、师妹一起去了一次双月湾。七月底的时候，群里就开始讨论八月去双月湾，一开始以为自己要加班，就没有答应去，哪知他们直接把我算上了。到了要去的那周，想着既然不需要加班，一直待在住的地方也不合适，应该多走动走动，于是便同意了。周六清晨出发，周日下午便回深，整个历程虽然很赶，甚至天气还是暴雨连连，但是整个人的还是挺放松的。十个人，两个两室一厅的套房，从白天玩到了深夜一两点，四个大男人睡一个卧室，凑在两张床上😃 ，<del>~</del>真是历来罕见哇。</p><p><img src="/assets/articleImg/2018/2018-12-31-4.jpg" alt=""></p><div class="caption">『双月湾—暴风雨下的沙滩』</div><p>海滩上的一搜大破船，不经意间却成了一道风景。</p><p><img src="/assets/articleImg/2018/2018-12-31-8.png" alt=""></p><div class="caption">『双月湾-周边』</div><p>印象里周六那天，早上到双月湾的时候已经是狂风暴雨了，打伞的时候会感觉伞四处飘动。因为肚子空空，只能在附近的小店吃了一碗粉，味道一般，算是凑合着吧！</p><h3 id="居住环境"><a href="#居住环境" class="headerlink" title="居住环境"></a>居住环境</h3><p>以前，心里面想的是，一天也就住的时候待在宿舍，对住所的要求便是无所谓。现在，思想有所改观，想着每天累了一整天的，回来能够有个好的住处，也是蛮幸福、蛮开心的事了。今年一共搬了两次住所，第一次搬家，是因为原居住环境不仅潮湿，而且光线太暗，虽然是一室一厅，长时间下去对身体不好。于是搬进了一个单间公寓里面，这间房子靠近外面的车道，房内也太小了，待在里面会有些压抑，尤其是到周末的时候。后来，便开始了合租生活，虽然房租比以前稍多，但是空间大很多，总的来说也算舒适。</p><h3 id="运动"><a href="#运动" class="headerlink" title="运动"></a>运动</h3><p>某天早上，知乎上推出来了一个msg，title是：「人类身体从二十五岁就开始走下坡路」的说法是否有科学依据？</p><p>顺着各位答主的回答，看到一个百度百科：<a href="https://baike.baidu.com/item/%E4%BA%BA%E4%BD%93%E5%99%A8%E5%AE%98%E8%A1%B0%E8%80%81%E6%97%B6%E9%97%B4%E8%A1%A8/5813507" target="_blank" rel="noopener">人体器官衰老时间表</a>。下面这段话摘自百科：</p><blockquote><p>人体衰老退化时间表，英国研究人员确认了人体一些器官的衰老退化时间， 肺活量从20岁起开始缓慢下降，到了40岁一些人就出现气喘吁吁的状况；大脑从20岁起开始逐年下降，到了40岁神经细胞的数量开始以每天1万个的速度递减；女人到了35岁乳房的组织和脂肪开始丧失，大小和丰满度因此下降；70岁才会变老的肝脏似乎是体内唯一能挑战老化进程的器官。</p></blockquote><p>知乎回答的内容里面有一句话比较有意思，大致就是：人的最后发育阶段也就是20多岁。过了这个最后发育点，就等于大自然跟你讲：身体该长的都给你长完了，你拿去折腾吧。就像一辆组装完毕出厂的新车，之后不管你怎么保养，也恢复不到刚出厂时的崭新程度了，从这个意义上讲，那肯定就是走下坡路了。但是，众所周知，车子性能最佳的时候，肯定不是刚出厂。体育锻炼就是人类的磨合技巧。养生之道就是人类的保养技巧。下坡路怎么走，能走多远，还得看各人。</p><p>是的，下坡怎么走，能走多远，还得看各自。就拿自己来说，大学的时候视力还是很突出的，从入大学的时候是双5.2，毕业后的时候是5.1与5.2。自从进入研究生，视力就开始降了，去北京前体检的时候已经是5.0和4.8了，现在应该是更低了。平时看电脑，玩手机，没注意好，真是惭愧~</p><p>前两天，昊子给我发了个链接，又一个因为工作加班过多离世的人，留下了一家子老小，真是让人深思、惋惜！看着现在的自己，每天晚上也只是做40来个俯卧撑，小小的锻炼一下！2019年，争取周末好好锻炼，有时间就去小区跑个4-5km，尽量保留自己多年来留存的腹肌吧~^_^，毕竟未来还是属于身体好的！健康的活着，就是最大的幸福了。</p><h3 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h3><p>“莫等闲，白了少年头，空悲切”，学习，可以说是每年必不可少的环节。今年的学习，主要集中在专业能力上。由于上半年的工作比较分散，码代码、分布式部署、搭建自动部署平台等，业余的时候只能自我折腾DL。下半年，由于工作内容的切换，学习也慢慢步入了正轨。</p><ol><li>NLP：jieba、n-gram、bag-of-words、skip-gram、word2vector、word embedding、sentiment analysis、bert、etc</li><li>Deep Learning：DNN、RNN、LSTM、GRU、etc</li><li>Machine Learning：xgboost、gbdt、svm、random forest、adaboost、LR、k-means、isolation forest、etc</li><li>Recommendation System：item-based CF、user-based CF、user-based embedding、item-based embedding、FM、etc</li><li>Other：包括方案设计，架构，沟通能力等.</li></ol><p>对我来说，ML、NLP、DL以及 RS，又开始了新的旅途。前路遥远不可知，具体还有多少坑，只有踩过才知道，能够造多少个轮子，就看自己接下来的精力了。对于理论学习，每温故一次，都会有新的想法，产生新的理解。而新的知识，也会通过相互关联将两者联想到一起。以前对NLP接触的不多，很长时间都停留在Word2vector阶段，今年通过比赛，对word-Embedding有了新的实践。本来想在19年前写一篇word2vector与word-embedding的总结，时间紧凑，日程没安排好，等过段时间再写吧！前不久，Google Bert 一出，震撼了nlp的各大业界。看到BERT刷新了如此多的记录，本想用来玩一玩，可惜没有一台好的服务器够自己折腾，无奈……╮(╯▽╰)╭。</p><p>今年在GitHub上提交的代码不多，看到以前的两个项目在不断的被关注，甚是开心：</p><ul><li><a href="https://github.com/csuldw/MachineLearning" target="_blank" rel="noopener">MachineLearning</a>：机器学习相关算法，<code>454</code>个star和<code>432</code>个fork，后续有新的内容持续往里面添加;</li><li><a href="https://github.com/csuldw/WSpider" target="_blank" rel="noopener">WSpider</a>: 以前编写的sina爬虫项目，<code>104</code>个star，<code>53</code>个fork，现在也许不适用了，仅供参考。</li></ul><p>工作上的内容，由于保密性，当然是不能上传的，所以只能业余时间自己折腾些其他的了。</p><h3 id="计划"><a href="#计划" class="headerlink" title="计划"></a>计划</h3><p>面对在即将到来的2019年，希望能够做到下面六点：</p><ol><li>每月至少一篇高质量博文；</li><li>练习吉他，能够达到solo效果；</li><li>一场轻松的旅行；</li><li>坚持锻炼，每周坚持跑步；</li><li>每天坚持一道算法题，锻炼思维；</li><li>维护一个公众号，例行发文。</li></ol><p>2019年，一切又从零开始。不乱于心，不困于情，不畏将来，不念过去，平静，便好！相信前方一定会有另一番不同的风景，善待自己！祝大家新年快乐，元旦快乐！</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/assets/articleImg/2018/first.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;&lt;/div&gt;

&lt;p&gt;前阵子，丫姐说18年快过了，看你以前每年都写总结，今年的总结什么时候写，写完告诉我，我去看看！&lt;/p&gt;
&lt;p&gt;的确，一年又要过了。从读研那年起，就开始写年总结，久而久之，便成了一种习惯。记得还是14年的时候，少不经事，懵懵懂懂，写的内容也是东拼西凑，词不尽意，流水般的记录下自己一年的“奇葩”经历，犹如游记一般。现如今，五年过去了，虽然这两年没怎么写博文，但年度总结终归还是不能落下，毕竟，过了今天，又是一年呢！&lt;/p&gt;
    
    </summary>
    
      <category term="年度总结" scheme="https://www.csuldw.com/categories/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="总结" scheme="https://www.csuldw.com/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>Batch Normalization(Paper 解读)</title>
    <link href="https://www.csuldw.com/2018/07/16/2018-07-16-BN/"/>
    <id>https://www.csuldw.com/2018/07/16/2018-07-16-BN/</id>
    <published>2018-07-15T16:31:00.000Z</published>
    <updated>2019-03-10T13:22:32.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文主要针对<a href="https://arxiv.org/pdf/1502.03167.pdf" target="_blank" rel="noopener">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>进行翻译，参考了<a href="https://www.jianshu.com/p/14f4eae76a19" target="_blank" rel="noopener">Batch Normalization论文翻译——中文版</a>一文，正文内容部分进行了修改，主要是格式上进行了调整，方便后续阅读。如有侵权还请联系博主删除博文，感谢！</p><a id="more"></a><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>训练深度神经网络的复杂性在于，每层输入的分布在训练过程中会发生变化，因为前面的层的参数会发生变化。通过要求较低的学习率和仔细的参数初始化减慢了训练，并且使具有饱和非线性的模型训练起来非常困难。我们将这种现象称为internal covariate shift，并通过标准化层输入来解决这个问题。我们的方法力图使标准化成为模型架构的一部分，并为每个训练小批量数据执行标准化。批标准化使我们能够使用更高的学习率，并且不用太注意初始化。它也作为一个正则化项，在某些情况下不需要Dropout。将批量标准化应用到最先进的图像分类模型上，批标准化在取得相同的精度的情况下，减少了14倍的训练步骤，并以显著的差距击败了原始模型。使用批标准化网络的组合，我们改进了在ImageNet分类上公布的最佳结果：达到了4.9％ top-5的验证误差（和4.8％测试误差），超过了人类评估者的准确性。</p><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><p>深度学习在视觉、语音等诸多方面显著提高了现有技术的水平。随机梯度下降（SGD）已经被证明是训练深度网络的有效方式，并且已经使用诸如动量（Sutskever等，2013）和Adagrad（Duchi等人，2011）等SGD变种取得了最先进的性能。SGD优化网络参数$\Theta$，以最小化损失</p><p>$$\Theta = \arg \min_\Theta \frac{1}{N}\sum_{i=1}^N \ell(x_i, \Theta)$$</p><p>其中$x_{1\ldots N}$是训练数据集。使用SGD，训练将逐步进行，在每一步中，我们考虑一个大小为$m$的小批量数据$x_{1 \ldots m}$。通过计算$\frac {1} {m} \sum _{i=1} ^m \frac {\partial \ell(x_i, \Theta)} {\partial \Theta}$，使用小批量数据来近似损失函数关于参数的梯度。使用小批量样本，而不是一次一个样本，在一些方面是有帮助的。首先，小批量数据的梯度损失是训练集上的梯度估计，其质量随着批量增加而改善。第二，由于现代计算平台提供的并行性，对一个批次的计算比单个样本计算$m$次效率更高。</p><p>虽然SGD简单有效，但它需要仔细调整模型的hyper-parameters，特别是优化中使用的learning rate以及模型参数的 initial values。训练的复杂性在于每层的输入受到前面所有层的参数的影响——因此当网络变得更深时，网络参数的微小变化就会被放大。</p><p>由于这些层需要不断适应新的分布，致使各层输入的分布变化成为一大问题。当学习系统的输入分布发生变化时，会导致covariate shift（Shimodaira，2000）。通常是通过domain adaptation（Jiang，2008）来处理。然而，covariate shift的概念可以扩展到整个学习系统之外，应用到学习系统的一部分，例如子网络或某一层。考虑下面这个网络计算：</p><p>$$\ell = F_2(F_1(u, \Theta_1), \Theta_2)$$ </p><p>其中$F_1$和$F_2$可以任意变换，参数$\Theta_1，\Theta_2$通过以便最小化损失$\ell$学习得到。$\Theta_2$的学习可以看作将$x=F_1(u,\Theta_1)$作为输入送到子网络</p><p>$$\ell = F_2(x, \Theta_2)。$$</p><p>例如，梯度下降步骤</p><p>$$<br>\Theta_2\leftarrow \Theta_2 - \frac {\alpha} {m} \sum_{i=1}^m \frac {\partial F_2(x_i,\Theta_2)} {\partial \Theta_2}<br>$$</p><p>（对于batch size $m$和学习率$\alpha$）与输入为$x$的单独网络$F_2$完全等价。因此，输入分布特性使训练更有效——例如训练数据和测试数据之间有相同的分布——也适用于训练子网络。因此$x$的分布在时间上保持固定是有利的。然后，$\Theta_2$不必重新调整来补偿$x$分布的变化。</p><p>子网络输入的固定分布对于子网络外的层也有积极的影响。考虑一个激活函数为$g(x) = \frac{1}{1+\exp(-x)}$的层，$u$是输入层，权重矩阵$W$和偏置向量$b$是层参数，$g(x) = \frac{1}{1+\exp(-x)}$。随着$|x|$的增加，$g’(x)$趋向于0。这意味着对于$x=Wu+b$的所有维度，除了那些具有小的绝对值之外，流向$u$的梯度将会消失，模型将缓慢的进行训练。然而，由于$x$受$W,b$和下面所有层的参数的影响，训练期间那些参数的改变可能会将$x$的许多维度移动到非线性的饱和状态并减慢收敛的速度。这个影响随着网络深度的增加而被逐步放大。在实践中，饱和问题和由此产生的vanishing gradients通常可以使用Rectified Linear Units(Nair &amp; Hinton, 2010) $ReLU(x)=\max(x,0)$、适当的初始化(Bengio &amp; Glorot, 2010; Saxe et al., 2013)或者小的学习率来解决。然而，如果我们能保证非线性输入的分布在网络训练时保持更稳定，那么优化器将不太可能陷入饱和状态，训练也将得到加速。</p><p>我们把训练过程中深度网络内部结点的分布变化称为Internal Covariate Shift。消除它可以保证更快的训练。我们提出了一种新的机制，我们称为为Batch Normalization，它是减少internal covariate shift的一个步骤，这样做可以显著加速深度神经网络的训练。它通过标准化步骤来实现，标准化步骤修正了输入层的均值和方差。Batch Normalization减少了梯度对参数或它们的初始化的依赖，对通过网络的梯度流动大有裨益。这允许我们使用更高的学习率而没有发散的风险。此外，Batch Normalization对模型进行了正则化并减少了模型对Dropout(Srivastava et al., 2014)的依赖。最后，Batch Normalization通过阻止网络陷入饱和模式让使用饱和非线性成为可能。</p><p>在4.2小节，我们将BN应用到性能最好的ImageNet分类网络上，并且表明我们可以使用仅7％的训练步骤来匹配其性能，并且可以进一步超过其准确性一大截。通过使用批标准化训练的网络的集合，我们取得了top-5错误率，其改进了ImageNet分类上已知的最佳结果。</p><h2 id="2-Towards-Reducing-Internal-Covariate-Shift"><a href="#2-Towards-Reducing-Internal-Covariate-Shift" class="headerlink" title="2. Towards Reducing Internal Covariate Shift"></a>2. Towards Reducing Internal Covariate Shift</h2><p>由于训练过程中网络参数的变化，我们将Internal Covariate Shift定义为网络激活层分布的变化。为了改善训练，我们寻求减少Internal Covariate Shift。随着训练的进行，通过固定层输入$x$的分布，我们期望提高训练速度。众所周知(LeCun et al., 1998b; Wiesler &amp; Ney, 2011)如果对网络的输入进行白化，网络训练将会收敛的更快——即输入线性变换为具有零均值和单位方差，并去相关。当每一层观察下面的层（上一层）产生的输入时，实现每一层输入进行相同的白化将是有利的。通过白化每一层的输入，我们将采取措施实现输入层的分布固定，消除Internal Covariate Shift的不良影响。</p><p>我们考虑在每个训练步骤或在某些间隔来白化激活值，通过直接修改网络或根据网络激活值来更改优化方法的参数(Wiesler et al., 2014; Raiko et al., 2012; Povey et al., 2014; Desjardins &amp; Kavukcuoglu)。然而，如果这些修改分散在优化步骤中，那么梯度下降步骤可能会试图以要求标准化进行更新的方式来更新参数，这会降低梯度下降步骤的影响。例如，考虑一个层，其输入$u$加上学习到的偏置$b$，通过减去在训练集上计算的激活值的均值对结果进行归一化：$\hat x=x - E[x]$，$x = u+b$, $X={x_{1\ldots N}}$是训练集上$x$值的集合，$E[x] = \frac{1}{N}\sum_{i=1}^N x_i$。如果梯度下降步骤忽略了$E[x]$对$b$的依赖，那它将更新$b\leftarrow b+\Delta b$，其中$\Delta b\propto -\partial{\ell}/\partial{\hat x}$。然后$u+(b+\Delta b) -E[u+(b+\Delta b)] = u+b-E[u+b]$。因此，结合$b$的更新和接下来标准化中的改变会导致层的输出和损失都没有变化。随着训练的继续，$b$将无限增长而损失保持不变。如果标准化过程不仅对激活值进行中心化，还进行了缩放，那么问题会变得更糟糕。我们在最初的实验中已经观察到了这一点，当标准化参数在梯度下降步骤之外计算时，模型会爆炸。</p><p>上述方法存在的问题是梯度下降优化没有考虑到标准化引起的问题。为了解决这个问题，我们希望确保对于任何参数值，网络总是能够产生所需分布的激活值。这样可以使用模型参数损失的梯度来解释标准化，以及它对模型参数$\Theta$的依赖。设$x$为层的输入，将其看作向量，$\cal X$是这些输入在训练集上的集合。标准化可以写为变换</p><p>$$\hat x=Norm(x, \cal X)$$</p><p>它不仅依赖于给定的训练样本$x$，而且依赖于所有样本$\cal X$——如果$x$是由另一层生成，那么它们每一个都依赖$\Theta$，。对于反向传播，我们将需要计算Jacobians<br>$$<br>\frac {\partial Norm(x,\cal X)} {\partial x} and \frac {\partial Norm(x,\cal X)} {\partial \cal X}<br>$$</p><p>忽略后一项会导致上面描述的模型爆炸。在这个框架中，对层输入进行白化的代价是非常大的，因为它要求计算协方差矩阵$Cov[x]=E_{x\in \cal X}[x x^T]- E[x]E[x]T$和它的平方根倒数，从而生成白化的激活$Cov[x]{-1/2}(x-E[x])$和这些变换进行反向传播的偏导数。这促使我们寻求一种替代方案，以可微分的方式执行输入标准化，并且在每次参数更新后不需要对整个训练集进行分析。</p><p>以前的一些方法（例如（Lyu＆Simoncelli，2008））使用通过单个训练样本计算的统计信息，或者在图像网络的情况下，使用给定位置处不同特征图上的统计。然而，通过丢弃激活值绝对尺度改变了网络的表示能力。我们希望通过对相对于整个训练数据统计信息的单个训练样本的激活值进行归一化来保留网络中的信息。</p><h2 id="3-通过Mini-Batch统计进行标准化"><a href="#3-通过Mini-Batch统计进行标准化" class="headerlink" title="3. 通过Mini-Batch统计进行标准化"></a>3. 通过Mini-Batch统计进行标准化</h2><p>由于对每层输入的整个白化的代价非常昂贵，而且并不是处处可微的，因此我们做了两个必要的简化。首先是我们将单独标准化每个标量特征，从而代替在层输入输出对特征进行共同白化，使其具有零均值和单位方差。对于具有$d$维输入$x = (x^{(1)}\ldots x^{(d)})$的层，我们将标准化每一维</p><p>$$\hat x^{(k)} = \frac{x^{(k)} - E[x^{(k)}]} {\sqrt {Var[x^{(k)}]}}$$</p><p>其中期望和方差在整个训练数据集上计算。如(LeCun et al., 1998b)中所示，这种标准化加速了收敛，即使特征没有去除相关性。</p><p>注意到对层输入的简单标准化可能会改变层的表示。例如，标准化sigmoid的输入会将它们约束到非线性的线性状态。为了解决这个问题，我们要确保<strong>插入到网络中的变换可以表示恒等变换</strong>。为了实现这个，对于每一个激活值$x{(k)}$，我们引入成对的参数$\gamma{(k)}，\beta{(k)}$，它们会归一化和移动标准化值：</p><p>$$y{(k)} = \gamma^{(k)}\hat x^{(k)} + \beta{(k)}.$$</p><p>这些参数与原始的模型参数一起学习，并恢复网络的表示能力。实际上，通过设置$\gamma{(k)} = \sqrt{Var[x{(k)}]}$和$\beta{(k)} = E[x^{(k)}]$，我们可以重新获得原始的激活值，如果这是要做的最优的事。</p><p>每个训练步骤的批处理设置是基于整个训练集的，我们将使用整个训练集来标准化激活值。然而，当使用随机优化时，这是不切实际的。因此，我们做了第二个简化：<strong>由于我们在随机梯度训练中使用小批量，每个小批量产生每次激活平均值和方差的估计</strong>。这样，用于标准化的统计信息可以完全参与梯度反向传播。注意，通过计算每一维的方差而不是联合协方差，可以实现小批量的使用；在联合情况下，将需要正则化，因为小批量大小可能小于白化的激活值的数量，从而导致单个协方差矩阵。</p><p>考虑一个大小为$m$的小批量数据$\cal B$。由于标准化被单独地应用于每一个激活，所以让我们集中在一个特定的激活$x^{(k)}$，而忽略$k$。在小批量数据里我们有这个激活的$m$个值，</p><p>$$\cal B=\lbrace x_{1\ldots m} \rbrace.$$</p><p>设标准化值为$\hat x_{1\ldots m}$，它们的线性变换为$y_{1\ldots m}$。我们把变换</p><p>$$BN_{\gamma,\beta}: x_{1\ldots m}\rightarrow y_{1\ldots m}$$</p><p>看作批标准化变换。我们在算法1中提出了BN变换。在算法中，为了数值稳定，$\epsilon$是一个加到小批量数据方差上的常量。</p><p><img src="/assets/articleImg/bn-alg-1.png" alt="Algorithm 1"></p><p>BN变换可以添加到网络上来操纵任何激活。在公式$y = BN_{\gamma,\beta}(x)$中，我们指出参数$\gamma$和$\beta$需要进行学习，但应该注意到在每一个训练样本中BN变换不单独处理激活。相反，$BN_{\gamma,\beta}(x)$取决于训练样本和小批量数据中的其它样本。缩放和移动的值$y$被传递到其它网络层。标准化的激活值$\hat x$在我们的变换内部，但它们的存在至关重要。只要每个小批量的元素从相同的分布中进行采样，如果我们忽略$\epsilon$，那么任何$\hat x$值的分布都具有期望为$0$，方差为$1$。这可以通过观察$\sum_{i=1}^m \hat x_i = 0$和$\frac {1} {m} \sum_{i=1}^m \hat x_i^2 = 1$得到，并取得预期。每一个标准化的激活值$\hat x{(k)}$可以看作由线性变换$y{(k)}=\gamma^{(k)}\hat x{(k)}+\beta{(k)}$组成的子网络的输入，接下来是原始网络的其它处理。所有的这些子网络输入都有固定的均值和方差，尽管这些标准化的$\hat x^{(k)}$的联合分布可能在训练过程中改变，但我们预计标准化输入的引入会加速子网络的训练，从而加速整个网络的训练。</p><p>在训练过程中我们需要通过这个变换反向传播损失$\ell$的梯度，以及计算关于BN变换参数的梯度。我们使用的链式法则如下（简化之前）：</p><p>$$<br>\begin {align}<br>&amp;\frac {\partial \ell}{\partial \hat x_i} = \frac {\partial \ell} {\partial y_i} \cdot \gamma\\<br>&amp;\frac {\partial \ell}{\partial \sigma_\cal B^2} = \sum_{i=1}^m \frac {\partial \ell}{\partial \hat x_i}\cdot(x_i-\mu_\cal B)\cdot \frac {-1}{2}(\sigma_\cal B2+\epsilon){-3/2}\\<br>&amp;\frac {\partial \ell}{\partial \mu_\cal B} = \sum_{i=1}^m \frac {\partial \ell}{\partial \hat x_i}\cdot \frac {-1} {\sqrt {\sigma_\cal B^2 + \epsilon}}\\<br>&amp;\frac {\partial \ell}{\partial x_i} = \sum_{i=1}^m \frac {\partial \ell}{\partial \hat x_i} \cdot \frac {-1} {\sqrt {\sigma_\cal B^2 + \epsilon}} + \frac {\partial \ell}{\partial \sigma_\cal B^2} \cdot \frac {2(x_i - \mu_\cal B)} {m} + \frac {\partial \ell} {\partial \mu_\cal B} \cdot \frac {1} {m}\\<br>&amp;\frac {\partial \ell}{\partial \gamma} = \sum_{i=1}^m \frac {\partial \ell}{\partial y_i} \cdot \hat x_i \\<br>&amp;\frac {\partial \ell}{\partial \beta} = \sum_{i=1}^m \frac {\partial \ell}{\partial y_i}<br>\end{align}<br>$$</p><p>因此，BN变换是将标准化激活引入到网络中的可微变换。这确保了在模型训练时，层可以继续学习输入分布，表现出更少的internal covariate shift，从而加快训练。此外，应用于这些标准化的激活上的学习到的仿射变换允许BN变换表示恒等变换并保留网络的能力。</p><h3 id="3-1-Training-and-Inference-with-Batch-Normalized-Networks"><a href="#3-1-Training-and-Inference-with-Batch-Normalized-Networks" class="headerlink" title="3.1 Training and Inference with Batch-Normalized Networks"></a>3.1 Training and Inference with Batch-Normalized Networks</h3><p>为了批标准化一个网络，根据算法1，我们指定一个激活的子集，然后在每一个激活中插入BN变换。任何以前接收$x$作为输入的层现在接收$BN(x)$作为输入。采用批标准化的模型可以使用批梯度下降，或者用小批量数据大小为$m&gt;1$的SGD，或使用它的任何变种例如Adagrad (Duchi et al., 2011)进行训练。依赖小批量数据的激活值的标准化可以有效地训练，但在推断过程中是不必要的也是不需要的；我们希望输出只确定性地取决于输入。为此，一旦网络训练完成，我们使用总体统计来进行标准化</p><p>$$\hat x=\frac {x - E[x]} {\sqrt{Var[x] + \epsilon}}$$</p><p>而不是小批量数据统计。跟训练过程中一样，如果忽略$\epsilon$，这些标准化的激活具有相同的均值0和方差1。我们使用无偏方差估计$Var[x] = \frac {m} {m-1} \cdot E_\cal B[\sigma_\cal B^2]$，其中期望是在大小为$m$的小批量训练数据上得到的，$\sigma_\cal B^2$是其样本方差。使用这些值移动平均，我们在训练过程中可以跟踪模型的准确性。由于均值和方差在推断时是固定的，因此标准化是应用到每一个激活上的简单线性变换。它可以进一步由缩放$\gamma$和转移$\beta$组成，以产生代替$BN(x)$的单线性变换。算法2总结了训练批标准化网络的过程。</p><p><img src="/assets/articleImg/bn-alg-2.png" alt="Algorithm 2"></p><h3 id="3-2-Batch-Normalized-Convolutional-Networks"><a href="#3-2-Batch-Normalized-Convolutional-Networks" class="headerlink" title="3.2. Batch-Normalized Convolutional Networks"></a>3.2. Batch-Normalized Convolutional Networks</h3><p>批标准化可以应用于网络的任何激活集合。这里我们专注于仿射变换和元素级非线性组成的变换：</p><p>$$z = g(Wu+b)$$ </p><p>其中$W$和$b$是模型学习的参数，$g(\cdot)$是非线性例如sigmoid或ReLU。这个公式涵盖了全连接层和卷积层。我们在非线性之前通过标准化$x=Wu+b$加入BN变换。我们也可以标准化层输入$u$，但由于$u$可能是另一个非线性的输出，它的分布形状可能在训练过程中改变，并且限制其一阶矩或二阶矩不能消除covariate shift。相比之下，$Wu+b$更可能具有对称，非稀疏分布，即“更高斯”（Hyvärinen＆Oja，2000）；对其标准化可能产生具有稳定分布的激活。</p><p>注意，由于我们对$Wu+b$进行标准化，偏置$b$可以忽略，因为它的效应将会被后面的中心化取消（偏置的作用会归入到算法1的$\beta$）。因此，$z = g(Wu+b)$被$$z = g(BN(Wu))$$替代，其中BN变换独立地应用到$x=Wu$的每一维，每一维具有单独的成对学习参数$\gamma{(k)}$，$\beta{(k)}$。</p><p>另外，对于卷积层我们希望标准化遵循卷积特性——为的是同一特征映射的不同元素，在不同的位置，以相同的方式进行标准化。为了实现这个，我们在所有位置联合标准化了小批量数据中的所有激活。在算法1中，我们让$\cal B$是跨越小批量数据的所有元素和空间位置的特征图中所有值的集合——因此对于大小为$m$的小批量数据和大小为$p\times q$的特征映射，我们使用有效的大小为$m’=|\cal B| = m\cdot p, q$的小批量数据。我们每个特征映射学习一对参数$\gamma{(k)}$和$\beta{(k)}$，而不是每个激活。算法2进行类似的修改，以便推断期间BN变换对在给定的特征映射上的每一个激活应用同样的线性变换。</p><h3 id="3-3-Batch-Normalization-enables-higher-learning-rates"><a href="#3-3-Batch-Normalization-enables-higher-learning-rates" class="headerlink" title="3.3. Batch Normalization enables higher learning rates"></a>3.3. Batch Normalization enables higher learning rates</h3><p>在传统的深度网络中，学习率过高可能会导致梯度爆炸或梯度消失，以及陷入差的局部最小值（提前收敛）。Batch Normalization有助于解决这些问题。通过标准化整个网络的激活值，在数据通过深度网络传播时，它可以防止层参数的微小变化被放大。例如，这使sigmoid非线性更容易保持在它们的非饱和状态，这对训练深度sigmoid网络至关重要，但在传统上很难实现。</p><p>Batch Normalization也使训练对参数的缩放更有弹性。通常，大的学习率可能会增加层参数的缩放，这会在反向传播中放大梯度并导致模型爆炸。然而，通过批标准化，通过层的反向传播不受其参数缩放的影响。实际上，对于标量$a$，</p><p>$$BN(Wu) = BN((aW)u)$$</p><p>我们可以看到</p><p>$$\frac {\partial BN((aW)u)} {\partial u}= \frac {\partial BN(Wu)} {\partial u}$$</p><p>$$\frac {\partial BN((aW)u)} {\partial (aW)}=\frac{1}{a} \cdot \frac {\partial BN(Wu)} {\partial W}$$</p><p>标量不影响层的Jacobian行列式，也不影响梯度传播。此外，更大的权重会导致更小的梯度，并且BN会稳定参数的增长。</p><p>我们进一步推测，批标准化可能会导致雅可比行列式的奇异值接近于1，这被认为对训练是有利的(Saxe et al., 2013)。考虑具有标准化输入的两个连续的层，并且变换位于这些标准化向量之间：$\hat z = F(\hat x)$。如果我们假设$\hat x$和$\hat z$是高斯分布且不相关的，那么$F(\hat x)\approx J \hat x$是对给定模型参数的一个线性变换，$\hat x$和$\hat z$有单位方差，并且$I=Cov[\hat z] =J Cov[\hat x] J^T = JJ^T$。因此，$J$是正交的，其保留了反向传播中的梯度大小。尽管上述假设在现实中不是真实的，但我们希望批标准化有助于梯度传播更好的执行。这有待于进一步研究。</p><h2 id="4-实验"><a href="#4-实验" class="headerlink" title="4. 实验"></a>4. 实验</h2><h3 id="4-1-随时间激活"><a href="#4-1-随时间激活" class="headerlink" title="4.1. 随时间激活"></a>4.1. 随时间激活</h3><p>为了验证internal covariate shift对训练的影响，以及BN对抗它的能力，我们考虑了在MNIST数据集上预测数字类别的问题(LeCun et al., 1998a)。我们使用非常简单的网络，28x28的二值图像作为输入，以及三个全连接层，每层100个激活。每一个隐藏层用sigmoid非线性计算$y = g(Wu+b)$，权重$W$初始化为小的随机高斯值。最后的隐藏层之后是具有10个激活（每类1个）和交叉熵损失的全连接层。我们训练网络50000次迭代，每份小批量数据中有60个样本。如第3.1节所述，我们在网络的每一个隐藏层后添加批标准化。我们对基准线和批标准化网络之间的比较感兴趣，而不是实现在MNIST上的最佳性能（所描述的架构没有）。</p><p>Fig 1(a)显示了随着训练进行，两个网络在提供的测试数据上正确预测的分数。批标准化网络具有更高的测试准确率。为了调查原因，我们在训练过程中研究了原始网络$N$和批标准化网络$N_{BN}^{tr}$(Alg. 2)中的sigmoid输入。在图1(b，c)中，我们显示，对于来自每个网络的最后一个隐藏层的一个典型的激活，其分布如何演变。原始网络中的分布随着时间的推移而发生显著变化，无论是平均值还是方差，都会使后面的层的训练复杂化。相比之下，随着训练的进行，批标准化网络中的分布更加稳定，这有助于训练。</p><p><img src="/assets/articleImg/bn-fig-1.png" alt="Figure 1"></p><p>Fig1 (a)使用批标准化和不使用批标准化训练的网络在MNIST上的测试准确率，以及训练的迭代次数。批标准化有助于网络训练的更快，取得更高的准确率。(b，c)典型的sigmoid在训练过程中输入分布的演变，显示为15%，50%，85%。批标准化使分布更稳定并降低了internal covariate shift。</p><h3 id="4-2-ImageNet分类"><a href="#4-2-ImageNet分类" class="headerlink" title="4.2. ImageNet分类"></a>4.2. ImageNet分类</h3><p>我们将批标准化化应用于在ImageNet分类任务（Russakovsky等，2014）上训练的Inception网络的新变种（Szegedy等，2014）。网络具有大量的卷积和池化层，和一个softmax层用来在1000个可能之中预测图像的类别。卷积层使用ReLU作为非线性。与（Szegedy等人，2014年）中描述的网络的主要区别是5×5卷积层被两个连续的3x3卷积层替换，最多可以有128个滤波器。该网络包含$13.6 \cdot 10^6$个参数，除了顶部的softmax层之外，没有全连接层。在其余的文本中我们将这个模型称为Inception。训练在大型分布式架构（Dean et al。，2012）上进行，10个模型副本中的每一个都使用了5个并行步骤，使用异步带动量的SGD（Sutskever等，2013），小批量数据大小为32。随着训练进行，所有网络都通过计算验证准确率@1来评估，即每幅图像使用单个裁剪图像，在1000个可能性中预测正确标签的概率。</p><p>在我们的实验中，我们评估了几个带有批标准化的Inception修改版本。在所有情况下，如第3.2节所述，批标准化以卷积方式应用于每个非线性的输入，同时保持架构的其余部分不变。</p><h4 id="4-2-1-加速BN网络"><a href="#4-2-1-加速BN网络" class="headerlink" title="4.2.1. 加速BN网络"></a>4.2.1. 加速BN网络</h4><p>将BN简单添加到网络中不能充分利用我们方法的优势。为此，我们进行了以下修改：</p><ul><li><strong>提高学习率</strong>。在批标准化模型中，我们已经能够从高学习率中实现训练加速，没有不良的副作用（第3.3节）。</li><li><strong>移除Dropout</strong>。我们发现从BN-Inception中移除dropout可以使网络实现更高的验证准确率。我们推测，BN提供了类似dropout的正则化收益，因为对于训练样本观察到的激活受到了同一小批量数据中样本随机选择的影响。</li><li><strong>减少L2正则化权重</strong>。虽然在Inception中模型参数的L2损失会控制过拟合，但在修改的BN-Inception中，损失的权重减少了5倍。我们发现这提高了在提供的验证数据上的准确性。</li><li><strong>加速学习率衰减</strong>。在训练Inception时，学习率呈指数衰减。因为我们的网络训练速度比Inception更快，所以我们将学习速度降低加快6倍。</li><li><strong>删除局部响应归一化(Remove Local Response Normalization)</strong>。虽然Inception和其它网络（Srivastava等人，2014）从中受益，但是我们发现使用批标准化它是不必要的。</li><li><strong>更彻底地搅乱训练样本</strong>。我们启用了分布内部搅乱训练数据，这样可以防止同一个例子一起出现在小批量数据中。这导致验证准确率提高了约1％，这与BN作为正则化项的观点是一致的：它每次被看到时都会影响一个样本，在我们的方法中内在的随机化应该是最有益的。</li><li><strong>Reduce the photometric distortions</strong>。因为批标准化网络训练更快，并且观察每个训练样本更少的次数，所以通过更少地扭曲它们，我们让训练器关注更多的“真实”图像。</li></ul><h4 id="4-2-2-单网络分类"><a href="#4-2-2-单网络分类" class="headerlink" title="4.2.2. 单网络分类"></a>4.2.2. 单网络分类</h4><p>我们评估了下面的网络，所有的网络都在LSVRC2012训练数据上训练，并在验证数据上测试：</p><ul><li>Inception：在4.2小节开头描述的网络，以0.0015的初始学习率进行训练。</li><li>BN-Baseline：每个非线性之前加上批标准化，其它的与Inception一样。</li><li>BN-x5：带有批标准化的Inception，修改在4.2.1小节中。初始学习率增加5倍到了0.0075。原始Inception增加同样的学习率会使模型参数达到机器无限大。</li><li>BN-x30：类似于BN-x5，但初始学习率为0.045（Inception学习率的30倍）。</li><li>BN-x5-Sigmoid：类似于BN-x5，但使用sigmoud非线性$g(t)=\frac{1}{1+\exp(-x)}$来代替ReLU。我们也尝试训练带有sigmoid的原始Inception，但模型保持在相当于机会的准确率。<br>在图2中，我们显示了网络的验证集准确率，作为训练步骤次数的函数。Inception网络在$31 \cdot 10^6$次训练步骤后达到了72.2％的准确率。图3显示，对于每个网络，达到同样的72.2％准确率需要的训练步骤数量，以及网络达到的最大验证集准确率和达到该准确率的训练步骤数量。</li></ul><p><img src="/assets/articleImg/bn-fig-2-3.png" alt="Figure 2"></p><p>通过仅使用Batch Normalization（BN-Baseline），我们在不到Inception一半的训练步骤数量内将准确度与其相匹配。通过应用4.2.1小节中的修改，我们显著提高了网络的训练速度。BN-x5需要比Inception少14倍的步骤就达到了72.2％的准确率。有趣的是，进一步提高学习率（BN-x30）使得该模型最初训练有点慢，但可以使其达到更高的最终准确率。这种现象是违反直觉的，应进一步调查。在$6 \cdot 10^6$步骤之后，BN-x30达到74.8％的准确率，即比Inception达到72.2％的准确率所需的步骤减少了5倍。<br>我们也证实了尽管训练这样的网络是众所周Batch Normalization的深层网络被训练。的确，BN-x5-Sigmoid取得了69.8％的准确率达。没有Batch Normalization，使用sigmoid的Inception从未达到比1/1000准确率更好的结果。</p><h4 id="4-2-3-组合分类"><a href="#4-2-3-组合分类" class="headerlink" title="4.2.3. 组合分类"></a>4.2.3. 组合分类</h4><p>目前在ImageNet大型视觉识别竞赛中报道的最佳结果是传统模型（Wu et al。，2015）的Deep Image组合和（He等，2015）的组合模型。后者报告了ILSVRC测试服务器评估的4.94％的top-5错误率。这里我们在测试服务器上报告4.82％的测试错误率。这提高了以前的最佳结果，并且根据（Russakovsky等，2014）这超过了人类评估者的评估准确率。</p><p>对于我们的组合，我们使用了6个网络。每个都是基于BN-x30的，进行了以下一些修改：增加卷积层中的初始重量；使用Dropout（丢弃概率为5％或10％，而原始Inception为40％）；模型最后的隐藏层使用非卷积BN。每个网络在大约$6 \cdot 10^6$个训练步骤之后实现了最大的准确率。组合预测是基于组成网络的预测类概率的算术平均。组合和多裁剪图像推断的细节与（Szegedy et al，2014）类似。</p><p>我们在图4中证实了BN使我们能够在ImageNet分类挑战基准上设置新的最佳结果。</p><p><img src="/assets/articleImg/bn-fig-4.png" alt="Figure 4"></p><p>Fig4。BN Inception与以前的最佳结果在提供的包含5万张图像的验证集上的比较。组合结果是在测试集上由测试服务器评估的结果。BN-Inception组合在验证集的5万张图像上取得了4.9% top-5的错误率。所有报道的其它结果是在验证集上。</p><h2 id="5-结论"><a href="#5-结论" class="headerlink" title="5. 结论"></a>5. 结论</h2><p>我们提出了一个新的机制，大大加快了深度网络的训练。它是基于covariate shift的前提，covariate shift会使机器学习系统的训练变得复杂化，也适用于子网络和层，并且从网络的内部激活中去除它可能有助于训练。我们提出的方法从其标准化激活中获取其功能，并将这种标准化合并到网络架构本身。这确保了标准化可以被用来训练网络的任何优化方法进行恰当的处理。为了让深度网络训练中常用的随机优化方法可用，我们对每个小批量数据执行标准化，并通过标准化参数来反向传播梯度。BN每个激活只增加了两个额外的参数，这样做可以保持网络的表示能力。我们提出了一个算法，其用于构建，训练和执行推断批标准化网络。所得到的网络可以用饱和非线性进行训练，能更容忍增加的训练率，并且通常不需要丢弃来进行正则化。</p><p>仅仅将批标准化添加到了最新的图像分类模型中便在训练中取得了实质的加速。通过进一步提高学习率，删除丢弃和应用批标准化所提供的其它修改，我们只用了少部分的训练步骤就达到了以前的技术水平——然后在单网络图像分类中击败了最先进的技术。此外，通过组合多个使用BN训练的模型，我们在ImageNet上的表现显著优于最好的已知系统。</p><p>我们的方法与（Gülçehre＆Bengio，2013）的standardization layer相似，尽管这两个方法解决的目标不同。Batch Normalization的目的是<strong>在整个训练过程中获得激活值的稳定分布</strong>，在实验中我们在非线性之前应用它，因为在非线性之前一阶矩和二阶矩更有可能导致稳定分布。相反，标准化层被应用于非线性的输出，这导致了更稀疏的激活。在我们大规模的图像分类实验中，无论有没有Batch Normalization，我们都没有观察到非线性输入是稀疏的。Batch Normalization的其它显著差异包括学习到的缩放和转移允许BN变换表示恒等，卷积层处理以及不依赖于小批量数据的确定性推断。</p><p>在这项工作中，我们没有探索Batch Normalization可能实现的全部可能性。我们的未来工作包括将我们的方法应用于RNN（Pascanu et al.，2013），其internal covariate shift和梯度消失或爆炸情况特别严重，这将使我们能够更彻底地测试假设标准化改善了梯度传播（第3.3节）。需要对Batch Normalization的正则化属性进行更多的研究，我们认为这是BN-Inception中删除丢弃时我们观察到的改善的原因。我们计划调查批标准化是否有助于传统意义上的domain adaptation——即网络执行标准化是否能够更容易泛化到新的数据分布，也许仅仅是对总体均值和方差的重新计算（Alg.2）。最后，我们认为，该算法的进一步理论分析将允许更多的改进和应用。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要针对&lt;a href=&quot;https://arxiv.org/pdf/1502.03167.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift&lt;/a&gt;进行翻译，参考了&lt;a href=&quot;https://www.jianshu.com/p/14f4eae76a19&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Batch Normalization论文翻译——中文版&lt;/a&gt;一文，正文内容部分进行了修改，主要是格式上进行了调整，方便后续阅读。如有侵权还请联系博主删除博文，感谢！&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="https://www.csuldw.com/tags/Deep-Learning/"/>
    
      <category term="BN" scheme="https://www.csuldw.com/tags/BN/"/>
    
  </entry>
  
  <entry>
    <title>Deep Learning - RNN原理剖析</title>
    <link href="https://www.csuldw.com/2018/06/28/2018-06-28-recurrent-neural-networks/"/>
    <id>https://www.csuldw.com/2018/06/28/2018-06-28-recurrent-neural-networks/</id>
    <published>2018-06-27T16:01:00.000Z</published>
    <updated>2019-10-19T10:28:23.576Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在上一篇<a href="http://www.csuldw.com/2018/05/16/2018-05-16-cnn-theory/">Deep Learning - CNN原理剖析</a>一文中介绍了卷积神经网络，CNN的层次框架是输入层、卷积层、ReLU层、Pooling层、FC全连接层，其两大主要特性是：局部感知和权值共享。在应用上，CNN主要用于图像分析，然而对于存在上下文关系或是时序特性的场景，如NLP、语音识别等，CCN则表现得很无力。由此便出现了另一种神经网络结构——RNN（Recurrent Neural Networks，循环神经网络）。</p><a id="more"></a><h2 id="RNN介绍"><a href="#RNN介绍" class="headerlink" title="RNN介绍"></a>RNN介绍</h2><p>RNN是一类用于处理序列数据的神经网络，它的深度就是时间的长度。那么什么是时序序列数据呢？百度百科：时间序列数据（time series data）是在不同时间上收集到的数据，这类数据是按时间顺序收集到的，用于所描述现象随时间变化的情况。从理论上将，RNN可以保留很长的序列信息，但实践中并非如此，它只能保留短期的信息。下面来看看RNN框架：</p><p><img src="/assets/articleImg/2018/rnn.jpg" alt=""></p><div class="caption">一个最基本的RNN framework，折叠与展开时的形态(Source: Nature)</div><p>第一眼看到上面的左图，可能会让人觉得迷糊，笔者看到的时候也一样。我们来分析下上面这个图，先看看左边的，一共有六个变量。根据神经网络典型的三层结构，输入层、隐藏层、输出层，我们可以很清楚的确定$x$为输入层，在NLP中，就是一段文本；$o$表示的是输出层，比如情感分类中，就是输出这句话的的情感色彩。中间的$s$属于隐藏状态，$s$会通过输入层和上一个隐藏层不断的叠加。通过展开之后，从图右我们可以看到在不同时刻RNN的计算方式。</p><ul><li>$x_t$是$t$时刻的输入，例如$x_1$表示一段文本中第一个单词的ont-hot 向量。</li><li>$s_t$是$t$时刻的隐藏状态。$s_t$的值是根据上一个隐藏状态与当前时刻的输入进行计算的，即$s_t = f(Ux_t + W s_{t-1})$。激活函数$f$是非线性函数，如tanh或ReLU，$s_{-1}为第一个隐藏层，$通常初始化全为$0$。隐藏状态的内容可以看做是网络的记忆。</li><li>$o_t$是$t$时刻的输出，例如，我们想要预测句子中下一个单词是什么，那么输出便是我们词库的一个概率向量$o_t = softmax(Vs_t)$。由于$o_t$的计算仅仅基于$t$时刻的记忆，而在实际当中，$s_t$通常无法保留过多的记忆，所以隐藏层的循环过程显得有些复杂。</li></ul><p>通过上图我们可以看到，RNN每一步都是共享权值（U、V、W）的，基于这一点，与相同层数的DNN相比，RNN需要计算的参数要少很多。</p><h2 id="RNN能做什么"><a href="#RNN能做什么" class="headerlink" title="RNN能做什么"></a>RNN能做什么</h2><p>RNN对应场景可分为下图集中情况：</p><p><img src="/assets/articleImg/2018/dbNLo.jpg" alt=""></p><div class="caption">RNN场景 来源：https://i.stack.imgur.com/dbNLo.jpg</div><h3 id="One-to-One"><a href="#One-to-One" class="headerlink" title="One-to-One"></a>One-to-One</h3><p>One-to-One每一个输入都有对应的输出，比如词性标注。</p><h3 id="Many-to-One"><a href="#Many-to-One" class="headerlink" title="Many-to-One"></a>Many-to-One</h3><p>Many-to-One最典型的场景就是文本分类，比如情感识别，输入一段话，最后判断该句话的情感是积极的还是消极的。</p><p><img src="/assets/articleImg/2018/SimpleRNN01.png" alt=""></p><div class="caption">线性RNN结构</div><h3 id="One-to-Many"><a href="#One-to-Many" class="headerlink" title="One-to-Many"></a>One-to-Many</h3><p>One-to-Many比较典型的场景是图像到文本，输入是一张图片，输出是一段文字，比如图像描述。</p><p><img src="/assets/articleImg/2018/Screen-Shot-2015-09-17-at-11.44.24-AM-1024x349.png" alt=""></p><div class="caption">Deep Visual-Semantic Alignments生成图像描述. 来源: [cs.stanford.edu](http://cs.stanford.edu/people/karpathy/deepimagesent/)</div><h3 id="Many-to-Many"><a href="#Many-to-Many" class="headerlink" title="Many-to-Many"></a>Many-to-Many</h3><p>机器翻译类似于语言建模，我们输入的是源语言（例如德语）中的一系列单词。我们希望输出目标语言（如英语）中的一系列单词。一个关键的区别是，我们的输出只有在看到整个输入之后才开始输出，因为翻译的每一个单词还得考虑上下文的关系。</p><p><img src="/assets/articleImg/2018/Screen-Shot-2015-09-17-at-10.39.06-AM.png" alt=""></p><div class="caption">基于RNN的机器翻译. 图片来源: [CS224d-Lecture8.pdf](http://cs224d.stanford.edu/lectures/CS224d-Lecture8.pdf)</div><p>关于机器翻译相关的文章：</p><ol><li><a href="http://www.aclweb.org/anthology/P14-1140.pdf" target="_blank" rel="noopener">A Recursive Recurrent Neural Network for Statistical Machine Translation</a></li><li><a href="http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf" target="_blank" rel="noopener">Sequence to Sequence Learning with Neural Networks</a></li><li><a href="http://research.microsoft.com/en-us/um/people/gzweig/Pubs/EMNLP2013RNNMT.pdf" target="_blank" rel="noopener">Joint Language and Translation Modeling with Recurrent Neural Networks</a></li></ol><p>除了机器翻译之外，还有视频帧的分类，都属于M2M。</p><h2 id="权值更新推导"><a href="#权值更新推导" class="headerlink" title="权值更新推导"></a>权值更新推导</h2><p>首先我们看看下图，该图是第一张图的细化图，一个完整的RNN结构图。</p><p><img src="/assets/articleImg/2018/rnn-framework-complex.png" alt=""></p><div class="caption">计算RNN训练损失的计算图</div><ul><li>$x^{(t)}$表示在$t$时刻训练样本的输入。同样的，$x^{(t−1)}$和$x^{(t+1)}$代表在$t−1$和$t+1$时刻训练样本的输入。</li><li>$h(t)$表示$t$时刻模型的隐藏状态。$h^{(t)}$由$t$时刻的输入$x^{(t)}$和$t-1$时刻的隐藏状态$h^{(t−1)}$共同决定。</li><li>$o(t)$表示$t$时刻模型的输出。$o(t)$只由模型当前的隐藏状态$h^{(t)}$)决定。</li><li>$L(t)$表示$t$时刻模型的loss function。</li><li>$y(t)$表示$t$时刻训练样本序列的真实输出。</li><li>$U,W,V$ 这三个矩阵是我们的模型的线性关系参数，它在整个RNN 网络中是共享的，这点和DNN 很不相同。也正因为是共享了，它体现了RNN的模型的“循环反馈”的思想。RNN输入到隐藏的连接由权重矩阵$U$参数化，隐藏到隐藏的循环连接由权重矩阵$w$参数化，隐藏到输出的连接由权重矩阵$V$参数化。　</li></ul><h3 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h3><p>根据前向传播的思想，对于任意一个时刻$t$，它的隐藏状态$h^{(t)}$由$x^{(t)}$和$h^{(t−1)}$计算得到，假设$tanh$函数为RNN的隐藏状态的激活函数,那么隐藏状态的计算公式为：</p><p>$$<br>h^{(t)} = tanh(z^{(t)}) = tanh(Ux^{(t)} + Wh^{(t-1)} +b )<br>\tag{1} \label{1}<br>$$</p><p>$b$为线性关系的偏置项。通过上图，我们可以知道$t$时刻的输出为$o^{(t)}$：</p><p>$$<br>o^{(t)} = Vh^{(t)} +c<br>\tag{2} \label{2}<br>$$</p><p>假定RNN用于训练分类模型，那么上面最终预测输出这一层的激活函数为softmax，那么最终的预测输出为：</p><p>$$<br>\hat{y}^{(t)} = softmax(o^{(t)})<br>\tag{3} \label{3}<br>$$</p><p>通过损失函数$L(t)$，比如对数似然损失函数，我们可以量化模型在当前时刻的损失，即$\hat{y}^{(t)}$和$y(t)$的差值。</p><h3 id="后向传播"><a href="#后向传播" class="headerlink" title="后向传播"></a>后向传播</h3><p>RNN后向传播的思路与DNN是一样的，都是通过梯度下降逐步迭代，关于BP算法，可以参考下之前写的文章<a href="http://www.csuldw.com/2018/05/01/2018-05-01-backpropagation-algorithm/">Deep Learning - 神经网络与BP算法</a>。基于RNN的模型主要是寻找合适的参数：$U$、$W$、$V$、$b$和$c$。由于RNN存在时序关系，所以RNN的BP算法也叫做BPTT(back-propagation through time)。需要注意的是，RNN共享参数，所以BP算法更新的都是相同的变量$U$、$W$、$V$、$b$和$c$.下面，来看看RNN的权值更新推导，找出损失函数对$U$、$W$、$V$、$b$和$c$的偏导数。</p><p>假定我们最终的损失函数为$L$，这里假设为MSE，那么</p><p>$$<br>L = \sum\limits_{t=1}^{\tau}L^{(t)}<br>\tag{4} \label{4}<br>$$</p><p>输出层的偏导数为：</p><p>$$<br>\frac{\partial L}{\partial o^{(t)}}<br>= \color{ blue }{\frac{\partial L}{\partial L^{(t)}} } \frac{\partial L^{(t)}} {\partial o^{(t)}}<br>=  \frac{\partial L^{(t)}} {\partial o^{(t)}}<br>=\hat{y}^{(t)} - y^{(t)}<br>\tag{5} \label{5}<br>$$</p><p>关于$V$和$c$的梯度计算，公式如下：</p><p>$$<br>\frac{\partial L}{\partial c} = \sum\limits_{t=1}^{\tau}\frac{\partial L^{(t)}}{\partial c} = \sum\limits_{t=1}^{\tau}\frac{\partial L^{(t)}}{\partial o^{(t)}} \frac{\partial o^{(t)}}{\partial c} = \sum\limits_{t=1}^{\tau}\hat{y}^{(t)} - y^{(t)}<br>\tag{6} \label{6}<br>$$</p><p>$$<br>\frac{\partial L}{\partial V}<br>=\sum\limits_{t=1}^{\tau} \frac{\partial L^{(t)}}{\partial V}<br>= \sum\limits_{t=1}^{\tau} \frac{\partial L^{(t)}}{\partial o^{(t)}} \color{ blue }{\frac{\partial o^{(t)}}{\partial V} }<br>= \sum\limits_{t=1}^{\tau}(\hat{y}^{(t)} - y^{(t)}) \color{ blue }{(h^{(t)})^T}<br>\tag{7} \label{7}<br>$$</p><p>对于$W$、$U$、$b$的计算略微复杂，从RNN的模型结构来看，在BP过程时，$t$时刻的梯度损失由当前位置的输出$o^{(t)}$的梯度损失和$t+1$时刻的梯度损失两部分共同决定（$t$时刻的输出$o^{(t)}$与$t+1$时刻的隐藏状态$h^{(t+1)}$都调用了$h^{(t)}$）。对于$W$在$t$时刻的梯度损失需要BP迭代计算。我们假定$t$时刻的隐藏状态的梯度为：</p><p>$$<br>\delta^{(t)} = \frac{\partial L}{\partial h^{(t)}}<br>\tag{8} \label{8}<br>$$</p><p>那么根据$\delta^{(t+1)}$递推$\delta^{(t)}$,我们可以得到下面的结果（由上到下的计算原因是$\eqref{1}$中的激活函数$h$为$tanh$，其导数为$tanh’(x) = 1 - tanh^2(x)$）：</p><p>$$<br>\begin{align}<br>\delta^{(t)}<br>&amp;=\frac{\partial L}{\partial o^{(t)}} \color{ blue }{\frac{\partial o^{(t)}}{\partial h^{(t)}}} + \color{ red }{\frac{\partial L}{\partial h^{(t+1)}}}\frac{\partial h^{(t+1)}}{\partial h^{(t)}} \\<br>&amp;= \color{ blue }{V^T}(\hat{y}^{(t)} - y^{(t)}) + W^T \color{ red }{\delta^{(t+1)}}diag(1-(h^{(t+1)})^2)<br>\end{align}<br>\tag{9} \label{9}<br>$$</p><p>其中$diag(1-(h^{(t+1)})^2)$表示$1-(h^{(t+1)})^2$的对角矩阵，是关于t+1时刻与隐藏单元的双正切的Jacobian。假设最后一个时间步为$\tau$时刻，那么：</p><p>$$<br>\delta^{(\tau)} =\frac{\partial L}{\partial o^{(\tau)}} \frac{\partial o^{(\tau)}}{\partial h^{(\tau)}} = V^T(\hat{y}^{(\tau)} - y^{(\tau)})<br>\tag{10} \label{10}<br>$$</p><p>有了$\delta^{(t)}$,计算$W、U、b$的梯度就容易了，基于公式$\eqref{1}$，可以得到$L$对各个隐藏层各个参数的偏导如下：</p><p>$$<br>\frac{\partial L}{\partial W}<br>= \sum\limits_{t=1}^{\tau} \color{ blue }{\frac{\partial L}{\partial h^{(t)}}} \frac{\partial h^{(t)}}{\partial W} = \sum\limits_{t=1}^{\tau}diag(1-(h^{(t)})^2) \color{ blue }{\delta^{(t)}}(h^{(t-1)})^T<br>\tag{11} \label{11}<br>$$</p><p>$$<br>\frac{\partial L}{\partial U}<br>= \sum\limits_{t=1}^{\tau} \color{ blue }{\frac{\partial L}{\partial h^{(t)}}} \frac{\partial h^{(t)}}{\partial U}<br>= \sum\limits_{t=1}^{\tau}diag(1-(h^{(t)})^2) \color{ blue }{\delta^{(t)}}(x^{(t)})^T<br>\tag{12} \label{12}<br>$$</p><p>$$<br>\frac{\partial L}{\partial b}<br>= \sum\limits_{t=1}^{\tau}\color{ blue }{\frac{\partial L}{\partial h^{(t)}}} \frac{\partial h^{(t)}}{\partial b}<br>= \sum\limits_{t=1}^{\tau}diag(1-(h^{(t)})^2) \color{ blue }{\delta^{(t)}}<br>\tag{13} \label{13}<br>$$</p><p>得到损失函数与偏导数的关系之后，我们就可以采用基于梯度的优化方法如SGD进行参数训练，逐步逼近最优解。</p><h3 id="梯度爆炸与梯度消失"><a href="#梯度爆炸与梯度消失" class="headerlink" title="梯度爆炸与梯度消失"></a>梯度爆炸与梯度消失</h3><p>在CNN中，当我们的网络层次比较深的时候，如果激活函数为sigmoid或tanh函数，则会出现“梯度消失”的现象。对于tanh和sigmoid函数，它们在两端的梯度值都为0。在CNN中，当前时刻的梯度为0会使得前面层的梯度也为0。同时，矩阵出现比较小的值的时候，当多个矩阵相乘就会使梯度值以指数级速度下降，最终在几步后完全消失。比较远的时刻的梯度值最终会等于0，这些时刻的状态对学习过程没有帮助，导致你无法学习到长距离依赖。那么在RNN中，又会出现什么现象呢？</p><p>根据RNN上面BPTT推导，我们可以得到$\eqref{11}$、$\eqref{12}$、$\eqref{13}$三个表达式，这三个表达式都存在一个$\delta^{(t)}$，表示$t$时刻隐藏状态的梯度，根据$\eqref{9}$我们可以看到$\delta^{(t)}$是通过迭代计算得到，与$\delta^{(t+1)}$强相关，我们把$\eqref{9}$式变化一下：</p><p>$$<br>\begin{align}<br>\delta^{(t)}<br>&amp;=\frac{\partial L}{\partial o^{(t)}} \color{ blue }{\frac{\partial o^{(t)}}{\partial h^{(t)}}} + \frac{\partial L}{\partial h^{(t+1)}}\frac{\partial h^{(t+1)}}{\partial h^{(t)}} \\<br>&amp;= \color{ blue }{V^T}(\hat{y}^{(t)} - y^{(t)}) + \color{ red }{W^T \delta^{(t+1)} * tanh’}<br>\end{align}<br>\tag{14} \label{14}<br>$$</p><p>仔细观察上面的式子，当$W$初始化值很大时，由于每个$\delta$都存在$W$，而$\delta^{(t)}$等于$W$与$\delta^{(t+1)}$的乘机，因此多个$W$相乘，最终导致“梯度爆炸”现象；另外，由于$\delta^{(t)}$与$\delta^{(t+1)}$之间还有一个$tanh’$ ($tanh’\leq 1$),当层次比较深的时候，就会出现很多个$tanh’$相乘，最终会使得梯度越来越小，逐渐趋近0，随后“梯度消失”现象也就出现了。</p><p>通常梯度消失比梯度爆炸受到了更多的关注，其原因有二:</p><ol><li>“梯度爆炸”出现之后容易发现，梯度值会变成NaN，从而导致程序崩溃，容易确定问题并fixed；</li><li>“梯度消失”的出现不会那么明显，处理起来不方便。</li></ol><p>当然，神经网络经过多年的发展，已经有一些方法解决了“梯度消失”问题的办法。比如</p><ol><li>合适的初始化矩阵$W$可以适当的减小梯度消失效应；</li><li>在损失函数上加上正则也能起一定作用；</li><li>选择择ReLU而不是sigmoid和tanh作为激活函数。ReLU的导数是常数值0或1，所以不可能会引起梯度消失。</li></ol><p>这些方法并不是最好的，还有更好的解决方法，也就是采用LSTM或GRU，本文暂且不做介绍。</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>上面总结了通用的RNN模型和前向与反向传播过程。RNN虽然理论上可以很漂亮的解决序列数据的训练，但是它也像DNN一样存在“梯度消失”的问题，当序列很长的时候问题尤其严重。因此，上面的RNN模型一般不能直接用于应用领域。在语音识别，手写书别以及机器翻译等NLP领域实际应用比较广泛的是基于RNN模型的一个变体LSTM，关于LSTM的细节，将在下一节进行介绍。一大串的公式，敲得头头昏脑涨，喝杯咖啡，休息休息！</p><p><strong>说明：文章公式较多，如有攥写错误，还请读者指出，深表感谢！</strong></p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="https://en.wikipedia.org/wiki/Recurrent_neural_network" target="_blank" rel="noopener">Recurrent_neural_network</a></li><li><a href="http://cs231n.stanford.edu/slides/2016/winter1516_lecture10.pdf" target="_blank" rel="noopener">cs231n - winter1516_lecture10</a></li><li><a href="http://ufldl.stanford.edu/tutorial/" target="_blank" rel="noopener">ufldl.stanford.edu/tutorial</a></li><li><a href="http://neuralnetworksanddeeplearning.com/chap2.html" target="_blank" rel="noopener">How the backpropagation algorithm works</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在上一篇&lt;a href=&quot;http://www.csuldw.com/2018/05/16/2018-05-16-cnn-theory/&quot;&gt;Deep Learning - CNN原理剖析&lt;/a&gt;一文中介绍了卷积神经网络，CNN的层次框架是输入层、卷积层、ReLU层、Pooling层、FC全连接层，其两大主要特性是：局部感知和权值共享。在应用上，CNN主要用于图像分析，然而对于存在上下文关系或是时序特性的场景，如NLP、语音识别等，CCN则表现得很无力。由此便出现了另一种神经网络结构——RNN（Recurrent Neural Networks，循环神经网络）。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="https://www.csuldw.com/tags/Deep-Learning/"/>
    
      <category term="RNN" scheme="https://www.csuldw.com/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>Deep Learning - CNN原理剖析</title>
    <link href="https://www.csuldw.com/2018/05/16/2018-05-16-cnn-theory/"/>
    <id>https://www.csuldw.com/2018/05/16/2018-05-16-cnn-theory/</id>
    <published>2018-05-15T17:04:00.000Z</published>
    <updated>2019-05-28T16:30:12.514Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在<a href="http://www.csuldw.com/2018/05/01/2018-05-01-backpropagation-algorithm/">Deep Learning - 神经网络与BP算法</a>一文中介绍了神经网络的原理，可以发现不同层之间是全连接的，当神经网络的深度、节点数变大，会导致过拟合、参数过多等问题。因此，本文将介绍另一种神经网络：CNN，卷积神经网络。</p><a id="more"></a><h2 id="CNN简介"><a href="#CNN简介" class="headerlink" title="CNN简介"></a>CNN简介</h2><p>卷积神经网络通常是由三种层构成：<strong>卷积层</strong>，<strong>Pooling层</strong>（一般指<strong>Max Pooling</strong>）和<strong>全连接层</strong>（简称FC）。ReLU激活函数也应该算是是一层，它逐元素地进行激活函数操作。在本节中将讨论在卷积神经网络中这些层通常是如何组合在一起的。</p><p><img src="/assets/articleImg/2018/cnn-framework.png" alt=""></p><div class="caption">一个典型的CNN框架</div><p>一个CNN网络由若干卷积层、Pooling层、全连接层组成。你可以构建各种不同的卷积神经网络，它的常用架构模式为：</p><pre><code>INPUT -&gt; [[CONV -&gt; ReLU] * N -&gt; POOL?]*M -&gt; [FC -&gt; RELU] * K -&gt; FC</code></pre><p>即N个[卷积层 + ReLU层]叠加，然后叠加一个可选的Pooling 层，整个结构重复M次，最后叠加K个[全连接+Relu]层。通常，</p><ul><li>当N = M = K = 0时，INPUT -&gt; FC是一个线性分类；</li><li>INPUT -&gt; CONV -&gt; RELU -&gt; FC </li><li>INPUT -&gt; [CONV -&gt; RELU -&gt; POOL]*2 -&gt; FC -&gt; RELU -&gt; FC。此处在每个Pooling 层之间有一个CONV层;</li><li>INPUT -&gt; [CONV -&gt; RELU -&gt; CONV -&gt; RELU -&gt; POOL]*3 -&gt; [FC -&gt; RELU]*2 -&gt; FC。此处每个Pooling层前有两个卷积层，这个思路适用于<strong>更大更深的网络</strong>，因为在执行具有破坏性的Pooling操作前，多重的卷积层可以从输入数据中学习到更多的复杂特征。</li></ul><h2 id="原理分析"><a href="#原理分析" class="headerlink" title="原理分析"></a>原理分析</h2><p>下面对CNN的原理进行深层次剖析，当然，由于笔者能力有限，解释模糊的地方还望读者谅解。</p><p>对于卷积神经网络，主要有两个特性：</p><ol><li>局部感知：卷积核；</li><li>局部权值共享：每个卷积过程的权重相同。</li></ol><p>卷积神经网络的层次依次是输入层、卷积层、ReLU层、Pooling层、输出层，具体细节请往下看。</p><h3 id="输入层"><a href="#输入层" class="headerlink" title="输入层"></a>输入层</h3><p>对于输入层，以图像为例，通常是一张图片的$n*n$的像素点，如果考虑RGB三种通道，输入就为$n*n*3$的图像。</p><h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>卷积层是CNN的核心层，它的作用是进行特征提取。卷积层若干卷积单元组成，卷积单元的参数都是通过反向传播算法最佳化得到的。在这一层，我们通过卷积核可以得到更深层次的feature map，每个卷积运算的目的都是为了提取输入图的不同特征，第一层卷积层可能是指提取一些低级的特征如边缘、线条和角等，更多层的网路能从低级特征中迭代提取更复杂的特征。</p><p>卷积层需要着重关注的几个点：</p><ul><li>局部感知（Local Connectivity）：卷积核（也叫滤波器，感受野）的大小；</li><li>空间排列（Spatial arrangement）：卷积层的输出；</li><li>参数共享（Parameter Sharing）：卷积核上的权重一样。</li></ul><p>那么对于卷积层，怎么计算输出层的大小呢？请看下面：</p><ol><li>首先接收一个$3D$的立体图像，长宽高表示为：$W_{1} \times H_{1} \times D_{1}$</li><li>超参数<ul><li>filter卷积核的数量$K$;</li><li>卷积核的大小$F$，例如$3*3$的卷积核，$F=3$;</li><li>步长stride：$S$;</li><li><ul><li>zero padding（零填充），补零数$P$，表达式为：$P = (F - 1)/2$;</li></ul></li></ul></li><li>输出一个新的3D对象：$W_{2}\times H_{2}\times D_{2}$，那么输出的图像各个维度的大小为：<ul><li>$W_{2} = (W_{1} - F + 2P)/S + 1$;</li><li>$H_{2} = (H_{1} - F + 2P)/S + 1$;</li><li>$D_{2} = K$（卷积核的个数，对应输出层的深度）;</li></ul></li><li>通过参数共享，每个filter共携带$F\cdot F \cdot D_{1}$个权值，对于整个卷积层，共有$(F\cdot F \cdot D_{1})\cdot K$个权值，另外还有$K$个偏置bias。</li></ol><h3 id="ReLU层"><a href="#ReLU层" class="headerlink" title="ReLU层"></a>ReLU层</h3><p>ReLU层就是激活函数层，这里把它单独出来是因为这一层充当非常重要的作用，它可以增强判定函数和整个神经网络的非线性特性，而本身并不会改变卷积层的空间排列。不同的激活函数产生的效果也大不相同，这里采用ReLU而不采用sigmoid或tanh的主要原因是ReLU可以克服vanishing gradient problem。ReLU的表达式如下：</p><p>$$<br>f(x) = max(0, x)<br>\tag{1} \label{1}<br>$$</p><p>使用ReLU的四个原因：</p><ol><li>fast to compute.</li><li>biological reason.</li><li>infinite sigmoid with different biases.</li><li>vanising gradient problem.</li></ol><p>关于第四点，CNN采用ReLU能够解决梯度消失问题，原理如下：假设经过第$i$层卷积之后，得到的输出为$f_i$，那么有:</p><p>$$<br>f_1 = f(w_1x + b_1) = f(net _ 1)<br>$$</p><p>$$f_2 = f(w_2f(w_1x + b_1) + b_2) = f(net _2)$$</p><p>$$f_3 = f(w_3f(w_2f(w_1x + b_1) + b_2) + b_3) = f(net _3)$$</p><p>假设最终损失为$L$，通过BP可以推导出：</p><p>$$<br>\frac{\partial L}{ \partial w_1} = \frac{\partial L}{ \partial f_3} \frac{\partial f_3}{ \partial net_3} w_3 \frac{\partial f_2}{ \partial net_2}  w_2 \frac{\partial f_1}{ \partial net_1} \frac{\partial net_1}{ w_1}<br>\tag{2} \label{2}<br>$$</p><p>当$f$为sigmoid时，$\frac{\partial f_3}{ \partial net_3}$与$\frac{\partial f_2}{ \partial net_2}$均大于0，小于等于0.25（sigmoid激活函数的导数为$y * (1-y) \leq \frac{y^2 + (1-y)^2}{2}  $，当且仅当 $y = 1-y$时取等号），所以当层数比较大的时候，就会出现“梯度消失”的问题。当激活函数为ReLU的时候，偏导数只在$0$和$1$两个数，所以只要在第一层中有一个不为零的偏导数，后面所有的偏导数均不为0。</p><h3 id="Pooling层"><a href="#Pooling层" class="headerlink" title="Pooling层"></a>Pooling层</h3><p>Pooling层相当于采样层，通常有max pooling、average pooling、L2-norm pooling。</p><p><img src="/assets/articleImg/2018/max-pool.png" alt=""></p><div class="caption">图片来自【[cs231n - cnn](http://cs231n.github.io/convolutional-networks/)】：Pooling层在空间上是对卷积层进行采样。图左：在本例中，大小为[224x224x64]的输入卷积层与大小为2的filter合并，步长为2最后输出图的大小为[112x112x64]。注意，变换前后深度是不变的。图右：最常见的降采样操作是max pooling，实例的步长为2。也就是说，每个max比较的元素为4个数字（2x2的方正）</div><p>那么经过pooling层之后，输出图的大小如何计算呢？请看下面：</p><ol><li>接收一个3D的立体对象：$W_{1} \times H_{1} \times D_{1}$</li><li>必备超参数<ul><li>filter的空间大小：$F$</li><li>步长$S$</li></ul></li><li>输出一个新的3D对象：$W_{2}\times H_{2}\times D_{2}$<ul><li>$W_{2} = (W_{1} - F)/S + 1$</li><li>$H_{2} = (H_{1} - F)/S + 1$</li><li>$D_{2} = D_{1}$</li></ul></li><li>将输入导入固定函数，引入0参数</li></ol><h3 id="FC层"><a href="#FC层" class="headerlink" title="FC层"></a>FC层</h3><p>FC层中的神经元与前一层中的所有激活具有完全连接，如在常规神经网络中所见。因此，它们的激活函数可以用一个矩阵乘法和一个偏移量来计算，即$wx+b$。同时，使用一个损失函数来“惩罚”网络的预测结果和真实结果之间的差异。例如，Softmax 交叉熵损失函数用于多分类问题，而Sigmoid交叉熵损失函数常常用于二分类问题。</p><h2 id="权值更新推导"><a href="#权值更新推导" class="headerlink" title="权值更新推导"></a>权值更新推导</h2><p>首先，回忆下上一篇文章神经网络和反向传播算法介绍的反向传播算法，整个算法分为三个步骤：</p><ol><li>前向计算每个神经元的输出值；</li><li>反向传播计算每个神经元的误差项$\delta_{i}$，实际上是网络的损失函数$E_{k}$对神经元加权组成的网络的偏导数，即$\delta_i=\frac{\partial{E_k}}{\partial{net_i}}$；</li><li>计算神经元连接权重梯度$w_{ij}$（$w_{ij}$表示从神经元$j$连接到神经元$i$的权重），公式为$\frac{\partial{E_{k}}}{\partial{w_{ij}}}=\delta_{i}a_{j}$，其中，<font color="blue">$a_{j}$表示神经元$j$的输出</font>。然后根据梯度下降法则更新每个权重。</li></ol><p>对于卷积神经网络，由于CONV和pooling下采样层的出现，影响了第二步$\delta$的计算，同时权值共享影响了第三步$w_{ji}$的更新。下面来详细分析卷积层和pooling层的反向传播过程，通过分析参数更新规则来进一步理解卷积神经网络。</p><p>对于卷积网络的权值推导，误差使用BP算法由后往前传递，可依次将其分为以下三部分：</p><ol><li>输出层</li><li>Pooling层</li><li>池化层</li></ol><p>输出层是全连接层，其权值更新规则与上一篇文章介绍的一样，本文不再详细介绍。下面来看Pooling层与卷积层。</p><p>在公式推导之前，先对几个核心的变量进行简单说明，如下表：</p><table><thead><tr><th align="center">变量</th><th>描述</th></tr></thead><tbody><tr><td align="center">$E_{total}$</td><td>表示整个网络输出层的误差和</td></tr><tr><td align="center">$\delta_{k}^{l}$</td><td>表示第$l$层，第$k$个神经元的误差项</td></tr><tr><td align="center">$a_{k}^{l}$</td><td>表示第$l$层，第$k$个神经元的输出</td></tr><tr><td align="center">$net_{k}^{l}$</td><td>表示第$l$层，第$k$个神经元的输入</td></tr><tr><td align="center">$w^{l}$</td><td>表示第$l$层filter的权重</td></tr><tr><td align="center">$f(net)$</td><td>f表示激活函数</td></tr></tbody></table><h3 id="Pooling-Layers-池化层"><a href="#Pooling-Layers-池化层" class="headerlink" title="Pooling Layers 池化层"></a>Pooling Layers 池化层</h3><p>克罗内克积(Kronecker product)</p><p>$$<br>\delta_k^{l-1} = \frac{\partial E_{total}}{\partial a_k^{l-1}} \frac{\partial  a_k^{l-1}}{\partial net_k^{l-1}} = up(\delta_k^l) \odot f^{‘}(net_k^{l-1})<br>\tag{3} \label{3}<br>$$</p><p>其中，up函数表示上采样，完成了池化误差矩阵放大与误差重新分配的逻辑。</p><h3 id="Convolution-Layers-卷积层"><a href="#Convolution-Layers-卷积层" class="headerlink" title="Convolution Layers 卷积层"></a>Convolution Layers 卷积层</h3><p>前一层的feature map与卷积核进行卷积，然后输入到激活函数$f$中，形成输出层的feature map。每个输出图可由多个卷积核与多个输入图卷积加和而成。如下图：</p><p><img src="http://upload-images.jianshu.io/upload_images/2256672-958f31b01695b085.gif" alt=""></p><p>整个卷积层的形式如下：</p><p>$$<br>a^{l}_{j} = f \left ( \sum_{i \in M_{j} } a_{i}^{l-1} \ast k_{ij}^{l} + b_{j}^{l}   \right )<br>\tag{4} \label{4}<br>$$</p><p>其中$M_{j}$表示选择的输入图，$b$表示每个输出图携带的一个额外的偏置项。对于一个特定的输出图，卷积各个输入图的卷积核是不一样的。也就是说，如果输出feature map $j$和输出feature map $k$都是从输入图 $i$中卷积求和得到，那么两者对应的卷积核是不一样的。</p><p>在CNN反向传播过程中，假设输出层是是第$l+1$层，那么第$l$层是Pooling层，第$l-1$层属于卷积层。现在，输出层与Pooling层的误差项已经可以计算出来，现在，我们通过Pooling层的误差项$\delta_{l}$来推导卷积层的误差项$\delta^{l-1}$。</p><p>首先，$l$层与$l-1$层的输出值之间的关系如下：</p><p>$$<br>a^l= f(net^l) = f \left (a^{l-1}*W^l +b^l \right )<br>\tag{5} \label{5}<br>$$</p><p>下面，我们通过一个实例，来归纳卷积层的误差项$\delta^{l-1}$的计算式。</p><!-- ### 梯度$$\frac{\partial E\_{total}}{\partial W^{l}} = \frac{\partial E\_{total}}{\partial net^{l}}\frac{\partial net^{l}}{\partial W^{l}} =\delta^l*rot180(a^{l-1})$$ --><p>假设我们$l-1$层（卷积层）是一个$3 \times 3$的矩阵，filter是一个$2 \times 2$ 的矩阵，在步长为1，没有零填充的条件下，输出层（即$l$层）则是一个$2 \times 2$的矩阵。表达式可表示如下（输出层没有增加激活函数）：</p><p>$$<br>\left( \begin{array}{ccc} a_{11}^{l-1}&amp;a_{12}^{l-1}&amp;a_{13}^{l-1} \\<br>a_{21}^{l-1}&amp;a_{22}^{l-1}&amp;a_{23}^{l-1}\\<br>a_{31}^{l-1}&amp;a_{32}^{l-1}&amp;a_{33}^{l-1} \end{array} \right)    *  \left( \begin{array}{ccc} w_{11}^{l}&amp;w_{12}^{l}\\<br>w_{21}^{l}&amp;w_{22}^{l} \end{array} \right) = \left( \begin{array}{ccc} net_{11}^{l}&amp;net_{12}^{l}\\<br>net_{21}^{l}&amp;net_{22}^{l} \end{array} \right)<br>\tag{6} \label{6}<br>$$</p><p>通过卷积的定义，我们可以轻松得知各个$net$的表达式：</p><p>$$<br>net_{11}^{l} = a_{11}^{l-1}w_{11}^{l} + a_{12}^{l-1}w_{12}^{l} + a_{21}^{l-1}w_{21}^{l} +   a_{22}^{l-1}w_{22}^{l} \\<br>net_{12}^{l} = a_{12}^{l-1}w_{11}^{l} + a_{13}^{l-1}w_{12}^{l} + a_{22}^{l-1}w_{21}^{l} +   a_{23}^{l-1}w_{22}^{l} \\<br>net_{21}^{l} = a_{21}^{l-1}w_{11}^{l} + a_{22}^{l-1}w_{12}^{l} + a_{31}^{l-1}w_{21}^{l} +   a_{32}^{l-1}w_{22}^{l} \\<br>net_{22}^{l} = a_{22}^{l-1}w_{11}^{l} + a_{23}^{l-1}w_{12}^{l} + a_{32}^{l-1}w_{21}^{l} +   a_{33}^{l-1}w_{22}^{l}<br>\tag{7} \label{7}<br>$$</p><p>模拟反向求导，可得</p><p>$$<br>\nabla a^{l-1} = \frac{\partial E_{total}}{\partial a^{l-1}} = \frac{\partial E_{total}}{\partial net^{l}} \frac{\partial net^{l}}{\partial a^{l-1}} = \delta^{l} \frac{\partial net^{l}}{\partial a^{l-1}}<br>\tag{8} \label{8}<br>$$</p><p>根据上式，我们将各个偏导数展开，如下：</p><p>$$<br>\begin{align}<br>&amp;\nabla a_{11}^{l-1} = \delta_{11}^{l}w_{11}^{l} \\<br>&amp;\nabla a_{12}^{l-1} = \delta_{11}^{l}w_{12}^{l} + \delta_{12}^{l}w_{11}^{l}\\<br>&amp;\nabla a_{13}^{l-1} = \delta_{12}^{l}w_{12}^{l} \\<br>&amp;\nabla a_{21}^{l-1} = \delta_{11}^{l}w_{21}^{l} + \delta_{21}^{l}w_{11}^{l}\\<br>&amp;\nabla a_{22}^{l-1} = \delta_{11}^{l}w_{22}^{l} + \delta_{12}^{l}w_{21}^{l} + \delta_{21}^{l}w_{12}^{l} + \delta_{22}^{l}w_{11}^{l} \\<br>&amp;\nabla a_{23}^{l-1} = \delta_{12}^{l}w_{22}^{l} + \delta_{22}^{l}w_{12}^{l} \\<br>&amp;\nabla a_{31}^{l-1} = \delta_{21}^{l}w_{21}^{l} \\<br>&amp;\nabla a_{32}^{l-1} = \delta_{21}^{l}w_{22}^{l} + \delta_{22}^{l}w_{21}^{l} \\<br>&amp;\nabla a_{33}^{l-1} = \delta_{22}^{l}w_{22}^{l}<br>\end{align}<br>\tag{9} \label{9}<br>$$</p><p>将上面的几个表达式用矩阵的形式转换，形式如下：</p><p>$$<br>\left( \begin{array}{ccc} 0&amp;0&amp;0&amp;0 \\<br>0&amp;\delta_{11}^{l}&amp; \delta_{12}^{l}&amp;0 \\<br>0&amp;\delta_{21}^{l}&amp;\delta_{22}^{l}&amp;0 \\<br>0&amp;0&amp;0&amp;0 \end{array} \right) * \left( \begin{array}{ccc} w_{22}^{l}&amp;w_{21}^{l}\\<br>w_{12}^{l}&amp;w_{11}^{l} \end{array} \right)<br>= \left( \begin{array}{ccc} \nabla a_{11}^{l-1}&amp;\nabla a_{12}^{l-1}&amp;\nabla a_{13}^{l-1} \\<br>\nabla a_{21}^{l-1}&amp;\nabla a_{22}^{l-1}&amp;\nabla a_{23}^{l-1}\\<br>\nabla a_{31}^{l-1}&amp;\nabla a_{32}^{l-1}&amp;\nabla a_{33}^{l-1}<br>\end{array} \right)<br>\tag{10} \label{10}<br>$$</p><p>为了符合梯度计算，我们在误差矩阵周围填充了一圈0，此时我们将卷积核翻转后和反向传播的梯度误差进行卷积，就得到了前一次的梯度误差。</p><p>由于</p><p>$$<br>net^{l}=a^{l-1} \ast W^{l}+b^{l}=f(net^{l-1}) \ast W^{l}+b^{l}<br>\tag{11} \label{11}<br>$$</p><p>可以得知</p><p>$$<br>\begin{align}<br>\delta^{l-1}<br>&amp;=\frac{ \partial E_{total}}{\partial net^{l-1}}\\<br>&amp;=\frac{ \partial E_{total}}{\partial net^{l}} \frac{ \partial net^{l}}{ \partial net^{l-1}} \\<br>&amp;= \color{ blue }{\frac{ \partial E_{total}}{\partial net^{l}} \frac{ \partial net^{l}}{ \partial a^{l-1}} } \color{red}{ \frac{ \partial a^{l-1}}{ \partial net^{l-1}}} \\<br>&amp;= \color{blue} {\delta^{l}*rot180(W^{l})} \odot  \color{red} {f^{‘}(net^{l-1})}<br>\end{align}<br>\tag{12} \label{12}<br>$$</p><p>上面分析的是误差项的传递，接下来计算误差对权值和偏置的偏导数。</p><p>$$<br>\begin{align}<br>\frac{ \partial E}{\partial W^{l}}<br>=\frac{ \partial E}{\partial net^{l}} \frac{ \partial net^{l}}{ \partial W^{l}}<br>=\delta^{l} \frac{ \partial net^{l}}{ \partial W^{l}}<br>= \color{blue} {\delta^{l}*rot180(a^{l-1})}<br>\end{align}<br>\tag{13} \label{13}<br>$$</p><p>对于权值的初始化，通常有下面三种选择：</p><ul><li>全0初始化（Bad）；</li><li>比较小的随机数（Bad）；</li><li>使用高斯分布来初始化，标准差为sqrt(2/n)，其中n为输出神经元的数量（Good）</li></ul><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>CNN是人工神经网络的一种，人工神经网络里是用BP算法将误差层层回传，利用梯度下降更新每一层的权值，CNN中也是类似，主要是掌握BP算法。OK，关于CNN的总结暂且至此吧，推导部分的公式有点复杂，敲起来很不容易，有的地方也许存在误差，后续再进行修缮！下一篇开始RNN系列学习。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://cs231n.github.io/convolutional-networks/" target="_blank" rel="noopener">CS231n Convolutional Neural Networks for Visual Recognition</a></li><li><a href="https://www.zybuluo.com/hanbingtao/note/485480" target="_blank" rel="noopener">零基础入门深度学习(4) - 卷积神经网络</a></li><li><a href="https://project.inria.fr/deeplearning/files/2016/05/session3.pdf" target="_blank" rel="noopener">https://project.inria.fr/deeplearning/files/2016/05/session3.pdf</a></li><li><a href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture5.pdf" target="_blank" rel="noopener">http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture5.pdf</a></li><li><a href="http://cogprints.org/5869/1/cnn_tutorial.pdf" target="_blank" rel="noopener">http://cogprints.org/5869/1/cnn_tutorial.pdf</a></li><li><a href="https://www.cnblogs.com/pinard/p/6494810.html#!comments" target="_blank" rel="noopener">https://www.cnblogs.com/pinard/p/6494810.html#!comments</a></li><li><a href="https://blog.csdn.net/hearthougan/article/details/72910223" target="_blank" rel="noopener">https://blog.csdn.net/hearthougan/article/details/72910223</a></li><li><a href="https://www.zybuluo.com/hanbingtao/note/485480" target="_blank" rel="noopener">https://www.zybuluo.com/hanbingtao/note/485480</a></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在&lt;a href=&quot;http://www.csuldw.com/2018/05/01/2018-05-01-backpropagation-algorithm/&quot;&gt;Deep Learning - 神经网络与BP算法&lt;/a&gt;一文中介绍了神经网络的原理，可以发现不同层之间是全连接的，当神经网络的深度、节点数变大，会导致过拟合、参数过多等问题。因此，本文将介绍另一种神经网络：CNN，卷积神经网络。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="CNN" scheme="https://www.csuldw.com/tags/CNN/"/>
    
      <category term="Deep Learning" scheme="https://www.csuldw.com/tags/Deep-Learning/"/>
    
      <category term="卷积神经网络" scheme="https://www.csuldw.com/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Deep Learning - 神经网络与BP算法</title>
    <link href="https://www.csuldw.com/2018/05/01/2018-05-01-backpropagation-algorithm/"/>
    <id>https://www.csuldw.com/2018/05/01/2018-05-01-backpropagation-algorithm/</id>
    <published>2018-05-01T15:58:00.000Z</published>
    <updated>2019-05-31T16:51:57.178Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在前面的<a href="http://www.csuldw.com/2018/01/27/2018-01-29-perceptron-theory-and-implemention/">Perceptron - 原理与实现</a>一文中介绍了神经网络的基础算法，通过该文我们初步了解了感知机的原理以及实现。本文将介绍神经网络以及训练网络使用的Backpropagation（反向传播）算法，进一步为学习深度学习打好基础。阅读之前，先说明一下，由于推导过程公式较多，在编辑过程中可能出现个别差错，如有读者发现存在纰漏，还请<a href="mailto:ldwhippo@gmail.com" target="_blank" rel="noopener">E-mail</a>告知，多谢！</p><a id="more"></a><h2 id="神经元"><a href="#神经元" class="headerlink" title="神经元"></a>神经元</h2><p>提到神经网络，首先引入一下神经元的概念。神经元和感知器在本质上是一样的，不同之处就是两者的激活函数不一样，感知器使用的是符号函数，而神经元通常使用的则是sigmoid函数。关于sigmoid函数，可以参考之前的<a href="http://www.csuldw.com/2016/09/19/2016-09-19-logistic-regression-theory/#Sigmoid_%E5%87%BD%E6%95%B0">Logistic Regression Theory</a>一文，这里就不多描述了。</p><h2 id="神经网络定义"><a href="#神经网络定义" class="headerlink" title="神经网络定义"></a>神经网络定义</h2><p>神经网络是按照一定规则连接起来的多个神经元。神经网络按照层级来布局神经元。最左边的层叫做输入层（input layer），主要负责接收输入数据；最右边的层叫输出层（output layer），可以从这一层获取神经网络输出数据。输入层与输出层之间的层叫做隐藏层，可以包含多个隐藏层，之所以叫做隐藏层，是因为它们对于外部来说是不可见的。神经网络的特征如下：</p><ul><li>位于同一层的各个神经元没有任何连接。</li><li>位于第N层的每个神经元都与第N-1层的所有神经元相连，也就是全连接（Full Connection），第N-1层神经元的输出就是第N层神经元的输入。</li><li>全连接的每个连接都有一个权值。</li></ul><p>上面这些规则定义了全连接神经网络的结构。事实上还存在很多其它结构的神经网络，比如卷积神经网络(CNN)、循环神经网络(RNN)，他们都具有不同的连接规则。</p><h2 id="基本函数"><a href="#基本函数" class="headerlink" title="基本函数"></a>基本函数</h2><p>在本文，推导过程中值得注意的几个要点：</p><ul><li>激活函数：sigmoid</li><li>误差函数：平方误差</li><li>优化方法：梯度下降，降低误差大的网络的权值，增加误差小的网络的权值。</li></ul><p>下面先来介绍几个在神经网络反向传播算法的推导过程中用到的几个函数：</p><p>1.Network function(网络函数)</p><p>The network is a particular implementation of a composite function from input to output space, which we call the network function. </p><p>$$<br>h(x)=w^T x = \sum_{i=1}^{n} w_i x_i<br>\tag{1} \label{1}<br>$$</p><p>2.Activation function(激活函数)</p><p>本文使用的激活函数为Sigmoid函数：</p><p>$$<br>y=f(z)=\frac{1}{1+e^{-z}}<br>\tag{2} \label{2}<br>$$</p><p>3.Error function：（误差函数）</p><p>采用平方误差:</p><p>$$<br>E = \frac{1}{2} \sum_{i=1}^{n}\left[ t_i -  y_i\right] ^2<br>\tag{3} \label{3}<br>$$</p><p>其中$t_i$为真实值，$y_i$为计算值，等于$f(h(x_i)) $.下面我们通过BP算法来模拟整个神经网络的计算过程。</p><p>反向传播算法用于找出误差函数的局部最小值，网络首先会随机地初始化各个权值。在计算上，通常会使用误差函数的梯度来修正权值。我们的任务就是递归地计算梯度。</p><p>首先，我们知道每个神经元都是一个感知器，对于输入层而言，$i1$和$i2$直接获取得到$x_i$的两个值，对于隐藏层和输出层，它们的每个神经元都是上一层的一个全连接，即：</p><p>$$h(x) = \sum_{i=1}^{n} w_i x_i$$</p><h2 id="原理推导"><a href="#原理推导" class="headerlink" title="原理推导"></a>原理推导</h2><h3 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h3><p>首先，我们来看看下面这张图：</p><!-- ![](https://blog.webkid.io/content/images/old/neural-networks-in-javascript/nn_blog.png) --><p><img src="/assets/articleImg/Colored_neural_network.svg" alt=""><br>上图展示的是一个经典的三层神经网络，包括输入层、隐藏层、输出层。为了体现一般性，现在我们用数学语言进行描述：</p><p>给定一个训练集$\{(x_1, t_1), (x_2, t_2), …, (x_n, t_n)\}$，目标变量$t_i$的取值可以有多个，其中$x_i$是一个$m$维向量（对应输入层的$m$个神经元），表达式为$x_i=(x_{i1}, x_{i2},…, x_{im})$。我们将输入层、隐藏层、输出层合并在一起，就形成了一个<strong>network</strong>。在这个network里，除输入层外，其他层上的每个神经元都是上一层神经元的全连接，不同的是全连接的权值不一样。现在，我们需要通过训练，来求出各个神经元的权重值，也就是$w$。</p><p>那么现在的问题是，这些权值应该如何计算呢？</p><p><img src="/assets/articleImg/bp-frame.png" alt=""></p><p>刚刚说到，<strong>除输入层外，其他层上的每个神经元都是上一层神经元的全连接</strong>,比如隐藏层$h1$，是隐藏层的第一个神经元，它的输出值是输入层的全连接，即：</p><p>$$<br>h_1 = f(\vec{w}_{1}^{(1)}\centerdot\vec{x})<br>\tag{4}\label{4}<br>$$</p><p>$$<br>net_{1}^{(1)} = w_{11}^{(1)} x_1 + w_{12}^{(1)} x_2 + w_{13}^{(1)} x_3 + b_{1}^{(1)}<br>\tag{5}\label{5}<br>$$</p><p>其中$f$为$sigmoid$函数，$\vec{w}_{ij}^{(1)}$表示隐藏层的第$i$个节点与输入层的第$j$个节点的权重值，$b_{i}^{(1)}$表示第$i$个隐藏层全连接中的偏置，$x_i$为输入层的值，即样本的输入值。</p><p>类似的，可以计算出$h_2$、$h_3$、$h_4$。</p><p>$$<br>h_1 = f(w_{11}^{(1)} x_1 + w_{12}^{(1)} x_2 + w_{13}^{(1)} x_3 + b_{1}^{(1)}) \\<br>h_2 = f(w_{21}^{(1)} x_1 + w_{22}^{(1)} x_2 + w_{23}^{(1)} x_3 + b_{2}^{(1)}) \\<br>h_3 = f(w_{31}^{(1)} x_1 + w_{32}^{(1)} x_2 + w_{33}^{(1)} x_3 + b_{3}^{(1)}) \\<br>h_4 = f(w_{41}^{(1)} x_1 + w_{42}^{(1)} x_2 + w_{43}^{(1)} x_3 + b_{4}^{(1)})<br>$$</p><p>因此，我们可以将隐藏层表示为如下通式：</p><p>$$<br>\vec{h}=f(net^{(1)})=f(\vec{w}^{(1)}\cdot\vec{x})<br>\tag{6}\label{6}<br>$$</p><p>$$<br>\vec{w}^{(1)}=<br>\begin{bmatrix}<br>\vec{w}_{1}^{(1)} \\<br>\vec{w}_{2}^{(1)} \\<br>\vec{w}_{3}^{(1)} \\<br>\vec{w}_{4}^{(1)} \\<br>\end{bmatrix}=<br>\begin{bmatrix}<br>w_{11}^{(1)},w_{12}^{(1)},w_{13}^{(1)},b_{1}^{(1)} \\<br>w_{21}^{(1)},w_{22}^{(1)},w_{23}^{(1)},b_{2}^{(1)} \\<br>w_{31}^{(1)},w_{32}^{(1)},w_{33}^{(1)},b_{3}^{(1)} \\<br>w_{41}^{(1)},w_{42}^{(1)},w_{43}^{(1)},b_{4}^{(1)} \\<br>\end{bmatrix}<br>$$</p><p>对于输出层，也是同样的计算方式，只不过对于输出层而言，它们的输入为隐藏层的输出，即$\vec{h}$，输出层的表达式为：</p><p>$$<br>\vec{y}=f(\vec{w}^{(2)}\cdot\vec{h})<br>$$</p><p>$$<br>\vec{w}^{(2)}=<br>\begin{bmatrix}<br>\vec{w}_{1}^{(2)} \\<br>\vec{w}_{2}^{(2)} \\<br>\end{bmatrix}=<br>\begin{bmatrix}<br>w_{11}^{(2)},w_{12}^{(2)},w_{13}^{(2)}, w_{14}^{(2)},b_{1}^{(2)} \\<br>w_{21}^{(2)},w_{22}^{(2)},w_{23}^{(2)}, w_{24}^{(2)},b_{2}^{(2)} \\<br>\end{bmatrix}<br>$$</p><p>$$<br>y_1 = f(w_{11}^{(2)} h_1 + w_{12}^{(2)} h_2 + w_{13}^{(2)} h_3 + w_{13}^{(2)} h_4+ b_{1}^{(2)}) \\<br>y_2 = f(w_{21}^{(2)} h_1 + w_{22}^{(2)} h_2 + w_{23}^{(2)} h_3 + w_{13}^{(2)} h_4+ b_{2}^{(2)}) \\<br>$$</p><p>即：</p><p>$$<br>\vec{y}_i=f(net_i^{(2)})=f(\sum_{j=1} w_{ij}^{(2)}h_j + b_j^{(2)})<br>\tag{7}\label{7}<br>$$</p><p>上述部分属于feed-forward部分，从前往后依次计算出各个输出层，最后求得$y$。但是值得注意的是，这些权值还未知呢，计算权值还得继续往下看，接下来通过BP算法来逐步更新权值。</p><h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><p>首先，我们对所有的权值$w$，给定一个初始值， 然后根据前向传播的方式来计算出输出值$y$，为了评估此次训练模型是否合理，我们取网络所有输出层节点的误差平方和作为目标函数，对于样本$k$，其误差表达式为：</p><p>$$<br>E_{k} = \frac{1}{2} \sum_{j=1}^{output}\left [ t_j-  y_j \right ] ^2<br>\tag{8}\label{8}<br>$$</p><p>有了目标函数之后，现在我们采用梯度下降来寻找最优解。</p><p><strong>1）输出层</strong></p><p>对于输出层节点，第$i$个输出节点与第$j$个隐藏节点的权值更新规则为：</p><p>$$<br>w_{ij}^{(2)}\gets w_{ij}^{(2)}-\eta\frac{\partial{E_k}}{\partial{w_{ij}}}<br>\tag{9}\label{9}<br>$$</p><p>其中$\eta$为学习率，由于$E_k$是$y_i$的函数，$y_i$是$net$的函数，$net$是$w_{ij}$的函数，如下图，根据链式求导法则，有：</p><p><img src="/assets/articleImg/bp-output.png" alt=""></p><p>$$<br>\frac{\partial{E_k}}{\partial{w_{ij}}} = \frac{\partial{E_k}}{\partial{ y_i }} \frac{\partial{y_i}}{\partial{net_{i}}} \frac{\partial{net_{i}}}{\partial{w_{ij}}}<br>\tag{10}\label{10}<br>$$</p><p>根据上述公式，可以分别求出偏导数：</p><p>$$<br>\begin{align}<br>\frac{\partial{E_k}}{\partial{y_i}}<br>&amp;=\frac{\partial}{\partial{y_i}} \left [\frac{1}{2}\sum_{j}^{outputs}(t_j-y_j)^2 \right ] \\<br>&amp;=\frac{\partial}{\partial{y_i}} \left [\frac{1}{2}(t_j-y_j)^2 \right ]_{j=i} + \frac{\partial}{\partial{y_i}} \left [\frac{1}{2}\sum_{j}^{outputs}(t_j-y_j)^2 \right ]_{\color{red}{j \neq i}} \\<br>&amp;=\frac{\partial}{\partial{y_i}} \left [ \frac{1}{2}(t_i-y_i)^2 \right ] + 0\\<br>&amp;=-(t_i-y_i)<br>\end{align}<br>$$</p><p>$$<br>\frac{\partial{y_i}}{\partial{net_{i}}} =y_i(1-y_i)<br>$$</p><p>$$<br>\frac{\partial{net_{i}}}{\partial{w_{ij}}} = h_j<br>$$</p><p>由此可得，</p><p>$$<br>\begin{align}<br>\frac{\partial{E_k}}{\partial{w_{ij}}} = -(t_i-y_i) \cdot y_i(1-y_i) \cdot h_j<br>\end{align}<br>\tag{11}\label{11}<br>$$</p><p>令$\delta_i=\frac{\partial{E_k}}{\partial{net_i}}=-(t_i-y_i) \cdot y_i(1-y_i)$，（表示误差项，实际上是网络的损失函数$E_{k}$对神经元输入网络的偏导数）则：</p><p>$$<br>w_{ij}^{(2)} = w_{ij}^{(2)} - \eta \delta_i h_j<br>\tag{12}\label{12}<br>$$</p><p><strong>2）隐藏层</strong></p><p>首先，对于隐藏层的任意一个神经元，输出层的每个神经单元的误差对其都有影响。因此，对于隐藏层第$i$个神经元，它与输入层的第$j$个神经元的权值更新规则为：</p><p>$$<br>w_{ij}^{(1)}\gets w_{ij}^{(1)}-\eta \color{red}{\frac{\partial{E_k}}{\partial{w_{ij}}}}<br>$$</p><p>接着由链式法则，我们对上面红色部分进行展开：</p><p>$$<br>\begin{align}<br>\frac{\partial{E_k}}{\partial{w_{ij}}}<br>&amp;= \frac{ \partial{}}{\partial{w_{ij}}} \left ( \sum_s^{outputs} E_s \right ) \\<br>&amp;= \sum_s^{outputs}<br>    \frac{ \partial{  E_s }}{\partial{net^{(2)}_{s}}}<br>    \frac{ \partial{  net^{(2)}_{s} }}{\partial{  net^{(1)}_{i} }}<br>    \frac{ \partial{  net^{(1)}_{i} }}{\partial{w_{ij}}} \\<br>&amp;= \sum_s^{outputs} \left ( -\delta_{s} \cdot<br>    \frac{ \partial{  net^{(2)}_{s} }}{\partial{  net^{(1)}_{i} }}<br>    \frac{ \partial{  net^{(1)}_{i} }}{\partial{w_{ij}}}     \right ) \\<br>&amp;= \sum_s^{outputs} \left ( -\delta_{s} \cdot<br>    \frac{ \partial{  net^{(2)}_{s} }}{\partial{  h_{i} }}<br>    \frac{ \partial{  h_{i} }}{\partial{  net^{(1)}_{i} }}<br>    \frac{ \partial{  net^{(1)}_{i} }}{\partial{w_{ij}}}  \right )    \\<br>&amp;= \sum_s^{outputs} \left ( -\delta_{s} \cdot<br>    w_{si} \cdot<br>    \frac{ \partial{  h_{i} }}{\partial{  net^{(1)}_{i} }}<br>    \frac{ \partial{  net^{(1)}_{i} }}{\partial{w_{ij}}}  \right )    \\<br>&amp;= \sum_s^{outputs} \left ( -\delta_{s} \cdot<br>    w_{si} \cdot<br>    h_i(1-h_i)\cdot<br>    \frac{ \partial{  net^{(1)}_{i} }}{\partial{w_{ij}}}  \right )    \\<br>&amp;= \sum_s^{outputs} \left ( -\delta_{s}<br>    w_{si}<br>    h_i(1-h_i)<br>    x_j  \right )    \\<br>&amp;= -h_i(1-h_i) \left ( \sum_s^{outputs}  \delta_{s}  w_{si}   \right ) x_j<br>\end{align}<br>$$</p><p>带入到上式，得到隐藏层的权值更新公式：</p><p>$$<br>w_{ij}^{(1)} = w_{ij}^{(1)}+\eta h_i(1-h_i) \left ( \sum_s^{outputs}  \delta_{s}  w_{si}   \right ) x_j<br>\tag{13}\label{13}<br>$$</p><p>令$\delta_i=\frac{\partial{E_k}}{\partial{net_i}}=-h_i(1-h_i) \left ( \sum_s \delta_{s}  w_{si}   \right ) $，则公式简化为：</p><p>$$<br>w_{ij}^{(1)} = w_{ij}^{(1)}- \eta \delta_i x_j<br>\tag{14}\label{14}<br>$$</p><h3 id="权值更新归纳"><a href="#权值更新归纳" class="headerlink" title="权值更新归纳"></a>权值更新归纳</h3><p>通过BP推导，现在我们知道如何更新权值了，下面来总结一下。假定每个节点的误差项为$\delta_i$，不管是隐藏节点还是输出节点，其输出值统一使用$x_{j}$来表示，那么权值更新规则为：</p><p>$$<br>w_{ij} \gets w_{ij} - \eta \delta_i x_j<br>\tag{15} \label{15}<br>$$</p><p>当节点为输出层神经元时，</p><p>$$<br>\delta_i= - y_i(1-y_i)(t_i-y_i)<br>\tag{15-1} \label{15-1}<br>$$</p><p>当节点为隐藏层神经元时，</p><p>$$<br>\delta_i = - h_i(1-h_i) \left ( \sum_s \delta_{s}  w_{si}   \right )<br>\tag{15-2} \label{15-2}<br>$$</p><p>其中，$\delta_{i}$ 是节点的误差项，$y_{i}$是输出节点的输出值，$t_{i}$是样本$i$对应的目标值，$h_{i}$为隐藏节点的输出值。</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>在实际编码中，整个参数训练过程大致如下：</p><ol><li>初始化权值；</li><li>根据前向传播算法计算出输出层的输出，并计算出误差;</li><li>判断误差是否小于某个阈值，</li><li>误差满足阈值条件，则终止训练；</li><li>误差太大，则使用反向传播来更新权值，并转至步骤2，循环执行。</li></ol><p>OK，终于完成了BP算法的推导过程，说实在的，公式敲得真是累人，不过看着充满逻辑的公式，心里还真有点成就感。关于具体的例子，可参考<a href="https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/" target="_blank" rel="noopener">A Step by Step Backpropagation Example</a>一文。至此，深度学习的大门似乎已经慢慢打开了，接下来，开始探索深度学习更深层的奥秘吧！</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://page.mi.fu-berlin.de/rojas/neural/" target="_blank" rel="noopener">Neural Networks - A Systematic Introduction</a></li><li><a href="https://page.mi.fu-berlin.de/rojas/neural/chapter/K7.pdf" target="_blank" rel="noopener">The Backpropagation Algorithm</a></li><li><a href="https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/" target="_blank" rel="noopener">A Step by Step Backpropagation Example</a></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在前面的&lt;a href=&quot;http://www.csuldw.com/2018/01/27/2018-01-29-perceptron-theory-and-implemention/&quot;&gt;Perceptron - 原理与实现&lt;/a&gt;一文中介绍了神经网络的基础算法，通过该文我们初步了解了感知机的原理以及实现。本文将介绍神经网络以及训练网络使用的Backpropagation（反向传播）算法，进一步为学习深度学习打好基础。阅读之前，先说明一下，由于推导过程公式较多，在编辑过程中可能出现个别差错，如有读者发现存在纰漏，还请&lt;a href=&quot;mailto:ldwhippo@gmail.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;E-mail&lt;/a&gt;告知，多谢！&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="https://www.csuldw.com/tags/Deep-Learning/"/>
    
      <category term="神经网络" scheme="https://www.csuldw.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="backpropagation" scheme="https://www.csuldw.com/tags/backpropagation/"/>
    
      <category term="反向传播" scheme="https://www.csuldw.com/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/"/>
    
  </entry>
  
  <entry>
    <title>Spring+Mybatis+Mysql接口层读写分离(应用篇)</title>
    <link href="https://www.csuldw.com/2018/03/20/2018-03-20-spring-mybatis-read-write-seperation-part2/"/>
    <id>https://www.csuldw.com/2018/03/20/2018-03-20-spring-mybatis-read-write-seperation-part2/</id>
    <published>2018-03-20T15:22:00.000Z</published>
    <updated>2018-04-09T13:49:42.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>在<a href="http://www.csuldw.com/2018/03/13/2018-03-13-spring-mybatis-read-write-seperation/">上一篇文章</a>中已经介绍过读写分离，并且通过代码也已实现局部的读写分离。为什么说是局部的呢？首先，来分析下，针对上一篇文章中提到的方法，如果在service层没有配置事务，那么当程序走到Dao层时，就可以根据自己定义的规则进行读写分离；倘若在service层配置了事物，那么在Dao切换数据库key的时候，是无法正真的进行读写分离的。因此，通过进一步的研究和尝试，找到了一种新的方法来实现真正意义上的Dao层读写分离，该方法可以在事务内部直接切换数据库，达到读写分库的功能。</p><a id="more"></a><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>上一篇文章中介绍的方法，对存在事务的方法使用分库功能，无法成功，主要是因为Service层进入事务之后，在内部切换数据库Key无法正确。因此，继续深入，发现另一种方法是切换SqlSessionFactory，可以达到分库的效果。Spring整合MyBatis切换SqlSessionFactory有两种方法，第一种是继承SqlSessionDaoSupport，然后重写获取SqlSessionFactory的方法；第二中是继承SqlSessionTemplate，然后重写getSqlSessionFactory、getConfiguration 和SqlSessionInterceptor 这个拦截器。其中最为关键还是继承SqlSessionTemplate 并重写里面的方法。整个读写分离可归纳为以下三个步骤：</p><ul><li>Step 1：实现动态切换数据源：配置两个DataSource，配置两个SqlSessionFactory指向两个不同的DataSource，两个SqlSessionFactory都用一个SqlSessionTemplate，同时重写Mybatis提供的SqlSessionTemplate类，最后配置Mybatis自动扫描。</li><li>Step 2：利用aop切面，拦截dao层所有方法，因为dao层方法命名的特点，比如所有查询sql都是select开头，或者get开头等等，拦截这些方法，并把当前数据源切换至从库。</li><li>Step 3：由于在事务内部进行了分库，所以需要引入atomikos进行多事务分布式管理。</li></ul><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="重写SqlSessionTemplate"><a href="#重写SqlSessionTemplate" class="headerlink" title="重写SqlSessionTemplate"></a>重写SqlSessionTemplate</h3><p>DynamicSqlSessionTemplate类继承SqlSessionTemplate，并重写getSqlSessionFactory、getConfiguration和SqlSessionInterceptor这个拦截器。代码如下：</p><ol><li>DynamicSqlSessionTemplate.java</li></ol><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.test.dlab.aop.core;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> java.lang.reflect.Proxy.newProxyInstance;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.apache.ibatis.reflection.ExceptionUtil.unwrapThrowable;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.mybatis.spring.SqlSessionUtils.closeSqlSession;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.mybatis.spring.SqlSessionUtils.getSqlSession;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.mybatis.spring.SqlSessionUtils.isSqlSessionTransactional;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.InvocationHandler;</span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.Method;</span><br><span class="line"><span class="keyword">import</span> java.sql.Connection;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.exceptions.PersistenceException;</span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.executor.BatchResult;</span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.session.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.session.ExecutorType;</span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.session.ResultHandler;</span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.session.RowBounds;</span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.session.SqlSession;</span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.session.SqlSessionFactory;</span><br><span class="line"><span class="keyword">import</span> org.mybatis.spring.MyBatisExceptionTranslator;</span><br><span class="line"><span class="keyword">import</span> org.mybatis.spring.SqlSessionTemplate;</span><br><span class="line"><span class="keyword">import</span> org.springframework.dao.support.PersistenceExceptionTranslator;</span><br><span class="line"><span class="keyword">import</span> org.springframework.util.Assert;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> liudiwei</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DynamicSqlSessionTemplate</span> <span class="keyword">extends</span> <span class="title">SqlSessionTemplate</span> </span>{</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> SqlSessionFactory sqlSessionFactory;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ExecutorType executorType;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> SqlSession sqlSessionProxy;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> PersistenceExceptionTranslator exceptionTranslator;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">private</span> Map&lt;Object, SqlSessionFactory&gt; targetSqlSessionFactorys;</span><br><span class="line">    <span class="keyword">private</span> SqlSessionFactory defaultTargetSqlSessionFactory;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setTargetSqlSessionFactorys</span><span class="params">(Map&lt;Object, SqlSessionFactory&gt; targetSqlSessionFactorys)</span> </span>{</span><br><span class="line">        <span class="keyword">this</span>.targetSqlSessionFactorys = targetSqlSessionFactorys;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> Map&lt;Object, SqlSessionFactory&gt; <span class="title">getTargetSqlSessionFactorys</span><span class="params">()</span></span>{</span><br><span class="line">        <span class="keyword">return</span> targetSqlSessionFactorys;</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setDefaultTargetSqlSessionFactory</span><span class="params">(SqlSessionFactory defaultTargetSqlSessionFactory)</span> </span>{</span><br><span class="line">        <span class="keyword">this</span>.defaultTargetSqlSessionFactory = defaultTargetSqlSessionFactory;</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DynamicSqlSessionTemplate</span><span class="params">(SqlSessionFactory sqlSessionFactory)</span> </span>{</span><br><span class="line">        <span class="keyword">this</span>(sqlSessionFactory, sqlSessionFactory.getConfiguration().getDefaultExecutorType());</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DynamicSqlSessionTemplate</span><span class="params">(SqlSessionFactory sqlSessionFactory, ExecutorType executorType)</span> </span>{</span><br><span class="line">        <span class="keyword">this</span>(sqlSessionFactory, executorType, <span class="keyword">new</span> MyBatisExceptionTranslator(sqlSessionFactory.getConfiguration()</span><br><span class="line">                .getEnvironment().getDataSource(), <span class="keyword">true</span>));</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DynamicSqlSessionTemplate</span><span class="params">(SqlSessionFactory sqlSessionFactory, ExecutorType executorType,</span></span></span><br><span class="line"><span class="function"><span class="params">            PersistenceExceptionTranslator exceptionTranslator)</span> </span>{</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">super</span>(sqlSessionFactory, executorType, exceptionTranslator);</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">this</span>.sqlSessionFactory = sqlSessionFactory;</span><br><span class="line">        <span class="keyword">this</span>.executorType = executorType;</span><br><span class="line">        <span class="keyword">this</span>.exceptionTranslator = exceptionTranslator;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">this</span>.sqlSessionProxy = (SqlSession) newProxyInstance(</span><br><span class="line">                SqlSessionFactory<span class="class">.<span class="keyword">class</span>.<span class="title">getClassLoader</span>(),</span></span><br><span class="line">                new Class[] { SqlSession.class }, </span><br><span class="line">                <span class="keyword">new</span> SqlSessionInterceptor());</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">this</span>.defaultTargetSqlSessionFactory = sqlSessionFactory;</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SqlSessionFactory <span class="title">getSqlSessionFactory</span><span class="params">()</span> </span>{</span><br><span class="line"> </span><br><span class="line">        SqlSessionFactory targetSqlSessionFactory = targetSqlSessionFactorys.get(SqlSessionContentHolder.getContextType());</span><br><span class="line">        <span class="keyword">if</span> (targetSqlSessionFactory != <span class="keyword">null</span>) {</span><br><span class="line">            <span class="keyword">return</span> targetSqlSessionFactory;</span><br><span class="line">        } <span class="keyword">else</span> <span class="keyword">if</span> (defaultTargetSqlSessionFactory != <span class="keyword">null</span>) {</span><br><span class="line">            <span class="keyword">return</span> defaultTargetSqlSessionFactory;</span><br><span class="line">        } <span class="keyword">else</span> {</span><br><span class="line">            Assert.notNull(targetSqlSessionFactorys, <span class="string">"Property 'targetSqlSessionFactorys' or 'defaultTargetSqlSessionFactory' are required"</span>);</span><br><span class="line">            Assert.notNull(defaultTargetSqlSessionFactory, <span class="string">"Property 'defaultTargetSqlSessionFactory' or 'targetSqlSessionFactorys' are required"</span>);</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.sqlSessionFactory;</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Configuration <span class="title">getConfiguration</span><span class="params">()</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.getSqlSessionFactory().getConfiguration();</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> ExecutorType <span class="title">getExecutorType</span><span class="params">()</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.executorType;</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> PersistenceExceptionTranslator <span class="title">getPersistenceExceptionTranslator</span><span class="params">()</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.exceptionTranslator;</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> &lt;T&gt; <span class="function">T <span class="title">selectOne</span><span class="params">(String statement)</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.sqlSessionProxy.&lt;T&gt; selectOne(statement);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> &lt;T&gt; <span class="function">T <span class="title">selectOne</span><span class="params">(String statement, Object parameter)</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.sqlSessionProxy.&lt;T&gt; selectOne(statement, parameter);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> &lt;K, V&gt; <span class="function">Map&lt;K, V&gt; <span class="title">selectMap</span><span class="params">(String statement, String mapKey)</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.sqlSessionProxy.&lt;K, V&gt; selectMap(statement, mapKey);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> &lt;K, V&gt; <span class="function">Map&lt;K, V&gt; <span class="title">selectMap</span><span class="params">(String statement, Object parameter, String mapKey)</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.sqlSessionProxy.&lt;K, V&gt; selectMap(statement, parameter, mapKey);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> &lt;K, V&gt; <span class="function">Map&lt;K, V&gt; <span class="title">selectMap</span><span class="params">(String statement, Object parameter, String mapKey, RowBounds rowBounds)</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.sqlSessionProxy.&lt;K, V&gt; selectMap(statement, parameter, mapKey, rowBounds);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> &lt;E&gt; <span class="function">List&lt;E&gt; <span class="title">selectList</span><span class="params">(String statement)</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.sqlSessionProxy.&lt;E&gt; selectList(statement);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> &lt;E&gt; <span class="function">List&lt;E&gt; <span class="title">selectList</span><span class="params">(String statement, Object parameter)</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.sqlSessionProxy.&lt;E&gt; selectList(statement, parameter);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> &lt;E&gt; <span class="function">List&lt;E&gt; <span class="title">selectList</span><span class="params">(String statement, Object parameter, RowBounds rowBounds)</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.sqlSessionProxy.&lt;E&gt; selectList(statement, parameter, rowBounds);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">select</span><span class="params">(String statement, ResultHandler handler)</span> </span>{</span><br><span class="line">        <span class="keyword">this</span>.sqlSessionProxy.select(statement, handler);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">select</span><span class="params">(String statement, Object parameter, ResultHandler handler)</span> </span>{</span><br><span class="line">        <span class="keyword">this</span>.sqlSessionProxy.select(statement, parameter, handler);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">select</span><span class="params">(String statement, Object parameter, RowBounds rowBounds, ResultHandler handler)</span> </span>{</span><br><span class="line">        <span class="keyword">this</span>.sqlSessionProxy.select(statement, parameter, rowBounds, handler);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">insert</span><span class="params">(String statement)</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.sqlSessionProxy.insert(statement);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">insert</span><span class="params">(String statement, Object parameter)</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.sqlSessionProxy.insert(statement, parameter);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">update</span><span class="params">(String statement)</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.sqlSessionProxy.update(statement);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">update</span><span class="params">(String statement, Object parameter)</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.sqlSessionProxy.update(statement, parameter);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">delete</span><span class="params">(String statement)</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.sqlSessionProxy.delete(statement);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">delete</span><span class="params">(String statement, Object parameter)</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.sqlSessionProxy.delete(statement, parameter);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> &lt;T&gt; <span class="function">T <span class="title">getMapper</span><span class="params">(Class&lt;T&gt; type)</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> getConfiguration().getMapper(type, <span class="keyword">this</span>);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">commit</span><span class="params">()</span> </span>{</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException(<span class="string">"Manual commit is not allowed over a Spring managed SqlSession"</span>);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">commit</span><span class="params">(<span class="keyword">boolean</span> force)</span> </span>{</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException(<span class="string">"Manual commit is not allowed over a Spring managed SqlSession"</span>);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rollback</span><span class="params">()</span> </span>{</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException(<span class="string">"Manual rollback is not allowed over a Spring managed SqlSession"</span>);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rollback</span><span class="params">(<span class="keyword">boolean</span> force)</span> </span>{</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException(<span class="string">"Manual rollback is not allowed over a Spring managed SqlSession"</span>);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>{</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException(<span class="string">"Manual close is not allowed over a Spring managed SqlSession"</span>);</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">clearCache</span><span class="params">()</span> </span>{</span><br><span class="line">        <span class="keyword">this</span>.sqlSessionProxy.clearCache();</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Connection <span class="title">getConnection</span><span class="params">()</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.sqlSessionProxy.getConnection();</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * {<span class="doctag">@inheritDoc</span>}</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@since</span> 1.0.2</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;BatchResult&gt; <span class="title">flushStatements</span><span class="params">()</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.sqlSessionProxy.flushStatements();</span><br><span class="line">    }</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Proxy needed to route MyBatis method calls to the proper SqlSession got from Spring's Transaction Manager It also</span></span><br><span class="line"><span class="comment">     * unwraps exceptions thrown by {<span class="doctag">@code</span> Method#invoke(Object, Object...)} to pass a {<span class="doctag">@code</span> PersistenceException} to</span></span><br><span class="line"><span class="comment">     * the {<span class="doctag">@code</span> PersistenceExceptionTranslator}.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">SqlSessionInterceptor</span> <span class="keyword">implements</span> <span class="title">InvocationHandler</span> </span>{</span><br><span class="line">        <span class="function"><span class="keyword">public</span> Object <span class="title">invoke</span><span class="params">(Object proxy, Method method, Object[] args)</span> <span class="keyword">throws</span> Throwable </span>{</span><br><span class="line">            <span class="keyword">final</span> SqlSession sqlSession = getSqlSession(</span><br><span class="line">                    DynamicSqlSessionTemplate.<span class="keyword">this</span>.getSqlSessionFactory(),</span><br><span class="line">                    DynamicSqlSessionTemplate.<span class="keyword">this</span>.executorType, </span><br><span class="line">                    DynamicSqlSessionTemplate.<span class="keyword">this</span>.exceptionTranslator);</span><br><span class="line">            <span class="keyword">try</span> {</span><br><span class="line">                Object result = method.invoke(sqlSession, args);</span><br><span class="line">                <span class="keyword">if</span> (!isSqlSessionTransactional(sqlSession, DynamicSqlSessionTemplate.<span class="keyword">this</span>.getSqlSessionFactory())) {</span><br><span class="line">                    <span class="comment">// force commit even on non-dirty sessions because some databases require</span></span><br><span class="line">                    <span class="comment">// a commit/rollback before calling close()</span></span><br><span class="line">                    sqlSession.commit(<span class="keyword">true</span>);</span><br><span class="line">                }</span><br><span class="line">                <span class="keyword">return</span> result;</span><br><span class="line">            } <span class="keyword">catch</span> (Throwable t) {</span><br><span class="line">                Throwable unwrapped = unwrapThrowable(t);</span><br><span class="line">                <span class="keyword">if</span> (DynamicSqlSessionTemplate.<span class="keyword">this</span>.exceptionTranslator != <span class="keyword">null</span> &amp;&amp; unwrapped <span class="keyword">instanceof</span> PersistenceException) {</span><br><span class="line">                    Throwable translated = DynamicSqlSessionTemplate.<span class="keyword">this</span>.exceptionTranslator</span><br><span class="line">                        .translateExceptionIfPossible((PersistenceException) unwrapped);</span><br><span class="line">                    <span class="keyword">if</span> (translated != <span class="keyword">null</span>) {</span><br><span class="line">                        unwrapped = translated;</span><br><span class="line">                    }</span><br><span class="line">                }</span><br><span class="line">                <span class="keyword">throw</span> unwrapped;</span><br><span class="line">            } <span class="keyword">finally</span> {</span><br><span class="line">                closeSqlSession(sqlSession, DynamicSqlSessionTemplate.<span class="keyword">this</span>.getSqlSessionFactory());</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>下面定义SqlSessionContentHolder类，使用ThreadLocal技术来记录当前线程中的sessionFactory的key。</p><ol start="2"><li>SqlSessionContentHolder.java</li></ol><p>SqlSessionContentHolder主要用于设置SqlSessionFactory的类型.</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.test.dlab.aop.core;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">SqlSessionContentHolder</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">static</span> String SESSION_FACTORY_MASTER = <span class="string">"master"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">static</span> String SESSION_FACTORY_SLAVE = <span class="string">"slave"</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> ThreadLocal&lt;String&gt; contextHolder = <span class="keyword">new</span> ThreadLocal&lt;String&gt;();  </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">setContextType</span><span class="params">(String contextType)</span> </span>{  </span><br><span class="line">        contextHolder.set(contextType);  </span><br><span class="line">    }  </span><br><span class="line">      </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getContextType</span><span class="params">()</span> </span>{  </span><br><span class="line">        <span class="keyword">return</span> contextHolder.get();  </span><br><span class="line">    }  </span><br><span class="line">      </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">clearContextType</span><span class="params">()</span> </span>{  </span><br><span class="line">        contextHolder.remove();  </span><br><span class="line">    } </span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2 id="定义数据源的AOP切面"><a href="#定义数据源的AOP切面" class="headerlink" title="定义数据源的AOP切面"></a>定义数据源的AOP切面</h2><p>定义数据源的AOP切面，通过该Dao的方法名判断是应该走读库还是写库。</p><h3 id="DynamicDataSourceAspect-java"><a href="#DynamicDataSourceAspect-java" class="headerlink" title="DynamicDataSourceAspect.java"></a>DynamicDataSourceAspect.java</h3><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.test.dlab.aop.core;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang3.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.JoinPoint;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.annotation.Aspect;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Aspect</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DynamicDataSourceAspect</span></span></span><br><span class="line"><span class="class"></span>{</span><br><span class="line"></span><br><span class="line">    Logger log = Logger.getLogger(DynamicDataSourceAspect<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String[] slaveMethodPrefixList = <span class="keyword">new</span> String[]</span><br><span class="line">            { <span class="string">"quer"</span>, <span class="string">"find"</span>, <span class="string">"get"</span>, <span class="string">"check"</span>, <span class="string">"sum"</span>, <span class="string">"list"</span>, <span class="string">"is"</span>, <span class="string">"count"</span>, <span class="string">"load"</span> };</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">pointCut</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>{</span><br><span class="line"></span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">before</span><span class="params">(JoinPoint jp)</span></span></span><br><span class="line"><span class="function">    </span>{</span><br><span class="line">        String methodName = jp.getSignature().getName();</span><br><span class="line">        </span><br><span class="line">        log.info(<span class="string">"当前方法名为 | MethodName: "</span> + methodName);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// dao方法查询走从库</span></span><br><span class="line">        <span class="keyword">if</span>(StringUtils.startsWithAny(methodName, slaveMethodPrefixList))</span><br><span class="line">        <span class="comment">//if (methodName.startsWith("query") || methodName.startsWith("get") || methodName.startsWith("count") || methodName.startsWith("list"))</span></span><br><span class="line">        {</span><br><span class="line">            log.info(<span class="string">"设置sessionFactory："</span> + SqlSessionContentHolder.SESSION_FACTORY_SLAVE);</span><br><span class="line">            SqlSessionContentHolder.setContextType(SqlSessionContentHolder.SESSION_FACTORY_SLAVE);</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        {</span><br><span class="line">            log.info(<span class="string">"设置sessionFactory："</span> + SqlSessionContentHolder.SESSION_FACTORY_MASTER);</span><br><span class="line">            SqlSessionContentHolder.setContextType(SqlSessionContentHolder.SESSION_FACTORY_MASTER);</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><h3 id="配置db-properties"><a href="#配置db-properties" class="headerlink" title="配置db.properties"></a>配置db.properties</h3><p>在db.properties配置文件中增加主库和从库的信息，这里master为主库，slave为从库，具体内容如下：</p><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">jdbc.master.driver=com.mysql.jdbc.Driver</span><br><span class="line">jdbc.master.url=jdbc:mysql://10.88.184.156:3306/resource_manage?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true</span><br><span class="line">jdbc.master.username=root</span><br><span class="line">jdbc.master.password=test</span><br><span class="line"></span><br><span class="line">jdbc.slave01.driver=com.mysql.jdbc.Driver</span><br><span class="line">jdbc.slave01.url=jdbc:mysql://127.0.0.1:3306/resource_manage?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true</span><br><span class="line">jdbc.slave01.username=root</span><br><span class="line">jdbc.slave01.password=123456</span><br></pre></td></tr></tbody></table></figure><h3 id="添加主从数据库连接池"><a href="#添加主从数据库连接池" class="headerlink" title="添加主从数据库连接池"></a>添加主从数据库连接池</h3><p>修改applicationContext.xml，masterDataSource和slaveDataSource。</p><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 主从数据库配置  part1 start --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置连接池 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"masterDataSource"</span> <span class="attr">class</span>=<span class="string">"com.mchange.v2.c3p0.ComboPooledDataSource"</span> <span class="attr">destroy-method</span>=<span class="string">"close"</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 数据库驱动 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"driverClass"</span> <span class="attr">value</span>=<span class="string">"${jdbc.master.driver}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 相应驱动的jdbcUrl --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"jdbcUrl"</span> <span class="attr">value</span>=<span class="string">"${jdbc.master.url}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 数据库的用户名 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"user"</span> <span class="attr">value</span>=<span class="string">"${jdbc.master.username}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 数据库的密码 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"password"</span> <span class="attr">value</span>=<span class="string">"${jdbc.master.password}"</span> /&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!--初始化时获取三个连接，取值应在minPoolSize与maxPoolSize之间。Default: 3 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"initialPoolSize"</span> <span class="attr">value</span>=<span class="string">"${jdbc.initialPoolSize}"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--连接池中保留的最大连接数。Default: 15 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"maxPoolSize"</span> <span class="attr">value</span>=<span class="string">"${jdbc.maxPoolSize}"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--连接池中保留的最小连接数。 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"minPoolSize"</span> <span class="attr">value</span>=<span class="string">"${jdbc.minPoolSize}"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--最大空闲时间,1800秒内未使用则连接被丢弃。若为0则永不丢弃。Default: 0 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"maxIdleTime"</span> <span class="attr">value</span>=<span class="string">"${jdbc.maxIdleTime}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--当连接池中的连接耗尽的时候c3p0一次同时获取的连接数。Default: 3 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"acquireIncrement"</span> <span class="attr">value</span>=<span class="string">"${jdbc.acquireIncrement}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--每0秒检查所有连接池中的空闲连接。Default: 0 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"idleConnectionTestPeriod"</span> <span class="attr">value</span>=<span class="string">"${jdbc.idleConnectionTestPeriod}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--定义在从数据库获取新连接失败后重复尝试的次数。Default: 30 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"acquireRetryAttempts"</span> <span class="attr">value</span>=<span class="string">"${jdbc.acquireRetryAttempts}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--如果设为true那么在取得连接的同时将校验连接的有效性。Default: false --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"testConnectionOnCheckin"</span> <span class="attr">value</span>=<span class="string">"true"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"preferredTestQuery"</span> <span class="attr">value</span>=<span class="string">"SELECT CURRENT_DATE"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置连接池 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"slaveDataSource"</span> <span class="attr">class</span>=<span class="string">"com.mchange.v2.c3p0.ComboPooledDataSource"</span>  <span class="attr">destroy-method</span>=<span class="string">"close"</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 数据库驱动 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"driverClass"</span> <span class="attr">value</span>=<span class="string">"${jdbc.slave01.driver}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 相应驱动的jdbcUrl --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"jdbcUrl"</span> <span class="attr">value</span>=<span class="string">"${jdbc.slave01.url}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 数据库的用户名 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"user"</span> <span class="attr">value</span>=<span class="string">"${jdbc.slave01.username}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 数据库的密码 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"password"</span> <span class="attr">value</span>=<span class="string">"${jdbc.slave01.password}"</span> /&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!--初始化时获取三个连接，取值应在minPoolSize与maxPoolSize之间。Default: 3 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"initialPoolSize"</span> <span class="attr">value</span>=<span class="string">"${jdbc.initialPoolSize}"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--连接池中保留的最大连接数。Default: 15 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"maxPoolSize"</span> <span class="attr">value</span>=<span class="string">"${jdbc.maxPoolSize}"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--连接池中保留的最小连接数。 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"minPoolSize"</span> <span class="attr">value</span>=<span class="string">"${jdbc.minPoolSize}"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--最大空闲时间,1800秒内未使用则连接被丢弃。若为0则永不丢弃。Default: 0 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"maxIdleTime"</span> <span class="attr">value</span>=<span class="string">"${jdbc.maxIdleTime}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--当连接池中的连接耗尽的时候c3p0一次同时获取的连接数。Default: 3 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"acquireIncrement"</span> <span class="attr">value</span>=<span class="string">"${jdbc.acquireIncrement}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--每0秒检查所有连接池中的空闲连接。Default: 0 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"idleConnectionTestPeriod"</span> <span class="attr">value</span>=<span class="string">"${jdbc.idleConnectionTestPeriod}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--定义在从数据库获取新连接失败后重复尝试的次数。Default: 30 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"acquireRetryAttempts"</span> <span class="attr">value</span>=<span class="string">"${jdbc.acquireRetryAttempts}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--如果设为true那么在取得连接的同时将校验连接的有效性。Default: false --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"testConnectionOnCheckin"</span> <span class="attr">value</span>=<span class="string">"true"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"preferredTestQuery"</span> <span class="attr">value</span>=<span class="string">"SELECT CURRENT_DATE"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 主从数据库配置 part1 end --&gt;</span></span><br></pre></td></tr></tbody></table></figure><h3 id="配置两个sessionFactory"><a href="#配置两个sessionFactory" class="headerlink" title="配置两个sessionFactory"></a>配置两个sessionFactory</h3><p>两个sessionFactory内容大致一样，唯一不同的就是dataSource数据源。</p><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 配置 mybatis 的 sqlsession 的工厂 ， 设置mapper location--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"masterSqlSessionFactory"</span> <span class="attr">class</span>=<span class="string">"org.mybatis.spring.SqlSessionFactoryBean"</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"configLocation"</span> <span class="attr">value</span>=<span class="string">"classpath:config/mybatis.xml"</span> /&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"dataSource"</span> <span class="attr">ref</span>=<span class="string">"masterDataSource"</span> /&gt;</span>  </span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"mapperLocations"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">list</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>classpath:com/test/dlab/mappers/***/*Mapper.xml<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>classpath:com/test/dlab/mappers/***/***/*Mapper.xml<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">list</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"typeAliasesPackage"</span> <span class="attr">value</span>=<span class="string">"com.test.dlab.entity"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- PageHelper 分页插件 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"plugins"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">array</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">bean</span> <span class="attr">class</span>=<span class="string">"com.github.pagehelper.PageHelper"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"properties"</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line">                dialect=mysql</span><br><span class="line">                pageSizeZero=true</span><br><span class="line">                reasonable=false</span><br><span class="line">                <span class="comment">&lt;!-- supportMethodsArguments=false --&gt;</span></span><br><span class="line">                returnPageInfo=always </span><br><span class="line">              <span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">array</span>&gt;</span>            </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span>  </span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"slaveSqlSessionFactory"</span> <span class="attr">class</span>=<span class="string">"org.mybatis.spring.SqlSessionFactoryBean"</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"configLocation"</span> <span class="attr">value</span>=<span class="string">"classpath:config/mybatis.xml"</span> /&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"dataSource"</span> <span class="attr">ref</span>=<span class="string">"slaveDataSource"</span> /&gt;</span>  </span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"mapperLocations"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">list</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>classpath:com/test/dlab/mappers/***/*Mapper.xml<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>classpath:com/test/dlab/mappers/***/***/*Mapper.xml<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">list</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"typeAliasesPackage"</span> <span class="attr">value</span>=<span class="string">"com.test.dlab.entity"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- PageHelper 分页插件 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"plugins"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">array</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">bean</span> <span class="attr">class</span>=<span class="string">"com.github.pagehelper.PageHelper"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"properties"</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line">                dialect=mysql</span><br><span class="line">                pageSizeZero=true</span><br><span class="line">                reasonable=false</span><br><span class="line">                <span class="comment">&lt;!-- supportMethodsArguments=false --&gt;</span></span><br><span class="line">                returnPageInfo=always </span><br><span class="line">              <span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">array</span>&gt;</span>            </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span>  </span><br><span class="line">    </span><br><span class="line"><span class="comment">&lt;!-- 两个SqlSessionFactory使用同一个SqlSessionTemplate配置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"MasterAndSlaveSqlSessionTemplate"</span> <span class="attr">class</span>=<span class="string">"com.test.dlab.aop.core.DynamicSqlSessionTemplate"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">constructor-arg</span> <span class="attr">index</span>=<span class="string">"0"</span> <span class="attr">ref</span>=<span class="string">"masterSqlSessionFactory"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"targetSqlSessionFactorys"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">map</span>&gt;</span>  </span><br><span class="line">            <span class="tag">&lt;<span class="name">entry</span> <span class="attr">value-ref</span>=<span class="string">"masterSqlSessionFactory"</span> <span class="attr">key</span>=<span class="string">"master"</span>/&gt;</span>  </span><br><span class="line">            <span class="tag">&lt;<span class="name">entry</span> <span class="attr">value-ref</span>=<span class="string">"slaveSqlSessionFactory"</span> <span class="attr">key</span>=<span class="string">"slave"</span>/&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;/<span class="name">map</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure><h3 id="配置mapper"><a href="#配置mapper" class="headerlink" title="配置mapper"></a>配置mapper</h3><p>这里采用sqlSessionTemplateBeanName进行mapper的配置，与之前sqlSessionFactoryBeanName有点区别。</p><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">&lt;!-- 一次性配置所有Mapper,替代MapperScannerConfigurer,指定要扫描包： 多个包用逗号隔开   --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">class</span>=<span class="string">"org.mybatis.spring.mapper.MapperScannerConfigurer"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"basePackage"</span> <span class="attr">value</span>=<span class="string">"com.test.dlab.dao"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"sqlSessionTemplateBeanName"</span> <span class="attr">value</span>=<span class="string">"MasterAndSlaveSqlSessionTemplate"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure><h3 id="引入jta-atomikos实现分布式事务管理"><a href="#引入jta-atomikos实现分布式事务管理" class="headerlink" title="引入jta/atomikos实现分布式事务管理"></a>引入jta/atomikos实现分布式事务管理</h3><p>由于Service层的事务不能更改，所以当我们引入多个库的时候，需要引入atomikos来进行分布式事务管理。</p><p>首先引入以下六个jar包</p><ul><li>atomikos-util-4.0.4.jar</li><li>jta-1.1.jar </li><li>transactions-4.0.4.jar</li><li>transactions-api-4.0.4.jar</li><li>transactions-jdbc-4.0.4.jar</li><li>transactions-jta-4.0.4.jar</li></ul><p>然后配置全局的事务管理，并声明注解事务即可。</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 配置事务管理器bean --&gt;</span><br><span class="line">&lt;bean id=<span class="string">"atomikosTransactionManager"</span> <span class="class"><span class="keyword">class</span></span>=<span class="string">"com.atomikos.icatch.jta.UserTransactionManager"</span> init-method=<span class="string">"init"</span> destroy-method=<span class="string">"close"</span>&gt;  </span><br><span class="line">    &lt;property name=<span class="string">"forceShutdown"</span>&gt;  </span><br><span class="line">        &lt;value&gt;true&lt;/value&gt;  </span><br><span class="line">    &lt;/property&gt;  </span><br><span class="line">&lt;/bean&gt;  </span><br><span class="line"></span><br><span class="line">&lt;bean id=<span class="string">"atomikosUserTransaction"</span> <span class="class"><span class="keyword">class</span></span>=<span class="string">"com.atomikos.icatch.jta.UserTransactionImp"</span>&gt;  </span><br><span class="line">    &lt;property name=<span class="string">"transactionTimeout"</span> value=<span class="string">"300"</span> /&gt;  </span><br><span class="line">&lt;/bean&gt;  </span><br><span class="line">&lt;!-- spring 事务管理器 --&gt;    </span><br><span class="line">&lt;bean id=<span class="string">"springTransactionManager"</span> <span class="class"><span class="keyword">class</span></span>=<span class="string">"org.springframework.transaction.jta.JtaTransactionManager"</span>&gt;  </span><br><span class="line">    &lt;property name=<span class="string">"transactionManager"</span> ref=<span class="string">"atomikosTransactionManager"</span> /&gt;  </span><br><span class="line">    &lt;property name=<span class="string">"userTransaction"</span> ref=<span class="string">"atomikosUserTransaction"</span> /&gt;  </span><br><span class="line">    &lt;!-- 必须设置，否则程序出现异常 JtaTransactionManager does not support custom isolation levels by <span class="keyword">default</span> --&gt;  </span><br><span class="line">    &lt;property name=<span class="string">"allowCustomIsolationLevels"</span> value=<span class="string">"true"</span>/&gt;   </span><br><span class="line">&lt;/bean&gt;  </span><br><span class="line">&lt;!-- 声明注解事务 --&gt;</span><br><span class="line">&lt;tx:annotation-driven transaction-manager=<span class="string">"springTransactionManager"</span>/&gt;</span><br></pre></td></tr></tbody></table></figure><h3 id="配置事务属性"><a href="#配置事务属性" class="headerlink" title="配置事务属性"></a>配置事务属性</h3><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 配置事务属性 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">tx:advice</span> <span class="attr">id</span>=<span class="string">"txAdvice"</span> <span class="attr">transaction-manager</span>=<span class="string">"springTransactionManager"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">tx:attributes</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 增删改查方法  配置事务 --&gt;</span>        </span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"save*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> <span class="attr">rollback-for</span>=<span class="string">"java.lang.Exception"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"add*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> <span class="attr">rollback-for</span>=<span class="string">"java.lang.Exception"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"create*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> <span class="attr">rollback-for</span>=<span class="string">"java.lang.Exception"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"insert*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> <span class="attr">rollback-for</span>=<span class="string">"java.lang.Exception"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"update*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> <span class="attr">rollback-for</span>=<span class="string">"java.lang.Exception"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"merge*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> <span class="attr">rollback-for</span>=<span class="string">"java.lang.Exception"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"del*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> <span class="attr">rollback-for</span>=<span class="string">"java.lang.Exception"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"remove*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> <span class="attr">rollback-for</span>=<span class="string">"java.lang.Exception"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"put*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> <span class="attr">rollback-for</span>=<span class="string">"java.lang.Exception"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"use*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> <span class="attr">rollback-for</span>=<span class="string">"java.lang.Exception"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"batch*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> <span class="attr">rollback-for</span>=<span class="string">"java.lang.Exception"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"bind*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> <span class="attr">rollback-for</span>=<span class="string">"java.lang.Exception"</span>/&gt;</span> </span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 查询方法 配置只读属性 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"get*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> <span class="attr">read-only</span>=<span class="string">"true"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"count*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> <span class="attr">read-only</span>=<span class="string">"true"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"find*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> <span class="attr">read-only</span>=<span class="string">"true"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"list*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> <span class="attr">read-only</span>=<span class="string">"true"</span> /&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> /&gt;</span>    </span><br><span class="line">    <span class="tag">&lt;/<span class="name">tx:attributes</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">tx:advice</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure><h3 id="配置事务切面"><a href="#配置事务切面" class="headerlink" title="配置事务切面"></a>配置事务切面</h3><p>为了让之前配置的Aspect作用域Dao方法上，我们需要在Dao层面加入一些配置，使数据源分库功能作用于Dao方法上，实现动态的读写分离。</p><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 配置数据库注解aop --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--     &lt;bean id="dynamicDataSourceAspect" class="com.test.dlab.aop.spring.DynamicDataSourceAspect" /&gt;</span></span><br><span class="line"><span class="comment">&lt;bean class="com.test.dlab.aop.aspect.DataSourceAspect2" id="dynamicDataSourceAspect" /&gt; --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">class</span>=<span class="string">"com.test.dlab.aop.core.DynamicDataSourceAspect"</span> <span class="attr">id</span>=<span class="string">"dynamicDataSourceAspect"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">aop:config</span> &gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">aop:pointcut</span> <span class="attr">id</span>=<span class="string">"txPointcut"</span> <span class="attr">expression</span>=<span class="string">"execution(* com.test.dlab.service..*.*(..))"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">aop:advisor</span> <span class="attr">advice-ref</span>=<span class="string">"txAdvice"</span> <span class="attr">pointcut-ref</span>=<span class="string">"txPointcut"</span>/&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- 将切面应用到自定义的切面处理器上，-9999保证该切面优先级最高执行 --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">aop:aspect</span> <span class="attr">ref</span>=<span class="string">"dynamicDataSourceAspect"</span> <span class="attr">order</span>=<span class="string">"-9999"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">aop:pointcut</span> <span class="attr">id</span>=<span class="string">"tx"</span> <span class="attr">expression</span>=<span class="string">"execution(* com.test.dlab.dao..*.*(..))"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">aop:before</span> <span class="attr">method</span>=<span class="string">"before"</span> <span class="attr">pointcut-ref</span>=<span class="string">"tx"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">aop:aspect</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">aop:config</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure><p>OK，启动项目，访问一切ok！</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li><a href="http://blog.csdn.net/zl3450341/article/details/20150687" target="_blank" rel="noopener">关于Spring3 + Mybatis3整合时，多数据源动态切换的问题</a></li><li><a href="https://www.cnblogs.com/FlyHeLanMan/p/6744171.html" target="_blank" rel="noopener">Spring + Mybatis 项目实现动态切换数据源</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景介绍&quot;&gt;&lt;a href=&quot;#背景介绍&quot; class=&quot;headerlink&quot; title=&quot;背景介绍&quot;&gt;&lt;/a&gt;背景介绍&lt;/h2&gt;&lt;p&gt;在&lt;a href=&quot;http://www.csuldw.com/2018/03/13/2018-03-13-spring-mybatis-read-write-seperation/&quot;&gt;上一篇文章&lt;/a&gt;中已经介绍过读写分离，并且通过代码也已实现局部的读写分离。为什么说是局部的呢？首先，来分析下，针对上一篇文章中提到的方法，如果在service层没有配置事务，那么当程序走到Dao层时，就可以根据自己定义的规则进行读写分离；倘若在service层配置了事物，那么在Dao切换数据库key的时候，是无法正真的进行读写分离的。因此，通过进一步的研究和尝试，找到了一种新的方法来实现真正意义上的Dao层读写分离，该方法可以在事务内部直接切换数据库，达到读写分库的功能。&lt;/p&gt;
    
    </summary>
    
      <category term="Java" scheme="https://www.csuldw.com/categories/Java/"/>
    
    
      <category term="读写分离" scheme="https://www.csuldw.com/tags/%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/"/>
    
      <category term="主从分离" scheme="https://www.csuldw.com/tags/%E4%B8%BB%E4%BB%8E%E5%88%86%E7%A6%BB/"/>
    
      <category term="Spring" scheme="https://www.csuldw.com/tags/Spring/"/>
    
      <category term="MySql" scheme="https://www.csuldw.com/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>Spring+Mybatis+Mysql数据库读写分离</title>
    <link href="https://www.csuldw.com/2018/03/13/2018-03-13-spring-mybatis-read-write-seperation/"/>
    <id>https://www.csuldw.com/2018/03/13/2018-03-13-spring-mybatis-read-write-seperation/</id>
    <published>2018-03-13T15:22:00.000Z</published>
    <updated>2018-04-09T13:49:48.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>通常，在与数据库进行交互时，对数据库的操作都是“读多写少”，一方面，对数据库读取数据的压力比较大；另一方面，如果数据库分布在国内，那么在国外访问项目的时候，如果查询的接口较多，那么直接访问国内的数据库会大大的降低访问性能。因此，为了提升数据访问速度，缓解数据库的压力，我们可以在国外的服务器也安装一个mysql，部署一个项目，两个mysql进行主从配置，那么对于接口就需要采用读写分离策略，其基本思想是：将数据库分为主库和从库，主库只有一个，从库可有多个，主库主要负责写入数据，而从库则负责读取数据。</p><a id="more"></a><p>要求：</p><ol><li>主从一致：读库和写库的数据一致；</li><li>写走主库：写数据必须写到写库；</li><li>读走从库：读数据必须到读库；</li></ol><p>本文针对读写分离使用的方法是基于应用层实现，对原有代码的改动量较小，只是对配置文件进行了修改，下面来看具体实现。</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>SSM框架将后台划分成了Dao、Service、Mapper层，读写分离的原理是在进入Service/Dao（具体哪一层，看配置项）之前，使用AOP来判断请求是前往写库还是读库，判断依据可以根据方法名判断，比如说以query、find、get等开头的就走读库，其他的走写库。</p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="定义动态数据源"><a href="#定义动态数据源" class="headerlink" title="定义动态数据源"></a>定义动态数据源</h3><p>实现通过集成Spring提供的AbstractRoutingDataSource，只需要实现determineCurrentLookupKey方法即可，由于DynamicDataSource是单例的，线程不安全的，所以采用ThreadLocal保证线程安全，由DynamicDataSourceHolder完成。</p><p>1.DynamicDataSource.java</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.test.dlab.aop.aspect;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 定义动态数据源，实现通过集成Spring提供的AbstractRoutingDataSource，</span></span><br><span class="line"><span class="comment"> * 只需要实现determineCurrentLookupKey方法即可</span></span><br><span class="line"><span class="comment"> * 由于DynamicDataSource是单例的，线程不安全的，所以采用ThreadLocal保证线程安全，</span></span><br><span class="line"><span class="comment"> * 由DynamicDataSourceHolder完成。</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> liudiwei 2018年3月12日</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DynamicDataSource</span> <span class="keyword">extends</span> <span class="title">AbstractRoutingDataSource</span></span></span><br><span class="line"><span class="class"></span>{</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> Object <span class="title">determineCurrentLookupKey</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>{</span><br><span class="line">        <span class="comment">// 使用DynamicDataSourceHolder保证线程安全，并且得到当前线程中的数据源key</span></span><br><span class="line">        <span class="keyword">return</span> DynamicDataSourceHolder.getDataSourceKey();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>下面定义DynamicDataSourceHolder类，使用ThreadLocal技术来记录当前线程中的数据源的key。</p><p>2.DynamicDataSourceHolder.java</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.test.dlab.aop.aspect;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> liudiwei 2018年3月12日 使用ThreadLocal技术来记录当前线程中的数据源的key</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DynamicDataSourceHolder</span></span></span><br><span class="line"><span class="class"></span>{</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Logger log = Logger.getLogger(DynamicDataSource<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 写库对应的数据源key</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String MASTER = <span class="string">"master"</span>;</span><br><span class="line">    <span class="comment">// 读库对应的数据源key</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String SLAVE = <span class="string">"slave"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 使用ThreadLocal记录当前线程的数据源key</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> ThreadLocal&lt;String&gt; holder = <span class="keyword">new</span> ThreadLocal&lt;String&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 设置数据源key</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> key</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">setDataSourceKey</span><span class="params">(String key)</span></span></span><br><span class="line"><span class="function">    </span>{</span><br><span class="line">        holder.set(key);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取数据源key</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getDataSourceKey</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>{</span><br><span class="line">        <span class="keyword">return</span> holder.get();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 标记写库</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">markAsMaster</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>{</span><br><span class="line">        setDataSourceKey(MASTER);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 标记读库</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">markAsSlave</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>{</span><br><span class="line">        setDataSourceKey(SLAVE);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">clearDataSource</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>{</span><br><span class="line">        log.info(<span class="string">"移除clearDataSource"</span>);</span><br><span class="line">        holder.remove();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2 id="定义数据源的AOP切面"><a href="#定义数据源的AOP切面" class="headerlink" title="定义数据源的AOP切面"></a>定义数据源的AOP切面</h2><p>定义数据源的AOP切面，通过该Service的方法名判断是应该走读库还是写库。</p><h3 id="DataSourceAspect-java"><a href="#DataSourceAspect-java" class="headerlink" title="DataSourceAspect.java"></a>DataSourceAspect.java</h3><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.test.dlab.aop.aspect;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.JoinPoint;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 定义数据源的AOP切面，通过该Service的方法名判断是应该走读库还是写库</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> liudiwei 2018年3月12日</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DataSourceAspect</span></span></span><br><span class="line"><span class="class"></span>{</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger log = Logger.getLogger(DataSourceAspect<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 在进入Service方法之前执行</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> point</span></span><br><span class="line"><span class="comment">     *            切面对象</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">before</span><span class="params">(JoinPoint point)</span></span></span><br><span class="line"><span class="function">    </span>{</span><br><span class="line">        <span class="comment">// 获取到当前执行的方法名</span></span><br><span class="line">        String methodName = point.getSignature().getName();</span><br><span class="line">        <span class="keyword">if</span> (isSlave(methodName))</span><br><span class="line">        {</span><br><span class="line">            <span class="comment">// 标记为读库</span></span><br><span class="line">            DynamicDataSourceHolder.markAsSlave();</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        {</span><br><span class="line">            <span class="comment">// 标记为写库</span></span><br><span class="line">            DynamicDataSourceHolder.markAsMaster();</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断是否为读库</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> methodName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> Boolean <span class="title">isSlave</span><span class="params">(String methodName)</span></span></span><br><span class="line"><span class="function">    </span>{</span><br><span class="line">        log.info(<span class="string">"根据Service方法名前缀判断是否走从库."</span>);</span><br><span class="line">        <span class="keyword">return</span> org.apache.commons.lang3.StringUtils.startsWithAny(methodName, <span class="string">"query"</span>, <span class="string">"quer"</span>, <span class="string">"find"</span>, <span class="string">"get"</span>);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h3 id="优化后的Aspect"><a href="#优化后的Aspect" class="headerlink" title="优化后的Aspect"></a>优化后的Aspect</h3><p>DataSourceAspect2.java</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.test.dlab.aop.aspect;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang3.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.JoinPoint;</span><br><span class="line"><span class="keyword">import</span> org.springframework.transaction.interceptor.NameMatchTransactionAttributeSource;</span><br><span class="line"><span class="keyword">import</span> org.springframework.transaction.interceptor.TransactionAttribute;</span><br><span class="line"><span class="keyword">import</span> org.springframework.transaction.interceptor.TransactionAttributeSource;</span><br><span class="line"><span class="keyword">import</span> org.springframework.transaction.interceptor.TransactionInterceptor;</span><br><span class="line"><span class="keyword">import</span> org.springframework.util.PatternMatchUtils;</span><br><span class="line"><span class="keyword">import</span> org.springframework.util.ReflectionUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.Field;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 定义数据源的AOP切面，通过该Dao的方法名判断是应该走读库还是写库</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> liudiwei 2018年3月12日</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DataSourceAspect2</span></span></span><br><span class="line"><span class="class"></span>{</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger log = Logger.getLogger(DataSourceAspect<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> List&lt;String&gt; slaveMethodPattern = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String[] defaultSlaveMethodStart = <span class="keyword">new</span> String[] { <span class="string">"quer"</span>, <span class="string">"find"</span>, <span class="string">"get"</span> };</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String[] slaveMethodStart;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 读取事务管理中的策略</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> txAdvice</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setTxAdvice</span><span class="params">(TransactionInterceptor txAdvice)</span> <span class="keyword">throws</span> Exception</span></span><br><span class="line"><span class="function">    </span>{</span><br><span class="line">        <span class="keyword">if</span> (txAdvice == <span class="keyword">null</span>)</span><br><span class="line">        {</span><br><span class="line">            log.info(<span class="string">"没有配置事务管理策略"</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 从txAdvice获取到策略配置信息</span></span><br><span class="line">        TransactionAttributeSource transactionAttributeSource = txAdvice.getTransactionAttributeSource();</span><br><span class="line">        <span class="keyword">if</span> (!(transactionAttributeSource <span class="keyword">instanceof</span> NameMatchTransactionAttributeSource))</span><br><span class="line">        {</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 使用反射技术获取到NameMatchTransactionAttributeSource对象中的nameMap属性值</span></span><br><span class="line">        NameMatchTransactionAttributeSource matchTransactionAttributeSource = (NameMatchTransactionAttributeSource) transactionAttributeSource;</span><br><span class="line">        Field nameMapField = ReflectionUtils.findField(NameMatchTransactionAttributeSource.class, "nameMap");</span><br><span class="line"></span><br><span class="line">        log.info(<span class="string">"nameMapField AAAAA:"</span> + nameMapField);</span><br><span class="line"></span><br><span class="line">        nameMapField.setAccessible(<span class="keyword">true</span>); <span class="comment">// 设置该字段可访问</span></span><br><span class="line">        <span class="comment">// 获取nameMap的值</span></span><br><span class="line">        Map&lt;String, TransactionAttribute&gt; map = (Map&lt;String, TransactionAttribute&gt;) nameMapField</span><br><span class="line">                .get(matchTransactionAttributeSource);</span><br><span class="line">        <span class="comment">// 遍历nameMap</span></span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;String, TransactionAttribute&gt; entry : map.entrySet())</span><br><span class="line">        {</span><br><span class="line">            log.info(<span class="string">"entity结果:"</span> + entry.toString());</span><br><span class="line">            <span class="comment">// 判断之后定义了ReadOnly的策略才加入到slaveMethodPattern</span></span><br><span class="line">            <span class="keyword">if</span> (!entry.getValue().isReadOnly())</span><br><span class="line">            {</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            }</span><br><span class="line">            slaveMethodPattern.add(entry.getKey());</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 在进入Service方法之前执行</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> point</span></span><br><span class="line"><span class="comment">     *            切面对象</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">before</span><span class="params">(JoinPoint point)</span></span></span><br><span class="line"><span class="function">    </span>{</span><br><span class="line">        <span class="comment">// 获取到当前执行的方法名</span></span><br><span class="line">        String methodName = point.getSignature().getName();</span><br><span class="line">        log.info(<span class="string">"方法名称："</span> + methodName);</span><br><span class="line">        <span class="keyword">boolean</span> isSlave = <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">if</span> (slaveMethodPattern.isEmpty())</span><br><span class="line">        {</span><br><span class="line">            log.info(<span class="string">"当前Spring容器中没有配置事务策略，采用方法名匹配方式"</span>);</span><br><span class="line">            isSlave = isSlave(methodName);</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        {</span><br><span class="line">            log.info(<span class="string">"使用策略规则匹配"</span>);</span><br><span class="line">            <span class="keyword">for</span> (String mappedName : slaveMethodPattern)</span><br><span class="line">            {</span><br><span class="line">                <span class="keyword">if</span> (isMatch(methodName, mappedName))</span><br><span class="line">                {</span><br><span class="line">                    isSlave = <span class="keyword">true</span>;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span> (isSlave)</span><br><span class="line">        {</span><br><span class="line">            log.info(<span class="string">"标记为读库"</span>);</span><br><span class="line">            DynamicDataSourceHolder.markAsSlave();</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        {</span><br><span class="line">            log.info(<span class="string">"标记为写库"</span>);</span><br><span class="line">            DynamicDataSourceHolder.markAsMaster();</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">after</span><span class="params">(JoinPoint point)</span></span></span><br><span class="line"><span class="function">    </span>{</span><br><span class="line">        DynamicDataSourceHolder.clearDataSource();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断是否为读库</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> methodName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> Boolean <span class="title">isSlave</span><span class="params">(String methodName)</span></span></span><br><span class="line"><span class="function">    </span>{</span><br><span class="line">        log.info(<span class="string">"根据Dao方法名前缀判断是否走从库."</span>);</span><br><span class="line">        <span class="keyword">return</span> StringUtils.startsWithAny(methodName, getSlaveMethodStart());</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 通配符匹配</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * Return if the given method name matches the mapped name.</span></span><br><span class="line"><span class="comment">     * &lt;p&gt;</span></span><br><span class="line"><span class="comment">     * The default implementation checks for "xxx*", "*xxx" and "*xxx*" matches,</span></span><br><span class="line"><span class="comment">     * as well as direct equality. Can be overridden in subclasses.</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> methodName</span></span><br><span class="line"><span class="comment">     *            the method name of the class</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> mappedName</span></span><br><span class="line"><span class="comment">     *            the name in the descriptor</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> if the names match</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@see</span> org.springframework.util.PatternMatchUtils#simpleMatch(String,</span></span><br><span class="line"><span class="comment">     *      String)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">isMatch</span><span class="params">(String methodName, String mappedName)</span></span></span><br><span class="line"><span class="function">    </span>{</span><br><span class="line">        <span class="keyword">return</span> PatternMatchUtils.simpleMatch(mappedName, methodName);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 用户指定slave的方法名前缀</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> slaveMethodStart</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSlaveMethodStart</span><span class="params">(String[] slaveMethodStart)</span></span></span><br><span class="line"><span class="function">    </span>{</span><br><span class="line">        <span class="keyword">this</span>.slaveMethodStart = slaveMethodStart;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String[] getSlaveMethodStart()</span><br><span class="line">    {</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.slaveMethodStart == <span class="keyword">null</span>)</span><br><span class="line">        {</span><br><span class="line">            <span class="comment">// 没有指定，使用默认</span></span><br><span class="line">            <span class="keyword">return</span> defaultSlaveMethodStart;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> slaveMethodStart;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><h3 id="配置db-properties"><a href="#配置db-properties" class="headerlink" title="配置db.properties"></a>配置db.properties</h3><p>在db.properties配置文件中增加主库和从库的信息，这里master为主库，slave为从库，具体内容如下：</p><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">jdbc.master.driver=com.mysql.jdbc.Driver</span><br><span class="line">jdbc.master.url=jdbc:mysql://127.0.0.1:3307/resource_test?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true</span><br><span class="line">jdbc.master.username=root</span><br><span class="line">jdbc.master.password=123456</span><br><span class="line"></span><br><span class="line">jdbc.slave01.driver=com.mysql.jdbc.Driver</span><br><span class="line">jdbc.slave01.url=jdbc:mysql://127.0.0.1:3306/resource_test?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true</span><br><span class="line">jdbc.slave01.username=root</span><br><span class="line">jdbc.slave01.password=123456</span><br></pre></td></tr></tbody></table></figure><h3 id="修改applicationContext-xml"><a href="#修改applicationContext-xml" class="headerlink" title="修改applicationContext.xml"></a>修改applicationContext.xml</h3><p>1)添加主从数据库连接池masterDataSource和slave01DataSource。</p><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 配置连接池 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"masterDataSource"</span> <span class="attr">class</span>=<span class="string">"com.mchange.v2.c3p0.ComboPooledDataSource"</span>    <span class="attr">destroy-method</span>=<span class="string">"close"</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 数据库驱动 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"driverClass"</span> <span class="attr">value</span>=<span class="string">"${jdbc.master.driver}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 相应驱动的jdbcUrl --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"jdbcUrl"</span> <span class="attr">value</span>=<span class="string">"${jdbc.master.url}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 数据库的用户名 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"user"</span> <span class="attr">value</span>=<span class="string">"${jdbc.master.username}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 数据库的密码 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"password"</span> <span class="attr">value</span>=<span class="string">"${jdbc.master.password}"</span> /&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!--初始化时获取三个连接，取值应在minPoolSize与maxPoolSize之间。Default: 3 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"initialPoolSize"</span> <span class="attr">value</span>=<span class="string">"${jdbc.initialPoolSize}"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--连接池中保留的最大连接数。Default: 15 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"maxPoolSize"</span> <span class="attr">value</span>=<span class="string">"${jdbc.maxPoolSize}"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--连接池中保留的最小连接数。 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"minPoolSize"</span> <span class="attr">value</span>=<span class="string">"${jdbc.minPoolSize}"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--最大空闲时间,1800秒内未使用则连接被丢弃。若为0则永不丢弃。Default: 0 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"maxIdleTime"</span> <span class="attr">value</span>=<span class="string">"${jdbc.maxIdleTime}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--当连接池中的连接耗尽的时候c3p0一次同时获取的连接数。Default: 3 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"acquireIncrement"</span> <span class="attr">value</span>=<span class="string">"${jdbc.acquireIncrement}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--每0秒检查所有连接池中的空闲连接。Default: 0 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"idleConnectionTestPeriod"</span> <span class="attr">value</span>=<span class="string">"${jdbc.idleConnectionTestPeriod}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--定义在从数据库获取新连接失败后重复尝试的次数。Default: 30 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"acquireRetryAttempts"</span> <span class="attr">value</span>=<span class="string">"${jdbc.acquireRetryAttempts}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--如果设为true那么在取得连接的同时将校验连接的有效性。Default: false --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"testConnectionOnCheckin"</span> <span class="attr">value</span>=<span class="string">"true"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"preferredTestQuery"</span> <span class="attr">value</span>=<span class="string">"SELECT CURRENT_DATE"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置连接池 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"slave01DataSource"</span> <span class="attr">class</span>=<span class="string">"com.mchange.v2.c3p0.ComboPooledDataSource"</span>    <span class="attr">destroy-method</span>=<span class="string">"close"</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 数据库驱动 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"driverClass"</span> <span class="attr">value</span>=<span class="string">"${jdbc.slave01.driver}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 相应驱动的jdbcUrl --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"jdbcUrl"</span> <span class="attr">value</span>=<span class="string">"${jdbc.slave01.url}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 数据库的用户名 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"user"</span> <span class="attr">value</span>=<span class="string">"${jdbc.slave01.username}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 数据库的密码 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"password"</span> <span class="attr">value</span>=<span class="string">"${jdbc.slave01.password}"</span> /&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!--初始化时获取三个连接，取值应在minPoolSize与maxPoolSize之间。Default: 3 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"initialPoolSize"</span> <span class="attr">value</span>=<span class="string">"${jdbc.initialPoolSize}"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--连接池中保留的最大连接数。Default: 15 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"maxPoolSize"</span> <span class="attr">value</span>=<span class="string">"${jdbc.maxPoolSize}"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--连接池中保留的最小连接数。 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"minPoolSize"</span> <span class="attr">value</span>=<span class="string">"${jdbc.minPoolSize}"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--最大空闲时间,1800秒内未使用则连接被丢弃。若为0则永不丢弃。Default: 0 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"maxIdleTime"</span> <span class="attr">value</span>=<span class="string">"${jdbc.maxIdleTime}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--当连接池中的连接耗尽的时候c3p0一次同时获取的连接数。Default: 3 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"acquireIncrement"</span> <span class="attr">value</span>=<span class="string">"${jdbc.acquireIncrement}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--每0秒检查所有连接池中的空闲连接。Default: 0 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"idleConnectionTestPeriod"</span> <span class="attr">value</span>=<span class="string">"${jdbc.idleConnectionTestPeriod}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--定义在从数据库获取新连接失败后重复尝试的次数。Default: 30 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"acquireRetryAttempts"</span> <span class="attr">value</span>=<span class="string">"${jdbc.acquireRetryAttempts}"</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--如果设为true那么在取得连接的同时将校验连接的有效性。Default: false --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"testConnectionOnCheckin"</span> <span class="attr">value</span>=<span class="string">"true"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"preferredTestQuery"</span> <span class="attr">value</span>=<span class="string">"SELECT CURRENT_DATE"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure><p>2)定义DataSource</p><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 定义数据源，使用自己实现的数据源 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"dataSource"</span> <span class="attr">class</span>=<span class="string">"com.test.dlab.aop.aspect.DynamicDataSource"</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 设置多个数据源 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"targetDataSources"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">map</span> <span class="attr">key-type</span>=<span class="string">"java.lang.String"</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 这个key需要和程序中的key一致 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span>=<span class="string">"master"</span> <span class="attr">value-ref</span>=<span class="string">"masterDataSource"</span> /&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span>=<span class="string">"slave"</span> <span class="attr">value-ref</span>=<span class="string">"slave01DataSource"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">map</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 设置默认的数据源，这里默认走写库 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"defaultTargetDataSource"</span> <span class="attr">ref</span>=<span class="string">"masterDataSource"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure><p>3)配置事务管理器</p><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 配置事务管理器bean --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"transactionManager"</span> <span class="attr">class</span>=<span class="string">"org.springframework.jdbc.datasource.DataSourceTransactionManager"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"dataSource"</span> <span class="attr">ref</span>=<span class="string">"dataSource"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure><p>4)配置事务属性</p><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">tx:advice</span> <span class="attr">id</span>=<span class="string">"txAdvice"</span> <span class="attr">transaction-manager</span>=<span class="string">"transactionManager"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">tx:attributes</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--定义查询方法都是只读的 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"query*"</span> <span class="attr">read-only</span>=<span class="string">"true"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"find*"</span> <span class="attr">read-only</span>=<span class="string">"true"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"get*"</span> <span class="attr">read-only</span>=<span class="string">"true"</span> /&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 主库执行操作，事务传播行为定义为默认行为 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"save*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"update*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"delete*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> /&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 主库执行操作，事务传播行为定义为默认行为 --&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--其他方法使用默认事务策略 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"*"</span> /&gt;</span>     </span><br><span class="line">    <span class="tag">&lt;/<span class="name">tx:attributes</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">tx:advice</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure><p>5)配置事务切面</p><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 主从数据库配置  part2 start --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置数据库注解aop --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">class</span>=<span class="string">"com.test.dlab.aop.aspect.DataSourceAspect2"</span> <span class="attr">id</span>=<span class="string">"dataSourceAspect"</span> /&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置xml事务 切面 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">aop:config</span> <span class="attr">expose-proxy</span>=<span class="string">"true"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">aop:pointcut</span> <span class="attr">id</span>=<span class="string">"txPointcut"</span> <span class="attr">expression</span>=<span class="string">"execution(* com.test.dlab.service..*.*(..))"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">aop:advisor</span> <span class="attr">advice-ref</span>=<span class="string">"txAdvice"</span> <span class="attr">pointcut-ref</span>=<span class="string">"txPointcut"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 将切面应用到自定义的切面处理器上，-9999保证该切面优先级最高执行 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">aop:aspect</span> <span class="attr">ref</span>=<span class="string">"dataSourceAspect"</span> <span class="attr">order</span>=<span class="string">"-9999"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">aop:pointcut</span> <span class="attr">id</span>=<span class="string">"tx"</span> <span class="attr">expression</span>=<span class="string">"execution(* com.test.dlab.dao..*.*(..))"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">aop:before</span> <span class="attr">method</span>=<span class="string">"before"</span> <span class="attr">pointcut-ref</span>=<span class="string">"tx"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">aop:aspect</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">aop:config</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 主从数据库配置  part2 end --&gt;</span></span><br></pre></td></tr></tbody></table></figure><p>OK，启动项目，访问一切ok！</p><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p>1.由于实现的是dao层的读写分离，因此在配置aop的时候，应该去掉 <code>proxy-target-class="true"</code>:</p><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">aop:aspectj-autoproxy</span> /&gt;</span></span><br></pre></td></tr></tbody></table></figure><p>2.由于service层配置了事务，所以为了不影响dao层的主从分离，在配置service事务属性的时候，不能添加下列语句，否则数据库在service层进入事务之后，无法实现dao层的主从分离。</p><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">tx:method</span> <span class="attr">name</span>=<span class="string">"*"</span> <span class="attr">propagation</span>=<span class="string">"REQUIRED"</span> /&gt;</span></span><br></pre></td></tr></tbody></table></figure><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景介绍&quot;&gt;&lt;a href=&quot;#背景介绍&quot; class=&quot;headerlink&quot; title=&quot;背景介绍&quot;&gt;&lt;/a&gt;背景介绍&lt;/h2&gt;&lt;p&gt;通常，在与数据库进行交互时，对数据库的操作都是“读多写少”，一方面，对数据库读取数据的压力比较大；另一方面，如果数据库分布在国内，那么在国外访问项目的时候，如果查询的接口较多，那么直接访问国内的数据库会大大的降低访问性能。因此，为了提升数据访问速度，缓解数据库的压力，我们可以在国外的服务器也安装一个mysql，部署一个项目，两个mysql进行主从配置，那么对于接口就需要采用读写分离策略，其基本思想是：将数据库分为主库和从库，主库只有一个，从库可有多个，主库主要负责写入数据，而从库则负责读取数据。&lt;/p&gt;
    
    </summary>
    
      <category term="Java" scheme="https://www.csuldw.com/categories/Java/"/>
    
    
      <category term="读写分离" scheme="https://www.csuldw.com/tags/%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/"/>
    
      <category term="主从分离" scheme="https://www.csuldw.com/tags/%E4%B8%BB%E4%BB%8E%E5%88%86%E7%A6%BB/"/>
    
      <category term="Spring" scheme="https://www.csuldw.com/tags/Spring/"/>
    
      <category term="MySql" scheme="https://www.csuldw.com/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>Perceptron - 原理与实现</title>
    <link href="https://www.csuldw.com/2018/01/29/2018-01-29-perceptron-theory-and-implemention/"/>
    <id>https://www.csuldw.com/2018/01/29/2018-01-29-perceptron-theory-and-implemention/</id>
    <published>2018-01-28T16:22:22.000Z</published>
    <updated>2018-10-20T05:48:14.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>回顾了下以前的博文，发现自己CSDN博客里面有的博文没有同步到这里来。出于温故知新的目的，打算将perceptron引入至此，并在原来的基础上稍作更改，下面请看正文。</p><a id="more"></a><p>追根溯源，Perceptron是<strong>Rosenblatt</strong>于1957年提出，它是<strong>神经网络</strong>和<strong>支持向量机</strong>的基础，我们称之为”感知器“，或”感知机“。在机器学习理论中，<strong>感知机</strong>（perceptron）属于二分类方法，构造的模型属于线性分类模型，同时它也是监督学习算法的一种，其输入为样本实例的特征向量，输出为样本实例的类别label（取+1/-1或0/1）。感知机对应于在输入空间中将样本空间划分为两类的分离超平面，它旨在求出该超平面。为了求得此超平面，进一步引入了基于误分类的损失函数，并利用梯度下降法对损失函数进行最优化。感知机的学习算法具有简单而易于实现的优点。感知机预测则是用学习得到的感知机模型对新的样本实例进行预测的，属于判别式模型。</p><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a><strong>定义</strong></h2><p>假设输入空间(特征向量)为$X\subseteq R^n$，输出空间为Y={-1,+1}。输入$x∈X$表示样本实例的特征向量，对应于输入空间的点；输出$y∈Y$表示样本的类别。输入空间到输出空间的决策函数为：</p><p>$$f(x)=sign(w·x + b)$$</p><p>这种模型称为感知机。其中，参数w叫做权值向量<strong>weight</strong>，b称为偏置<strong>bias</strong>。$w·x$表示w和x的<strong>点积</strong></p><p>$$\sum_{i=1}^m w_i x_i= w_1x_1+w_2x_2+…+w_nx_n$$</p><p><strong>sign</strong>为符号函数，公式如下：</p><p>$$<br>f(x)=<br>\begin{cases}<br>+1 &amp; \text{if } z&gt;0 \\<br>-1 &amp; \text{else }<br>\end{cases}<br>$$</p><p>可以看到，一个感知机主要由如下三部分组成：</p><ul><li>输入权值：$w$，叫做权值向量<strong>(weight)</strong>;</li><li>激活函数：感知器的激活函数可以有很多选择，比如这里我们选择是$sign$符号函数作为激活函数；</li><li>输出：$y=f(\mathrm{w}\cdot \mathrm{x}+b)\qquad $</li></ul><p>在二分类问题中，$f(x)$的值（+1或-1）用于判别$x$为正样本（+1）还是负样本（-1）。刚刚说到，感知机是一种线性分类模型，属于判别模型。因此，我们需要做的就是找到一个最佳的满足$w \cdot x + b = 0$的权值向量w和偏置项b，也就是一条分离超平面（<em>separating hyperplane</em>）。如下图，一个线性可分的感知机模型</p><center>![这里写图片描述](/assets/articleImg/2018-01-29-1.png)</center><p>中间的直线即$w \cdot x + b = 0$这条直线。</p><p>线性分类器的几何表示有：直线、平面、超平面。</p><h2 id="学习策略"><a href="#学习策略" class="headerlink" title="学习策略"></a><strong>学习策略</strong></h2><p><font color="red"><strong>核心：极小化损失函数。</strong></font></p><p>如果训练集是可分的，感知机的学习目的是求得一个能将训练集正样本点和负样本点完全分开的分离平面（或超平面）。为了找到这样一个平面（或超平面），即确定感知机模型参数w和b，我们采用的是学习策略是极小化损失函数。</p><p>对于损失函数的选择，有多种，这里我们采用的是误分类点到超平面的距离，如下（可以自己推算一下，这里采用的是几何间距，就是点到直线的距离）：</p><p>$$\dfrac{1}{\parallel w\parallel}|w*x_{0}+b|$$</p><p>其中$||w||$是$L2$范数。</p><p>对于正确分类的样本点$(x_i, y_i)$而言：</p><p>$$y_i(w * x_i+b)&gt;0$$</p><p>所以，对于误分类点$(x_i, y_i)$来说：</p><p>$$- y_i(w * x_i+b)&gt;0 $$</p><p>误分类点$x_i$到超平面的距离为：</p><p>$$-\dfrac{1}{\parallel w\parallel}y_0(w*x_i+b)$$</p><p>那么，所有点到超平面的总距离为：</p><p>$$-\dfrac{1}{\parallel w\parallel} \sum_{x_i\epsilon M} y_i|w*x_i+b|$$</p><p>由于极值计算不受常量的影响，因此不考虑$\frac{1}{||w||}$,由此得到感知机的损失函数如下：</p><p>$$L(w,b) = - \sum_{x_i\epsilon M} y_i(w*x_i+b)$$</p><p>其中$M$为误分类的集合。这个损失函数就是感知机学习的<strong>经验风险函数</strong>。</p><p>可以看出，随时函数$L(w,b)$是非负的。<font color="red"><strong>如果没有误分类点，则损失函数的值为0，而且误分类点越少，误分类点距离超平面就越近，损失函数值就越小</strong></font>。同时，损失函数$L(w, b)$是连续可导函数。</p><h2 id="学习算法"><a href="#学习算法" class="headerlink" title="学习算法"></a><strong>学习算法</strong></h2><p>通过上面的分析，得到了感知器的损失函数，由此将感知机学习转变成求解损失函数$L(w,b)$的最优化问题。通常采用的是SGD随机梯度下降法（stochastic gradient descent）。关于梯度下降的详细内容，参考<a href="https://en.wikipedia.org/wiki/Gradient_descent" target="_blank" rel="noopener">wikipedia Gradient descent</a>。下面给出一个简单的梯度下降的可视化图：</p><center>![这里写图片描述](/assets/articleImg/2018-01-29-2.png)</center><p>上图就是随机梯度下降法一步一步达到最优值的过程，说明一下，梯度下降其实是局部最优。感知机学习算法本身是误分类驱动的，因此我们采用随机梯度下降法。首先，任选一个超平面$w_0$和$b_0$，然后使用梯度下降法不断地<strong>极小化目标函数</strong></p><p>$$min_{w,b}  L(w,b) = - \sum_{x_i\epsilon M} y_i(w*x_0+b)$$</p><p>极小化过程不是一次使M中所有误分类点的梯度下降，而是一次随机的选取一个误分类点使其梯度下降。使用的规则为 $\theta: = \theta - \alpha \nabla_\theta \ell (\theta)$，其中$\alpha$是步长，$\nabla_\theta \ell (\theta)$是梯度。假设误分类点集合$M$是固定的，那么损失函数$ L(w,b)$的梯度通过偏导计算：</p><p>$$\frac{\partial L(w,b)}{\partial w} = - \sum_{x_i\epsilon M}y_ix_i$$</p><p>$$\frac{\partial L(w,b)}{\partial b} = - \sum_{x_i\epsilon M}y_i$$</p><p>然后，随机选取一个误分类点，根据上面的规则，计算新的$w,b$，然后进行更新：</p><p>$$w :=  w + \eta y_i x_i$$</p><p>$$b :=  b + \eta y_i$$</p><p>其中$\eta$是步长，大于0小于1，在统计学习中称之为学习率（<em>learning rate</em>）。这样，通过迭代可以期待损失函数$L(w,b)$不断减小，直至逼近于0.</p><p>在有的文章中，最后得到的更新公式为：</p><p>$$w :=  w + \Delta w$$</p><p>$$\Delta w = \eta(t-o)x_i$$</p><p><font color="red"><strong>这是因为它采取的激活函数是正样本为1、负样本为0，所以权值的变化式子有点区别，不过思想都是一样的。</strong></font></p><p>算法描述如下：</p><p><strong>算法：感知机学习算法原始形式</strong></p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">输入：T={(x1,y1),(x2,y2)...(xN,yN)}（其中xi∈X=Rn，yi∈Y={<span class="number">-1</span>, +<span class="number">1</span>}，i=<span class="number">1</span>,<span class="number">2.</span>..N，学习速率为η）</span><br><span class="line">输出：w, b;感知机模型f(x)=sign(w·x+b)</span><br><span class="line">(<span class="number">1</span>) 初始化w0,b0，权值可以初始化为<span class="number">0</span>或一个很小的随机数</span><br><span class="line">(<span class="number">2</span>) 在训练数据集中选取（x_i, y_i）</span><br><span class="line">(<span class="number">3</span>) 如果yi(w xi+b)≤<span class="number">0</span></span><br><span class="line">           w = w + ηy_ix_i</span><br><span class="line">           b = b + ηy_i</span><br><span class="line">(<span class="number">4</span>) 转至（<span class="number">2</span>）,直至训练集中没有误分类点</span><br></pre></td></tr></tbody></table></figure><p>解释：当一个实例点被误分类时，调整w,b，使分离超平面向该误分类点的一侧移动，以减少该误分类点与超平面的距离，直至超越该点被正确分类。</p><p>对于每个$w\cdot x$其实是这样子的（假设x表示的是n维）：</p><p>$$y_j(t) = f[\mathbf{w}(t)\cdot\mathbf{x}_j+b] = f[w_1(t)x_{j,1} + w_2(t)x_{j,2} + \dotsb + w_n(t)x_{j,n}+b]$$</p><p>对于输入的每个特征都附加一个权值，然后将相加得到一个和函数$f$，最后该函数的输出即为输出的$y$值。</p><h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a><strong>实例</strong></h2><p>正样本点：$x_1=(3,3)^T$,$x_2=(4,3)^T$<br>负样本点：$x_1=(1,1)^T$<br>求感知机模型$f(x)=sign(w\cdot x+b)$,其中$w=(w^{(1)},w^{(2)})^T,x=(x^{(1)},x^{(2)})^T$</p><p><strong>解答思路：</strong>根据上面讲解的，写初始化权值w和偏置b，然后一步一步的更新权值，直到所有的点都分正确为止。</p><p>解：</p><p>（1） 令$w_0=0,b_0=0$<br>（2） 随机的取一个点，如$x_1$,计算$y_1(w_0\cdot x_1+b_0)$,结果为0，表示未被正确分类，根据下面的式子更新$w,b$<font color="red">（此例中，我们将学习率$\eta$设置为1）</font>:</p><p>$$w \leftarrow  w + \eta y_ix_i$$</p><p>$$b \leftarrow  b + \eta y_i$$</p><p>计算得到</p><p>$$w_1 = w_0 + \eta y_1x_1=(3,3)^T$$</p><p>$$b_1 =  b_0 + \eta y_1=1$$</p><p>得到一个模型</p><p>$$w_1\cdot x+b_1 = 3x_{(1)}+3x_{(2)}+1$$</p><p>（3）接着继续，计算各个点是否分错，通过计算得到，$x_1和x_2$两个点，$y_i(w_0\cdot x_i+b_1)$都大于0，所以是被正确分类的点，无需修改权值w和bias项；而对于$x_3$通过计算得到$y_3(w_0\cdot x_3+b_1)&lt;0$,误分了，所以修改权值：</p><p>$$w_2 = w_1 + y_3x_3=(2,2)^T$$</p><p>$$b_2 =  b_1 + y_3=0$$</p><p>得到线性模型：</p><p>$$w_2x+b_2 = 2x_{(1)}+2x_{(2)}$$</p><p>一次下去，知道所有的点都有$y_i(w_0\cdot x_i+b_1)&gt;0$即可，最后求得</p><p>$$w_7 = (1,1)^T,b_7=-3$$</p><p>所以感知机模型为：</p><p>$$f(x) = sign(x_{(1)}+x_{(2)}-3)$$</p><p>即我们所求的感知机模型。</p><h2 id="源码实现"><a href="#源码实现" class="headerlink" title="源码实现"></a>源码实现</h2><p>下面是感知器类的实现，详情请看注释。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Mon Jan 29 09:20:04 2018</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: liudiwei</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Perceptron</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_num, activation_func)</span>:</span></span><br><span class="line">        <span class="string">"""init parameter</span></span><br><span class="line"><span class="string">        activation_func: this is a function of activation</span></span><br><span class="line"><span class="string">        input_num: number of sample</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.activation_func = activation_func</span><br><span class="line">        self.weights = [<span class="number">0.0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> range(input_num)]</span><br><span class="line">        self.bias = <span class="number">0.0</span>           </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, input_vecs, labels, iteration, rate)</span>:</span></span><br><span class="line">        <span class="string">"""training model</span></span><br><span class="line"><span class="string">        input_vec: input vetcor, a 2-D list</span></span><br><span class="line"><span class="string">        labels: class label list</span></span><br><span class="line"><span class="string">        iteration: </span></span><br><span class="line"><span class="string">        rate: learning rate</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(iteration):</span><br><span class="line">            self._one_iteration(input_vecs, labels, rate)</span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_one_iteration</span><span class="params">(self, input_vecs, labels, rate)</span>:</span></span><br><span class="line">        <span class="string">"""training model on input_vecs dataset"""</span></span><br><span class="line">        samples = zip(input_vecs, labels)</span><br><span class="line">        <span class="keyword">for</span> (input_vec, class_label) <span class="keyword">in</span> samples:</span><br><span class="line">            output_val = self.predict(input_vec)</span><br><span class="line">            self._update_weights(input_vec, output_val, class_label, rate)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_update_weights</span><span class="params">(self, input_vec, output_val, class_label, rate)</span>:</span></span><br><span class="line">        <span class="string">"""update weights for each iteration"""</span></span><br><span class="line">        delta = class_label - output_val</span><br><span class="line">        self.weights = map(<span class="keyword">lambda</span> (x, w): w + rate * delta * x, </span><br><span class="line">                           zip(input_vec, self.weights))</span><br><span class="line">        self.bias += rate * delta</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__to_string__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">'weights\t: %s\nbias\t: %f\n'</span> % (self.weights, self.bias)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, input_vec)</span>:</span></span><br><span class="line">        <span class="string">"""input input_vec and return a prediction value"""</span></span><br><span class="line">        <span class="keyword">return</span> self.activation_func(</span><br><span class="line">            reduce(<span class="keyword">lambda</span> a, b: a + b,</span><br><span class="line">                    map(<span class="keyword">lambda</span> (x, w): x * w, zip(input_vec, self.weights)),</span><br><span class="line">                    <span class="number">0.0</span>) + self.bias)</span><br></pre></td></tr></tbody></table></figure><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>感知器Perceptron在机器学习当中是相当重要的基础，理解好感知器对后面的SVM和神经网络都有很大的帮助。事实上感知器学习就是一个损失函数的最优化问题，这里采用的是随机梯度下降法来优化。对于感知机的介绍，就到此为止，文章更新部分如有纰漏，还请指正！</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a><strong>References</strong></h2><p>[1] 统计学习方法， 李航 著<br>[2] Wikiwand之Perceptron <a href="http://www.wikiwand.com/en/Perceptron" target="_blank" rel="noopener">http://www.wikiwand.com/en/Perceptron</a><br>[3] Wikipedia <a href="https://en.wikipedia.org/wiki/Machine_learning" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Machine_learning</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;回顾了下以前的博文，发现自己CSDN博客里面有的博文没有同步到这里来。出于温故知新的目的，打算将perceptron引入至此，并在原来的基础上稍作更改，下面请看正文。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="算法" scheme="https://www.csuldw.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="感知机" scheme="https://www.csuldw.com/tags/%E6%84%9F%E7%9F%A5%E6%9C%BA/"/>
    
  </entry>
  
  <entry>
    <title>2017，不再见</title>
    <link href="https://www.csuldw.com/2018/01/02/2018-01-02-annual-summary/"/>
    <id>https://www.csuldw.com/2018/01/02/2018-01-02-annual-summary/</id>
    <published>2018-01-02T15:17:00.000Z</published>
    <updated>2020-04-15T15:04:56.371Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>17年的总结，来的比往年晚了一些。记忆中还在回望着二零一六年十二月的点点滴滴，而如今又是一年。每年的总结，都夹带着一些伤感，今年似乎也不例外。</p><a id="more"></a><h2 id="往事回味"><a href="#往事回味" class="headerlink" title="往事回味"></a>往事回味</h2><ul><li>2017年1月，完成WSpider爬虫；</li><li>2017年3月，完成毕业论文初稿；</li><li>2017年4月，完成毕业论文答辩；</li><li>2017年6月，硕士毕业；</li><li>2017年7月，进入菊厂，开启职业生涯；</li><li>2017年8月，进入东莞，为期一个月硬装实践；</li><li>2017年10月，业余时间开启个人项目，学习与实践结合。</li></ul><p>记得17年1月的时候，出于某某理由，写了一个爬去新浪微博的爬虫。也因为这个项目，收到了很多的邮件和私信。有请教问题的，有提问题的，也有提供招聘信息的。在这里，先感谢大家的信任。作为一名刚步入社会的新人，自己要学的东西还有很多，希望能够在接下来的职场生活中，保留一份自己的爱好。也希望在18年里，将更好地东西分享出来，敬请期待吧~</p><p>说到伤感的事情，毕业旅行便是一个。早在15、16年的时候，就计划着在17年毕业前与实验室的朋友们一起搞一次毕业旅行，可惜最后却没能实现，可惜了。这大概也是人生中的又一次遗憾吧！现在回想起来，这个旅行计划之所以失败，很大程度也得怪罪于自己！或许一个小小的改变，就可以有一个圆满的结局。</p><p>忘记是哪个傍晚，走在E区和F区的路上，隐约闻到了一阵桂花的香味，不知是这片园区真的存在这桂花树，还是因为自己回味校园的味道而产生的错觉……2017这一年，最大的变化大概就是告别了自己的学业生涯，正式开启了职场生活。从长沙来到深圳，慢慢地改变了自己的作息，也慢慢地改变了整个人的生活节奏。以往悠闲自在、时间任由自己安排的学校生活已经不再，而按部就班的职场生活正式来临。简单地说，是多了一份责任，少了一份自由。</p><p>毕业之后，进入菊厂报道，从大队培训开始，走到今天，已经五个月有余了。作为一名应届毕业生，很高兴能够走进菊厂，走进三朵云。记得刚来报道的时候，心里除了兴奋，剩下的就是担忧。因为不确定自己会下发到哪一个地方，哪一个部门。直到7月13日，收到秘书的短信之后，才静下心来。为期一周的大队培训过的很快，虽然纪律严明，但却轻松自在，有一种刚进校园的新鲜感。在培训中，也认识了一些来自五湖四海的佼佼者，从他们身上也学到了很多宝贵的东西。随后到了八月，便开启了自己的硬装历程。</p><p><img src="/assets/articleImg/2018-01-02-2.jpg" alt=""></p><div class="caption">『硬装期间安装天线时拍摄』</div><p>从8月14日到9月9日，足足二十七天，期间经历了两次台风，多次暴雨，庆幸地是，我们最终顺利地完成了四个基站的搭建和拆除工作。此番实践，让我第一次体验了这不一样的生活，不一般的工作。如今走在这大街上，每当看到抱杆或塔上挂的无线天线，或是看到那绝缘胶带，都会立刻回想起那段待在松山湖的日子。这次硬装可以说是一次身心的体验与磨练，那里不仅有优秀的导师和同事，还有足够的基站场地让我们去练习、去开发。面对困难的时候，我们选择的不会是埋怨，而是踏破荆棘，奋勇直前。二十七天，说短不短，说长也不长。印象比较深刻的是，每天只要进了基地，我们的工服就从来没有干过，脸上背上的汗水就没有停过。终于体会到了这汗流浃背、挥汗如雨的刺激。在这四个基站的搭建中，最困难的当属场景二。相比于其他场景，该场景不仅任务量大，而且布线复杂，方舱闷热，从领取物料到各类端子的制作，都要自己亲手做，比较耗费时间，难度略高。然而值得欣慰地是，我们小组的各个成员都赋有吃苦耐劳的健强体魄，都心怀艰苦奋斗的无畏意志，坚持将基站的搭建工作进行到底。从始至终，不抛弃任何一个组员，不放弃任何一个环节，一路上齐心协力，直到最后的完工验。每每想到我们在场景二中那大汗淋漓的场面，以及老师在基站完工时露出的满意的笑容，真心为我们自己感到骄傲，感到自豪。我深深地相信，我们大家都是经得起磨练的丑小鸭，我们每个人都能耐得住寂寞，经得起考验。几周的硬装实践，对于一个应届毕业生来说，可以说是一个很好的心态转变阶段。来到这里的每个人，不少都是当年叱咤校园的风云人物。然而如今作为一名应届毕业生，我们已不再属于哪所学校，也不再是学校的佼佼者。当我们踏上社会的那一刻起，我们就和其他平凡的人们一样普通。要时刻谨记每个行业里都是”山外有山，人外有人“，一定要摆好自己的心态，不要好高骛远，自恃清高。</p><p>在菊厂，起初不太满意的是不能随时随地地同步自己的总结，因为这里面牵扯到信息安全问题。周末想要写些总结型的东西，只能凭自己的记忆来拼凑。后来慢慢地改变了周末学习的内容，也就慢慢的习惯了这个规章制度。在工作上，更多的是朝着全栈的方向来发展，然而自己仍然没有抛却对ML的热爱和学习。目前所做的一切就当是在武装自己的技术储备，厚积薄发，砥砺前行吧！</p><h2 id="厚积薄发"><a href="#厚积薄发" class="headerlink" title="厚积薄发"></a>厚积薄发</h2><p>在工作之余，自己也开启了一个新的任务，原本打算2017年12月月底发布的，却因为时间过于仓促，没能完工。也罢，慢工出细活，将这份礼物放在2018年吧，希望自己在2018年能够早点完成自己的初愿。</p><h2 id="憧憬"><a href="#憧憬" class="headerlink" title="憧憬"></a>憧憬</h2><p>2017年，恍惚的度过了，没有去旅行，也没有认真的写过博客。看着博客17年的内容寥寥无几，着实多了几份空虚。在2018年里，一定要规划好时间，拾回初心，博客不能落下。前路漫漫无人知，且行且珍惜。除了一度关心的博客，也要好好注意身体。元旦当天居然喉咙开始痛疼了，看来抵抗力是真的下降了，不服老都不行了。</p><p>生活总在不断地前行，有人的地方就有故事。在2017年，不知不觉中迷失了一个朋友，愿2018年，一切都能安好。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;17年的总结，来的比往年晚了一些。记忆中还在回望着二零一六年十二月的点点滴滴，而如今又是一年。每年的总结，都夹带着一些伤感，今年似乎也不例外。&lt;/p&gt;
    
    </summary>
    
      <category term="年度总结" scheme="https://www.csuldw.com/categories/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="总结" scheme="https://www.csuldw.com/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>Hello，九月</title>
    <link href="https://www.csuldw.com/2017/09/22/2017-09-22-hello-september/"/>
    <id>https://www.csuldw.com/2017/09/22/2017-09-22-hello-september/</id>
    <published>2017-09-22T15:10:00.000Z</published>
    <updated>2020-04-15T15:04:13.838Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/assets/articleImg/hello-sep.jpg" alt=""></p><div class="caption">『一张温馨图片，献给金秋九月.』</div><p>时隔大半年，回头看着这停滞不前的博客，心里忐忑不安，久久不平。上半年一直在为毕业忙碌，毕业之后进入工作状态，业余时间也就少了很多了。以前在学校的时候，很自由，能够腾出来写博客的实践是一大把，毕竟时间都是自己安排，能够充分地利用。如今进入公司，就不能这么随性了。所以，对于现在这个状态的自己，还是要好好计划好，工作肯定是不能耽误的，当然自己的博客也不能荒废了。</p><a id="more"></a><h3 id="博客那些事"><a href="#博客那些事" class="headerlink" title="博客那些事"></a>博客那些事</h3><p>首先对于自己的这个博客主题，用的时间大概有两年了吧，很久也没有更新过。其实，还是有很多东西可以加进来的。所以，在接下的业余时间里，我打算修复一下本博客遗留的一些BUG，主要包括：</p><ul><li>留言板：现在使用的是disqus，需要翻墙才行，而且有的翻墙软件还不能访问，待解决；</li><li>修改文章POST页面的右边显示；</li><li>About修改：这个是必须的，毕业之后，一些信息还是得修改下；</li><li>分类页面：感觉原本的这个分类页面做的有点不美观；</li><li>Tag页面：适当的换一个吧。</li></ul><p>这个需求对于现在这个状态的我，感觉还是要点时间。不过没关系，慢慢来吧。同时还可以慢慢的加入一些新的特性，比如：</p><ul><li>照片个性展示</li><li>历史读书记录</li><li>个人足迹</li><li>好文推荐</li></ul><p>对于新特性中“好文推荐”，主要是编写一个很Nice的推荐功能。比如先去网上爬去一些评分比较高的文章，然后进行评分，最后进行自动推荐；或者是简单一点的，直接推荐一些知名人士的文章列表；再或者选择一个主题进行推荐等。其实想法还是挺多的，关键是怎么实现更合理，因为有的东西还是得要自己有一个服务器才行，毕竟博主的博客是托管在GitHub上面的。说到这里，还真想去弄一个服务器，搞一个大一点的技术分享网站了。慢慢来吧，这个plan先定在这里吧。</p><h3 id="学习那些事"><a href="#学习那些事" class="headerlink" title="学习那些事"></a>学习那些事</h3><p>虽然现在工作了，但是还是不能停止自身能力的提升。来到华为，在工作时间上，其实与之前在360实习对比，还是差不多的，并没有像外面的人描述的那样，每天晚上搞到十一二点才回去。加不加班这个应该是和部门有关的，而且一般都是“好事不出门，坏事传千里”，加班加的厉害的消息估计都被传到海里海外了。</p><p>OK，言归正传，不管平时有多忙，还是要抽出时间来充充电。就我个人而言，对机器学习这一块还是非常感兴趣的，虽然这大半年懒癌发作，荒废了很多，但还是不会忘记这个定位的，后续还得继续加强自己理论的学习。</p><h3 id="生活那些事"><a href="#生活那些事" class="headerlink" title="生活那些事"></a>生活那些事</h3><p>从长沙来到深圳，告别了学校的三人间，哪个温馨而让人怀念的旧宿舍，如今来到深圳，租了一个一室一厅的民房，装修说不上很好，大体上不破也不新吧，算是一个很大的转变吧。周末闲下来的时候，就自己下下厨，生活得也还过得去。工作两月有余，深圳很多地方现在也还没有去过，自己的单反也很久没用过了，真是对不起当年自己的一腔热血呀。赶紧适应环境，好好稳定下来吧。</p><p>生活还刚开始，对于今后的每一天，我都是满怀期待的。来到深圳这个大城市，不管是学习还是生活，都不能顾此失彼，毕竟日子还是要过得，好好工作,好好加油吧！</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/assets/articleImg/hello-sep.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;『一张温馨图片，献给金秋九月.』&lt;/div&gt;

&lt;p&gt;时隔大半年，回头看着这停滞不前的博客，心里忐忑不安，久久不平。上半年一直在为毕业忙碌，毕业之后进入工作状态，业余时间也就少了很多了。以前在学校的时候，很自由，能够腾出来写博客的实践是一大把，毕竟时间都是自己安排，能够充分地利用。如今进入公司，就不能这么随性了。所以，对于现在这个状态的自己，还是要好好计划好，工作肯定是不能耽误的，当然自己的博客也不能荒废了。&lt;/p&gt;
    
    </summary>
    
      <category term="生活" scheme="https://www.csuldw.com/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="生活" scheme="https://www.csuldw.com/tags/%E7%94%9F%E6%B4%BB/"/>
    
      <category term="九月" scheme="https://www.csuldw.com/tags/%E4%B9%9D%E6%9C%88/"/>
    
  </entry>
  
  <entry>
    <title>SVD奇异值分解逐步推导</title>
    <link href="https://www.csuldw.com/2017/03/09/2017-03-09-svd/"/>
    <id>https://www.csuldw.com/2017/03/09/2017-03-09-svd/</id>
    <published>2017-03-09T12:31:00.000Z</published>
    <updated>2019-07-25T17:00:38.667Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在先前的文章<a href="https://www.csuldw.com/2016/02/28/2016-02-28-pca/">PCA主成分分析Python实现</a>中介绍了一种降维方法，本文主要介绍另一种方法：SVD(Singular Value Decomposition，奇异值分解)。该算法在推荐系统中经常用到，而且也可用于降维，PCA的实现除了通过求解协方差矩阵、特征值、特征向量来计算以外，还可以使用SVD来求解，具体细节本文就不讨论了，下面主要来介绍下SVD的推导。</p><a id="more"></a><h2 id="基本理论"><a href="#基本理论" class="headerlink" title="基本理论"></a>基本理论</h2><ol><li>对于$n$阶方阵$A$，有$Ax=\lambda x$，则$\lambda$特征值，$x$特征向量;</li><li>如果向量$\vec{a}$和向量$\vec{b}$正交，则$\vec{a} \cdot \vec{b} = 0$;</li><li>一个内积空间的正交基（orthogonal basis）是元素两两正交的基,基中的元素称为基向量。如果一个正交基的基向量的模长都是单位长度1，则称这正交基为标准正交基或”规范正交基”（Orthonormal basis）；</li><li>A与A的转置矩阵是有相同的特征值,但是他们各自的特征向量没有关系；</li></ol><h2 id="SVD推导"><a href="#SVD推导" class="headerlink" title="SVD推导"></a>SVD推导</h2><h3 id="Step1：矩阵分解"><a href="#Step1：矩阵分解" class="headerlink" title="Step1：矩阵分解"></a>Step1：矩阵分解</h3><p>对于矩阵$A$，有$A^TA = \lambda_{i} v_{i}$，其中$\lambda_{i}$为特征值，$v_{i}$为特征向量。假定$(v_{i}, v_{j})$是一组正交基，那么有$v_{i}^{T} \cdot v_{j} = 0$，那么：</p><p>$$<br>\begin{align}<br>(Av_{i}, Av_{j})<br>&amp;= (Av_{i})^{T} \cdot Av_{j} \\<br>&amp;= v_{i}^{T} A^T Av_{j} \\<br>&amp;= v_{i}^{T} \lambda_{j} v_{j} \\<br>&amp;= \lambda_{j} \color{red}{v_{i}^{T} v_{j}} \\<br>&amp;= 0<br>\end{align}<br>\label{1}\tag{1}<br>$$</p><p>可以得出$Av_{i}, Av_{j}$也是一组正交基，根据公式\eqref{1}可以推导出$(Av_{i}, Av_{i}) = \lambda_{i} v_{i}^{T} v_{i}=\lambda_{i} $，从而可以得到：</p><p>$$<br>\begin{align}<br>&amp; |Av_{i}|^2 = \lambda_{i} \\<br>&amp; |Av_{i}| = \sqrt{\lambda_{i}}<br>\end{align}<br>\label{2}\tag{2}<br>$$</p><p>根据公式\eqref{2}，有 $\frac{Av_{i}}{|Av_{i}|} = \frac{1}{\sqrt{\lambda_{i}}} Av_{i}$，令$ \frac{1}{\sqrt{\lambda_{i}}} Av_{i}= u_{i}$，可以得到</p><p>$$<br>Av_{i}= \sqrt{\lambda_{i}}u_{i}=\delta_{i}u_{i}<br>\label{3}\tag{3}<br>$$</p><p>其中$\delta_{i} = \sqrt{\lambda_{i}}$，得到这个表达之后，我们可以进一步推导：</p><p>$$<br>\begin{align}<br>AV &amp;= A(v_{1}, v_{2}, \dots, v_{n} ) \\<br>&amp;= (Av_{1}, Av_{2}, \dots, Av_{n} ) \\<br>&amp;= (\delta_{1}u_{1}, \delta_{2}u_{2}, \dots, \delta_{n}u_{n} ) \\<br>&amp;= U\Sigma<br>\end{align}<br>\label{4}\tag{4}<br>$$</p><p>从而可以得出：</p><p>$$<br>A = U\Sigma V^T<br>\label{5}\tag{5}<br>$$</p><h3 id="Step2：矩阵计算"><a href="#Step2：矩阵计算" class="headerlink" title="Step2：矩阵计算"></a>Step2：矩阵计算</h3><p>得到矩阵$A$的表示之后，我们应该如何计算向量$U$和$V$呢？继续往下面分析：</p><p>首先计算出$A$的转置$A^T$:</p><p>$$<br>\begin{align}<br>A^T =  V\Sigma^TU^T<br>\end{align}<br>\label{6}\tag{6}<br>$$</p><p>得到$A$的转置之后，我们接下来计算$A^TA$值：</p><p>$$<br>\begin{align}<br>A^TA<br>&amp;= V\Sigma^TU^T U\Sigma V^T \\<br>&amp;= V\Sigma^2V^T<br>\end{align}<br>\label{7}\tag{7}<br>$$</p><p>通过公式\eqref{7}，可以得到$A^TA v_{i} = \lambda_{i}v_{i}$，只需要求出$A^TA$的特征向量即可得到$V$.</p><p>同理可得$AA^T$的值：</p><p>$$<br>\begin{align}<br>A A^T<br>&amp;= U\Sigma V^T V\Sigma^TU^T \\<br>&amp;= U\Sigma^2U^T<br>\end{align}<br>\label{8}\tag{8}<br>$$</p><p>通过公式\eqref{8}，可以得到$AA^T u_{i} = \lambda_{i}u_{i}$，只需要求出$AA^T$的特征向量即可得到$U$.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>SVD将矩阵分解为$U$和$V$，得到$A = U\Sigma V^T$。我们可以取前k个非零奇异值，将这k个对应的奇异向量合并来进行降维。SVD还可以用于PCA的求解过程，主要用到SVD的右奇异矩阵$V$。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="https://en.wikipedia.org/wiki/Singular_value_decomposition" target="_blank" rel="noopener">Singular_value_decomposition</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在先前的文章&lt;a href=&quot;https://www.csuldw.com/2016/02/28/2016-02-28-pca/&quot;&gt;PCA主成分分析Python实现&lt;/a&gt;中介绍了一种降维方法，本文主要介绍另一种方法：SVD(Singular Value Decomposition，奇异值分解)。该算法在推荐系统中经常用到，而且也可用于降维，PCA的实现除了通过求解协方差矩阵、特征值、特征向量来计算以外，还可以使用SVD来求解，具体细节本文就不讨论了，下面主要来介绍下SVD的推导。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="SVD" scheme="https://www.csuldw.com/tags/SVD/"/>
    
      <category term="奇异值" scheme="https://www.csuldw.com/tags/%E5%A5%87%E5%BC%82%E5%80%BC/"/>
    
      <category term="推荐系统" scheme="https://www.csuldw.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>2016，明天你好</title>
    <link href="https://www.csuldw.com/2016/12/31/2016-12-31-annual-review/"/>
    <id>https://www.csuldw.com/2016/12/31/2016-12-31-annual-review/</id>
    <published>2016-12-31T14:10:00.000Z</published>
    <updated>2020-04-15T15:04:53.873Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>前阵子，幸运的中了一篇BIBM regular paper，对于不打算继续攻读PhD的自己，整个硕士也算是没有遗憾了。这两天，隔壁实验室的导师又开始催着交论文初稿了，恍恍惚惚地才意识到，一年又到头了。这一年，去过很多城市，走过很多地方，也收获了许多曾经。零零碎碎的事情比较多，为了勉励下自己，还是决定写点东西。有时候感觉，一个人静静地坐在椅子上回想着过去的点点滴滴，会心地一笑，淡然地释怀那些不开心的往事，也算是一种觉悟、一种享受吧。</p><a id="more"></a><p>去年的这个时候，也在写总结。从当时日记的字里行间可以看出，当时自己不知为何心情好像还有点压抑，可能是因为忆往昔容易触景生情吧。也罢，也罢，是时候换个心态了！翻着这一年在不同的地方记下的那些残言片语，想着那时那地那景那情，似乎还有一种故地重游之感，Nice ^_^！今年走过了很多的城市，也遇到了很多的人，还找了一份工作，可以说目前应该是自己多年以来最轻松的时光了，就等着论文答辩然后毕业吧。</p><p><img src="/assets/articleImg/sun.png" alt=""></p><div class="caption">『早晨的太阳，隔着窗户倒别有一番风景.』</div><p>印象中，今年的春季开学前，自己还在找特征换算法跑模型。说实在的，要想发一篇好的paper，好的idea的确是very important的！感觉那时已经折腾的精气神都快没了，paper修改完之后便马上交于导师，随后就开始着手准备春季实习面试。过完年，正月初六就从家里赶出来，万万没想到的是那天在高速路上竟堵了十多个小时。初六中午十二点的车，正常驾驶的话，下午四五点应该就可以到长沙，结果却堵到了初七早上六点，算是打破了我多年来乘坐大巴的好几项记录了。接着，初八去当了伴郎，算起来这也是我人生第二次当伴郎了，以后还是不能再当了，初九便开始了我的学习之旅。开始啃算法，该复习的复习，该学习的学习，敲代码，写Demo，做笔记，etc。看到算法先啃原理，然后再去实现，实现不了的就找相关库，再去理解，反反复复，仿佛一切就像是昨天一样清晰可见。这段时间也是自己这一年最发奋的时间段吧，很多知识都从陌生走到了熟悉。谈到春季面试，碰壁当然是在所难免的，但总的来说自己倒也还挺幸运，最后去了奇虎360做推荐。三月底发的offer，在与HR沟通之后确定四月中旬入职。给我的感觉是，360的HR倒还挺和善的（或许别的公司也一样吧！）。四月份，因为之前确定了offer，腾讯和网易的面试也都让自己给推掉了，当时倒也不觉得可惜（现在想想当时应该去一下的，增加点面经也是不错的）。</p><p>去北京的那天是4月19日，坐的是高铁。说实在的，我倒是倾向于乘坐高铁，比飞机舒服，比火车快，而且价格也还OK。还记得刚到北京的那个时刻，那是一个阴天，北京的上空被一层层的雾霾笼罩着，灰茫茫的天空里夹带着细如鹅毛的白色杨絮，随风飘散着，北风吹在身上还有股凉意。从北京西站的高铁站望去，那里走着一个初来乍到的年轻人，拖着一个象牙白色的箱子，外着一件蓝色衬衫，背着一个黑色的电脑包，短发，四处观望着，俨然一个找不到家的游子——是的，那就是我，一个来到陌生城市的陌生人。</p><p>记得进京的第一天，到达高铁站的时候，已经傍晚了。在高铁站办了地铁卡，然后就去找订的旅社，之后就去办了银行卡，晚上就在公司附近走了走，感觉还不错，离旅社不是很远。第二天，前去报到，不料帝都早上的公交太堵了，就提前给HR竟文姐发了个短信告知了堵车，她说没关系，到的时候直接去某某大厅就可以了，最后还是迟到了一刻钟，还算OK吧。接着听入职宣讲、签合同、领工卡、找工位、领器材、配置电脑等等，一上午很快就过去了。在这里，还是感谢下那位HR实习生不辞辛苦的接待和指导。下午就开始接触业务知识，节奏很快，确实有点措不及防。晚上在公司就餐，奈何饭点时间是七点半，让我们这种从学校刚出来的学生如何等的起，难堪！以前在学校，五点半没到就吃晚餐，现在却要推迟两小时，结果可想而知，开始那段日子饿的真心难以承受。工作之余，好心的同事告诉我，公司内网会有一些新的租房信息，让我关注下。也就是内网，让我认识了一位待离职同事和一位新的室友，也让我从一个又小又贵的旅社里住到了京旺家园1500元/月的80平二室一厅的二居室里，房间里应有尽有，并且距离公司5公里左右，下班回去之后，还可以坐在沙发上看看电视，真是享受了长达两个月的好日子。后来六月低搬到了公司附近2公里左右79元/天的蒋府家园，起初还有个孕妇大姐住在隔壁卧室，认识了几天，就搬走了。虽然是四居室，但后来的室友基本都是“闭门自居”的，平时也见不着个人影儿，入住一月有余却连名字叫不上，更谈不上交流了。也罢，作息不一样，只能如此啦！慢慢地，开始有了一种漂泊感，或许这就是他们所说的没有归属感。有过这种经历也算是一种磨练，一种成长吧。</p><p>来北京实习，确实出乎了我的意外。以前和同学朋友聊天的时候，从来都没想过要去北京。或许是因为我是南方人；或许是因为离家太远；或许是因为人生地不熟；又或许是因为北京的空气吧。只是人在江湖，身不由己。事已至此，就抱着“既来之，则安之”的心态，开始计划着如何来度过这实习期！回想起在京的那段日子，说实在的还真的有点让人留恋。那里有很好的办公坏境和休闲场所；有周末的双休节假日；重要是有一群志同道合的非常随和的同事。虽然每天回去的时间比较晚（十点左右吧），但确实让我感觉非常充实。周末，还可以去周边的景点溜达溜达，也算是不枉此行吧。有段时间，很喜欢一个人去鸟巢，去听奥森公园里的流浪歌手唱歌；去看那水立方旁边的广场上一群群小孩练习着滑冰、跳绳；去看鸟巢晚上五彩缤纷的夜景。我只是静静的坐在地上，享受着周围这一切带来的美好。记得有这样一句歌词，“不喜欢孤独，却又害怕两个人相处。”，说的大概就是我吧。离开前去了一趟长城，在长城的堡台上说了一句这样的话，“北京最后一站，是再见，还是再也不见……”。现已确定了工作去向，再见确实很难了。说来也是惭愧，实习离职前，直系上属超哥还诚心诚意叮嘱我一定要回去，甚至在后面校招时还直接发了offer，而我最后却没有去。选择的同时，也代表着放弃。这应该是今年做的最败人品的一件事情了，以后有机会再见面的话，还是要诚心诚意地道个歉。</p><p>说到工作，今年秋招确实掀起了一阵腥风血雨。那段时间，实验室的同学面的都是后端、前端、Android等岗位，只有我投的是算法、ML或DM方向，孤阵无援，靠的只能是自己。让你想不到的是，一次次的笔试真的会让人渐渐开始怀疑自己的能力。当然，路都是自己选的，就得有担当、有毅力，否则不是打自己脸么T_^。起初的情况是这样的，北京那边的公司我真的是一个都没投，一方面是因为心里捉摸着要是去其它公司，还不如回360呢，至少还有熟悉的人，还可以做着喜欢的事；另一方面，自己确实不想去北京这个城市，房价是一回事，还有空气质量差、干燥、饮食不习惯等一系列的问题，的确不适合我。好在后来深圳的菊花厂给了一个SP，城市也是自己挑的，也算是尽了人事由天命了。那段时间，周边求职的同学（当然也包括我）心情都不大好，有多少苦多少泪大家都憋在心里，其实我们心里都知道，只是不愿意说出来而已，都想着找个好工作之后，然后再一起庆祝吧。</p><p>工作定下来之后，便与同学去了一趟西北，走了一个小环线。见证了那晶莹剔透的雪山，碧海蓝天的青海湖，有着绝世地貌的雅丹魔鬼城，还有那长风万里嘉峪关，以及金灿灿的金塔胡杨林等等，也算是意料之外的一次旅行！对于胡杨林，当时记下了下面这几句话，也因此让同行之人开了几天的玩笑，真有意思，让人百思不得其解！</p><center style="margin-top:-10px">茫茫荒漠夜缠绵，金塔胡杨度千年。孤枝嫩叶寒霜冻，春来秋去惹人怜。  </center><p>从西宁返回兰州的那天，火车上与一位老人并排而坐。一路上听着他诉说着他的故事，也算得上是一种意外的享受。这位老人经历的事情比我们现在苦多了，时运造人，一点都不假。在他年轻的那个时代，充斥着危险，或许一个不小心人就没了,所以才有了如今的他吧。</p><p><img src="/assets/articleImg/xibei.png" alt=""></p><div class="caption">『西北之旅，让我明白了很多事情.』</div><p>旅行，应该是大多数人都喜欢的！在我的世界观里，我会把旅行当作是释压放松的一种方式，同时也当成是一种享受。所以，每次出去的时候，我会将除了旅行以外的事情都抛之脑后，暂且放下。因为如果在旅程中有任何的不如意，都直接决定了这次游玩的成败。此次西北之行，是小黄鸡带的队，自己也是临时才做的决定，没有考虑到太多的因素，算是一个经验吧。去的当晚十二点左右收到了BIBM的投稿结果，看到Accept的时候，很是让人兴奋。随后给导师发了个消息，也算是这么久以来最大的收获吧，也谢谢导师长久以来不抛弃不放弃的心态。</p><p>在京的那段时间，趁着周末的双休日，自己也去过很多景点，从四月到八月，想去的景点基本上都去了，有的甚至去了好几次。有时是一个人，有时则与朋友一起。刚去的时候，不知道可以使用学生证，直到后来跟同学一起去北海才知道，原来在帝没有研究生与本科生之分，甚至只要有校园卡都可以买半票，真是白白浪费了好多门票钱<del>o(&gt;_&lt;)o ~</del>。细数那些走过的地方，风景自在心中，余味犹存……</p><ul><li>四月：天安门、故宫、王府井、蓝色港湾、颐和园、798</li><li>五月：后海 ＆ 什刹海、北海、南锣鼓巷、奥林匹克森林公园、鸟巢 &amp; 水立方</li><li>六月：青龙峡、香山、北大、奥林匹克森林公园 （夜景）</li><li>七月：北京园博园Shark Run 乐跑、北海</li><li>八月：长城、奥林匹克森林公园（夜景） 、鸟巢（演唱会）</li></ul><p><img src="/assets/articleImg/beijing.png" alt=""></p><div class="caption">『实习那会儿在北京拍下的照片，难得的蓝天白云，留个纪念.』</div><p>如果北京的空气没有那么糟，天空还是特别蓝的，环境还是挺好的，可惜没有如果。北京的天空，一个月能见到三到四次蓝天白云就很不错了。其实我在北京那会儿，周末的晚上还喜欢去看电影。即使是一个人，只要有好的电影上映了，我都会义不容辞的去捧个人场，献上自己的一张门票。庆哥经常说我跟他以前很像，说他在我这个年纪的时候也经常这样出去玩，现在结婚了，不在这么玩了。政哥则笑着说我真会玩，他周末一般都宅着，大概是因为毕业了吧。政哥是在我前一周入的职，正式员工，比我年长一岁，在部门里算是与我走的比较进的同事了，与我相邻而坐，有时候有什么问题还可以向他请教。他的想法倒是跟我也很像，比如都有想过先在外面拼个几年磨练下自己，成家这些都还是次要。感觉他的抗压能力确实挺强的，六月份同事离职，将很多的任务都交接给他，最后他都毫不埋怨地接过来了。日常交流中，同事都经常开他玩笑，叫他“老司机”，虽然不知道什么意思，但我也跟着这么叫。后来来了新同事，政哥就要我改口，要是叫他“老司机”他就不应答我，没办法哈，只能妥协啦，慢慢地就改口叫政哥了，对于“老司机”这个nickname，也就偶尔喊一下了。</p><p>相比去年，今年静下来学习的时间少了很多，大多数时间都在外奔波。六月的时候，用了下Gitbook，确实比较好用，可以将自己写的文章按章节布置好，然后它会自动的绑定Github，并发布到网上。又一次，在删Gitbook的时候，不幸将自己的Github给删了，那天中午没午休，整个大脑都有点混乱。当时看到这个结果，有些失落，毕竟自己的blog还托管在上面，有点无奈。当时就Email联系了Github的管理员，短时间内没有收到回复，我就新建了一个同名账户。主要还是因为时差问题，他们那时的时间正处在晚上，估计都休息了吧。第二天早上看到了管理员的回复，说是暂时无法召回，因为以前的账号与新建的用户重复了，需要将新建的账户删掉才能找回之前的账户和项目。来来回回几封邮件耗了好几天时间，所幸最后还是把账号找回来了，只是Github的加入年限变成今年的了，有点小忧桑，编程新用户了。自从去了北京之后，CSDN的兼职翻译也停了下来，技术博客的更新也没有以前那么勤快了，与朋友聊天的时间也少了，有的甚至开始生疏起来。渐渐地开始意识到，以后工作了，剩下的时间大概是少之又少了，且行且珍惜吧！没去北京前，我曾一度想过以后就留在长沙，找一份薪水还OK的工作就行，小城市毕竟还是有小城市的好处的。后来整个思想都转变了，慢慢地明白，如果要想发展地好点，大城市是必须要去的，没有经历风雨，哪能见得彩虹！那里才是我们这些年轻人该去的地方，或许是个三五年，又或许会是一二十年吧。我相信，时间会慢慢地将你想要的东西悉数给你的，只要你肯付出，只要你愿意等。</p><p>最近，为了学习，又迷恋上了爬虫。从爬取房价到模拟知乎登录，再到新浪微博，瞎倒腾了一番，也算是掌握了一些爬虫基础。为此写了好几篇笔记，就当是为后来者做点贡献吧。从深圳回来之后又开始倒腾爬虫了，主要还是以新浪为主，打算爬点数据，做个统计分析什么的。不料前几天爬取的数据有点多，一不小心，让新浪把我的IP给禁了，真的是给禁了，打开链接满满的全都是“403 Forbidden”，忧桑%&gt;_&lt;%。原本代码里已经使用了代理，并且还用了多个账户在多进程的情况下爬取，数据量倒还OK的，没想到还是被识别出了真实ip，真是一大失误啊！真该好好反省反省了。</p><p>今年收到了很多的Email，大多是看了我的blog，或是Github的项目找过来的。其中有请教学习的，也有邀请去面试的，有介绍做兼职项目的，还有邀请去做知识分享、写书等等。对于那些向我请教的朋友，我都尽我所能地去为他们解答（当然力不能及的时候也有）。对于做知识分享以及撰写书籍之类的邀请，我自知能力不足，为免误人子弟，都一一推掉了。希望等以后强大的能够撑起我的个人世界的时候，再谈这些吧。虽然现在维护的blog已经有两年了，写过的文章有许多也已被转到其他网址或是分享到微信公众号上，但个人觉得自己的知识面比较窄，同时深度也不够，还需继续fighting。曾在实习的时候，超哥面试其它的应聘者都会问到VC Dimension（VC维），当时我对这个概念还是有点模糊，模棱两可，直到实习结束后才进一步学习了一番。学海无涯，大概就是这个道理。前两天，实验室的师妹生日，不由得想到了今年自己的生日。那天是八月中旬的某一天，也是回长沙的前一天。其实，今年我也没打算过生日的。那天中午与亚君和棋民哥一起吃的饭，那一顿算是为我践行吧，棋民哥也是湖南的，算是老乡吧。晚上就约了立波还有他的女朋友一起吃的烧烤，还弄了点扎啤，味道还是挺棒的，这一顿主要是为了谢谢立波在我刚来北京时对我的款待，另外也算是告别一下。回去之后，还与另一个同事去看了场电影，没记错的话应该是《使徒行者》。这一天，经历的事情倒是挺多，不过他们都不知道那天是我的生日，感觉简简单单的过着也挺好的。对了，还有一件比较有趣的乌龙事件。公司每个月月底都会举行生日趴，在七月底举行生日趴的时候，意外的把我的生日也糊里糊涂的给过了，其实我是农历七月，到了阳历就成了八月了。无辜的收了一份生日礼物，还收到了超哥的贺卡，狮子座的我真有点受宠若惊呀。这么好的心意，我也就不推辞了，谢谢领导的厚爱吧！</p><p>12月中旬，去深圳参加了BIBM，虽然不是ML方向的顶级会议，但却是顶级的国际医学会议，荣幸之至。由于自身英语表达能力的欠缺，presentation的讲解着实有些吃力，QA环节也略显尴尬。不过这些都不重要了，重要的是结识了一群博士生和留学生，同时认识到了自身的不足，涨知识了。原本还打算在深圳多待留几日，与深圳的同学朋友聚一聚，顺便看看深圳的海，最后因故还是没改签。只能说计划赶不上变化，只能明年工作的时候再去深圳找他们聚聚了。说起大学同学，今年结婚的倒是没有，不过当爹当妈的倒是有三四个了，看着TA们开开心心的在群里相互晒baby，真为TA们高兴，羡慕，祝福TA们(<em>^__^</em>) ！。目前还在读书的同学，远哥是打算出国攻读博士，不知道现状如何了；许同学现在则还在Pittsburgh，PITT，据说今晚要在飞机上跨年回国，听起来还蛮霸气的，愿一路平安就好！而我呢，以后还是一心一意去工业界吧！</p><p><img src="/assets/articleImg/bibm.png" alt=""></p><div class="caption">『前不久去深圳参加了BIBM会议，左边的是餐票，右边的是日程安排.』</div><p>前不久，班上一位同学的父母生病了，需要大笔的医疗费，人生最不幸的应该就属这种事情吧，希望叔叔阿姨能够早日康复！是的，家家有本难念的经！小时候，自己家里也曾遭遇过一次，我姐也因此而辍学，最后家里就只剩我一人在读书了。从初中到高中，再到大学、研究生，说没点压力是不可能的，这或许也是我有点偏向独处的缘故吧！现在看来，整个家里面最轻松的应该就属我了。很多人都是身在福中不知福，还是好好珍惜才好！说到身体，今年的自己还算可以，没有什么大病，只是最近感觉脖子有点不舒服，左右摆动时会有点酸痛，希望只是简单的落枕。对于视力，感觉肯定又下降不少，之前做入职体检的时候，左眼是5.0，右眼是4.8，估计现在更糟糕了！虽然目前还没有戴眼镜，不过感觉离戴眼镜的日子真的不远了。终于能够渐渐体会到大学时同学说的没注意到了，真是惭愧！</p><p>大学毕业之后，身在长沙的我每年的秋天都会去母校转转，看看枫叶，逛逛校园，见见朋友。今年也一样，只不过今年的枫叶没有往年的那么红艳，可能是我去的时间不大合适吧！在大学里，处的最好的老师当属我的英语老师文静姐了，说来话长，这里就不多阐述了。算了算大概有一年多没见了，毕业前一定得去探望下。</p><p><img src="/assets/articleImg/bless.png" alt=""></p><div class="caption">『愿来年大家工作顺利.』</div><p>在学校的时候，我喜欢一个人安静的在跑道上跑步，不快也不慢，锻炼身体的同时，还可以让我思考很多事情。不过最近好一段时间没去跑步了，整天瞎忙活，也没出点成果，有点小沮丧。曾看到过这样一句话，“我们总像智者一样去劝慰别人，却像傻子一样折磨自己。”，很实在，也很现实。经过这多年的生活，慢慢的也开始意识到这样一个道理：<strong>好脾气是好，但一定得有个度</strong>。是的，凡事都得有个度！你对别人一再的好，别人未必就会领你的情。相反，他们也许会把这当作是理所当然。于是，你会一直处在一个“被欺负中”的位置，终于有一天，你无法忍受了，当你选择沉默的时候，他们则会认为是你变了，甚至还可能到处去说你的不是，他们不懂反省你为什么突然这样子了，实际上只是你比别人多懂了一些尊重人的道理而已。</p><p>今年的平安夜，以前实验室的昊总求婚了，整个过程布置的非常用心，用的是Darry Ring 钻戒，一生只送一人，先在这祝福这对准夫妻吧！希望明年工作中的我能有时间去参加他们的婚礼(*^__^*) ……。至于我，没有关系，幸福可以来的慢一些，我可以等，只要它是真的。</p><p>从2016年的元旦到今天，整整一年了！2017，明天，你好！祝大家新年快乐！Happy new year！</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前阵子，幸运的中了一篇BIBM regular paper，对于不打算继续攻读PhD的自己，整个硕士也算是没有遗憾了。这两天，隔壁实验室的导师又开始催着交论文初稿了，恍恍惚惚地才意识到，一年又到头了。这一年，去过很多城市，走过很多地方，也收获了许多曾经。零零碎碎的事情比较多，为了勉励下自己，还是决定写点东西。有时候感觉，一个人静静地坐在椅子上回想着过去的点点滴滴，会心地一笑，淡然地释怀那些不开心的往事，也算是一种觉悟、一种享受吧。&lt;/p&gt;
    
    </summary>
    
      <category term="年度总结" scheme="https://www.csuldw.com/categories/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="总结" scheme="https://www.csuldw.com/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>新浪微博数据爬取Part 3：小爬虫的诞生</title>
    <link href="https://www.csuldw.com/2016/12/25/2016-12-25-sina-spider-user-data-part3/"/>
    <id>https://www.csuldw.com/2016/12/25/2016-12-25-sina-spider-user-data-part3/</id>
    <published>2016-12-25T11:10:00.000Z</published>
    <updated>2017-09-27T13:46:44.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在前几篇博文里，<a href="http://www.csuldw.com/2016/11/10/2016-11-10-simulate-sina-login/">【模拟新浪微博登录：从原理分析到实现】</a>一文介绍了如何登陆微博，<a href="http://www.csuldw.com/2016/12/24/2016-12-24-sina-spider-user-data-part1/">【新浪微博数据爬取Part 1：用户个人信息】</a>与<a href="http://www.csuldw.com/2016/12/24/2016-12-24-sina-spider-user-data-part2/">【新浪微博数据爬取Part 2：好友关系与用户微博】</a>两篇文章介绍了如何爬取微博用户个人资料、关注者列表、粉丝列表以及发表的微博。那么，在这篇文章里，将介绍如何把前几篇的内容融合到一起，整合成一个完整的新浪爬虫框架。OK，让我们来见证一个爬虫的诞生吧^_^。</p><a id="more"></a><p>本文代码请移步Github：<a href="https://github.com/csuldw/WSpider/tree/master/SinaWSpider" target="_blank" rel="noopener">https://github.com/csuldw/WSpider/tree/master/SinaWSpider</a>。</p><h2 id="环境说明"><a href="#环境说明" class="headerlink" title="环境说明"></a>环境说明</h2><ul><li>开发语言：Python 2.75；</li><li>Python相关库：BeautifulSoup、urllib、urllib2、base64、rsa、json、logging、pymongo。</li><li>数据存储：MongoDB 3.2 + Robomongo 0.9.0 可视化工具</li></ul><p>如果你的Python环境里没有上述的某个库，那么使用<code>pip</code>或是<code>easy_install</code>来进行安装。另外，如果你暂时不打算使用MongoDB存储数据，也可在<code>./output</code>目录中查看每个用户的相关信息。</p><h2 id="方法封装"><a href="#方法封装" class="headerlink" title="方法封装"></a>方法封装</h2><p>为了方便，我们首先将爬取新浪相关的方法都封装到<code>SinaSpider.py</code>文件中，该文件可以说是新浪spider的核心内容，里面主要是SinaClient类，内部方法说明如下。</p><h3 id="主要方法"><a href="#主要方法" class="headerlink" title="主要方法"></a>主要方法</h3><p>对于整个爬虫项目，外部函数调用内部方法的时候只需要关注以下几个即可：</p><ul><li>login(self, username, password)：根据用户名和密码登录sina微博；</li><li>switchUserAccount(self, userlist)：用于切换用户账号，防止长时间单账号爬取，其中调用了login方法；</li><li>getUserInfos(self, uid)：根据用户ID获取用户个人信息；</li><li>getUserFollows(self, uid, params)：根据用户ID 获取用户关注的用户ID列表；</li><li>getUserFans(self, uid, params)：根据用户ID 获取粉丝ID列表；</li><li>getUserTweets(self, uid, tweets_all, params)：根据用户ID 获取微博，tweets_all是一个list变量。</li></ul><p>如果还需要爬取微博其它的数据，可在SinaClient类中补充即可。</p><h3 id="辅助方法"><a href="#辅助方法" class="headerlink" title="辅助方法"></a>辅助方法</h3><p>对于该爬虫，我们想要的就是让她正常工作，所以为了防止访问次数超限，可在爬取过程中调用<code>switchUserAgent</code>来切换用户代理，或是在使用cookie的时候，将enableCookie中的 enableProxy参数置为True。在SinaClient类中，其它的辅助方法说明如下：</p><ul><li>initParams(self)：初始化参数；</li><li>setAccount(self, username, password)：设置username与password；</li><li>setPostData(self)：设置请求登录时的post_data内容；</li><li>switchUserAgent(self, enableAgent=True)：切换用户代理User-Agent；</li><li>enableCookie(self, enableProxy=False)：允许存储cookie；</li><li>openURL(self, url, data=None)：打开url时携带headers,此header需携带cookies；</li><li>output(self, content, out_path, save_mode=”w”)：将文本内容输出至本地。</li></ul><h2 id="参数封装"><a href="#参数封装" class="headerlink" title="参数封装"></a>参数封装</h2><p>为了方便配置变量，我们将一些需要自己赋值的变量抽取出来，写入到<code>conf.ini</code>文件，而加载该配置文件的代码写与<code>myconf.py</code>中，并在<code>myconf.py</code>文件中定义一些中转变量agent_list 和userlist，方便切换代理和更换用户时使用，同时将配置日志输出的代码写到<code>Logger.py</code>中。另外，对于登录时提交的与post_data 有关的数据都封装到<code>dataEncode.py</code>。对于这几个文件，可概括如下：</p><ul><li>conf.ini：用于配置proxies、headers等参数，其中Sina API的参数需设置成自己的；</li><li>myconf.py：加载配置文件；</li><li>dataEncode.py：用于模拟登录sina时提交的POST数据；</li><li>Logger.py：用于输出日志文件；</li></ul><p>在上述文件中，<code>dataEncode.py</code>文件里有个值得一提的参数，那就是encode_post_data方法中的post_data。如果你使用第一个post_data，那么有的账号是需要输入验证码的，在运行本代码时，有的用户无法正常登陆，她会提示你“Login Failed –&gt; 为了您的帐号安全，请输入验证码”，因此，笔者在敲代码的时候将第一个注释掉了，一般使用第二个post_data。别问我怎么知道的，实践才是真理啦。通过封装参数之后，我们只需要将<code>myconf.py</code> 中的userlist 修改成自己的账户列表就可以正常登录了。如果你还想增加代理，那么只需将<code>conf.ini</code>中的proxies 设置称自己的代理即可。</p><blockquote><p>温馨提示：如果你对Sina API感兴趣，并想试下它的用法，那么你可以将conf.ini中的access_token与app_key设置成自己配置新浪API接口时获取的值（请自行查阅相关资料），然后另写一个test方法调用getUserInfo方法便可得到相应的JSON数据。</p></blockquote><h2 id="调用封装"><a href="#调用封装" class="headerlink" title="调用封装"></a>调用封装</h2><p>通过上面的方法封装和参数封装，我们可以很方便的进行调用了。这里，我们将代码的执行函数写入到<code>main.py</code> 文件里，后续如果还需要得到什么样的结果以及如何存储这些返回的结果集，都可以在此文件中编写。</p><ul><li>main.py：运行项目的入口文件</li></ul><h2 id="结果说明"><a href="#结果说明" class="headerlink" title="结果说明"></a>结果说明</h2><p>截止2016年12月25日，该爬虫共可爬取如下几部分信息，每个函数的返回值均为JSON串：</p><p><strong>1.getUserInfos获取用户信息</strong></p><figure class="highlight armasm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">uid</span>：用户ID</span><br><span class="line"><span class="symbol">nickname</span>：昵称</span><br><span class="line"><span class="keyword">address：地址</span></span><br><span class="line"><span class="keyword">sex：性别</span></span><br><span class="line"><span class="keyword">birthday：生日</span></span><br><span class="line"><span class="keyword">desc：简介</span></span><br><span class="line"><span class="keyword">marriage:婚姻状况</span></span><br><span class="line"><span class="keyword">follows_count：关注数</span></span><br><span class="line"><span class="keyword">fans_count：粉丝数</span></span><br><span class="line"><span class="keyword">tweets_count：微博数</span></span><br><span class="line"><span class="keyword">homepage：首页链接</span></span><br><span class="line"><span class="keyword">reg_date：注册时间</span></span><br><span class="line"><span class="keyword">tag：标签</span></span><br><span class="line"><span class="keyword">sex_orientation：性取向</span></span><br></pre></td></tr></tbody></table></figure><p><strong>2.getUserFollows获取用户关注人</strong></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">uid：用户ID</span><br><span class="line">follow_ids：关注人ID列表</span><br></pre></td></tr></tbody></table></figure><p><strong>3.getUserFans 获取用户粉丝</strong></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">uid：用户ID</span><br><span class="line">fans_ids：粉丝ID列表</span><br></pre></td></tr></tbody></table></figure><p><strong>4.getUserTweets获取用户微博信息</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">uid：用户ID</span><br><span class="line">content：微博内容</span><br><span class="line">created_at：发表时间</span><br><span class="line"><span class="built_in">source</span>：发布工具/平台</span><br><span class="line">comment_count：评论数</span><br><span class="line">repost_count：转载数</span><br><span class="line"><span class="built_in">type</span>：微博类型（原创/转发）</span><br><span class="line">like_count：点赞量</span><br><span class="line">reason：转发理由（原创博文无理由取值为空）</span><br></pre></td></tr></tbody></table></figure><h2 id="存储结果"><a href="#存储结果" class="headerlink" title="存储结果"></a>存储结果</h2><p>调用main.py文件会得到四个结果，截图如下：</p><div class="caption">『用户个人信息表.』</div><p><img src="/assets/articleImg/sina-data-infos.png" alt=""></p><div class="caption">『用户关注表.』</div><p><img src="/assets/articleImg/sina-data-follows.png" alt=""></p><div class="caption">『用户粉丝表.』</div><p><img src="/assets/articleImg/sina-data-fans.png" alt=""></p><div class="caption">『用户微博表.』</div><p><img src="/assets/articleImg/sina-data-tweets.png" alt=""></p><p>由于博主时间有限，目前该爬虫正处于成长阶段，部分功能尚未完善，需进一步优化，如果感兴趣，可关注博主的微博<a href="http://weibo.com/liudiwei210" target="_blank" rel="noopener">@拾毅者</a>，或是移步Github 关注本爬虫<a href="https://github.com/csuldw/WSpider/tree/master/SinaWSpider" target="_blank" rel="noopener">SinaWSpider</a>的最新动态。最后，祝大家圣诞节日快乐吧，期待下个路口遇见你。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="http://www.csuldw.com/2016/11/05/2016-11-05-simulate-zhihu-login/">小试牛刀：使用Python模拟登录知乎</a></li><li><a href="http://www.csuldw.com/2016/11/10/2016-11-10-simulate-sina-login/">模拟新浪微博登录：从原理分析到实现</a></li><li><a href="http://www.csuldw.com/2016/12/24/2016-12-24-sina-spider-user-data-part1/">新浪微博数据爬取Part 1：用户个人信息</a></li><li><a href="http://www.csuldw.com/2016/12/24/2016-12-24-sina-spider-user-data-part2/">新浪微博数据爬取Part 2：好友关系与用户微博</a></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在前几篇博文里，&lt;a href=&quot;http://www.csuldw.com/2016/11/10/2016-11-10-simulate-sina-login/&quot;&gt;【模拟新浪微博登录：从原理分析到实现】&lt;/a&gt;一文介绍了如何登陆微博，&lt;a href=&quot;http://www.csuldw.com/2016/12/24/2016-12-24-sina-spider-user-data-part1/&quot;&gt;【新浪微博数据爬取Part 1：用户个人信息】&lt;/a&gt;与&lt;a href=&quot;http://www.csuldw.com/2016/12/24/2016-12-24-sina-spider-user-data-part2/&quot;&gt;【新浪微博数据爬取Part 2：好友关系与用户微博】&lt;/a&gt;两篇文章介绍了如何爬取微博用户个人资料、关注者列表、粉丝列表以及发表的微博。那么，在这篇文章里，将介绍如何把前几篇的内容融合到一起，整合成一个完整的新浪爬虫框架。OK，让我们来见证一个爬虫的诞生吧^_^。&lt;/p&gt;
    
    </summary>
    
      <category term="Spider" scheme="https://www.csuldw.com/categories/Spider/"/>
    
    
      <category term="Python" scheme="https://www.csuldw.com/tags/Python/"/>
    
      <category term="Spider" scheme="https://www.csuldw.com/tags/Spider/"/>
    
      <category term="Sina" scheme="https://www.csuldw.com/tags/Sina/"/>
    
      <category term="微博" scheme="https://www.csuldw.com/tags/%E5%BE%AE%E5%8D%9A/"/>
    
  </entry>
  
  <entry>
    <title>新浪微博数据爬取Part 2：好友关系与用户微博</title>
    <link href="https://www.csuldw.com/2016/12/24/2016-12-24-sina-spider-user-data-part2/"/>
    <id>https://www.csuldw.com/2016/12/24/2016-12-24-sina-spider-user-data-part2/</id>
    <published>2016-12-24T11:10:00.000Z</published>
    <updated>2017-03-26T07:01:32.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>上一篇博文<a href="http://www.csuldw.com/2016/12/24/2016-12-24-sina-spider-user-data-part1/">新浪微博数据爬取Part 1：用户个人信息</a>介绍了如何爬取用户个人资料，使用了BeautifulSoup以及正则表达式，最后得到了与用户有关的14个字段。在这篇文章里，将继续介绍如何爬取微博数据，爬取的内容包括用户的粉丝、用户的关注者、用户个人发表的微博三部分信息。博主知道，没有完整的项目源码支持，对于初学者来说，确实是一件不容易的事。所以，笔者打算先将每个部分的代码单独抽取出来，等到下一篇附上源码的同时，介绍如何运行整个爬虫项目。</p><a id="more"></a><p>本文继续使用第二种方法进行数据爬取，与登录有关的信息,此处就不重复介绍了，读者可参考前面的文章<a href="http://www.csuldw.com/2016/11/10/2016-11-10-simulate-sina-login/">模拟新浪微博登录：从原理分析到实现</a> AND <a href="http://www.csuldw.com/2016/12/24/2016-12-24-sina-spider-user-data-part1/">新浪微博数据爬取Part 1：用户个人信息</a>。</p><p>说明一下，以下所有方法都是写在SinaClient类中，关于SinaClient类所有方法，本文不会细说，不过会在后续文章中给出，还请见谅。</p><h2 id="获取用户关注者"><a href="#获取用户关注者" class="headerlink" title="获取用户关注者"></a>获取用户关注者</h2><p>登录微博之后，可以使用浏览器观察某个用户关注者的url链接，最后你会发现，用户<code>1669282904</code>的关注者url为<a href="http://weibo.cn/1669282904/follow?page=1" target="_blank" rel="noopener">http://weibo.cn/1669282904/follow?page=1</a>，后面的<code>page=1</code>为参数，所以我们需要做的就是获取所有page的源码，并将关注着的uid取出来，然后合并到一起。整个代码如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#爬取单个用户的follow，ulr = http://weibo.cn/%uid/follow?page=1</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getUserFollows</span><span class="params">(self, uid, params=<span class="string">"page=1"</span>)</span>:</span></span><br><span class="line">    time.sleep(<span class="number">2</span>)   </span><br><span class="line">    url = <span class="string">"http://weibo.cn/%s/follow?%s"</span> %(uid, params)</span><br><span class="line">    self.logger.info(<span class="string">"page is: "</span> + url)</span><br><span class="line">    text = self.openURL(url)</span><br><span class="line">    soup = BS(text, <span class="string">"html.parser"</span>)</span><br><span class="line">    res = soup.find_all(<span class="string">'table'</span>)</span><br><span class="line">    reg_uid = <span class="string">r"uid=(\d+)&amp;"</span> <span class="comment">#匹配uid</span></span><br><span class="line">    follows = {<span class="string">"uid"</span>: uid, <span class="string">"follow_ids"</span>: list(set([y <span class="keyword">for</span> x <span class="keyword">in</span> [re.findall(reg_uid, str(elem)) <span class="keyword">for</span> elem <span class="keyword">in</span> res] <span class="keyword">for</span> y <span class="keyword">in</span> x ]))}</span><br><span class="line">    next_url = re.findall(<span class="string">'&lt;div&gt;&lt;a href="(.*?)"&gt;下页&lt;/a&gt;&amp;nbsp'</span>, text) <span class="comment">#匹配"下页"内容</span></span><br><span class="line">    <span class="keyword">if</span> len(next_url) != <span class="number">0</span>:</span><br><span class="line">        url_params = next_url[<span class="number">0</span>].split(<span class="string">"?"</span>)[<span class="number">-1</span>] </span><br><span class="line">        follows[<span class="string">'follow_ids'</span>].extend(self.getUserFollows(uid, params=url_params)[<span class="string">"follow_ids"</span>]) <span class="comment">#将结果集合并</span></span><br><span class="line">    <span class="keyword">return</span> follows</span><br></pre></td></tr></tbody></table></figure><p>温馨提示：在获取用户关注者时，有的用户因不明原因被sina确定为广告用户，所以不会显示出来，因此在得到的follows列表里，uid的总数会有所缩减。最后返回一个JSON字符串，包括uid、follow_ids两个字段，即：</p><figure class="highlight avrasm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">uid:</span>用户ID</span><br><span class="line"><span class="symbol">follow_ids:</span>关注人ID列表</span><br></pre></td></tr></tbody></table></figure><h2 id="获取用户粉丝"><a href="#获取用户粉丝" class="headerlink" title="获取用户粉丝"></a>获取用户粉丝</h2><p>同理，可以使用浏览器观察某个用户粉丝的url链接，以用户<code>1669282904</code>为例，粉丝的url链接为<a href="http://weibo.cn/1669282904/fans?page=1" target="_blank" rel="noopener">http://weibo.cn/1669282904/fans?page=1</a>，后面的<code>page=1</code>为参数，所以我们需要做的也是获取所有page的源码，并将用户粉丝的uid取出，最后合并到一起。整个代码如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#获取用户粉丝对象UID列表 ulr = http://weibo.cn/%uid/fans?page=1</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getUserFans</span><span class="params">(self, uid, params=<span class="string">"page=1"</span>)</span>:</span></span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line">    url = <span class="string">"http://weibo.cn/%s/fans?%s"</span> %(uid, params)</span><br><span class="line">    self.logger.info(<span class="string">"page is: "</span> + url)</span><br><span class="line">    text = self.openURL(url)</span><br><span class="line">    soup = BS(text, <span class="string">"html.parser"</span>)</span><br><span class="line">    res = soup.find_all(<span class="string">'table'</span>)</span><br><span class="line">    reg_uid = <span class="string">r"uid=(\d+)&amp;"</span> <span class="comment">#正则匹配uid</span></span><br><span class="line">    fans = {<span class="string">"uid"</span>: uid, <span class="string">"fans_ids"</span>: list(set([y <span class="keyword">for</span> x <span class="keyword">in</span> [re.findall(reg_uid, str(elem)) <span class="keyword">for</span> elem <span class="keyword">in</span> res] <span class="keyword">for</span> y <span class="keyword">in</span> x ]))}</span><br><span class="line">    next_url = re.findall(<span class="string">'&lt;div&gt;&lt;a href="(.*?)"&gt;下页&lt;/a&gt;&amp;nbsp'</span>, text) <span class="comment">#匹配"下页"内容</span></span><br><span class="line">    <span class="keyword">if</span> len(next_url) != <span class="number">0</span>:</span><br><span class="line">        url_params = next_url[<span class="number">0</span>].split(<span class="string">"?"</span>)[<span class="number">-1</span>]</span><br><span class="line">        fans[<span class="string">'fans_ids'</span>].extend(self.getUserFans(uid, params=url_params)[<span class="string">"fans_ids"</span>]) <span class="comment">#将结果集合并</span></span><br><span class="line">    <span class="keyword">return</span> fans</span><br></pre></td></tr></tbody></table></figure><p>温馨提示：在获取用户粉丝时，有的用户同样因不明原因被sina确定为广告用户，所以不会显示出来，因此在得到的fans列表里，uid的总数会也有所缩减。最后返回一个JSON字符串，包括uid、fans_ids两个字段,即：</p><figure class="highlight avrasm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">uid:</span>用户ID</span><br><span class="line"><span class="symbol">fans_ids:</span>粉丝列表</span><br></pre></td></tr></tbody></table></figure><h2 id="获取个人发表微博"><a href="#获取个人发表微博" class="headerlink" title="获取个人发表微博"></a>获取个人发表微博</h2><p>为了获取用户发表的微博，我们同样需要知道显示微博的url，在这里我们使用的网址是<a href="http://weibo.cn/" target="_blank" rel="noopener">http://weibo.cn/</a>，该url内容相对而言易于爬取。值得一提的是，爬取时需要注意的细节比较多，尤其是用户发微博的时间，需要仔细斟酌。下面是获取用户tweets的源码，每个tweets结果包括用户ID、创建时间、评论数、转发数、内容、发表来源、转发理由、点赞量、tweets类型（转发、原创）等字段。完整的代码如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">@func: 获取用户的发的微博信息</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getUserTweets</span><span class="params">(self, uid, tweets_all, params=<span class="string">"page=1"</span>)</span>:</span></span><br><span class="line">    self.switchUserAccount(myconf.userlist)</span><br><span class="line">    url = <span class="string">r"http://weibo.cn/%s/profile?%s"</span> %(uid, params)</span><br><span class="line">    self.logger.info(<span class="string">"URL path is: "</span> + url)</span><br><span class="line">    text = self.openURL(url)</span><br><span class="line">    soup = BS(text, <span class="string">"html.parser"</span>)</span><br><span class="line">    res = soup.find_all(<span class="string">"div"</span>, {<span class="string">"class"</span>:<span class="string">"c"</span>})</span><br><span class="line">    <span class="comment">#规则：如果div中子div数量为1，则为一个原厂文本说说；数量为2，则根据cmt判断是原创图文还是转发文本说说；数量为3，则为转发图文</span></span><br><span class="line">    tweets_list = []</span><br><span class="line">    <span class="keyword">for</span> elem <span class="keyword">in</span> res:</span><br><span class="line">        tweets = {}</span><br><span class="line">        unicode_text = unicode(elem)</span><br><span class="line">        sub_divs = elem.find_all(<span class="string">"div"</span>)</span><br><span class="line">        today = time.strftime(<span class="string">'%Y-%m-%d'</span>,time.localtime(time.time()))</span><br><span class="line">        <span class="keyword">if</span> len(sub_divs) <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]:</span><br><span class="line">            tweets[<span class="string">"uid"</span>] = uid</span><br><span class="line">            tweets[<span class="string">"reason"</span>] = <span class="string">"null"</span></span><br><span class="line">            <span class="comment">#tweets["content"] = re.findall("&lt;span class=\"ctt\"&gt;(.*?)&lt;/span&gt;", str(elem.find("span", {"class": "ctt"})))[0]</span></span><br><span class="line">            tweets[<span class="string">"content"</span>] = elem.find(<span class="string">"span"</span>, {<span class="string">"class"</span>: <span class="string">"ctt"</span>}).text</span><br><span class="line">            soup_text = elem.find(<span class="string">"span"</span>, {<span class="string">"class"</span>: <span class="string">"ct"</span>}).text</span><br><span class="line">            created_at = re.findall(<span class="string">"\d\d\d\d-\d\d-\d\d \d\d:\d\d:\d\d"</span>, unicode(soup_text))</span><br><span class="line">            post_time = re.findall(<span class="string">"\d\d:\d\d"</span>, unicode(soup_text))</span><br><span class="line">            split_text = unicode(soup_text).split(<span class="string">u"\u5206\u949f\u524d"</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> created_at:</span><br><span class="line">                created_at = re.findall(<span class="string">u"\d\d\u6708\d\d\u65e5 \d\d:\d\d"</span>, unicode(soup_text))</span><br><span class="line">                tweets[<span class="string">"created_at"</span>] = time.strftime(<span class="string">"%Y-"</span>,time.localtime()) + unicode(created_at[<span class="number">0</span>]).replace(<span class="string">u"\u6708"</span>, <span class="string">"-"</span>).replace(<span class="string">u"\u65e5"</span>, <span class="string">""</span>) + <span class="string">":00"</span></span><br><span class="line">                tweets[<span class="string">"source"</span>] = soup_text.split(created_at[<span class="number">0</span>])[<span class="number">-1</span>].strip(<span class="string">u"\u00a0\u6765\u81ea"</span>)</span><br><span class="line">            <span class="keyword">elif</span> created_at:</span><br><span class="line">                tweets[<span class="string">"created_at"</span>] = unicode(created_at[<span class="number">0</span>]).replace(<span class="string">u"\u6708"</span>, <span class="string">"-"</span>).replace(<span class="string">u"\u65e5"</span>, <span class="string">""</span>)</span><br><span class="line">                tweets[<span class="string">"source"</span>] = soup_text.split(created_at[<span class="number">0</span>])[<span class="number">-1</span>].strip(<span class="string">u"\u00a0\u6765\u81ea"</span>)</span><br><span class="line">            <span class="keyword">elif</span> post_time:</span><br><span class="line">                tweets[<span class="string">"created_at"</span>] = today + <span class="string">" "</span> + post_time[<span class="number">0</span>] + <span class="string">":00"</span></span><br><span class="line">                tweets[<span class="string">"source"</span>] = soup_text.split(post_time[<span class="number">0</span>])[<span class="number">-1</span>].strip(<span class="string">u"\u00a0\u6765\u81ea"</span>)</span><br><span class="line">            <span class="keyword">elif</span> len(split_text) == <span class="number">2</span>:</span><br><span class="line">                tweets[<span class="string">"created_at"</span>] = time.strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>, time.localtime(time.time() - int(split_text[<span class="number">0</span>])*<span class="number">60</span>))</span><br><span class="line">                tweets[<span class="string">"source"</span>] = split_text[<span class="number">-1</span>].strip(<span class="string">u"\u00a0\u6765\u81ea"</span>)</span><br><span class="line">            tweets[<span class="string">"like_count"</span>] = re.findall(<span class="string">u'\u8d5e\[(\d+)\]'</span>, unicode_text)[<span class="number">-1</span>]</span><br><span class="line">            tweets[<span class="string">"repost_count"</span>] = re.findall(<span class="string">u'\u8f6c\u53d1\[(\d+)\]'</span>, unicode_text)[<span class="number">-1</span>]</span><br><span class="line">            tweets[<span class="string">"comment_count"</span>] = re.findall( <span class="string">u'\u8bc4\u8bba\[(\d+)\]'</span>, unicode_text)[<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">if</span> len(sub_divs) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">elif</span> len(sub_divs) == <span class="number">1</span>:</span><br><span class="line">            <span class="comment">#self.logger.info("text")</span></span><br><span class="line">            tweets[<span class="string">"type"</span>] = <span class="string">"original_text"</span></span><br><span class="line">        <span class="keyword">elif</span> len(sub_divs) == <span class="number">2</span>:</span><br><span class="line">            <span class="comment">#self.logger.info("image")</span></span><br><span class="line">            tweets[<span class="string">"type"</span>] = <span class="string">"original_image"</span></span><br><span class="line">            <span class="comment">#根据cmt的存在判断是否为转发的文字和原创的图文说说</span></span><br><span class="line">            cmt = elem.find_all(<span class="string">"span"</span>, {<span class="string">"class"</span>: <span class="string">"cmt"</span>})</span><br><span class="line">            <span class="keyword">if</span> cmt: </span><br><span class="line">                tweets[<span class="string">"type"</span>] = <span class="string">"repost_text"</span></span><br><span class="line">                tweets[<span class="string">"reason"</span>] = re.findall(<span class="string">"&lt;/span&gt;(.*?)&lt;a"</span>, str(sub_divs[<span class="number">1</span>]))[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">elif</span> len(sub_divs) == <span class="number">3</span>:</span><br><span class="line">            <span class="comment">#self.logger.info("repost")</span></span><br><span class="line">            tweets[<span class="string">"type"</span>] = <span class="string">"repost_image"</span></span><br><span class="line">            tweets[<span class="string">"reason"</span>] = re.findall(<span class="string">"&lt;/span&gt;(.*?)&lt;a"</span>, str(sub_divs[<span class="number">2</span>]))[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.logger.error(<span class="string">"parse error"</span>)</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">if</span> tweets:</span><br><span class="line">            tweets_list.append(json.dumps(tweets))</span><br><span class="line">    self.output(<span class="string">"\n"</span>.join(tweets_list), <span class="string">"output/"</span> + uid + <span class="string">"/"</span> + uid + <span class="string">"_tweets_"</span> + params.replace(<span class="string">"="</span>, <span class="string">""</span>) + <span class="string">".json"</span>)</span><br><span class="line">    </span><br><span class="line">    next_url = re.findall(<span class="string">'&lt;div&gt;&lt;a href="(.*?)"&gt;下页&lt;/a&gt;&amp;nbsp'</span>, text) <span class="comment">#匹配"下页"内容</span></span><br><span class="line">    <span class="keyword">if</span> len(next_url) != <span class="number">0</span>:</span><br><span class="line">        url_params = next_url[<span class="number">0</span>].split(<span class="string">"?"</span>)[<span class="number">-1</span>]</span><br><span class="line">        tweets_all.extend(tweets_list)</span><br><span class="line">        self.getUserTweets(uid, tweets_all, params=url_params)</span><br><span class="line">    <span class="keyword">return</span> tweets_list</span><br></pre></td></tr></tbody></table></figure><p>getUserTweets 方法传入三个参数，外部调用时只需传入前两个参数即可，一个是uid，一个是类型为list的tweets_list。最后返回就是该list，每个元素都是一个JSON字符串，字段如下：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">uid：用户ID</span><br><span class="line">content：微博内容</span><br><span class="line">created_at：发表时间</span><br><span class="line"><span class="built_in">source</span>：发布工具/平台</span><br><span class="line">comment_count：评论数</span><br><span class="line">repost_count：转载数</span><br><span class="line"><span class="built_in">type</span>：微博类型（原创/转发）</span><br><span class="line">like_count：点赞量</span><br><span class="line">reason：转发理由（原创博文无理由取值为空）</span><br></pre></td></tr></tbody></table></figure><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>根据上面的代码运行可得到如下样例结果：</p><p><strong>1.getUserFollows</strong></p><figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">{<span class="attr">"follow_ids"</span>: [<span class="string">"6049590367"</span>, <span class="string">"2239044693"</span>, <span class="string">"1974808274"</span>, <span class="string">"1674175865"</span>], <span class="attr">"uid"</span>: <span class="string">"1669282904"</span>}</span><br></pre></td></tr></tbody></table></figure><p><strong>2.getUserFans</strong></p><figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">{<span class="attr">"fans_ids"</span>: [<span class="string">"5883245860"</span>, <span class="string">"3104658267"</span>], <span class="attr">"uid"</span>: <span class="string">"1669282904"</span>}</span><br></pre></td></tr></tbody></table></figure><p><strong>3.getUserTweets</strong></p><figure class="highlight taggerscript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">{"uid": "1669282904", "created_at": "2016-12-16 11:42:00", "comment_count": "0", "repost_count": "0", "content": "#<span class="symbol">\u</span>5317<span class="symbol">\u</span>4eac<span class="symbol">\u</span>7a81<span class="symbol">\u</span>53d1#<span class="symbol">\u</span>3010<span class="symbol">\u</span>96fe<span class="symbol">\u</span>973e<span class="symbol">\u</span>8fdb<span class="symbol">\u</span>57ce<span class="symbol">\u</span>4e86<span class="symbol">\u</span>2026[<span class="symbol">\u</span>6cea]<span class="symbol">\u</span>3011@<span class="symbol">\u</span>6c14<span class="symbol">\u</span>8c61<span class="symbol">\u</span>5317<span class="symbol">\u</span>4eac <span class="symbol">\u</span>ff1a<span class="symbol">\u</span>96fe<span class="symbol">\u</span>973e<span class="symbol">\u</span>5df2<span class="symbol">\u</span>5230<span class="symbol">\u</span>5317<span class="symbol">\u</span>4eac<span class="symbol">\u</span>ff0c<span class="symbol">\u</span>6b64<span class="symbol">\u</span>523b<span class="symbol">\u</span>80fd<span class="symbol">\u</span>89c1<span class="symbol">\u</span>5ea6<span class="symbol">\u</span>5357<span class="symbol">\u</span>5317<span class="symbol">\u</span>5dee<span class="symbol">\u</span>8ddd<span class="symbol">\u</span>5f88<span class="symbol">\u</span>5927<span class="symbol">\u</span>ff0c<span class="symbol">\u</span>5357<span class="symbol">\u</span>90e8<span class="symbol">\u</span>6c61<span class="symbol">\u</span>67d3<span class="symbol">\u</span>7269<span class="symbol">\u</span>6d53<span class="symbol">\u</span>8f83<span class="symbol">\u</span>9ad8<span class="symbol">\u</span>ff0c<span class="symbol">\u</span>901a<span class="symbol">\u</span>5dde<span class="symbol">\u</span>3001<span class="symbol">\u</span>95e8<span class="symbol">\u</span>5934<span class="symbol">\u</span>6c9f<span class="symbol">\u</span>548c<span class="symbol">\u</span>6d77<span class="symbol">\u</span>6dc0<span class="symbol">\u</span>8fd8<span class="symbol">\u</span>80fd<span class="symbol">\u</span>770b<span class="symbol">\u</span>89c1<span class="symbol">\u</span>84dd<span class="symbol">\u</span>5929<span class="symbol">\u</span>ff0c<span class="symbol">\u</span>4f46<span class="symbol">\u</span>5927<span class="symbol">\u</span>5174<span class="symbol">\u</span>90e8<span class="symbol">\u</span>5206<span class="symbol">\u</span>5730<span class="symbol">\u</span>533a<span class="symbol">\u</span>80fd<span class="symbol">\u</span>89c1<span class="symbol">\u</span>5ea6<span class="symbol">\u</span>5df2<span class="symbol">\u</span>4e0d<span class="symbol">\u</span>8db32<span class="symbol">\u</span>516c<span class="symbol">\u</span>91cc<span class="symbol">\u</span>3002<span class="symbol">\u</span>3002<span class="symbol">\u</span>3002<span class="symbol">\u</span>5927<span class="symbol">\u</span>5bb6<span class="symbol">\u</span>4e00<span class="symbol">\u</span>5b9a<span class="symbol">\u</span>8bb0<span class="symbol">\u</span>5f97<span class="symbol">\u</span>6234<span class="symbol">\u</span>53e3<span class="symbol">\u</span>7f69<span class="symbol">\u</span>ff0c<span class="symbol">\u</span>8fd9<span class="symbol">\u</span>51e0<span class="symbol">\u</span>5929<span class="symbol">\u</span>4e5f<span class="symbol">\u</span>5c3d<span class="symbol">\u</span>91cf<span class="symbol">\u</span>4e0d<span class="symbol">\u</span>8981<span class="symbol">\u</span>5f00<span class="symbol">\u</span>7a97<span class="symbol">\u</span>901a<span class="symbol">\u</span>98ce<span class="symbol">\u</span>3002", "source": "iPhone 6s Plus", "reason": "<span class="symbol">\u</span>6709<span class="symbol">\u</span>79cd<span class="symbol">\u</span>707e<span class="symbol">\u</span>96be<span class="symbol">\u</span>7247<span class="symbol">\u</span>7684<span class="symbol">\u</span>8d76<span class="symbol">\u</span>811a[<span class="symbol">\u</span>611f<span class="symbol">\u</span>5192] ", "like_count": "0", "type": "repost_image"}</span><br><span class="line">{"uid": "1669282904", "created_at": "2016-12-01 21:03:00", "comment_count": "3", "repost_count": "0", "content": "<span class="symbol">\u</span>679c<span class="symbol">\u</span>7136<span class="symbol">\u</span>6211<span class="symbol">\u</span>5927<span class="symbol">\u</span>6570<span class="symbol">\u</span>636e<span class="symbol">\u</span>4e07<span class="symbol">\u</span>80fd<span class="symbol">\u</span>7684<span class="symbol">\u</span>ff0c<span class="symbol">\u</span>505a<span class="symbol">\u</span>5b8cweb<span class="symbol">\u</span>505aapp<span class="symbol">\u</span>ff0c<span class="symbol">\u</span>505a<span class="symbol">\u</span>5b8capp<span class="symbol">\u</span>505a<span class="symbol">\u</span>5e7f<span class="symbol">\u</span>544a[<span class="symbol">\u</span>4e8c<span class="symbol">\u</span>54c8][<span class="symbol">\u</span>4e8c<span class="symbol">\u</span>54c8]", "source": "iPhone 6s Plus", "reason": "null", "like_count": "1", "type": "original_text"}</span><br></pre></td></tr></tbody></table></figure><p>匆忙之际赶出本文，篇幅有些简洁，代码部分只给出了核心内容，如有任何问题，可在下面留言。对于微博数据爬取的全部内容，将在下一篇文章中介绍，敬请期待！</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="http://www.csuldw.com/2016/12/24/2016-12-24-sina-spider-user-data-part1/">新浪微博数据爬取Part 1：用户个人信息</a></li><li><a href="http://www.csuldw.com/2016/11/10/2016-11-10-simulate-sina-login/">模拟新浪微博登录：从原理分析到实现</a></li><li><a href="http://www.csuldw.com/2016/11/05/2016-11-05-simulate-zhihu-login/">小试牛刀：使用Python模拟登录知乎</a></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上一篇博文&lt;a href=&quot;http://www.csuldw.com/2016/12/24/2016-12-24-sina-spider-user-data-part1/&quot;&gt;新浪微博数据爬取Part 1：用户个人信息&lt;/a&gt;介绍了如何爬取用户个人资料，使用了BeautifulSoup以及正则表达式，最后得到了与用户有关的14个字段。在这篇文章里，将继续介绍如何爬取微博数据，爬取的内容包括用户的粉丝、用户的关注者、用户个人发表的微博三部分信息。博主知道，没有完整的项目源码支持，对于初学者来说，确实是一件不容易的事。所以，笔者打算先将每个部分的代码单独抽取出来，等到下一篇附上源码的同时，介绍如何运行整个爬虫项目。&lt;/p&gt;
    
    </summary>
    
      <category term="Spider" scheme="https://www.csuldw.com/categories/Spider/"/>
    
    
      <category term="Python" scheme="https://www.csuldw.com/tags/Python/"/>
    
      <category term="Spider" scheme="https://www.csuldw.com/tags/Spider/"/>
    
      <category term="Sina" scheme="https://www.csuldw.com/tags/Sina/"/>
    
      <category term="微博" scheme="https://www.csuldw.com/tags/%E5%BE%AE%E5%8D%9A/"/>
    
  </entry>
  
  <entry>
    <title>新浪微博数据爬取Part 1：用户个人信息</title>
    <link href="https://www.csuldw.com/2016/12/24/2016-12-24-sina-spider-user-data-part1/"/>
    <id>https://www.csuldw.com/2016/12/24/2016-12-24-sina-spider-user-data-part1/</id>
    <published>2016-12-24T08:10:00.000Z</published>
    <updated>2017-03-26T07:01:18.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>从上一篇博文到现在，已有一月有余，期间发生了许多事情，庆幸地是博主终于想开了，有的时候，那些无法改变的人或事，就让TA 去吧，不必多多挂怀，趁着还有时间，做些自己喜欢的事情。此前在<a href="http://www.csuldw.com/2016/11/10/2016-11-10-simulate-sina-login/">模拟新浪微博登录：从原理分析到实现</a>这篇博文中讲解了如何登陆新浪微博，虽然模拟登录看似比较复杂，但将其过程理解透彻之后，你会觉得它其实也比较简单。实现了登录，接下来就是新浪数据的爬取。本文是数据爬取的第一部分，以Python实现新浪用户个人信息的爬取，其余篇章将在后续博文中陆续给出。</p><a id="more"></a><p>新浪微博数据的爬取主要有两种方法，当然也可以说博主只知道这两种方法，一种是使用新浪API获取，另一种是结合正则直接爬取页面信息。第一种方法虽然官方封装甚好，给出的数据也比较丰富，但说到底还是限制太多，很多接口只能获取当前登录用户的信息，无法获取好友的信息（你若不信，可以实践一下），所以在爬取数据的过程中干脆放弃了。本文主要介绍第二种方法，即如何结合正则爬取页面信息。</p><h2 id="登录微博"><a href="#登录微博" class="headerlink" title="登录微博"></a>登录微博</h2><p>首先是登录微博，博主使用的是urllib2（当然你也可以使用requests），说明一下，有关爬取的相关代码，都写在<code>SinaClient</code>这个类中，login方法如下：</p><figure class="highlight php"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用urllib2模拟登录过程</span></span><br><span class="line">def login(<span class="keyword">self</span>, username=None, password=None):</span><br><span class="line">    <span class="keyword">self</span>.status = <span class="keyword">False</span> <span class="comment">#重新将登录状态设置为False</span></span><br><span class="line">    <span class="keyword">self</span>.logger.info(<span class="string">"Start to login..."</span>)</span><br><span class="line">    <span class="comment">#根据用户名和密码给默认参数赋值,并初始化post_data</span></span><br><span class="line">    <span class="keyword">self</span>.setAccount(username, password) </span><br><span class="line">    <span class="keyword">self</span>.setPostData() </span><br><span class="line">    <span class="keyword">self</span>.enableCookie() </span><br><span class="line">    <span class="comment">#登录时请求的url</span></span><br><span class="line">    login_url = r<span class="string">'https://login.sina.com.cn/sso/login.php?client=ssologin.js(v1.4.15)'</span></span><br><span class="line">    headers = <span class="keyword">self</span>.headers</span><br><span class="line">    request = urllib2.Request(login_url, urllib.urlencode(<span class="keyword">self</span>.post_data), headers)</span><br><span class="line">    resText = urllib2.urlopen(request).read()</span><br><span class="line">    <span class="keyword">try</span>:        </span><br><span class="line">        jsonText = json.loads(resText)</span><br><span class="line">        <span class="keyword">if</span> jsonText[<span class="string">"retcode"</span>] == <span class="string">"0"</span>:</span><br><span class="line">            <span class="keyword">self</span>.logger.info(<span class="string">"Login success!"</span>)</span><br><span class="line">            <span class="keyword">self</span>.status = <span class="keyword">True</span></span><br><span class="line">            <span class="comment">#将cookie加入到headers中</span></span><br><span class="line">            cookies = <span class="string">';'</span>.join([cookie.name + <span class="string">"="</span> + cookie.value <span class="keyword">for</span> cookie in <span class="keyword">self</span>.cookiejar])</span><br><span class="line">            headers[<span class="string">"Cookie"</span>] = cookies</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">self</span>.logger.error(<span class="string">"Login Failed --&gt; "</span> + jsonText[<span class="string">"reason"</span>])</span><br><span class="line">    except <span class="keyword">Exception</span>, e:</span><br><span class="line">        <span class="keyword">print</span> e</span><br><span class="line">        <span class="keyword">self</span>.logger.info(<span class="string">"Login Failed2!"</span>)</span><br><span class="line">    <span class="keyword">self</span>.headers = headers</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">self</span></span><br></pre></td></tr></tbody></table></figure><p>上面用到了几个方法，与先前的<a href="http://www.csuldw.com/2016/11/10/2016-11-10-simulate-sina-login/">模拟新浪微博登录：从原理分析到实现</a>这篇博文的源码类似，可以参考模拟登录新浪的源码<a href="https://github.com/csuldw/WSpider/tree/master/SinaLogin" target="_blank" rel="noopener">https://github.com/csuldw/WSpider/tree/master/SinaLogin</a>。本文的完整源码，待后续整理完整后，也会在该github的<code>WSpider</code>仓库中给出。</p><p>登录之后，就可以进行数据爬取了。</p><h2 id="获取用户个人信息"><a href="#获取用户个人信息" class="headerlink" title="获取用户个人信息"></a>获取用户个人信息</h2><p>为了方便，博主将请求ULR的内容写在了openURL方法里，该方法返回的是该url链接的源码，代码如下：</p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#打开url时携带headers,此header需携带cookies</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">openURL</span><span class="params">(<span class="keyword">self</span>, url, data=None)</span></span><span class="symbol">:</span></span><br><span class="line">    req = urllib2.Request(url, data=data, headers=<span class="keyword">self</span>.headers)</span><br><span class="line">    text = urllib2.urlopen(req).read()</span><br><span class="line">    <span class="keyword">return</span> text</span><br></pre></td></tr></tbody></table></figure><p>爬取用户个人信息时，为了得到更多的信息，我们需请求多个地址，博主在爬取时访问了如下四个：</p><ul><li>url_app = “<a href="http://weibo.cn/%s/info&quot;" target="_blank" rel="noopener">http://weibo.cn/%s/info"</a> %uid</li><li>app_page = “<a href="http://weibo.cn/%s&quot;" target="_blank" rel="noopener">http://weibo.cn/%s"</a> %uid</li><li>url_web = “<a href="http://weibo.com/%s/info&quot;" target="_blank" rel="noopener">http://weibo.com/%s/info"</a> %uid</li><li>tag_url = “<a href="http://weibo.cn/account/privacy/tags/?uid=%s&quot;" target="_blank" rel="noopener">http://weibo.cn/account/privacy/tags/?uid=%s"</a> %uid</li></ul><p>温馨提示：<code>%uid</code>是新浪微博用户ID，若想查看四个页面的信息，将<code>%s</code>替换成用户ID即可。比如将url_app中的uid赋值为<code>1669282904</code>，则网址为<a href="http://weibo.cn/1669282904/info" target="_blank" rel="noopener">http://weibo.cn/1669282904/info</a>。</p><p>在上述网址中，从url_app中可以得到昵称、性别、地区、生日、简介、性取向、婚姻状况、首页链接八个字段；从app_page中可以得到用户的关注量、粉丝量、微博量；从url_web中可以获取用户的注册日期；从tag_url中则可以得到用户的标签信息。将这些信息合并到一起，加上uid，共可得14个字段。爬取过程中有的字段取值因用户没填写而造成结果不存在，为了统一字段数量，我们将这些不存在的字段统一置为空串。请求一个页面时，我们可以将页面的源码保存下来，然后使用BeautifulSoup进行解析，再结合正则找到需要的字段值。整个代码如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup <span class="keyword">as</span> BS</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getUserInfos</span><span class="params">(self, uid)</span>:</span></span><br><span class="line">    url_app = <span class="string">"http://weibo.cn/%s/info"</span> %uid</span><br><span class="line">    text_app = self.openURL(url_app)</span><br><span class="line">    soup_app = unicode(BS(text_app, <span class="string">"html.parser"</span>))</span><br><span class="line">    nickname = re.findall(<span class="string">u'\u6635\u79f0[:|\uff1a](.*?)&lt;br'</span>, soup_app)  <span class="comment"># 昵称</span></span><br><span class="line">    gender = re.findall(<span class="string">u'\u6027\u522b[:|\uff1a](.*?)&lt;br'</span>, soup_app)  <span class="comment"># 性别</span></span><br><span class="line">    address = re.findall(<span class="string">u'\u5730\u533a[:|\uff1a](.*?)&lt;br'</span>, soup_app)  <span class="comment"># 地区（包括省份和城市）</span></span><br><span class="line">    birthday = re.findall(<span class="string">u'\u751f\u65e5[:|\uff1a](.*?)&lt;br'</span>, soup_app)  <span class="comment"># 生日</span></span><br><span class="line">    desc = re.findall(<span class="string">u'\u7b80\u4ecb[:|\uff1a](.*?)&lt;br'</span>, soup_app)  <span class="comment"># 简介</span></span><br><span class="line">    sexorientation = re.findall(<span class="string">u'\u6027\u53d6\u5411[:|\uff1a](.*?)&lt;br'</span>, soup_app)  <span class="comment"># 性取向</span></span><br><span class="line">    marriage = re.findall(<span class="string">u'\u611f\u60c5\u72b6\u51b5[:|\uff1a](.*?)&lt;br'</span>, soup_app)  <span class="comment"># 婚姻状况</span></span><br><span class="line">    homepage = re.findall(<span class="string">u'\u4e92\u8054\u7f51[:|\uff1a](.*?)&lt;br'</span>, soup_app)  <span class="comment">#首页链接</span></span><br><span class="line">    <span class="comment">#根据app主页获取数据</span></span><br><span class="line">    app_page = <span class="string">"http://weibo.cn/%s"</span> %uid</span><br><span class="line">    text_homepage = self.openURL(app_page)</span><br><span class="line">    soup_home = unicode(BS(text_homepage, <span class="string">"html.parser"</span>))</span><br><span class="line">    tweets_count = re.findall(<span class="string">u'\u5fae\u535a\[(\d+)\]'</span>, soup_home)</span><br><span class="line">    follows_count = re.findall(<span class="string">u'\u5173\u6ce8\[(\d+)\]'</span>, soup_home)</span><br><span class="line">    fans_count = re.findall(<span class="string">u'\u7c89\u4e1d\[(\d+)\]'</span>, soup_home)</span><br><span class="line">    <span class="comment">#根据web用户详情页获取注册日期</span></span><br><span class="line">    url_web = <span class="string">"http://weibo.com/%s/info"</span> %uid</span><br><span class="line">    text_web = self.openURL(url_web)</span><br><span class="line">    reg_date = re.findall(<span class="string">r"\d{4}-\d{2}-\d{2}"</span>, text_web)</span><br><span class="line">    <span class="comment">#根据标签详情页获取标签        </span></span><br><span class="line">    tag_url = <span class="string">"http://weibo.cn/account/privacy/tags/?uid=%s"</span> %uid</span><br><span class="line">    text_tag = self.openURL(tag_url)      </span><br><span class="line">    soup_tag = BS(text_tag, <span class="string">"html.parser"</span>)</span><br><span class="line">    res = soup_tag.find_all(<span class="string">'div'</span>, {<span class="string">"class"</span>:<span class="string">"c"</span>})</span><br><span class="line">    tags = <span class="string">"|"</span>.join([elem.text <span class="keyword">for</span> elem <span class="keyword">in</span> res[<span class="number">2</span>].find_all(<span class="string">"a"</span>)])</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#将用户信息合并        </span></span><br><span class="line">    userinfo = {}</span><br><span class="line">    userinfo[<span class="string">"uid"</span>] = uid</span><br><span class="line">    userinfo[<span class="string">"nickname"</span>] = nickname[<span class="number">0</span>] <span class="keyword">if</span> nickname <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line">    userinfo[<span class="string">"gender"</span>] = gender[<span class="number">0</span>] <span class="keyword">if</span> gender <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line">    userinfo[<span class="string">"address"</span>] = address[<span class="number">0</span>] <span class="keyword">if</span> address <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line">    userinfo[<span class="string">"birthday"</span>] = birthday[<span class="number">0</span>] <span class="keyword">if</span> birthday <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line">    userinfo[<span class="string">"desc"</span>] = desc[<span class="number">0</span>] <span class="keyword">if</span> desc <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line">    userinfo[<span class="string">"sex_orientation"</span>] = sexorientation[<span class="number">0</span>] <span class="keyword">if</span> sexorientation <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line">    userinfo[<span class="string">"marriage"</span>] = marriage[<span class="number">0</span>] <span class="keyword">if</span> marriage <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line">    userinfo[<span class="string">"homepage"</span>] = homepage[<span class="number">0</span>] <span class="keyword">if</span> homepage <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line">    userinfo[<span class="string">"tweets_count"</span>] = tweets_count[<span class="number">0</span>] <span class="keyword">if</span> tweets_count <span class="keyword">else</span> <span class="string">"0"</span></span><br><span class="line">    userinfo[<span class="string">"follows_count"</span>] = follows_count[<span class="number">0</span>] <span class="keyword">if</span> follows_count <span class="keyword">else</span> <span class="string">"0"</span></span><br><span class="line">    userinfo[<span class="string">"fans_count"</span>] = fans_count[<span class="number">0</span>] <span class="keyword">if</span> fans_count <span class="keyword">else</span> <span class="string">"0"</span></span><br><span class="line">    userinfo[<span class="string">"reg_date"</span>] = reg_date[<span class="number">0</span>] <span class="keyword">if</span> reg_date <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line">    userinfo[<span class="string">"tags"</span>] = tags <span class="keyword">if</span> tags <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line">    <span class="keyword">return</span> userinfo</span><br></pre></td></tr></tbody></table></figure><p>上述方法传入的只有一个用户ID<code>uid</code>，最终返回的是一个dict，也就是json串。之所以以JSON串返回是因为这会方便我们后续的数据处理，比如存储至本地或者写入到数据库中。结果字段值如下：</p><figure class="highlight avrasm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">uid:</span>用户ID</span><br><span class="line"><span class="symbol">nickname:</span>昵称</span><br><span class="line"><span class="symbol">address:</span>地址</span><br><span class="line"><span class="symbol">sex:</span>性别</span><br><span class="line"><span class="symbol">birthday:</span>生日</span><br><span class="line"><span class="symbol">desc:</span>简介</span><br><span class="line"><span class="symbol">marriage:</span>婚姻状况</span><br><span class="line"><span class="symbol">follows_count:</span>关注数</span><br><span class="line"><span class="symbol">fans_count:</span>粉丝数</span><br><span class="line"><span class="symbol">tweets_count:</span>微博数</span><br><span class="line"><span class="symbol">homepage:</span>首页链接</span><br><span class="line"><span class="symbol">reg_date:</span>注册时间</span><br><span class="line"><span class="symbol">tag:</span>标签</span><br><span class="line"><span class="symbol">sex_orientation:</span>性取向</span><br></pre></td></tr></tbody></table></figure><h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><p>运行代码后，最终的结果将以JSON串返回，传入uid为<code>1669282904</code>的参数，返回结果如下：</p><p><img src="/assets/articleImg/sina-userinfo.png" alt=""></p><p>目前只包含这14个字段，如果需要更多的信息，可去新浪微博网址中仔细查看相关字段，然后将想要的信息加入到userinfo中即可。在后续博文中，将给出用户粉丝爬取、用户关注爬取、用户微博爬取等相关信息，敬请期待！最后，预祝大家平安夜快乐，圣诞快乐吧~</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="http://www.csuldw.com/2016/11/10/2016-11-10-simulate-sina-login/">模拟新浪微博登录：从原理分析到实现</a></li><li><a href="http://www.csuldw.com/2016/11/05/2016-11-05-simulate-zhihu-login/">小试牛刀：使用Python模拟登录知乎</a></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;从上一篇博文到现在，已有一月有余，期间发生了许多事情，庆幸地是博主终于想开了，有的时候，那些无法改变的人或事，就让TA 去吧，不必多多挂怀，趁着还有时间，做些自己喜欢的事情。此前在&lt;a href=&quot;http://www.csuldw.com/2016/11/10/2016-11-10-simulate-sina-login/&quot;&gt;模拟新浪微博登录：从原理分析到实现&lt;/a&gt;这篇博文中讲解了如何登陆新浪微博，虽然模拟登录看似比较复杂，但将其过程理解透彻之后，你会觉得它其实也比较简单。实现了登录，接下来就是新浪数据的爬取。本文是数据爬取的第一部分，以Python实现新浪用户个人信息的爬取，其余篇章将在后续博文中陆续给出。&lt;/p&gt;
    
    </summary>
    
      <category term="Spider" scheme="https://www.csuldw.com/categories/Spider/"/>
    
    
      <category term="Python" scheme="https://www.csuldw.com/tags/Python/"/>
    
      <category term="爬虫" scheme="https://www.csuldw.com/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Spider" scheme="https://www.csuldw.com/tags/Spider/"/>
    
      <category term="Sina" scheme="https://www.csuldw.com/tags/Sina/"/>
    
      <category term="微博" scheme="https://www.csuldw.com/tags/%E5%BE%AE%E5%8D%9A/"/>
    
  </entry>
  
  <entry>
    <title>模拟新浪微博登录：从原理分析到实现</title>
    <link href="https://www.csuldw.com/2016/11/10/2016-11-10-simulate-sina-login/"/>
    <id>https://www.csuldw.com/2016/11/10/2016-11-10-simulate-sina-login/</id>
    <published>2016-11-10T13:10:00.000Z</published>
    <updated>2017-03-26T07:01:22.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>上一篇文章<a href="http://www.csuldw.com/2016/11/05/2016-11-05-simulate-zhihu-login/">小试牛刀：使用Python模拟登录知乎</a>介绍了如何模拟知乎登录，虽然用到了验证码信息，但请求的参数都是原封不动的传递，刚开始接触的时候，觉得难度适中，回头再看的时候，反而感觉挺容易的。在这篇文章，将继续介绍模拟登录。与之前不一样的是，这次选择的对象是新浪微博，难度稍微提升了点，好在以往的许多码友们都留有许多经验贴，经过几番斟酌，微博的模拟登录算是实现了。这两天还在研究如何高性能地爬取微博数据，业余之际乘着还有点记忆，索性将先前的小实验加工成文，算是一份小结吧。下面来看看整个实验过程。</p><a id="more"></a><h2 id="开发工具"><a href="#开发工具" class="headerlink" title="开发工具"></a>开发工具</h2><p>一如既往，笔者使用的还是之前的工具，如下：</p><ul><li>Windows 7 + Python 2.75</li><li>Chrome + Fiddler</li></ul><h2 id="微博登录请求过程分析"><a href="#微博登录请求过程分析" class="headerlink" title="微博登录请求过程分析"></a>微博登录请求过程分析</h2><p>新浪微博的登录有多个URL链接，笔者在实验的时候试了两个，这两个都是新浪通行证登录页面，都是不需要验证码的。一个是 【<a href="http://login.sina.com.cn" target="_blank" rel="noopener">http://login.sina.com.cn</a>】，另一个是 【<a href="https://login.sina.com.cn/signup/signin.php?entry=sso" target="_blank" rel="noopener">https://login.sina.com.cn/signup/signin.php?entry=sso</a>】。两个URL虽然很大部分相同，登录过程中仅仅是传递参数不一样。第一个URL传递的过程对“password”进行了加密，而第二个没有加密，所以如果使用第二个URL进行模拟登录，就简单多了。在这里，笔者决定选择使用第一种方式进行分析，下面来看详细过程。</p><p>请求登录过程可归纳为三部分</p><ol><li>请求登录login.php页面<strong>前</strong>的参数预获取</li><li>请求登录login.php页面<strong>时</strong>的参数分析</li><li>提交POST请求时的参数构造</li></ol><h3 id="Step-1：GET方式请求prelogin-php页面"><a href="#Step-1：GET方式请求prelogin-php页面" class="headerlink" title="Step 1：GET方式请求prelogin.php页面"></a>Step 1：GET方式请求prelogin.php页面</h3><p>在模拟登录之前，先观察浏览器登录过程中Fiddler抓到的包，在<code>/sso/login.php</code>打开之前会先使用“GET”方式请求“/sso/prelogin.php”，请求的URL为：【<code>https://login.sina.com.cn/sso/prelogin.php?entry=account&amp;callback=sinaSSOController.preloginCallBack&amp;su=bGl1ZGl3ZWkxOCU0MHNpbmEuY29t&amp;rsakt=mod&amp;client=ssologin.js(v1.4.15)</code>】，可以看看下面这张图：</p><p><img src="/assets/articleImg/prelogin.png" alt=""></p><p>在Fiddler中，可以点击“Preview”查看具体详情，也可以直接将Request URL复制到浏览器上查看，效果图如下：</p><p><img src="/assets/articleImg/prelogin-preview-view.png" alt=""></p><p>可以看出，这是一个json数据，并且携带了几个参数，我们关心的有以下四个：</p><ul><li>servertime</li><li>nonce</li><li>pubkey</li><li>rsakv</li></ul><p>说明一下，之所以认为这几个参数比较重要，那是因为后面对“password”的加密需要用到，对其他参数没有提及的原因是在提交POST时其它的参数并没有用到。好了，为了进行进一步探索，我们从Fiddler的结果可以看出，接下来到了“/sso/login.php”。</p><h3 id="Step-2：POST方式请求login-php页面"><a href="#Step-2：POST方式请求login-php页面" class="headerlink" title="Step 2：POST方式请求login.php页面"></a>Step 2：POST方式请求login.php页面</h3><p>从这里开始，就进行“login.php”页面的请求分析了（详细的Request URL:【<code>https://login.sina.com.cn/sso/login.php?client=ssologin.js(v1.4.15)</code>】，后面的时间戳可省略）。点击查看详情，结果图如下：</p><p><img src="/assets/articleImg/login.png" alt=""></p><p>可以发现<code>/sso/login.php</code>页面有如下参数（From Data）：</p><pre><code class="Markdown">cdult: 3domain: sina.com.cnencoding: UTF-8entry: accountfrom:gateway: 1nonce: AFE3O9pagerefer: http://login.sina.com.cn/sso/logout.phpprelt: 41pwencode: rsa2returntype: TEXTrsakv: 1330428213savestate: 30servertime: 1478568922service: ssosp: passwordsr: 1366*768su: usernameuseticket: 0vsnf: 1</code></pre><p>到了这里，我们大概可以知道我们需要哪些参数了。在From Data 参数列表中，需要我们指定的参数有下面几个：</p><ul><li>servertime</li><li>nonce</li><li>rsakv</li><li>sp：加密后的密码</li><li>su：加密后的用户名</li></ul><p>对于参数“nonce”、“servertime”、“rsakv”，都可以从第一步中的“prelogin.php” 中直接获取，而“sp”和“su”则是经过加密后的字符串值，至于具体的加密规则，我们下面通过查看源码分析得出。</p><h3 id="Step-3：探索加密规则"><a href="#Step-3：探索加密规则" class="headerlink" title="Step 3：探索加密规则"></a>Step 3：探索加密规则</h3><p>首先看看请求“/sso/prelogin.php”的具体情况，看到“client”为“ssologin.js”，见下图：</p><p><img src="/assets/articleImg/sshlogin-js.png" alt=""></p><p>然后我们到登录页面<a href="https://login.sina.com.cn" target="_blank" rel="noopener">https://login.sina.com.cn</a>中查看源码【<a href="view-source:https://login.sina.com.cn/" target="_blank" rel="noopener">view-source:https://login.sina.com.cn/</a>】并搜索“ssllogin.js”，接着点击进入<a href="https://login.sina.com.cn/js/sso/ssologin.js" target="_blank" rel="noopener">ssologin.js</a>文件，这时我们可在文件中搜索“username”字符串，找到与“username”相应的加密部分（需仔细查看+揣测），接着搜索“password”，找到“password”的加密部分，最后分析出“username”和“password”的加密规则。加密部分的代码如下图：</p><p><img src="/assets/articleImg/encode-su-sp.png" alt=""></p><p>加密用户名的代码：</p><figure class="highlight ini"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">request.su</span> = sinaSSOEncoder.base64.encode(urlencode(username))<span class="comment">;</span></span><br></pre></td></tr></tbody></table></figure><p>加密密码的代码：</p><figure class="highlight vbscript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> ((<span class="keyword">me</span>.loginType &amp; rsa) &amp;&amp; <span class="keyword">me</span>.servertime &amp;&amp; sinaSSOEncoder &amp;&amp; sinaSSOEncoder.RSAKey) {</span><br><span class="line">  <span class="built_in">request</span>.servertime = <span class="keyword">me</span>.servertime;</span><br><span class="line">  <span class="built_in">request</span>.nonce = <span class="keyword">me</span>.nonce;</span><br><span class="line">  <span class="built_in">request</span>.pwencode = <span class="string">"rsa2"</span>;</span><br><span class="line">  <span class="built_in">request</span>.rsakv = <span class="keyword">me</span>.rsakv;</span><br><span class="line">  var RSAKey = <span class="keyword">new</span> sinaSSOEncoder.RSAKey();</span><br><span class="line">  RSAKey.setPublic(<span class="keyword">me</span>.rsaPubkey, <span class="string">"10001"</span>);</span><br><span class="line">  password = RSAKey.encrypt([<span class="keyword">me</span>.servertime, <span class="keyword">me</span>.nonce].<span class="built_in">join</span>(<span class="string">"\t"</span>) + <span class="string">"\n"</span> + password)</span><br><span class="line">} <span class="keyword">else</span> {</span><br><span class="line">  <span class="keyword">if</span> ((<span class="keyword">me</span>.loginType &amp; wsse) &amp;&amp; <span class="keyword">me</span>.servertime &amp;&amp; sinaSSOEncoder &amp;&amp; sinaSSOEncoder.hex_sha1) {</span><br><span class="line">    <span class="built_in">request</span>.servertime = <span class="keyword">me</span>.servertime;</span><br><span class="line">    <span class="built_in">request</span>.nonce = <span class="keyword">me</span>.nonce;</span><br><span class="line">    <span class="built_in">request</span>.pwencode = <span class="string">"wsse"</span>;</span><br><span class="line">    password = sinaSSOEncoder.hex_sha1(<span class="string">""</span> + sinaSSOEncoder.hex_sha1(sinaSSOEncoder.hex_sha1(password)) + <span class="keyword">me</span>.servertime + <span class="keyword">me</span>.nonce)</span><br><span class="line">  }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>微博对于“username”的加密规则比较单一，使用的是“Base64”加密算法，而对“password”的加密规则比较复杂，虽然使用的是“RSA2”（python中需要使用<code>pip install rsa</code> 安装rsa模块），但加密的逻辑比较多。根据上面的代码，可以看出“password”加密是这样的一个过程：首先创建一个“rsa”公钥，公钥的两个参数都是固定值，第一个参数是登录过程中“prelogin.php”中的“pubkey”，第二个参数是加密的“js”文件中指定的“10001”（这两个值需要先从16进制转换成10进制，把“10001”转成十进制为“65537”）。最后再加入“servertime”和“nonce”进行进一步加密。</p><p>经过上面的分析之后，发起“POST”请求时的“post_data”基本上已经全部可以得到了，接下来就跟模拟登录其它网站类似了，可以使用“request”，也可以使用“urllib2”。下面来看详细代码部分。</p><h2 id="源码实现"><a href="#源码实现" class="headerlink" title="源码实现"></a>源码实现</h2><p>Github源码链接：<a href="https://github.com/csuldw/WSpider/tree/master/SinaLogin" target="_blank" rel="noopener">https://github.com/csuldw/WSpider/tree/master/SinaLogin</a>，源码包括下列文件：</p><ul><li>dataEncode.py：用于对提交POST请求的数据进行编码处理</li><li>Logger.py：用于打印log</li><li>SinaSpider.py：用于爬取sina微博数据的文件（主文件）</li></ul><p>为了方便扩展，笔者将代码进行了封装，所以看起来代码量比较多，不过个人觉得可读性还是比较良好，算是凑合吧。</p><p>1.<a href="https://github.com/csuldw/WSpider/blob/master/SinaLogin/dataEncode.py" target="_blank" rel="noopener">dataEncode.py</a></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Tue Nov 08 10:14:38 2016</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: liudiwei</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="keyword">import</span> rsa</span><br><span class="line"><span class="keyword">import</span> binascii</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用base64对用户名进行编码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">encode_username</span><span class="params">(username)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> base64.encodestring(username)[:<span class="number">-1</span>]</span><br><span class="line">    </span><br><span class="line"><span class="comment">#使用rsa2对password进行编码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">encode_password</span><span class="params">(password, servertime, nonce, pubkey)</span>:</span></span><br><span class="line">    rsaPubkey = int(pubkey, <span class="number">16</span>)</span><br><span class="line">    RSAKey = rsa.PublicKey(rsaPubkey, <span class="number">65537</span>) <span class="comment">#创建公钥</span></span><br><span class="line">    codeStr = str(servertime) + <span class="string">'\t'</span> + str(nonce) + <span class="string">'\n'</span> + str(password) <span class="comment">#根据js拼接方式构造明文</span></span><br><span class="line">    pwd = rsa.encrypt(codeStr, RSAKey)  <span class="comment">#使用rsa进行加密</span></span><br><span class="line">    <span class="keyword">return</span> binascii.b2a_hex(pwd)  <span class="comment">#将加密信息转换为16进制。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#读取preinfo.php，获取servertime, nonce, pubkey, rsakv四个参数值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_prelogin_info</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">r'http://login.sina.com.cn/sso/prelogin.php?entry=weibo&amp;callback=sinaSSOController.preloginCallBack&amp;su=&amp;rsakt=mod&amp;client=ssologin.js(v1.4.18)'</span></span><br><span class="line">    html = requests.get(url).text</span><br><span class="line">    jsonStr = re.findall(<span class="string">r'\((\{.*?\})\)'</span>, html)[<span class="number">0</span>]</span><br><span class="line">    data = json.loads(jsonStr)</span><br><span class="line">    servertime = data[<span class="string">"servertime"</span>]</span><br><span class="line">    nonce = data[<span class="string">"nonce"</span>]</span><br><span class="line">    pubkey = data[<span class="string">"pubkey"</span>]</span><br><span class="line">    rsakv = data[<span class="string">"rsakv"</span>]</span><br><span class="line">    <span class="keyword">return</span> servertime, nonce, pubkey, rsakv</span><br><span class="line"></span><br><span class="line"><span class="comment">#根据Fiddler抓取的数据，构造post_data</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">encode_post_data</span><span class="params">(username, password, servertime, nonce, pubkey, rsakv)</span>:</span></span><br><span class="line">    su = encode_username(username)</span><br><span class="line">    sp = encode_password(password, servertime, nonce, pubkey)</span><br><span class="line">    <span class="comment">#用于登录到 http://login.sina.com.cn</span></span><br><span class="line">    post_data = {</span><br><span class="line">        <span class="string">"cdult"</span> : <span class="string">"3"</span>,</span><br><span class="line">        <span class="string">"domain"</span> : <span class="string">"sina.com.cn"</span>,</span><br><span class="line">        <span class="string">"encoding"</span> : <span class="string">"UTF-8"</span>,</span><br><span class="line">        <span class="string">"entry"</span> : <span class="string">"account"</span>,</span><br><span class="line">        <span class="string">"from"</span> : <span class="string">""</span>,</span><br><span class="line">        <span class="string">"gateway"</span> : <span class="string">"1"</span>,</span><br><span class="line">        <span class="string">"nonce"</span> : nonce,</span><br><span class="line">        <span class="string">"pagerefer"</span> : <span class="string">"http://login.sina.com.cn/sso/logout.php"</span>,</span><br><span class="line">        <span class="string">"prelt"</span> : <span class="string">"41"</span>,</span><br><span class="line">        <span class="string">"pwencode"</span> : <span class="string">"rsa2"</span>,</span><br><span class="line">        <span class="string">"returntype"</span> : <span class="string">"TEXT"</span>,</span><br><span class="line">        <span class="string">"rsakv"</span> : rsakv,</span><br><span class="line">        <span class="string">"savestate"</span> : <span class="string">"30"</span>,</span><br><span class="line">        <span class="string">"servertime"</span> : servertime,</span><br><span class="line">        <span class="string">"service"</span> : <span class="string">"sso"</span>,</span><br><span class="line">        <span class="string">"sp"</span> : sp,</span><br><span class="line">        <span class="string">"sr"</span> : <span class="string">"1366*768"</span>,</span><br><span class="line">        <span class="string">"su"</span> : su,</span><br><span class="line">        <span class="string">"useticket"</span> : <span class="string">"0"</span>,</span><br><span class="line">        <span class="string">"vsnf"</span> : <span class="string">"1"</span></span><br><span class="line">    }</span><br><span class="line">    <span class="comment">#用于登录到 http://login.sina.com.cn/signup/signin.php?entry=ss，将POST替换成下面的即可</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    post_data = {</span></span><br><span class="line"><span class="string">        "cdult" : "3",</span></span><br><span class="line"><span class="string">        "domain" : "sina.com.cn",</span></span><br><span class="line"><span class="string">        "encoding" : "UTF-8",</span></span><br><span class="line"><span class="string">        "entry" : "sso",</span></span><br><span class="line"><span class="string">        "from" : "null",</span></span><br><span class="line"><span class="string">        "gateway" : "1",</span></span><br><span class="line"><span class="string">        "pagerefer" : "",</span></span><br><span class="line"><span class="string">        "prelt" : "0",</span></span><br><span class="line"><span class="string">        "returntype" : "TEXT",</span></span><br><span class="line"><span class="string">        "savestate" : "30",</span></span><br><span class="line"><span class="string">        "service" : "sso",</span></span><br><span class="line"><span class="string">        "sp" : password,</span></span><br><span class="line"><span class="string">        "sr" : "1366*768",</span></span><br><span class="line"><span class="string">        "su" : su,</span></span><br><span class="line"><span class="string">        "useticket" : "0",</span></span><br><span class="line"><span class="string">        "vsnf" : "1"</span></span><br><span class="line"><span class="string">    }    </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> post_data</span><br></pre></td></tr></tbody></table></figure><p>2.<a href="https://github.com/csuldw/WSpider/blob/master/SinaLogin/Logger.py" target="_blank" rel="noopener">Logger.py</a></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Thu Nov 02 14:01:17 2016</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: liudiwei</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> logging  </span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogClient</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.logger = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="string">"""#EXAMPLE </span></span><br><span class="line"><span class="string">    logger = createLogger('mylogger', 'temp/logger.log')</span></span><br><span class="line"><span class="string">    logger.debug('logger debug message')  </span></span><br><span class="line"><span class="string">    logger.info('logger info message')  </span></span><br><span class="line"><span class="string">    logger.warning('logger warning message')  </span></span><br><span class="line"><span class="string">    logger.error('logger error message')  </span></span><br><span class="line"><span class="string">    logger.critical('logger critical message')  </span></span><br><span class="line"><span class="string">    """</span>    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">createLogger</span><span class="params">(self, logger_name, log_file)</span>:</span></span><br><span class="line">        prefix = os.path.dirname(log_file)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(prefix):</span><br><span class="line">            os.makedirs(prefix)</span><br><span class="line">        <span class="comment"># 创建一个logger</span></span><br><span class="line">        logger = logging.getLogger(logger_name)  </span><br><span class="line">        logger.setLevel(logging.INFO)  </span><br><span class="line">        <span class="comment"># 创建一个handler，用于写入日志文件    </span></span><br><span class="line">        fh = logging.FileHandler(log_file)  </span><br><span class="line">        <span class="comment"># 再创建一个handler，用于输出到控制台    </span></span><br><span class="line">        ch = logging.StreamHandler()  </span><br><span class="line">        <span class="comment"># 定义handler的输出格式formatter    </span></span><br><span class="line">        formatter = logging.Formatter(<span class="string">'%(asctime)s | %(name)s | %(levelname)s | %(message)s'</span>)  </span><br><span class="line">        fh.setFormatter(formatter)  </span><br><span class="line">        ch.setFormatter(formatter)  </span><br><span class="line">        <span class="comment"># 给logger添加handler    </span></span><br><span class="line">        logger.addHandler(fh)  </span><br><span class="line">        logger.addHandler(ch)</span><br><span class="line">        self.logger = logger</span><br><span class="line">        <span class="keyword">return</span> self.logger</span><br></pre></td></tr></tbody></table></figure><p>2.<a href="https://github.com/csuldw/WSpider/blob/master/SinaLogin/SinaSpider.py" target="_blank" rel="noopener">SinaSpider.py</a></p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">Created on Tue Nov 08 10:14:38 2016</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: liudiwei</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">import os</span><br><span class="line">import getpass</span><br><span class="line">import json</span><br><span class="line">import requests</span><br><span class="line">import cookielib</span><br><span class="line">import urllib</span><br><span class="line">import urllib2</span><br><span class="line">import gzip</span><br><span class="line">import StringIO</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">import dataEncode</span><br><span class="line">from Logger import LogClient</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SinaClient</span>(<span class="title">object</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, username=None, password=None)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="comment">#用户输入的用户名与密码</span></span><br><span class="line">        <span class="keyword">self</span>.username = username</span><br><span class="line">        <span class="keyword">self</span>.password = password</span><br><span class="line">        <span class="comment">#从prelogin.php中获取的数据</span></span><br><span class="line">        <span class="keyword">self</span>.servertime = None</span><br><span class="line">        <span class="keyword">self</span>.nonce = None</span><br><span class="line">        <span class="keyword">self</span>.pubkey = None</span><br><span class="line">        <span class="keyword">self</span>.rsakv = None</span><br><span class="line">        <span class="comment">#请求时提交的数据列表</span></span><br><span class="line">        <span class="keyword">self</span>.post_data = None</span><br><span class="line">        <span class="keyword">self</span>.headers = {}</span><br><span class="line">        <span class="comment">#用于存储登录后的session</span></span><br><span class="line">        <span class="keyword">self</span>.session = None   </span><br><span class="line">        <span class="keyword">self</span>.cookiejar = None</span><br><span class="line">        <span class="comment">#用于输出log信息</span></span><br><span class="line">        <span class="keyword">self</span>.logger = None</span><br><span class="line">        <span class="comment">#存储登录状态，初始状态为False        </span></span><br><span class="line">        <span class="keyword">self</span>.state = False</span><br><span class="line">        <span class="comment">#初始时调用initParams方法，初始化相关参数</span></span><br><span class="line">        <span class="keyword">self</span>.initParams()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#初始化参数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initParams</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.logger = LogClient().createLogger(<span class="string">'SinaClient'</span>, <span class="string">'out/log_'</span> + time.strftime(<span class="string">"%Y%m%d"</span>, time.localtime()) + <span class="string">'.log'</span>)</span><br><span class="line">        <span class="keyword">self</span>.headers = dataEncode.headers</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">self</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#设置username 和 password</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setAccount</span><span class="params">(<span class="keyword">self</span>, username, password)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.username = username</span><br><span class="line">        <span class="keyword">self</span>.password = password</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">self</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#设置post_data</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setPostData</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.servertime, <span class="keyword">self</span>.nonce, <span class="keyword">self</span>.pubkey, <span class="keyword">self</span>.rsakv = dataEncode.get_prelogin_info()</span><br><span class="line">        <span class="keyword">self</span>.post_data = dataEncode.encode_post_data(<span class="keyword">self</span>.username, <span class="keyword">self</span>.password, <span class="keyword">self</span>.servertime, <span class="keyword">self</span>.nonce, <span class="keyword">self</span>.pubkey, <span class="keyword">self</span>.rsakv)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">self</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment">#使用requests库登录到 https://login.sina.com.cn</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">login</span><span class="params">(<span class="keyword">self</span>, username=None, password=None)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="comment">#根据用户名和密码给默认参数赋值,并初始化post_data</span></span><br><span class="line">        <span class="keyword">self</span>.setAccount(username, password) </span><br><span class="line">        <span class="keyword">self</span>.setPostData()</span><br><span class="line">        <span class="comment">#登录时请求的url</span></span><br><span class="line">        login_url = r<span class="string">'https://login.sina.com.cn/sso/login.php?client=ssologin.js(v1.4.15)'</span></span><br><span class="line">        session = requests.Session()</span><br><span class="line">        response = session.post(login_url, data=<span class="keyword">self</span>.post_data)</span><br><span class="line">        json_text = response.content.decode(<span class="string">'gbk'</span>)</span><br><span class="line">        res_info = json.loads(json_text)</span><br><span class="line">        <span class="symbol">try:</span></span><br><span class="line">            <span class="keyword">if</span> res_info[<span class="string">"retcode"</span>] == <span class="string">"0"</span><span class="symbol">:</span></span><br><span class="line">                <span class="keyword">self</span>.logger.info(<span class="string">"Login success!"</span>)</span><br><span class="line">                <span class="keyword">self</span>.state = True</span><br><span class="line">                <span class="comment">#把cookies添加到headers中</span></span><br><span class="line">                cookies = session.cookies.get_dict()</span><br><span class="line">                cookies = [key + <span class="string">"="</span> + value <span class="keyword">for</span> key, value <span class="keyword">in</span> cookies.items()]</span><br><span class="line">                cookies = <span class="string">"; "</span>.join(cookies)</span><br><span class="line">                session.headers[<span class="string">"Cookie"</span>] = cookies</span><br><span class="line">            <span class="symbol">else:</span></span><br><span class="line">                <span class="keyword">self</span>.logger.error(<span class="string">"Login Failed! | "</span> + res_info[<span class="string">"reason"</span>])</span><br><span class="line">        except Exception, <span class="symbol">e:</span></span><br><span class="line">            <span class="keyword">self</span>.logger.error(<span class="string">"Loading error --&gt; "</span> + e)</span><br><span class="line">        <span class="keyword">self</span>.session = session</span><br><span class="line">        <span class="keyword">return</span> session</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#生成Cookie,接下来的所有get和post请求都带上已经获取的cookie</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">enableCookie</span><span class="params">(<span class="keyword">self</span>, enableProxy=False)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.cookiejar = cookielib.LWPCookieJar()  <span class="comment"># 建立COOKIE</span></span><br><span class="line">        cookie_support = urllib2.HTTPCookieProcessor(<span class="keyword">self</span>.cookiejar)</span><br><span class="line">        <span class="keyword">if</span> <span class="symbol">enableProxy:</span></span><br><span class="line">            proxy_support = urllib2.ProxyHandler({<span class="string">'http'</span>: <span class="string">'http://122.96.59.107:843'</span>}) <span class="comment"># 使用代理</span></span><br><span class="line">            opener = urllib2.build_opener(proxy_support, cookie_support, urllib2.HTTPHandler)</span><br><span class="line">            <span class="keyword">self</span>.logger.info(<span class="string">"Proxy enable."</span>)</span><br><span class="line">        <span class="symbol">else:</span></span><br><span class="line">            opener = urllib2.build_opener(cookie_support, urllib2.HTTPHandler)</span><br><span class="line">        urllib2.install_opener(opener)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#使用urllib2模拟登录过程</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">login2</span><span class="params">(<span class="keyword">self</span>, username=None, password=None)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.logger.info(<span class="string">"Start to login..."</span>)</span><br><span class="line">        <span class="comment">#根据用户名和密码给默认参数赋值,并初始化post_data</span></span><br><span class="line">        <span class="keyword">self</span>.setAccount(username, password) </span><br><span class="line">        <span class="keyword">self</span>.setPostData()</span><br><span class="line">        <span class="keyword">self</span>.enableCookie()</span><br><span class="line">        <span class="comment">#登录时请求的url</span></span><br><span class="line">        login_url = r<span class="string">'https://login.sina.com.cn/sso/login.php?client=ssologin.js(v1.4.15)'</span></span><br><span class="line">        headers = <span class="keyword">self</span>.headers</span><br><span class="line">        request = urllib2.Request(login_url, urllib.urlencode(<span class="keyword">self</span>.post_data), headers)</span><br><span class="line">        resText = urllib2.urlopen(request).read()</span><br><span class="line">        <span class="symbol">try:</span>        </span><br><span class="line">            jsonText = json.loads(resText)</span><br><span class="line">            <span class="keyword">if</span> jsonText[<span class="string">"retcode"</span>] == <span class="string">"0"</span><span class="symbol">:</span></span><br><span class="line">                <span class="keyword">self</span>.logger.info(<span class="string">"Login success!"</span>)</span><br><span class="line">                <span class="keyword">self</span>.state = True</span><br><span class="line">                <span class="comment">#将cookie加入到headers中</span></span><br><span class="line">                cookies = <span class="string">';'</span>.join([cookie.name + <span class="string">"="</span> + cookie.value <span class="keyword">for</span> cookie <span class="keyword">in</span> <span class="keyword">self</span>.cookiejar])</span><br><span class="line">                headers[<span class="string">"Cookie"</span>] = cookies</span><br><span class="line">            <span class="symbol">else:</span></span><br><span class="line">                <span class="keyword">self</span>.logger.error(<span class="string">"Login Failed --&gt; "</span> + jsonText[<span class="string">"reason"</span>])</span><br><span class="line">        except Exception, <span class="symbol">e:</span></span><br><span class="line">            print e</span><br><span class="line">        <span class="keyword">self</span>.headers = headers</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">self</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#打开url时携带headers,此header需携带cookies</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">openURL</span><span class="params">(<span class="keyword">self</span>, url, data=None)</span></span><span class="symbol">:</span></span><br><span class="line">        req = urllib2.Request(url, data=data, headers=<span class="keyword">self</span>.headers)</span><br><span class="line">        text = urllib2.urlopen(req).read()</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">self</span>.unzip(text)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#功能：将文本内容输出至本地</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">output</span><span class="params">(<span class="keyword">self</span>, content, out_path, save_mode=<span class="string">"w"</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.logger.info(<span class="string">"Download html page to local machine. | path: "</span> + out_path)</span><br><span class="line">        prefix = os.path.dirname(out_path)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(prefix)<span class="symbol">:</span></span><br><span class="line">            os.makedirs(prefix)</span><br><span class="line">        fw = open(out_path, save_mode)</span><br><span class="line">        fw.write(content)</span><br><span class="line">        fw.close()</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">self</span></span><br><span class="line">        </span><br><span class="line">    <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    防止读取出来的HTML乱码，测试样例如下</span></span><br><span class="line"><span class="string">    req = urllib2.Request(url, headers=headers)</span></span><br><span class="line"><span class="string">    text = urllib2.urlopen(req).read()</span></span><br><span class="line"><span class="string">    unzip(text)</span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">unzip</span><span class="params">(<span class="keyword">self</span>, data)</span></span><span class="symbol">:</span></span><br><span class="line">        data = StringIO.StringIO(data)</span><br><span class="line">        gz = gzip.GzipFile(fileobj=data)</span><br><span class="line">        data = gz.read()</span><br><span class="line">        gz.close()</span><br><span class="line">        <span class="keyword">return</span> data    </span><br><span class="line"></span><br><span class="line"><span class="comment">#调用login1进行登录</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testLogin</span><span class="params">()</span></span><span class="symbol">:</span></span><br><span class="line">    client = SinaClient()</span><br><span class="line">    username = raw_input(<span class="string">"Please input username: "</span>)</span><br><span class="line">    password = getpass.getpass(<span class="string">"Please input your password: "</span>)   </span><br><span class="line">    session = client.login(username, password)</span><br><span class="line">    </span><br><span class="line">    follow = session.post(<span class="string">"http://weibo.cn/1669282904/follow"</span>).text.encode(<span class="string">"utf-8"</span>)</span><br><span class="line">    client.output(follow, <span class="string">"out/follow.html"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#调用login2进行登录</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testLogin2</span><span class="params">()</span></span><span class="symbol">:</span></span><br><span class="line">    client = SinaClient()</span><br><span class="line">    username = raw_input(<span class="string">"Please input username: "</span>)</span><br><span class="line">    password = getpass.getpass(<span class="string">"Please input your password: "</span>)   </span><br><span class="line">    session = client.login2(username, password)</span><br><span class="line">    </span><br><span class="line">    info = session.openURL(<span class="string">"http://weibo.com/1669282904/info"</span>)</span><br><span class="line">    client.output(info, <span class="string">"out/info2.html"</span>)    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name_<span class="number">_</span> == <span class="string">'__main__'</span><span class="symbol">:</span></span><br><span class="line">    testLogin2()</span><br></pre></td></tr></tbody></table></figure><p>关于源码的分析，可以参考代码中的注解，如有不理解的地方，可在评论中提出。</p><h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><p>直接在Windows控制台运行<code>python SinaSpider.py</code>，然后根据提示输入用户名和密码即可。</p><p>运行结果展示</p><p><img src="/assets/articleImg/sina_login_demo.png" alt=""></p><p>OK，匆忙之际赶出了本文，如有言之不合理之处，可在评论中指出。现在可以成功地登录到微博了，接下来想爬取什么数据就尽情的爬吧。后续笔者将进一步介绍如何爬取微博数据，好了，后会有期吧！</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://en.wikipedia.org/wiki/Base64" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Base64</a></li><li><a href="http://www.jb51.net/article/46053.htm" target="_blank" rel="noopener">python使用rsa加密算法模块模拟新浪微博登录</a></li><li><a href="http://blog.csdn.net/bcj296050240/article/details/46685947" target="_blank" rel="noopener">新浪微博爬虫（模拟登录+数据解析）</a></li><li><a href="http://blog.csdn.net/monsion/article/details/8656690" target="_blank" rel="noopener">新浪微博模拟登录（Python+RSA加密算法）附源代码</a></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上一篇文章&lt;a href=&quot;http://www.csuldw.com/2016/11/05/2016-11-05-simulate-zhihu-login/&quot;&gt;小试牛刀：使用Python模拟登录知乎&lt;/a&gt;介绍了如何模拟知乎登录，虽然用到了验证码信息，但请求的参数都是原封不动的传递，刚开始接触的时候，觉得难度适中，回头再看的时候，反而感觉挺容易的。在这篇文章，将继续介绍模拟登录。与之前不一样的是，这次选择的对象是新浪微博，难度稍微提升了点，好在以往的许多码友们都留有许多经验贴，经过几番斟酌，微博的模拟登录算是实现了。这两天还在研究如何高性能地爬取微博数据，业余之际乘着还有点记忆，索性将先前的小实验加工成文，算是一份小结吧。下面来看看整个实验过程。&lt;/p&gt;
    
    </summary>
    
      <category term="Spider" scheme="https://www.csuldw.com/categories/Spider/"/>
    
    
      <category term="Python" scheme="https://www.csuldw.com/tags/Python/"/>
    
      <category term="爬虫" scheme="https://www.csuldw.com/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Spider" scheme="https://www.csuldw.com/tags/Spider/"/>
    
      <category term="Sina" scheme="https://www.csuldw.com/tags/Sina/"/>
    
      <category term="微博" scheme="https://www.csuldw.com/tags/%E5%BE%AE%E5%8D%9A/"/>
    
  </entry>
  
  <entry>
    <title>小试牛刀：使用Python模拟登录知乎</title>
    <link href="https://www.csuldw.com/2016/11/05/2016-11-05-simulate-zhihu-login/"/>
    <id>https://www.csuldw.com/2016/11/05/2016-11-05-simulate-zhihu-login/</id>
    <published>2016-11-05T08:10:00.000Z</published>
    <updated>2017-03-26T07:01:26.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最近突然对爬虫兴趣倍增，主要是自己想从网上爬点数据来玩玩。前阵子从某房屋出售网爬取了长沙地区的房价以及2016年的成交额，只有几千条数据，量较少，没劲o(╯□╰)o，因此将目标成功地转移到了社交网上，难度显然大了点。爬取社交网站比较鲜明的特点就是需要登录，否则很多东西都无法获取。做了几个小Demo之后发现，人人网的登录还比较简单，验证码的都不用就可以成功登录；知乎虽然携带验证码，但难度算是适中；微博的登录难度稍微大点，因为不仅有验证码，还在传递参数的时候对用户名进行了base64加密。在这篇博文里，主要是以知乎为例，模拟知乎登录，至于数据爬取部分咱们就暂且不谈吧。</p><a id="more"></a><h2 id="环境与开发工具"><a href="#环境与开发工具" class="headerlink" title="环境与开发工具"></a>环境与开发工具</h2><p>模拟知乎登录前，先看看本次案例使用的环境及其工具：</p><ul><li>Windows 7 + Python 2.75</li><li>Chrome + Fiddler: 用来监控客户端与服务器的通讯情况，以及查找相关参数的位置。</li></ul><p>Github源码下载：<a href="https://github.com/csuldw/WSpider" target="_blank" rel="noopener">https://github.com/csuldw/WSpider</a>.</p><h2 id="模拟过程概述"><a href="#模拟过程概述" class="headerlink" title="模拟过程概述"></a>模拟过程概述</h2><ol><li>使用Google浏览器结合Fiddler来监控客户端与服务端的通讯过程；</li><li>根据监控结果，构造请求服务器过程中传递的参数；</li><li>使用Python模拟参数传递过程。</li></ol><p>客户端与服务端通信过程的几个关键点：</p><ul><li>登录时的url地址。</li><li>登录时提交的参数【params】，获取方式主要有两种：第一、分析页面源代码，找到表单标签及属性。适应比较简单的页面。第二、使用抓包工具，查看提交的url和参数，通常使用的是Chrome的开发者工具中的Network， Fiddler等。</li><li>登录后跳转的url。</li></ul><p>在抓包的时候，开始使用的是Chrome开发工具中的Network，结果没有抓到，后来使用Fiddler成功抓取数据。下面逐步来细化上述过程。</p><h2 id="参数探索"><a href="#参数探索" class="headerlink" title="参数探索"></a>参数探索</h2><p>首先看看这个登录页面(<a href="https//www.zhihu.com">https//www.zhihu.com</a>)，也就是我们登录时的url地址。</p><p><img src="/assets/articleImg/zhihu-login-page.png" alt=""></p><p>看到这个页面，我们也可以大概猜测下请求服务器时传递了几个字段，很明显有：用户名、密码、验证码以及“记住我”这几个值。那么实际上有哪些呢？下面来分分析下。</p><p>首先查看一下HTML源码，Google里可以使用<code>CTRL+U</code>查看，然后使用<code>CTRL+F</code>输入input看看有哪些字段值，详情如下：</p><p><img src="/assets/articleImg/src-input.png" alt=""></p><p>通过源码，我们可以看到，在请求服务器的过程中还携带了一个隐藏字段”_xsrf”。那么现在的问题是：这些参数在传递时是以什么名字传递的呢？这就需要借用其他工具抓包进行分析了。笔者是Windows系统，这里使用的是<strong>Fiddler</strong>（当然，你也可以使用其他的）。</p><p>抓包过程比较繁琐，因为抓到的东西比较多，很难快速的找到需要的信息。关于fiddler，很容易使用，有过不会，可以去百度搜一下。为了防止其他信息干扰，我们先将fiddler中的记录清除，然后输入用户名（笔者使用的是邮箱登录）、密码等信息登录，相应的在fiddler中会有如下结果:</p><p><img src="/assets/articleImg/login-email.png" alt=""></p><p>备注：如果是使用手机登录，则对应fiddler中的url是“/login/phone_num”。</p><p>为了查看详细的请求参数，我们左键单机“/login/email”，可以看到下列信息：</p><p><img src="/assets/articleImg/login-email-detail.png" alt=""></p><p>请求方式为<code>POST</code>，请求的url为<a href="https://www.zhihu.com/login/email" target="_blank" rel="noopener">https://www.zhihu.com/login/email</a>。而从From Data可以看出，相应的字段名称如下：</p><ul><li>_xsrf</li><li>captcha</li><li>email</li><li>password</li><li>remember</li></ul><p>对于这五个字段，代码中email、password以及captcha都是手动输入的，remember初始化为true。剩下的_xsrf则可以根据登录页面的源文件，取input为_xsrf的value值即可。</p><p><img src="/assets/articleImg/xsrf-info.png" alt=""></p><p>对于验证码，则需要通过额外的请求，该链接可以通过定点查看源码看出：</p><p><img src="/assets/articleImg/captcha-link.png" alt=""></p><p>链接为<a href="https://www.zhihu.com/captcha.gif?type=login" target="_blank" rel="noopener">https://www.zhihu.com/captcha.gif?type=login</a>，这里省略了ts（经测试，可省略掉）。现在，可以使用代码进行模拟登录。</p><p>温馨提示：<strong>如果使用的是手机号码进行登录，则请求的url为<a href="https://www.zhihu.com/login/phone_num" target="_blank" rel="noopener">https://www.zhihu.com/login/phone_num</a>，同时email字段名称将变成“phone_num”。</strong></p><h2 id="模拟源码"><a href="#模拟源码" class="headerlink" title="模拟源码"></a>模拟源码</h2><p>在编写代码实现知乎登录的过程中，笔者将一些功能封装成了一个简单的类WSpider，以便复用，文件名称为<a href="https://github.com/csuldw/WSpider/blob/master/WSpider.py" target="_blank" rel="noopener">WSpider.py</a>。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Thu Nov 02 14:01:17 2016</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: liudiwei</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> cookielib</span><br><span class="line"><span class="keyword">import</span> logging  </span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WSpider</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#init params</span></span><br><span class="line">        self.url_path = <span class="literal">None</span></span><br><span class="line">        self.post_data = <span class="literal">None</span></span><br><span class="line">        self.header = <span class="literal">None</span></span><br><span class="line">        self.domain = <span class="literal">None</span></span><br><span class="line">        self.operate = <span class="literal">None</span></span><br><span class="line">        <span class="comment">#init cookie</span></span><br><span class="line">        self.cookiejar = cookielib.LWPCookieJar()</span><br><span class="line">        self.opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(self.cookiejar))</span><br><span class="line">        urllib2.install_opener(self.opener)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setRequestData</span><span class="params">(self, url_path=None, post_data=None, header=None)</span>:</span></span><br><span class="line">        self.url_path = url_path</span><br><span class="line">        self.post_data = post_data</span><br><span class="line">        self.header = header</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getHtmlText</span><span class="params">(self, is_cookie=False)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.post_data == <span class="literal">None</span> <span class="keyword">and</span> self.header == <span class="literal">None</span>:</span><br><span class="line">            request = urllib2.Request(self.url_path)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            request = urllib2.Request(self.url_path, urllib.urlencode(self.post_data), self.header)</span><br><span class="line">        response = urllib2.urlopen(request)</span><br><span class="line">        <span class="keyword">if</span> is_cookie: </span><br><span class="line">            self.operate = self.opener.open(request)</span><br><span class="line">        resText = response.read()</span><br><span class="line">        <span class="keyword">return</span> resText </span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Save captcha to local    </span></span><br><span class="line"><span class="string">    """</span>    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">saveCaptcha</span><span class="params">(self, captcha_url, outpath, save_mode=<span class="string">'wb'</span>)</span>:</span></span><br><span class="line">        picture = self.opener.open(captcha_url).read() <span class="comment">#用openr访问验证码地址,获取cookie</span></span><br><span class="line">        local = open(outpath, save_mode)</span><br><span class="line">        local.write(picture)</span><br><span class="line">        local.close()    </span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getHtml</span><span class="params">(self, url)</span>:</span></span><br><span class="line">        page = urllib.urlopen(url)</span><br><span class="line">        html = page.read()</span><br><span class="line">        <span class="keyword">return</span> html</span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    功能：将文本内容输出至本地</span></span><br><span class="line"><span class="string">    @params </span></span><br><span class="line"><span class="string">        content：文本内容</span></span><br><span class="line"><span class="string">        out_path: 输出路径</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">output</span><span class="params">(self, content, out_path, save_mode=<span class="string">"w"</span>)</span>:</span></span><br><span class="line">        fw = open(out_path, save_mode)</span><br><span class="line">        fw.write(content)</span><br><span class="line">        fw.close()</span><br><span class="line"></span><br><span class="line">    <span class="string">"""#EXAMPLE </span></span><br><span class="line"><span class="string">    logger = createLogger('mylogger', 'temp/logger.log')</span></span><br><span class="line"><span class="string">    logger.debug('logger debug message')  </span></span><br><span class="line"><span class="string">    logger.info('logger info message')  </span></span><br><span class="line"><span class="string">    logger.warning('logger warning message')  </span></span><br><span class="line"><span class="string">    logger.error('logger error message')  </span></span><br><span class="line"><span class="string">    logger.critical('logger critical message')  </span></span><br><span class="line"><span class="string">    """</span>    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">createLogger</span><span class="params">(self, logger_name, log_file)</span>:</span></span><br><span class="line">        <span class="comment"># 创建一个logger</span></span><br><span class="line">        logger = logging.getLogger(logger_name)  </span><br><span class="line">        logger.setLevel(logging.INFO)  </span><br><span class="line">        <span class="comment"># 创建一个handler，用于写入日志文件    </span></span><br><span class="line">        fh = logging.FileHandler(log_file)  </span><br><span class="line">        <span class="comment"># 再创建一个handler，用于输出到控制台    </span></span><br><span class="line">        ch = logging.StreamHandler()  </span><br><span class="line">        <span class="comment"># 定义handler的输出格式formatter    </span></span><br><span class="line">        formatter = logging.Formatter(<span class="string">'%(asctime)s | %(name)s | %(levelname)s | %(message)s'</span>)  </span><br><span class="line">        fh.setFormatter(formatter)  </span><br><span class="line">        ch.setFormatter(formatter)  </span><br><span class="line">        <span class="comment"># 给logger添加handler    </span></span><br><span class="line">        logger.addHandler(fh)  </span><br><span class="line">        logger.addHandler(ch)  </span><br><span class="line">        <span class="keyword">return</span> logger</span><br></pre></td></tr></tbody></table></figure><p>关于模拟登录知乎的源码，保存在<a href="https://github.com/csuldw/WSpider/blob/master/zhiHuLogin.py" target="_blank" rel="noopener">zhiHuLogin.py</a>文件，内容如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Thu Nov 02 17:07:17 2016</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: liudiwei</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">from</span> WSpider <span class="keyword">import</span> WSpider</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup <span class="keyword">as</span> BS</span><br><span class="line"><span class="keyword">import</span> getpass</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> WLogger <span class="keyword">as</span> WLog</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">2016.11.03 由于验证码问题暂时无法正常登陆</span></span><br><span class="line"><span class="string">2016.11.04 成功登录，期间出现下列问题</span></span><br><span class="line"><span class="string">验证码错误返回：{ "r": 1, "errcode": 1991829, "data": {"captcha":"验证码错误"}, "msg": "验证码错误" }</span></span><br><span class="line"><span class="string">验证码过期：{ "r": 1, "errcode": 1991829, "data": {"captcha":"验证码回话无效 :(","name":"ERR_VERIFY_CAPTCHA_SESSION_INVALID"}, "msg": "验证码回话无效 :(" }</span></span><br><span class="line"><span class="string">登录：{"r":0, "msg": "登录成功"}</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">zhiHuLogin</span><span class="params">()</span>:</span></span><br><span class="line">    spy = WSpider()</span><br><span class="line">    logger = spy.createLogger(<span class="string">'mylogger'</span>, <span class="string">'temp/logger.log'</span>)</span><br><span class="line">    </span><br><span class="line">    homepage = <span class="string">r"https://www.zhihu.com/"</span>    </span><br><span class="line">    html = spy.opener.open(homepage).read()</span><br><span class="line">    soup = BS(html, <span class="string">"html.parser"</span>)</span><br><span class="line">    _xsrf = soup.find(<span class="string">"input"</span>, {<span class="string">'type'</span>:<span class="string">'hidden'</span>}).get(<span class="string">"value"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#根据email和手机登陆得到的参数名不一样，email登陆传递的参数是‘email’，手机登陆传递的是‘phone_num’</span></span><br><span class="line">    username = raw_input(<span class="string">"Please input username: "</span>)</span><br><span class="line">    password = getpass.getpass(<span class="string">"Please input your password: "</span>)</span><br><span class="line">    account_name = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">"@"</span> <span class="keyword">in</span> username:</span><br><span class="line">        account_name = <span class="string">'email'</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        account_name = <span class="string">'phone_num'</span> </span><br><span class="line"></span><br><span class="line">    <span class="comment">#保存验证码</span></span><br><span class="line">    logger.info(<span class="string">"save captcha to local machine."</span>)</span><br><span class="line">    captchaURL = <span class="string">r"https://www.zhihu.com/captcha.gif?type=login"</span> <span class="comment">#验证码url</span></span><br><span class="line">    spy.saveCaptcha(captcha_url=captchaURL, outpath=<span class="string">"temp/captcha.jpg"</span>) <span class="comment">#temp目录需手动创建</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#请求的参数列表</span></span><br><span class="line">    post_data = {</span><br><span class="line">        <span class="string">'_xsrf'</span>: _xsrf,</span><br><span class="line">        account_name: username,</span><br><span class="line">        <span class="string">'password'</span>: password,</span><br><span class="line">        <span class="string">'remember_me'</span>: <span class="string">'true'</span>,</span><br><span class="line">        <span class="string">'captcha'</span>:raw_input(<span class="string">"Please input captcha: "</span>)</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">#请求的头内容</span></span><br><span class="line">    header ={</span><br><span class="line">        <span class="string">'Accept'</span>:<span class="string">'*/*'</span> ,</span><br><span class="line">        <span class="string">'Content-Type'</span>:<span class="string">'application/x-www-form-urlencoded; charset=UTF-8'</span>,</span><br><span class="line">        <span class="string">'X-Requested-With'</span>:<span class="string">'XMLHttpRequest'</span>,</span><br><span class="line">        <span class="string">'Referer'</span>:<span class="string">'https://www.zhihu.com/'</span>,</span><br><span class="line">        <span class="string">'Accept-Language'</span>:<span class="string">'en-GB,en;q=0.8,zh-CN;q=0.6,zh;q=0.4'</span>,</span><br><span class="line">        <span class="string">'Accept-Encoding'</span>:<span class="string">'gzip, deflate, br'</span>,</span><br><span class="line">        <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36'</span>,</span><br><span class="line">        <span class="string">'Host'</span>:<span class="string">'www.zhihu.com'</span></span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    url = <span class="string">r"https://www.zhihu.com/login/"</span> + account_name</span><br><span class="line">    spy.setRequestData(url, post_data, header)</span><br><span class="line">    resText = spy.getHtmlText()</span><br><span class="line">    jsonText = json.loads(resText)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> jsonText[<span class="string">"r"</span>] == <span class="number">0</span>:</span><br><span class="line">        logger.info(<span class="string">"Login success!"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        logger.error(<span class="string">"Login Failed!"</span>)</span><br><span class="line">        logger.error(<span class="string">"Error info ---&gt; "</span> + jsonText[<span class="string">"msg"</span>])</span><br><span class="line">        </span><br><span class="line">    text = spy.opener.open(homepage).read() <span class="comment">#重新打开主页，查看源码可知此时已经处于登录状态</span></span><br><span class="line">    spy.output(text, <span class="string">"out/home.html"</span>) <span class="comment">#out目录需手动创建</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    zhiHuLogin()</span><br></pre></td></tr></tbody></table></figure><p>关于源码的分析，可以参考代码中的注解。</p><h2 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h2><p>在控制台中运行<code>python zhiHuLogin.py</code>，然后按提示输入相应的内容，最后可得到以下不同的结果（举了三个实例）：</p><p>结果一：密码错误</p><p><img src="/assets/articleImg/run-example-password-error.png" alt=""></p><p>结果二：验证码错误</p><p><img src="/assets/articleImg/run-example-captcha-error.png" alt=""></p><p>结果三：成功登录</p><p><img src="/assets/articleImg/run-example-success.png" alt=""></p><p>通过代码，可以成功的登录到知乎，接着如果要爬取知乎里面的内容，就比较方便了。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近突然对爬虫兴趣倍增，主要是自己想从网上爬点数据来玩玩。前阵子从某房屋出售网爬取了长沙地区的房价以及2016年的成交额，只有几千条数据，量较少，没劲o(╯□╰)o，因此将目标成功地转移到了社交网上，难度显然大了点。爬取社交网站比较鲜明的特点就是需要登录，否则很多东西都无法获取。做了几个小Demo之后发现，人人网的登录还比较简单，验证码的都不用就可以成功登录；知乎虽然携带验证码，但难度算是适中；微博的登录难度稍微大点，因为不仅有验证码，还在传递参数的时候对用户名进行了base64加密。在这篇博文里，主要是以知乎为例，模拟知乎登录，至于数据爬取部分咱们就暂且不谈吧。&lt;/p&gt;
    
    </summary>
    
      <category term="Spider" scheme="https://www.csuldw.com/categories/Spider/"/>
    
    
      <category term="Python" scheme="https://www.csuldw.com/tags/Python/"/>
    
      <category term="爬虫" scheme="https://www.csuldw.com/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Spider" scheme="https://www.csuldw.com/tags/Spider/"/>
    
      <category term="ZhiHu" scheme="https://www.csuldw.com/tags/ZhiHu/"/>
    
  </entry>
  
  <entry>
    <title>逻辑回归理论推导</title>
    <link href="https://www.csuldw.com/2016/09/19/2016-09-19-logistic-regression-theory/"/>
    <id>https://www.csuldw.com/2016/09/19/2016-09-19-logistic-regression-theory/</id>
    <published>2016-09-19T10:24:00.000Z</published>
    <updated>2019-05-28T16:19:08.877Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>出于学习的目的，笔者决定将逻辑回归总结一次。本文主要介绍逻辑回归的推导，囊括Sigmoid函数、极大似然估计、损失函数以、梯度下降以及正则化。文章内容纯属总结性知识，并不是对LR进行大篇长论。如有理解不到位的地方，还请读者指出。</p><a id="more"></a><p>什么是逻辑回归？引用<a href="http://www.statisticssolutions.com/what-is-logistic-regression/" target="_blank" rel="noopener">StatisticsSolutions</a>的解释就是：</p><blockquote><p>Logistic regression is the appropriate regression analysis to conduct when the dependent variable is dichotomous (binary).  Like all regression analyses, the logistic regression is a predictive analysis.  Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more metric (interval or ratio scale) independent variables.</p></blockquote><p>通常监督学习问题可归纳为以下三个步骤：</p><ul><li>寻找假设空间中的$h$函数（即hypothesis）；</li><li>根据已知条件构造损失函数$J(\theta)$；</li><li>最小化损失函数，即求解使得$J(\theta)$最小时的回归参数$\theta$(当然，在有的文章中求得是$w$和$b$).</li></ul><h2 id="Sigmoid-函数"><a href="#Sigmoid-函数" class="headerlink" title="Sigmoid 函数"></a>Sigmoid 函数</h2><p>说到逻辑回归，Sigmoid是一大要点，其表达式为：</p><p>$$ g(z) = \frac{1}{1 + e^{-z} }<br>\tag{1} \label{1}$$</p><p>该函数是一个可导函数，定义域为$(-\infty, +\infty)$，值域为[0, 1]，其导数表达式如下：</p><p>$$g’(z) = g(z)(1-g(z))<br>\tag{2} \label{2}$$</p><p>说明一下，表达式$\eqref{1}$等价于使用线性回归模型的预测结果直接去逼近真实标记的对数几率，因此将其称作“对数几率回归（logit regression）”。使用这种方法有以下几大优点：</p><ul><li>直接对样本进行建模，无需对样本进行先验假设；</li><li>其结果不仅可以预测出“label”，还可以得到近似的概率预测值；</li><li>sigmoid函数的数学性质良好，它是任意阶可导的凸函数，因此许多的优化方法都可使用。</li></ul><p>简单介绍了一下逻辑回归的核心函数，那么逻辑回归源于什么思想呢，即统计三要素（模型+策略+算法）中的”模型”和”策略”是什么？</p><h2 id="极大似然估计MLE与损失函数"><a href="#极大似然估计MLE与损失函数" class="headerlink" title="极大似然估计MLE与损失函数"></a>极大似然估计MLE与损失函数</h2><p>在李航博士的统计学习方法一书中指出，损失函数（loss function）是用来估量你模型的预测值$f(x)$与真实值$Y$的不一致程度，它是一个非负实值函数，通常使用$L(Y, f(x))$来表示，损失函数越小，模型的鲁棒性就越好。损失函数是<strong>经验风险函数</strong>的核心部分，也是<strong>结构风险函数</strong>重要组成部分。模型的结构风险函数包括了经验风险项和正则项，通常结构风险函数可以表示成如下式子：</p><p>$$\theta^* = \arg \min_\theta \frac{1}{N}{}\sum_{i=1}^{N} L(y_i, f(x_i; \theta)) + \lambda\  \Phi(\theta)<br>\tag{3}\label{3}$$</p><p>对于逻辑回归，其loss function是log损失，也可以说是交叉熵损失，可以通过极大似然估计进行推导得到。首先，给定一个样本$x$，可以使用一个线性函数对自变量进行线性组合，</p><p>$$\theta_0 + \theta_1 x_1 + \theta_2 x_2 + \cdots + \theta_nx_n  = \theta^T x<br>\tag{4} \label{4}$$</p><p>根据sigmoid函数，我们可以得出预测函数的表达式：</p><p>$$h_{\theta}(x) = g(\theta^Tx) = \frac{1}{1 + e^{-\theta^Tx}}<br>\tag{5} \label{5}$$</p><p>式$\eqref{4}$表示$y=1$时预测函数为$h_{\theta}(x)$。在这里，假设因变量$y$服从伯努利分布，取值为$0$和$1$，当$y$等于1时，预测值为$h_{\theta}(x)$，当$y$等于$0$时，预测值为$1-h_{\theta}(x)$，公式表示如下：</p><p>$$p(y=1 | x) = h_{\theta} (x)<br>\tag{6} \label{6}$$</p><p>$$p(y=0 | x) = 1 - h_{\theta} (x)<br>\tag{7} \label{7}$$</p><p>而对于上面的两个表达式，通过观察，我们可以将其合并为下式$\eqref{7}$：</p><p>$$p(y | x) = h_{\theta} (x)^y (1-h_{\theta} (x))^{1-y}<br>\tag{8} \label{8}$$</p><p>根据公式$\eqref{7}$，给定一定的样本之后，我们可以构造出似然函数，然后可以使用极大似然估计MLE的思想来求解参数。但是，为了满足最小化风险理论，我们可以将MLE的思想转化为最小化风险化理论，最大化似然函数其实就等价于最小化负的似然函数。对于MLE，<strong>就是利用已知的样本分布，找到最有可能（即最大概率）导致这种分布的参数值；或者说是什么样的参数才能使我们观测到目前这组数据的概率最大</strong>。使用MLE推导LR的loss function的过程如下。</p><p>首先，根据上面的假设，写出相应的极大似然函数（假定有$m$个样本）：</p><p>$$<br>\begin{aligned}<br>L(\theta)<br>&amp;=  \prod_{i=1}^{m} p(y^{(i)} | x^{(i)}; \theta)  \\<br>&amp;=  \prod_{i=1}^{m} h_{\theta} (x^{(i)})^{y^{(i)}} (1-h_{\theta} (x^{(i)}))^{1-y^{(i)}} \\<br>\end{aligned}<br>\tag{9} \label{9}$$</p><p>直接对上面的式子求导会不方便，因此，为了便于计算，我们可以对似然函数取对数，经过化简可以得到下式的推导结果：</p><p>$$<br>\begin{aligned}<br>\log L(\theta)<br>&amp;= \sum_{i=1}^{m} \log \left [ (h_{\theta} (x_i)^{y^{(i)}} (1-h_{\theta} (x^{(i)}))^{1-y^{(i)}}) \right ] \\<br>&amp;= \sum_{i=1}^{m} \left [ y^{(i)} \log h_{\theta} (x^{(i)}) +  (1-y^{(i)}) \log(1-h_{\theta} (x^{(i)})) \right ]  \\<br>\end{aligned}<br>\tag{10} \label{10}$$</p><p>因此，损失函数可以通过最小化负的似然函数得到，即下式：</p><p>$$J(\theta) = - \frac{1}{m} \sum_{i=1}^m \left [ y^{(i)} \log h_{\theta}(x^{(i)}) + (1-y^{(i)}) \log(1-h_{\theta}(x^{(i)}))  \right ]<br>\tag{11} \label{11}$$</p><p>在有的资料上，还有另一种损失函数的表达形式，但本质是一样的，如下：</p><p>$$J(\theta) = \frac{1}{m} \sum_{i=1}^m log(1 + e^{-y^{(i)} \theta^T x})$$</p><h2 id="Gradient-descent"><a href="#Gradient-descent" class="headerlink" title="Gradient descent"></a>Gradient descent</h2><p>上面提到了模型和策略，下面来说说统计学习方法三要素中的算法，算法指的是学习模型的具体计算方法，求解的最优化方法，而本文主要介绍的是梯度下降优化算法的思想。</p><p>梯度下降法又叫做最速下降法，为了求解使损失函数$J(\theta)$最小时的参数$\theta$，这里就以<strong>梯度下降</strong>为例进行求解，其迭代公式的推导过程如下：</p><p>$$<br>\begin{aligned}<br>\frac{ \partial J(\theta)} {\partial \theta_j}<br>&amp;= -\frac{1}{m} \sum_{i}^{m} \left [ y^{(i)}(1 - h_{\theta}(x^{(i)})) \cdot (-x_{j}^{(i)}) + (1 - y^{(i)}) h_{\theta} (x^{(i)})  \cdot (x_{j}^{(i)}) \right ]  \\<br>&amp;= - \frac{1}{m} \sum_{i}^{m}  (-y^{(i)} \cdot x_j^{(i)} + h_{\theta}(x^{(i)}) \cdot x_j^{(i)})  \\<br>&amp;= -\frac{1}{m} \sum_{i}^{m} (h_{\theta}(x^{(i)}) - y^{(i)}) x_j^{(i)}<br>\end{aligned}<br>\tag{12} \label{12}$$</p><p>通过上面得到，可以得到最后的迭代式子：</p><p>$$\theta_j = \theta_j - \alpha \sum_{i=1}^{m} (h_{\theta}(x^{(i)}） - y^{(i)}) x_j^{(i)}<br>\tag{13}\label{13}$$</p><p>其中$\alpha$是步长。</p><p>最优化算法并不限于梯度下降，还有：</p><ul><li>Newton Method（牛顿法）</li><li>Conjugate gradient method(共轭梯度法)</li><li>Quasi-Newton Method(拟牛顿法)</li><li>BFGS Method</li><li>L-BFGS(Limited-memory BFGS)</li></ul><p>上述优化算法中，BFGS与L-BFGS均由拟牛顿法引申出来，与梯度下降算法相比，其优点是：第一、不需要手动的选择步长；第二、比梯度下降算法快。但缺点是这些算法更加复杂，实用性不如梯度下降。</p><h2 id="Regulization"><a href="#Regulization" class="headerlink" title="Regulization"></a>Regulization</h2><p>上面提到了，结构风险函数包括了经验风险项和正则项，加入正则项相当于对参数加入了一个先验分布，常用的有L1和L2正则，L1，L2正则化项对模型的参数向量进行“惩罚”，从而避免单纯最小二乘问题的过拟合问题。正则化项本质上是一种先验信息，整个最优化问题从贝叶斯观点来看是一种<strong>贝叶斯最大后验估计</strong>，其中正则化项对应后验估计中的先验信息，损失函数对应后验估计中的似然函数，两者的乘积即对应贝叶斯最大后验估计的形式，如果将这个贝叶斯最大后验估计的形式取对数，即进行极大似然估计，你就会发现问题立马变成了损失函数+正则化项的最优化问题形式。</p><p>在逻辑回归求解中，如果对样本加上一个先验的服从高斯分布的假设，那么取log后，式子经过化简后就变成在经验风险项后面加上一个正则项，此时结构风险函数为。</p><p>$$J(\theta) = - \frac{1}{m}\sum_{i=1}^m  \left [ y^{(i)} \log h_{\theta}(x^{(i)}) + (1-y^{(i)}) \log(1-h_{\theta}(x^{(i)}))  \right ] + \frac{\lambda}{2m} \sum_{j=1}^{n} \theta_{j}^2<br>\tag{14}\label{14}$$</p><p>关于LR，这里还有个PDF可以参考一下：<a href="https://www.cs.berkeley.edu/~russell/classes/cs194/f11/lectures/CS194%20Fall%202011%20Lecture%2006.pdf" target="_blank" rel="noopener">Lecture 6: logistic regression.pdf</a>。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li>Andrew Ng《机器学习》学习笔记</li><li><a href="https://en.wikipedia.org/wiki/Logistic_regression" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Logistic_regression</a></li><li><a href="https://github.com/JohnLangford/vowpal_wabbit/wiki/Loss-functions" target="_blank" rel="noopener">https://github.com/JohnLangford/vowpal_wabbit/wiki/Loss-functions</a></li><li><a href="https://www.cs.berkeley.edu/~russell/classes/cs194/f11/lectures/CS194%20Fall%202011%20Lecture%2006.pdf" target="_blank" rel="noopener">Lecture 6: logistic regression.pdf</a></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;出于学习的目的，笔者决定将逻辑回归总结一次。本文主要介绍逻辑回归的推导，囊括Sigmoid函数、极大似然估计、损失函数以、梯度下降以及正则化。文章内容纯属总结性知识，并不是对LR进行大篇长论。如有理解不到位的地方，还请读者指出。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="逻辑回归" scheme="https://www.csuldw.com/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    
      <category term="极大似然函数" scheme="https://www.csuldw.com/tags/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0/"/>
    
      <category term="梯度下降" scheme="https://www.csuldw.com/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"/>
    
      <category term="Sigmoid" scheme="https://www.csuldw.com/tags/Sigmoid/"/>
    
  </entry>
  
  <entry>
    <title>Dynamic Programming Example：Maximum Sum Submatrix in Matrix</title>
    <link href="https://www.csuldw.com/2016/09/14/2016-09-14-maximum-sum-of-a-sub-matrix-in-2d-matrix/"/>
    <id>https://www.csuldw.com/2016/09/14/2016-09-14-maximum-sum-of-a-sub-matrix-in-2d-matrix/</id>
    <published>2016-09-14T10:24:00.000Z</published>
    <updated>2016-09-14T12:58:06.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><blockquote><p>Find maximum sum submatrix in a given 2D matrix of integers.</p></blockquote><a id="more"></a><p><strong>输入</strong>：</p><ul><li>第1组<code>n m</code>：表示一个数组是$n$行$m$列的；</li><li>第2组：输入第一个$n$行$m$列的数组；</li></ul><p><strong>返回</strong>：</p><ul><li>最大子矩阵和</li></ul><p><strong>样例：</strong></p><p>给定一个$n * m$维的二维数据，如下</p><pre><code class="markdown">4    40    -2    -7    09    2    -6    2-4    1    -4    1-1    8    0    -2</code></pre><p>最后输出子矩阵和：</p><pre><code class="markdown">15</code></pre><h2 id="最大连续子序列和"><a href="#最大连续子序列和" class="headerlink" title="最大连续子序列和"></a>最大连续子序列和</h2><p>最大子矩阵与<a href="http://www.geeksforgeeks.org/largest-sum-contiguous-subarray/" target="_blank" rel="noopener">最大连续子序列和</a>有着千丝万缕的联系，最大连续子序列的DP动态转移方程为</p><p>$$dp[i] = max(dp[i-1] + arr[i], arr[i])$$</p><p>其中$dp[i]$表示从左到右到第$i$个元素时的最大子序列和， $arr$ 是子序列，这里可以使用一维数组表示。代码如下：</p><figure class="highlight fortran"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">int</span> maxSubArray(vector&lt;<span class="built_in">int</span>&gt; arr){</span><br><span class="line">    <span class="built_in">int</span> n = arr.<span class="built_in">size</span>();</span><br><span class="line">    vector&lt;<span class="built_in">int</span>&gt; dp(n);</span><br><span class="line">    <span class="built_in">int</span> <span class="built_in">maxVal</span> = INT_MIN;</span><br><span class="line">    for(<span class="built_in">int</span> i = <span class="number">0</span>; i &lt; n; ++i){</span><br><span class="line">        dp[i] = i == <span class="number">0</span> ? arr[i] : <span class="built_in">max</span>(arr[i], dp[i - <span class="number">1</span>] + arr[i]);</span><br><span class="line">        <span class="built_in">maxVal</span> = <span class="built_in">maxVal</span> &gt; dp[i] ? <span class="built_in">maxVal</span> : dp[i];</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">maxVal</span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>通过设置一个最大和变量<code>maxVal</code>，每次获取$dp[i]$时就将两者比较一下，并将大的赋值给<code>maxVal</code>即可。</p><h2 id="最大子矩阵和"><a href="#最大子矩阵和" class="headerlink" title="最大子矩阵和"></a>最大子矩阵和</h2><h3 id="Step1-构造行和矩阵"><a href="#Step1-构造行和矩阵" class="headerlink" title="Step1: 构造行和矩阵"></a>Step1: 构造行和矩阵</h3><p>首先开辟一个临时矩阵<code>sumMatrix</code>，第$i$行各列的元素表示的是原始矩阵$matrix$第$0$行到第$i$行各列的元素之和，使用公式表示就是：</p><p>$$sumMatrix[i][j] = \sum_{k = 0}^i matrix[k][j]$$</p><p>可以将原始矩阵转为行和矩阵：</p><p>$$<br>\begin{bmatrix}<br> a_{11} &amp;a_{12}  &amp;\cdots &amp; a_{1m} \\<br> a_{21} &amp;a_{22}  &amp;\cdots &amp; a_{2m} \\<br> \vdots  &amp;\vdots  &amp; \cdots  &amp; \vdots  \\<br> a_{n1} &amp;a_{n2}  &amp;\cdots &amp; a_{nm} \\<br>\end{bmatrix}<br>\Rightarrow<br>\begin{bmatrix}<br> a_{11} &amp;a_{12}  &amp;\cdots &amp; a_{1m} \\<br>  a_{11} + a_{21} &amp; a_{12} + a_{22}  &amp;\cdots &amp;  a_{1m} + a_{2m} \\<br> \vdots  &amp;\vdots  &amp; \cdots  &amp; \vdots  \\<br>  \sum_{i=1}^n a_{i1} &amp;\sum_{i=1}^n a_{i2}  &amp;\cdots &amp; \sum_{i=1}^n a_{im} \\<br>\end{bmatrix}<br>$$</p><h3 id="Step2：寻找状态转移矩阵"><a href="#Step2：寻找状态转移矩阵" class="headerlink" title="Step2：寻找状态转移矩阵"></a>Step2：寻找状态转移矩阵</h3><p>变量说明：</p><ul><li>matrix: 原始矩阵</li><li>sumMatrix: 行和矩阵</li></ul><h4 id="解释一"><a href="#解释一" class="headerlink" title="解释一"></a>解释一</h4><p>分析下，如果最终得到的是一维子数组，那么有两种情况，第一种是行子数组，第二种是列子数组，如果是行子数组，则相当于在原数组matrix上对每行执行一次<strong>最大连续子序列和</strong>方法并取最大的值即可，如果切换到行和矩阵上，则原始数据matrix的第$i$行等价于行和矩阵sumMatrix的第$i$行减去$i-1$行的值，即$sumMatrix[i][j] - sumMatrix[i - 1][j]$；同理，如果是列子数组，假设是第$i$行到第$j$行的列子数组，则等价到行和数组上，就是第$j$行每一列的值减去第$i$行每一列的值，然后求解此时最大的一列即可。那么，如果是多行多列的子数组呢？</p><p>对于这种情况，可以设置一个变量$k$，用以调整子矩阵的行数，当$k$等于0的时候，表示的是一维数组，也就是上面讨论的一维行子矩阵的情况；当$k$等于$1$的时候，则表示子矩阵的行数为$2$，那么通过什么来获取这个子矩阵呢？我们可以根据行和矩阵，以间隔为$1$进行相减获取子矩阵的列和并将其转为一维数组，即$sumMatrix[i][j] - sumMatrix[i - 1 - 1][j]$；同理，当$k$等于$2,3,\cdots$的时候，子矩阵的列和就为$sumMatrix[i][j] - sumMatrix[i - 1 - k ][j]$，然后求解此时的一维数组的最大子序列和，需要注意的是，当$i == k$时，由于是$k+1$行相加，因此首行就是$sumMatrix[i][j]$。 因此可以得到下列递推式式子：</p><figure class="highlight markdown"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">temp[<span class="string">j</span>] = k == 0 ? matrix[<span class="string">i</span>][<span class="symbol">j</span>] : i == k ? sumMatrix[<span class="string">i</span>][<span class="symbol">j</span>] : sumMatrix[<span class="string">i</span>][<span class="symbol">j</span>] - sumMatrix[<span class="string">i - k - 1</span>][<span class="symbol">j</span>]</span><br></pre></td></tr></tbody></table></figure><h3 id="解释二"><a href="#解释二" class="headerlink" title="解释二"></a>解释二</h3><p>同样设置一个变量$k$，并且此时的$k$同样代表子矩阵的行数，但规则不一样。当$k=0$时，我们根据行号$i$来确定子矩阵的行数，如果是第$i$行，则表示子矩阵的行数也是$i$取值为前$i$行,也就是行和矩阵$sumMatrix[i][j]$；当$k=1$时，则当行号为$i$时，我们取(k, i]行之间的元素，即$sumMatrix[i][j] - sumMatrix[i - k][j]$。因此可以得到下列状态转移方程：</p><figure class="highlight markdown"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">temp[<span class="string">j</span>] = k == 0 ? sumMatrix[<span class="string">i</span>][<span class="symbol">j</span>] : sumMatrix[<span class="string">i</span>][<span class="symbol">j</span>] - sumMatrix[<span class="string">i - k</span>][<span class="symbol">j</span>]</span><br></pre></td></tr></tbody></table></figure><h3 id="解释三"><a href="#解释三" class="headerlink" title="解释三"></a>解释三</h3><p>同样设置一个变量$k$，此$k$用以表示子矩阵的首行，由于子矩阵肯定是连续的行，因此，当$k=0$时，根据行号$i$依次得到子矩阵的行和$[0, i]$；当$k=1$时，表示子矩阵的首行为$1$，根据$i$依次得到$[k, i]$行的元素；由此可以得出状态转移矩阵为：</p><figure class="highlight markdown"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">temp[<span class="string">j</span>] = k == 0 ? sumMatrix[<span class="string">i</span>][<span class="symbol">j</span>] : sumMatrix[<span class="string">i</span>][<span class="symbol">j</span>] - sumMatrix[<span class="string">k-1</span>][<span class="symbol">j</span>];</span><br></pre></td></tr></tbody></table></figure><p>当得到这个递推式子之后，每次得到新的子矩阵列和，然后根据新的一维数组求解最大连续子序列。</p><p>上面给出了三种解释，因此可以根据之前的推导编写出下列代码，源代码如下：</p><figure class="highlight mel"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;<span class="keyword">vector</span>&gt;</span><br><span class="line">using <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">int</span> maxSubArray(<span class="keyword">vector</span>&lt;<span class="keyword">int</span>&gt; arr);</span><br><span class="line"><span class="keyword">int</span> maximumSubMatrix(<span class="keyword">vector</span>&lt;<span class="keyword">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; <span class="keyword">matrix</span>);</span><br><span class="line"><span class="keyword">int</span> main(){</span><br><span class="line">    <span class="keyword">int</span> n, m;</span><br><span class="line">    <span class="keyword">while</span>(cin&gt;&gt;n&gt;&gt;m){</span><br><span class="line">        <span class="keyword">vector</span>&lt;<span class="keyword">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; <span class="keyword">matrix</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++){</span><br><span class="line">            <span class="keyword">vector</span>&lt;<span class="keyword">int</span>&gt; temp;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; m; ++j){</span><br><span class="line">                <span class="keyword">int</span> value;</span><br><span class="line">                cin&gt;&gt;value;</span><br><span class="line">                temp.push_back(value);</span><br><span class="line">            }</span><br><span class="line">            <span class="keyword">matrix</span>.push_back(temp);</span><br><span class="line">        }</span><br><span class="line">        cout&lt;&lt;maximumSubMatrix(<span class="keyword">matrix</span>)&lt;&lt;endl;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> maxSubArray(<span class="keyword">vector</span>&lt;<span class="keyword">int</span>&gt; arr){</span><br><span class="line">    <span class="keyword">int</span> n = arr.<span class="keyword">size</span>();</span><br><span class="line">    <span class="keyword">vector</span>&lt;<span class="keyword">int</span>&gt; dp(n);</span><br><span class="line">    <span class="keyword">int</span> maxVal = INT_MIN;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; ++i){</span><br><span class="line">        dp[i] = i == <span class="number">0</span> ? arr[i] : <span class="keyword">max</span>(arr[i], dp[i - <span class="number">1</span>] + arr[i]);</span><br><span class="line">        maxVal = maxVal &gt; dp[i] ? maxVal : dp[i];</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> maxVal;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> maximumSubMatrix(<span class="keyword">vector</span>&lt;<span class="keyword">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; <span class="keyword">matrix</span>){</span><br><span class="line">    <span class="keyword">int</span> n = <span class="keyword">matrix</span>.<span class="keyword">size</span>();</span><br><span class="line">    <span class="keyword">int</span> m = <span class="keyword">matrix</span>[<span class="number">0</span>].<span class="keyword">size</span>();</span><br><span class="line">    <span class="keyword">vector</span>&lt;<span class="keyword">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; sumMatrix(n, <span class="keyword">vector</span>&lt;<span class="keyword">int</span>&gt;(m)), dp(n, <span class="keyword">vector</span>&lt;<span class="keyword">int</span>&gt;(m));</span><br><span class="line">    <span class="keyword">int</span> i, j, k;</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; n; ++i){</span><br><span class="line">        <span class="keyword">for</span>(j = <span class="number">0</span>; j &lt; m; ++j){</span><br><span class="line">           sumMatrix[i][j] =  i == <span class="number">0</span> ? <span class="keyword">matrix</span>[i][j] : sumMatrix[i<span class="number">-1</span>][j] + <span class="keyword">matrix</span>[i][j];</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">int</span> maxVal = INT_MIN;</span><br><span class="line">    <span class="keyword">vector</span>&lt;<span class="keyword">int</span>&gt; temp(m);</span><br><span class="line">    <span class="keyword">for</span>(k = <span class="number">0</span>; k &lt; n; ++k){</span><br><span class="line">        <span class="keyword">for</span>(i = k; i &lt; n; ++i){</span><br><span class="line">            <span class="keyword">for</span>(j = <span class="number">0</span>; j &lt; m; ++j){</span><br><span class="line">                <span class="comment">//temp[j] = k == 0 ? matrix[i][j] : i == k ? sumMatrix[i][j] : sumMatrix[i][j] - sumMatrix[i - k - 1][j];</span></span><br><span class="line">                temp[j] = k == <span class="number">0</span> ? sumMatrix[i][j] : sumMatrix[i][j] - sumMatrix[i - k][j];</span><br><span class="line">                <span class="comment">//temp[j] = k == 0 ? sumMatrix[i][j] : sumMatrix[i][j] - sumMatrix[k - 1][j];</span></span><br><span class="line">            }</span><br><span class="line">            <span class="keyword">int</span> arrVal = maxSubArray(temp);</span><br><span class="line">            maxVal = <span class="keyword">max</span>(maxVal, arrVal);</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> maxVal;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>关于DP，有个博客讲解的非常详实，感兴趣的可以看看，地址：<a href="http://www.csie.ntnu.edu.tw/~u91029/DynamicProgramming.html" target="_blank" rel="noopener">演算法笔记</a>。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://prismoskills.appspot.com/lessons/Dynamic_Programming/Chapter_07_-_Submatrix_with_largest_sum.jsp" target="_blank" rel="noopener">Chapter_07_-_Submatrix_with_largest_sum</a></li><li><a href="https://www.youtube.com/watch?v=yCQN096CwWM" target="_blank" rel="noopener">Maximum Sum Rectangular Submatrix in Matrix dynamic programming/2D kadane</a></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a&gt;问题描述&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;Find maximum sum submatrix in a given 2D matrix of integers.&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="算法与数据结构" scheme="https://www.csuldw.com/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
      <category term="动态规划" scheme="https://www.csuldw.com/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
      <category term="DP" scheme="https://www.csuldw.com/tags/DP/"/>
    
      <category term="最大子矩阵和" scheme="https://www.csuldw.com/tags/%E6%9C%80%E5%A4%A7%E5%AD%90%E7%9F%A9%E9%98%B5%E5%92%8C/"/>
    
      <category term="算法" scheme="https://www.csuldw.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Adaboost - 新的角度理解权值更新策略</title>
    <link href="https://www.csuldw.com/2016/08/28/2016-08-28-adaboost-algorithm-theory/"/>
    <id>https://www.csuldw.com/2016/08/28/2016-08-28-adaboost-algorithm-theory/</id>
    <published>2016-08-28T11:24:00.000Z</published>
    <updated>2016-09-02T11:52:30.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>关于Adaboost，在<a href="http://www.csuldw.com/2015/07/05/2015-07-05-ML-algorithm-Adaboost/">先前的一篇文章</a>里，也介绍过它的步骤与实现，但理论上的推导未曾涉及。虽然Adaboost算法思想通俗易懂，但权值更新公式的由来，想必并非人人皆知。本文着重于从理论层面进一步阐述Adaboost，最终推导出迭代时的样本权值更新公式。</p><a id="more"></a><p>关于本文使用的数学符号的具体解释，见下表：</p><table><thead><tr><th>变量</th><th>符号</th><th>描述</th></tr></thead><tbody><tr><td>训练数据</td><td>$(X, Y)$</td><td>第$i$个样本为$(x_i, y_i)$，其中$x_i =( x_{i1}, x_{i2}, \cdots, x_{id} )$，$y_i \in \lbrace +1, -1 \rbrace $</td></tr><tr><td>错误率</td><td>$e$</td><td>第$m$个弱分类器的错误率为$e_m$</td></tr><tr><td>分类器的系数</td><td>$\alpha$</td><td>第$m$个弱分类器的系数为$\alpha_m$</td></tr><tr><td>样本权重向量</td><td>$D$</td><td>迭代至第$m$次时的第$i$个样本的权值为$D_{m,i}$，初始阶段，所有样本的权重值均为$\frac{1}{N}$</td></tr><tr><td>归一化因子</td><td>$Z$</td><td>迭代至第$m$次的的归一化因子为$Z_m$</td></tr><tr><td>组合分类器</td><td>f(x)</td><td>迭代至第$m$次的组合分类器为$f_m(x)$</td></tr><tr><td>最终分类器</td><td>G(X)</td><td>最终分类器为$G(X) = sign(f_M(x))$</td></tr></tbody></table><p>下面来看看Adaboost的算法思想与其权值的推导。</p><h2 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h2><p>关于Adaboost，它是boosting算法，从bias-variance（偏差-方差）的角度来看，boosting算法主要关注的是降低偏差。仔细想想便可理解，因为boosting算法每个分类器都是弱分类器，而弱分类器的特性就是high-bias &amp; low variance（高偏差-低方差），其与生俱来的优点就是泛化性能好。因此，将多个算法组合起来之后，可以达到降偏差的效果，进而得到一个偏差小、方差小的泛化能力好的模型。另外，Adaboost的损失函数是指数损失$L(y, f(x)) = e^{-yf(x)}$。为了掌握Adaboost的整个流程，我将其思想通过下图简单的进行了一番总结（由于此图是我使用LaTex编辑的，所以如有表达不妥的地方，还请读者指出）：</p><p><img src="/assets/articleImg/adaboost-algorithm.png" alt=""></p><div class="caption">图一 Adaboost 算法</div><p>Adaboost算法可以归纳至三步，如下：</p><ul><li>第一步：初始化每个样本的权重值为$\frac{1}{N}$；</li><li>第二步：迭代$M$次，每次都根据错误率$e_m$不断修改训练数据的权值分布（此处需要确保弱学习器的错误率$e$小于$0.5$），样本权值更新规则为增加分类错误样本的权重，减少分类正确样本的权重；</li><li>第三步：根据每个弱学习器的系数$\alpha_m$，将$M$个弱学习器组合到一起，共同决定最终的学习结果，即$G(X) = \sum_{m=1}^M \alpha_m G_m(x)$.</li></ul><p>对于上面给出的算法，可能会存在一些疑问，诸如：</p><ol><li>弱学习器的错误率$e$为何要小于$0.5$?</li><li>弱学习器的系数$\alpha$这个等式如何得到的？</li><li>归一化因子$Z_m$又有何寓意？</li></ol><p>对于第一点，应该比较容易理解，因为如果弱学习器的效果都没有随机猜测好，那么学习得到的模型毫无疑问肯定是无用的。事实上，在上面三个问题中，最让人不解的应该是这个$\alpha$的取值。<strong>为什么它会是这种$\eqref{1}$形式呢？</strong>下面我们一起来推导一下。</p><h2 id="权值推导"><a href="#权值推导" class="headerlink" title="权值推导"></a>权值推导</h2><p>从图一我们可以看到，迭代至第$m$次时，分类器的系数计算公式为:</p><p>$$<br>\alpha_m = \frac{1}{2} ln \left ( \frac{1 - e_m}{e_m} \right )<br>\tag{1}\label{1}$$</p><p>然而，为何会是它呢？其推导方式有两种，第一种是最小化训练误差界进行推导；第二种是最小化损失函数进行推导。两者在本质上是一样的，都是为了求最小化某个式子时的$\alpha$值。在下面的篇章中，只涉及第一种。也就是为了确定$\alpha$的表达式，根据<strong>训练误差界</strong>来逐步推导。</p><h3 id="训练误差界"><a href="#训练误差界" class="headerlink" title="训练误差界"></a>训练误差界</h3><p>从图一可知，最终得到的函数表达式是$G(x)$，然而，当$G(x_i) \neq y_i$时，$y_i f_M(x_i) &lt; 0$，从而得到$e^{-y_i f_M(x_i)} \geq 1$，进而可以得到：</p><p>$$<br>\frac{1}{N} \sum_{i=1}^N I(G(x_i) \neq y_i)  \leq \frac{1}{N} \sum_i e^{ - y_i f_M(x_i)}<br>\tag{2}\label{2}$$ </p><p>从图一中还可以看到，更新训练样本的权值分布公式如下：</p><p>$$<br>D_{m+1, i} = \frac{D_{m,i}}{Z_m} \cdot exp \lbrace -\alpha_m y_i G_m(x_i) \rbrace<br>\tag{3}\label{3}$$</p><p>现在，对权值更新公式$\eqref{3}$变形，得到下列式子：</p><p>$$<br>Z_m D_{m+1, i} = D_{m,i} \cdot exp \lbrace -\alpha_m y_i G_m(x_i) \rbrace<br>\tag{4}\label{4}$$</p><p>对于上面这个式子，非常重要，是下面这个推导的核心。对于公式$\eqref{2}$不等于的右式，我们可以做如下推导：</p><p>$$<br>\begin{aligned}<br>\frac{1}{N}\sum_i e^{ - y_i f_M(x_i)}<br>&amp;= \frac{1}{N}\sum_i exp \left ( - \sum_{m=1}^M \alpha_m y_i G_m(x_i) \right )\\<br>&amp;\stackrel{\color{red}{D_{1,i} = \frac{1}{N}}}=  \sum_{i} D_{1,i} \prod_{m=1}^{M} exp \left ( -\alpha_m y_i G_m(x_i) \right ) \\<br>&amp;\stackrel{\color{red}{\eqref{4}}}=  \sum_i Z_1 D_{2,i} \prod_{m=2}^M exp \left ( -\alpha_m y_i G_m(x_i) \right ) \\<br>&amp;\stackrel{\color{red}{\eqref{4}}}= Z_1 \cdot \sum_i  Z_2 D_{3,i} \prod_{m=3}^M exp \left ( -\alpha_m y_i G_m(x_i) \right ) \\<br>&amp;\stackrel{\color{red}{\eqref{4}}}= Z_1 Z_2 \cdot \sum_i  Z_3 D_{4,i} \prod_{m=4}^M exp \left ( -\alpha_m y_i G_m(x_i) \right ) \\<br>&amp;= \prod_{m=1}^M Z_m<br>\end{aligned}<br>$$</p><p>因此可以得出，Adaboost的误差界为</p><p>$$<br>\frac{1}{N} \sum_{i=1}^N I(G(x_i) \neq y_i)  \leq \frac{1}{N} \sum_i e^{ - y_i f_M(x_i)} = \prod_{m=1}^M Z_m<br>\tag{5}\label{5}$$ </p><p>从公式$\eqref{6}$可以看出，在每一轮生成弱分类器$G_m(x)$时，应使归一化因子$Z_m$尽可能的小，而最小化时的$\alpha$就是我们要求的$\alpha$， 即求优化表达式$\underset{\alpha_m}{min} \ Z_m(\alpha_m)$。</p><h3 id="系数-alpha"><a href="#系数-alpha" class="headerlink" title="系数$\alpha$"></a>系数$\alpha$</h3><p>将问题转化为求最小值，这就比较简单了，只需要对$Z_m$求$\alpha_m$的导数，然后令导数为零，求出此时的$\alpha_m$就好了。OK，下面给出计算过程如下：</p><p>$$<br>\begin{aligned}<br>Z_m &amp; = \sum_{i=1}^{N} D_{m,i} \cdot exp \lbrace - \alpha y_i G_m(x_i) \rbrace \\<br>&amp; = \sum_{G_{m}(x_i) =  y_i} D_{m,i} \cdot e^{-\alpha_m} +  \sum_{G_{m}(x_i) \neq y_i} D_{m,i} \cdot e^{\alpha_m} \\<br>&amp; = (1-e_m) \cdot e^{- \alpha_m} + e_m \cdot e^{\alpha_m} \\<br>\end{aligned}<br>\tag{6} \label{6}$$</p><p>$$<br>\frac{\partial Z_m }{\partial \alpha_m} = -(1 - e_m) \cdot e^{-\alpha_m} + e_m \cdot e^{\alpha_m}<br>\tag{7} \label{7}$$</p><p>然后令导数式$\eqref{7}$等于$0$，简单的进行化简即可求得$\eqref{1}$式。</p><blockquote><p>说明：对于$\eqref{6}$式的变形，从第一步变换为第二步时，应用的规则是，当样本被正确分类，$y_iG_m(x_i) = 1$；当样本被错误分类，$y_iG_m(x_i) = -1$。而从第二步到第三步，则可以理解为正确分类的样本所占比例为$1-e_m$，错误分类的样本占比$e_m$。</p></blockquote><h3 id="样本权值"><a href="#样本权值" class="headerlink" title="样本权值"></a>样本权值</h3><p>通过上面的推导，得到$\alpha$之后，根据$\eqref{1}$式，又可以化简得到正确分类时的$e^{-\alpha_m}$ 和错误分类时的$e^{\alpha_m}$ ，公式如下：</p><p>$$<br>e^{-\alpha_{m}} = e^{ - \frac{1}{2} ln \left ( \frac{1 - e_m}{e_m}  \right )} = \sqrt {\frac{e_m}{1-e_m}} \<br>\tag{8} \label{8}$$</p><p>$$<br>e^{\alpha_{m}} = e^{ \frac{1}{2} ln \left ( \frac{1 - e_m}{e_m}  \right )} = \sqrt {\frac{1-e_m}{e_m}}<br>\tag{9} \label{9}$$</p><p>而对于归一化因子$Z_m$，又可以通过$\alpha$推导其与错误率$e$的关系，推导过程如下：</p><p>$$<br>\begin{aligned}<br>Z_m &amp; = \sum_{i=1}^{N} D_{m,i} \cdot exp \lbrace - \alpha y_i G_m(x_i) \rbrace \\<br>&amp; = \sum_{G_{m}(x_i) =  y_i} D_{m,i} \cdot e^{-\alpha_m} +  \sum_{G_{m}(x_i) \neq y_i} D_{m,i} \cdot e^{\alpha_m} \\<br>&amp; = (1-e_m) \cdot e^{- \alpha_m} + e_m \cdot e^{\alpha_m} \\<br>&amp; \stackrel{\color{red}{\eqref{8}\eqref{9}}}= (1-e_m) \cdot \sqrt{\frac{e_m}{1-e_m}} + e_m \cdot \sqrt{\frac{1-e_m}{e_m}} \\<br>&amp; = 2 \sqrt{e_m (1-e_m)}<br>\end{aligned}<br>\tag{10} \label{10}$$</p><p>因此，根据$\eqref{10}$式的推导结果，可以进一步得到，当样本被正确分类时，$y_iG_m(x_i) = 1$，权值公式可更新为：</p><p>$$<br>\frac{exp \lbrace -\alpha_m y_i G_m(x_i) \rbrace}{Z_m} = \frac{e^{-\alpha_m}}{Z_m}  \stackrel{\color{red}{\eqref{9}\eqref{10}}}= \sqrt{\frac{ \color{blue}{e_m}}{1-e_m}} \cdot \frac{ 1}{2\sqrt{ \color{blue}{e_m} (1-e_m)}} = \frac{1}{2(1-e_m)}<br>\tag{11} \label{11}$$</p><p>当样本被错误分类时，$y_iG_m(x_i) = -1$，权值公式可更新为：</p><p>$$<br>\frac{exp \lbrace -\alpha_m y_i G_m(x_i) \rbrace}{Z_m} = \frac{e^{\alpha_m}}{Z_m} \stackrel{\color{red}{\eqref{9}\eqref{10}}}= \sqrt{\frac{ \color{blue}{1-e_m}}{e_m}} \cdot \frac{ 1}{2\sqrt{e_m (\color{blue}{1-e_m})}} = \frac{1}{2e_m}<br>\tag{12} \label{12}$$</p><p>公式$\eqref{11}$与公式$\eqref{12}$就是最终的权值更新系数，只需将其带入到公式$\eqref{3}$即可求得新的样本权值。</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>本文主要侧重于权值的推导，而编写这篇博文的目的主要是为了弥补先前学习过程中的疏忽与不足，进而达到学习的目的。关于文章的实现，可去博主的github下载源码<a href="https://github.com/csuldw/MachineLearning/tree/master/Adaboost" target="_blank" rel="noopener">csuldw-Adaboost</a> （各位同学，记得给个star噢^_^），另外，也可参考先前的博文<a href="http://www.csuldw.com/2015/07/05/2015-07-05-ML-algorithm-Adaboost/">Machine Learning algorithm - Adaboost</a>。关于机器学习的其它文章，本博客将会持续更新。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li>Y Freund，R Schapire, A decision-theoretic generalization of on-line learning algorithms and an application to boosting, <em>Journal of Popular Culture</em>, 1997</li><li>统计学习方法》 by 李航</li><li><a href="https://en.wikipedia.org/wiki/AdaBoost" target="_blank" rel="noopener">Wikipedia-Adaboost </a></li><li>《机器学习 Machine Learning》 by 周志华</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于Adaboost，在&lt;a href=&quot;http://www.csuldw.com/2015/07/05/2015-07-05-ML-algorithm-Adaboost/&quot;&gt;先前的一篇文章&lt;/a&gt;里，也介绍过它的步骤与实现，但理论上的推导未曾涉及。虽然Adaboost算法思想通俗易懂，但权值更新公式的由来，想必并非人人皆知。本文着重于从理论层面进一步阐述Adaboost，最终推导出迭代时的样本权值更新公式。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="Adaboost" scheme="https://www.csuldw.com/tags/Adaboost/"/>
    
      <category term="权值" scheme="https://www.csuldw.com/tags/%E6%9D%83%E5%80%BC/"/>
    
      <category term="boosting" scheme="https://www.csuldw.com/tags/boosting/"/>
    
  </entry>
  
  <entry>
    <title>一段在京实习的日子</title>
    <link href="https://www.csuldw.com/2016/08/24/2016-08-24-internship-summary/"/>
    <id>https://www.csuldw.com/2016/08/24/2016-08-24-internship-summary/</id>
    <published>2016-08-24T02:24:00.000Z</published>
    <updated>2020-04-15T15:03:57.622Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>实习结束一个星期有余了，也来说道说道吧。此次去奇虎360实习，不仅认识了许多牛人，同时也算是见识到了工业界与学术界的不同，更是游览了北京的不少景点，可以说是不虚此行吧。整个实习历时115天，于我而言，这是人生的第一次，或许也会是最后一次。我不敢奢求什么，只希望通过这篇随性而写的不长不短的Summary，给此次实习画上一个圆满的句号，或许以后回头看到这篇文章的时候，还可以勉强回忆下实习中的点点滴滴。</p><a id="more"></a><p>坐在电脑桌前，回想起今年四月进京前的那会儿，其实当时内心是抗拒的。想着要孤身前往帝都，在一个陌生的城市里去生活，莫名的会产生一种后怕，或许是因为之前从未一人远走过他乡吧。现在回头一看，真的很庆幸自己当初做了这个decision。这次实习给自己感触颇多，或多或少的大致如下：</p><ol><li>去陌生的城市实习，解决住房是关键；</li><li>学术界可行的知识，工业界却并未用上，工业上用的算法，并不是高深莫测，往往简单实用才是最好；</li><li>自己以往的学习存在很多缺陷，表面上还OK，实则根基不牢，没有抓到本质；</li><li>工作之后，节奏感很快，时间似乎已经不属于自己了；</li><li>业务上的东西，永远是不断变化的，你不能去改变，就只能拥抱、适应；</li><li>南方人与北方人在饮食上的差别不是一般大；</li><li>帝都并没有想象的那么好，空气也并没有传说中的那么差；</li><li>面对问题，要保持一颗乐观的心态，要有一种敢于学习新知识的态度；</li><li>山外有山，人外有人。</li></ol><p>对于这些感触，想必去过实习的多多少少都会有点，根本谈不上是什么经验，更说不上是什么人生大道理，写在这里，就当是自己的感悟吧。“吃一堑，长一智”，以此为鉴就好。回想这段时间自己在推荐小组做的事情，大致包括了策略优化、统计分析、日志处理等，不仅接触了Spark、Scala，还接触了千万乃至上亿级别的数据处理。虽然杂杂碎碎的事情比较多，但收获倒也不少。作为推荐小组的一个算法实习生，能够在业务上与前端、后端、服务端、产品、数据统计等人员都打交道，了解整个业务的流程，实属难得。更庆幸的是，在离职时，直系上属给予了自己很好的评价并亲自为我践行，确实让我有些受宠若惊。本想写一些与工作相关的干货，但考虑到部门内部有些信息不便公开，在这还是不公开阐述了。好啦，既然是回忆篇，下面就来回忆下自己在帝都都经历了些什么事儿，索性从4月19日当天说起吧。</p><p>记得那是一个阴天，灰茫茫的天空夹带着细如鹅毛的白色杨絮，一个初来乍到的陌生人走在北京西站的高铁站，拖着象牙白色的箱子，外着一件蓝色衬衫，背着一个黑色的电脑包，短发，俨然一个找不到家的游子——是的，这就是我。下了高铁，在地铁口匆匆忙忙地打开手机，找到先前预定的旅社位置，然后按照某地图APP的提示一站一站地前往目的地。然而看到的旅社真的不堪入目，着实令人失望，如果在长沙，这个价应该可以住得上很好的酒店了。不过这也不奇怪，毕竟这是大城市，大帝都。也罢，耐心忍一忍也就过去了。</p><p>进京第一天，办了地铁卡、银行卡，并去公司附近走了走，嗯，感觉还不错，离旅社不是很远。第二天，前去报到，不料帝都早上的公交太堵了，就提前给HR姐姐发了个短信告知了详情，HR说没关系，到的时候直接去某某大厅就可以了，最后迟到了一刻钟，还算OK吧。接着听入职宣讲、签合同、领工卡、找工位、领器材、配置电脑等等，一上午很快就过去了。在这里，还是感谢下那位HR实习生不辞辛苦的接待和指导。下午就开始接触业务知识，节奏很快，确实有点措不及防。晚上在公司就餐，奈何饭点时间是七点半，让我们这种从学校刚出来的学生如何等的起，难堪！以前在学校，五点半没到就吃晚餐，现在却要推迟两小时，结果可想而知，开始那段日子饿的真心难以承受。工作之余，好心的同事告诉我，公司内网会有一些新的租房信息，让我关注下。也就是内网，让我认识了一位待离职同事和一位新的室友，也让我从一个又小又贵的旅社里住到了京旺家园1500元/月的80平二室一厅的二居室里，房间里应有尽有，并且距离公司5公里左右，下班回去之后，还可以坐在沙发上看看电视，真是享受了长达两个月的好生活。后来六月低搬到了公司附近2公里左右79元/天的将府家园，虽然是四居室，但各个室友都是“闭门自居”，平时也见不着人影儿，入住一月有余却也叫不上名字，更谈不上交流了。慢慢地，也便开始萌生了一种漂泊感，或许这才是大城市里大多数人的感受。有过这种感觉也算是一种经历，一种成长，下面来数落下自己去过的地方吧。</p><ul><li>四月：天安门、故宫、王府井、蓝色港湾、颐和园、798</li><li>五月：后海 ＆ 什刹海、北海、南锣鼓巷、奥林匹克森林公园、鸟巢 &amp; 水立方</li><li>六月：青龙峡、香山、北大、奥林匹克森林公园 （夜景） </li><li>七月：北京园博园Shark Run 乐跑、北海</li><li>八月：长城、奥林匹克森林公园（夜景） 、鸟巢（演唱会）</li></ul><p>待在北京的同学朋友并不多，目前大学时候的同学也就许*同学一人，见过一两次，关系还可以；研究生的同学相对而言倒还不多不少。去北京的第一个周末，是*波同学接待的，带我去了天安门、故宫，晚上还逛了王府井，感觉陌生的地方有个朋友真心不错。后来，*勇来实习之后，又多了在京朋友，跟他倒是聚过不少，也去过不少地方。事实上，很多地方都是自己独自闲游，久而久之也就变得习惯，然后就习以为常了。六月，公司团建去了青龙峡，跨越三天的假期，玩的倒也挺嗨。七月期间，与中南在京的同学聚过一次，第一次有种大家庭聚会的氛围，毕竟都是他乡之客的校友同学，相互之间也就没那么生分。每周周末除了出去游玩之外，晚上还会去电影院看看电影，虽然经常独行，但感觉倒也不错。想到去过的这些地方可能再也不会去第二次，说再见的人或许再也不见，莫名的就有些失落。得失尽在一念之间，Relax……</p><p>如果有人问我在奇虎上班是种什么样的体验？我会直言不讳的告诉他，公司坐落于朝阳798艺术地带，隐隐约约的带有一种艺术气息，下班后可以走进798艺术区，来一场艺术熏陶也是不错。另外，虽然平时下班比较晚，但那里没有硬性的周末加班制度，这对于工作的人而言，应该是很不错的福利了。也就是这些周末，让我有时间去北京各大景点转悠，见识了那些以往只能在银屏上看到的风景。除此之外，还有健身房、食堂、理发店、浴室、洗衣房、游戏机等不错的公共环境。在健身房里，自己玩过比较多的就属桌上足球与台球了，很nice。</p><p>最后，希望我所在的新闻部能够发展越来越好，也希望部门独立出去之后，“北京时间”能有更好的前景。虽然不知道是否还会再续前缘，但想到至少曾经拥有过，也是一大乐事。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;实习结束一个星期有余了，也来说道说道吧。此次去奇虎360实习，不仅认识了许多牛人，同时也算是见识到了工业界与学术界的不同，更是游览了北京的不少景点，可以说是不虚此行吧。整个实习历时115天，于我而言，这是人生的第一次，或许也会是最后一次。我不敢奢求什么，只希望通过这篇随性而写的不长不短的Summary，给此次实习画上一个圆满的句号，或许以后回头看到这篇文章的时候，还可以勉强回忆下实习中的点点滴滴。&lt;/p&gt;
    
    </summary>
    
      <category term="生活" scheme="https://www.csuldw.com/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="总结" scheme="https://www.csuldw.com/tags/%E6%80%BB%E7%BB%93/"/>
    
      <category term="实习" scheme="https://www.csuldw.com/tags/%E5%AE%9E%E4%B9%A0/"/>
    
      <category term="北京" scheme="https://www.csuldw.com/tags/%E5%8C%97%E4%BA%AC/"/>
    
      <category term="帝都" scheme="https://www.csuldw.com/tags/%E5%B8%9D%E9%83%BD/"/>
    
      <category term="新闻部" scheme="https://www.csuldw.com/tags/%E6%96%B0%E9%97%BB%E9%83%A8/"/>
    
  </entry>
  
  <entry>
    <title>Computational Learning Theory - VC Dimension</title>
    <link href="https://www.csuldw.com/2016/08/23/2016-08-23-vc-dimentions/"/>
    <id>https://www.csuldw.com/2016/08/23/2016-08-23-vc-dimentions/</id>
    <published>2016-08-23T01:24:00.000Z</published>
    <updated>2019-10-20T01:45:24.179Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在计算学习理论里面，有一个比较重要的概念，那就是VC维（Vapnic-Chervonenkis Dimension）。它解释了机器学习算法为什么可以去学习，数据又为什么可以被学习。在机器学习领域，VC维可以说是一个非常基础的定量化概念，可用来刻画分类系统的性能，也因此给诸多机器学习方法的可学习性提供了坚实的理论基础。网上有许多讲解VC维的博文，自己在学习VC维的时候也搜到很多，数量多的同时质量难免也良莠不齐。所以在这里，强烈推荐一下pluskid写的关于<a href="http://freemind.pluskid.org/slt/vc-theory-hoeffding-inequality/" target="_blank" rel="noopener">VC theory</a> 的系列文章，总结的确实非常深入。</p><a id="more"></a><p>由于pluskid的VC维系列比较深入，如果有一定的数学基础，那么学起来倒不难，但对初学者来说可能就比较困难。不过，不用担心，还有一份比较好的入门级学习教程，就是林轩田老师的《机器学习基石》，该课程前面几堂课讲的都是VC维，并且林老师讲解VC维时将理论与实例结合在一起，以讲故事的形式来阐述VC维，极力推荐一下，的确值得一听。有兴趣的同学可以去Google找找资料，这里推荐一个学者在听课过程中总结的笔记“<a href="http://beader.me/mlnotebook/" target="_blank" rel="noopener">《机器学习基石课程笔记》</a>“。然而，虽然目前已经有很多前辈都透彻地阐述了VC维，但要想将知识转为己有，就必须自己反复地去琢磨，去回顾归纳并去总结。本文对于VC维而言可以说是冰山一角，想要更全面地理解VC维，还请读者前去查阅与VC维有关的paper。此外，本文主要以总结为主，理论上的证明将不会过多的涉及，内容则主要围绕下面几点展开：</p><ol><li>Hoeffding Inequality</li><li>Probably Approximately Correct Learnable</li><li>Vapnic-Chervonenkis Dimension<ul><li>Growth function</li><li>Dichotomy</li><li>Shatter &amp;&amp; Break point</li><li>VC dimension</li></ul></li></ol><p>最近，在总结VC维的时候，脑海中总会浮现以下几个问题，确切的说，这也是VC维能够解决的事情（当然，不同的人会有不同的想法，或者携带的问题会更多）：</p><ol><li>为什么机器学习方法可以学习？</li><li>为什么会出现过拟合？</li><li>机器学习模型的复杂度如何衡量？</li></ol><p>下面根据上文提到的几点，来对各个要点逐个展开。</p><h2 id="Hoeffding-Inequality"><a href="#Hoeffding-Inequality" class="headerlink" title="Hoeffding Inequality"></a>Hoeffding Inequality</h2><p><a href="https://en.wikipedia.org/wiki/Hoeffding%27s_inequality" target="_blank" rel="noopener">Hoeffding不等式</a>是一个关于一组随机变量均值的概率不等式。</p><blockquote><p><strong>Hoeffding Inequality</strong>：设$X_1, X_2,\cdot, X_n$为一组独立同分布的随机变量，满足$X_i \epsilon [a, b], 0 \leq i \leq n $，$n$为随机变量的个数。记$n$个随机变量的经验期望 $\bar{X} = \frac{X_1 + X_2 + \cdots + X_n}{n}$，则对于任意的$0&lt;\delta&lt;1$, Hoeffding不等式可以表示为:</p></blockquote><p>$$ P(\bar{X} - E(\bar{X}) \geq \epsilon   ) \leq exp \left (\frac{-2 n \epsilon ^{2} }{(b-a)^{2}} \right ) \tag{1} \label{1}$$</p><p>在上述式子中，注意到$X_i$的取值范围是$[a, b]$，当分类误差为$0-1$损失时，$a$和$b$分别对应到$0$和$1$，此时，方程$\eqref{1}$简化为</p><p>$$ P(\bar{X} - E(\bar{X}) \geq \epsilon   ) \leq exp\left(-2 n \epsilon ^{2} \right ) \tag{2}$$</p><p>或</p><p>$$ P( \left | \bar{X} - E(\bar{X}) \right | \geq \epsilon   ) \leq 2  exp \left (-2 n \epsilon ^{2} \right ) \tag{3} \label{3}$$</p><p>如果单纯的从概率的角度来看，Hoeffding 不等式刻画的是某个随机事件的真实概率及其$n$个独立重复试验中观察到的频率之间的差异。换言之，它是$n$个不同伯努利（Bernoulli）试验的应用。那么现在的问题是：<strong>对于这样一个不等式，如何将其与机器学习联系在一起呢？</strong></p><p>首先，机器学习的目的是从合理数量的训练数据中，通过合理的计算量可靠的学习到知识。换句话说，就是从已有的数据中使用算法从假设空间$\mathcal{H}$中选择一个最好的$g$，虽然这个$g$很好，但它与样本真实的目标函数$f$存在一定的区别，从而导致训练时产生error。为了方便起见，我们将机器学习是在训练时会产生的训练误差叫做$E_{in}(g)$，当样本量为$n$时（从某个data set中有放回的抽取$n$次，最终未抽到的样本为out-of-sample），其表达式为：</p><p>$$ E_{in}(g) = \frac{1}{n} \sum_{i=1}^{n}  l(g, X_i, y_i) \tag{4}$$</p><p>类似地，我们把out-of-sample的产生的误差叫做$E_{out}(g)$，表达式为</p><p>$$E_{out}(g) = \mathbb{E}_{P_{xy}} \left [ l(g, X, Y) \right ] \tag{5}$$</p><p>因此，可以将Hoeffding 不等式应用到$E_{in}$和$E_{out}$，公式$\eqref{3}$可化为式$\eqref{6}$</p><p>$$ P( \left | E_{in} - E_{out} \right | \geq \epsilon   ) \leq 2  exp \left (-2 n \epsilon ^{2} \right ) \tag{6} \label{6}$$</p><p>公式$\eqref{6}$表达了算法学习到的$g$属于bad model的概率。换言之，当右边这个“upper bound”足够小时，我们可以说$g$在sample中的表现(错误率)与$g$在总体中的表现是差不多的。然而，对于假设空间$\mathcal{H}$中一个固定的$h$ 而言，$E_{in}(h)$会与$E_{out}(h)$很接近，这种情况能说是一种好的learning吗？答案当然是不能的，因为如果$E_{in}(h)$很大，则$E_{out}(h)$也大，这种学习得到的结果显然意义不大。</p><p>然而，不幸的是，在实际的采样过程中，我们可能会碰到bad sample（凡是由于抽样误差所造成样本分布与总体分布相差很大的样本，我们都可以称之为bad sample。）,从而造成训练时选择的$g$并非我们想要的。So，bad sample发生的概率有多大呢？当假设空间$\mathcal{H}$有$M$个可以学习的函数时，每个函数发生bad sample的概率为$\leq 2exp\left ( -2 \epsilon^2 n \right )$，如果每个$M$都出现了bad sample，则出现bad sample总概率为：</p><p>$$  \begin{aligned} \mathbb{P}_{\mathcal{D}}[BAD\ \mathcal{D}]<br>&amp; = \mathbb{P}_{\mathcal{D}}[BAD\ \mathcal{D}\ for\ h_1\ or\ BAD\ \mathcal{D}\ for\ h_2\ or\ …\ or\ BAD\ \mathcal{D}\ for\ h_M]\\<br>\ &amp; \leq \mathbb{P}_{\mathcal{D}}[BAD\ \mathcal{D}\ for\ h_1] + \mathbb{P}_{\mathcal{D}}[BAD\ \mathcal{D}\ for\ h_2]+…+\mathbb{P}_{\mathcal{D}}[BAD\ \mathcal{D}\ for\ h_M] \\<br>\ &amp; \leq 2exp(-2\epsilon ^2n) + \leq 2exp(-2\epsilon ^2n) + … + \leq 2exp(-2\epsilon ^2n) \\<br>\ &amp; = 2Mexp(-2\epsilon ^2n)<br>\end{aligned} \tag{7} \label{7}<br>$$</p><p>由公式$\eqref{7}$的推导可以看出，我们的算法learning得好不好，还与假设空间$\mathcal{H}$里决策函数的个数$M$有关。当$M$有限时，那么数据量$n$越大，发生bad sample的可能性越低。同理如果$M$太大，遇到bad sample的概率也会越大。</p><p>综上所述，从概率论的角度出发，根据Hoeffding不等式，可以证明当$E_{in}(h)$与$E_{out}(h)$很接近，同时$E_{in}(h)$与$E_{out}(h)$都比较小的时候，那么机器学习算法是可learning的。在learning的过程中，如果$E_{in}(h)$明显的小于$E_{out}(h)$，那么我们的模型便发生overfiting了；相反，如果$E_{in}(h)$本身就特别大，那么我们把这种情况称作underfitting。</p><h2 id="Probably-Approximately-Correct-Learnable"><a href="#Probably-Approximately-Correct-Learnable" class="headerlink" title="Probably Approximately Correct Learnable"></a>Probably Approximately Correct Learnable</h2><p>为了简便起见，这里以分类场景为例。</p><p>假定$f$表示样本的真实“概念”，是从样本空间$X$到类别空间$Y$的映射，它决定了样本$x$的真实标记$y$，如果对于任意的样例$(x, y)$，都有$f(x)=y$成立，则称$f$为目标概念。在训练过程中，由于我们并不确定算法是否能够找到真正的$f$，因此将算法学到的概念称作“假设（hypotheses）”，那么算法考虑的所有可能的“hypotheses”便构成了假设空间（hypotheses space，记作$\mathcal{H}$）。理想的情况下，我们希望最终学习得到的模型$g (g \in \mathcal{H})$可以与$f$等价$(g \equiv  f)$，以0误差完美的做出决策，但在现实中，这种情况很难发生，原因有三：</p><ul><li>有限的训练样本数决定了训练模型的上限；</li><li>从分布$D$采样得到的数据具有一定的偶然性，因此不同大小的训练集，得到的结果也可能有所不同；</li><li>训练数据中可能存在bad sample，导致训练时发生一定的误导性；</li></ul><p>因此，为了尽可能达到预设上限的模型，我们需要弱化我们对学习器的要求，不要求学习器能够输出零错误率的假设，只要求错误率以置信度为$\delta$被限制在某个可以接受的常数$\varepsilon$范围内，并且$\varepsilon$越小越好。简而言之，我们只要求学习器可以以较大的概率（至少是1-$\delta$）学习到一个“近似正确（Approximately Correct）”的假设，这就是“Probably Approximately Correct”的由来，简称“PAC”。形象的描述</p><blockquote><p><strong>PAC Identify</strong>：给定$0 &lt; \varepsilon,\delta &lt;１$，对于所有的$f \in \mathcal{F}$ 和数据分布$D$，若学习算法的输出空间$g \in \mathcal{H}$满足</p></blockquote><blockquote><p>$$P(E(g) \leq \varepsilon) \geq 1 - \delta$$</p></blockquote><blockquote><p>则称学习算法能从假设空间$\mathcal{H}$中以较大的概率$(\geq 1 - \delta)$学习到目标概念$f$的近似假设（误差最多为$\varepsilon$），简称PAC Identify。</p></blockquote><p>当有了上述条件，便可以得到PAC Learnable的定义：</p><blockquote><p><strong>PAC Learnable</strong>: 令$n$表示从分布$\mathcal{D}$中独立同分布采样得到的样本数，假设空间为$\mathcal{H}$，真实概念类为$\mathcal{F}$，且$0 &lt; \varepsilon,\delta &lt;１$，对于分布$\mathcal{D}$，若存在学习算法$\Psi $和多项式函数$poly(.,.,.,.)$，使得对于任意的$n \geq poly( \frac{1}{\varepsilon}, \frac{1}{\delta}, size(x), size(f))$，算法$\Psi$能够从假设空间$\mathcal{H}$中PAC Identify 真实概念类$\mathcal{F}$，则称概念类$\mathcal{F}$对假设空间$\mathcal{H}$而言是PAC可学习的。</p></blockquote><p>从PAC可学习的定义可以看出，训练样本的数量与学习所需的计算资源密切相关。我们称满足PAC学习算法$\Psi$所需的$n \geq poly( \frac{1}{\varepsilon}, \frac{1}{\delta}, size(x), size(f))$中最小的$n$为学习算法$\mathcal{\Psi}$的样本复杂度。假定学习器对每个训练样本需要某个最小的处理时间，那么如果要使目标函数$g$是PAC可学习的，学习器就必须在多项式数量的训练样本中进行学习。</p><h2 id="Vapnic-Chervonenkis-Dimension"><a href="#Vapnic-Chervonenkis-Dimension" class="headerlink" title="Vapnic-Chervonenkis Dimension"></a>Vapnic-Chervonenkis Dimension</h2><p>前面提到了假设空间$\mathcal{H}$，当假设空间比较多时，此时式$\eqref{6}$就变成了</p><p>$$\sum_{h \in \mathcal{H}} P(\left | E_{in}(h) - E_{out}(h) \right | \geq \epsilon) \leq 2 \color{red}{ \left | \mathcal{H} \right |} exp \left ( -2n \epsilon^2 \right ) \tag{8} \label{8}$$</p><p>其中$\left | \mathcal{H} \right |$是假设空间的大小。根据式$\eqref{8}$可以看出，当$\left | \mathcal{H} \right |$比较大时，经验误差$E_{in}(h)$和泛化误差$E_{out}(h)$逼近的概率也就越大，然而与此同时，我们想要从hypotheses space中选择出一条很好的假设就比较困难；相反，如果$\left | \mathcal{H} \right |$比较小，经验误差$E_{in}(h)$和泛化误差$E_{out}(h)$逼近的概率也就越小了。所以，为了找到一个折衷的衡量经验误差与泛化误差逼近程度的表达式，我们需要对$\left | \mathcal{H} \right |$进行转化。因此，VC维便诞生了。</p><p>在进入VC维之前，先引入下面几个概念：</p><ul><li>Dichotomy </li><li>Growth function </li><li>Shatter &amp;&amp; Break point</li></ul><h3 id="Dichotomy"><a href="#Dichotomy" class="headerlink" title="Dichotomy"></a>Dichotomy</h3><p>首先来看看dichotomy的定义：</p><blockquote><p><strong>Dichotomy</strong>： 给定hypotheses space$\mathcal{H}$和样本集$D = \lbrace x_1, x_2, \cdots, x_n \rbrace $， 假设从$\mathcal{H}$中任意选择一个方程$h$，并让$h$对$D$进行二元分类，最后输出一个结果向量，我们把这个输出向量称为一个Dichotomy。</p></blockquote><p>例如，在$2\mathbb{D}$平面空间，用一条直线对$2$个点进行binary classification，输出可能的结果为$ \lbrace 1,–1  \rbrace $，$ \lbrace –1,1 \rbrace$，$ \lbrace 1,1 \rbrace $，$ \lbrace–1,–1 \rbrace$，每个结果对都是一个dichotomy。对于二分类而言，Dichotomy最多有$2^n$种可能。</p><p>虽然hypotheses space 中$\left | \mathcal{H} \right |$可以很大，但有效的假设$h$（即dichotomy）是有限的，于是，我们可以用dichotomy的有效数量来取代有限hypotheses space 的Hoeffding不等式中的$\left | \mathcal{H} \right |$，即</p><p>$$\sum_{h \in \mathcal{H}} P(\left | E_{in}(h) - E_{out}(h) \right | \geq \epsilon) \leq 2 \cdot \color{red}{effective(n)} \cdot exp \left ( -2n \epsilon^2 \right ) \tag{9} \label{9}$$</p><h3 id="Growth-function"><a href="#Growth-function" class="headerlink" title="Growth function"></a>Growth function</h3><p>由于dichotomy最多有$2^n$种可能，因此当样本量$n$增加时，dichotomy的可能结果数也会增加。对于所有的$n \in \mathbb{N}$, 假设空间$\mathcal{H}$的growth function $\mathbb{G}_{\mathcal{H}} (n)$为</p><p>$$\mathbb{G}_{\mathcal{H}} (n) =\underset{\lbrace x_1, x_2, \cdots, x_n \rbrace \subseteq X  }{ max} \left | \lbrace (h(x_1), h(x_2), \cdots, h(x_n) | h \epsilon \mathcal{H} \rbrace \right  | \tag{10} \label{10}$$</p><p>对于式子$\eqref{10}$，$\mathbb{G}_{\mathcal{H}} (n) $的upper bound是$2^n$。更严格一点为下式</p><p>$$<br>\begin{aligned}<br>\mathbb{G}_{\mathcal{H}}(n)\leq \sum_{i=0}^{d_{vc}}\binom {n}{i}\leq n^{d_{vc}} ,<br>\textit{( for }n\geq 2, d_{vc}\geq 2\textit{ )}<br>\end{aligned}<br>\tag{11} \label{11}$$</p><p>当Growth function表示假设空间$\mathcal{H}$对$n$个示例所能赋予标记的最大可能的结果数。显然，结果数越多，$\mathcal{H}$的表达能力越强。由此可见，growth function描述的是假设空间$\mathcal{H}$的表达能力，尽管$\mathcal{H}$可能包含无穷多个假设，但其对$D$中示例赋予标记的可能结果数是有限的。</p><h3 id="Shatter-amp-amp-Break-point"><a href="#Shatter-amp-amp-Break-point" class="headerlink" title="Shatter &amp;&amp; Break point"></a>Shatter &amp;&amp; Break point</h3><p>有了Growth function和Dichotomy的概念之后，下面我们来定义Shatter：</p><blockquote><p>当假设空间$\mathcal{H}$作用于$n$个输入样本集时， 产生的dichotomy的数量等于这$n$个点总的组合数$2^n$，也就是Growth function的取值为$2^n$，即$\mathbb{G}_{\mathcal{H}} (n)  = 2^n$，此时我们就称这$n$个输入被hypotheses space $\mathcal{H}$“Shatter”。</p></blockquote><p>在一些资料中，“shatter”被翻译为“打散”。对于break point这个概念，使用下面这个例子来说明，会更加直观。</p><p>假定在某个枪击游戏中，你有一把散弹枪，每个关卡里面都只装有$6$颗子弹，而敌人的数量会随着关卡的不同而不同，具体数量为$2^i$，$i$为关卡号。现在，进入第一关时，敌人的数量为$2^1 = 2$个，很明显你可以shatter掉所有敌人并可以轻松过关；当进入第二关时，敌人数量为$2^2 = 4$，你也可以勉强过关；但是当你进入第三关时，敌人数量为$2^3 = 8$个，而你的子弹数只有$6$颗，此时你就无法通过散弹枪顺利过关了。我们把这个关卡$3$就叫做<strong>break point</strong>。</p><h3 id="VC-dimension"><a href="#VC-dimension" class="headerlink" title="VC dimension"></a>VC dimension</h3><p>了解了growth function、dichotomy、shatter、break point这些概念之后，这时，我们也可以使用growth function来估计$E_{in}$和$E_{out}$的关系，式$\eqref{9}$变为下式：</p><p>$$\sum_{h \in \mathcal{H}} P(\left | E_{in}(h) - E_{out}(h) \right | \geq \epsilon) \leq \color{red}{4 \cdot \mathbb{G}_{\mathcal{H}} (2n) } \cdot exp \left ( - \color{red}{\frac{1}{8}}n \epsilon^2 \right ) \tag{12} \label{12}$$</p><p>式$\eqref{11}$就是我们的<strong>VC bound</strong>。这个公式的意义在于：如果假设空间$\mathcal{H}$存在有限的break point $k$，那么$\mathbb{G}_{\mathcal{H}} (2n) $会被最高幂次为$k–1$的多项式上界给约束住。随着$n$的逐渐增大，指数式$exp(*)$的下降会比多项式$\mathbb{G}$的增长速度更快，所以此时可以推断出VC Bound是有界的。更进一步，当$n$足够大时，对于$\mathcal{H}$中的任意一个假设$h$，$E_{in}(h)$都将接近于$E_{out}(h)$，表示学习是可行的。</p><p>现在，我们现在可以定义VC维了，此概念由Vladimir Vapnik与Alexey Chervonenkis提出。</p><blockquote><p><strong>VC Dimension</strong>：给定假设空间$\mathcal{H}$，它的VC维是能被$\mathcal{H}$ shatter的最大实例集大小$n$，<br>$$VC(\mathcal{H}) = max \lbrace n: \mathcal{G}_{\mathcal{H}}(n) = 2^n \rbrace $$</p></blockquote><p>简而言之，若存在大小为$n$的示例集能被假设空间$\mathcal{H}$打散，但不存在任何大小为$n+1$的示例集能被$\mathcal{H}$打散，则假设空间$\mathcal{H}$的VC维是$n$。此时，break point为$n+1$。若对于任意数目的样本都有$2^n$个函数能将它们打散，则函数集的VC维是无穷大。</p><p>由于寻找所有hypothesis space的growth function是困难的，因此我们使用$n^{d_{vc}}$作为hypothesis space中所有$VC(\mathcal{H})=d_{vc}$的growth function的上界。So，对于hypothesis space $\mathcal{H}$的任意一个$g$来说，都有：</p><p>$$<br>\begin{aligned};;;,<br>\mathbb{P}[|E_{in}(g) - E_{out}(g) \ge \epsilon|]<br>&amp;\leq \mathbb{P}[BAD]  \\<br>&amp;= \mathbb{P}[\exists h \in \mathcal{H}\text{ s.t. } |E_{in}(h)-E_{out}(h)|\ge \epsilon] \\<br>&amp;\leq 4\mathbb{G}_{\mathcal{H}}(2n) exp \left ( - \frac{1}{8}  n\epsilon^2 \right ) \\<br>&amp;\leq 4(2n)^{d_{vc}}exp \left (- \frac{1}{8} n\epsilon^2 \right ) , (\textit{ if }d_{vc}\textit{ is finite })<br>\end{aligned}<br>\tag{13} \label{13}$$</p><p>因此，如果想要让机器学到东西，并且学习得到的结果比较好，就得满足三个条件：</p><ol><li>Good $\mathcal{H}$：假设空间$\mathcal{H}$的VC维$d_{vc}$是有限的;</li><li>Good $D$：适中的样本量$n$，这样才能确保vc bound的不会太大；</li><li>Good $\Psi$：一个好的算法，确保能够从假设空间$\mathcal{H}$中挑选出一个能使$E_{in}$最小的函数$g$。</li></ol><p>VC维反映了函数集的学习能力，VC维越大，学习机器越复杂。根据前面的推导，我们知道VC维的大小：与学习算法$\Psi$无关，与输入变量$X$的分布也无关，与我们求解的目标函数$g$无关，只与模型和假设空间$\mathcal{H}$有关。实践中有这样一个规律：假设空间 $\mathcal{H}$的VC 维与假设参数$w$的自由变量数目大约相等。即$VC(\mathcal{H}) = free \ parameters$。</p><p>最后，令之前得到的VC Bound为$\delta$，则坏事情发生的概率$P[|E_{in}(g)−E_{out}(g)|&gt;\epsilon] \le \delta$，好事情发生的概率$P[|E_{in}(g)−E_{out}(g)|≤\epsilon] \ge 1−\delta$，从而可以推导出$\epsilon$：</p><p>$$<br>\begin{aligned}<br>&amp;P[|E_{in}(g)-E_{out}(g)|\ge \epsilon] \le \delta \\<br>\Rightarrow<br>&amp;P[|E_{in}(g)-E_{out}(g)|\leq  \epsilon] \ge 1 - \delta \\<br>&amp;\text{set};;;;<br>\delta = 4(2n)^{d_{vc}}exp(-\frac{1}{8}n\epsilon^2)\\<br>\Rightarrow<br>&amp; \epsilon = \sqrt{\frac{8}{n}ln(\frac{4(2n)^{d_{vc}}}{\delta})}<br>\end{aligned}<br>\tag{14} \label{14}$$</p><p>根据$\eqref{14}$的结果，进而可以推导出$E_{in}$与$E_{out}$的关系：</p><p>$$<br>E_{in}(g)-\sqrt{\frac{8}{n}ln(\frac{4(2n)^{d_{vc}}}{\delta})} \leq E_{out}(g) \leq E_{in}(g)+ \color{red}{ \underset{\Omega }{\underbrace{\sqrt{\frac{8}{n}ln(\frac{4(2n)^{d_{vc}}}{\delta})}}}}<br>\tag{15} \label{15}$$</p><p>当然，我们比较关心的还是$E_{out}$的上界，式$\eqref{15}$红色部分为模型的复杂度$\Omega$，模型越复杂，$E_{in}$与$E_{out}$的逼近程度越远。随着VC维的上升，$E_{in}$会不断降低，而$\Omega$项会不断上升，其上升与下降的速度在每个阶段都有所不同，因此我们能够寻找一个二者兼顾的，比较合适的$d_{vc}$，用来决定应该使用多复杂的模型。反过来，如果我们需要使用$d_{vc}=3$这种复杂度的模型，并且想保证$\epsilon=0.1$，置信度$1−\delta=0.9$，我们也可以通过VC Bound来求得大致需要的数据量$n$。通过简单的计算可以得到，理论上我们需要$n \approx 10,000d_{vc}$大小的数据量，但VC Bound事实上是一个极为宽松的bound，因为它对于任何演算法$\Psi$，任何分布的数据$D$，以及任何目标函数$g$都成立，所以经验上，常常认为$n \approx 10d_{vc}$就可以有不错的结果。</p><p>另外，还可以从VC维的角度解释正则项的作用。在训练的时候，我们是从假设空间$\mathcal{H}$中寻找最佳的$g$时，然而为了避免overfiting，通常会加上正则项。当正则项加入之后，新的hypotheses space会加入一些新的bound，这时新假设空间的VC维也将变小。换言之，对于同样的训练数据，$E_{in}$更有可能等于$E_{out}$，从而泛化能力变得更强。</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>虽然本文大致的叙述了VC维，但因笔者自身水平有限，很多东西仅仅只是一隅之见，理解的并不到位，如果有措辞上的不妥，还请读者告之。此外，VC维可以说是机器学习中的一大核心，并非一篇文章就可以讲解透彻，本文相对于VC维而言，仅仅是冰山一角，如果想深入理解的，还请前去查阅相关paper。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li>Hoeffding, W. (1963). Probability Inequalities for Sums of Bounded Random Variables. Journal of the American Statistical Association, 58(301), 13–30.</li><li>Kearns, M. J., &amp; Vazirani, U. V. (1994). An introduction to computational learning theory. Cambridge, MA, USA: MIT Press.</li><li>周志华《Machine Learning 机器学习》第12章 计算学习理论.</li><li><a href="https://en.wikipedia.org/wiki/VC_dimension" target="_blank" rel="noopener">Wikipedia- Vapnik–Chervonenkis theory</a></li><li><a href="http://freemind.pluskid.org/slt/vc-theory-hoeffding-inequality/" target="_blank" rel="noopener">VC Theory: Hoeffding Inequality</a></li><li><a href="http://freemind.pluskid.org/slt/vc-theory-symmetrization" target="_blank" rel="noopener">VC Theory: Symmetrization</a></li><li><a href="http://freemind.pluskid.org/slt/vc-theory-vapnik-chervonenkis-dimension/" target="_blank" rel="noopener">VC Theory: Vapnik–Chervonenkis Dimension</a></li><li><a href="http://beader.me/mlnotebook/" target="_blank" rel="noopener">林轩田老师《机器学习基石》课程笔记</a></li><li><a href="http://www.flickering.cn/machine_learning/2015/04/vc%E7%BB%B4%E7%9A%84%E6%9D%A5%E9%BE%99%E5%8E%BB%E8%84%89/" target="_blank" rel="noopener">Flickering - VC维的来龙去脉</a></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在计算学习理论里面，有一个比较重要的概念，那就是VC维（Vapnic-Chervonenkis Dimension）。它解释了机器学习算法为什么可以去学习，数据又为什么可以被学习。在机器学习领域，VC维可以说是一个非常基础的定量化概念，可用来刻画分类系统的性能，也因此给诸多机器学习方法的可学习性提供了坚实的理论基础。网上有许多讲解VC维的博文，自己在学习VC维的时候也搜到很多，数量多的同时质量难免也良莠不齐。所以在这里，强烈推荐一下pluskid写的关于&lt;a href=&quot;http://freemind.pluskid.org/slt/vc-theory-hoeffding-inequality/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;VC theory&lt;/a&gt; 的系列文章，总结的确实非常深入。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="VC dimension" scheme="https://www.csuldw.com/tags/VC-dimension/"/>
    
      <category term="PAC" scheme="https://www.csuldw.com/tags/PAC/"/>
    
      <category term="Hoeffding Inequality" scheme="https://www.csuldw.com/tags/Hoeffding-Inequality/"/>
    
  </entry>
  
  <entry>
    <title>概率分布 Probability Distributions</title>
    <link href="https://www.csuldw.com/2016/08/19/2016-08-19-probability-distributions/"/>
    <id>https://www.csuldw.com/2016/08/19/2016-08-19-probability-distributions/</id>
    <published>2016-08-19T02:24:00.000Z</published>
    <updated>2016-08-21T02:48:58.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在机器学习领域，概率分布对于数据的认识有着非常重要的作用。不管是有效数据还是噪声数据，如果知道了数据的分布，那么在数据建模过程中会得到很大的启示。本文总结了几种常见的概率分布，比如离散型随机变量的分布代表伯努利分布以及连续型随机变量的分布代表高斯分布。对于每种分布，不仅给出它的概率密度函数，还会对其期望和方差等几个主要的统计量进行分析。目前文章的内容还比较简洁，后续再不断进行完善。</p><a id="more"></a><p>本文主要从三个方面进行阐述：</p><ol><li>一个函数：Gamma函数</li><li>六大分布：伯努利分布、二项分布、多项式分布、Beta分布、Dirichlet分布、高斯分布</li><li>一个理论：共轭先验</li></ol><h2 id="一个函数：Gamma函数"><a href="#一个函数：Gamma函数" class="headerlink" title="一个函数：Gamma函数"></a>一个函数：Gamma函数</h2><p>Gamma函数是阶乘在实数上的推广，其公式如下：</p><p>$$\Gamma(k) = \int_0^\infty x^{k-1} e^{-x} , dx, \quad k \in (0, \infty)$$</p><p>Gamma函数有着一个特别的性质，即：</p><p>$$\Gamma(n) = (n-1)!$$</p><h2 id="六大分布"><a href="#六大分布" class="headerlink" title="六大分布"></a>六大分布</h2><h3 id="伯努利分布"><a href="#伯努利分布" class="headerlink" title="伯努利分布"></a>伯努利分布</h3><p>伯努利分布（Bernoulli distribution）是关于布尔变量$x \epsilon  \lbrace 0,1  \rbrace $的概率分布，其连续参数$\mu \epsilon [0,1] $表示变量$x=1$的概率。其概率分布可以写成如下形式：</p><p>$$p(x | \mu) = B(x | \mu) = \mu ^{x} (1-\mu)^{1-x}$$</p><p>对于伯努利分布，它的期望和方差如下：</p><p>$$E(x) = \mu$$</p><p>$$var(x) = \mu(1-\mu)$$</p><h3 id="二项分布"><a href="#二项分布" class="headerlink" title="二项分布"></a>二项分布</h3><p>二项分布（binomial distribution）描述的是$n$次独立的伯努利分布中有$m$次成功（即$x=1$）的概率，其中每次伯努利实验成功的概率都是$\mu \epsilon [0,1] $.</p><p>$$p(m|n,\mu) = Bin(m | n,\mu) = C_{n} ^{m} \mu^{m}(1-\mu)^{n-m}$$</p><p>对于二项分布，它是伯努利分布的推广，而对于独立事件，加和的均值等于均值的加和，加和的方差等于方差的加和。因此其期望和方差如下：</p><p>$$E(x) = n\mu$$</p><p>$$var(x) = n\mu(1-\mu)$$</p><p>当$n=1$时，二项分布退化为伯努利分布.</p><h3 id="多项式分布"><a href="#多项式分布" class="headerlink" title="多项式分布"></a>多项式分布</h3><p>将伯努利分布的单变量扩展到$d$维向量$\vec{x}$，其中 $ x_i \epsilon  \lbrace 0,1 \rbrace $，且$\sum_{i=1}^{d} x_i =1$，假设$x_i =1$的概率为 $\mu \epsilon [0, 1] $, </p><p>并且$\sum_{i=1}^{d} \mu_i= 1$，则将得到离散分布</p><p>$$p(x| \mu) = \prod_{i=1}^{d} \mu_{i}^{x_{i}} $$</p><p>在此基础上扩展二项分布得到多项式分布（multinomial distribution），该分布描述的是在$n$次独立实验中有$m_i$次$x_i = 1$的概率,其密度函数可以表达为如下形式：</p><p>$$p(m_1, m_2, \cdots , m_d | n, \mu) =  \frac{n!}{m_1!m_2!…m_d !} \prod_{i=1}^{d} \mu_{i}^{m_{i}}$$</p><p>多项式分布的期望、方差、协方差如下：</p><p>$$E(x) = n\mu_i$$</p><p>$$var(x) = n\mu_i (1-\mu_i)$$</p><p>$$cov(m_i, m_j) = -n \mu_i \mu_j$$</p><h3 id="Beta分布"><a href="#Beta分布" class="headerlink" title="Beta分布"></a>Beta分布</h3><p><strong>Beta分布是二项分布的共轭先验分布</strong>，下面先介绍两个函数，Beta函数和Gamma函数（直接贴公式吧）：</p><p>$$B(a, b) = \frac{\Gamma(a) \Gamma(b)}{\Gamma(a + b)}; \quad a, , b \in (0, \infty)$$</p><p>$$\Gamma(k) = \int_0^\infty x^{k-1} e^{-x} , dx, \quad k \in (0, \infty)$$</p><p>贝塔分布（Beta distribution）是关于连续变量$\mu \epsilon [0, 1]$的概率分布，它由两个参数$a$和$b$共同确定，概率密度函数如下：</p><p>$$Beta(\mu | a,b) = \frac{1}{B(a, b)} \mu^{a-1} (1 - \mu)^{b-1}, \quad 0 &lt;  x &lt;  1$$</p><p>Beta分布的期望和方差如下：</p><p>$$E(\mu) = \frac{a}{a+b}$$</p><p>$$var(\mu) = \frac{ab}{(a+b)^2 (a+b+1)}$$</p><h3 id="狄利克雷分布"><a href="#狄利克雷分布" class="headerlink" title="狄利克雷分布"></a>狄利克雷分布</h3><p>狄利克雷分布（Dirichlet distribution）是Beta分布在高维度上的推广，它是关于一组$d$个连续变量$\mu_i \epsilon [0, 1]$ 的概率分布.</p><p>$$\sum_{i=1}^d \mu_i = 1$$</p><p>令$\mu = (\mu_i, \mu_2, …, \mu_d)$, 其中参数为:</p><p>$$\alpha = (\alpha_1, \alpha_2, \cdots, \alpha_d)$, $\alpha_i&gt;0, \tilde{\alpha} = \sum_{i=1}^d \alpha_i$$ </p><p>则狄利克雷分布的概率密度函数为：</p><p>$$p(\mu; \alpha) = D(\mu; \alpha) = \frac{\Gamma(\tilde{\alpha})}{\Gamma(\alpha_1)…\Gamma(\alpha_i)} \prod_{i=1}^{d} \mu_{i}^{\alpha_{i}-1} $$</p><p>Dirichlet 分布的期望和方差如下：</p><p>$$E(\mu_{i}) = \frac{\alpha_{i}}{\tilde{\alpha}}$$</p><p>$$var(\mu_{i}) = \frac{\alpha_{i}(\tilde{\alpha - \alpha_{i}})}{\tilde{\alpha}^{2}(\tilde{\alpha} + 1)}$$</p><p>$$cov(\mu_{i}, \mu_{j}) = \frac{\alpha_{i}\alpha_{j}}{\tilde{\alpha}^{2}(\tilde{\alpha} + 1)}$$</p><p>当$d=2$时，狄利克雷分布退化为Beta分布.</p><h3 id="高斯分布"><a href="#高斯分布" class="headerlink" title="高斯分布"></a>高斯分布</h3><p>高斯分布又称正态分布，在实际应用中最为广泛。对于单变量$x \epsilon (-\infty , +\infty )$,高斯分布的参数有两个，分别是均值$\mu \epsilon (-\infty , +\infty )$和方差$\sigma^2 &gt;0$，其概率密度函数为</p><p>$$N(x | \mu, \sigma^2) = \frac{1}{\sqrt{2\pi}\sigma} exp  \lbrace - \frac{(x-\mu)^2}{2\sigma^2}  \rbrace $$</p><p>期望方差如下：</p><p>$$E(x) = \mu $$</p><p>$$var(x) = \sigma^2$$</p><p>对于D维向量$x$,多元高斯分布的概率密度函数为：</p><p>$$N(x | \mu, \Sigma) = \frac{1}{\sqrt{(2\pi)^D } \left | \Sigma \right | ^{1/2}} exp \lbrace - \frac{1}{2} (x-\mu)^T \Sigma^{-1} (x-\mu)  \rbrace $$</p><p>其中， $µ$是$D$维均值向量， $Σ$是$D × D$的协方差矩阵， $|Σ|$是$Σ$的行列式。多元高斯分布的期望为$\mu$, 方差为$\Sigma$.</p><h2 id="共轭先验"><a href="#共轭先验" class="headerlink" title="共轭先验"></a>共轭先验</h2><p>先验分布反映了某种先验信息，后验分布既反映了先验分布提供的信息，又反映了样本提供的信息。<strong>若先验分布和抽样分布决定的后验分布与先验分布是同类型分布，则称先验分布为抽样分布的共轭分布</strong>。当先验分布与抽样分布共轭时，后验分布与先验分布属于同一种类型，这意味着先验信息和样本信息提供的信息具有一定的同一性。</p><ul><li>Beta的共轭分布是伯努利分布；</li><li>多项式分布的共轭分布是狄利克雷分布；</li><li>高斯分布的共轭分布是高斯分布。</li></ul><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="http://www.math.uah.edu/stat/special/index.html" target="_blank" rel="noopener">special distribution</a></li><li><a href="http://www.math.uah.edu/stat/special/Gamma.html#gam" target="_blank" rel="noopener">Gamma distribution</a></li><li><a href="http://www.math.uah.edu/stat/special/Beta.html" target="_blank" rel="noopener">Beta distribution</a></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在机器学习领域，概率分布对于数据的认识有着非常重要的作用。不管是有效数据还是噪声数据，如果知道了数据的分布，那么在数据建模过程中会得到很大的启示。本文总结了几种常见的概率分布，比如离散型随机变量的分布代表伯努利分布以及连续型随机变量的分布代表高斯分布。对于每种分布，不仅给出它的概率密度函数，还会对其期望和方差等几个主要的统计量进行分析。目前文章的内容还比较简洁，后续再不断进行完善。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="概率" scheme="https://www.csuldw.com/tags/%E6%A6%82%E7%8E%87/"/>
    
      <category term="分布" scheme="https://www.csuldw.com/tags/%E5%88%86%E5%B8%83/"/>
    
      <category term="共轭" scheme="https://www.csuldw.com/tags/%E5%85%B1%E8%BD%AD/"/>
    
  </entry>
  
  <entry>
    <title>Inverted Index（倒排索引）</title>
    <link href="https://www.csuldw.com/2016/07/30/2016-07-30-inverted-index-example/"/>
    <id>https://www.csuldw.com/2016/07/30/2016-07-30-inverted-index-example/</id>
    <published>2016-07-30T14:12:00.000Z</published>
    <updated>2016-07-30T14:10:24.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>传统的正排索引指的是doc-&gt;word的映射，然而在实际工作中，仅仅只有正排索引是远远不够的，比如我想知道某个word出现在那些doc当中，就需要遍历所有的doc，这在实时性要求比较严的系统中是不能接受的。因此，就出现了倒排索引（inverted index ），详细内容参见<a href="https://en.wikipedia.org/wiki/Inverted_index" target="_blank" rel="noopener">Wikipedia-Inverted index</a>。本文主要讲解的是如何使用Scala编写Spark程序来实现倒排索引。</p><a id="more"></a><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p><strong>目的：</strong>根据某个word来查找包含该word的document。</p><p>现在，假设有一个输入文件<a href="https://github.com/csuldw/MachineLearning/blob/master/spark-demo/invertedIndex/data/input.data" target="_blank" rel="noopener">input.data</a>，里面包含5篇document，该文件的具体内容如下：</p><pre><code>doc1    Apache Spark Scala Hadoop Java C Python Do And Will KNNdoc2    SVM Scala News Play Akka Yes GBDTdoc3    LDA SVM RF GBDT Adaboost Kmeans KNN doc4    QQ BAT I Great All LDAdoc5    Apache Hadoop MapReduce Git SVN SVM</code></pre><p>文件每行包含一篇doc的标示符（如doc1）以及该doc中包含的word，并且doc与word之间以”\t”分隔，而word与word之间以空格符分隔。</p><p>现在，我们需要建立的倒排索引如下（从结果数据中取出的top 10）：</p><pre><code class="markdown">(Akka,doc2)(Python,doc1)(QQ,doc4)(RF,doc3)(Apache,doc1|doc5)(Will,doc1)(Java,doc1)(MapReduce,doc5)(SVM,doc2|doc3|doc5)(Scala,doc1|doc2)(Git,doc5)</code></pre><p>上述结果为k-v结构的pair对，key值为word，value为文档表示符，并且doc与doc之间以”|”分隔，以示区分。下面使用Spark来建立倒排索引。</p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>根据上面的分析，大概知道了该实例的目的，下面使用Scala编写Spark程序实现倒排索引。</p><figure class="highlight typescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Created by liudiwei on 2016-07-30.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkContext</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkContext._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkContext</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.RDD</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.configuration.{ <span class="function"><span class="params">PropertiesConfiguration</span> =&gt;</span> HierConf }</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.broadcast.Broadcast</span><br><span class="line"></span><br><span class="line">object InvertedIndex{</span><br><span class="line">  def main(args : <span class="built_in">Array</span>[<span class="built_in">String</span>]){</span><br><span class="line">    val conf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">"invertedIndex"</span>)</span><br><span class="line">      .set(<span class="string">"spark.serializer"</span>, <span class="string">"org.apache.spark.serializer.JavaSerializer"</span>)</span><br><span class="line">      .set(<span class="string">"spark.akka.frameSize"</span>,<span class="string">"256"</span>)</span><br><span class="line">      .set(<span class="string">"spark.ui.port"</span>,<span class="string">"4071"</span>)</span><br><span class="line">    val sc = <span class="keyword">new</span> org.apache.spark.SparkContext(conf)</span><br><span class="line">    val cfg = <span class="keyword">new</span> HierConf(args(<span class="number">0</span>))</span><br><span class="line">    val inputfile = cfg.getString(<span class="string">"inputfile"</span>)</span><br><span class="line">    val result = sc.textFile(inputfile)</span><br><span class="line">      .map(<span class="function"><span class="params">x</span> =&gt;</span> x.split(<span class="string">"\t"</span>))</span><br><span class="line">      .map(<span class="function"><span class="params">x</span> =&gt;</span> (x(<span class="number">0</span>), x(<span class="number">1</span>)))</span><br><span class="line">      .map(<span class="function"><span class="params">x</span> =&gt;</span> x._2.split(<span class="string">" "</span>).map(<span class="function"><span class="params">y</span> =&gt;</span> (y, x._1)))</span><br><span class="line">      .flatMap(<span class="function"><span class="params">x</span> =&gt;</span> x)</span><br><span class="line">      .reduceByKey( <span class="function">(<span class="params">x, y</span>) =&gt;</span> x + <span class="string">"|"</span> + y)</span><br><span class="line">    result.collect.foreach(println)</span><br><span class="line">    sc.stop()</span><br><span class="line">  }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>从上面的代码可以看出，在spark中，只需几个map操作再加上一个reduceByKey聚合函数就可以建立倒排索引，非常简洁，相比其他语言有很大的优势。整个代码的核心只有21-26行这一系列操作，可以说是非常精简。</p><p>最后，完整的spark源码，请见Github：<a href="https://github.com/csuldw/MachineLearning/tree/master/spark-demo/invertedIndex" target="_blank" rel="noopener">https://github.com/csuldw/MachineLearning/tree/master/spark-demo/invertedIndex</a>。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://en.wikipedia.org/wiki/Inverted_index" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Inverted_index</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/inverted-index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/guide/current/inverted-index.html</a></li><li><a href="https://www.quora.com/Information-Retrieval-What-is-inverted-index" target="_blank" rel="noopener">https://www.quora.com/Information-Retrieval-What-is-inverted-index</a></li></ul><p style="height: 14px;line-height: 14px; border-left: solid 3px #e41c1e; padding-left: 10px; color: #666; font-size: 14px;">版权声明：本文为博主原创文章，转载请注明来源。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;传统的正排索引指的是doc-&amp;gt;word的映射，然而在实际工作中，仅仅只有正排索引是远远不够的，比如我想知道某个word出现在那些doc当中，就需要遍历所有的doc，这在实时性要求比较严的系统中是不能接受的。因此，就出现了倒排索引（inverted index ），详细内容参见&lt;a href=&quot;https://en.wikipedia.org/wiki/Inverted_index&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Wikipedia-Inverted index&lt;/a&gt;。本文主要讲解的是如何使用Scala编写Spark程序来实现倒排索引。&lt;/p&gt;
    
    </summary>
    
      <category term="Spark" scheme="https://www.csuldw.com/categories/Spark/"/>
    
    
      <category term="Spark" scheme="https://www.csuldw.com/tags/Spark/"/>
    
      <category term="Scala" scheme="https://www.csuldw.com/tags/Scala/"/>
    
      <category term="InvertedIndex" scheme="https://www.csuldw.com/tags/InvertedIndex/"/>
    
      <category term="倒排索引" scheme="https://www.csuldw.com/tags/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/"/>
    
  </entry>
  
  <entry>
    <title>Spark体系架构</title>
    <link href="https://www.csuldw.com/2016/07/23/2016-07-23-spark-architecture/"/>
    <id>https://www.csuldw.com/2016/07/23/2016-07-23-spark-architecture/</id>
    <published>2016-07-23T14:24:00.000Z</published>
    <updated>2016-07-27T15:44:52.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最近看到一篇关于Spark架构的博文，作者是 Alexey Grishchenko。看过Alexey博文的同学应该都知道，他对Spark理解地非常深入，读完他的<a href="https://0x0fff.com/spark-architecture/" target="_blank" rel="noopener"> “spark-architecture” </a>这篇博文，有种醍醐灌顶的感觉，从JVM内存分配到Spark集群的资源管理，步步深入，感触颇多。因此，在周末的业余时间里，将此文的核心内容译成中文，并在这里与大家分享。如在翻译过程中有文字上的表达纰漏，还请大家指出。</p><a id="more"></a><p>首先来看一张Spark 1.3.0 官方给出的图片，如下：</p><p><img src="/assets/articleImg/cluster-overview.png" alt=""></p><p>在这张图中，你会看到很多的术语 ，诸如“executor”, “task”, “cache”, “Worker Node” 等。原作者表示，在他开始学spark的时候，上述图是唯一一张可以找到的图片（Spark 1.3.0），形势很不乐观。更加不幸地是，这张图并没有很好地表达出Spark内在的一些概念。因此，通过不断地学习，作者将自己所学的知识整理成一个系列，而<a href="https://0x0fff.com/spark-architecture/" target="_blank" rel="noopener">此文</a>仅是其中的一篇。下面进入核心要点。</p><h2 id="Spark-内存分配"><a href="#Spark-内存分配" class="headerlink" title="Spark 内存分配"></a>Spark 内存分配</h2><p>在你的cluster或是local machine上正常运行的任何Spark程序都是一个JVM进程。对于任何的JVM进程，你都可以使用<code>-Xmx</code>和<code>-Xms</code>配置它的堆大小（heap size）。问题是：这些进程是如何使用它的堆内存（heap memory）以及为何需要它呢？下面围绕这个问题慢慢展开。</p><p>首先来看看下面这张Spark JVM堆内存分配图：</p><p><img src="/assets/articleImg/Spark-Heap-Usage.png" alt="Spark-Heap-Usage.png"></p><h3 id="Heap-Size"><a href="#Heap-Size" class="headerlink" title="Heap Size"></a>Heap Size</h3><p>默认情况下，Spark启动时会初始化512M的JVM 堆内存。处于安全角度以及避免OOM错误，Spark只允许使用90%的的堆内存，该参数可以通过Spark的<code>spark.storage.safetyFraction</code>参数进行控制。 OK，你可能听说Spark是基于内存的工具，它允许你将数据存在内存中。如果你读过作者的 <a href="https://0x0fff.com/spark-misconceptions/" target="_blank" rel="noopener">Spark Misconceptions</a> 这篇文章，那么你应该知道Spark其实不是真正的基于内存（in-memory）的工具。它仅仅是在LRU cache (<a href="http://en.wikipedia.org/wiki/Cache_algorithms" target="_blank" rel="noopener">http://en.wikipedia.org/wiki/Cache_algorithms</a>) 过程中使用内存。所以一部分的内存用在数据缓存上，这部分通常占安全堆内存（90%）的60%，该参数也可以通过配置<code>spark.storage.memoryFraction</code>进行控制。因此，如果你想知道在Spark中可以缓存多少数据，你可以通过对所有executor的堆大小求和，然后乘以<code>safetyFraction</code> 和<code>storage.memoryFraction</code>即可，默认情况下是0.9 * 0.6 = 0.54,即总的堆内存的54%可供Spark使用。</p><h3 id="Shuffle-Memory"><a href="#Shuffle-Memory" class="headerlink" title="Shuffle Memory"></a>Shuffle Memory</h3><p>接下来谈谈shuffle memory，计算公式是 <code>“Heap Size” * spark.shuffle.safetyFraction * spark.shuffle.memoryFraction</code>。<code>spark.shuffle.safetyFraction</code>的默认值是 0.8 或80%，  <code>spark.shuffle.memoryFraction</code>的默认值是0.2或20%，所以你最后可以用于shuffle的JVM heap 内存大小是 <code>0.8*0.2=0.16</code>，即总heap size的<code>16%</code>。 问题是Spark是如何来使用这部分内存呢？官方的Github上面有更详细的解释<a href="https://github.com/apache/spark/blob/branch-1.3/core/src/main/scala/org/apache/spark/shuffle/ShuffleMemoryManager.scala" target="_blank" rel="noopener">(https://github.com/apache/spark/blob/branch-1.3/core/src/main/scala/org/apache/spark/shuffle/ShuffleMemoryManager.scala)</a>。总得来说，Spark将这部分memory 用于Shuffle阶段调用其他的具体task。当shuffle执行之后，有时你需要对数据进行sort。在sort阶段，通常你还需要一个类似缓冲的buffer来存储已经排序好的数据（谨记，不能修改已经LRU cache中的数据，因为这些数据可能会再次使用）。因此，需要一定数量的RAM来存储已经sorted的数据块。如果你没有足够的memory用来排序，该怎么做呢？在<a href="http://en.wikipedia.org/wiki/External_sorting" target="_blank" rel="noopener">wikipedia</a> 搜一下“external sorting” （外排序），仔细研读一下即可。外排序允许你对块对数据块进行分类，然后将最后的结果合并到一起。</p><h3 id="unroll-Memory"><a href="#unroll-Memory" class="headerlink" title="unroll Memory"></a>unroll Memory</h3><p>关于RAM最后要讲到”unroll” memory，用于unroll 进程的内存总量计算公式为：<code>spark.storage.unrollFraction * spark.storage.memoryFraction *spark.storage.safetyFraction</code>。默认情况下是 <code>0.2 * 0.6 * 0.9 = 0.108</code>,<br>即<code>10.8%</code>的heap size。 当你需要在内存中将数据块展开的时候使用它。为什么需要 unroll 操作呢？在Spark中，允许以 序列化（serialized ）和反序列化（deserialized） 两种方式存储数据，而对于序列化后的数据是无法直接使用的，所以在使用时必须对其进行unroll操作，因此这部分RAM是用于unrolling操作的内存。unroll memory 与storage RAM 是共享的，也就是当你在对数据执行unroll操作时，如果需要内存，而这个时候内存却不够，那么可能会致使撤销存储在 Spark  LRU cache中少些数据块。</p><h2 id="Spark-集群模式JVM分配"><a href="#Spark-集群模式JVM分配" class="headerlink" title="Spark 集群模式JVM分配"></a>Spark 集群模式JVM分配</h2><p>OK，通过上面的讲解，我们应该对Spark进程有了进一步的理解，并且已经知道它是如何利用JVM进程中的内存。现在切换到集群上，以YARN模式为例。</p><p><img src="/assets/articleImg/Spark-Architecture-On-YARN-1024x826.png" alt="Spark-Architecture-On-YARN"></p><p>在YARN集群里，它有一个YARN ResourceMananger 守护进程控制着集群资源（也就是memory），还有一系列运行在集群各个节点的YARN Node Managers控制着节点资源的使用。从YARN的角度来看，每个节点可以看做是可分配的RAM池，当你向ResourceManager发送request请求资源时，它会返回一些NodeManager信息，这些NodeManager将会为你提供execution container，而每个execution container 都是一个你发送请求时指定的heap size的JVM进程。JVM的位置是由 YARN ResourceMananger 管理的，你没有控制权限。如果某个节点有64GB的RAM被YARN控制着（可通过设置<code>yarn-site.xml</code> 配置文件中参数         <code>yarn.nodemanager.resource.memory-mb</code> )，当你请求10个4G内存的executors时，这些executors可能运行在同一个节点上，即便你的集群跟大也无济于事。</p><p>当以YARN模式启动spark集群时，你可以指定executors的数量（<code>-num-executors</code> 或者 <code>spark.executor.instances</code> 参数)，可以指定每个executor 固有的内存大小（<code>-executor-memory</code> 或者 <code>spark.executor.memory</code>)，可以指定每个executor使用的cpu核数（<code>-executor-cores</code> 或者 <code>spark.executor.cores</code>)，可以指定分配给每个task的core的数量（<code>spark.task.cpus</code>)，还可以指定 driver 上使用的内存（<code>-driver-memory</code> 或者 <code>spark.driver.memory</code>)。</p><p>当你在集群上执行应用程序时，job程序会被切分成多个stages，每个stage又会被切分成多个task，每个task单独调度，可以把每个executor的JVM进程看做是task执行槽池，每个executor 会给你的task设置 <code>spark.executor.cores/ spark.task.cpus execution</code>个执行槽。例如，在集群的YARN NodeManager中运行有12个节点，每个节点有64G内存和32个CPU核（16个超线程物理core）。每个节点可以启动2个26G内存的executor（剩下的RAM用于系统程序、YARN NM 和DataNode），每个executor有12个cpu核可以用于执行task（剩下的用于系统程序、YARN NM 和DataNode），这样整个集群可以处理 <code>12 machines * 2 executors per machine * 12 cores per executor / 1 core = 288</code> 个task 执行槽，这意味着你的spark集群可以同时跑288个task，几乎充分利用了所有的资源。整个集群用于缓存数据的内存有<code>0.9 spark.storage.safetyFraction * 0.6 spark.storage.memoryFraction * 12 machines * 2 executors per machine * 26 GB per executor = 336.96 GB</code>. 实际上没有那么多，但在大多数情况下，已经足够了。</p><p>到这里，大概已经了解了spark是如何使用JVM的内存，并且知道什么是集群的执行槽。而关于task，它是Spark执行的工作单元，并且作为exector JVM 进程中的一个thread执行。这也是为什么Spark job启动时间快的原因，在JVM中启动一个线程比启动一个单独的JVM进程块，而在Hadoop中执行MapReduce应用会启动多个JVM进程。</p><h2 id="Spark-Partition"><a href="#Spark-Partition" class="headerlink" title="Spark Partition"></a>Spark Partition</h2><p>下面来谈谈Spark的另一个抽象概念”partition”。在Spark程序运行过程中，所有的数据都会被切分成多个Partion。问题是一个parition是什么并且如何决定partition的数量呢？首先Partition的大小完全依赖于你的数据源。在Spark中，大部分用于读取数据的method都可以指定生成的RDD中Partition数量。当你从hdfs上读取一个文件时，你会使用Hadoop的InputFormat来指定，默认情况下InputFormat返回每个InputSplit都会映射到RDD中的一个Partition上。对于HDFS上的大部分文件，每个数据块都会生成一个InputSplit，大小近似为64 MB/128 MB的数据。近似情况下，HDFS上数据的块边界是按字节来算的（64MB一个块），但是当数据被处理时，它会按记录进行切分。对于文本文件来说切分的字符就是换行符，对于sequence文件，它以块结束等等。比较特殊的是压缩文件，由于整个文件被压缩了，因此不能按行进行切分了，整个文件只有一个inputsplit，这样spark中也会只有一个parition，在处理的时候需要手动对它进行repatition。</p><p>本文是对 Alexey Grishchenko 的 Distributed Systems Architecture 系列的第一篇文章核心要点的翻译，原作者的第二篇文章是关于<code>shuffle</code>的，<a href="https://0x0fff.com/spark-architecture-shuffle/" target="_blank" rel="noopener">【原文链接】</a>，第三篇文章是关于<code>memory 管理模式</code>的，<a href="https://0x0fff.com/spark-memory-management/" target="_blank" rel="noopener">【原文链接】</a>，极力推荐。</p><h2 id="相关阅读"><a href="#相关阅读" class="headerlink" title="相关阅读"></a>相关阅读</h2><ol><li><a href="https://0x0fff.com/spark-misconceptions/" target="_blank" rel="noopener">https://0x0fff.com/spark-misconceptions/</a></li><li><a href="http://en.wikipedia.org/wiki/Cache_algorithms" target="_blank" rel="noopener">http://en.wikipedia.org/wiki/Cache_algorithms</a></li><li><a href="https://0x0fff.com/spark-architecture-shuffle/" target="_blank" rel="noopener">https://0x0fff.com/spark-architecture-shuffle/</a></li><li><a href="https://0x0fff.com/spark-memory-management/" target="_blank" rel="noopener">https://0x0fff.com/spark-memory-management/</a></li><li><a href="https://0x0fff.com/spark-architecture/" target="_blank" rel="noopener">https://0x0fff.com/spark-architecture/</a></li><li><a href="http://en.wikipedia.org/wiki/External_sorting" target="_blank" rel="noopener">http://en.wikipedia.org/wiki/External_sorting</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近看到一篇关于Spark架构的博文，作者是 Alexey Grishchenko。看过Alexey博文的同学应该都知道，他对Spark理解地非常深入，读完他的&lt;a href=&quot;https://0x0fff.com/spark-architecture/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt; “spark-architecture” &lt;/a&gt;这篇博文，有种醍醐灌顶的感觉，从JVM内存分配到Spark集群的资源管理，步步深入，感触颇多。因此，在周末的业余时间里，将此文的核心内容译成中文，并在这里与大家分享。如在翻译过程中有文字上的表达纰漏，还请大家指出。&lt;/p&gt;
    
    </summary>
    
      <category term="Spark" scheme="https://www.csuldw.com/categories/Spark/"/>
    
    
      <category term="Spark - 架构" scheme="https://www.csuldw.com/tags/Spark-%E6%9E%B6%E6%9E%84/"/>
    
      <category term="YARN" scheme="https://www.csuldw.com/tags/YARN/"/>
    
      <category term="JVM" scheme="https://www.csuldw.com/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>SparkSQL之更改表结构</title>
    <link href="https://www.csuldw.com/2016/07/22/2016-07-23-spark-sql-change-table-schema/"/>
    <id>https://www.csuldw.com/2016/07/22/2016-07-23-spark-sql-change-table-schema/</id>
    <published>2016-07-22T15:24:00.000Z</published>
    <updated>2016-07-30T14:09:54.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文篇幅较短，内容源于自己在使用SparkSQL时碰到的一个小问题，因为在之后的数据处理过程中多次使用，所以为了加深印象，在此单独成文，以便回顾。至于文章中使用的方法，或许不是最好的，如果你有更好的方法，还请分享一下。</p><a id="more"></a><h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><p>最近，在使用SparkSQL进行数据处理和数据分析时，碰到这样一种情况：需要自己去改变DataFrame中某个字段的类型。简而言之，就是要更改SparkSQL的表结构。因此，出于学习目的，在这里做了一个简单的Demo。下面来看看这个实例。</p><h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p>假设你现在也碰到了这个问题，那么前面的很多文件读取和数据转换操作，这里就不提及了，直奔主题吧。</p><pre><code>............此处省略相关jar包的引入</code></pre><p>首先使用sparkSQL的jsonFile加载HDFS上的一个文件（此步在此直接省略了），得到如下的表结构：</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">scala&gt;</span> <span class="string">dfs.printSchema</span></span><br><span class="line"><span class="string">root</span></span><br><span class="line"> <span class="string">|--</span> <span class="attr">name:</span> <span class="string">string</span> <span class="string">(nullable</span> <span class="string">=</span> <span class="literal">true</span><span class="string">)</span></span><br><span class="line"> <span class="string">|--</span> <span class="attr">desc:</span> <span class="string">string</span> <span class="string">(nullable</span> <span class="string">=</span> <span class="literal">true</span><span class="string">)</span></span><br><span class="line"> <span class="string">|--</span> <span class="attr">click:</span> <span class="string">double</span> <span class="string">(nullable</span> <span class="string">=</span> <span class="literal">true</span><span class="string">)</span></span><br><span class="line"> <span class="string">|--</span> <span class="attr">view:</span> <span class="string">double(nullable</span> <span class="string">=</span> <span class="literal">true</span><span class="string">)</span></span><br></pre></td></tr></tbody></table></figure><p><strong>目的</strong>：将<code>click</code>和<code>view</code>转成的类型转成<code>Long</code>。</p><p>操作如下:</p><p>首先需要定义一个函数，将表内的<code>Double</code>类型转为<code>Long</code>类型，函数如下：</p><figure class="highlight markdown"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val toLong = udf[<span class="string">Long, Double</span>](<span class="link">_.toLong</span>)</span><br></pre></td></tr></tbody></table></figure><p>然后使用<code>withColumn</code>变换字段类型，代码如下：</p><figure class="highlight pf"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val dfs2 = dfs.withColumn(<span class="string">"click"</span>, <span class="keyword">to</span>Long(dfs(<span class="string">"click"</span>))).withColumn(<span class="string">"view"</span>, <span class="keyword">to</span>Long(dfs(<span class="string">"view"</span>)))</span><br></pre></td></tr></tbody></table></figure><p>使用<code>printSchema</code>查看表结构：</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">scala&gt;</span> <span class="string">dfs2.printSchema</span></span><br><span class="line"><span class="string">root</span></span><br><span class="line"> <span class="string">|--</span> <span class="attr">name :</span> <span class="string">string</span> <span class="string">(nullable</span> <span class="string">=</span> <span class="literal">true</span><span class="string">)</span></span><br><span class="line"> <span class="string">|--</span> <span class="attr">desc :</span> <span class="string">string</span> <span class="string">(nullable</span> <span class="string">=</span> <span class="literal">true</span><span class="string">)</span></span><br><span class="line"> <span class="string">|--</span> <span class="attr">click:</span> <span class="string">long</span> <span class="string">(nullable</span> <span class="string">=</span> <span class="literal">true</span><span class="string">)</span></span><br><span class="line"> <span class="string">|--</span> <span class="attr">view:</span> <span class="string">long</span> <span class="string">(nullable</span> <span class="string">=</span> <span class="literal">true</span><span class="string">)</span></span><br></pre></td></tr></tbody></table></figure><p>OK，一个简单的表结构变换便完成了，又get了一个小技巧。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文篇幅较短，内容源于自己在使用SparkSQL时碰到的一个小问题，因为在之后的数据处理过程中多次使用，所以为了加深印象，在此单独成文，以便回顾。至于文章中使用的方法，或许不是最好的，如果你有更好的方法，还请分享一下。&lt;/p&gt;
    
    </summary>
    
      <category term="Spark" scheme="https://www.csuldw.com/categories/Spark/"/>
    
    
      <category term="Scala" scheme="https://www.csuldw.com/tags/Scala/"/>
    
      <category term="Spark - SparkSQL" scheme="https://www.csuldw.com/tags/Spark-SparkSQL/"/>
    
      <category term="Schema" scheme="https://www.csuldw.com/tags/Schema/"/>
    
      <category term="表结构" scheme="https://www.csuldw.com/tags/%E8%A1%A8%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>Escaping from Saddle Points（避开鞍点 ) </title>
    <link href="https://www.csuldw.com/2016/07/10/2016-07-10-saddlepoints/"/>
    <id>https://www.csuldw.com/2016/07/10/2016-07-10-saddlepoints/</id>
    <published>2016-07-10T15:48:00.000Z</published>
    <updated>2016-08-23T02:50:10.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>此文是一篇译文，是本人于今年四月应<a href="http://www.csdn.net/article/2016-04-07/2826616" target="_blank" rel="noopener">CSDN</a>编辑之邀翻译的一篇文章，原文发表于今年三月 <a href="http://www.offconvex.org/2016/03/22/saddlepoints/" target="_blank" rel="noopener">[Escaping from Saddle Points]</a>（共两篇），此文是第一篇文章的译文，第二篇文章尚未翻译，如有需要请点击原文 <a href="http://www.offconvex.org/2016/03/24/saddles-again/" target="_blank" rel="noopener">Saddles Again</a>。文章讲述了各式各样的 <strong>critical points</strong> 以及使用何种方法来来避开 <strong>saddle point</strong>（鞍点），个人觉得比较实用，属于纯理论知识，因此重新整理了一番，受益匪浅。详细内容请看正文。</p><a id="more"></a><p>凸函数比较简单——它们通常只有一个局部最小值。非凸函数则更加复杂。在这篇文章中，我们将讨论不同类型的<strong>临界点（critical points）</strong>，当你在寻找<strong>凸路径（convex path）</strong>的时候可能会遇到。特别是，<strong>基于梯度下降</strong>的简单启发式学习方法，在很多情形下会致使你在多项式时间内陷入<strong>局部最小值（local minimum）</strong>。</p><h2 id="不同类型的-Critical-Points"><a href="#不同类型的-Critical-Points" class="headerlink" title="不同类型的 Critical Points"></a>不同类型的 Critical Points</h2><p><img src="/assets/articleImg/minmaxsaddle.png" alt=""></p><p>为了最小化函数$f:\mathbb{R}^n\to \mathbb{R}$，最流行的方法就是往负梯度方向前进$\nabla f(x)$（为了简便起见，我们假定谈及的所有函数都是可微的），即：</p><p>$$y = x - \eta \nabla f(x),$$</p><p>其中η表示步长。这就是梯度下降算法（gradient descent algorithm）。</p><p>每当梯度$\nabla f(x)$不等于零的时候，只要我们选择一个足够小的步长η，算法就可以保证目标函数向局部最优解前进。当梯度$\nabla f(x)$等于$\vec{0}$时，该点称为<strong>临界点（critical point）</strong>，此时梯度下降算法就会陷入局部最优解。对于（强）凸函数，它只有一个临界点（critical point），也是<strong>全局最小值点（global minimum）</strong>。</p><p>然而，对于非凸函数，仅仅考虑梯度等于$\vec{0}$远远不够。来看一个简单的实例：</p><p>$$ y= x1^2 −x2^2 $$</p><p>当$x=(0,0)$时,梯度为 $\vec{0}$，很明显此点并不是局部最小值点，因为当$x = (0, \epsilon)$时函数值更小。在这种情况下，(0,0)点叫作该函数的鞍点（saddle point ）。</p><p>为了区分这种情况，我们需要考虑二阶导数$\nabla^2 f(x)$——一个$n×n$的矩阵（通常称作Hessian矩阵），第i,j项等于$\frac{\partial ^2}{\partial x_1 x_2} f(x)$ 。当Hessian矩阵正定时（即对任意的$u≠0$，有$u^⊤ ∇^2 f（x）u &gt; 0$恒成立），对于任何方向向量$u$，通过二阶泰勒展开式$f(x + \eta u) \approx f(x) + \frac{\eta^2}{2} u^\top\nabla^2 f(x) u &gt; f(x),$ ，可知$x$必定是一个局部最小值点。同样，当Hessian矩阵负定时，此点是一个局部最大值点；当Hessian矩阵同时具有正负特征值时，此点便是鞍点。</p><p>对于许多问题，包括<a href="http://arxiv.org/abs/1412.0233" target="_blank" rel="noopener">learning deep nets</a>，几乎所有的局部最优解都有与全局最优解（global optimum）非常相似的函数值，因此能够找到一个局部最小值就足够好了。然而，寻找一个局部最小值也属于NP-hard问题（参见<a href="http://arxiv.org/abs/1602.05908" target="_blank" rel="noopener">Anandkumar，GE 2006</a>中的讨论一节）。实践当中，许多流行的优化技术都是基于一阶导的优化算法：它们只观察梯度信息，并没有明确计算Hessian矩阵。这样的算法可能会陷入鞍点之中。</p><p>在文章的剩下部分，我们首先会介绍，收敛于鞍点的可能性是很大的，因为大多数自然目标函数都有指数级的鞍点。然后，我们会讨论如何对算法进行优化，让它能够尝试去避开鞍点。</p><p>在文章的剩下部分，我们首先会介绍，收敛于鞍点的可能性是很大的，因为大多数自然目标函数都有指数级的鞍点。然后，我们会讨论如何对算法进行优化，让它能够尝试去避开鞍点。</p><h2 id="对称与鞍点（Symmetry-and-Saddle-Points）"><a href="#对称与鞍点（Symmetry-and-Saddle-Points）" class="headerlink" title="对称与鞍点（Symmetry and Saddle Points）"></a>对称与鞍点（Symmetry and Saddle Points）</h2><p>许多学习问题都可以被抽象为寻找$k$个不同的分量（比如特征，中心…）。例如，在聚类问题中，有$n$个点，我们想要寻找$k$个簇，使得各个点到离它们最近的簇的距离之和最小。又如在一个两层的<a href="https://en.wikipedia.org/wiki/Artificial_neural_network" target="_blank" rel="noopener">神经网络</a>中，我们试图在中间层寻找一个含有$k$个不同神经元的网络。在我<a href="http://www.offconvex.org/2015/12/17/tensor-decompositions/" target="_blank" rel="noopener">先前的文章</a>中谈到过张量分解（tensor decomposition），其本质上也是寻找$k$个不同的秩为1的分量。</p><p>解决此类问题的一种流行方法是设计一个目标函数：设$x_1, x_2, \ldots, x_k \in \mathbb{R}^n$表示所求的中心（centers ），让目标函数$f(x_1,…,x_k)$来衡量函数解的可行性。当向量$x_1,x_2,…,x_k$是我们需要的$k$的分量时，此函数值会达到最小。</p><p>这种问题在本质上是非凸的自然原因是转置对称性（permutation symmetry）。例如，如果我们将第一个和第二个分量的顺序交换，目标函数相当于：$f(x_1,x_2,…,x_k) = f(x_2, x_1,…,x_k)$.</p><p>然而，如果我们取平均值，我们需要求解的是$\frac{x_1+x_2}{2}, \frac{x_1+x_2}{2}, x_3,…,x_k$，两者是不等价的！如果原来的解是最优解，这种均值情况很可能不是最优。因此，这种目标函数不是凸函数，因为对于凸函数而言，最优解的均值仍然是最优。</p><p><img src="/assets/articleImg/equivalent.png" alt=""></p><p>所有相似解的排列有指数级的全局最优解。鞍点自然会在连接这些孤立的局部最小值点上出现。下面的图展示了函数$y = x_1^4-2x_1^2 + x_2^2$：在两个对称的局部最小点$（−1,0）$和$（1,0）$之间，点$（0,0）$是一个鞍点。</p><p><img src="/assets/articleImg/symmetrysmall.png" alt=""></p><h2 id="避开鞍点（Escaping-from-Saddle-Points）"><a href="#避开鞍点（Escaping-from-Saddle-Points）" class="headerlink" title="避开鞍点（Escaping from Saddle Points）"></a>避开鞍点（Escaping from Saddle Points）</h2><p>为了优化这些存在许多鞍点的非凸函数，优化算法在鞍点处（或者附近）也需要向最优解前进。最简单的方法就是使用二阶泰勒展开式：</p><p>$$f(y) \approx f(x) + \left&lt;\nabla f(x), y-x\right&gt;+\frac{1}{2} (y-x)^\top \nabla^2 f(x) (y-x).$$</p><p>如果$\nabla f(x)$的梯度为$\vec{0}$,我们仍然希望能够找到一个向量$u$，使得$u^\top \nabla^2 f(x) u &lt; 0$。在这种方式下，如果我们令$y = x+\eta u$，函数值$f(y)$就会更小。许多优化算法，诸如 trust region algorithms 和 cubic regularization使用的就是这种思想，它们可以在多项式时间内避开鞍点。</p><h3 id="严格鞍函数（Strict-Saddle-Functions）"><a href="#严格鞍函数（Strict-Saddle-Functions）" class="headerlink" title="严格鞍函数（Strict Saddle Functions）"></a>严格鞍函数（Strict Saddle Functions）</h3><p>通常寻找局部最小值也属于NP-hard问题， 许多算法都可能陷入鞍点之中。那么避开一个鞍点需要多少步呢？这与鞍点的表现良好性密切相关。直观地说，如果存在一个方向$u$，使得二阶导$u^\top \nabla^2 f(x) u$明显比0小，则此鞍点x表现良好（well-behaved）——从几何上来讲，它表示存在一个陡坡方向会使函数值减小。为了量化它，在<a href="http://arxiv.org/abs/1503.02101" target="_blank" rel="noopener">我与Furong Huang, Chi Jin and Yang Yuan合作的一篇论文</a>中 介绍了严鞍函数的概念（在<a href="http://arxiv.org/abs/1510.06096" target="_blank" rel="noopener">Sun et al. 2015</a>一文中称作“ridable”函数）</p><blockquote><p>对于所有的$x$，如果同时满足下列条件之一，则函数$f(x)$是严格鞍函数：</p><ol><li>梯度$\nabla f(x)$很大。</li><li>Hessian矩阵$\nabla^2 f(x)$具有负的特征值。</li><li>点$x$位于局部极小值附近。</li></ol></blockquote><p>从本质上讲，每个点x的局部区域看起来会与下图之一类似：</p><p><img src="/assets/articleImg/strictsaddle.png" alt=""></p><p>对于这种函数，<a href="http://link.springer.com/article/10.1007%2Fs10107-015-0893-2" target="_blank" rel="noopener">trust region算法</a> 和 <a href="http://link.springer.com/article/10.1007%2Fs10107-006-0706-8" target="_blank" rel="noopener">cubic regularization</a> 都可以有效地找到一个局部最小值点。</p><blockquote><p><strong>定理（非正式）</strong>：至少存在一种多项式时间算法，它可以找到严格鞍函数的局部最小值点。</p></blockquote><p>什么函数是严格鞍？ <a href="http://arxiv.org/abs/1503.02101" target="_blank" rel="noopener">Ge et al. 2015</a> 表明<a href="http://www.offconvex.org/2015/12/17/tensor-decompositions/" target="_blank" rel="noopener">张量分解</a>（tensor decomposition）问题属于严格鞍。 <a href="http://arxiv.org/abs/1510.06096" target="_blank" rel="noopener">Sun et al. 2015</a>观察到诸如完整的<a href="https://en.wikipedia.org/wiki/Machine_learning#Sparse_dictionary_learning" target="_blank" rel="noopener">dictionary learning</a>，<a href="https://en.wikipedia.org/wiki/Phase_retrieval" target="_blank" rel="noopener">phase retrieval</a> 问题也是严格鞍。</p><p>定理（非正式）：至少存在一种多项式时间算法，它可以找到严格鞍函数的局部最小值点。</p><h3 id="一阶方法避开鞍点（First-Order-Method-to-Escape-from-Saddle-Points）"><a href="#一阶方法避开鞍点（First-Order-Method-to-Escape-from-Saddle-Points）" class="headerlink" title="一阶方法避开鞍点（First Order Method to Escape from Saddle Points）"></a>一阶方法避开鞍点（First Order Method to Escape from Saddle Points）</h3><p>Trust region算法非常强大。然而它们需要计算目标函数的二阶导数，这在实践中往往过于费时。如果算法只计算函数梯度，是否仍有可能避开鞍点？</p><p>这似乎很困难，因为在鞍点处梯度为$\vec{0}$,并且没有给我们提供任何信息。然而，关键在于鞍点本身是非常不稳定的（unstable）：如果我们把一个球放在鞍点处，然后轻微地抖动，球就可能会掉下去！当然，我们需要让这种直觉在更高维空间形式化，因为简单地寻找下跌方向，需要计算Hessian矩阵的最小特征向量。</p><p>为了形式化这种直觉，我们将尝试使用一个带有噪声的梯度下降法（noisy gradient descent）</p><p>$$y = x - \eta \nabla f(x) + \epsilon.$$</p><p>这里$\epsilon$是均值为$0$的噪声向量。这种额外的噪声会提供初步的推动，使得球会顺着斜坡滚落。</p><p>事实上，计算噪声梯度通常比计算真正的梯度更加省时——这也是<a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent" target="_blank" rel="noopener">随机梯度法</a>（stochastic gradient ）的核心思想，大量的工作表明，噪声并不会干扰凸优化的收敛。对于非凸优化，人们直观地认为，固有的噪声有助于收敛，因为它有助于当前点远离鞍点（ saddle points）。这并不是bug，而是一大特色！</p><p><img src="/assets/articleImg/escapesmall.png" alt=""></p><p>多项式高度依赖于维度N和Hessian矩阵的最小特征值，因此不是很实用。对于严格鞍问题，找到最佳收敛率仍是一个悬而未决的问题。</p><p>最近 <a href="http://arxiv.org/abs/1602.04915" target="_blank" rel="noopener">Lee et al.</a>的论文表明如果初始点是随机选择的，那么即使没有添加噪声，梯度下降也不会收敛到任何严格鞍点。然而他们的结果依赖于动态系统理论（dynamical systems theory）的<a href="https://en.wikipedia.org/wiki/Stable_manifold_theorem" target="_blank" rel="noopener">稳定流形定理(Stable Manifold Theorem)</a>，其本身并不提供任何步数的上界。</p><h2 id="复杂鞍点"><a href="#复杂鞍点" class="headerlink" title="复杂鞍点"></a>复杂鞍点</h2><p>通过上文的介绍，我们知道算法可以处理（简单）的鞍点。然而，非凸问题的外形更加复杂，含有退化鞍点（degenerate saddle points ）——Hessian矩阵是半正定的，有$0$特征值。这样的退化结构往往展示了一个更为复杂的鞍点（如<a href="https://en.wikipedia.org/wiki/Monkey_saddle" target="_blank" rel="noopener">monkey saddle（猴鞍</a>），图（a））或一系列连接的鞍点（图（b）（c））。在<a href="http://arxiv.org/abs/1602.05908" target="_blank" rel="noopener">Anandkumar, Ge 2016</a>我们给出了一种算法，可以处理这些退化的鞍点。</p><p><img src="/assets/articleImg/highorder.png" alt=""></p><p>非凸函数的轮廓更加复杂，而且还存在许多公认的问题。还有什么函数是严格鞍？当存在退化鞍点，或者有伪局部最小值点时，我们又该如何使优化算法工作呢？我们希望有更多的研究者对这类问题感兴趣！</p><hr><p>如有时间，可继续看看下一篇文章（英文）：<a href="http://www.offconvex.org/2016/03/24/saddles-again/" target="_blank" rel="noopener">Saddles Again</a>.</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;此文是一篇译文，是本人于今年四月应&lt;a href=&quot;http://www.csdn.net/article/2016-04-07/2826616&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;编辑之邀翻译的一篇文章，原文发表于今年三月 &lt;a href=&quot;http://www.offconvex.org/2016/03/22/saddlepoints/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[Escaping from Saddle Points]&lt;/a&gt;（共两篇），此文是第一篇文章的译文，第二篇文章尚未翻译，如有需要请点击原文 &lt;a href=&quot;http://www.offconvex.org/2016/03/24/saddles-again/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Saddles Again&lt;/a&gt;。文章讲述了各式各样的 &lt;strong&gt;critical points&lt;/strong&gt; 以及使用何种方法来来避开 &lt;strong&gt;saddle point&lt;/strong&gt;（鞍点），个人觉得比较实用，属于纯理论知识，因此重新整理了一番，受益匪浅。详细内容请看正文。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="鞍点" scheme="https://www.csuldw.com/tags/%E9%9E%8D%E7%82%B9/"/>
    
      <category term="最优化" scheme="https://www.csuldw.com/tags/%E6%9C%80%E4%BC%98%E5%8C%96/"/>
    
      <category term="泰勒" scheme="https://www.csuldw.com/tags/%E6%B3%B0%E5%8B%92/"/>
    
  </entry>
  
  <entry>
    <title>Spark批量读取Redis数据-Pipeline（Scala）</title>
    <link href="https://www.csuldw.com/2016/06/26/2016-06-26-spark-and-redis-pipeline-exp/"/>
    <id>https://www.csuldw.com/2016/06/26/2016-06-26-spark-and-redis-pipeline-exp/</id>
    <published>2016-06-26T07:15:00.000Z</published>
    <updated>2017-03-10T07:03:26.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最近在处理数据时，需要将原始数据与Redis的数据进行join，在读取Redis的过程中，碰到了一些问题，顺便做个笔记，希望对其他同学也有所帮助。实验过程中，当数据量还是十万级别的时候，逐个读取Redis并无压力；但当数据量达到千万级别时，问题就油然而生了，即使是使用Spark的mapPartitions也无法解决。因此，就考虑使用Redis的pipeline了（如果你有更好的方法，还请不吝赐教）。PS：本文主要针对的是Scala语言，因为目前在网上还没有看到Scala版本的Redis pipeline，希望此文能给初学者提供一个参考。</p><a id="more"></a><p>文章会先介绍如何使用Scala逐个去读取Redis数据，然后再介绍pipeline的使用。</p><h2 id="方法一、逐行读取Redis数据"><a href="#方法一、逐行读取Redis数据" class="headerlink" title="方法一、逐行读取Redis数据"></a>方法一、逐行读取Redis数据</h2><p>在本文，主要使用的是<code>redis.clients.jedis.Jedis</code>库，如果你是使用sbt来运行spark，可以在build.sbt中做如下配置：</p><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">name := <span class="string">"sparkRedisExp"</span></span><br><span class="line"></span><br><span class="line">version := <span class="string">"1.0.0"</span></span><br><span class="line"></span><br><span class="line">scalaVersion := <span class="string">"2.10.4"</span></span><br><span class="line"></span><br><span class="line">libraryDependencies += <span class="string">"org.apache.spark"</span> %% <span class="string">"spark-core"</span> % <span class="string">"1.3.1"</span></span><br><span class="line"></span><br><span class="line">libraryDependencies += <span class="string">"redis.clients"</span> % <span class="string">"jedis"</span> % <span class="string">"2.6.2"</span></span><br><span class="line"></span><br><span class="line">resolvers += <span class="string">"Akka Respository"</span> at <span class="string">"http://repo.akka.io/releases/"</span></span><br></pre></td></tr></tbody></table></figure><p>相应的jedis库可以到Github中下载 jedis-2.6.2.jar：<a href="https://github.com/csuldw/WorkUtils/tree/master/Spark/deps" target="_blank" rel="noopener">https://www.csuldw.com/csuldw/WorkUtils/tree/master/Spark/deps</a>。下面请看详细内容。</p><h3 id="导入Redis库"><a href="#导入Redis库" class="headerlink" title="导入Redis库"></a>导入Redis库</h3><p>首先导入redis库，这里使用redis.clients.jedis.Jedis库。</p><figure class="highlight css"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">import</span> <span class="selector-tag">redis</span><span class="selector-class">.clients</span><span class="selector-class">.jedis</span><span class="selector-class">.Jedis</span></span><br></pre></td></tr></tbody></table></figure><h3 id="连接Redis"><a href="#连接Redis" class="headerlink" title="连接Redis"></a>连接Redis</h3><p>然后连接Redis，主要设置<code>redisHost</code>、<code>redisPort</code>，如果有密码，需要进行密码验证。</p><figure class="highlight fsharp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> redisHost = <span class="string">"localhost"</span></span><br><span class="line"><span class="keyword">val</span> redisPort = <span class="number">8080</span></span><br><span class="line"><span class="keyword">val</span> redisClient = <span class="keyword">new</span> Jedis(redisHost, redisPort)</span><br><span class="line">redisClient.auth(redisPassword)</span><br></pre></td></tr></tbody></table></figure><h3 id="读取Redis数据"><a href="#读取Redis数据" class="headerlink" title="读取Redis数据"></a>读取Redis数据</h3><p>接下来，就可以直接使用get获取redis数据</p><figure class="highlight processing"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val keys = <span class="keyword">Array</span>(<span class="string">"key1"</span>, <span class="string">"key2"</span>, <span class="string">"key3"</span>, <span class="string">"key4"</span>)</span><br><span class="line"><span class="keyword">for</span>(<span class="built_in">key</span> &lt;- keys){</span><br><span class="line">  <span class="built_in">println</span>(redisClient.<span class="built_in">get</span>(<span class="built_in">key</span>))</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>上述方法并没有使用Redis的pipeline，当数据较少的时候，可以用来使用。下面介绍如何使用pipeline来批量读取Redis数据。</p><h2 id="方法二、使用Redis-pipeline批量读取Redis数据"><a href="#方法二、使用Redis-pipeline批量读取Redis数据" class="headerlink" title="方法二、使用Redis pipeline批量读取Redis数据"></a>方法二、使用Redis pipeline批量读取Redis数据</h2><p>相对于第一种方法，这里需要额外引入两个bao，<code>redis.clients.jedis.Pipeline</code>和<code>redis.clients.jedis.Response</code>。</p><h3 id="导入相关库"><a href="#导入相关库" class="headerlink" title="导入相关库"></a>导入相关库</h3><figure class="highlight css"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">import</span> <span class="selector-tag">redis</span><span class="selector-class">.clients</span><span class="selector-class">.jedis</span><span class="selector-class">.Jedis</span></span><br><span class="line"><span class="selector-tag">import</span> <span class="selector-tag">redis</span><span class="selector-class">.clients</span><span class="selector-class">.jedis</span><span class="selector-class">.Pipeline</span></span><br><span class="line"><span class="selector-tag">import</span> <span class="selector-tag">redis</span><span class="selector-class">.clients</span><span class="selector-class">.jedis</span><span class="selector-class">.Response</span></span><br></pre></td></tr></tbody></table></figure><h3 id="连接Redis-1"><a href="#连接Redis-1" class="headerlink" title="连接Redis"></a>连接Redis</h3><p>此操作与上面的一样，如下：</p><figure class="highlight fsharp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> redisHost = <span class="string">"localhost"</span></span><br><span class="line"><span class="keyword">val</span> redisPort = <span class="number">8080</span></span><br><span class="line"><span class="keyword">val</span> redisClient = <span class="keyword">new</span> Jedis(redisHost, redisPort)</span><br><span class="line">redisClient.auth(redisPassword)</span><br></pre></td></tr></tbody></table></figure><h3 id="使用pipeline读取数据之一（简化版）"><a href="#使用pipeline读取数据之一（简化版）" class="headerlink" title="使用pipeline读取数据之一（简化版）"></a>使用pipeline读取数据之一（简化版）</h3><p>先给出代码，下面再做解释。</p><figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> tempRedisRes = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Response</span>[<span class="type">String</span>]]()</span><br><span class="line"><span class="keyword">val</span> keys = <span class="type">Array</span>(<span class="string">"key1"</span>, <span class="string">"key2"</span>, <span class="string">"key3"</span>, <span class="string">"key4"</span>)</span><br><span class="line"><span class="keyword">val</span> pp = redisClient.pipelined()</span><br><span class="line"><span class="keyword">for</span>(key &lt;- keys){</span><br><span class="line">  tempRedisRes ++= <span class="type">Map</span>(key -&gt; pp.get(key)) </span><br><span class="line">}</span><br><span class="line">pp.sync()</span><br></pre></td></tr></tbody></table></figure><p>因为<code>redis.clients.jedis.Jedis</code>的<code>pipelined</code>下的<code>get</code>方法获取的是一个<code>Response[String]</code>类型的返回值，所以上面定义了一个临时变量<code>Map[String, Response[String]]</code>类型的<code>tempRedisRes</code>，key是String类型，value是Response[String]类型，用于保存<code>pp.get(key)</code>的返回值。当for循环执行完之后，使用sync同步即可。这样便实现了Redis的Pipeline功能。</p><h3 id="使用pipeline读取数据之二（强化版）"><a href="#使用pipeline读取数据之二（强化版）" class="headerlink" title="使用pipeline读取数据之二（强化版）"></a>使用pipeline读取数据之二（强化版）</h3><p>为了防止连接Redis时的意外失败，我们需要设置一个尝试次数，确保数据一定程度上的正确性。因此，在上面的代码外面增加一层连接逻辑，如下：</p><figure class="highlight dart"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> tempRedisRes = <span class="built_in">Map</span>[<span class="built_in">String</span>, Response[<span class="built_in">String</span>]]()</span><br><span class="line">val keys = Array(<span class="string">"key1"</span>, <span class="string">"key2"</span>, <span class="string">"key3"</span>, <span class="string">"key4"</span>)</span><br><span class="line"><span class="keyword">var</span> tryTimes = <span class="number">2</span></span><br><span class="line"><span class="keyword">var</span> flag = <span class="keyword">false</span></span><br><span class="line"><span class="keyword">while</span>(tryTimes &gt; <span class="number">0</span> &amp;&amp; !flag) {</span><br><span class="line">  <span class="keyword">try</span>{</span><br><span class="line">    val pp = redisClient.pipelined()</span><br><span class="line">    <span class="keyword">for</span>(key &lt;- keys){</span><br><span class="line">      tempRedisRes ++= <span class="built_in">Map</span>(key -&gt; pp.<span class="keyword">get</span>(key))</span><br><span class="line">    }</span><br><span class="line">    pp.<span class="keyword">sync</span>()</span><br><span class="line">    flag = <span class="keyword">true</span></span><br><span class="line">  }<span class="keyword">catch</span> {</span><br><span class="line">    <span class="keyword">case</span> e: Exception =&gt; {</span><br><span class="line">      flag = <span class="keyword">false</span></span><br><span class="line">      println(<span class="string">"Redis-Timeout"</span> + e)</span><br><span class="line">      tryTimes = tryTimes - <span class="number">1</span></span><br><span class="line">    }</span><br><span class="line">  }<span class="keyword">finally</span>{</span><br><span class="line">    redisClient.disconnect()</span><br><span class="line">  }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>再次说明：<code>pp.get()</code>得到的是一个<code>Response[String]</code>的结果，详细内容请查看<a href="http://tool.oschina.net/uploads/apidocs/jedis-2.1.0/redis/clients/jedis/Pipeline.html" target="_blank" rel="noopener">redis-clients-jedis-Pipeline</a>.</p><p>Ok，本文内容到此结束，感谢阅读.</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近在处理数据时，需要将原始数据与Redis的数据进行join，在读取Redis的过程中，碰到了一些问题，顺便做个笔记，希望对其他同学也有所帮助。实验过程中，当数据量还是十万级别的时候，逐个读取Redis并无压力；但当数据量达到千万级别时，问题就油然而生了，即使是使用Spark的mapPartitions也无法解决。因此，就考虑使用Redis的pipeline了（如果你有更好的方法，还请不吝赐教）。PS：本文主要针对的是Scala语言，因为目前在网上还没有看到Scala版本的Redis pipeline，希望此文能给初学者提供一个参考。&lt;/p&gt;
    
    </summary>
    
      <category term="Spark" scheme="https://www.csuldw.com/categories/Spark/"/>
    
    
      <category term="Spark" scheme="https://www.csuldw.com/tags/Spark/"/>
    
      <category term="Scala" scheme="https://www.csuldw.com/tags/Scala/"/>
    
      <category term="Redis" scheme="https://www.csuldw.com/tags/Redis/"/>
    
      <category term="pipeline" scheme="https://www.csuldw.com/tags/pipeline/"/>
    
  </entry>
  
  <entry>
    <title>Spark算子之combineByKey</title>
    <link href="https://www.csuldw.com/2016/06/09/2016-06-09-spark-combineByKey/"/>
    <id>https://www.csuldw.com/2016/06/09/2016-06-09-spark-combineByKey/</id>
    <published>2016-06-09T02:24:00.000Z</published>
    <updated>2016-07-30T14:09:18.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在做数据分析时，往往会碰到很多K-V结构，而处理K-V这种Pair型的数据结构是非常常见的事。譬如对Pair数据按照key进行分组、聚合，或是根据key对value进行fold运算等。本文讲解的就是spark的combineByKey算子。下面首先会对combineByKey的各个参数进行简单的介绍，然后通过一个实例来加深对它的理解。</p><a id="more"></a><h2 id="combineByKey介绍"><a href="#combineByKey介绍" class="headerlink" title="combineByKey介绍"></a>combineByKey介绍</h2><p>Spark的combineByKey属于Key-Value型算子，主要做的是聚集操作，像这种transformation不会触发作业的提交，在一点与groupByKey和reduceByKey类似。combineByKey函数主要有三个参数，分别是:</p><ul><li><code>combiner function</code> : 组合器函数，用于将<code>RDD[K,V]</code>中的V转换成一个新的值<code>C1</code>；</li><li><code>mergeValue function</code> ：合并值函数，将一个<code>C1</code>类型值和一个V类型值合并成一个<code>C2</code>类型，输入参数为<code>(C1,V)</code>，输出为新的<code>C2</code>;</li><li><code>mergeCombiners function</code> ：合并组合器函数，用于将两个C2类型值合并成一个<code>C3</code>类型，输入参数为<code>(C2,C2)</code>，输出为新的<code>C3</code>.</li></ul><p>下面通过一个实例来理解。</p><h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p>首先来看看代码，如下：</p><figure class="highlight typescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">outInfo.combineByKey(</span><br><span class="line">  (v) =&gt; (<span class="number">1</span>, v),</span><br><span class="line">  (acc: <span class="function">(<span class="params">Int, <span class="built_in">String</span></span>), <span class="params">v</span>) =&gt;</span> (acc._1 + <span class="number">1</span>, acc._2),</span><br><span class="line">  (acc1: <span class="function">(<span class="params">Int, <span class="built_in">String</span></span>), <span class="params">acc2</span>: (<span class="params">Int, <span class="built_in">String</span></span>)) =&gt;</span> (acc1._1 + acc2._1, acc2._2)</span><br><span class="line">).sortBy(_._2, <span class="literal">false</span>).map{</span><br><span class="line">  <span class="keyword">case</span> <span class="function">(<span class="params">key, (<span class="params">key1, value</span>)</span>) =&gt;</span> <span class="built_in">Array</span>(key, key1.toString, value).mkString(<span class="string">"\t"</span>)</span><br><span class="line">}.saveAsTextFile(<span class="string">"/out"</span>)</span><br></pre></td></tr></tbody></table></figure><p>在上述代码中，outInfo 其实是一个RDD，数据类型<code>(K: String, V: String)</code>，下面是测试数据的格式：</p><figure class="highlight clojure"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(<span class="string">"hello"</span>, <span class="string">"world"</span>)</span><br><span class="line">(<span class="string">"hello"</span>, <span class="string">"ketty"</span>)</span><br><span class="line">(<span class="string">"hello"</span>, <span class="string">"Tom"</span>)</span><br><span class="line">(<span class="string">"Sam"</span>, <span class="string">"love"</span>)</span><br><span class="line">(<span class="string">"Sam"</span>, <span class="string">"sorry"</span>)</span><br><span class="line">(<span class="string">"Tom"</span>, <span class="string">"big"</span>)</span><br><span class="line">(<span class="string">"Tom"</span>, <span class="string">"shy"</span>)</span><br></pre></td></tr></tbody></table></figure><p>现在，我的目的是按key值统计数据并对key去重，然后将每个key的最后一次出现的value作为value的第二个元素，即(key，count，value)，可以通过<strong>combimeByKey</strong>将上列数据转换成下列结果：</p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"hello"</span><span class="number">3</span><span class="string">"Tom"</span></span><br><span class="line"><span class="string">"Sam"</span><span class="number">2</span><span class="string">"soryy"</span></span><br><span class="line"><span class="string">"Tom"</span><span class="number">2</span><span class="string">"shy"</span></span><br></pre></td></tr></tbody></table></figure><p>每行数据以<code>\t</code>分隔。</p><p><strong>详细解释：</strong></p><ul><li>首先定义combiner function表达式<code>(v) =&gt; (1, v)</code>,可以将一个(“hello”, “world”)转换成 (“hello”, (1, “world”));</li><li>然后定义mergeValue function表达式 <code>(acc: (Int, String), v) =&gt; (acc._1 + 1, acc._2)</code>, 可以将((“hello”, (1, “world”))、(“hello”, “ketty”)转换成(“hello”, (2, “ketty”)); </li><li>接着定义mergeCombiners function表达式<code>(acc1: (Int, String), acc2: (Int, String)) =&gt; (acc1._1 + acc2._1, acc2._2)</code>可以将(“hello”, (2, “ketty”))、(“hello”, (1, “Tom”))转换成 (“hello”, (3, “Tom”)). </li><li>最后按<code>count</code>进行排序，并以 <code>"hello"    3    "Tom"</code> 格式化输出，中间以”\t”分隔。</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在做数据分析时，往往会碰到很多K-V结构，而处理K-V这种Pair型的数据结构是非常常见的事。譬如对Pair数据按照key进行分组、聚合，或是根据key对value进行fold运算等。本文讲解的就是spark的combineByKey算子。下面首先会对combineByKey的各个参数进行简单的介绍，然后通过一个实例来加深对它的理解。&lt;/p&gt;
    
    </summary>
    
      <category term="Spark" scheme="https://www.csuldw.com/categories/Spark/"/>
    
    
      <category term="Spark" scheme="https://www.csuldw.com/tags/Spark/"/>
    
      <category term="算子" scheme="https://www.csuldw.com/tags/%E7%AE%97%E5%AD%90/"/>
    
      <category term="combineByKey" scheme="https://www.csuldw.com/tags/combineByKey/"/>
    
      <category term="Scala" scheme="https://www.csuldw.com/tags/Scala/"/>
    
  </entry>
  
  <entry>
    <title>随机森林和mRMR特征选择</title>
    <link href="https://www.csuldw.com/2016/05/07/2016-05-07-feature-selection/"/>
    <id>https://www.csuldw.com/2016/05/07/2016-05-07-feature-selection/</id>
    <published>2016-05-07T07:04:00.000Z</published>
    <updated>2016-05-10T16:01:52.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>算法性能的好坏跟数据是密不可分的，因此找到一组更具代表性的特征子集显得更加重要。在实际项目中，因为有的特征对模型而言是冗余的，它对算法的性能会产生负面影响，此时就需要做特征选择。特征选择的目的就是从一组特征集合中去除冗余或不相关的特征从而达到降维的目的。说到降维，它不仅包括特征选择，还包括了特征提取，而本文主要介绍两种常用的特征选择方法。</p><a id="more"></a><p>对于一个包含n个特征的特征集合，搜索空间高达$2^n - 1$种可能的子集，所以如果是使用穷举法，不得不说下，穷举法的结果确实很好，特征少的时候或许可以考虑，但特征多的时候必将带来不可估量的计算量。所以我们需要找一种相对折衷的方法。也就是下面谈到的RF和mRMR。</p><h2 id="Random-Forest"><a href="#Random-Forest" class="headerlink" title="Random Forest"></a>Random Forest</h2><p><font color="#007ff"><strong>注意：随机森林使用的CART算法的方法增长树，也就是使用Gini指数来划分</strong></font>。Gini指数度量的是数据分区或训练集D的不纯度（注意，这里是不纯度，跟熵有点不同）。基尼不纯度表示的是一个随机选中的样本在子集中被分错的可能性。基尼不纯度为这个样本被选中的概率乘上它被分错的概率。当一个节点中所有样本都是一个类时，基尼不纯度为零。 定义为：</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24Gini%28D%29%20%3D%201%20-%20%5Csum_%7Bi%3D1%7D%5Em%20p_i%5E2%24%24" alt="$$Gini(D) = 1 - \sum_{i=1}^m p_i^2$$"></p><p>假设A有v个不同的值出现在特征D中，它的二元划分有$2^v - 2$种（除去自己和空集）。当考虑二元划分裂时，计算每个结果分区的不纯度加权和。比如A有两个值，则特征D被划分成D1和D2,这时Gini指数为：</p><p><img src="http://latex.codecogs.com/gif.latex?Gini_A%28D%29%20%3D%20%5Cfrac%7BD_1%7D%7BD%7D%20Gini%28D_1%29%20+%20%5Cfrac%7BD_2%7D%7BD%7D%20Gini%28D_2%29" alt="$$Gini_A(D) = \frac{D_1}{D} Gini(D_1) + \frac{D_2}{D} Gini(D_2)$$"></p><p>Gini指数偏向于多值属性，并且当类的数量很大时会有困难，而且它还倾向于导致相等大小的分区和纯度。但实践效果不错。</p><p>如果训练数据集有m维,样本个数为n,则 CART算法的时间复杂度为$ Ο (m n logn^2)$ 。</p><p>互信息是条件概率与后验概率的比值，化简之后就可以得到信息增益。所以说互信息其实就是信息增益。计算方法【互信息=熵-条件熵】。熵描述的是不确定性。熵越大，不确定性就越大，条件熵H（B|A）描述的是在A给定的条件下B的不确定性，如果条件熵越小，表示不确定性就越小，那么B就越容易确定结果。所以使用熵减去条件熵，就得到了信息增益，他描述的不确定性的降低程度，可以用来度量两个变量的相关性。比如，在给定一个变量的条件下，另一个变量它的不确定性能够降低多少，如果不确定性降低得越多，那么它的确定性就越大，就越容易区分，两者就越相关。</p><p>$$IG(D, A) = H(D) - H(D|A)$$</p><p>随机森林对于每一棵决策树，首先对列（特征）进行采样，然后计算当前的Gini指数，随后进行全分裂过程，每棵树的非叶节点都有一个Gini指数，一棵树建立之后可以得到该树各个节点的重要性，通过对其按照Gini指数作为特征相关性来排序，接着一次建立多棵决策树，并且生成多个特征相关性排名，最后对这些特征选平均值，得到最终排好序的特征重要性排名。</p><p>随机森林OOB特征选择：</p><ul><li>首先建立m棵决策树，然后分别计算每棵树的OOB袋外误差errOOBj。</li><li>计算特征$x_i $的重要性。随机的修改OOB中的每个特征$x_i $的值，再次计算它的袋外误差errOOBi；$x_i 的重要性=\sum\frac{errOOBi-errOOBj}{Ntree}$.</li><li>按照特征的重要性排序，然后剔除后面不重要的特征；</li><li>然后重复以上步骤，直到选出m个特征。</li></ul><p>在scikit-learn中封装了random forest特征选择方法：</p><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.datasets <span class="built_in">import</span> load_boston</span><br><span class="line">from sklearn.ensemble <span class="built_in">import</span> RandomForestRegressor</span><br><span class="line"><span class="built_in">import</span> numpy as np</span><br><span class="line"><span class="comment">#Load boston housing dataset as an example</span></span><br><span class="line"><span class="attr">boston</span> = load_boston()</span><br><span class="line"><span class="attr">X</span> = boston[<span class="string">"data"</span>]</span><br><span class="line"><span class="attr">Y</span> = boston[<span class="string">"target"</span>]</span><br><span class="line"><span class="attr">names</span> = boston[<span class="string">"feature_names"</span>]</span><br><span class="line"><span class="attr">rf</span> = RandomForestRegressor()</span><br><span class="line">rf.fit(X, Y)</span><br><span class="line">print <span class="string">"Features sorted by their score:"</span></span><br><span class="line">print sorted(zip(<span class="built_in">map</span>(lambda x: round(x, <span class="number">4</span>), rf.feature_importances_), names), </span><br><span class="line">             <span class="attr">reverse=True)</span></span><br></pre></td></tr></tbody></table></figure><p>最后输出的是：</p><blockquote><p>Features sorted by their score:<br>[(0.5298, ‘LSTAT’), (0.4116, ‘RM’), (0.0252, ‘DIS’), (0.0172, ‘CRIM’), (0.0065, ‘NOX’), (0.0035, ‘PTRATIO’), (0.0021, ‘TAX’), (0.0017, ‘AGE’), (0.0012, ‘B’), (0.0008, ‘INDUS’), (0.0004, ‘RAD’), (0.0001, ‘CHAS’), (0.0, ‘ZN’)]</p></blockquote><h2 id="mRMR"><a href="#mRMR" class="headerlink" title="mRMR"></a>mRMR</h2><p>最大相关最小冗余（mRMR），顾名思义，我们可以知道，它不仅考虑到了特征和label之间的相关性，还考虑到了特征和特征之间的相关性。度量标准使用的是互信息(Mutual information)。对于mRMR方法，<font color="#007FFF"><strong>特征子集与类别的相关性通过各个特征与类别的信息增益的均值来计算，而特征与特征的冗余使用的是特征和特征之间的互信息加和再除以子集中特征个数的平方</strong></font>，因为I(xi,xj)计算了两次。</p><p><strong>No.1 最大相关性</strong></p><p>目的：保证特征和类别的相关性最大。</p><p><img src="http://latex.codecogs.com/gif.latex?max%20%5C%20D%28S%2C%20c%29%2C%5C%20D%20%3D%20%5Cfrac%7B1%7D%7B%7CS%7C%7D%20%5Csum_%7Bx_i%20%5Cepsilon%20S%20%7D%20I%28x_i%3B%20c%29" alt="$$max \ D(S, c),\  D = \frac{1}{|S|} \sum_{x_i \epsilon S } I(x_i; c)$$"></p><p><strong>No.2 最小冗余性</strong></p><p>目的：确保特征之间的冗余性最小。</p><p><img src="http://latex.codecogs.com/gif.latex?min%5C%20R%28S%2C%20c%29%2C%5C%20%5C%20R%20%3D%20%5Cfrac%7B1%7D%7B%7CS%7C%5E2%7D%20%5Csum_%7Bx_i%2Cx_j%20%5Cepsilon%20S%20%7D%20I%28x_i%3B%20x_j%29" alt="min\ R(S, c),\ \ R = \frac{1}{|S|^2} \sum_{x_i,x_j \epsilon S } I(x_i; x_j)"></p><p>两个式子中，S表示已经选择的特征子集，c表示classs_label，x表示特征。最后选择标准是：</p><p>$$max \  \Phi(D,R) , \Phi = D - R$$</p><p>得到的子集在保证特征与类别的相关性较大的同时，还保证了特征的冗余性最小。</p><p>关于mRMR实现，可以到github上面去下载：<a href="https://github.com/csuldw/MachineLearning/tree/master/mRMR" target="_blank" rel="noopener">网址链接</a></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>使用RF和mRMR进行特征选择后，都会得到一个重要性排名。接下来通常需要结合交叉验证来选择结果性能最好的特征子集。比较原始的方法就是，根据排名对特征子集从<code>top1-topn</code>一个个进行交叉验证测试，然后选择结果最好的一组特征即可。</p><h2 id="文献"><a href="#文献" class="headerlink" title="文献"></a>文献</h2><ul><li>《数据挖掘概念与技术》，韩家炜；</li><li><a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwitzvCwpMzLAhUFUaYKHQi8A5IQFggmMAE&amp;url=http%3A%2F%2Fpenglab.janelia.org%2Fproj%2FmRMR%2FBIBM07_mRMR_071103_handout.pdf&amp;usg=AFQjCNFh9Rqy1qlJjqUABlFuaY4yvBsPTA&amp;sig2=YxQvuBTk64GkAaZ560gznQ" target="_blank" rel="noopener">Minimum Redundancy and Maximum Relevance Feature selection</a></li><li><a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=5&amp;cad=rja&amp;uact=8&amp;sqi=2&amp;ved=0ahUKEwiWho6tpczLAhWEppQKHdr0BdEQFgg7MAQ&amp;url=https%3A%2F%2Fhal.archives-ouvertes.fr%2Fhal-00755489%2Ffile%2FPRLv4.pdf&amp;usg=AFQjCNGq5RLaeyLLQXzBbsKvL_UUn-mflw&amp;sig2=XuJTB29C5kU1f0WAtJwwfg" target="_blank" rel="noopener">Variable selection using Random Forests </a></li><li><a href="http://blog.datadive.net/selecting-good-features-part-iii-random-forests/" target="_blank" rel="noopener">Selecting good features – Part III: random forests</a></li><li><a href="http://penglab.janelia.org/proj/mRMR/" target="_blank" rel="noopener">mRMR (minimum Redundancy Maximum Relevance Feature Selection)</a></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;算法性能的好坏跟数据是密不可分的，因此找到一组更具代表性的特征子集显得更加重要。在实际项目中，因为有的特征对模型而言是冗余的，它对算法的性能会产生负面影响，此时就需要做特征选择。特征选择的目的就是从一组特征集合中去除冗余或不相关的特征从而达到降维的目的。说到降维，它不仅包括特征选择，还包括了特征提取，而本文主要介绍两种常用的特征选择方法。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="mRMR" scheme="https://www.csuldw.com/tags/mRMR/"/>
    
      <category term="特征选择" scheme="https://www.csuldw.com/tags/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"/>
    
      <category term="Random Forest" scheme="https://www.csuldw.com/tags/Random-Forest/"/>
    
  </entry>
  
  <entry>
    <title>Linux环境下非root用户安装Python及相关库</title>
    <link href="https://www.csuldw.com/2016/05/06/2016-05-06-python-and-pip/"/>
    <id>https://www.csuldw.com/2016/05/06/2016-05-06-python-and-pip/</id>
    <published>2016-05-06T08:24:14.000Z</published>
    <updated>2016-05-17T14:15:14.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>以前在使用python的时候，都是使用root用户安装好的全局python，现在，因为root用户安装的Python版本太低，同时自己没有root权限去对全局Python升级，所以要在非root用户下安装自己指定的Python。因此，就重新整理了一份如何在Linux环境下使用非root用户安装python及其相关的库，以备不时之需。</p><a id="more"></a><h2 id="安装python"><a href="#安装python" class="headerlink" title="安装python"></a>安装python</h2><p>python版本库<a href="https://www.python.org/ftp/python/" target="_blank" rel="noopener">https://www.python.org/ftp/python/</a>，此处我选择2.7.5版本的，在安装python的时候，使用<code>--prefix</code>指定安装路径即可，命令如下：</p><figure class="highlight vim"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">wget http<span class="variable">s:</span>//www.<span class="keyword">python</span>.org/ftp/<span class="keyword">python</span>/<span class="number">2.7</span>.<span class="number">5</span>/Python-<span class="number">2.7</span>.<span class="number">5</span>.tgz</span><br><span class="line">tar -xzf Python-<span class="number">2.7</span>.<span class="number">5</span>.tgz</span><br><span class="line"><span class="keyword">cd</span> Python-<span class="number">2.7</span>.<span class="number">5</span></span><br><span class="line"><span class="built_in">mkdir</span> -<span class="keyword">p</span> /home/liudiwei/software/python27 </span><br><span class="line">./configure --prefix=<span class="string">"/home/liudiwei/software/python27"</span></span><br><span class="line"><span class="keyword">make</span></span><br><span class="line"><span class="keyword">make</span> install</span><br></pre></td></tr></tbody></table></figure><h2 id="安装setuptools"><a href="#安装setuptools" class="headerlink" title="安装setuptools"></a>安装setuptools</h2><p>setuptools主要是为安装pip做准备的，下面是从下载到安装的全部命令,使用上面安装的指定路径的python<code>/home/liudiwei/software/python27/bin/python</code>进行安装：</p><figure class="highlight perl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget --<span class="keyword">no</span>-check-certificate http:<span class="regexp">//pypi</span>.python.org/packages/source/<span class="keyword">s</span>/setuptools/setuptools-<span class="number">2.0</span>.tar.gz</span><br><span class="line">tar -xzvf setuptools-<span class="number">2.0</span>.tar.gz</span><br><span class="line">cd setuptools-<span class="number">2.0</span></span><br><span class="line">/home/liudiwei/software/python27/bin/python setup.py install</span><br></pre></td></tr></tbody></table></figure><h2 id="安装pip"><a href="#安装pip" class="headerlink" title="安装pip"></a>安装pip</h2><p>使用pip来安装python相关库，方便简单，此处将<code>python setup.py install</code>的python换成自己安装的指定路径下的python<code>/home/liudiwei/software/python27/bin/python setup.py install</code>.</p><figure class="highlight vim"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget --<span class="keyword">no</span>-check-certificate http<span class="variable">s:</span>//pypi.<span class="keyword">python</span>.org/packages/<span class="number">41</span>/<span class="number">27</span>/<span class="number">9</span>a8d24e1b55bd8c85e4d022da2922cb206f183e2d18fee4e320c9547e751/pip-<span class="number">8.1</span>.<span class="number">1</span>.tar.gz#md5=<span class="number">6</span>b86f11841e89c8241d689956ba99ed7</span><br><span class="line">tar -xzf pip-<span class="number">8.1</span>.<span class="number">1</span>.tar.gz</span><br><span class="line"><span class="keyword">cd</span> pip-<span class="number">8.1</span>.<span class="number">1</span></span><br><span class="line">/home/liudiwei/software/python27/bin/<span class="keyword">python</span> setup.<span class="keyword">py</span> install</span><br></pre></td></tr></tbody></table></figure><h2 id="安装相关库"><a href="#安装相关库" class="headerlink" title="安装相关库"></a>安装相关库</h2><p>进入python安装目录的bin路径下，安装下面相关库，经测试，下列库均可安装。</p><ul><li>simplejson</li><li>redis</li><li>numpy</li><li>scipy</li><li>sklearn</li></ul><p>安装命令：</p><figure class="highlight jboss-cli"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cd</span> <span class="string">/home/liudiwei/software/python27/bin/</span></span><br><span class="line"><span class="string">./pip</span> install simplejson</span><br><span class="line"><span class="string">./pip</span> install redis</span><br><span class="line"><span class="string">./pip</span> install numpy</span><br><span class="line"><span class="string">./pip</span> install scipy</span><br><span class="line"><span class="string">./pip</span> install sklearn</span><br></pre></td></tr></tbody></table></figure><p>关于matplotlib的安装，因为系统有些依赖包没有安装而导致matplotlib安装失败，如libpng， freetype等，待后续安装完成后，再来完善。</p><h2 id="附"><a href="#附" class="headerlink" title="附"></a>附</h2><p>如果想将自己安装的python使用指定的变量运行，比如使用<code>mypython</code>来运行python，只需配置一下<code>~/.bashrc</code>文件即可，如下：</p><figure class="highlight jboss-cli"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~<span class="string">/.bashrc</span></span><br></pre></td></tr></tbody></table></figure><p>在文件末尾追加下列内容:</p><pre><code>alias mypython='/home/liudiwei/software/python27/bin/python'</code></pre><p>然后使用<code>source ~/.bashrc</code>让该配置生效。接着就可以使用<code>mypython</code>进入python控制台了。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;以前在使用python的时候，都是使用root用户安装好的全局python，现在，因为root用户安装的Python版本太低，同时自己没有root权限去对全局Python升级，所以要在非root用户下安装自己指定的Python。因此，就重新整理了一份如何在Linux环境下使用非root用户安装python及其相关的库，以备不时之需。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://www.csuldw.com/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.csuldw.com/tags/Python/"/>
    
      <category term="pip" scheme="https://www.csuldw.com/tags/pip/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-损失函数</title>
    <link href="https://www.csuldw.com/2016/03/26/2016-03-26-loss-function/"/>
    <id>https://www.csuldw.com/2016/03/26/2016-03-26-loss-function/</id>
    <published>2016-03-26T05:04:00.000Z</published>
    <updated>2016-09-19T08:40:50.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>损失函数（loss function）是用来估量你模型的预测值f(x)与真实值Y的不一致程度，它是一个非负实值函数,通常使用L(Y, f(x))来表示，损失函数越小，模型的鲁棒性就越好。损失函数是<strong>经验风险函数</strong>的核心部分，也是<strong>结构风险函数</strong>重要组成部分。模型的结构风险函数包括了经验风险项和正则项，通常可以表示成如下式子：</p><p>$$\theta^* = \arg \min_\theta \frac{1}{N}{}\sum_{i=1}^{N} L(y_i, f(x_i; \theta)) + \lambda\  \Phi(\theta)$$</p><a id="more"></a><p>其中，前面的均值函数表示的是经验风险函数，L代表的是损失函数，后面的$\Phi$是正则化项（regularizer）或者叫惩罚项（penalty term），它可以是L1，也可以是L2，或者其他的正则函数。整个式子表示的意思是<font color="#1986C7"><strong>找到使目标函数最小时的$\theta$值</strong></font>。下面主要列出几种常见的损失函数。</p><h2 id="一、log对数损失函数（逻辑回归）"><a href="#一、log对数损失函数（逻辑回归）" class="headerlink" title="一、log对数损失函数（逻辑回归）"></a>一、log对数损失函数（逻辑回归）</h2><p>有些人可能觉得逻辑回归的损失函数就是平方损失，其实并不是。平方损失函数可以通过线性回归在假设样本是高斯分布的条件下推导得到，而逻辑回归得到的并不是平方损失。在逻辑回归的推导中，它假设样本服从<font color="#1986C7"><strong>伯努利分布（0-1分布）</strong></font>，然后求得满足该分布的似然函数，接着取对数求极值等等。而逻辑回归并没有求似然函数的极值，而是把极大化当做是一种思想，进而推导出它的经验风险函数为：<font color="#1986C7"><strong>最小化负的似然函数（即max F(y, f(x))  —&gt;  min -F(y, f(x)))</strong></font>。从损失函数的视角来看，它就成了log损失函数了。</p><p><strong>log损失函数的标准形式</strong>：<br>$$L(Y,P(Y|X)) = -\log P(Y|X)$$<br>刚刚说到，取对数是为了方便计算极大似然估计，因为在MLE中，直接求导比较困难，所以通常都是先取对数再求导找极值点。损失函数L(Y, P(Y|X))表达的是样本X在分类Y的情况下，使概率P(Y|X)达到最大值（换言之，<font color="#1986C7"><strong>就是利用已知的样本分布，找到最有可能（即最大概率）导致这种分布的参数值；或者说什么样的参数才能使我们观测到目前这组数据的概率最大</strong></font>）。因为log函数是单调递增的，所以logP(Y|X)也会达到最大值，因此在前面加上负号之后，最大化P(Y|X)就等价于最小化L了。  </p><p>逻辑回归的P(Y=y|x)表达式如下（为了将类别标签y统一为1和0，下面将表达式分开表示）：</p><p><img src="https://zhihu.com/equation?tex=P%28Y%3Dy%7Cx%29+%3D+%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%0Ah_%5Ctheta%28x%29+%3D+g%28f%28x%29%29+%3D+%5Cfrac%7B1%7D%7B1+%2B+exp%5C%7B-f%28x%29%5C%7D+%7D%26+%2Cy%3D1%5C%5C+%0A1+-+h_%5Ctheta%28x%29+%3D+1+-+g%28f%28x%29%29+%3D+%5Cfrac%7B1%7D%7B1+%2B+exp%5C%7Bf%28x%29%5C%7D+%7D+%26+%2Cy%3D0%0A%5Cend%7Bmatrix%7D%5Cright." alt=""></p><p>将它带入到上式，通过推导可以得到logistic的损失函数表达式，如下：</p><p><img src="https://zhihu.com/equation?tex=L%28y%2CP%28Y%3Dy%7Cx%29%29+%3D+%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%0A+%5Clog+%281%2Bexp%5C%7B-f%28x%29%5C%7D%29+%26+%2Cy%3D1%5C%5C+%0A+%5Clog+%281%2Bexp%5C%7B+f%28x%29%5C%7D%29++%26+%2Cy%3D0%5C%5C+%0A%5Cend%7Bmatrix%7D%5Cright." alt=""></p><p>逻辑回归最后得到的目标式子如下：</p><p>$$J(\theta) = - \frac{1}{m} \sum_{i=1}^m \left [ y^{(i)} \log h_{\theta}(x^{(i)}) + (1-y^{(i)}) \log(1-h_{\theta}(x^{(i)}))  \right ]$$</p><p>上面是针对二分类而言的。这里需要解释一下：<font color="green"><strong>之所以有人认为逻辑回归是平方损失，是因为在使用梯度下降来求最优解的时候，它的迭代式子与平方损失求导后的式子非常相似，从而给人一种直观上的错觉</strong></font>。</p><p>这里有个PDF可以参考一下：<a href="https://www.cs.berkeley.edu/~russell/classes/cs194/f11/lectures/CS194%20Fall%202011%20Lecture%2006.pdf" target="_blank" rel="noopener">Lecture 6: logistic regression.pdf</a>.</p><h2 id="二、平方损失函数（最小二乘法-Ordinary-Least-Squares-）"><a href="#二、平方损失函数（最小二乘法-Ordinary-Least-Squares-）" class="headerlink" title="二、平方损失函数（最小二乘法, Ordinary Least Squares ）"></a>二、平方损失函数（最小二乘法, Ordinary Least Squares ）</h2><p>最小二乘法是线性回归的一种，OLS将问题转化成了一个凸优化问题。在线性回归中，它假设样本和噪声都服从高斯分布（为什么假设成高斯分布呢？其实这里隐藏了一个小知识点，就是<strong>中心极限定理</strong>，可以参考<a href="https://en.wikipedia.org/wiki/Central_limit_theorem" target="_blank" rel="noopener">【central limit theorem】</a>），最后通过极大似然估计（MLE）可以推导出最小二乘式子。最小二乘的基本原则是：<font color="1986C7"><strong>最优拟合直线应该是使各点到回归直线的距离和最小的直线，即平方和最小</strong></font>。换言之，OLS是基于距离的，而这个距离就是我们用的最多的欧几里得距离。为什么它会选择使用欧式距离作为误差度量呢（即Mean squared error， MSE），主要有以下几个原因：</p><ul><li>简单，计算方便；</li><li>欧氏距离是一种很好的相似性度量标准；</li><li>在不同的表示域变换后特征性质不变。</li></ul><p><strong>平方损失（Square loss）的标准形式如下：</strong><br>$$ L(Y, f(X)) = (Y - f(X))^2 $$<br>当样本个数为n时，此时的损失函数变为：<br><img src="http://latex.codecogs.com/gif.latex?L%28Y%2C%20f%28X%29%29%20%3D%20%5Csum%20_%7Bi%3D1%7D%5E%7Bn%7D%28Y%20-%20f%28X%29%29%5E2" alt="$$L(Y, f(X)) = \sum _{i=1}^{n}(Y - f(X))^2$$"><br><code>Y-f(X)</code>表示的是残差，整个式子表示的是<font color="#1986C7"><strong>残差的平方和</strong></font>，而我们的目的就是最小化这个目标函数值（注：该式子未加入正则项），也就是最小化残差的平方和（residual sum of squares，RSS）。</p><p>而在实际应用中，通常会使用均方差（MSE）作为一项衡量指标，公式如下：<br>$$MSE = \frac{1}{n} \sum_{i=1} ^{n} (\tilde{Y_i} - Y_i )^2$$<br>上面提到了线性回归，这里额外补充一句，我们通常说的线性有两种情况，一种是因变量y是自变量x的线性函数，一种是因变量y是参数$\alpha$的线性函数。在机器学习中，通常指的都是后一种情况。</p><h2 id="三、指数损失函数（Adaboost）"><a href="#三、指数损失函数（Adaboost）" class="headerlink" title="三、指数损失函数（Adaboost）"></a>三、指数损失函数（Adaboost）</h2><p>学过Adaboost算法的人都知道，它是前向分步加法算法的特例，是一个加和模型，损失函数就是指数函数。在Adaboost中，经过m此迭代之后，可以得到$f_{m} (x)$:</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24f_m%20%28x%29%20%3D%20f_%7Bm-1%7D%28x%29%20+%20%5Calpha_m%20G_m%28x%29%24%24" alt="$$f_m (x) = f_{m-1}(x) + \alpha_m G_m(x)$$"></p><p>Adaboost每次迭代时的目的是为了找到最小化下列式子时的参数$\alpha$ 和G：</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24%5Carg%20%5Cmin_%7B%5Calpha%2C%20G%7D%20%3D%20%5Csum_%7Bi%3D1%7D%5E%7BN%7D%20exp%5B-y_%7Bi%7D%20%28f_%7Bm-1%7D%28x_i%29%20+%20%5Calpha%20G%28x_%7Bi%7D%29%29%5D%24%24" alt="$$\arg \min_{\alpha, G} = \sum_{i=1}^{N} exp[-y_{i} (f_{m-1}(x_i) + \alpha G(x_{i}))]$$"></p><p><strong>而指数损失函数(exp-loss）的标准形式如下</strong></p><p><img src="http://latex.codecogs.com/gif.latex?L%28y%2C%20f%28x%29%29%20%3D%20%5Cexp%5B-yf%28x%29%5D" alt="$$L(y, f(x)) = \exp[-yf(x)]$$"></p><p>可以看出，Adaboost的目标式子就是指数损失，在给定n个样本的情况下，Adaboost的损失函数为：</p><p><img src="http://latex.codecogs.com/gif.latex?L%28y%2C%20f%28x%29%29%20%3D%20%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Cexp%5B-y_if%28x_i%29%5D" alt="L(y, f(x)) = \frac{1}{n}\sum_{i=1}^{n}\exp[-y_if(x_i)]"></p><p>关于Adaboost的推导，可以参考Wikipedia：<a href="https://en.wikipedia.org/wiki/AdaBoost" target="_blank" rel="noopener">AdaBoost</a>或者《统计学习方法》P145.</p><h2 id="四、Hinge损失函数（SVM）"><a href="#四、Hinge损失函数（SVM）" class="headerlink" title="四、Hinge损失函数（SVM）"></a>四、Hinge损失函数（SVM）</h2><p>在机器学习算法中，hinge损失函数和SVM是息息相关的。在<strong>线性支持向量机</strong>中，最优化问题可以等价于下列式子：<br><img src="http://latex.codecogs.com/gif.latex?%24%24%5Cmin_%7Bw%2Cb%7D%20%5C%20%5Csum_%7Bi%7D%5E%7BN%7D%20%5B1%20-%20y_i%28w%5Ccdot%20x_i%20+%20b%29%5D_%7B+%7D%20+%20%5Clambda%7C%7Cw%7C%7C%5E2%20%24%24" alt="$$\min_{w,b}  \ \sum_{i}^{N} [1 - y_i(w\cdot x_i + b)]_{+} + \lambda||w||^2 $$"><br>下面来对式子做个变形，令：<br><img src="http://latex.codecogs.com/gif.latex?%24%24%5B1%20-%20y_i%28w%5Ccdot%20x_i%20+%20b%29%5D_%7B+%7D%20%3D%20%5Cxi_%7Bi%7D%24%24" alt="$$[1 - y_i(w\cdot x_i + b)]_{+} = \xi_{i}$$"><br>于是，原式就变成了：<br><img src="http://latex.codecogs.com/gif.latex?%24%24%5Cmin_%7Bw%2Cb%7D%20%5C%20%5Csum_%7Bi%7D%5E%7BN%7D%20%5Cxi_i%20+%20%5Clambda%7C%7Cw%7C%7C%5E2%20%24%24" alt="$$\min_{w,b}  \ \sum_{i}^{N} \xi_i + \lambda||w||^2 $$"><br>如若取$\lambda=\frac{1}{2C}$，式子就可以表示成：<br><img src="http://latex.codecogs.com/gif.latex?%24%24%5Cmin_%7Bw%2Cb%7D%20%5Cfrac%7B1%7D%7BC%7D%5Cleft%20%28%20%5Cfrac%7B1%7D%7B2%7D%5C%20%7C%7Cw%7C%7C%5E2%20%24%24%20+%20C%20%5Csum_%7Bi%7D%5E%7BN%7D%20%5Cxi_i%5Cright%20%29%24%24" alt="$$\min_{w,b}  \frac{1}{C}\left ( \frac{1}{2}\ ||w||^2 $$ + C \sum_{i}^{N} \xi_i\right )$$"><br>可以看出，该式子与下式非常相似：<br><img src="http://latex.codecogs.com/gif.latex?%5Cfrac%7B1%7D%7Bm%7D%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%20l%28w%20%5Ccdot%20x_i%20+%20b%2C%20y_i%29%20+%20%7C%7Cw%7C%7C%5E2" alt="$$\frac{1}{m} \sum_{i=1}^{m} l(w \cdot  x_i + b, y_i) + ||w||^2$$"></p><p>前半部分中的$l$就是hinge损失函数，而后面相当于L2正则项。</p><p><strong>Hinge 损失函数的标准形式</strong><br>$$L(y) = \max(0, 1-y\tilde{y}), y=\pm 1$$<br>可以看出，当|y|&gt;=1时，L(y)=0。</p><p>更多内容，参考<a href="https://en.wikipedia.org/wiki/Hinge_loss" target="_blank" rel="noopener">Hinge-loss</a>。</p><p>补充一下：在libsvm中一共有4中核函数可以选择，对应的是<code>-t</code>参数分别是：</p><ul><li>0-线性核；</li><li>1-多项式核；</li><li>2-RBF核；</li><li>3-sigmoid核。</li></ul><h2 id="五、其它损失函数"><a href="#五、其它损失函数" class="headerlink" title="五、其它损失函数"></a>五、其它损失函数</h2><p>除了以上这几种损失函数，常用的还有：</p><p><strong>0-1损失函数</strong><br><img src="http://latex.codecogs.com/gif.latex?L%28Y%2C%20f%28X%29%29%20%3D%20%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D1%20%2C%26%20Y%20%5Cneq%20f%28X%29%5C%5C%200%20%2C%26%20y%20%3D%20f%28X%29%20%5Cend%7Bmatrix%7D%5Cright." alt="L(Y, f(X)) = \left\{\begin{matrix}1 ,&amp; Y \neq f(X)\\ 0 ,&amp; y = f(X)    \end{matrix}\right."><br><strong>绝对值损失函数</strong><br><img src="http://latex.codecogs.com/gif.latex?L%28Y%2C%20f%28X%29%29%20%3D%20%7CY-f%28X%29%7C" alt="$$L(Y, f(X)) = |Y-f(X)|$$"><br>下面来看看几种损失函数的可视化图像，对着图看看横坐标，看看纵坐标，再看看每条线都表示什么损失函数，多看几次好好消化消化。<br><img src="/assets/articleImg/4DFDU.png" alt=""><br>OK，暂时先写到这里，休息下。最后，需要记住的是：<font color="#1986C7"><strong>参数越多，模型越复杂，而越复杂的模型越容易过拟合</strong></font>。过拟合就是说模型在训练数据上的效果远远好于在测试集上的性能。此时可以考虑正则化，通过设置正则项前面的hyper parameter，来权衡损失函数和正则项，减小参数规模，达到模型简化的目的，从而使模型具有更好的泛化能力。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://github.com/JohnLangford/vowpal_wabbit/wiki/Loss-functions" target="_blank" rel="noopener">https://github.com/JohnLangford/vowpal_wabbit/wiki/Loss-functions</a></li><li><a href="http://image.diku.dk/shark/sphinx_pages/build/html/rest_sources/tutorials/concepts/library_design/losses.html" target="_blank" rel="noopener">library_design/losses</a></li><li><a href="http://www.cs.cmu.edu/~yandongl/loss.html" target="_blank" rel="noopener">http://www.cs.cmu.edu/~yandongl/loss.html</a></li><li><a href="http://math.stackexchange.com/questions/782586/how-do-you-minimize-hinge-loss" target="_blank" rel="noopener">http://math.stackexchange.com/questions/782586/how-do-you-minimize-hinge-loss</a></li><li>《统计学习方法》 李航 著.</li></ul><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;损失函数（loss function）是用来估量你模型的预测值f(x)与真实值Y的不一致程度，它是一个非负实值函数,通常使用L(Y, f(x))来表示，损失函数越小，模型的鲁棒性就越好。损失函数是&lt;strong&gt;经验风险函数&lt;/strong&gt;的核心部分，也是&lt;strong&gt;结构风险函数&lt;/strong&gt;重要组成部分。模型的结构风险函数包括了经验风险项和正则项，通常可以表示成如下式子：&lt;/p&gt;
&lt;p&gt;$$\theta^* = \arg \min_\theta \frac{1}{N}{}\sum_{i=1}^{N} L(y_i, f(x_i; \theta)) + \lambda\  \Phi(\theta)$$&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="损失函数" scheme="https://www.csuldw.com/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>分类之性能评估指标</title>
    <link href="https://www.csuldw.com/2016/03/12/2016-03-12-performance-evaluation/"/>
    <id>https://www.csuldw.com/2016/03/12/2016-03-12-performance-evaluation/</id>
    <published>2016-03-12T12:03:00.000Z</published>
    <updated>2019-10-20T01:46:49.137Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文主要介绍几种常用的用于分类的性能评估指标，同时介绍如何绘制ROC曲线以及计算AUC值的便捷方法。最后再附上一个绘制ROC曲线和计算AUC的Python源码实现。</p><a id="more"></a><h2 id="Precision和Recall"><a href="#Precision和Recall" class="headerlink" title="Precision和Recall"></a>Precision和Recall</h2><p>首先我们来看看下面这个混淆矩阵：</p><table><thead><tr><th>pred_label/true_label</th><th>Positive</th><th>Negative</th></tr></thead><tbody><tr><td>Positive</td><td>TP</td><td>FP</td></tr><tr><td>Negtive</td><td>FN</td><td>TN</td></tr></tbody></table><p>如上表所示，行表示预测的label值，列表示真实label值。TP，FP，FN，TN分别表示如下意思：</p><ul><li>TP（true positive）：表示样本的真实类别为正，最后预测得到的结果也为正；</li><li>FP（false positive）：表示样本的真实类别为负，最后预测得到的结果却为正；</li><li>FN（false negative）：表示样本的真实类别为正，最后预测得到的结果却为负；</li><li>TN（true negative）：表示样本的真实类别为负，最后预测得到的结果也为负.</li></ul><p>根据以上几个指标，可以分别计算出Accuracy、Precision、Recall（Sensitivity，SN），Specificity（SP）。</p><p>$$Accuracy = \frac{TP+TN}{TP+FP+TN+FN}$$</p><p>$$Precision = \frac{TP}{TP+FP}$$</p><p>$$Recall = \frac{TP}{TP+FN}$$</p><p>$$SP = \frac{TN}{TN + FP}$$</p><ul><li>Accuracy：表示预测结果的精确度，预测正确的样本数除以总样本数。</li><li>precision，准确率，表示预测结果中，预测为正样本的样本中，正确预测为正样本的概率；</li><li>recall，召回率，表示在原始样本的正样本中，最后被正确预测为正样本的概率；</li><li>specificity，常常称作特异性，它研究的样本集是原始样本中的负样本，表示的是在这些负样本中最后被正确预测为负样本的概率。</li></ul><p>在实际当中，我们往往希望得到的precision和recall都比较高，比如当FN和FP等于0的时候，他们的值都等于1。但是，它们往往在某种情况下是互斥的。例如，有50个正样本，50个负样本，结果全部预测为正样本，那么TP=50,FP=50,TN=0,FN=0,按照上面的公式计算，可以得到正样本的recall却为1，precision却为0.5.所以需要一种折衷的方式，因此就有了F1-score。</p><p>$$ F1-score = \frac{ 2 \times recall \times precision}{ recall + precision}$$</p><p>F1-score表示的是precision和recall的调和平均评估指标。</p><p>另外还有一个指标，即MCC，该指标对于不均衡数据集的评估非常有效，公式如下：</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24MCC%20%3D%20%5Cfrac%7BTP%20%5Ctimes%20TN%20-%20FP%20%5Ctimes%20FN%7D%7B%20%5Csqrt%20%7B%28TP%20+%20FP%29%28TP%20+%20FN%29%28%20TN%20+%20FP%29%28TN+FN%29%7D%7D%24%24" alt="$$MCC = \frac{TP \times TN - FP \times FN}{ \sqrt {(TP + FP)(TP + FN)( TN + FP)(TN+FN)}}$$"></p><h2 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h2><p>ROC（receiver operating characteristic），平面的横坐标是false positive rate(FPR)假阳率，纵坐标是true positive rate(TPR)真阳率。ROC计算过程如下：</p><ul><li>首先每个样本都需要有一个label值，并且还需要一个预测的score值（取值0到1）;</li><li>然后按这个score对样本由大到小进行排序，假设这些数据位于表格中的一列，从上到下依次降序;</li><li>现在从上到下按照样本点的取值进行划分，位于分界点上面的我们把它归为预测为正样本，位于分界点下面的归为负样本;</li><li>分别计算出此时的TPR（Recall）=TP/P和FPR（1-SP）=FP/N，然后在图中绘制（FPR, TPR）点。</li></ul><p>从上往下逐个样本计算，最后会得到一条光滑的曲线 。</p><p>然而，千言万语都不如下面这幅图懂得快：</p><p><img src="http://www.csuldw.com/assets/articleImg/roc_plot.gif" alt=""></p><div class="caption">『roc曲线绘制动画—图片来自[参考文献5](http://stats.stackexchange.com/questions/105501/understanding-roc-curve/105577).』</div><h2 id="AUC计算"><a href="#AUC计算" class="headerlink" title="AUC计算"></a>AUC计算</h2><p>AUC（area under the curve）就是ROC曲线下方的面积，取值在0.5到1之间，因为随机猜测得到额AUC就是0.5。面积如下图所示，阴影部分即为AUC面积：</p><p><img src="http://www.csuldw.com/assets/articleImg/area_under_curve.png" alt=""></p><div class="caption">『AUC面积图解—图片来自[参考文献5](http://stats.stackexchange.com/questions/105501/understanding-roc-curve/105577).』</div><p>AUC的几种解释（来自<a href="http://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it?" target="_blank" rel="noopener">【Interpreting the AUROC】</a>）:</p><ul><li>The expectation that a uniformly drawn random positive is ranked before a uniformly drawn random negative.</li><li>The expected proportion of positives ranked before a uniformly drawn random negative.</li><li>The expected true positive rate if the ranking is split just before a uniformly drawn random negative.</li><li>The expected proportion of negatives ranked after a uniformly drawn random positive.</li><li>The expected false positive rate if the ranking is split just after a uniformly drawn random positive.</li></ul><p>下面来介绍下它的计算方法，AUC的计算主要有以下三种。</p><p>第一种：积分思维。这也是在早期机器学习文献中常用的AUC计算方法。从积分的思想中演化而来的。假如我们的测试样本有限，那么我们得到的AUC曲线必然是呈现阶梯形状。因此，计算的AUC也就是这些阶梯下面的面积之和（有没有想起以前学高数时的积分面积哈）。我们可以这样来计算，首先把score值进行排序，假设score越大，此样本属于正类的概率就越大。然后一边扫描一边计算就可以得到我们想要的AUC。但是，这样做会有个缺点，当多个测试样本的score值相等时，我们调整一下阈值，得到的不是往上或者往右的延展，而是斜着向上形成一个梯形。此时，就需要计算这个梯形的面积，这样是比较麻烦。 简单的用代码描述下</p><figure class="highlight maxima"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">auc = <span class="number">0.0</span></span><br><span class="line"><span class="built_in">height</span> = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> each training <span class="built_in">example</span> x_i, y_i：</span><br><span class="line">  <span class="keyword">if</span> y_i = <span class="number">1.0</span>:</span><br><span class="line">    <span class="built_in">height</span> = <span class="built_in">height</span> + tpr</span><br><span class="line">  <span class="keyword">else</span> </span><br><span class="line">    auc +=  <span class="built_in">height</span> * fpr</span><br><span class="line"></span><br><span class="line"><span class="built_in">return</span> auc</span><br></pre></td></tr></tbody></table></figure><p>第二种：<a href="https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test" target="_blank" rel="noopener">Mann–Whitney U test（MWW）</a>。关于AUC还有一个很有趣的性质，它和Wilcoxon-Mann-Witney Test类似（可以去google搜一下），而Wilcoxon-Mann-Witney Test就是<font color="#007FFF"><strong>测试任意给一个正类样本和一个负类样本，正类样本的score有多大的概率大于负类样本的score</strong></font>。有了这个定义，就可以得到了另外一中计算AUC的方法：计算出这个概率值。我们知道，在有限样本中我们常用的得到概率的办法就是通过频率来估计之。这种估计随着样本规模的扩大而逐渐逼近真实值。样本数越多，计算的AUC越准确类似，也和计算积分的时候，小区间划分的越细，计算的越准确是同样的道理。具体来说就是：<font color="red"> 统计一下所有的 M×N(M为正类样本的数目，N为负类样本的数目)个正负样本对中，有多少个组中的正样本的score大于负样本的score。当二元组中正负样本的 score相等的时候，按照0.5计算。然后除以MN。实现这个方法的复杂度为O(n^2  )。n为样本数(即n=M+N)</font>,公式表示如下：</p><p><img src="http://latex.codecogs.com/gif.latex?AUC%20%3D%20%5Cfrac%7B%5Csum_i%5En%20%28%20%5C%20pos%5C_score%20%3E%20neg%5C_score%20%5C%20%29%20+%200.5%20*%20%5Csum_i%5En%7B%28%5C%20pos%5C_score%3Dneg%5C_score%5C%20%29%7D%7D%7BM%20*%20N%7D" alt="$$**AUC = \frac{\sum_i^n ( \ pos\_score  > neg\_score \ )}{M * N}**$$"></p><p>第三种：该方法和上述第二种方法原理一样，但复杂度降低了。首先对score从大到小排序，然后令最大score对应的sample的rank值为n，第二大score对应sample的rank值为n-1，以此类推从n到1。然后把所有的正类样本的rank相加，再减去正类样本的score为最小的那M个值的情况。得到的结果就是有多少对正类样本的score值大于负类样本的score值，最后再除以M×N即可。值得注意的是，当存在score相等的时候，对于score相等的样本，需要赋予相同的rank值(无论这个相等的score是出现在同类样本还是不同类的样本之间，都需要这样处理)。具体操作就是再把所有这些score相等的样本 的rank取平均。然后再使用上述公式。此公式描述如下： </p><p><img src="http://latex.codecogs.com/gif.latex?AUC%20%3D%20%5Cfrac%7B%5Csum_%7Bins_i%20%5Cepsilon%20pos%7Drank_%7Bins_i%7D%20-%20%5Cfrac%7BM%20*%20%28M+1%29%7D%7B2%7D%7D%7BM%20*%20N%7D" alt="$$AUC = \frac{\sum_{ins_i \epsilon pos}rank_{ins_i} - \frac{M * (M+1)}{2}}{M * N}$$"></p><p>这三种方法，第一种比较好理解，后面两种确实不太好理解，先记下，慢慢理解。</p><h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><p>最后，附上ROC曲线绘制代码。下面使用的思想类似积分，但是求得是AUC的近似值，忽略了梯形部分，Code如下：</p><p>依赖库：</p><ul><li>numpy</li><li>matplotlib</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Sat Mar 12 17:43:48 2016</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: liudiwei</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotROC</span><span class="params">(predScore, labels)</span>:</span></span><br><span class="line">    point = (<span class="number">1.0</span>, <span class="number">1.0</span>) <span class="comment">#由于下面排序的索引是从小到大，所以这里从(1,1)开始绘制</span></span><br><span class="line">    ySum = <span class="number">0.0</span> </span><br><span class="line">    numPos = np.sum(np.array(labels)==<span class="number">1.0</span>)</span><br><span class="line">    numNeg = len(labels)-numPos</span><br><span class="line">    yStep = <span class="number">1</span>/np.float(numPos)</span><br><span class="line">    xStep = <span class="number">1</span>/np.float(numNeg)</span><br><span class="line">    sortedIndex = predScore.argsort() <span class="comment">#对predScore进行排序，的到排序索引值</span></span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    fig.clf()</span><br><span class="line">    ax = plt.subplot(<span class="number">111</span>)</span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> sortedIndex.tolist()[<span class="number">0</span>]:</span><br><span class="line">        <span class="keyword">if</span> labels[index] == <span class="number">1.0</span>: <span class="comment">#如果正样本各入加1，则x不走动，y往下走动一步</span></span><br><span class="line">            delX = <span class="number">0</span></span><br><span class="line">            delY = yStep;</span><br><span class="line">        <span class="keyword">else</span>:                   <span class="comment">#否则，x往左走动一步，y不走动</span></span><br><span class="line">            delX = xStep</span><br><span class="line">            delY = <span class="number">0</span></span><br><span class="line">            ySum += point[<span class="number">1</span>]     <span class="comment">#统计y走动的所有步数的和</span></span><br><span class="line">        ax.plot([point[<span class="number">0</span>], point[<span class="number">0</span>] - delX], [point[<span class="number">1</span>], point[<span class="number">1</span>] - delY],c=<span class="string">'b'</span>)</span><br><span class="line">        point = (point[<span class="number">0</span>] - delX, point[<span class="number">1</span>] - delY)</span><br><span class="line">    ax.plot([<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">1</span>],<span class="string">'b--'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'False positive rate'</span>); plt.ylabel(<span class="string">'True positive rate'</span>)</span><br><span class="line">    plt.title(<span class="string">'ROC Curve'</span>)</span><br><span class="line">    ax.axis([<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">    plt.show() </span><br><span class="line">    <span class="comment">#最后，所有将所有矩形的高度进行累加，最后乘以xStep得到的总面积，即为AUC值</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">"the Area Under the Curve is: "</span>, ySum * xStep</span><br></pre></td></tr></tbody></table></figure><p>对于ROC曲线绘制中的参数，输入的第二个参数是类别标签（如，+1，-1形成的文件，每行表示一个样本的真实类别）；第一个参数则是由模型训练出来的预测强度，如Adaboost对样本i预测的结果为0.67，对i+1个样本预测的结果是0.3，等等，每行一个，格式和classLabels一样。最后绘制ROC曲线的同时，也在输出ROC曲线下方的AUC面积。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Receiver_operating_characteristic</a><br>[2] <a href="http://blog.csdn.net/chjjunking/article/details/5933105" target="_blank" rel="noopener">http://blog.csdn.net/chjjunking/article/details/5933105</a><br>[3]《Machine Learning in Action》<br>[4] <a href="https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test</a><br>[5] <a href="http://stats.stackexchange.com/questions/105501/understanding-roc-curve/105577" target="_blank" rel="noopener">Understanding ROC curve</a><br>[6] <a href="http://stats.stackexchange.com/questions/145566/how-to-calculate-area-under-the-curve-auc-or-the-c-statistic-by-hand" target="_blank" rel="noopener">http://stats.stackexchange.com/questions/145566/how-to-calculate-area-under-the-curve-auc-or-the-c-statistic-by-hand</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要介绍几种常用的用于分类的性能评估指标，同时介绍如何绘制ROC曲线以及计算AUC值的便捷方法。最后再附上一个绘制ROC曲线和计算AUC的Python源码实现。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="ROC" scheme="https://www.csuldw.com/tags/ROC/"/>
    
      <category term="AUC" scheme="https://www.csuldw.com/tags/AUC/"/>
    
  </entry>
  
  <entry>
    <title>PCA主成分分析Python实现</title>
    <link href="https://www.csuldw.com/2016/02/28/2016-02-28-pca/"/>
    <id>https://www.csuldw.com/2016/02/28/2016-02-28-pca/</id>
    <published>2016-02-28T07:24:00.000Z</published>
    <updated>2016-05-10T16:17:28.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Github源码：<a href="https://github.com/csuldw/MachineLearning/tree/master/PCA" target="_blank" rel="noopener">https://github.com/csuldw/MachineLearning/tree/master/PCA</a></p><p>PCA（principle component analysis） ，主成分分析，主要是用来降低数据集的维度，然后挑选出主要的特征。原理简单，实现也简单。关于原理公式的推导，本文不会涉及，你可以参考下面的参考文献，也可以去Wikipedia，这里主要关注实现，算是锻炼一下自己，对PCA在理论的基础上画个圆满的句号。</p><a id="more"></a><p>本来是在复习LDA的，然后就看到了PCA，就跟着下面这篇文章的步骤，把PCA用python实现了一遍，具体的思想可以参考这篇文章，讲的通俗易懂，主要是有个实例参考，值得拥有！</p><ul><li><a href="http://www.cnblogs.com/jerrylead/archive/2011/04/18/2020209.html" target="_blank" rel="noopener">JerryLead之PCA主成分分析</a></li></ul><p>下面自己来简单的清理下思路！</p><h2 id="PCA思想"><a href="#PCA思想" class="headerlink" title="PCA思想"></a>PCA思想</h2><p>思想：<font color="#007FFF"><strong>移动坐标轴，将n维特征映射到k维上（k&lt;n），这k维是全新的正交特征。</strong></font>这k维特征称为主元，是重新构造出来的k维特征，而不是简单地从n维特征中去除其余n-k维特征。</p><p>说到PCA难免会提到LDA（linear discriminate analysis，线性判别分析），以及FA（factor analysis，因子分析）。关于LDA，打算有时间也用代码实现一遍，下面给出它的主要思想。</p><p>LDA思想：<font color="#007FFF"><strong>最大类间距离，最小类内距离</strong></font>。简而言之，第一，为了实现投影后的两个类别的距离较远，用映射后两个类别的均值差的绝对值来度量。第二，为了实现投影后，每个类内部数据点比较聚集，用投影后每个类别的方差来度量。</p><p>三者的描述如下</p><p> 以下内容引自 <a href="https://en.wikipedia.org/wiki/Linear_discriminant_analysis" target="_blank" rel="noopener">Wikipedia- Linear discriminant analysis</a></p><blockquote><p>LDA is also closely related to principal component analysis (PCA) and factor         analysis in that they both look for linear combinations of variables which best explain the data.[4] LDA explicitly attempts to model the difference between the classes of data. PCA on the other hand does not take into account any difference in class, and factor analysis builds the feature combinations based on differences rather than similarities. Discriminant analysis is also different from factor analysis in that it is not an interdependence technique: a distinction between independent variables and dependent variables (also called criterion variables) must be made.</p></blockquote><p>区别：PCA选择样本点投影具有最大方差的方向，LDA选择分类性能最好的方向。</p><p>好了，下面来看下实现源码！</p><h2 id="基本步骤"><a href="#基本步骤" class="headerlink" title="基本步骤"></a>基本步骤</h2><p>基本步骤：</p><ul><li>对数据进行归一化处理（代码中并非这么做的，而是直接减去均值）</li><li>计算归一化后的数据集的协方差矩阵                   </li><li>计算协方差矩阵的特征值和特征向量</li><li>保留最重要的k个特征（通常k&lt;n），可以自己制定，也可以选择个阈值，让后通过前k个特征值之和减去后面n-k个特征值之和大于这个阈值，找到这个k</li><li>找出k个特征值对应的特征向量</li><li>将m $*$ n的数据集乘以k个n维的特征向量的特征向量（n $*$ k）,得到最后降维的数据。</li></ul><p>其实PCA的本质就是对角化协方差矩阵。有必要解释下为什么将特征值按从大到小排序后再选。首先，要明白特征值表示的是什么？在线性代数里面我们求过无数次了，那么它具体有什么意义呢？对一个$n*n$的对称矩阵进行分解，我们可以求出它的特征值和特征向量，就会产生n个n维的正交基，每个正交基会对应一个特征值。然后把矩阵投影到这n个基上，此时特征值的模就表示矩阵在该基的投影长度。<font color="#007FFF"><strong>特征值越大，说明矩阵（样本）在对应的特征向量上投影后的方差越大，样本点越离散，越容易区分，信息量也就越多</strong></font>。因此，特征值最大的对应的特征向量方向上所包含的信息量就越多，如果某几个特征值很小，那么就说明在该方向的信息量非常少，我们就可以删除小特征值对应方向的数据，只保留大特征值方向对应的数据，这样做以后数据量减小，但有用的信息量都保留下来了。PCA就是这个原理。</p><h2 id="源码实现"><a href="#源码实现" class="headerlink" title="源码实现"></a>源码实现</h2><p>1.首先引入numpy，由于测试中用到了pandas和matplotlib，所以这里一并加载</p><figure class="highlight elm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></tbody></table></figure><p>2.定义一个均值函数</p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#计算均值,要求输入数据为numpy的矩阵格式，行表示样本数，列表示特征    </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">meanX</span><span class="params">(dataX)</span></span><span class="symbol">:</span></span><br><span class="line">    <span class="keyword">return</span> np.mean(dataX,axis=<span class="number">0</span>)<span class="comment">#axis=0表示按照列来求均值，如果输入list,则axis=1</span></span><br></pre></td></tr></tbody></table></figure><p>3.编写pca方法，具体解释参考注释</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">参数：</span></span><br><span class="line"><span class="string">- XMat：传入的是一个numpy的矩阵格式，行表示样本数，列表示特征    </span></span><br><span class="line"><span class="string">- k：表示取前k个特征值对应的特征向量</span></span><br><span class="line"><span class="string">返回值：</span></span><br><span class="line"><span class="string">- finalData：参数一指的是返回的低维矩阵，对应于输入参数二</span></span><br><span class="line"><span class="string">- reconData：参数二对应的是移动坐标轴后的矩阵</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pca</span><span class="params">(XMat, k)</span>:</span></span><br><span class="line">    average = meanX(XMat) </span><br><span class="line">    m, n = np.shape(XMat)</span><br><span class="line">    data_adjust = []</span><br><span class="line">    avgs = np.tile(average, (m, <span class="number">1</span>))</span><br><span class="line">    data_adjust = XMat - avgs</span><br><span class="line">    covX = np.cov(data_adjust.T)   <span class="comment">#计算协方差矩阵</span></span><br><span class="line">    featValue, featVec=  np.linalg.eig(covX)  <span class="comment">#求解协方差矩阵的特征值和特征向量</span></span><br><span class="line">    index = np.argsort(-featValue) <span class="comment">#按照featValue进行从大到小排序</span></span><br><span class="line">    finalData = []</span><br><span class="line">    <span class="keyword">if</span> k &gt; n:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"k must lower than feature number"</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment">#注意特征向量时列向量，而numpy的二维矩阵(数组)a[m][n]中，a[1]表示第1行值</span></span><br><span class="line">        selectVec = np.matrix(featVec.T[index[:k]]) <span class="comment">#所以这里需要进行转置</span></span><br><span class="line">        finalData = data_adjust * selectVec.T </span><br><span class="line">        reconData = (finalData * selectVec) + average  </span><br><span class="line">    <span class="keyword">return</span> finalData, reconData</span><br></pre></td></tr></tbody></table></figure><p>4.编写一个加载数据集的函数</p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#输入文件的每行数据都以\t隔开</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loaddata</span><span class="params">(datafile)</span></span><span class="symbol">:</span></span><br><span class="line">    <span class="keyword">return</span> np.array(pd.read_csv(datafile,sep=<span class="string">"\t"</span>,header=-<span class="number">1</span>)).astype(np.float)</span><br></pre></td></tr></tbody></table></figure><p>5.可视化结果</p><p>因为我将维数k指定为2，所以可以使用下面的函数将其绘制出来：</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">def plotBestFit(data1, data2):  </span><br><span class="line">    dataArr1 = np.array(data1)</span><br><span class="line">    dataArr2 = np.array(data2)</span><br><span class="line">    </span><br><span class="line">    m = np.shape(dataArr1)[0]</span><br><span class="line">    axis_x1 = []</span><br><span class="line">    axis_y1 = []</span><br><span class="line">    axis_x2 = []</span><br><span class="line">    axis_y2 = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        axis_x1.append(dataArr1[i,0])</span><br><span class="line">        axis_y1.append(dataArr1[i,1])</span><br><span class="line">        axis_x2.append(dataArr2[i,0]) </span><br><span class="line">        axis_y2.append(dataArr2[i,1])  </span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(111)</span><br><span class="line">    ax.scatter(axis_x1, axis_y1, <span class="attribute">s</span>=50, <span class="attribute">c</span>=<span class="string">'red'</span>, <span class="attribute">marker</span>=<span class="string">'s'</span>)</span><br><span class="line">    ax.scatter(axis_x2, axis_y2, <span class="attribute">s</span>=50, <span class="attribute">c</span>=<span class="string">'blue'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'x1'</span>); plt.ylabel(<span class="string">'x2'</span>);</span><br><span class="line">    plt.savefig(<span class="string">"outfile.png"</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></tbody></table></figure><p>6.测试方法</p><p>测试方法写入main函数中，然后直接执行main方法即可：</p><p>data.txt可到github中下载：<a href="https://github.com/csuldw/MachineLearning/tree/master/PCA/data.txt" target="_blank" rel="noopener">data.txt</a></p><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#根据数据集data.txt</span></span><br><span class="line">def main():    </span><br><span class="line">    <span class="attr">datafile</span> = <span class="string">"data.txt"</span></span><br><span class="line">    <span class="attr">XMat</span> = loaddata(datafile)</span><br><span class="line">    <span class="attr">k</span> = <span class="number">2</span></span><br><span class="line">    return pca(XMat, k)</span><br><span class="line"><span class="keyword">if</span> <span class="attr">__name__</span> == <span class="string">"__main__"</span>:</span><br><span class="line">    finalData, <span class="attr">reconMat</span> = main()</span><br><span class="line">    plotBestFit(finalData, reconMat)</span><br></pre></td></tr></tbody></table></figure><h2 id="结果展示"><a href="#结果展示" class="headerlink" title="结果展示"></a>结果展示</h2><p>最后的结果图如下：</p><p><img src="/assets/images/pca.png" alt=""></p><p>蓝色部分为重构后的原始数据，红色则是提取后的二维特征！</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] <a href="http://www.cnblogs.com/jerrylead/archive/2011/04/18/2020209.html" target="_blank" rel="noopener">http://www.cnblogs.com/jerrylead/archive/2011/04/18/2020209.html</a><br>[2] <a href="https://en.wikipedia.org/wiki/Linear_discriminant_analysis" target="_blank" rel="noopener">Wikipedia- Linear discriminant analysis</a><br>[3] <a href="https://en.wikipedia.org/wiki/Principal_component_analysis" target="_blank" rel="noopener">Wikipedia- Principal_component_analysis</a><br>[4]<a href="https://www.zhihu.com/question/21874816" target="_blank" rel="noopener">知乎-如何理解矩阵特征值</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Github源码：&lt;a href=&quot;https://github.com/csuldw/MachineLearning/tree/master/PCA&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/csuldw/MachineLearning/tree/master/PCA&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;PCA（principle component analysis） ，主成分分析，主要是用来降低数据集的维度，然后挑选出主要的特征。原理简单，实现也简单。关于原理公式的推导，本文不会涉及，你可以参考下面的参考文献，也可以去Wikipedia，这里主要关注实现，算是锻炼一下自己，对PCA在理论的基础上画个圆满的句号。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="PCA" scheme="https://www.csuldw.com/tags/PCA/"/>
    
      <category term="主成分分析" scheme="https://www.csuldw.com/tags/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>机器学习算法比较</title>
    <link href="https://www.csuldw.com/2016/02/26/2016-02-26-choosing-a-machine-learning-classifier/"/>
    <id>https://www.csuldw.com/2016/02/26/2016-02-26-choosing-a-machine-learning-classifier/</id>
    <published>2016-02-26T12:24:00.000Z</published>
    <updated>2019-10-20T01:50:14.689Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文主要回顾下几个常用算法的适应场景及其优缺点！（提示：部分内容摘自网络）。</p><p>机器学习算法太多了，分类、回归、聚类、推荐、图像识别领域等等，要想找到一个合适算法真的不容易，所以在实际应用中，我们一般都是采用启发式学习方式来实验。通常最开始我们都会选择大家普遍认同的算法，诸如SVM，GBDT，Adaboost，现在深度学习很火热，神经网络也是一个不错的选择。假如你在乎精度（accuracy）的话，最好的方法就是通过交叉验证（cross-validation）对各个算法一个个地进行测试，进行比较，然后调整参数确保每个算法达到最优解，最后选择最好的一个。但是如果你只是在寻找一个“足够好”的算法来解决你的问题，或者这里有些技巧可以参考，下面来分析下各个算法的优缺点，基于算法的优缺点，更易于我们去选择它。</p><a id="more"></a><h2 id="偏差-amp-方差"><a href="#偏差-amp-方差" class="headerlink" title="偏差&amp;方差"></a>偏差&amp;方差</h2><p>在统计学中，一个模型好坏，是根据偏差和方差来衡量的，所以我们先来普及一下偏差(bias)和方差(variance)：</p><ul><li>偏差：描述的是预测值（估计值）的期望E’与真实值Y之间的差距。偏差越大，越偏离真实数据。</li></ul><p>$$<br>Bias [\hat{f}(x)] = E [\hat{f}(x)] - f(x) \<br>\tag{1} \label{1}<br>$$</p><ul><li>方差：描述的是预测值P的变化范围，离散程度，是预测值的方差，也就是离其期望值E的距离。方差越大，数据的分布越分散。</li></ul><p>$$<br>Var [\hat{f}(x)] = E [(\hat{f}(x) - E[\hat{f}(x)])^2]<br>\tag{2} \label{2}<br>$$</p><p>模型的真实误差是两者之和，如公式\eqref{3}：</p><p>$$<br>E \left [(y - \hat{f}(x))^2 \right ] = Bias [\hat{f}(x)]^2 + Var[\hat{f}(x)] + \sigma^2<br>\tag{3} \label{3}<br>$$</p><p>通常情况下，如果是小训练集，高偏差/低方差的分类器（例如，朴素贝叶斯NB）要比低偏差/高方差大分类的优势大（例如，KNN），因为后者会发生过拟合（overfiting）。然而，随着你训练集的增长，模型对于原数据的预测能力就越好，偏差就会降低，此时低偏差/高方差的分类器就会渐渐的表现其优势（因为它们有较低的渐近误差），而高偏差分类器这时已经不足以提供准确的模型了。</p><p>当然，你也可以认为这是生成模型（如NB）与判别模型（如KNN）的一个区别。</p><p><font color="red">为什么说朴素贝叶斯是高偏差低方差?</font></p><p>以下内容引自知乎：</p><blockquote><p>首先，假设你知道训练集和测试集的关系。简单来讲是我们要在训练集上学习一个模型，然后拿到测试集去用，效果好不好要根据测试集的错误率来衡量。但很多时候，我们只能假设测试集和训练集的是符合同一个数据分布的，但却拿不到真正的测试数据。这时候怎么在只看到训练错误率的情况下，去衡量测试错误率呢？</p></blockquote><blockquote><p>由于训练样本很少（至少不足够多），所以通过训练集得到的模型，总不是真正正确的。（就算在训练集上正确率100%，也不能说明它刻画了真实的数据分布，要知道刻画真实的数据分布才是我们的目的，而不是只刻画训练集的有限的数据点）。而且，实际中，训练样本往往还有一定的噪音误差，所以如果太追求在训练集上的完美而采用一个很复杂的模型，会使得模型把训练集里面的误差都当成了真实的数据分布特征，从而得到错误的数据分布估计。这样的话，到了真正的测试集上就错的一塌糊涂了（这种现象叫过拟合）。但是也不能用太简单的模型，否则在数据分布比较复杂的时候，模型就不足以刻画数据分布了（体现为连在训练集上的错误率都很高，这种现象较欠拟合）。过拟合表明采用的模型比真实的数据分布更复杂，而欠拟合表示采用的模型比真实的数据分布要简单。</p></blockquote><blockquote><p>在统计学习框架下，大家刻画模型复杂度的时候，有这么个观点，认为Error = Bias + Variance。这里的Error大概可以理解为模型的预测错误率，是有两部分组成的，一部分是由于模型太简单而带来的估计不准确的部分（Bias），另一部分是由于模型太复杂而带来的更大的变化空间和不确定性（Variance）。</p></blockquote><blockquote><p>所以，这样就容易分析朴素贝叶斯了。它简单的假设了各个数据之间是无关的，是一个被<strong>严重简化了的模型</strong>。所以，对于这样一个简单模型，大部分场合都会Bias部分大于Variance部分，也就是说高偏差而低方差。</p></blockquote><blockquote><p>在实际中，为了让Error尽量小，我们在选择模型的时候需要平衡Bias和Variance所占的比例，也就是平衡over-fitting和under-fitting。</p></blockquote><p>偏差、方差、模型复杂度三者之间的关系使用下图表示会更容易理解：</p><p><img src="/assets/articleImg/bias_variance.png" alt=""></p><p>当模型复杂度上升的时候，偏差会逐渐变小，而方差会逐渐变大。</p><h2 id="常见算法优缺点"><a href="#常见算法优缺点" class="headerlink" title="常见算法优缺点"></a>常见算法优缺点</h2><h3 id="1-朴素贝叶斯"><a href="#1-朴素贝叶斯" class="headerlink" title="1.朴素贝叶斯"></a>1.<strong>朴素贝叶斯</strong></h3><p>朴素贝叶斯属于生成式模型（关于生成模型和判别式模型，主要还是在于是否需要求联合分布），比较简单，你只需做一堆计数即可。如果注有条件独立性假设（一个比较严格的条件），朴素贝叶斯分类器的收敛速度将快于判别模型，比如逻辑回归，所以你只需要较少的训练数据即可。即使NB条件独立假设不成立，NB分类器在实践中仍然表现的很出色。它的主要缺点是它不能学习特征间的相互作用，用mRMR中R来讲，就是特征冗余。引用一个比较经典的例子，比如，虽然你喜欢Brad Pitt和Tom Cruise的电影，但是它不能学习出你不喜欢他们在一起演的电影。</p><p><strong>优点</strong>：</p><ul><li>朴素贝叶斯模型发源于古典数学理论，有着坚实的数学基础，以及稳定的分类效率。</li><li>对小规模的数据表现很好，能个处理多分类任务，适合增量式训练；</li><li>对缺失数据不太敏感，算法也比较简单，常用于文本分类。</li></ul><p><strong>缺点</strong>：</p><ul><li>需要计算先验概率；</li><li>分类决策存在错误率；</li><li>对输入数据的表达形式很敏感。</li></ul><hr><h3 id="2-Logistic-Regression（逻辑回归）"><a href="#2-Logistic-Regression（逻辑回归）" class="headerlink" title="2.Logistic Regression（逻辑回归）"></a>2.<strong>Logistic Regression（逻辑回归）</strong></h3><p>逻辑回归属于判别式模型，同时伴有很多模型正则化的方法（L0， L1，L2，etc），而且你不必像在用朴素贝叶斯那样担心你的特征是否相关。与决策树、SVM相比，你还会得到一个不错的概率解释，你甚至可以轻松地利用新数据来更新模型（使用在线梯度下降算法-online gradient descent）。如果你需要一个概率架构（比如，简单地调节分类阈值，指明不确定性，或者是要获得置信区间），或者你希望以后将更多的训练数据快速整合到模型中去，那么使用它吧。</p><p><strong>Sigmoid函数</strong>：表达式为公式\eqref{4}.  </p><p>$$<br>f(x) = \frac{1}{1+e^{-x}}<br>\tag{4}\label{4}<br>$$</p><p><strong>优点：</strong>  </p><ul><li>实现简单，广泛的应用于工业问题上；</li><li>分类时计算量非常小，速度很快，存储资源低；</li><li>便利的观测样本概率分数；</li><li>对逻辑回归而言，多重共线性并不是问题，它可以结合L2正则化来解决该问题；</li></ul><p><strong>缺点</strong>：</p><ul><li>当特征空间很大时，逻辑回归的性能不是很好；</li><li>容易<strong>欠拟合</strong>，一般准确度不太高</li><li>不能很好地处理大量多类特征或变量；</li><li>只能处理两分类问题（在此基础上衍生出来的softmax可以用于多分类），且必须<strong>线性可分</strong>；</li><li>对于非线性特征，需要进行转换；</li></ul><hr><h3 id="3-线性回归"><a href="#3-线性回归" class="headerlink" title="3.线性回归"></a><strong>3.线性回归</strong></h3><p> 线性回归是用于回归的，它不像Logistic回归那样用于分类，其基本思想是用<strong>梯度下降法</strong>对最小二乘法形式的误差函数进行优化，当然也可以用normal equation直接求得参数的解，结果为：</p><p>$$<br>\hat{w}=(X^{T}X)^{-1}X^Ty<br>\tag{5}\label{5}<br>$$</p><p>而在LWLR（局部加权线性回归）中，参数的计算表达式为:</p><p>$$<br>\hat{w}=(X^{T}WX)^{-1}X^TWy<br>\tag{6}\label{6}<br>$$</p><p>由此可见LWLR与LR不同，LWLR是一个非参数模型，因为每次进行回归计算都要遍历训练样本至少一次。</p><p><strong>优点</strong>： 实现简单，计算简单；<br><strong>缺点</strong>： 不能拟合非线性数据.</p><hr><h3 id="4-最近邻算法——KNN"><a href="#4-最近邻算法——KNN" class="headerlink" title="4.最近邻算法——KNN"></a>4.最近邻算法——KNN</h3><p>KNN即最近邻算法，其主要过程为：</p><pre><code>1. 计算训练样本和测试样本中每个样本点的距离（常见的距离度量有欧式距离，马氏距离等）；2. 对上面所有的距离值进行排序(升序)；3. 选前k个最小距离的样本；4. 根据这k个样本的标签进行投票，得到最后的分类类别；</code></pre><p>如何选择一个最佳的K值，这取决于数据。一般情况下，在分类时较大的K值能够减小噪声的影响，但会使类别之间的界限变得模糊。一个较好的K值可通过各种启发式技术来获取，比如，交叉验证。另外噪声和非相关性特征向量的存在会使K近邻算法的准确性减小。近邻算法具有较强的一致性结果，随着数据趋于无限，算法保证错误率不会超过贝叶斯算法错误率的两倍。对于一些好的K值，K近邻保证错误率不会超过贝叶斯理论误差率。</p><p><strong>KNN算法的优点</strong></p><ul><li>理论成熟，思想简单，既可以用来做分类也可以用来做回归；</li><li>可用于非线性分类；</li><li>训练时间复杂度为O(n)；</li><li>对数据没有假设，准确度高，对outlier不敏感；</li></ul><p><strong>缺点</strong></p><ul><li>计算量大（体现在距离计算上）；</li><li>样本不平衡问题（即有些类别的样本数量很多，而其它样本的数量很少）效果差；</li><li>需要大量内存；</li></ul><hr><h3 id="5-决策树"><a href="#5-决策树" class="headerlink" title="5.决策树"></a>5.决策树</h3><p>决策树的一大优势就是易于解释。它可以毫无压力地处理特征间的交互关系并且是非参数化的，因此你不必担心异常值或者数据是否线性可分（举个例子，决策树能轻松处理好类别A在某个特征维度x的末端，类别B在中间，然后类别A又出现在特征维度x前端的情况）。它的缺点之一就是不支持在线学习，于是在新样本到来后，决策树需要全部重建。另一个缺点就是容易出现过拟合，但这也就是诸如随机森林RF（或提升树boosted tree）之类的集成方法的切入点。另外，随机森林经常是很多分类问题的赢家（通常比支持向量机好上那么一丁点），它训练快速并且可调，同时你无须担心要像支持向量机那样调一大堆参数，所以在以前都一直很受欢迎。</p><p>决策树中很重要的一点就是选择一个属性进行分枝，因此要注意一下信息增益的计算公式，并深入理解它。</p><p>信息熵的计算公式如下:</p><p>$$<br>H=-\sum^{n}_{i=1}p(x_i)log_2p(x_i)<br>\tag{7}\label{7}<br>$$</p><p>其中的n代表有n个分类类别（比如假设是二类问题，那么n=2）。分别计算这2类样本在总样本中出现的概率p1和p2，这样就可以计算出未选中属性分枝前的信息熵。</p><p>现在选中一个属性$x_i$用来进行分枝，此时分枝规则是：如果$x_i=v$的话，将样本分到树的一个分支；如果不相等则进入另一个分支。很显然，分支中的样本很有可能包括2个类别，分别计算这2个分支的熵H1和H2,计算出分枝后的总信息熵H’ =p1 * H1+p2 * H2,则此时的信息增益ΔH = H - H’。以信息增益为原则，把所有的属性都测试一边，选择一个使增益最大的属性作为本次分枝属性。</p><p><strong>决策树自身的优点</strong></p><ul><li>计算简单，易于理解，可解释性强；</li><li>比较适合处理有缺失属性的样本；</li><li>能够处理不相关的特征；</li><li>在相对短的时间内能够对大型数据源做出可行且效果良好的结果。</li></ul><p><strong>缺点</strong></p><ul><li>容易发生过拟合（随机森林可以很大程度上减少过拟合）；</li><li>忽略了数据之间的相关性；</li><li>对于那些各类别样本数量不一致的数据，在决策树当中,信息增益的结果偏向于那些具有更多数值的特征（只要是使用了信息增益，都有这个缺点，如RF）。</li></ul><h4 id="5-1-Adaboosting"><a href="#5-1-Adaboosting" class="headerlink" title="5.1 Adaboosting"></a>5.1 Adaboosting</h4><p>Adaboost是一种加和模型，每个模型都是基于上一次模型的错误率来建立的，过分关注分错的样本，而对正确分类的样本减少关注度，逐次迭代之后，可以得到一个相对较好的模型。该算法是一种典型的boosting算法，其加和理论的优势可以使用Hoeffding不等式得以解释。有兴趣的同学可以阅读下笔者后面写的这篇文章<a href="http://www.csuldw.com/2016/08/28/2016-08-28-adaboost-algorithm-theory/">Adaboost - 新的角度理解权值更新策略</a>.下面总结下它的优缺点。</p><p><strong>优点</strong></p><ul><li>Adaboost是一种有很高精度的分类器。</li><li>可以使用各种方法构建子分类器，Adaboost算法提供的是框架。</li><li>当使用简单分类器时，计算出的结果是可以理解的，并且弱分类器的构造极其简单。</li><li>简单，不用做特征筛选。</li><li>不易发生overfitting。</li></ul><p>关于随机森林和GBDT等组合算法，参考这篇文章：<a href="http://www.csuldw.com/2015/07/22/2015-07-22%20%20ensemble/">机器学习-组合算法总结</a></p><p><strong>缺点：</strong>对outlier比较敏感</p><hr><h3 id="6-SVM支持向量机"><a href="#6-SVM支持向量机" class="headerlink" title="6.SVM支持向量机"></a>6.SVM支持向量机</h3><p>支持向量机，一个经久不衰的算法，高准确率，为避免过拟合提供了很好的理论保证，而且就算数据在原特征空间线性不可分，只要给个合适的核函数，它就能运行得很好。在动辄超高维的文本分类问题中特别受欢迎。可惜内存消耗大，难以解释，运行和调参也有些烦人，而随机森林却刚好避开了这些缺点，比较实用。</p><p><strong>优点</strong></p><ul><li>可以解决高维问题，即大型特征空间；</li><li>能够处理非线性特征的相互作用；</li><li>无需依赖整个数据；</li><li>可以提高泛化能力；</li></ul><p><strong>缺点</strong></p><ul><li>当观测样本很多时，效率并不是很高；</li><li>对非线性问题没有通用解决方案，有时候很难找到一个合适的核函数；</li><li>对缺失数据敏感；</li></ul><p>对于核的选择也是有技巧的（libsvm中自带了四种核函数：线性核、多项式核、RBF以及sigmoid核）：</p><ul><li>第一，如果样本数量小于特征数，那么就没必要选择非线性核，简单的使用线性核就可以了；</li><li>第二，如果样本数量大于特征数目，这时可以使用非线性核，将样本映射到更高维度，一般可以得到更好的结果；</li><li>第三，如果样本数目和特征数目相等，该情况可以使用非线性核，原理和第二种一样。</li></ul><p>对于第一种情况，也可以先对数据进行降维，然后使用非线性核，这也是一种方法。</p><hr><h3 id="7-人工神经网络的优缺点"><a href="#7-人工神经网络的优缺点" class="headerlink" title="7. 人工神经网络的优缺点"></a>7. 人工神经网络的优缺点</h3><p><strong>人工神经网络的优点：</strong></p><ul><li>分类的准确度高；</li><li>并行分布处理能力强,分布存储及学习能力强，</li><li>对噪声神经有较强的鲁棒性和容错能力，能充分逼近复杂的非线性关系；</li><li>具备联想记忆的功能。</li></ul><p><strong>人工神经网络的缺点：</strong></p><ul><li>神经网络需要大量的参数，如网络拓扑结构、权值和阈值的初始值；</li><li>不能观察之间的学习过程，输出结果难以解释，会影响到结果的可信度和可接受程度；</li><li>学习时间过长,甚至可能达不到学习的目的。</li></ul><hr><h3 id="8、K-Means聚类"><a href="#8、K-Means聚类" class="headerlink" title="8、K-Means聚类"></a>8、K-Means聚类</h3><p>之前笔者写过一篇关于K-Means聚类的文章，参见<a href="http://www.csuldw.com/2015/06/03/2015-06-03-ml-algorithm-K-means/">机器学习算法-K-means聚类</a>。关于K-Means的推导，里面可是有大学问的，蕴含着强大的EM思想。</p><p><strong>优点</strong></p><ul><li>算法简单，容易实现 ；</li><li>对处理大数据集，该算法是相对可伸缩的和高效率的，因为它的复杂度大约是O(nkt)，其中n是所有对象的数目，k是簇的数目,t是迭代的次数。通常$k&lt;&lt;n$。这个算法通常局部收敛。</li><li>算法尝试找出使平方误差函数值最小的k个划分。当簇是密集的、球状或团状的，且簇与簇之间区别明显时，聚类效果较好。</li></ul><p><strong>缺点</strong></p><ul><li>对数据类型要求较高，适合数值型数据；</li><li>可能收敛到局部最小值，在大规模数据上收敛较慢  </li><li>K值比较难以选取；</li><li>对初值的簇心值敏感，对于不同的初始值，可能会导致不同的聚类结果；</li><li>不适合于发现非凸面形状的簇，或者大小差别很大的簇。</li><li>对于”噪声”和孤立点数据敏感，少量的该类数据能够对平均值产生极大影响。</li></ul><h2 id="算法选择参考"><a href="#算法选择参考" class="headerlink" title="算法选择参考"></a>算法选择参考</h2><p>之前笔者翻译过一些国外的文章，其中有一篇文章中给出了一个简单的算法选择技巧：</p><ol><li>首次应该选择的就是逻辑回归，如果它的效果不怎么样，那么可以将它的结果作为基准来参考，在基础上与其他算法进行比较；</li><li>然后试试决策树（随机森林）看看是否可以大幅度提升你的模型性能。即便最后你并没有把它当做为最终模型，你也可以使用随机森林来移除噪声变量，做特征选择；</li><li>如果特征的数量和观测样本特别多，那么当资源和时间充足时（这个前提很重要），使用SVM不失为一种选择。</li></ol><p>通常情况下：【GBDT&gt;=SVM&gt;=RF&gt;=Adaboost&gt;=Other…】，现在深度学习很热门，很多领域都用到，它是以神经网络为基础的，目前笔者自己也在学习，只是理论知识不扎实，理解的不够深入，这里就不做介绍了，希望以后可以写一片抛砖引玉的文章。</p><p>算法固然重要，<strong>但好的数据却要优于好的算法</strong>，设计优良特征是大有裨益的。假如你有一个超大数据集，那么无论你使用哪种算法可能对分类性能都没太大影响（此时就可以根据速度和易用性来进行抉择）。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] <a href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff</a><br>[2] <a href="http://blog.echen.me/2011/04/27/choosing-a-machine-learning-classifier/" target="_blank" rel="noopener">http://blog.echen.me/2011/04/27/choosing-a-machine-learning-classifier/</a><br>[3] <a href="http://www.csuldw.com/2016/02/26/2016-02-26-choosing-a-machine-learning-classifier/">http://www.csuldw.com/2016/02/26/2016-02-26-choosing-a-machine-learning-classifier/</a>  </p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要回顾下几个常用算法的适应场景及其优缺点！（提示：部分内容摘自网络）。&lt;/p&gt;
&lt;p&gt;机器学习算法太多了，分类、回归、聚类、推荐、图像识别领域等等，要想找到一个合适算法真的不容易，所以在实际应用中，我们一般都是采用启发式学习方式来实验。通常最开始我们都会选择大家普遍认同的算法，诸如SVM，GBDT，Adaboost，现在深度学习很火热，神经网络也是一个不错的选择。假如你在乎精度（accuracy）的话，最好的方法就是通过交叉验证（cross-validation）对各个算法一个个地进行测试，进行比较，然后调整参数确保每个算法达到最优解，最后选择最好的一个。但是如果你只是在寻找一个“足够好”的算法来解决你的问题，或者这里有些技巧可以参考，下面来分析下各个算法的优缺点，基于算法的优缺点，更易于我们去选择它。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="算法选择" scheme="https://www.csuldw.com/tags/%E7%AE%97%E6%B3%95%E9%80%89%E6%8B%A9/"/>
    
      <category term="偏差" scheme="https://www.csuldw.com/tags/%E5%81%8F%E5%B7%AE/"/>
    
      <category term="方差" scheme="https://www.csuldw.com/tags/%E6%96%B9%E5%B7%AE/"/>
    
      <category term="LR" scheme="https://www.csuldw.com/tags/LR/"/>
    
  </entry>
  
  <entry>
    <title>机器学习数据集-MNIST</title>
    <link href="https://www.csuldw.com/2016/02/25/2016-02-25-machine-learning-MNIST-dataset/"/>
    <id>https://www.csuldw.com/2016/02/25/2016-02-25-machine-learning-MNIST-dataset/</id>
    <published>2016-02-25T09:24:00.000Z</published>
    <updated>2016-03-08T09:03:30.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>在学习机器学习的时候，首当其冲的就是准备一份通用的数据集，方便与其他的算法进行比较。在这里，我写了一个用于加载MNIST数据集的方法，并将其进行封装，主要用于将MNIST数据集转换成numpy.array()格式的训练数据。直接下面看下面的代码吧(主要还是如何用python去读取binnary file)！</p><a id="more"></a><p>MNIST数据集原网址：<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">http://yann.lecun.com/exdb/mnist/</a></p><p>Github源码下载：<a href="https://github.com/csuldw/MachineLearning/tree/master/dataset/MNIST" target="_blank" rel="noopener">数据集（源文件+解压文件+字体图像jpg格式）</a>， <a href="https://github.com/csuldw/MachineLearning/tree/master/utils/" target="_blank" rel="noopener">py源码文件</a></p><h2 id="文件目录"><a href="#文件目录" class="headerlink" title="文件目录"></a>文件目录</h2><ul><li><a href="https://github.com/csuldw/MachineLearning/tree/master/utils/data_util.py" target="_blank" rel="noopener">/utils/data_util.py</a> 用于加载MNIST数据集方法文件</li><li><a href="https://github.com/csuldw/MachineLearning/tree/master/utils/test.py" target="_blank" rel="noopener">/utils/test.py</a> 用于测试的文件，一个简单的KNN测试MNIST数据集</li><li><a href="https://github.com/csuldw/MachineLearning/tree/master/dataset/MNIST" target="_blank" rel="noopener">/data/train-images.idx3-ubyte</a> 训练集X</li><li><a href="https://github.com/csuldw/MachineLearning/tree/master/dataset/MNIST" target="_blank" rel="noopener">/dataset/train-labels.idx1-ubyte</a> 训练集y</li><li><a href="https://github.com/csuldw/MachineLearning/tree/master/dataset/MNIST" target="_blank" rel="noopener">/dataset/data/t10k-images.idx3-ubyte</a> 测试集X</li><li><a href="https://github.com/csuldw/MachineLearning/tree/master/dataset/MNIST" target="_blank" rel="noopener">/dataset/data/t10k-labels.idx1-ubyte</a> 测试集y</li></ul><h2 id="MNIST数据集解释"><a href="#MNIST数据集解释" class="headerlink" title="MNIST数据集解释"></a>MNIST数据集解释</h2><p>将MNIST文件解压后，发现这些文件并不是标准的图像格式。这些图像数据都保存在二进制文件中。每个样本图像的宽高为28*28。</p><p>mnist的结构如下，选取train-images</p><pre><code>TRAINING SET IMAGE FILE (train-images-idx3-ubyte):[offset] [type]          [value]          [description] 0000     32 bit integer  0x00000803(2051) magic number 0004     32 bit integer  60000            number of images 0008     32 bit integer  28               number of rows 0012     32 bit integer  28               number of columns 0016     unsigned byte   ??               pixel 0017     unsigned byte   ??               pixel ........ xxxx     unsigned byte   ??               pixel</code></pre><p>首先该数据是以二进制存储的，我们读取的时候要以’rb’方式读取；其次，真正的数据只有[value]这一项，其他的[type]等只是来描述的，并不真正在数据文件里面。也就是说，在读取真实数据之前，我们要读取4个<code>32 bit integer</code>.由[offset]我们可以看出真正的pixel是从0016开始的，一个int 32位，所以在读取pixel之前我们要读取4个 32 bit integer，也就是magic number, number of images, number of rows, number of columns. 当然，在这里使用struct.unpack_from()会比较方便.</p><h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><p>说明：</p><ul><li>‘&gt;IIII’指的是使用大端法读取4个unsinged int 32 bit integer</li><li>‘&gt;784B’指的是使用大端法读取784个unsigned byte</li></ul><p>data_util.py文件</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Thu Feb 25 14:40:06 2016</span></span><br><span class="line"><span class="string">load MNIST dataset</span></span><br><span class="line"><span class="string">@author: liudiwei</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> struct</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataUtils</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""MNIST数据集加载</span></span><br><span class="line"><span class="string">    输出格式为：numpy.array()    </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    使用方法如下</span></span><br><span class="line"><span class="string">    from data_util import DataUtils</span></span><br><span class="line"><span class="string">    def main():</span></span><br><span class="line"><span class="string">        trainfile_X = '../dataset/MNIST/train-images.idx3-ubyte'</span></span><br><span class="line"><span class="string">        trainfile_y = '../dataset/MNIST/train-labels.idx1-ubyte'</span></span><br><span class="line"><span class="string">        testfile_X = '../dataset/MNIST/t10k-images.idx3-ubyte'</span></span><br><span class="line"><span class="string">        testfile_y = '../dataset/MNIST/t10k-labels.idx1-ubyte'</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        train_X = DataUtils(filename=trainfile_X).getImage()</span></span><br><span class="line"><span class="string">        train_y = DataUtils(filename=trainfile_y).getLabel()</span></span><br><span class="line"><span class="string">        test_X = DataUtils(testfile_X).getImage()</span></span><br><span class="line"><span class="string">        test_y = DataUtils(testfile_y).getLabel()</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        #以下内容是将图像保存到本地文件中</span></span><br><span class="line"><span class="string">        #path_trainset = "../dataset/MNIST/imgs_train"</span></span><br><span class="line"><span class="string">        #path_testset = "../dataset/MNIST/imgs_test"</span></span><br><span class="line"><span class="string">        #if not os.path.exists(path_trainset):</span></span><br><span class="line"><span class="string">        #    os.mkdir(path_trainset)</span></span><br><span class="line"><span class="string">        #if not os.path.exists(path_testset):</span></span><br><span class="line"><span class="string">        #    os.mkdir(path_testset)</span></span><br><span class="line"><span class="string">        #DataUtils(outpath=path_trainset).outImg(train_X, train_y)</span></span><br><span class="line"><span class="string">        #DataUtils(outpath=path_testset).outImg(test_X, test_y)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">        return train_X, train_y, test_X, test_y </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, filename=None, outpath=None)</span>:</span></span><br><span class="line">        self._filename = filename</span><br><span class="line">        self._outpath = outpath</span><br><span class="line">        </span><br><span class="line">        self._tag = <span class="string">'&gt;'</span></span><br><span class="line">        self._twoBytes = <span class="string">'II'</span></span><br><span class="line">        self._fourBytes = <span class="string">'IIII'</span>    </span><br><span class="line">        self._pictureBytes = <span class="string">'784B'</span></span><br><span class="line">        self._labelByte = <span class="string">'1B'</span></span><br><span class="line">        self._twoBytes2 = self._tag + self._twoBytes</span><br><span class="line">        self._fourBytes2 = self._tag + self._fourBytes</span><br><span class="line">        self._pictureBytes2 = self._tag + self._pictureBytes</span><br><span class="line">        self._labelByte2 = self._tag + self._labelByte</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getImage</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        将MNIST的二进制文件转换成像素特征数据</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        binfile = open(self._filename, <span class="string">'rb'</span>) <span class="comment">#以二进制方式打开文件</span></span><br><span class="line">        buf = binfile.read() </span><br><span class="line">        binfile.close()</span><br><span class="line">        index = <span class="number">0</span></span><br><span class="line">        numMagic,numImgs,numRows,numCols=struct.unpack_from(self._fourBytes2,\</span><br><span class="line">                                                                    buf,\</span><br><span class="line">                                                                    index)</span><br><span class="line">        index += struct.calcsize(self._fourBytes)</span><br><span class="line">        images = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(numImgs):</span><br><span class="line">            imgVal = struct.unpack_from(self._pictureBytes2, buf, index)</span><br><span class="line">            index += struct.calcsize(self._pictureBytes2)</span><br><span class="line">            imgVal = list(imgVal)</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(len(imgVal)):</span><br><span class="line">                <span class="keyword">if</span> imgVal[j] &gt; <span class="number">1</span>:</span><br><span class="line">                    imgVal[j] = <span class="number">1</span></span><br><span class="line">            images.append(imgVal)</span><br><span class="line">        <span class="keyword">return</span> np.array(images)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getLabel</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        将MNIST中label二进制文件转换成对应的label数字特征</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        binFile = open(self._filename,<span class="string">'rb'</span>)</span><br><span class="line">        buf = binFile.read()</span><br><span class="line">        binFile.close()</span><br><span class="line">        index = <span class="number">0</span></span><br><span class="line">        magic, numItems= struct.unpack_from(self._twoBytes2, buf,index)</span><br><span class="line">        index += struct.calcsize(self._twoBytes2)</span><br><span class="line">        labels = [];</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(numItems):</span><br><span class="line">            im = struct.unpack_from(self._labelByte2,buf,index)</span><br><span class="line">            index += struct.calcsize(self._labelByte2)</span><br><span class="line">            labels.append(im[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">return</span> np.array(labels)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">outImg</span><span class="params">(self, arrX, arrY)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        根据生成的特征和数字标号，输出png的图像</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        m, n = np.shape(arrX)</span><br><span class="line">        <span class="comment">#每张图是28*28=784Byte</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>):</span><br><span class="line">            img = np.array(arrX[i])</span><br><span class="line">            img = img.reshape(<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line">            outfile = str(i) + <span class="string">"_"</span> +  str(arrY[i]) + <span class="string">".png"</span></span><br><span class="line">            plt.figure()</span><br><span class="line">            plt.imshow(img, cmap = <span class="string">'binary'</span>) <span class="comment">#将图像黑白显示</span></span><br><span class="line">            plt.savefig(self._outpath + <span class="string">"/"</span> + outfile)</span><br></pre></td></tr></tbody></table></figure><p>test.py文件:简单地测试了一下KNN算法，代码如下</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Thu Feb 25 16:09:58 2016</span></span><br><span class="line"><span class="string">Test MNIST dataset </span></span><br><span class="line"><span class="string">@author: liudiwei</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> neighbors  </span><br><span class="line"><span class="keyword">from</span> data_util <span class="keyword">import</span> DataUtils</span><br><span class="line"><span class="keyword">import</span> datetime  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    trainfile_X = <span class="string">'../dataset/MNIST/train-images.idx3-ubyte'</span></span><br><span class="line">    trainfile_y = <span class="string">'../dataset/MNIST/train-labels.idx1-ubyte'</span></span><br><span class="line">    testfile_X = <span class="string">'../dataset/MNIST/t10k-images.idx3-ubyte'</span></span><br><span class="line">    testfile_y = <span class="string">'../dataset/MNIST/t10k-labels.idx1-ubyte'</span></span><br><span class="line">    train_X = DataUtils(filename=trainfile_X).getImage()</span><br><span class="line">    train_y = DataUtils(filename=trainfile_y).getLabel()</span><br><span class="line">    test_X = DataUtils(testfile_X).getImage()</span><br><span class="line">    test_y = DataUtils(testfile_y).getLabel()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_X, train_y, test_X, test_y </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testKNN</span><span class="params">()</span>:</span></span><br><span class="line">    train_X, train_y, test_X, test_y = main()</span><br><span class="line">    startTime = datetime.datetime.now()</span><br><span class="line">    knn = neighbors.KNeighborsClassifier(n_neighbors=<span class="number">3</span>)  </span><br><span class="line">    knn.fit(train_X, train_y)  </span><br><span class="line">    match = <span class="number">0</span>;  </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(len(test_y)):  </span><br><span class="line">        predictLabel = knn.predict(test_X[i])[<span class="number">0</span>]  </span><br><span class="line">        <span class="keyword">if</span>(predictLabel==test_y[i]):  </span><br><span class="line">            match += <span class="number">1</span>  </span><br><span class="line">      </span><br><span class="line">    endTime = datetime.datetime.now()  </span><br><span class="line">    <span class="keyword">print</span> <span class="string">'use time: '</span>+str(endTime-startTime)  </span><br><span class="line">    <span class="keyword">print</span> <span class="string">'error rate: '</span>+ str(<span class="number">1</span>-(match*<span class="number">1.0</span>/len(test_y)))  </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    testKNN()</span><br></pre></td></tr></tbody></table></figure><p>通过main方法，最后直接返回numpy.array()格式的数据：train_X, train_y, test_X, test_y。如果你需要，直接条用main方法即可！</p><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h2&gt;&lt;p&gt;在学习机器学习的时候，首当其冲的就是准备一份通用的数据集，方便与其他的算法进行比较。在这里，我写了一个用于加载MNIST数据集的方法，并将其进行封装，主要用于将MNIST数据集转换成numpy.array()格式的训练数据。直接下面看下面的代码吧(主要还是如何用python去读取binnary file)！&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Python" scheme="https://www.csuldw.com/tags/Python/"/>
    
      <category term="MNIST" scheme="https://www.csuldw.com/tags/MNIST/"/>
    
      <category term="dataset" scheme="https://www.csuldw.com/tags/dataset/"/>
    
  </entry>
  
  <entry>
    <title>Python个人编码规范</title>
    <link href="https://www.csuldw.com/2016/02/23/2016-02-23-Python-coding-standards/"/>
    <id>https://www.csuldw.com/2016/02/23/2016-02-23-Python-coding-standards/</id>
    <published>2016-02-23T12:37:00.000Z</published>
    <updated>2019-10-20T01:54:07.690Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>接触Python已将近两年了，写过的代码也不少，每次对代码的编写都没有统一的规范，所以，根据自己以往的经验，专门为自己定制了一份用于编写Python代码时使用的代码规范。</p><a id="more"></a><h2 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h2><p>常量名所有字母大写，由下划线连接各个单词，如：USER_CONSTANT</p><h2 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h2><p>变量名全部小写，由下划线连接各个单词，如：</p><pre><code>color = WHITEthis_is_a_variable = 1</code></pre><h2 id="函数和方法"><a href="#函数和方法" class="headerlink" title="函数和方法"></a>函数和方法</h2><ul><li>私有方法：小写和一个前导下划线</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_secrete</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">"don't test me."</span></span><br></pre></td></tr></tbody></table></figure><ul><li>函数参数：小写和下划线，缺省值等号两边无空格</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">connect</span><span class="params">(self, user=None)</span>:</span></span><br><span class="line">    self._user = user</span><br></pre></td></tr></tbody></table></figure><h2 id="类"><a href="#类" class="headerlink" title="类"></a>类</h2><ul><li>类总是使用驼峰格式命名，不使用下划线连接单词，也不加入 C、T 等前缀，即所有单词首字母大写其余字母小写。类名应该简明，精确，并足以从中理解类所完成的工作。常见的一个方法是使用表示其类型或者特性的后缀，例如:</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLEngine</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></tbody></table></figure><ul><li>对于基类而言，可以使用一个 Base 或者 Abstract 前缀</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaseCookie</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AbstractGroup</span><span class="params">(object)</span>:</span></span><br><span class="line">    psss</span><br></pre></td></tr></tbody></table></figure><h2 id="特定命名方式"><a href="#特定命名方式" class="headerlink" title="特定命名方式"></a>特定命名方式</h2><p>主要是指 __xxx__ 形式的系统保留字命名法。项目中也可以使用这种命名，它的意义在于这种形式的变量是只读的，这种形式的类成员函数尽量不要重载。如</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Base</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, id, parent = None)</span>:</span></span><br><span class="line">        self.__id__ = id</span><br><span class="line">        self.__parent__ = parent</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__message__</span><span class="params">(self, msgid)</span>:</span></span><br><span class="line">        <span class="comment"># ...略</span></span><br></pre></td></tr></tbody></table></figure><p>其中 <code>_id</code>、<code>parent_</code> 和 <code>_message_</code>都采用了系统保留字命名法。</p><h2 id="空格"><a href="#空格" class="headerlink" title="空格"></a>空格</h2><ol><li>在二元算术、逻辑运算符前后加空格：如 <code>a = b + c</code>；</li></ol><ul><li>在一元前缀运算符后不加空格，如 <code>if !flg: pass</code>；</li><li>“:”用在行尾时前后皆不加空格，如分支、循环、函数和类定义语言；用在非行尾时后端加空格，如 <code>dict</code> 对象的定义 <code>d = {'key': 'value'}</code>;</li><li>括号（含圆括号、方括号和花括号）前后不加空格，如 <code>do_something(arg1, arg2)</code>, 而不是 <code>do_something( arg1, arg2 )</code>；</li><li>逗号后面加一个空格，前面不加空格。</li></ul><h2 id="空行"><a href="#空行" class="headerlink" title="空行"></a>空行</h2><ol><li>在类、函数的定义间加空行；</li></ol><ul><li>在import不同种类的模块间加空行；</li><li>在函数中的逻辑段落间加空行，即把相关的代码紧凑写在一起，作为一个逻辑段落，段落间以空行分隔。</li></ul><h2 id="断行"><a href="#断行" class="headerlink" title="断行"></a>断行</h2><p>（1）行的最大长度不得超过 80 个字符的标准。折叠长行的方法有以下几种方法：<br>1）为长变量名换一个短名，如：</p><figure class="highlight stylus"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">this<span class="selector-class">.is</span><span class="selector-class">.a</span><span class="selector-class">.very</span><span class="selector-class">.long</span><span class="selector-class">.variable_name</span> = this<span class="selector-class">.is</span><span class="selector-class">.another</span><span class="selector-class">.long</span>.variable_name</span><br></pre></td></tr></tbody></table></figure><p>应改为：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">variable_name1 = this.<span class="keyword">is</span>.a.very.long.variable_name</span><br><span class="line">variable_name2 = this.<span class="keyword">is</span>.another.variable_name</span><br><span class="line">variable_name1 = variable_name2</span><br></pre></td></tr></tbody></table></figure><p>（2）在括号（包括圆括号、方括号和花括号）内换行，如：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Edit</span><span class="params">(CBase)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, parent, width,</span></span></span><br><span class="line"><span class="function"><span class="params">                font = FONT, color = BLACK, pos = POS, style = <span class="number">0</span>)</span>:</span></span><br></pre></td></tr></tbody></table></figure><p>或：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">very_very_very_long_variable_name = Edit(parent, \</span><br><span class="line">                                         width, \</span><br><span class="line">                                         font, \</span><br><span class="line">                                         color, \</span><br><span class="line">                                         pos)</span><br></pre></td></tr></tbody></table></figure><p>（3）在长行加入续行符强行断行，断行的位置应在操作符前，且换行后多一个缩进，以使维护人员看代码的时候看到代码行首即可判定这里存在换行，如：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> color == WHITE <span class="keyword">or</span> color == BLACK \</span><br><span class="line">              <span class="keyword">or</span> color == BLUE:</span><br><span class="line">    do_something(color);</span><br></pre></td></tr></tbody></table></figure><h2 id="语句"><a href="#语句" class="headerlink" title="语句"></a>语句</h2><ul><li>import</li></ul><p>import 语句有以下几个原则需要遵守：</p><p>（1）import 的次序，先<code>import Python</code>内置模块，再import第三方模块，最后import自己开发的项目中的其它模块；这几种模块中用空行分隔开来。</p><p>（2）一条import语句import一个模块。</p><p>（3）当从模块中 import 多个对象且超过一行时，使用如下断行法（此语法 py2.5 以上版本才支持）：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> module <span class="keyword">import</span> (obj1, obj2, obj3, obj4,</span><br><span class="line">obj5, obj6)</span><br></pre></td></tr></tbody></table></figure><p>4）不要使用 <code>from module import *</code>，除非是 <code>import</code>常量定义模块或其它你确保不会出现命名空间冲突的模块。</p><h2 id="赋值"><a href="#赋值" class="headerlink" title="赋值"></a>赋值</h2><p>对于赋值语言，等号前后空一格，格式如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">1</span></span><br><span class="line">variable = <span class="number">2</span></span><br><span class="line">fn = callback_function</span><br></pre></td></tr></tbody></table></figure><h2 id="分支和循环"><a href="#分支和循环" class="headerlink" title="分支和循环"></a>分支和循环</h2><p>不要写成一行，如：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> !flg: <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">10</span>): <span class="keyword">print</span> i</span><br></pre></td></tr></tbody></table></figure><p>应该写成：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> !flg:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">print</span> i</span><br></pre></td></tr></tbody></table></figure><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul><li>使用 has 或 is 前缀命名布尔元素</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">is_connect = <span class="literal">True</span></span><br><span class="line">has_member = <span class="literal">False</span></span><br></pre></td></tr></tbody></table></figure><ul><li>用复数形式命名序列</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">members = [<span class="string">'user_1'</span>, <span class="string">'user_2'</span>]</span><br></pre></td></tr></tbody></table></figure><ul><li>用显式名称命名字典</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">person_address = {<span class="string">'user_1'</span>:<span class="string">'10 road WD'</span>, <span class="string">'user_2'</span> : <span class="string">'20 street huafu'</span>}</span><br></pre></td></tr></tbody></table></figure><ul><li><p>避免通用名称</p><ul><li>诸如 list, dict, sequence 或者 element 这样的名称应该避免。</li></ul></li></ul><ul><li><p>一些数字</p><ul><li>一行列数 : PEP 8 规定为 79 列，这有些苛刻了。根据自己的情况，比如不要超过满屏时编辑器的显示列数。这样就可以在不动水平游标的情况下，方便的查看代码。</li><li>一个函数 : 不要超过 30 行代码, 即可显示在一个屏幕类，可以不使用垂直游标即可看到整个函数。</li><li>一个类 : 不要超过 200 行代码，不要有超过 10 个方法。</li><li>一个模块 不要超过 500 行。</li></ul></li></ul><h2 id="Contributor"><a href="#Contributor" class="headerlink" title="Contributor"></a>Contributor</h2><ul><li>Liu Diwei: <a href="https://github.com/csuldw" target="_blank" rel="noopener">https://github.com/csuldw</a></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;接触Python已将近两年了，写过的代码也不少，每次对代码的编写都没有统一的规范，所以，根据自己以往的经验，专门为自己定制了一份用于编写Python代码时使用的代码规范。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://www.csuldw.com/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.csuldw.com/tags/Python/"/>
    
      <category term="编码规范" scheme="https://www.csuldw.com/tags/%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-牛顿方法&amp;指数分布族&amp;GLM</title>
    <link href="https://www.csuldw.com/2016/01/12/2016-01-12-Newton-Method/"/>
    <id>https://www.csuldw.com/2016/01/12/2016-01-12-Newton-Method/</id>
    <published>2016-01-12T02:24:00.000Z</published>
    <updated>2019-10-20T02:11:03.643Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><font color="green">回头再温习一下Andrew Ng的机器学习视频课，顺便把没写完的笔记写完。</font></p><p>本节内容</p><ul><li>牛顿方法</li><li>指数分布族</li><li>广义线性模型</li></ul><a id="more"></a><p>之前学习了梯度下降方法，关于梯度下降（gradient descent），这里简单的回顾下【参考感知机学习部分提到的梯度下降(<a href="http://blog.csdn.net/dream_angel_z/article/details/48915561" target="_blank" rel="noopener">gradient descent</a>)】。在最小化损失函数时，采用的就是梯度下降的方法逐步逼近最优解，规则为$\theta := \theta - \eta \nabla_{\theta} \ell(\theta)$。其实梯度下降属于一种优化方法，但梯度下降找到的是局部最优解。如下图：</p><p><img src="/assets/articleImg/newton-method.png" alt="这里写图片描述"></p><p>本节首先讲解的是牛顿方法（NewTon’s Method）。牛顿方法也是一种优化方法，它考虑的是<strong>全局最优</strong>。接着还会讲到指数分布族和广义线性模型。下面来详细介绍。</p><h2 id="1-牛顿方法"><a href="#1-牛顿方法" class="headerlink" title="1.牛顿方法"></a><strong>1.牛顿方法</strong></h2><p>现在介绍另一种最小化损失函数$\ell(\theta)$的方法——牛顿方法,参考<a href="http://www.phengkimving.com/calc_of_one_real_var/08_app_of_the_der_part_2/08_05_approx_of_roots_of_func_newtons_meth.htm" target="_blank" rel="noopener">Approximations Of Roots Of Functions – Newton’s Method</a><br>。它与梯度下降不同，其基本思想如下：</p><p>假设一个函数$f(x) = 0$,我们需要求解此时的$x$值。如下图所示：</p><center>![这里写图片描述](http://img.blog.csdn.net/20151006095845371)图1 $f(x0) = 0, a1, a2, a3, ... 逐步接近 x0$.</center><p>在<br>$a_1$点的时候，$f(x)$切线的目标函数$y = f(a_1) + f ‘(a_1)(x – a_1)$. 由于$(a_2,0)$在这条线上，所以我们有$ 0 = f(a_1) + f ‘(a_1)(a_2 – a_1)$,so:</p><p>$$a_2 = a_1-\frac{f(a_1)}{f’(a_1)}$$</p><p>同理，在$a_2$点的时候，切线的目标函数$y = f(a_2) + f ‘(a_2)(x – a_2)$. 由于$(a_3,0)$在这条线上，所以我们有$ 0 = f(a_2) + f ‘(a_2)(a_3– a_2)$,so:</p><p>$$a_3 = a_2-\frac{f(a_2)}{f’(a_2)}$$</p><p>假设在第$n$次迭代，有$f(a_n)=0$,那么此时有下面这个递推公式：</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24a_n%20%3D%20a_%7Bn-1%7D-%5Cfrac%7Bf%28a_%7Bn-1%7D%29%7D%7Bf%27%28a_%7Bn-1%7D%29%7D%24%24" alt=""></p><p>其中$n&gt;=2$.</p><p>最后得到的公式也就是牛顿方法的学习规则，为了和梯度下降对比，我们来替换一下变量，公式如下：</p><p>$$\theta := \theta - \frac{f(\theta)}{f’(\theta)}$$</p><p><font color="green"><strong>那么问题来了，怎么将牛顿方法应用到我们的问题上，最小化损失函数$\ell(\theta)$(或者是求极大似然估计的极大值)呢？</strong><br></font></p><p>  对于机器学习问题，现在我们优化的目标函数为极大似然估计$\ell$，当极大似然估计函数取值最大时，其导数为 0，这样就和上面函数f取 0 的问题一致了，令$f(\theta) = \ell’(\theta)$。极大似然函数的求解更新规则是：</p><p>$$\theta := \theta - \frac{\ell’(\theta)}{\ell’’(\theta)}$$</p><p>对于$\ell$，当一阶导数为零时，有极值；此时，如果二阶导数大于零，则$\ell$有极小值，如果二阶导数小于零，则有极大值。</p><p>上面的式子是当参数$\theta$为实数时的情况，下面我们要求出一般式。当参数为向量时，更新规则变为如下公式：</p><p>$$\theta := \theta - H^{-1} \nabla_{\theta}\ell(\theta)$$</p><p>其中$\nabla$后半部分$和之前梯度下降中提到的一样，是梯度，$H$是一个$n*n$的矩阵，$H $是函数的二次导数矩阵，被成为$Hessian$矩阵。其某个元素$ H_{ij}$ 计算公式如下：</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24H_%7Bij%7D%3D%5Cdfrac%7B%5Cpartial%5E%7B2%7D%5Cell%28%5Ctheta%29%7D%7B%5Cpartial%5Ctheta_%7Bi%7D%5Ctheta_%7Bj%7D%7D%24%24" alt="$$H_{ij}=\dfrac{\partial^{2}\ell(\theta)}{\partial\theta_{i}\theta_{j}}$$"></p><p><font color="red"><strong>和梯度下降相比，牛顿方法的收敛速度更快，通常只要十几次或者更少就可以收敛，牛顿方法也被称为二次收敛（quadratic convergence），因为当迭代到距离收敛值比较近的时候，每次迭代都能使误差变为原来的平方。缺点是当参数向量较大的时候，每次迭代都需要计算一次 Hessian 矩阵的逆，比较耗时。</strong><br></font></p><h2 id="2-指数分布族（The-exponential-family）"><a href="#2-指数分布族（The-exponential-family）" class="headerlink" title="2.指数分布族（The exponential family）"></a><strong>2.指数分布族（The exponential family）</strong></h2><p>指数分布族是指可以表示为指数形式的概率分布。指数分布的形式如下：</p><p>$$P(y;\eta)=b(y)exp(\eta^{T}T(y)-a(\eta))$$</p><p>其中，η成为分布的<strong>自然参数</strong>（nature parameter）；T(y)是<strong>充分统计量</strong>（sufficient statistic），通常 <strong>T(y)=y</strong>。当参数 a、b、T 都固定的时候，就定义了一个以η为参数的函数族。</p><p>下面介绍两种分布，伯努利分布和高斯分布，分别把它们表示成指数分布族的形式。</p><h3 id="伯努利分布"><a href="#伯努利分布" class="headerlink" title="伯努利分布"></a><strong>伯努利分布</strong></h3><p>伯努利分布是对0，1问题进行建模的，对于Bernoulli（$\varphi$）,$y\epsilon{0, 1}$.有$p(y=1; \varphi ) = \varphi; p(y=0; \varphi ) = 1- \varphi$，下面将其推导成指数分布族形式：</p><p><img src="/assets/articleImg/exp-form.png" alt="这里写图片描述"></p><p>将其与指数族分布形式对比，可以看出：</p><p><img src="http://img.blog.csdn.net/20151006105357353" alt="这里写图片描述"></p><p>表明伯努利分布也是指数分布族的一种。从上述式子可以看到，$\eta$的形式与logistic函数（sigmoid）一致，这是因为 logistic模型对问题的前置概率估计其实就是伯努利分布。</p><h3 id="高斯分布"><a href="#高斯分布" class="headerlink" title="高斯分布"></a><strong>高斯分布</strong></h3><p>下面对高斯分布进行推导，推导公式如下（为了方便计算，我们将方差 $\sigma$设置为1）：</p><p><img src="/assets/articleImg/gaussian-form.png" alt="这里写图片描述"></p><p>将上式与指数族分布形式比对，可知：</p><p>$$b(y) = \frac{1}{\sqrt{2\pi}}exp(-\frac{1}{2}y^{2})$$</p><p>$$T(y) = y$$</p><p>$$\eta = \mu$$</p><p>$$a(\eta)=\frac{1}{2}\mu^{2}$$</p><p>两个典型的指数分布族，伯努利和高斯分布。其实大多数概率分布都可以表示成指数分布族形式，如下所示：</p><ul><li>伯努利分布（Bernoulli）：对 0、1 问题进行建模；</li><li>多项式分布（Multinomial）：多有 K 个离散结果的事件建模；</li><li>泊松分布（Poisson）：对计数过程进行建模，比如网站访问量的计数问题，放射性衰变的数目，商店顾客数量等问题；</li><li>伽马分布（gamma）与指数分布（exponential）：对有间隔的正数进行建模，比如公交车的到站时间问题；</li><li>β 分布：对小数建模；</li><li>Dirichlet 分布：对概率分布进建模；</li><li>Wishart 分布：协方差矩阵的分布；</li><li>高斯分布（Gaussian）；</li></ul><p>下面来介绍下广义线性模型（Generalized Linear Model, GLM）。</p><h2 id="3-广义线性模型（Generalized-Linear-Model-GLM）"><a href="#3-广义线性模型（Generalized-Linear-Model-GLM）" class="headerlink" title="3.广义线性模型（Generalized Linear Model, GLM）"></a><strong>3.广义线性模型（Generalized Linear Model, GLM）</strong></h2><p>你可能会问，指数分布族究竟有何用？其实我们的目的是要引出GLM，通过指数分布族引出广义线性模型。</p><p>仔细观察伯努利分布和高斯分布的指数分布族形式中的$\eta$变量。可以发现，在伯努利的指数分布族形式中，$\eta$与伯努利分布的参数$\varphi$是一个logistic函数（下面会介绍logistic回归的推导）。此外，在高斯分布的指数分布族表示形式中，$\eta$与正态分布的参数$\mu$相等，下面会根据它推导出普通最小二乘法（Ordinary Least Squares）。通过这两个例子，我们大致可以得到一个结论，<font color="red"><strong>$η$以不同的映射函数与其它概率分布函数中的参数发生联系，从而得到不同的模型，广义线性模型正是将指数分布族中的所有成员（每个成员正好有一个这样的联系）都作为线性模型的扩展，通过各种非线性的连接函数将线性函数映射到其他空间，从而大大扩大了线性模型可解决的问题。</strong></font></p><p>下面我们看 GLM 的形式化定义，GLM 有三个假设：</p><ul><li>(1) $y|x; \theta~ExponentialFamily（\eta）$；给定样本$ x $与参数$θ$，样本分类$ y$ 服从指数分布族中的某个分布；</li><li>(2) 给定一个 $x$，我们需要的目标函数为$h_{\theta}(x)=E[T(y)|x]$;</li><li>(3)$\eta=\theta^{T}x$。</li></ul><p>依据这三个假设，我们可以推导出logistic模型与普通最小二乘模型。首先根据伯努利分布推导Logistic模型，推导过程如下:</p><p>$$\begin{align}<br>h_{\theta}(x) &amp;= E[T(y)|x]=E[y|x]=p(y=1|x;\theta) \\<br>&amp;=\varphi \\<br>&amp;=\frac{1}{1+e^{-\eta}} \\<br>&amp;=\frac{1}{1+e^{-\theta^{T}x}}<br>\end{align}<br>$$</p><p>公式第一行来自假设(2)，公式第二行通过伯努利分布计算得出，第三行通过伯努利的指数分布族表示形式得出，然后在公式第四行，根据假设三替换变量得到。</p><p>同样，可以根据高斯分布推导出普通最小二乘，如下：</p><p>$$\begin{align}<br>h_{\theta}(x) &amp;= E(T(y)|x)=E[y|x] \\<br>&amp;=\mu \\<br>&amp;=\eta\\<br>&amp;=\theta^{T}x<br>\end{align}$$</p><p>公式第一行来自假设（2），第二行是通过高斯分布$y|x;\theta$~$ N(\mu,\sigma^{2})$计算得出，第三行是通过高斯分布的指数分布族形式表示得出，第四行即为假设（3）。</p><p>其中，将η与原始概率分布中的参数联系起来的函数成为正则相应函数（canonical response function），如$φ =\frac{1}{1+e^{-\eta}}、μ = η$即是正则响应函数。正则响应函数的逆成为正则关联函数（canonical link function）。</p><p>所以，对于广义线性模型，需要决策的是选用什么样的分布，当选取高斯分布时，我们就得到最小二乘模型，当选取伯努利分布时，我们得到 logistic 模型，这里所说的模型是假设函数 h 的形式。</p><p>最后总结一下：<font color="red"><strong>广义线性模型通过假设一个概率分布，得到不同的模型，而梯度下降和牛顿方法都是为了求取模型中的线性部分$(\theta^{T}x)$的参数$\theta$的。</strong></font></p><p><strong>多分类模型-Softmax Regression</strong></p><p>下面再给出GLM的一个例子——<strong>Softmax Regression</strong>.</p><p>假设一个分类问题，y可取k个值，即$y \epsilon{1,2,…,k}$。现在考虑的不再是一个二分类问题，现在的类别可以是多个。如邮件分类：垃圾邮件、个人邮件、工作相关邮件。下面要介绍的是多项式分布（multinomial distribution）。</p><p>多项式分布推导出的GLM可以解决多类分类问题，是 logistic 模型的扩展。对于多项式分布中的各个y的取值，我们可以使用k个参数$\phi_1,\phi_2,…,\phi_k$来表示这k个取值的概率。即</p><p>$$P(y=i) = \phi_{i}$$</p><p>但是，这些参数可能会冗余，更正式的说可能不独立，因为$\sum\phi_i=1$，知道了前k-1个，就可以通过$1-\sum_{i=1}^{k-1}\phi_{i}$计算出第k个概率。所以，我们只假定前k-1个结果的概率参数$\phi_1$,$\phi_2$,…,$\phi_{k-1}$，第k个输出的概率通过下面的式子计算得出：</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24%5Cphi_%7Bk%7D%20%3D%201-%20%5Csum_%7Bi%3D1%7D%5E%7Bk-1%7D%5Cphi_%7Bi%7D%24%24" alt="$$\phi_{k} = 1- \sum_{i=1}^{k-1}\phi_{i}$$"></p><p>为了使多项式分布能够写成指数分布族的形式，我们首先定义 T(y)，如下所示：</p><p><img src="/assets/articleImg/newton-form2.png" alt=""></p><p>和之前的不一样，这里我们的$T(y)$不等$y$，$T(y)$现在是一个$k-1$维的向量，而不是一个真实值。接下来，我们将使用$(T(y))_{i}$表示$T(y)$的第i个元素。</p><p>下面我们引入指数函数I，使得：</p><p>$$I(True)=1,I(False)=0$$</p><p>这样，$T(y)$向量中的某个元素还可以表示成：</p><p>$$(T(y))_{i}=I(y=i)$$</p><p>举例来说，当$ y=2 时，T(2)_2=I(2=2)=1，T(2)_3=I(2=3)=0$。根据公式 15，我们还可以得到：</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24E%5B%28T%28y%29%29_%7Bi%7D%5D%3D%5Csum_%7By%3D1%7D%5E%7Bk%7D%28T%28y%29%29%7B%5Cphi%7D_i%3D%5Csum_%7By%3D1%7D%5E%7Bk%7DI%28y%3Di%29%5Cphi_i%3D%5Cphi_i%24%24" alt="$$E[(T(y))_{i}]=\sum_{y=1}^{k}(T(y)){\phi}_i=\sum_{y=1}^{k}I(y=i)\phi_i=\phi_i$$"></p><p>$$\sum_{i=1}^{k}I(y=i)=1$$</p><p>下面，二项分布转变为指数分布族的推导如下：</p><p><img src="/assets/articleImg/newton-form3.png" alt=""></p><p>其中，最后一步的各个变量如下：</p><p><img src="/assets/articleImg/newton-form4.png" alt=""></p><p>由$\eta$的表达式可知：</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24%5Ceta_%7Bi%7D%3Dlog%5Cfrac%7B%5Cphi_%7Bi%7D%7D%7B%5Cphi_%7Bk%7D%7D%5CRightarrow%20%5Cphi_%7Bi%7D%3D%5Cphi_%7Bk%7De%5E%7B%5Ceta_%7Bi%7D%7D%24%24" alt="$$\eta_{i}=log\frac{\phi_{i}}{\phi_{k}}\Rightarrow \phi_{i}=\phi_{k}e^{\eta_{i}}$$"></p><p>为了方便，再定义：</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24%5Ceta_%7Bk%7D%20%3D%20log%20%5Cfrac%7B%5Cphi_%7Bk%7D%7D%7B%5Cphi_%7Bk%7D%7D%3D0%24%24" alt="$$\eta_{k} = log \frac{\phi_{k}}{\phi_{k}}=0$$"></p><p>于是，可以得到：</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24%5Csum_%7Bj%3D1%7D%5E%7Bk%7D%5Cphi_%7Bi%7D%3D%5Csum_%7Bj%3D1%7D%5E%7Bk%7D%5Cphi_%7Bk%7De%5E%7B%5Ceta_%7Bi%7D%7D%3D1%20%5CRightarrow%20%5Cphi_%7Bk%7D%3D%5Cfrac%7B1%7D%7B%5Csum_%7Bj%3D1%7D%5E%7Bk%7De%5E%7B%5Ceta_%7Bi%7D%7D%7D%24%24" alt="$$\sum_{j=1}^{k}\phi_{i}=\sum_{j=1}^{k}\phi_{k}e^{\eta_{i}}=1 \Rightarrow \phi_{k}=\frac{1}{\sum_{j=1}^{k}e^{\eta_{i}}}$$"></p><p>将上式代入到</p><p><img src="http://latex.codecogs.com/gif.latex?%5Ceta_%7Bi%7D%3Dlog%5Cfrac%7B%5Cphi_%7Bi%7D%7D%7B%5Cphi_%7Bk%7D%7D%5CRightarrow%20%5Cphi_%7Bi%7D%3D%5Cphi_%7Bk%7De%5E%7B%5Ceta_%7Bi%7D%7D" alt="$$\eta_{i}=log\frac{\phi_{i}}{\phi_{k}}\Rightarrow \phi_{i}=\phi_{k}e^{\eta_{i}}$$">，得到：</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24%5Cphi_%7Bi%7D%3D%5Cfrac%7Be%5E%7B%5Ceta_%7Bi%7D%7D%7D%7B%5Csum_%7Bj%3D1%7D%5E%7Bk%7De%5E%7B%5Ceta_%7Bi%7D%7D%7D%3D%5Cfrac%7Be%5E%7B%5Ceta_%7Bi%7D%7D%7D%7B1+%5Csum_%7Bj%3D1%7D%5E%7Bk-1%7De%5E%7B%5Ceta_%7Bi%7D%7D%7D%24%24" alt="$$\phi_{i}=\frac{e^{\eta_{i}}}{\sum_{j=1}^{k}e^{\eta_{i}}}=\frac{e^{\eta_{i}}}{1+\sum_{j=1}^{k-1}e^{\eta_{i}}}$$"></p><p>从而，我们就得到了连接函数，有了连接函数后，就可以把多项式分布的概率表达出来:</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24P%28y%3Di%29%3D%5Cphi_%7Bi%7D%3D%5Cfrac%7Be%5E%7B%5Ceta_%7Bi%7D%7D%7D%7B1+%5Csum_%7Bj%3D1%7D%5E%7Bk-1%7De%5E%7B%5Ceta_%7Bi%7D%7D%7D%3D%5Cfrac%7Be%5E%7B%5Ctheta_%7Bi%7D%5E%7BT%7Dx%7D%7D%7B1+%5Csum_%7Bj%3D1%7D%5E%7Bk-1%7De%5E%7B%5Ctheta_%7Bj%7D%5E%7BT%7Dx%7D%7D%24%24" alt="$$P(y=i)=\phi_{i}=\frac{e^{\eta_{i}}}{1+\sum_{j=1}^{k-1}e^{\eta_{i}}}=\frac{e^{\theta_{i}^{T}x}}{1+\sum_{j=1}^{k-1}e^{\theta_{j}^{T}x}}$$"></p><p>注意到，上式中的每个参数$\eta_i$都是一个可用线性向量$\theta_i^Tx$表示出来的，因而这里的$\theta$其实是一个二维矩阵。</p><p>于是，我们可以得到假设函数 h 如下：</p><p><img src="/assets/articleImg/newton-form5.png" alt=""></p><p>那么就建立了假设函数，最后就获得了最大似然估计 </p><p><img src="/assets/articleImg/newton-form6.png" alt=""></p><p>对该式子可以使用梯度下降算法或者牛顿方法求得参数$\theta$后，使用假设函数$h$对新的样例进行预测，即可完成多类分类任务。这种多种分类问题的解法被称为 softmax regression.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a><strong>References</strong></h2><ul><li><a href="http://www.phengkimving.com/calc_of_one_real_var/08_app_of_the_der_part_2/08_05_approx_of_roots_of_func_newtons_meth.htm" target="_blank" rel="noopener">Approximations Of Roots Of Functions – Newton’s Method</a></li><li>机器学习-Andrew Ng 斯坦福大学<a href="http://open.163.com/movie/2008/1/E/D/M6SGF6VB4_M6SGHKAED.html" target="_blank" rel="noopener">机器学习视频-第四讲</a></li></ul><hr><center><strong>本栏目机器学习持续更新中，欢迎来访：<a href="http://blog.csdn.net/dream_angel_z" target="_blank" rel="noopener">Dream_Angel_Z 博客</a>新浪微博： <a href="http://weibo.com/liudiwei210" target="_black">@拾毅者</a><br></strong></center><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;font color=&quot;green&quot;&gt;回头再温习一下Andrew Ng的机器学习视频课，顺便把没写完的笔记写完。&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;本节内容&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;牛顿方法&lt;/li&gt;
&lt;li&gt;指数分布族&lt;/li&gt;
&lt;li&gt;广义线性模型&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="牛顿方法" scheme="https://www.csuldw.com/tags/%E7%89%9B%E9%A1%BF%E6%96%B9%E6%B3%95/"/>
    
      <category term="指数分布族" scheme="https://www.csuldw.com/tags/%E6%8C%87%E6%95%B0%E5%88%86%E5%B8%83%E6%97%8F/"/>
    
      <category term="GLM" scheme="https://www.csuldw.com/tags/GLM/"/>
    
  </entry>
  
  <entry>
    <title>用python模拟网页数据提交</title>
    <link href="https://www.csuldw.com/2016/01/02/2016-01-02-extracte-data-from-web-server-in-python/"/>
    <id>https://www.csuldw.com/2016/01/02/2016-01-02-extracte-data-from-web-server-in-python/</id>
    <published>2016-01-02T02:24:00.000Z</published>
    <updated>2016-03-13T06:50:10.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>做实验的时候，需要将独立测试集的数据与别人server跑出来的结果进行比较，比如下面这个：<a href="http://bioinfo.ggc.org/bindn/" target="_blank" rel="noopener">http://bioinfo.ggc.org/bindn/</a> 。但是这个server一次性只能提交一个fasta文件，也就是说，我有很多数据的话，就要分多次提交。如果是人工的去操作，会比较耗时，而且工作量特别大，因此这里就需要模拟网页的数据提交。这就是本文的主要内容，</p><a id="more"></a><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>下面先来理清下思路。我的目的是通过自己构造post数据来实现数据提交。</p><p>当模拟在网页上提交数据时，首先要弄清楚整个数据处理流程，比如发送了什么样的数据，给谁发的等。那么如果我要在网页上提交数据的话，肯定是要传递参数的，所以我们要知道如何查找这些参数，这是最重要的一点。其次，模拟数据提交，必须要知道提交前的网页和提交后的网页，这样才能将提交后显示结果网页保存下来。最后就是数据处理了，使用正则表达式将需要的数据抽取出来。</p><h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><h3 id="参数分析"><a href="#参数分析" class="headerlink" title="参数分析"></a>参数分析</h3><p>关于参数，可以从数据包中分析出来，我是使用google自带的抓包工具分析的，使用ctrl+shift+I快捷键，点击进入Network列，如下图：</p><p><img src="/assets/articleImg/2016-01-01-img1.png" alt=""></p><p>可以看到，当前什么都没有，下面我将参数填写完整</p><p><img src="/assets/articleImg/2016-01-01-img2.png" alt=""></p><p>当我将数据设置好之后，点击Submit Query按钮后，结果如下图所示：</p><p><img src="/assets/articleImg/2016-01-01-img3.png" alt=""></p><p>多了一个bindn.pl文件，我们来看看这个文件的内容，看看headers部分：</p><p><img src="/assets/articleImg/2016-01-01-img4.png" alt=""></p><p>和图二进行比较，你会看到是相互对应。也就是说，这就是我们需要提交的参数：</p><figure class="highlight 1c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">postData = {'seq' : oneseq,  <span class="meta">#oneseq是一个字符串，后面作为一个参数传递进来</span></span><br><span class="line">        'qtype' : 'rna',  </span><br><span class="line">        'vtype' : 'sp',</span><br><span class="line">        'val' : '80',</span><br><span class="line">        'submit' : 'Submit Query' </span><br><span class="line">        }</span><br></pre></td></tr></tbody></table></figure><p>而点击发送后的请求URL和HTML头内容，如下图：</p><p><img src="/assets/articleImg/2016-01-01-img5.png" alt=""></p><p>所以现在我们可以得到以下这些数据（postData在上面已经分析出来了）：</p><figure class="highlight gcode"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hosturl = <span class="string">'http://bioinfo.ggc.org/bindn/'</span> </span><br><span class="line">posturl = <span class="string">'http://bioinfo.ggc.org/cgi-bin/bindn/bindn.pl'</span> <span class="attr">#可以从数据包中分析出，处理post请求的url  </span></span><br><span class="line"><span class="attr">headers = {'User-Agent' : 'Mozilla/5</span><span class="number">.0</span> <span class="comment">(Windows NT 6.1; WOW64)</span> AppleWebKit/<span class="number">537.36</span> <span class="comment">(KHTML, like Gecko)</span> Chrome/<span class="number">46.0.</span><span class="number">2490.80</span> Safari/<span class="number">537.36</span><span class="string">',  </span></span><br><span class="line"><span class="string">           '</span>Referer<span class="string">' : '</span>http:<span class="comment">//bioinfo.ggc.org/bindn/'}</span></span><br></pre></td></tr></tbody></table></figure><h3 id="Python模拟"><a href="#Python模拟" class="headerlink" title="Python模拟"></a>Python模拟</h3><p>分析结束后，我们要构造自己的HTTP数据包，并发送给指定url。我们通过urllib2等几个模块提供的API来实现request请求的发送和相应的接收。最后需要编写一个函数，将自己需要的内容抽取出来。完整代码和讲解如下如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Fri Jan 01 09:34:50 2016</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: liudiwei</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os </span><br><span class="line"><span class="keyword">import</span> urllib  </span><br><span class="line"><span class="keyword">import</span> urllib2  </span><br><span class="line"><span class="keyword">import</span> cookielib  </span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment">#首先定义一个模拟数据提交的函数，传入刚刚分析出来的四个参数即可</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scratchData</span><span class="params">(hosturl, posturl, postData, headers)</span>:</span></span><br><span class="line">    <span class="comment">#设置一个cookie处理器，它负责从服务器下载cookie到本地，并且在发送请求时带上本地的cookie  </span></span><br><span class="line">    cj = cookielib.LWPCookieJar()  </span><br><span class="line">    cookie_support = urllib2.HTTPCookieProcessor(cj)  </span><br><span class="line">    opener = urllib2.build_opener(cookie_support, urllib2.HTTPHandler)  </span><br><span class="line">    urllib2.install_opener(opener) </span><br><span class="line">    <span class="comment">#打开登录主页面（他的目的是从页面下载cookie，这样我们在再送post数据时就有cookie了，否则发送不成功）</span></span><br><span class="line">    urllib2.urlopen(hosturl)  </span><br><span class="line">    <span class="comment">#需要给Post数据编码  </span></span><br><span class="line">    postDataEncode = urllib.urlencode(postData)  </span><br><span class="line">    <span class="comment">#通过urllib2提供的request方法来向指定Url发送我们构造的数据，并完成数据发送过程  </span></span><br><span class="line">    request = urllib2.Request(posturl, postDataEncode, headers)  </span><br><span class="line">    <span class="keyword">print</span> request  </span><br><span class="line">    response = urllib2.urlopen(request)  </span><br><span class="line">    resultText = response.read()  </span><br><span class="line">    <span class="keyword">return</span> resultText </span><br><span class="line"></span><br><span class="line"><span class="comment">#将一次提交写到一个函数里面，每次只需传入一个序列即可，因为其它的参数不变</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">BindN</span><span class="params">(oneseq, outdir)</span>:</span></span><br><span class="line">    <span class="comment">#当前页面，即提交数据页面</span></span><br><span class="line">    hosturl = <span class="string">'http://bioinfo.ggc.org/bindn/'</span> </span><br><span class="line">    <span class="comment">#post数据接收和处理的页面（我们要向这个页面发送我们构造的Post数据）  </span></span><br><span class="line">    posturl = <span class="string">'http://bioinfo.ggc.org/cgi-bin/bindn/bindn.pl'</span> <span class="comment">#可以从数据包中分析出，处理post请求的url  </span></span><br><span class="line">     <span class="comment">#构造header，一般header至少要包含一下两项。这两项是从抓到的包里分析得出的。  </span></span><br><span class="line">    headers = {<span class="string">'User-Agent'</span> : <span class="string">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.80 Safari/537.36'</span>,  </span><br><span class="line">               <span class="string">'Referer'</span> : <span class="string">'http://bioinfo.ggc.org/bindn/'</span>}   </span><br><span class="line">    <span class="comment">#构造Post数据，他也是从抓大的包里分析得出的。</span></span><br><span class="line">    postData = {<span class="string">'seq'</span> : oneseq,  </span><br><span class="line">            <span class="string">'qtype'</span> : <span class="string">'rna'</span>,  </span><br><span class="line">            <span class="string">'vtype'</span> : <span class="string">'sp'</span>,</span><br><span class="line">            <span class="string">'val'</span> : <span class="string">'80'</span>,</span><br><span class="line">            <span class="string">'submit'</span> : <span class="string">'Submit Query'</span> </span><br><span class="line">            } </span><br><span class="line">    result = scratchData(hosturl, posturl, postData, headers)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"+++++"</span>, oneseq </span><br><span class="line">    chainname = oneseq[<span class="number">1</span>:<span class="number">5</span>] + oneseq[<span class="number">6</span>:<span class="number">7</span>]</span><br><span class="line">    outfilename = str(chainname) + <span class="string">'.html'</span></span><br><span class="line">    fw_result = open(outdir + <span class="string">'/'</span> + outfilename, <span class="string">'w'</span>)</span><br><span class="line">    fw_result.write(result)</span><br><span class="line">    fw_result.close()</span><br><span class="line">    <span class="keyword">return</span> result, str(chainname)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#使用正则表达式提取数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extractBindN</span><span class="params">(htmlfmt, outfile)</span>:</span></span><br><span class="line">    fw_result = open(outfile, <span class="string">'w'</span>)</span><br><span class="line">    inputdata = htmlfmt.split(<span class="string">'\n'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(inputdata)):</span><br><span class="line">        onedata = inputdata[i].strip()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> onedata:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">'&lt;'</span> <span class="keyword">in</span> onedata <span class="keyword">or</span> <span class="string">'*'</span> <span class="keyword">in</span> onedata:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        regText = onedata.split(<span class="string">'\t'</span>)[<span class="number">0</span>].strip()</span><br><span class="line">        <span class="keyword">if</span> re.match(<span class="string">r'^\d+$'</span>, regText) <span class="keyword">and</span> <span class="literal">True</span> <span class="keyword">or</span> <span class="literal">False</span>:</span><br><span class="line">            fw_result.write(onedata + <span class="string">'\n'</span>)</span><br><span class="line">    fw_result.close()</span><br><span class="line"></span><br><span class="line"><span class="comment">#main方法</span></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    oneseq = <span class="string">"&gt;2XD0_A\nMKFYTISSKYIEYLKEFDDKVPNSEDPTYQNPKAFIGIVLEIQGHKYLAPLTSPK\</span></span><br><span class="line"><span class="string">    KWHNNVKESSLSCFKLHENGVPENQLGLINLKFMIPIIEAEVSLLDLGNMPNTPYKRMLYKQLQFIRANSDKIA\</span></span><br><span class="line"><span class="string">    SKSDTLRNLVLQGKMQGTCNFSLLEEKYRDFGK"</span></span><br><span class="line">    outdir = <span class="string">"/home/liudiwei/result"</span> <span class="comment">#输出路径</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(outdir):</span><br><span class="line">        os.mkdir(outdir)</span><br><span class="line">    <span class="keyword">print</span> outdir</span><br><span class="line">    result, chainname = BindN(oneseq, outdir)</span><br><span class="line">    outfile = outdir + <span class="string">"/"</span> + chainname + <span class="string">".data"</span> <span class="comment">#最终输出的文件名</span></span><br><span class="line">    extractBindN(result, outfile)</span><br></pre></td></tr></tbody></table></figure><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;做实验的时候，需要将独立测试集的数据与别人server跑出来的结果进行比较，比如下面这个：&lt;a href=&quot;http://bioinfo.ggc.org/bindn/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://bioinfo.ggc.org/bindn/&lt;/a&gt; 。但是这个server一次性只能提交一个fasta文件，也就是说，我有很多数据的话，就要分多次提交。如果是人工的去操作，会比较耗时，而且工作量特别大，因此这里就需要模拟网页的数据提交。这就是本文的主要内容，&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://www.csuldw.com/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.csuldw.com/tags/Python/"/>
    
      <category term="正则表达式" scheme="https://www.csuldw.com/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    
      <category term="数据提取" scheme="https://www.csuldw.com/tags/%E6%95%B0%E6%8D%AE%E6%8F%90%E5%8F%96/"/>
    
  </entry>
  
  <entry>
    <title>2015，稳稳地幸福</title>
    <link href="https://www.csuldw.com/2015/12/31/2015-12-31-annual-summary/"/>
    <id>https://www.csuldw.com/2015/12/31/2015-12-31-annual-summary/</id>
    <published>2015-12-31T15:00:00.000Z</published>
    <updated>2020-04-15T15:04:51.244Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>就用这首《稳稳地幸福》作为开场白吧，希望也有一种稳稳的幸福！</p><p><em>有一天，我发现自怜资格都已没有<br>只剩下不知疲倦的肩膀<br>担负着简单的满足<br>有一天，开始从平淡日子感受快乐<br>看到了明明白白的远方<br>我要的幸福……</em> </p><a id="more"></a><p>不知道从什么时候起，渐渐地开始喜欢安静，喜欢自言自语，喜欢胡思乱想，喜欢对着电脑敲打着键盘写着自己想说的话。也好，算是自己一种放松的方式吧。</p><p>2015对我来说是一个充满着故事的数字，装载了很多回忆，有美好的，当然也有难忘的。经历了很多，明白了许多，周围的人也在不断的发生变化，最明显的便是大学四年的室友也结婚了。这个话题似乎比较沉重，在这里就不谈了吧，归根结底，还是自己经历的太少了。</p><p>今年从研一进入了研二，过的很快，当你还没感觉到正式开始的时候，研究生生涯就已经过半了，同时也过了一整年。幸运地是，在研一期间收获了一群小伙伴。其实我很怀念今年三月的那段时间，实训的时候，一群实验室的同学经常上完实训课就结伴去食堂旁边的餐厅点菜，一边吃饭一边聊天，随便开玩笑，没有什么顾虑，有种亲切随和心安的感觉，当然还有一种大家庭的味道。当自己难过的时候，还有一群兄弟朋友在旁边陪伴，虽然偶尔会开下玩笑，但还是挺好的。虽然从四月开始，大家都纷纷出去实习了，但几个同城的小伙伴偶尔聚一次，搞点活动，过的倒也蛮潇洒。如果让我用一句话来形容我们的话，我会引用《速七》里面的一句话“we are not friends, we are family”。</p><p>言归正传，还是来总结一下今年的生活吧。说到总结，对于还生活在学生时期的我来说，学习是个不可逃避的话题，那么索性就先从学习开始吧。14年的时候，只是简单的学习了数据挖掘，当时拿着韩家炜的那本《数据挖掘概念与技术》就开始漫无目的的去看，很吃力，同样也很难理解，效果也不好，“万事开头难”确实是如此。一学期后，对算法并没有深入了解，然后就不了了事了。这次，乘着三月份之后大部分课程完结了，打算全面地重新学习下常用的算法知识。因而自从实训结束后，就全心地投入到ML的学习中了。看视频跑代码做实验等等，学习斯坦福大学AndrewNg的ML视频教程，还有《统计学习方法》，《机器学习实战》以及相关的Python机器学习库等，还买了很多的书籍，大多是与ML相关的书籍，也有和Linux相关的。虽然这个过程很艰苦，但慢慢的还是坚持了下来，对机器学习也有了进一步的认识，比如什么时候会发生overfiting，如何降低overfiting，又如何提高一个算法的robust等，说到底好的数据比算法更加重要吧，只是现在感觉缺乏一些实践。四月份，因为导师让我带本科生的云计算实验课，所以就顺便初步学习了Hadoop，但并没有深入，只是简单的配置了一下，了解了下Hadoop的文件系统HDFS。后来在博客里写了很多的博文，大多是和ML有关的（都是比较基础的），也有一些与python、Linux、R有关的文章，目前CSDN博客的访问量上升至7w+，主要还是给自己留一个空间，以后回头看的时候会有一些小成就感吧！也因此被CSDN的一个编辑人员发现。随后便成了CSDN云计算专栏的一名机器学习兼职翻译人员，开启了一段翻译旅程，主要负责将国外近期的机器学习优秀博文翻译成中文。时至今日，大概翻译过30余篇文章吧，受益匪浅，感触颇多。</p><p>五月下旬的时候，忘记是从哪儿冒出的灵感，突然脑子就产生了一个想法，决定搭建一个属于自己的博客，专门用来记录自己的学习与生活。所以在接下来的业余时间，就开始搭建了自己的<a href="http://www.csuldw.com">个人博客</a>。其实这个经历还是够呛的，起初自己很多东西都不知道，跟个小白没什么两样，比如域名解析、Git、VPS之类的也只是听过，没有实践过，有的只是一个目的（搭建博客）。然后听别人说到了WordPress，接着自己就去查阅资料，还花了点钱租了一个VPS并买了一个域名——csuldw。其实这个域名取名也是讲究了下，前三个字目csu表示Central South University，ldw是我名字的拼音首字母，很容易记的，然后就在VPS中搭建了一个WordPress个人博客，但使用WordPress搭建的博客挂在VPS上的访问速度真的不行，另外需要管理的东西太多了，也不方便发文章，现在连VPS账号都忘记了。无奈之下又去查资料，根据网上的推荐，就使用Jekyll搭建了一个静态博客，当时对这个主题还算满意。没过多久，想对主题进行修改，可是发现修改起来很困难（其实是自己对前端知识了解的不多）。最后，干脆再次换样式，换框架，然后便使用一款基于nodejs的Hexo框架在GitHub上搭建了一个纯静态博客。经过几番折腾之后，主题也修改好了，博客也就诞生了，自己也从一个Git小白慢慢地熟悉了Git，而且对Markdown的使用也越发熟练了，撰写笔记更加方便多了。一个小博客，算是今年的一个小成果吧，内容慢慢再充实。使用github搭建的静态博客，遇到的一个很直接的问题就是图片加载的比较慢，介于这一点，可以将图片上传到其它的图床中或是新浪相册，只要能够获取到图片的链接就OK了，说到底这个还是自己体验上的一个小强迫症吧。</p><p>下面是5月26日写下的日记，博客的缘由原来是这样的：</p><blockquote><p>2015.05.26 今天上午看了机器学习的“贝叶斯”部分，朴素贝叶斯比较简单，后来就去打印室帮一个在外地的在职研究生打印毕业论文。吃了中饭后无意间在网上看到说作为一个大学生，就应该有一个专属于自己的博客。带着一种学习的心情，去网上买了域名，租了一个美国的VPS，然后使用WordPress搭建了一个属于自己的博客。整个过程碰到了些许问题，然后请教横天的客服，原来是我这边网络的问题，后来就把VPS换成香港的，网速也上去了。很开心~不过由于WordPress是使用php编写的，而我学的是java，很多东西不是很懂，看来以后有时间得好好学习学习。然后自己又折腾了下github，因为看到一位大牛pluskid现在使用的是static 的blog，使用的是github，然后我折腾了好久，没折腾好。算了，先用着WordPress吧，等到以后那天也成“大牛”了，也换个地方折腾折腾。现在主要是能写下东西就ok了。中午没休息，好累，回去睡觉去了。</p></blockquote><p>说了这么多，在学习上其实还有一件虐心事，折腾了好几个月了，也就是论文，很揪心。七月份开始睡实验室，跑实验，开始是在自己电脑上面跑，几天没关机，电脑硬盘直接挂掉了，后来直接网购了一个SSD硬盘，换了原来的硬盘，把原来的硬盘撞在了光驱位用来存放临时数据，开机和关机都快了很多，心情一下子就愉快了。八月份跑完实验后就开始写论文，投稿的经历就不说了，结果就是至今还在大修，接下来还需要继续做实验，慢慢改吧，有时候做梦都在调参数，希望能够早点做完吧，然后顺利的出去实习！不过在这方面真的要感谢一下自己的导师，不仅耐心的指导我们，还特别地亲民和善，很nice的一位老师。说到论文，自己从实验中还是学到了很多东西。从数据集的处理，到特征选取，然后如何去处理不均衡数据问题，再到算法的使用、选择、评估。整个流程重复了好多遍，很多原本对理论模棱两可的知识都进一步理解了。比如评估指标的计算、ROC曲线的绘制以及scikit-learn的使用等，收获算是比较大吧。八月之后，从九月开始，大大小小的事情确实比较多了，自己能够安排的时间并不多，可现在回头一想，这段时间也并没有做出什么成果，一直处于瞎忙的状态，结果也就是“郁郁而终”了。其实起初我对自己的时间是有计划的，只是突如其来的事情太多，再加上看论文作报告修改论文等等，一下子一个学期就过去了。唯一值得欣慰的就是拿到了今年的研究生国奖，“否极泰来，物极必反”，大概就是这样的吧。敲门声响起无数次，其它的都是诱惑，只有一次是机会，估计是把今年的运气都集在这里了。突然想到了那句话“上帝为你关上一扇门的同时,还打开了一扇天窗”！</p><p><img src="/assets/articleImg/2015-12-31-desktop.jpg" alt="fdsfsf"></p><div class="caption">『上图是三月底的桌面，下图是十二月底的桌面，多了很多的书籍.』</div><p>在学习上还有一件让我印象比较深而且很难忘的事情，那就是今年一月下旬那会儿做的事情，应导师之需去配置实验室的cluster（集群）。当时自己压根就不知道cluster是什么，然后就去配置。当然，这里的cluster并不是大家常说的Hadoop，而是Torque，一种用于高性能计算的cluster。当时凭着之前自学的Linux知识，就从装系统开始，一步一步的去配。开始是在实验室的三台台式机器上做测试，只记得那会儿出错后就重装系统，很笨很笨的方式，遇到问题也只能去Google搜索，而那会儿对英文有种莫名恐惧的feel，想必大多数人都有过这种feel！经过几天之后，这三天机器配好了，然后就去配置服务器上的机器，一共开了62台虚拟机器，就我一个人，当时还是个小白，有问题也只能去Google。现在回想下，都不知道自己当时是怎么熬过来的，所幸还是把所有服务器配好了。最后集群之间可以通过NFS进行文件共享，还使用NIS对用户进行统一管理，只是对软件没有使用统一的管理方式，比如现在需要安装一个python库，那么我就需要给所有的机器都安装一遍，工作量太大，不科学。现在也想到了一种解决方法，就是将python安装在一个共享目录下，所有的库也安装在在此目录下，然后把这个目录mount到其它节点中，理论上是可以解决的。只是自那之后就没有对系统进行升级了，有时间再去折腾吧！！！</p><p>最近应导师之需，让我想个方法把今年大家做的报告PPT集中起来，比如新建一个百度云账号，或者在我们的服务器上建立一个公共文件夹等。起初我自己想到的是在Github上面建立一个仓库，然后让大家都把东西上传到上面去，也比较方便，但是考虑到Github上面的仓库都是公共的（私有的需要付费），所以这个念头从一开始就被自己全盘否决了。后来想，在服务器上弄个ftp服务器怎么样呢？就这样一个想法，剩下的就是如何去实现。记得之前也有这个想法，五月份的时候，不过那时用的外网的服务器是学校的机器，因为当时配置完SELinux时重启了服务器，后来导致半个小时没启动成功。下面是当天的日记：</p><blockquote><p>2015.05.28 今天按照导师的要求在学校的服务器上挂载了我们自己内网服务器上的两个共享文件夹，成功了。后来导师说装一个Samba吧，我正打算在学校的服务器上装的时候，安装完了还没有配置，需要重启机器，我就使用reboot重启了，结果服务器启动不了了。我就纳闷了，这怎么可能。然后我就跟管理服务器的史大牛汇报了一下，因为他在北京，所以不能处理，就跟管理这台服务器的周老师说了。这不说还好，一说就被骂了。因为周老师都不知道我们有这台服务器的权限，这台服务器的密码还是史给我们的，这下把他坑惨了。差点把他从北京坑回来了。所幸没什么事，过了没多久服务器启动成功了。然后周老师把密码都给改了，因为我们实验室的路由器的网络和实验室服务器的网络是两个不同内网，不在一个局域网，使用PuTTY登陆不上去。之前是因为学校的服务器接了多个网卡，我们可以通过先登录到学校的服务器上，然后通过内网透析使用SSH切换到我们自己的服务器上，现在好了，没权限了，让给我们开个非root用户当做登陆用户都不肯，导师说学校那帮人最懒了，一点也不假呀，占着资源不肯放。然后晚上跟导师群聊了下，导师说我们干脆自己再买一台服务器算了，免得用学校的到时候出问题了又赖在我们头上。汗，只能这样了，加油吧，多学点linux操作~fighting！！！</p></blockquote><p>周老师将服务器密码改了之后，最后导师就干脆自己买了一台服务器。因为这台服务器的大多配置都是我配的，比较了解。因为对其他机器没什么依赖，所以重启机器也不会出任何问题。于是就打算在这台服务器上配置一个FTP服务器。因为配置服务器当天中午开完组会之后没休息，所以从开始到最后，用了将近一个下午的时间。碰到的一个比较简单的问题就是端口设置，如何让防火墙开放某个端口。去年自己在虚拟机上的centos6.5系统配置过这个，当时是直接将防火墙关闭掉，但现在考虑到安全问题，所以不能这么做了。其实只要弄懂了思路，整个配置也就显得简单了。如果默认端口号是21的话，可以直接直接访问<code>ftp://192.168.12.12</code>，不过我在配置vsftpd的时候修改了端口，所以需要在ip地址后面加上端口号，也就是类似这种<code>ftp://192.168.12.12:9999</code>。配置的时候，在细节上也碰到一些问题，不过通过google还是很容易就搜到结果的。总的来说，得到了一个小道理：对于小白来说，就是用时间去攒经验，用时间去买教训，所以必须自己去动手实践，这样才能得到更加直观的结果。而我希望我能够尽最大的速度攒更多的经验，买更多的教训。学习就是一个不断升华的过程，以前看似复杂而困难的问题，当你在相关知识上达到一定深度之后，它们都将随之而变的简单。现在能做的就是不断的去练习、去实践，然后去总结，化教训为经验！</p><p>今年做过很多次小组报告，大多时候讲的主题都是与课题相关的论文。有时候自己在作报告的时候也会紧张，因为先前准备的不充分，很多论文中的东西还来不及理解，有时甚至连文章中的核心思想都还没完全弄懂，讲出来之后，大家可能也很迷惑。通过多次的锻炼，在这方面还是有了很大的提升，给我的教训就是：要做好一个报告，前提是自己要对这个报告主题内容详熟，能够达到那种完全脱稿的水平就再好不过了。这里说的脱稿并不是不看ppt，而是不要对着ppt上面的内容进行实读，要能够用自己的话进行总结，进行归纳，通过一个主题，自己能够扩展其他的内容，然后将语言表达通顺就OK了。在多次的报告讲解中我发现，如果是讲解自己的论文，那么完全不需要做太多的准备，毕竟整个实验过程自己都知道。另外，每次在讲解服务器的时候，思路很清晰，讲起来也很顺手，可能也是因为熟悉的原因吧！但是大家能不能听懂，又是另外一回事了吧，事实上我觉得听完之后能有个概念也就差不多了。</p><p>谈完学习，下面来说说与娱乐有关的吧。很遗憾，今年并没有去过多少地方游玩，离学校最远的地方也只是张家界（虽然离家很近，但我却从未去过），走得较多的还是市内的景点吧，去过植物园，爬过岳麓山，逛过橘子洲等，还回过几次农大，摘过草莓，看过枫叶，顺便在校园里散散心。其实并不是自己不想出去，而是今年压根就没闲下来，或者说是自己不想闲吧。一方面，时间确实比较紧，一直奔波在宿舍与实验室之间，更多的是想多学点东西；另一方面，自己今年也确实没计划过要去别的地方，然后很快地一年就过了。曾经自己也想过要去哪些地方，走哪些路，看哪些风景，想在某年某月某一天，背起行囊去流浪。就这样，一个人，一个背包，还有一颗毅然行动的心，去一个陌生的地方。曾想象，一个人留恋于古色古香的苏杭，闲游于景色迷人的西湖，雷峰塔下，断桥旁边，坐于亭中观看行人匆匆，烟雨濛濛。提一壶新茗，浪迹天涯，悠然地寻找江南文化的气息。曾期待，一个人游走在车水马龙的外滩，越过黄浦江眺望远方的东方明珠，在一片灯红酒绿迷人的世界里，感叹着时代的变迁。曾盼望，一个人站在魅力弥漫的日光城下，看着那神圣的布达拉宫，听颂着来自上天的独白，随着飘动的经幡，传到遥远的他方。曾渴望，一个人漫步于浪漫之都，仰望埃菲尔铁塔，身处薰衣草花海，品尝法式甜点，惊叹画家之笔，触摸着法兰西风情熏陶下香榭丽舍的梧桐树。曾梦想，一个人浪迹在伦敦街头，乘一辆红色双层巴士，与阿狸一同探寻永远站的方向。然后寻一家小店，品位正宗英国红茶带来的英伦历史的沉淀，感受风雨后之的痕迹。就这样，一个人，一座城。然而，后来慢慢地变得开始理性了，渐渐地想的也多了，明白的东西也多了。那么还是让我现实点，踏实地做该做的事情吧！突然想到那句，“累就对了,舒服是留给死人的！”，是的，加油吧！时机到了，会有机会出去的（算是给自己一个安慰吧T_T！）。只需记住，越有故事的人越沉静简单，越肤浅单薄的人越浮躁不安。每一个优秀的人，都有一段沉默的时光。</p><p>相比于游山玩山，今年做的最多的娱乐活动就是看电影了。回想了下，三月看了《帕丁顿熊》，四月看了吴京主演的《战狼》，还有《速度与激情7》，五月看了《何以笙箫默》，七月月看了《捉妖记》，八月看了《大圣归来》、九月看了《港囧》与《碟中谍5神秘国度》，十月看了《夏洛特烦恼》、《小王子》以及《蚁人》，就这些，有搞笑的，也有比较敷衍人的，总的来说还是比较开心，算是弥补了今年没有外出游玩的自己吧！还记得九月下旬那会儿，中秋在即，去了大学母校拜访了文静姐，一个正在享受着当母亲的老师。晚上请我吃了一顿大餐，还送给我一提月饼，感觉好幸福，所以我从来都不去羡慕别人家的老师啦^_^！十一月回农大看枫叶，逛了下校园，然后去红旗市场的溜冰场玩了一会儿，那时那地那景那情，缠绕于指尖，记忆犹深！其实我的爱好也很多的，比如摄影、爬山、溜冰、打桌球、唱K（属于瞎吼的那种）等等，当然也包括了学习（必要时还是得装一下，虽然装的不像）。只是现在除了想学好点，似乎对其它的东西都渐渐地失去了以往的热情，没有了那份心思和真诚，简单地说就是心不在此吧。都说在外待太久，会比较想家，可能我属于异类，回头想想，从过年后回校到现在，中途只回家待了三天，而且还待不住。比往年少了很多，以前至少暑假会回去，各方面的原因都有，可能真是因为自己长大了。其实长大并不可怕，可怕的应该是遗忘吧。</p><p><img src="/assets/articleImg/2015-12-31-movie_all1.jpg" alt=""></p><div class="caption">『今年保留的所有电影票，与以往比较，多了很多.』</div><p>今年并没有得什么大病，只是生过两次小病，并无大碍，但生病的时候还是让人很难受的。一次是在六月底七月初的时候，由于喉咙发炎，接着引发了感冒，发烧，然后头晕，后来连噎食喉咙都痛，大夏天的真是受罪。另外一次是十二月，也是喉咙发炎，不过幸好及时吃了消炎药，没有恶化，第三天就好了。可前些日子，突然心脏部位略微阵痛，算是尝到了什么叫心痛，真正的心痛，应该是最近太累了，一个本命年，过的真是受罪。恩，对，本命年，已经二十四了！！！希望明年的自己能有一个健康的身体吧。写到这里，不禁地想总结一下自己今年的作息。从三月实训开时，早上八点半到晚上五点半待在机房，晚上直到十点多才离开实验室，持续到27号实训结束，一个月只外出三次，一次农大，一次植物园，一次新校区。四月，外出看过两次电影。五月接待同学一天，然后张家界来回三天。六月全月不外出。七月开始睡实验室，中途和小伙伴们聚餐一次，外出看电影一次。八月开始赶论文到中旬，加班至一两点。中下旬接待同学，外出两天，随后搬往宿舍休息。九月回家待了三天，同学聚餐一次，外出看电影两次，农大探望老师一次。十月导师组织烧烤活动一次，外出看电影三次。十一月去农大看枫叶一次。十二月同学结婚，外出两天。其余时间都待在了实验室。对我来说，似乎没有假期与周末可言吧，每天都是一样的日子，千篇一律，有时待到十一点左右才回去，还是那句话，“累就对了，舒服是留给死人的！”。一年的实验室生活，碰到过很多问题，也学到了很多。每一位苦行僧的背后大概都有一段不为人知的往事吧。事实上，如果自己想休息，倒也可以给自己放个假，自由但不放纵，收敛自如，感觉还是很自在、很舒服！毕竟除了待在实验室，也没有其他的地方可以去，似乎到了这里情绪有些低落！！！！</p><p><img src="/assets/articleImg/2015-12-31-lab-morning.jpg" alt=""></p><div class="caption">『某天早晨，阳光从对面楼层的玻璃反射到我的卓子上，很温暖，特别的温馨.』</div><p>今年参与的活动不多，除了四月的时候研会举行的那次“最强班集体活动”外，还有一次就是十月中旬左右导师组织的野外烧烤了，其它的就是同学聚餐之类的。回想下四月份，那时的我还算比较积极，参加了好几个比赛项目，有的还拿到了第一名，不过不是个人赛啦。最后我们1402班拿下了冠军，奖励了400大洋呀，钱没发下来就先出去吃了顿好的，算是意料之外的收获吧。另外，印象比较深刻的就是那时的抽奖活动，至今都记忆犹新。也就是那些跟我一起的小伙伴每个人都抽到了奖品，唯独我没抽到，想必我应该就是那个传说中万中无一的人了(<em>^__^</em>)……。这应该不是巧合，运气太背了，于是乎“本命年”似乎又躺枪了，(^__^) ……。十月那会儿的烧烤活动，是由导师发起的，不过烧烤食物的原材料是由我和其他几个人一起去超市购买的。因为是第一次买这些食材，没有经验，份量更是不好估计，所幸最后大家都吃完了，关键是大家开心就好！</p><p>事实上，每个人都有不开心的时候，我也一样，但我的不开心，我的难受，我都尽量留给了自己。只是很多时候，那些安慰别人的话，怎么也安慰不了自己。原因不详，有待细查！那么在这里，就让所有不开心的事情随着2015的离去而过去吧！似乎是从今年五月起，慢慢地开始戒掉了QQ、微信这些社交网络，不会再刻意地去翻阅手机动态，不再专注于回复别人或是查看别人的回复，开始做一个沉默寡言的人，事不关已的事也无需多去关心，只是偶尔会在Sina这样一个安静的人少的地方水水心情！现在，也已习惯了这种节奏，晚上回到宿舍，洗漱完之后也不再会像以往那样经常刷状态，反倒是给自己省下了很多时间做其他的事情！我的计划是明年上半年就出去实习，如果能够早点学校这边的事情搞完，自己也就多点时间复习面试知识。“没有三两三，哪敢上梁山”嘛，掂量掂量自己的水平，提前做好面试准备，也好有个心理准备。可能很多人都觉得我学的好，不过，自己到底有几斤几两，水深还是不深，自己还是有自知之明的，能够将自己80%的好表现出来就行了。Remember，你所恐惧的东西，最终都将变成你的弱点！每当一个人独处的时候，总会想到很多的事情。过去，现在，未来，总有自己可想的事。现在的我，更多的是希望好好把技术学扎实，锻炼好自己各方面能力吧。之前就说过这样一句话，“对现在的自己要求高点，就是给未来的自已最好的礼物！”，一点都没错。相信自己！每当翻阅浙大张弛原和张睿卿两位大牛的文章，总给我一种奋勇向上的激情。如果自己的知识能够达到一定的深度，即便是苦点累点或是慢点，也值了！自己选择的路，跪着也要走完。</p><p><img src="/assets/articleImg/2015-12-31-huatian.jpg" alt=""></p><div class="caption">『今年十二月，大学室友结婚接新娘的那天早上在华天酒店拍的，当时还没系腰带.』</div><p>今年结婚的同学有两个，一位是大学时候的班长，一位是大学的一位室友。一个在二月，一个在十二月，很喜庆，一年好始好终的过了！班长结婚是在常德石门，因此几个有空的同学就跑到常德石门去祝福了，虽说参加别人的婚礼就像是花钱去看别人虐狗（开个玩笑），但有空还是要去的啦，至少还可以当个演员嘛^_^。在大学室友结婚那天也是挺开心的，当了一回伴郎。当伴郎收获比较多的就是，对整个婚礼的流程都了解的很清楚，当地的习俗也知道个大概。身为伴郎，在当天的酒席上并没有吃饭，只记得那天喝的有点多。那种酒席上的玻璃杯，喝了三大半杯白酒，只不过当伴郎喝酒也是没办法的事！随后应新郎支托给同学们开了间麻将房，接着去他们打麻将，自己就在里面睡了一下午，后来大脑虽然清醒，但真的很是难受，半醉半醒的状态更是不堪回首。毕竟我也是不喜欢喝酒的，当然也不抽烟，更谈不上喜欢了。说到吃的，其实我并不挑食，草莓，香蕉，水龙果，橘子好多水果都吃，喜欢喝咖啡，奶茶，绿茶，还喜欢嗑瓜子，最近又喜欢上夏威夷果子，而对巧克力也是无法抗拒的。以前还喜欢吃各类糖果，算一算也是蛮多的。只是如今一天到对着电脑，也顾不上吃这些水果零食了。说到大学同学，自从班长结婚之后，今年就很少聚了，大家交流的也很少了。一方面，大家应该都很忙吧，各自忙各自的，就像我一样。另一方面，可能班长结婚后，没有一个好的据点了吧！另外，听说有位同学已经奉子领证了，果真是士别三日当刮目相待呀！！！</p><p><img src="/assets/articleImg/2015-12-31-tiedao1.jpg" alt=""></p><div class="caption">『学校的西门，摄于某个晴空万里的冬天下午.』</div><p>来到中南，步入一个新的地方，认识了新的同学，结交了新的朋友，进入了一种新的学习状态，一年又半载，很多事情都在不经意间就开始了，而我也早已习惯了这里的生活！数落着剩下的研途生涯，希望自己能够学到更多的东西吧。烟雾蒙蒙的今晚，已经看不到点点繁星了，望着天空残寂的孤月，明亮中夹带着些许凄美，些许迷离。唏嘘的叹息，在这无眠清寂的长夜里，留下无数的落寞。过往的点滴，都渐渐的在遗逝的记忆里沉淀。走过了似水流年，看过了风花雪月，曾经有一段时光，做了温馨的梦，曾经有一场梦，沧桑中透着凄凉，曾经也有一座城市，却成了一生的梦。夜已深，心已静，默默的守候着今年最后的一点时光，就此成为往后的回忆。。。</p><p><img src="/assets/articleImg/2015-12-31-bagong.jpg" alt=""></p><div class="caption">『执着忠厚的八公.』</div><p>总之，好好奋斗吧……</p><p><em>我要稳稳的幸福<br>能抵挡失落的痛楚<br>一个人的路途<br>也不会孤独</em>  </p><p>2016年，祝大家新年快乐！同时也希望自己在新的一年能有一个好的开始！</p><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;就用这首《稳稳地幸福》作为开场白吧，希望也有一种稳稳的幸福！&lt;/p&gt;
&lt;p&gt;&lt;em&gt;有一天，我发现自怜资格都已没有&lt;br&gt;只剩下不知疲倦的肩膀&lt;br&gt;担负着简单的满足&lt;br&gt;有一天，开始从平淡日子感受快乐&lt;br&gt;看到了明明白白的远方&lt;br&gt;我要的幸福……&lt;/em&gt; &lt;/p&gt;
    
    </summary>
    
      <category term="年度总结" scheme="https://www.csuldw.com/categories/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="总结" scheme="https://www.csuldw.com/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>25个Java机器学习工具&amp;库(译)</title>
    <link href="https://www.csuldw.com/2015/12/25/2015-12-25-25-Java-Machine-Learning-Tools-&amp;-Libraries/"/>
    <id>https://www.csuldw.com/2015/12/25/2015-12-25-25-Java-Machine-Learning-Tools-&amp;-Libraries/</id>
    <published>2015-12-25T14:24:00.000Z</published>
    <updated>2016-03-08T09:04:26.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本列表总结了25个Java机器学习工具&amp;库：</p><ul><li>原文地址：<a href="http://bigdataanalyticsnews.com/25-java-machine-learning-tools-libraries/" target="_blank" rel="noopener">25 Java Machine Learning Tools &amp; Libraries</a></li><li>CSDN译文链接：<a href="http://www.csdn.net/article/2015-12-25/2826560" target="_blank" rel="noopener">http://www.csdn.net/article/2015-12-25/2826560</a></li></ul><a id="more"></a><p>1.<a href="http://www.cs.waikato.ac.nz/ml/weka/" target="_blank" rel="noopener">Weka</a>集成了数据挖掘工作的机器学习算法。这些算法可以直接应用于一个数据集上或者你可以自己编写代码来调用。Weka包括一系列的工具，如数据预处理、分类、回归、聚类、关联规则以及可视化。</p><p>2.<a href="http://moa.cms.waikato.ac.nz/" target="_blank" rel="noopener">Massive Online Analysis</a>（MOA）是一个面向数据流挖掘的流行开源框架，有着非常活跃的成长社区。它包括一系列的机器学习算法（分类、回归、聚类、异常检测、概念漂移检测和推荐系统）和评估工具。关联了WEKA项目，MOA也是用Java编写的，其扩展性更强。</p><p>3.<a href="http://meka.sourceforge.net/" target="_blank" rel="noopener">MEKA</a>项目提供了一个面向多标签学习和评价方法的开源实现。在多标签分类中，我们要预测每个输入实例的多个输出变量。这与“普通”情况下只涉及一个单一目标变量的情形不同。此外，MEKA基于WEKA的机器学习工具包。</p><p>4.<a href="https://adams.cms.waikato.ac.nz/" target="_blank" rel="noopener">Advanced Data mining And Machine learning System</a>（ADAMS）是一种新型的柔性工作流引擎，旨在迅速建立并保持真实世界的复杂知识流，它是基于GPLv3发行的。</p><p>5.<a href="http://elki.dbs.ifi.lmu.de/" target="_blank" rel="noopener">Environment for Developing KDD-Applications Supported by Index-Structure</a>（ELKI）是一款基于Java的开源（AGPLv3）数据挖掘软件。ELKI主要集中于算法研究，重点研究聚类分析中的无监督方法和异常检测。</p><p>6.<a href="http://mallet.cs.umass.edu/" target="_blank" rel="noopener">Mallet</a>是一个基于Java的面向文本文件的机器学习工具包。Mallet支持分类算法，如最大熵、朴素贝叶斯和决策树分类。</p><p>7.<a href="http://www.heatonresearch.com/encog" target="_blank" rel="noopener">Encog</a>是一个先进的机器学习框架，集成了支持向量机（SVM）、人工神经网络、遗传算法、贝叶斯网络、隐马尔可夫模型（HMM）、遗传编程和遗传算法。</p><p>8.<a href="http://www.datumbox.com/" target="_blank" rel="noopener">Datumbox</a>机器学习框架是一个用Java编写的开源框架，允许快速地开发机器学习和统计应用。该框架的核心重点包括大量的机器学习算法以及统计测试，能够处理中等规模的数据集。</p><p>9.<a href="http://deeplearning4j.org/" target="_blank" rel="noopener">Deeplearning4j</a>是使用Java和Scala编写的第一个商业级的、开源的、分布式深入学习库。其设计的目的是用于商业环境中，而不是作为一个研究工具。</p><p>10.<a href="http://mahout.apache.org/" target="_blank" rel="noopener">Mahout</a>是一个内置算法的机器学习框架。Mahout-Samsara帮助人们创建他们自己的数学，并提供了一些现成的算法实现。</p><p>11<a href="https://rapidminer.com/" target="_blank" rel="noopener">Rapid Miner</a>是德国多特蒙特技术大学开发的。它为开发者开发应用程序提供了一个GUI（图形用户界面）和Java API。它还提供了一些机器学习算法，用来做数据处理、可视化以及建模。</p><p>12.<a href="http://samoa.incubator.apache.org/" target="_blank" rel="noopener">Apache SAMOA</a>是一个机器学习（ML）框架，内嵌面向分布式流ML算法的编程抽象，并且允许在没有直接处理底层分布式流处理引擎（DSPEe，如Apache Storm、Apache S4和Apache samza）复杂性的情况下，开发新的ML算法。用户可以开发分布式流ML算法，而且可以在多个DSPEs上执行。</p><p>13.<a href="http://neuroph.sourceforge.net/" target="_blank" rel="noopener">Neuroph</a>通过提供支持创建、训练和保存神经网络的Java网络库和GUI工具，简化了神经网络开发。</p><p>14.<a href="http://oryx.io/" target="_blank" rel="noopener">Oryx 2</a>是一个建立在Apache Spark和Apache Kafka的Lambda架构实现，但随着实时大规模机器学习而逐渐开始专业化。这是一个用于构建应用程序的框架，但也包括打包，以及面向协同过滤、分类、回归和聚类的端到端的应用程序。</p><p>15.<a href="http://nlp.stanford.edu/software/classifier.shtml" target="_blank" rel="noopener">Stanford Classifier</a>是一个机器学习工具，它可以将数据项归置到一个类别。一个概率分类器，比如这个，它可以对一个数据项给出类分配的概率分布。该软件是最大熵分类器的一个Java实现。</p><p>16<a href="http://www.cortical.io/" target="_blank" rel="noopener">io</a>是一个Retina API，有着快速精确的类似大脑的自然语言处理算法。</p><p>17.<a href="https://github.com/EdwardRaff/JSAT/tree/master" target="_blank" rel="noopener">JSAT</a>是一个快速入门的机器学习库。该库是我在业余时间开发的，基于GPL3发行的。库中的一部分内容可自主学习，例如所有的代码都是独立的。JSAT没有外部依赖，而且是纯Java编写的。</p><p>18.<a href="http://nd4j.org/" target="_blank" rel="noopener">N-Dimensional Arrays for Java(ND4J)</a>是一个用于JVM的科学计算库。它们是用来在生产环境中使用的，这表明例程的设计是以最小的内存需求来运行的。</p><p>19.<a href="https://www.openhub.net/p/8582" target="_blank" rel="noopener">Java Machine Learning Library</a>（Java机器学习库）是一系列机器学习算法的相关实现。这些算法，无论是源代码还是文档，都编写的很出色。其主要语言是Java。</p><p>20.<a href="http://java-ml.sourceforge.net/" target="_blank" rel="noopener">Java-ML</a>是一个使用Java编写的一系列机器学习算法的Java API。它只提供了一个标准的算法接口。</p><p>21.<a href="http://spark.apache.org/mllib/" target="_blank" rel="noopener">MLlib(Spark)</a> 是Apache Spark的可扩展机器学习库。虽然是Java，但该库与平台还支持Java，Scala和Python绑定。此库是最新的，并且算法很多。</p><p>22.<a href="https://github.com/h2oai/h2o-3" target="_blank" rel="noopener">H2O</a>是用于智能应用的机器学习API。它在大数据上对统计学、机器学习和数学进行了规模化。H2O可扩展，开发者可以在核心部分使用简单的数学知识。</p><p>23.<a href="https://github.com/WalnutiQ/wAlnut" target="_blank" rel="noopener">WalnutiQ</a>是人脑部分面向对象模型，有着理论常用的学习算法（正在向简单强烈的情感人工智能模型方向研究）。</p><p>24.<a href="http://sourceforge.net/p/lemur/wiki/RankLib/" target="_blank" rel="noopener">RankLib</a>是一个排名学习算法库。目前已经实现八种流行的算法。</p><p>25.<a href="https://github.com/numenta/htm.java" target="_blank" rel="noopener">htm.java</a>（基于Java的Hierarchical Temporal Memory算法实现）是一个面向智能计算的Numenta平台的Java接口。<a href="http://www.demnag.com/b/java-machine-learning-tools-libraries-cm570/" target="_blank" rel="noopener">源码</a></p><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本列表总结了25个Java机器学习工具&amp;amp;库：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原文地址：&lt;a href=&quot;http://bigdataanalyticsnews.com/25-java-machine-learning-tools-libraries/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;25 Java Machine Learning Tools &amp;amp; Libraries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;CSDN译文链接：&lt;a href=&quot;http://www.csdn.net/article/2015-12-25/2826560&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://www.csdn.net/article/2015-12-25/2826560&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="译文" scheme="https://www.csuldw.com/tags/%E8%AF%91%E6%96%87/"/>
    
      <category term="框架&amp;库" scheme="https://www.csuldw.com/tags/%E6%A1%86%E6%9E%B6-%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>LeetCode部分题解</title>
    <link href="https://www.csuldw.com/2015/12/12/2015-12-12-LeetCode-ans/"/>
    <id>https://www.csuldw.com/2015/12/12/2015-12-12-LeetCode-ans/</id>
    <published>2015-12-11T16:00:00.000Z</published>
    <updated>2017-01-09T07:30:06.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文是先前做LeetCode时的部分题解，有的题目既包含C++代码，也有Python代码，为方便查阅，决定将这些思路合并到一文之中。</p><p><img src="/assets/articleImg/2015-12-12-leetcode.png" alt="leetcode"></p><a id="more"></a> <p>题解目录如下：</p><ul><li><a href="#Leetcode[1]-Two_Sum">Leetcode[1]-Two Sum</a></li><li><a href="#Leetcode[4]-Median_of_Two_Sorted_Arrays">Leetcode[4]-Median of Two Sorted Arrays</a></li><li><a href="#Leetcode[7]-Reverse_Integer">Leetcode[7]-Reverse Integer</a></li><li><a href="#Leetcode[9]-Palindrome_Number">Leetcode[9]-Palindrome Number</a></li><li><a href="#Leetcode[12]-Integer_to_Roman+++">Leetcode[12]-Integer to Roman+++</a></li><li><a href="#Leetcode[13]-Roman_to_Integer+++">Leetcode[13]-Roman to Integer+++</a></li><li><a href="#Leetcode[15]-3Sum">Leetcode[15]-3Sum</a></li><li><a href="#Leetcode[18]-4Sum">Leetcode[18]-4Sum</a></li><li><a href="#Leetcode[19]-Remove_Nth_Node_From_End_of_List">Leetcode[19]-Remove Nth Node From End of List</a></li><li><a href="#Leetcode[20]-Valid_Parentheses">Leetcode[20]-Valid Parentheses</a></li><li><a href="#Leetcode[21]-Merge_Two_Sorted_Lists">Leetcode[21]-Merge Two Sorted Lists</a></li><li><a href="#Leetcode[26]-Remove_Duplicates_from_Sorted_Array">Leetcode[26]-Remove Duplicates from Sorted Array</a></li><li><a href="#Leetcode[27]-Remove_Element">Leetcode[27]-Remove Element</a></li><li><a href="#Leetcode[33]-Search_in_Rotated_Sorted_Array">Leetcode[33]-Search in Rotated Sorted Array</a></li><li><a href="#Leetcode[35]-Search_Insert_Position">Leetcode[35]-Search Insert Position</a></li><li><a href="#Leetcode[36]-Valid_Sudoku">Leetcode[36]-Valid Sudoku</a></li><li><a href="#Leetcode[53]-Maximum_Subarray">Leetcode[53]-Maximum Subarray</a></li><li><a href="#Leetcode[62]-Unique_Paths">Leetcode[62]-Unique Paths</a></li><li><a href="#Leetcode[63]-Unique_Paths_II">Leetcode[63]-Unique Paths II</a></li><li><a href="#Leetcode[66]-Plus_One">Leetcode[66]-Plus One</a></li><li><a href="#Leetcode[70]-Climbing_Stairs">Leetcode[70]-Climbing Stairs</a></li><li><a href="#Leetcode[74]-Search_a_2D_Matrix">Leetcode[74]-Search a 2D Matrix</a></li><li><a href="#Leetcode[81]-Search_for_a_Range">Leetcode[81]-Search for a Range</a></li><li><a href="#Leetcode[82]-Remove_Duplicates_from_Sorted_List_II">Leetcode[82]-Remove Duplicates from Sorted List II</a></li><li><a href="#Leetcode[83]-Remove_Duplicates_from_Sorted_List">Leetcode[83]-Remove Duplicates from Sorted List</a></li><li><a href="#Leetcode[86]-Partition_List">Leetcode[86]-Partition List</a></li><li><a href="#Leetcode[88]-Merge_Sorted_Array">Leetcode[88]-Merge Sorted Array</a></li><li><a href="#Leetcode[92]-Reverse_Linked_List_II">Leetcode[92]-Reverse Linked List II</a></li><li><a href="#Leetcode[94]-Binary_Tree_Inorder_Traversal">Leetcode[94]-Binary Tree Inorder Traversal</a></li><li><a href="#Leetcode[96]-Unique_Binary_Search_Trees">Leetcode[96]-Unique Binary Search Trees</a></li><li><a href="#Leetcode[98]-Validate_Binary_Search_Tree">Leetcode[98]-Validate Binary Search Tree</a></li><li><a href="#Leetcode[100]-Same_Tree">Leetcode[100]-Same Tree</a></li><li><a href="#Leetcode[101]-Symmetric_Tree">Leetcode[101]-Symmetric Tree</a></li><li><a href="#Leetcode[102]-Binary_Tree_Level_Order_Traversal">Leetcode[102]-Binary Tree Level Order Traversal</a></li><li><a href="#Leetcode[103]-Binary_Tree_Zigzag_Level_Order_Traversal">Leetcode[103]-Binary Tree Zigzag Level Order Traversal</a></li><li><a href="#Leetcode[104]-Maximum_Depth_of_Binary_Tree">Leetcode[104]-Maximum Depth of Binary Tree</a></li><li><a href="#Leetcode[107]-Binary_Tree_Level_Order_Traversal_II">Leetcode[107]-Binary Tree Level Order Traversal II</a></li><li><a href="#Leetcode[110]-Balanced_Binary_Tree">Leetcode[110]-Balanced Binary Tree</a></li><li><a href="#Leetcode[111]-Minimum_Depth_of_Binary_Tree">Leetcode[111]-Minimum Depth of Binary Tree</a></li><li><a href="#Leetcode[113]-Path_Sum_II">Leetcode[113]-Path Sum II</a></li><li><a href="#Leetcode[114]-Flatten_Binary_Tree_to_Linked_List">Leetcode[114]-Flatten Binary Tree to Linked List</a></li><li><a href="#Leetcode[118]-Pascal's_Triangle">Leetcode[118]-Pascal’s Triangle</a></li><li><a href="#Leetcode[119]-Pascal's_Triangle_II">Leetcode[119]-Pascal’s Triangle II</a></li><li><a href="#Leetcode[125]-Valid_Palindrome">Leetcode[125]-Valid Palindrome</a></li><li><a href="#Leetcode[128]-Longest_Consecutive_Sequence">Leetcode[128]-Longest Consecutive Sequence</a></li><li><a href="#Leetcode[136]-Single_Number">Leetcode[136]-Single Number</a></li><li><a href="#Leetcode[137]-Single_Number_II">Leetcode[137]-Single Number II</a></li><li><a href="#Leetcode[141]-Linked_List_Cycle">Leetcode[141]-Linked List Cycle</a></li><li><a href="#Leetcode[143]-Reorder_List">Leetcode[143]-Reorder List</a></li><li><a href="#Leetcode[144]-Binary_Tree_Preorder_Traversal">Leetcode[144]-Binary Tree Preorder Traversal</a></li><li><a href="#Leetcode[145]-Binary_Tree_Postorder_Traversal">Leetcode[145]-Binary Tree Postorder Traversal</a></li><li><a href="#Leetcode[147]-Insertion_Sort_List">Leetcode[147]-Insertion Sort List</a></li><li><a href="#Leetcode[148]-Sort_List">Leetcode[148]-Sort List</a></li><li><a href="#Leetcode[153]-Find_Minimum_in_Rotated_Sorted_Array">Leetcode[153]-Find Minimum in Rotated Sorted Array</a></li><li><a href="#Leetcode[154]-Find_Minimum_in_Rotated_Sorted_Array_II">Leetcode[154]-Find Minimum in Rotated Sorted Array II</a></li><li><a href="#LeetCode[155]-Min_Stack">LeetCode[155]-Min Stack</a></li><li><a href="#Leetcode[162]-Find_Peak_Element">Leetcode[162]-Find Peak Element</a></li><li><a href="#Leetcode[169]-Majority_Element">Leetcode[169]-Majority Element</a></li><li><a href="#Leetcode[173]-Binary_Search_Tree_Iterator">Leetcode[173]-Binary Search Tree Iterator</a></li><li><a href="#Leetcode[189]-Rotate_Array">Leetcode[189]-Rotate Array</a></li><li><a href="#Leetcode[191]-Number_of_Bits">Leetcode[191]-Number of Bits</a></li><li><a href="#Leetcode[198]-House_Robber">Leetcode[198]-House Robber</a></li><li><a href="#Leetcode[202]-Happy_Number">Leetcode[202]-Happy Number</a></li><li><a href="#Leetcode[203]-Remove_Linked_List_Elements">Leetcode[203]-Remove Linked List Elements</a></li><li><a href="#Leetcode[206]-Reverse_Linked_List">Leetcode[206]-Reverse Linked List</a></li><li><a href="#Leetcode[215]-Kth_Largest_Element_in_an_Array">Leetcode[215]-Kth Largest Element in an Array</a></li><li><a href="#Leetcode[217]-Contains_Duplicate">Leetcode[217]-Contains Duplicate</a></li><li><a href="#Leetcode[219]-Contains_Duplicate_II">Leetcode[219]-Contains Duplicate II</a></li><li><a href="#Leetcode[222]-Count_Complete_Tree_Nodes">Leetcode[222]-Count Complete Tree Nodes</a></li><li><a href="#Leetcode[226]-Invert_Binary_Tree">Leetcode[226]-Invert Binary Tree</a></li><li><a href="#Leetcode[231]-Power_of_Two">Leetcode[231]-Power of Two</a></li><li><a href="#Leetcode[237]-Delete_Node_in_a_Linked_List">Leetcode[237]-Delete Node in a Linked List</a></li><li><a href="#Leetcode[242]-Valid_Anagram">Leetcode[242]-Valid Anagram</a></li><li><a href="#Leetcode[258]-Add_Digits">Leetcode[258]-Add Digits</a></li><li><a href="#Leetcode[260]-Single_Number_III">Leetcode[260]-Single Number III</a></li><li><a href="#Leetcode[263]-Ugly_Number++">Leetcode[263]-Ugly Number++</a></li><li><a href="#Leetcode[283]-Move_Zeroes">Leetcode[283]-Move Zeroes</a></li><li><a href="#Leetcode[292]-Nim_Game">Leetcode[292]-Nim Game</a></li><li><a href="#Leetcode[300]-Longest_Increasing_Subsequence">Leetcode[300]-Longest Increasing Subsequence</a></li></ul><p>下面是具体题解内容。</p><hr><h1 id="Leetcode-1-Two-Sum"><a href="#Leetcode-1-Two-Sum" class="headerlink" title="Leetcode[1]-Two Sum"></a>Leetcode[1]-Two Sum</h1><p>Link:<a href="https://leetcode.com/problems/two-sum/" target="_blank" rel="noopener">https://leetcode.com/problems/two-sum/</a>  </p><p>Given an array of integers, find two numbers such that they add up to a specific target number.</p><p>The function twoSum should return indices of the two numbers such that they add up to the target, where index1 must be less than index2. Please note that your returned answers (both index1 and index2) are not zero-based.</p><p>You may assume that each input would have exactly one solution.</p><p>Input: numbers={2, 7, 11, 15}, target=9<br>Output: index1=1, index2=2</p><hr><p>分析：<br>方法一：使用两个for循环，依次比较，不过这个方法在leetcode上超时了</p><p>c++</p><figure class="highlight fortran"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;<span class="built_in">int</span>&gt; twoSum(vector&lt;<span class="built_in">int</span>&gt;&amp; nums, <span class="built_in">int</span> <span class="keyword">target</span>) {</span><br><span class="line">    vector&lt;<span class="built_in">int</span>&gt; <span class="built_in">index</span>(<span class="number">2</span>);</span><br><span class="line">    <span class="built_in">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">    for(<span class="built_in">int</span> i = <span class="number">0</span>; i &lt; n ; i++) {</span><br><span class="line">        <span class="built_in">index</span>[<span class="number">0</span>] = i+<span class="number">1</span>;</span><br><span class="line">        for(<span class="built_in">int</span> j = i+<span class="number">1</span> ; j &lt; n ; j++) {</span><br><span class="line">            <span class="keyword">if</span>(nums[i] + nums[j] == <span class="keyword">target</span>){</span><br><span class="line">                <span class="built_in">index</span>[<span class="number">1</span>] = j+<span class="number">1</span>;</span><br><span class="line">                <span class="keyword">return</span> <span class="built_in">index</span>;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">index</span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>法二：使用map存储所有的数组值和下标值，然后循环在map中找看能否找到target-nums[i]的map，如果找到了就终止循环，没找到继续找；最后返回index数组；</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">twoSum</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span> </span>{</span><br><span class="line">        <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">index</span><span class="params">(<span class="number">2</span>)</span></span>;</span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="built_in">map</span>&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; mapv;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n ; i++) {</span><br><span class="line">            mapv[nums[i]] = i;</span><br><span class="line">        }</span><br><span class="line">        <span class="built_in">map</span>&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt;::iterator it;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) {</span><br><span class="line">            it = mapv.<span class="built_in">find</span>(target - nums[i]);</span><br><span class="line">            <span class="keyword">if</span>(it != mapv.<span class="built_in">end</span>() &amp;&amp; i!=it-&gt;second){</span><br><span class="line">                index[<span class="number">0</span>]=<span class="built_in">min</span>(i+<span class="number">1</span>, it-&gt;second + <span class="number">1</span>);</span><br><span class="line">                index[<span class="number">1</span>]=<span class="built_in">max</span>(i+<span class="number">1</span>, it-&gt;second + <span class="number">1</span>);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> index;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-4-Median-of-Two-Sorted-Arrays"><a href="#Leetcode-4-Median-of-Two-Sorted-Arrays" class="headerlink" title="Leetcode[4]-Median of Two Sorted Arrays"></a>Leetcode[4]-Median of Two Sorted Arrays</h1><p>Link: <a href="https://leetcode.com/problems/median-of-two-sorted-arrays/" target="_blank" rel="noopener">https://leetcode.com/problems/median-of-two-sorted-arrays/</a></p><p>There are two sorted arrays nums1 and nums2 of size m and n respectively. Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)).</p><hr><p>思路：先将两个数组合并，然后排序，最后找中位数</p><p>中位数：若有n个数，n为奇数，则选择第（n+1）/2个为中位数，若n为偶数，则中位数是（n/2以及n/2+1）的平均数；</p><p>合并两个vector：merge(nums1.begin(),nums1.end(),nums2.begin(),nums2.end(),nums.begin());</p><p>Code(c++):</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">double</span> <span class="title">findMedianSortedArrays</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums1, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums2)</span> </span>{</span><br><span class="line">        <span class="keyword">int</span> m = nums1.<span class="built_in">size</span>(),n = nums2.<span class="built_in">size</span>();</span><br><span class="line">        <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">nums</span><span class="params">(m+n)</span></span>;</span><br><span class="line">    </span><br><span class="line">        merge(nums1.<span class="built_in">begin</span>(),nums1.<span class="built_in">end</span>(),nums2.<span class="built_in">begin</span>(),nums2.<span class="built_in">end</span>(),nums.<span class="built_in">begin</span>());</span><br><span class="line">    </span><br><span class="line">        sort(nums.<span class="built_in">begin</span>(),nums.<span class="built_in">end</span>());</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">int</span> mid = (m+n)/<span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span>((m+n)%<span class="number">2</span>==<span class="number">0</span>) {</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">double</span>(nums[mid]+nums[mid - <span class="number">1</span>])/<span class="number">2</span>;</span><br><span class="line">        }<span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> nums[mid];</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-7-Reverse-Integer"><a href="#Leetcode-7-Reverse-Integer" class="headerlink" title="Leetcode[7]-Reverse Integer"></a>Leetcode[7]-Reverse Integer</h1><p>Link: <a href="https://leetcode.com/problems/reverse-integer/" target="_blank" rel="noopener">https://leetcode.com/problems/reverse-integer/</a></p><p>Reverse digits of an integer.</p><pre><code>Example1: x = 123, return 321Example2: x = -123, return -321</code></pre><hr><p>取一个数的最后一位，用<code>x % 10</code>,取一个数的前n-1位（共n位），用<code>x/10</code>，每一次取的时候，都将上一次取的数乘以10，然后再加上末尾的数即可，代码如下：</p><p>Code(C++)</p><figure class="highlight applescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">class</span> Solution {</span><br><span class="line">public:</span><br><span class="line">    int <span class="built_in">reverse</span>(int x) {</span><br><span class="line">        long <span class="literal">result</span> = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(x != <span class="number">0</span>)</span><br><span class="line">        {</span><br><span class="line">            <span class="literal">result</span> = <span class="literal">result</span>*<span class="number">10</span> + x % <span class="number">10</span>;</span><br><span class="line">            x /= <span class="number">10</span>;</span><br><span class="line">        }</span><br><span class="line"><span class="built_in">        return</span> (<span class="literal">result</span> &gt; INT_MAX || <span class="literal">result</span> &lt; INT_MIN)? <span class="number">0</span> : <span class="literal">result</span>;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-9-Palindrome-Number"><a href="#Leetcode-9-Palindrome-Number" class="headerlink" title="Leetcode[9]-Palindrome Number"></a>Leetcode[9]-Palindrome Number</h1><p>Link: <a href="https://leetcode.com/problems/palindrome-number/" target="_blank" rel="noopener">https://leetcode.com/problems/palindrome-number/</a></p><p>Determine whether an integer is a palindrome. Do this without extra space.</p><p>Some hints:<br>Could negative integers be palindromes? (ie, -1)</p><p>If you are thinking of converting the integer to string, note the restriction of using extra space.</p><p>You could also try reversing an integer. However, if you have solved the problem “Reverse Integer”, you know that the reversed integer might overflow. How would you handle such case?</p><p>There is a more generic way of solving this problem.</p><hr><p>思路：求出它的反转数，然后比较两个数是否恒等于即可。</p><p>C++代码：</p><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isPalindrome</span><span class="params">(<span class="keyword">int</span> x)</span> </span>{</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(x &lt; <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">int</span> y = x, result = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>( y &gt; <span class="number">0</span> ){</span><br><span class="line">            result = result * <span class="number">10</span> + y%<span class="number">10</span>;</span><br><span class="line">            y /= <span class="number">10</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> result == x;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p>法二：将数字转换成字符串，遍历一遍字符串，看首位是否相等即可</p><figure class="highlight axapta"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">bool isPalindrome(<span class="keyword">int</span> x) {</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span>(x &lt; <span class="number">0</span>) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">if</span>(x&gt;=<span class="number">0</span> &amp;&amp; x&lt;=<span class="number">9</span>) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    string <span class="keyword">str</span>;</span><br><span class="line">    stringstream ss;</span><br><span class="line">    ss&lt;&lt;x;</span><br><span class="line">    ss&gt;&gt;<span class="keyword">str</span>;</span><br><span class="line">    <span class="keyword">int</span> len = <span class="keyword">str</span>.length();</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; (len/<span class="number">2</span>); i++ ){</span><br><span class="line">        <span class="keyword">if</span>(<span class="keyword">str</span>[i] != <span class="keyword">str</span>[len<span class="number">-1</span>-i])<span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    </span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-12-Integer-to-Roman"><a href="#Leetcode-12-Integer-to-Roman" class="headerlink" title="Leetcode[12]-Integer to Roman+++"></a>Leetcode[12]-Integer to Roman+++</h1><p>Link: <a href="https://leetcode.com/problems/integer-to-roman/" target="_blank" rel="noopener">https://leetcode.com/problems/integer-to-roman/</a></p><p>Given an integer, convert it to a roman numeral.</p><p>Input is guaranteed to be within the range from 1 to 3999.</p><hr><p>分析：</p><p>C++:</p><figure class="highlight matlab"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    string intToRoman(int num) {</span><br><span class="line">        int s[<span class="number">7</span>]={<span class="number">0</span>};</span><br><span class="line">        int Roman[<span class="number">7</span>]={<span class="number">1000</span>,<span class="number">500</span>,<span class="number">100</span>,<span class="number">50</span>,<span class="number">10</span>,<span class="number">5</span>,<span class="number">1</span>};</span><br><span class="line">        char ch[<span class="number">7</span>]={<span class="string">'M'</span>,<span class="string">'D'</span>,<span class="string">'C'</span>,<span class="string">'L'</span>,<span class="string">'X'</span>,<span class="string">'V'</span>,<span class="string">'I'</span>};</span><br><span class="line">        int index=<span class="number">0</span>;</span><br><span class="line">        string result;</span><br><span class="line">        <span class="keyword">while</span>(index&lt;<span class="number">7</span>) {</span><br><span class="line">            s[index]=num/Roman[index];</span><br><span class="line">            num<span class="comment">%=Roman[index++];</span></span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">for</span>(int <span class="built_in">i</span>=<span class="number">0</span>;<span class="built_in">i</span>&lt;<span class="number">7</span>;<span class="built_in">i</span>++){</span><br><span class="line">            <span class="keyword">if</span> (s[<span class="built_in">i</span>]==<span class="number">1</span>&amp;&amp;<span class="built_in">i</span>+<span class="number">1</span>&lt;<span class="number">7</span>&amp;&amp;s[<span class="built_in">i</span>+<span class="number">1</span>]==<span class="number">4</span>)</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">if</span>(s[<span class="built_in">i</span>]==<span class="number">4</span>){</span><br><span class="line">                <span class="keyword">if</span> (s[<span class="built_in">i</span><span class="number">-1</span>]==<span class="number">1</span>)</span><br><span class="line">                    result=result+ch[<span class="built_in">i</span>]+ch[<span class="built_in">i</span><span class="number">-2</span>];</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    result=result+ch[<span class="built_in">i</span>]+ch[<span class="built_in">i</span><span class="number">-1</span>];</span><br><span class="line">            }<span class="keyword">else</span>{</span><br><span class="line">                <span class="keyword">for</span>(int <span class="built_in">j</span>=<span class="number">0</span>;<span class="built_in">j</span>&lt;s[<span class="built_in">i</span>];<span class="built_in">j</span>++)</span><br><span class="line">                    result+=ch[<span class="built_in">i</span>];</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-13-Roman-to-Integer"><a href="#Leetcode-13-Roman-to-Integer" class="headerlink" title="Leetcode[13]-Roman to Integer+++"></a>Leetcode[13]-Roman to Integer+++</h1><p>Link: <a href="https://leetcode.com/problems/roman-to-integer/" target="_blank" rel="noopener">https://leetcode.com/problems/roman-to-integer/</a></p><p>Given a roman numeral, convert it to an integer.</p><p>Input is guaranteed to be within the range from 1 to 3999.</p><hr><p>分析：</p><p>从前往后扫描，用一个临时变量记录分段数字。</p><p>如果当前处理的字符对应的值和上一个字符一样，那么临时变量加上这个字符。比如III = 3<br>如果当前比前一个大，说明这一段的值应该是当前这个值减去前面记录下的临时变量中的值。比如IIV = 5 – 2<br>如果当前比前一个小，那么就可以先将临时变量的值加到结果中，然后开始下一段记录。比如VI = 5 + 1</p><p>C++:</p><figure class="highlight dart"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>{</span><br><span class="line">public:</span><br><span class="line">    <span class="built_in">int</span> romanToInt(string s) {</span><br><span class="line">        <span class="built_in">int</span> <span class="built_in">num</span>[<span class="number">256</span>] = { <span class="number">0</span> };</span><br><span class="line">        <span class="built_in">num</span>[<span class="string">'I'</span>] = <span class="number">1</span>; <span class="built_in">num</span>[<span class="string">'V'</span>] = <span class="number">5</span>; <span class="built_in">num</span>[<span class="string">'X'</span>] = <span class="number">10</span>; <span class="built_in">num</span>[<span class="string">'L'</span>]=<span class="number">50</span>;</span><br><span class="line">        <span class="built_in">num</span>[<span class="string">'C'</span>] = <span class="number">100</span>; <span class="built_in">num</span>[<span class="string">'D'</span>] = <span class="number">500</span>; <span class="built_in">num</span>[<span class="string">'M'</span>] = <span class="number">1000</span>;</span><br><span class="line">        <span class="built_in">int</span> result = <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (i &lt; s.size()){</span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">num</span>[s[i]] &lt; <span class="built_in">num</span>[s[i+<span class="number">1</span>]])</span><br><span class="line">                result -= <span class="built_in">num</span>[s[i]];</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                result += <span class="built_in">num</span>[s[i]];</span><br><span class="line">            i++;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p>Python：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">romanToInt</span><span class="params">(self, s)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type s: str</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        Num = {<span class="string">"I"</span>:<span class="number">1</span>, <span class="string">"V"</span>:<span class="number">5</span>, <span class="string">"X"</span>:<span class="number">10</span>, <span class="string">"L"</span>:<span class="number">50</span>, <span class="string">"C"</span>:<span class="number">100</span>, <span class="string">"D"</span>:<span class="number">500</span>, <span class="string">"M"</span>:<span class="number">1000</span>}</span><br><span class="line">        L = len(s)</span><br><span class="line">        sum = <span class="number">0</span></span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">        <span class="keyword">while</span>(i &lt; L - <span class="number">1</span>):</span><br><span class="line">    </span><br><span class="line">            <span class="keyword">if</span>(Num.get(s[i]) &lt; Num.get(s[i + <span class="number">1</span>])):</span><br><span class="line">                sum -= Num.get(s[i])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                sum += Num.get(s[i])</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">        sum += Num.get(s[i])</span><br><span class="line">        <span class="keyword">return</span> sum</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-15-3Sum"><a href="#Leetcode-15-3Sum" class="headerlink" title="Leetcode[15]-3Sum"></a>Leetcode[15]-3Sum</h1><p>Link:<a href="https://leetcode.com/problems/3sum/" target="_blank" rel="noopener">https://leetcode.com/problems/3sum/</a></p><p>Given an array S of n integers, are there elements a, b, c in S such that a + b + c = 0? Find all unique triplets in the array which gives the sum of zero.</p><p>Note:<br>Elements in a triplet (a,b,c) must be in non-descending order. (ie, a ≤ b ≤ c)<br>The solution set must not contain duplicate triplets.<br>    For example, given array S = {-1 0 1 2 -1 -4},</p><pre><code>A solution set is:(-1, 0, 1)(-1, -1, 2)</code></pre><hr><p>分析：根据题意，我们可以要找出三个数相加等于0的这样的一个集合，所以采用二维数组存储。</p><p>首先对数组进行从小到大排序，然后抽取一个变量出来，该变量从左往右递归遍历，递归的同时设置两个变量，让其中一个从第一个变量的右边开始，另一个从数组的末端开始，同步的向中间遍历，有点类似于快速排序的判断方式，</p><ul><li>如果三个数相加小于零，则让第二个变量自加；</li><li>如果三个数相加大于零，则让第三个变量自减；</li><li>如果三个数相加等于零，则将三个数加入到数组中，然后让第二个变量和第三个变量同步增减，自增自减的过程中要判断是否有重复数字；</li></ul><p>依次递归，直到第一个变量条件终止为止。</p><p><strong>Code(c++):</strong></p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; <span class="title">threeSum</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &amp;nums)</span> </span>{</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt;  result;</span><br><span class="line"></span><br><span class="line">        sort(nums.<span class="built_in">begin</span>(), nums.<span class="built_in">end</span>());</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.<span class="built_in">size</span>(); i++){</span><br><span class="line">            <span class="keyword">if</span>(i &gt; <span class="number">0</span> &amp;&amp; nums[i] == nums[i<span class="number">-1</span>]) <span class="keyword">continue</span>;</span><br><span class="line">            threeNumber(nums, result, i); </span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">//return vector&lt;vector&lt;int&gt; &gt; results </span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">threeNumber</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &amp;nums, <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; &amp;results, <span class="keyword">int</span> curIndex)</span> </span>{</span><br><span class="line">        <span class="keyword">int</span> i = curIndex + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> j = nums.<span class="built_in">size</span>()<span class="number">-1</span>;</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">while</span>(i &lt; j){</span><br><span class="line">            <span class="keyword">if</span>(nums[curIndex] + nums[i] + nums[j] &lt; <span class="number">0</span>)   i++;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(nums[curIndex] + nums[i] + nums[j] &gt; <span class="number">0</span>)   j--;</span><br><span class="line">            <span class="keyword">else</span>{</span><br><span class="line">                <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; v;</span><br><span class="line">                v.push_back(nums[curIndex]);</span><br><span class="line">                v.push_back(nums[i]);</span><br><span class="line">                v.push_back(nums[j]);</span><br><span class="line">                results.push_back(v);</span><br><span class="line">                i++; j--;</span><br><span class="line">                <span class="keyword">while</span>(i &lt; j &amp;&amp; nums[i]==nums[i - <span class="number">1</span>]) i++;</span><br><span class="line">                <span class="keyword">while</span>(j &gt; i &amp;&amp; nums[j] == nums[j + <span class="number">1</span>]) j--;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-18-4Sum"><a href="#Leetcode-18-4Sum" class="headerlink" title="Leetcode[18]-4Sum"></a>Leetcode[18]-4Sum</h1><p>Link: <a href="https://leetcode.com/problems/4sum/" target="_blank" rel="noopener">https://leetcode.com/problems/4sum/</a></p><p>Given an array S of n integers, are there elements a, b, c, and d in S such that a + b + c + d = target? Find all unique quadruplets in the array which gives the sum of target.</p><p>Note:<br>Elements in a quadruplet (a,b,c,d) must be in non-descending order. (ie, a ≤ b ≤ c ≤ d)<br>The solution set must not contain duplicate quadruplets.</p><hr><p>分析：和第15道题有点类似，仅仅是多了一层循环，注意该循环的条件就行.</p><p>C++:</p><figure class="highlight matlab"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;vector&lt;int&gt; &gt; fourSum(vector&lt;int&gt;&amp; nums, int target) {</span><br><span class="line">        vector&lt;vector&lt;int&gt; &gt; result;    </span><br><span class="line">        int n = nums.<span class="built_in">size</span>();        </span><br><span class="line">        <span class="built_in">sort</span>(nums.begin(),nums.<span class="keyword">end</span>());</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(int <span class="built_in">i</span> = <span class="number">0</span>; <span class="built_in">i</span> &lt; n; <span class="built_in">i</span>++) {</span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">i</span>&gt;<span class="number">0</span> &amp;&amp; nums[<span class="built_in">i</span>] == nums[<span class="built_in">i</span><span class="number">-1</span>]) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">for</span>(int <span class="built_in">j</span> = <span class="built_in">i</span>+<span class="number">1</span>; <span class="built_in">j</span> &lt; n; <span class="built_in">j</span>++){</span><br><span class="line">                <span class="keyword">if</span>(<span class="built_in">j</span> &gt; <span class="built_in">i</span>+<span class="number">1</span> &amp;&amp; nums[<span class="built_in">j</span>]== nums[<span class="built_in">j</span><span class="number">-1</span>]) <span class="keyword">continue</span>;</span><br><span class="line">                fourNumber(nums,result,<span class="built_in">i</span>,<span class="built_in">j</span>,target);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    void fourNumber(vector&lt;int&gt; &amp; nums,vector&lt;vector&lt;int&gt; &gt; &amp;results, int curIndex1,int curIndex2,int target){</span><br><span class="line">        int <span class="built_in">i</span> = curIndex2 + <span class="number">1</span>;</span><br><span class="line">        int <span class="built_in">j</span> = nums.<span class="built_in">size</span>()<span class="number">-1</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span>(<span class="built_in">i</span>&lt;<span class="built_in">j</span>) {</span><br><span class="line">            <span class="keyword">if</span>(nums[curIndex1] + nums[curIndex2] + nums[<span class="built_in">i</span>] + nums[<span class="built_in">j</span>] &lt; target ) <span class="built_in">i</span>++;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(nums[curIndex1] + nums[curIndex2] + nums[<span class="built_in">i</span>] + nums[<span class="built_in">j</span>] &gt; target ) <span class="built_in">j</span>--;</span><br><span class="line">            <span class="keyword">else</span> {</span><br><span class="line">                vector&lt;int&gt; vec;</span><br><span class="line">                vec.push_back(nums[curIndex1]);</span><br><span class="line">                vec.push_back(nums[curIndex2]);</span><br><span class="line">                vec.push_back(nums[<span class="built_in">i</span>]);</span><br><span class="line">                vec.push_back(nums[<span class="built_in">j</span>]);</span><br><span class="line">                results.push_back(vec);</span><br><span class="line">                <span class="built_in">i</span>++,<span class="built_in">j</span>--;</span><br><span class="line">                <span class="keyword">while</span>(<span class="built_in">i</span> &lt; <span class="built_in">j</span> &amp;&amp; nums[<span class="built_in">i</span>] == nums[<span class="built_in">i</span><span class="number">-1</span>])<span class="built_in">i</span>++;</span><br><span class="line">                <span class="keyword">while</span>(<span class="built_in">j</span> &gt; <span class="built_in">i</span> &amp;&amp; nums[<span class="built_in">j</span>] == nums[<span class="built_in">j</span>+<span class="number">1</span>])<span class="built_in">j</span>--;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-19-Remove-Nth-Node-From-End-of-List"><a href="#Leetcode-19-Remove-Nth-Node-From-End-of-List" class="headerlink" title="Leetcode[19]-Remove Nth Node From End of List"></a>Leetcode[19]-Remove Nth Node From End of List</h1><p>Link: <a href="https://leetcode.com/problems/remove-nth-node-from-end-of-list/" target="_blank" rel="noopener">https://leetcode.com/problems/remove-nth-node-from-end-of-list/</a></p><p>Given a linked list, remove the nth node from the end of list and return its head.</p><p>For example,</p><pre><code>Given linked list: 1-&gt;2-&gt;3-&gt;4-&gt;5, and n = 2.After removing the second node from the end, the linked list becomes 1-&gt;2-&gt;3-&gt;5.</code></pre><p>Note:<br>Given n will always be valid.<br>Try to do this in one pass.</p><hr><p><strong>思路：</strong>先将链表翻转，然后遍历，找到第n-1个节点，然后删除第n个节点，最后再次翻转链表即可。</p><p><strong>笔记：</strong>在链表翻转后，我采用的是在翻转后的链表的头部放一个无关的节点，然后往后面找，变量从1到n，当变量为n的时候，此时节点还处于n-1节点上，接着我们就让该节点的下个节点指向它的下下个节点，这样第k个节点就删除了。</p><p>Code(c++):</p><figure class="highlight gradle"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * struct ListNode {</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode *next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) : val(x), next(NULL) {}</span></span><br><span class="line"><span class="comment"> * };</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">class</span> Solution {</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    ListNode* removeNthFromEnd(ListNode* head, <span class="keyword">int</span> n) {</span><br><span class="line">    </span><br><span class="line">        reverseList(head);</span><br><span class="line">        ListNode *newList = <span class="keyword">new</span> ListNode(-<span class="number">1</span>);</span><br><span class="line">        newList-&gt;<span class="keyword">next</span> = head;</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">int</span> <span class="keyword">count</span> = <span class="number">1</span>;</span><br><span class="line">        ListNode *pre = newList;</span><br><span class="line">    </span><br><span class="line">        <span class="comment">//find the prior element</span></span><br><span class="line"><span class="comment">//when we get the Nth Node,delete this node from list</span></span><br><span class="line">            <span class="keyword">if</span>(<span class="keyword">count</span>==n &amp;&amp; pre-&gt;<span class="keyword">next</span>!=<span class="keyword">NULL</span>){</span><br><span class="line">                pre-&gt;<span class="keyword">next</span> = pre-&gt;<span class="keyword">next</span>-&gt;<span class="keyword">next</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            }<span class="keyword">else</span>{</span><br><span class="line">                pre = pre-&gt;<span class="keyword">next</span>;</span><br><span class="line">                <span class="keyword">count</span>++;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        head = newList-&gt;<span class="keyword">next</span>;</span><br><span class="line">        <span class="comment">//when head is not null,reverse it</span></span><br><span class="line">        <span class="keyword">if</span>(head!=<span class="keyword">NULL</span>)</span><br><span class="line">            reverseList(head);</span><br><span class="line">        <span class="keyword">return</span> head;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">void</span> reverseList(ListNode* &amp;head){</span><br><span class="line">        <span class="keyword">if</span>(head==<span class="keyword">NULL</span> || head-&gt;<span class="keyword">next</span> == <span class="keyword">NULL</span>)<span class="keyword">return</span>;</span><br><span class="line">        </span><br><span class="line">        ListNode *newList = <span class="keyword">new</span> ListNode(-<span class="number">1</span>);</span><br><span class="line">        ListNode *pre = head;</span><br><span class="line">        </span><br><span class="line">        ListNode *temp;</span><br><span class="line">        <span class="keyword">while</span>(pre!=<span class="keyword">NULL</span>){</span><br><span class="line">            temp = pre-&gt;<span class="keyword">next</span>;</span><br><span class="line">            pre-&gt;<span class="keyword">next</span> = newList-&gt;<span class="keyword">next</span>;</span><br><span class="line">            newList-&gt;<span class="keyword">next</span> = pre;</span><br><span class="line">            pre = temp;</span><br><span class="line">        }</span><br><span class="line">        newList = newList-&gt;<span class="keyword">next</span>;</span><br><span class="line">        head = newList;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-20-Valid-Parentheses"><a href="#Leetcode-20-Valid-Parentheses" class="headerlink" title="Leetcode[20]-Valid Parentheses"></a>Leetcode[20]-Valid Parentheses</h1><p>Link: <a href="https://leetcode.com/problems/valid-parentheses/" target="_blank" rel="noopener">https://leetcode.com/problems/valid-parentheses/</a></p><p>Given a string containing just the characters <code>'(', ')'</code>, <code>'{', '}'</code>, <code>'[' and ']'</code>, determine if the input string is valid.</p><p>The brackets must close in the correct order, <code>"()"</code> and <code>"()[]{}"</code> are all valid but <code>"(]"</code> and <code>"([)]"</code> are not.</p><hr><p>思路：借助vector容器，存放字符’(‘,’{‘,’[‘，从左到右的读取字符串的每一个字符，</p><ul><li><p>如果字符为上面给定的三个，则加入到vector中；</p></li><li><p>如果不是，在确保vector容器有字符的情况下，则让其和vector的最后一个比较；</p><ul><li>如果是匹配的，则将vector容器的大小缩减为size()-1；</li><li>如果不匹配，则返回false；</li></ul></li><li><p>最后，如果vector元素全部匹配完了，则返回true，否则返回false；</p></li></ul><p>代码如下（c++）：</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isValid</span><span class="params">(<span class="built_in">string</span> s)</span> </span>{</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt; str;</span><br><span class="line">        <span class="keyword">int</span> len = s.length();</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;len; i++){</span><br><span class="line">            <span class="keyword">if</span>(isThose(s[i])) {</span><br><span class="line">                str.push_back(s[i]);</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            }</span><br><span class="line">            <span class="keyword">if</span>(str.<span class="built_in">size</span>()&gt;<span class="number">0</span> &amp;&amp; isTrue(str[str.<span class="built_in">size</span>()<span class="number">-1</span>],s[i])) {</span><br><span class="line">                <span class="built_in">cout</span>&lt;&lt;str.<span class="built_in">size</span>()&lt;&lt;<span class="string">"f"</span>&lt;&lt;isTrue(str[str.<span class="built_in">size</span>()<span class="number">-1</span>],s[i])&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">                str.resize(str.<span class="built_in">size</span>()<span class="number">-1</span>);</span><br><span class="line">            }<span class="keyword">else</span>{</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span>(str.<span class="built_in">size</span>() == <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isThose</span><span class="params">(<span class="keyword">char</span> &amp;a)</span></span>{</span><br><span class="line">        <span class="keyword">if</span>(a == <span class="string">'{'</span> || a == <span class="string">'('</span> || a == <span class="string">'['</span>)<span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isTrue</span><span class="params">(<span class="keyword">char</span> &amp;a, <span class="keyword">char</span> &amp;b)</span></span>{</span><br><span class="line">        <span class="keyword">if</span>( a == <span class="string">'('</span> &amp;&amp; b == <span class="string">')'</span> ) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>( a == <span class="string">'['</span> &amp;&amp; b == <span class="string">']'</span> ) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>( a == <span class="string">'{'</span> &amp;&amp; b == <span class="string">'}'</span> ) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-21-Merge-Two-Sorted-Lists"><a href="#Leetcode-21-Merge-Two-Sorted-Lists" class="headerlink" title="Leetcode[21]-Merge Two Sorted Lists"></a>Leetcode[21]-Merge Two Sorted Lists</h1><p>Link: <a href="https://leetcode.com/problems/merge-two-sorted-lists/" target="_blank" rel="noopener">https://leetcode.com/problems/merge-two-sorted-lists/</a></p><p>Merge two sorted linked lists and return it as a new list. The new list should be made by splicing together the nodes of the first two lists.</p><p><strong>思路</strong>：要求合并两个排好序的链表。开始我们初始化头front和尾tail，然后从两个单链表的头部比较两个单链表，两链表同时不为空的条件下递归比较：</p><ul><li>如果l1的值大于l2的值，就将尾部指向l1，并同步向右移动l1的头指针和tail指针</li><li>如果l1的值小于l2的值，就将尾部指向l2，并同步向右移动l2的头指针和tail指针</li></ul><p>接着，如果l1不为空，则将尾指针的下一个指向l1，如果l2不为空，则将尾指针的下一个指向l2，然后将front右移一位，</p><p>最后返回front即可。</p><p>Code(c++):</p><figure class="highlight xl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * struct ListNode {</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode *next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) : val(x), next(NULL) {}</span></span><br><span class="line"><span class="comment"> * };</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    ListNode* mergeTwoLists(ListNode* l1, ListNode* l2) {</span><br><span class="line">        <span class="keyword">if</span>(l1 == NULL) return l2;</span><br><span class="line">        <span class="keyword">if</span>(l2 == NULL) return l1;</span><br><span class="line">        </span><br><span class="line">        ListNode* front = new ListNode(-<span class="number">1</span>);</span><br><span class="line">        ListNode* tail = front;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span>( l1 &amp;&amp; l2){</span><br><span class="line">            <span class="function"><span class="title">if</span>(l1-&gt;</span><span class="function"><span class="title">val</span> &lt; l2-&gt;</span>val){</span><br><span class="line">                <span class="function"><span class="title">tail</span>-&gt;</span>next = l1;</span><br><span class="line">                <span class="function"><span class="title">l1</span> = l1-&gt;</span>next;</span><br><span class="line">                <span class="function"><span class="title">tail</span> = tail-&gt;</span>next;</span><br><span class="line">            }<span class="keyword">else</span> {</span><br><span class="line">                <span class="function"><span class="title">tail</span>-&gt;</span>next = l2;</span><br><span class="line">                <span class="function"><span class="title">l2</span> = l2-&gt;</span>next;</span><br><span class="line">                <span class="function"><span class="title">tail</span> = tail-&gt;</span>next;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span>(l1){</span><br><span class="line">            <span class="function"><span class="title">tail</span>-&gt;</span>next = l1;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span>(l2){</span><br><span class="line">            <span class="function"><span class="title">tail</span>-&gt;</span>next = l2;</span><br><span class="line">        }</span><br><span class="line">        <span class="function"><span class="title">front</span> = front-&gt;</span>next;</span><br><span class="line">        return front;</span><br><span class="line">        </span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-26-Remove-Duplicates-from-Sorted-Array"><a href="#Leetcode-26-Remove-Duplicates-from-Sorted-Array" class="headerlink" title="Leetcode[26]-Remove Duplicates from Sorted Array"></a>Leetcode[26]-Remove Duplicates from Sorted Array</h1><p>Link: <a href="https://leetcode.com/problems/remove-duplicates-from-sorted-array/" target="_blank" rel="noopener">https://leetcode.com/problems/remove-duplicates-from-sorted-array/</a></p><p>Given a sorted array, remove the duplicates in place such that each element appear only once and return the new length.</p><p>Do not allocate extra space for another array, you must do this in place with constant memory.</p><p>For example,<br>Given input array nums = [1,1,2],</p><p>Your function should return length = 2, with the first two elements of nums being 1 and 2 respectively. It doesn’t matter what you leave beyond the new length.</p><hr><p><strong>思路</strong>：需要额外添加一个新的变量pos，初始值为0，用来记录非重复元素的位置。从数组的第二个元素开始遍历，如果和前面的元素相等，则直接跳到下一个；如果不等，则将该数组的值赋值给++pos位，接着继续遍历下一个；</p><p><strong>Code(c++):</strong></p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">removeDuplicates</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>{</span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">if</span>(n==<span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> pos = <span class="number">0</span>,i = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(i &lt; n){</span><br><span class="line">            <span class="keyword">if</span>(nums[i] == nums[i<span class="number">-1</span>]){</span><br><span class="line">                i++;</span><br><span class="line">            }<span class="keyword">else</span>{</span><br><span class="line">                nums[++pos] = nums[i++];</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        n = pos+<span class="number">1</span>;</span><br><span class="line">        nums.resize(n);</span><br><span class="line">        <span class="keyword">return</span> n;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p>做个简单的修改：</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">removeDuplicates</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>{</span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">if</span>(n==<span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> pos = <span class="number">1</span>,i = <span class="number">1</span>;<span class="comment">//将pos从1开始</span></span><br><span class="line">        <span class="keyword">while</span>(i &lt; n){</span><br><span class="line">            <span class="keyword">if</span>(nums[i] == nums[i<span class="number">-1</span>]){</span><br><span class="line">                i++;</span><br><span class="line">            }<span class="keyword">else</span>{</span><br><span class="line">                nums[pos++] = nums[i++];<span class="comment">//这里保持一致</span></span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        n = pos;</span><br><span class="line">        nums.resize(n);</span><br><span class="line">        <span class="keyword">return</span> n;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p><strong>Python代码</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">removeDuplicates</span><span class="params">(self, nums)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        n = len(nums)</span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">0</span>: </span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        pos = <span class="number">1</span>;i = <span class="number">1</span>;count=<span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i &lt; n:</span><br><span class="line">            <span class="keyword">if</span> nums[i] == nums[i<span class="number">-1</span>]:</span><br><span class="line">                i=i+<span class="number">1</span></span><br><span class="line">                count=count+<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                nums[pos] = nums[i]</span><br><span class="line">                pos = pos+<span class="number">1</span></span><br><span class="line">                i = i + <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(count):</span><br><span class="line">            nums.pop(<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">return</span> len(nums)</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-27-Remove-Element"><a href="#Leetcode-27-Remove-Element" class="headerlink" title="Leetcode[27]-Remove Element"></a>Leetcode[27]-Remove Element</h1><p>Link: <a href="https://leetcode.com/problems/remove-element/" target="_blank" rel="noopener">https://leetcode.com/problems/remove-element/</a></p><p>Given an array and a value, remove all instances of that value in place and return the new length.</p><p>The order of elements can be changed. It doesn’t matter what you leave beyond the new length.</p><hr><p>思路：遍历数组，如果数组对应的数等于给定的值，数组最后一位和当前位互换，然后将数组长度减一；否则，就执行i++;最后重置数组长度。</p><p>Code(c++):</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span> *a, <span class="keyword">int</span> *b)</span></span>{</span><br><span class="line">        <span class="keyword">int</span> temp = *a;</span><br><span class="line">        *a = *b;</span><br><span class="line">        *b = temp;</span><br><span class="line">    }</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">removeElement</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> val)</span> </span>{</span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">if</span>(n == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>( i &lt; n){</span><br><span class="line">            <span class="keyword">if</span>(nums[i] == val) {</span><br><span class="line">                swap(&amp;nums[i],&amp;nums[n<span class="number">-1</span>]);</span><br><span class="line">                n--;</span><br><span class="line">            }<span class="keyword">else</span>{</span><br><span class="line">                i++;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        nums.resize(n);</span><br><span class="line">        <span class="keyword">return</span> n;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-33-Search-in-Rotated-Sorted-Array"><a href="#Leetcode-33-Search-in-Rotated-Sorted-Array" class="headerlink" title="Leetcode[33]-Search in Rotated Sorted Array"></a>Leetcode[33]-Search in Rotated Sorted Array</h1><p>Link: <a href="https://leetcode.com/problems/search-in-rotated-sorted-array/" target="_blank" rel="noopener">https://leetcode.com/problems/search-in-rotated-sorted-array/</a></p><p>Suppose a sorted array is rotated at some pivot unknown to you beforehand.</p><p>(i.e., 0 1 2 4 5 6 7 might become 4 5 6 7 0 1 2).</p><p>You are given a target value to search. If found in the array return its index, otherwise return -1.</p><p>You may assume no duplicate exists in the array.</p><hr><p>C++:</p><p>方法一：直接for循环求解</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">search</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span> </span>{</span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i&lt;n; i++){</span><br><span class="line">            <span class="keyword">if</span>(nums[i] == target) <span class="keyword">return</span> i;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p>方法二：二分搜索求解<br>分析：从中点处划分，左右两边一定有一部分是有序的，对于有序的分别做判断。</p><figure class="highlight aspectj"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>{</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> search(vector&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> <span class="keyword">target</span>) {</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>, j = nums.size()<span class="number">-1</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span>(i&lt;=j){</span><br><span class="line">            <span class="keyword">int</span> mid = (i+j)/<span class="number">2</span>;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span>(nums[mid] == <span class="keyword">target</span>) </span><br><span class="line">                <span class="keyword">return</span> mid;</span><br><span class="line">            <span class="comment">//if left is sorted</span></span><br><span class="line">            <span class="function"><span class="keyword">else</span> <span class="title">if</span><span class="params">(nums[i] &lt;= nums[mid])</span></span>{</span><br><span class="line">                <span class="keyword">if</span>(nums[i] &lt;= <span class="keyword">target</span> &amp;&amp; <span class="keyword">target</span> &lt; nums[mid]) </span><br><span class="line">                    j = mid<span class="number">-1</span>;</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    i = mid + <span class="number">1</span>;</span><br><span class="line">            }<span class="keyword">else</span> {</span><br><span class="line">                <span class="keyword">if</span>(nums[mid] &lt; <span class="keyword">target</span> &amp;&amp; <span class="keyword">target</span> &lt;= nums[j] ) </span><br><span class="line">                    i = mid +<span class="number">1</span>;</span><br><span class="line">                <span class="keyword">else</span> </span><br><span class="line">                    j = mid<span class="number">-1</span>;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-35-Search-Insert-Position"><a href="#Leetcode-35-Search-Insert-Position" class="headerlink" title="Leetcode[35]-Search Insert Position"></a>Leetcode[35]-Search Insert Position</h1><p>Link: <a href="https://leetcode.com/problems/search-insert-position/" target="_blank" rel="noopener">https://leetcode.com/problems/search-insert-position/</a></p><p>Given a sorted array and a target value, return the index if the target is found. If not, return the index where it would be if it were inserted in order.</p><p>You may assume no duplicates in the array.</p><pre><code>Here are few examples.[1,3,5,6], 5 → 2[1,3,5,6], 2 → 1[1,3,5,6], 7 → 4[1,3,5,6], 0 → 0</code></pre><p>题目比较简单，直接给出答案吧<br>code(c++):</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">searchInsert</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span> </span>{</span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">bool</span> flag = <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">while</span>(i&lt;n) {</span><br><span class="line">            <span class="keyword">if</span>( nums[i] &gt;= target) {</span><br><span class="line">                flag = <span class="literal">true</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            }</span><br><span class="line">            ++i;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> i;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-36-Valid-Sudoku"><a href="#Leetcode-36-Valid-Sudoku" class="headerlink" title="Leetcode[36]-Valid Sudoku"></a>Leetcode[36]-Valid Sudoku</h1><p>Link:<a href="https://leetcode.com/problems/valid-sudoku/" target="_blank" rel="noopener">https://leetcode.com/problems/valid-sudoku/</a></p><p>Determine if a Sudoku is valid, according to: Sudoku Puzzles - The Rules.</p><p>The Sudoku board could be partially filled, where empty cells are filled with the character ‘.’.<br><img src="http://img.blog.csdn.net/20150609210526658" alt="这里写图片描述"></p><p>A partially filled sudoku which is valid.</p><p>Note:<br>A valid Sudoku board (partially filled) is not necessarily solvable. Only the filled cells need to be validated.</p><hr><p>分析：验证一个数独的合法性，从三个方向入手</p><ul><li>每一行不能出现重复元素</li><li>每一列不能出现重复元素</li><li>每一个九方格不能出现重复元素</li></ul><p>我采用的是map来保存元素的数值，然后判断map中是否有，有则返回false；参数之间的关系推导如下：<br><img src="http://img.blog.csdn.net/20150609213752137" alt="这里写图片描述"><br><br>代码如下</p><p>Code(c++):</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isValidSudoku</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt;&gt;&amp; board)</span> </span>{</span><br><span class="line">        <span class="comment">//row</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span>  i = <span class="number">0</span>; i&lt;<span class="number">9</span>; i++) {</span><br><span class="line">            <span class="built_in">map</span>&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt; mp;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j&lt;<span class="number">9</span>; j++){</span><br><span class="line">                <span class="keyword">if</span>(mp.<span class="built_in">find</span>(board[i][j])!=mp.<span class="built_in">end</span>())</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                <span class="keyword">if</span>(board[i][j] == <span class="string">'.'</span>)<span class="keyword">continue</span>;</span><br><span class="line">                mp[board[i][j]] = j;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//cow</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span>  j = <span class="number">0</span>; j&lt;<span class="number">9</span>; j++) {</span><br><span class="line">            <span class="built_in">map</span>&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt; mp;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i&lt;<span class="number">9</span>; i++){</span><br><span class="line">                <span class="keyword">if</span>(mp.<span class="built_in">find</span>(board[i][j])!=mp.<span class="built_in">end</span>())</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                <span class="keyword">if</span>(board[i][j] == <span class="string">'.'</span>)<span class="keyword">continue</span>;</span><br><span class="line">                mp[board[i][j]] = i;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//board</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">9</span>; i++){</span><br><span class="line">            <span class="built_in">map</span>&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; mp;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = (i/<span class="number">3</span>)*<span class="number">3</span>; j &lt; <span class="number">3</span> + (i/<span class="number">3</span>)*<span class="number">3</span> ; j++){</span><br><span class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> k = (<span class="number">3</span>*i)%<span class="number">9</span>; k &lt;= (<span class="number">3</span>*(i+<span class="number">1</span>)<span class="number">-1</span>)%<span class="number">9</span>; k++){</span><br><span class="line">                    <span class="keyword">if</span>(mp.<span class="built_in">find</span>(board[j][k])!=mp.<span class="built_in">end</span>())</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                    <span class="keyword">if</span>(board[j][k] == <span class="string">'.'</span>)<span class="keyword">continue</span>;</span><br><span class="line">                    mp[board[j][k]] = k;</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        </span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-53-Maximum-Subarray"><a href="#Leetcode-53-Maximum-Subarray" class="headerlink" title="Leetcode[53]-Maximum Subarray"></a>Leetcode[53]-Maximum Subarray</h1><p>Link: <a href="https://leetcode.com/problems/maximum-subarray/" target="_blank" rel="noopener">https://leetcode.com/problems/maximum-subarray/</a></p><p>Find the contiguous subarray within an array (containing at least one number) which has the largest sum.</p><p>For example, given the array [−2,1,−3,4,−1,2,1,−5,4],<br>the contiguous subarray [4,−1,2,1] has the largest sum = 6.</p><p>More practice:<br>If you have figured out the O(n) solution, try coding another solution using the divide and conquer approach, which is more subtle.</p><hr><p>给定一个长度为n的序列，求其最大子序列和。<br>算法思路：使用动态规划求解，dp[i]表示在尾数在位置i上的最大子序列和，那么dp[i]可以表示为</p><ul><li>dp[i] = max(dp[i-1] + nums[i],nums[i])</li><li>dp[0] = nums[0]</li></ul><p>其中dp[0]表示初值。</p><p><strong>C++代码如下：</strong></p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxSubArray</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>{</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">dp</span><span class="params">(n)</span></span>;</span><br><span class="line">        dp[<span class="number">0</span>] = nums[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">int</span> answer = dp[<span class="number">0</span>];</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;n; ++i){</span><br><span class="line">            dp[i] = <span class="built_in">max</span>(dp[i<span class="number">-1</span>]+nums[i],nums[i]);</span><br><span class="line">            answer = <span class="built_in">max</span>(answer,dp[i]);</span><br><span class="line">        }</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> answer;</span><br><span class="line">        </span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p><strong>Python代码如下：</strong></p><figure class="highlight vim"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def maxSubArray(self, nums):</span><br><span class="line">        <span class="string">""</span><span class="comment">"</span></span><br><span class="line">        :<span class="built_in">type</span> num<span class="variable">s:</span> List[<span class="keyword">int</span>]</span><br><span class="line">        :rtype: <span class="keyword">int</span></span><br><span class="line">        <span class="string">""</span><span class="comment">"</span></span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        ans = nums[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">dp</span> = []</span><br><span class="line">        <span class="keyword">dp</span>.<span class="keyword">append</span>(ans)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i in <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">            <span class="keyword">dp</span>.<span class="keyword">append</span>(<span class="built_in">max</span>(<span class="keyword">dp</span>[i-<span class="number">1</span>] + nums[i],nums[i]))</span><br><span class="line">            ans = <span class="built_in">max</span>(<span class="keyword">dp</span>[i], ans)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-62-Unique-Paths"><a href="#Leetcode-62-Unique-Paths" class="headerlink" title="Leetcode[62]-Unique Paths"></a>Leetcode[62]-Unique Paths</h1><p>Link: <a href="https://leetcode.com/problems/unique-paths/" target="_blank" rel="noopener">https://leetcode.com/problems/unique-paths/</a></p><p>A robot is located at the top-left corner of a m x n grid (marked ‘Start’ in the diagram below).</p><p>The robot can only move either down or right at any point in time. The robot is trying to reach the bottom-right corner of the grid (marked ‘Finish’ in the diagram below).</p><p>How many possible unique paths are there?</p><p><img src="http://articles.leetcode.com/wp-content/uploads/2014/12/robot_maze.png" alt="这里写图片描述"></p><p>Above is a 3 x 7 grid. How many possible unique paths are there?</p><p>Note: m and n will be at most 100.</p><hr><p>题目：给定一个m*n的矩阵，让机器人从左上方走到右下方，只能往下和往右走，一共多少种走法。</p><p>思路：采用动态规划设计思想，到第0列和第0行的任何位置都只有1种走法，即初始化为d[0][*] = 1,d[*][0] = 1;当机器人走到第i行第j列的时候，它的走法总数是等于第i-1行第j列的总数加上第i行第j-1列的总数，即dp [ i ] [ j ]  = d[i-1][j] + dp[i][j-1].代码如下:</p><p>Code(c++): </p><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">uniquePaths</span><span class="params">(<span class="keyword">int</span> m, <span class="keyword">int</span> n)</span> </span>{</span><br><span class="line">        <span class="function"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; <span class="title">dp</span><span class="params">(m,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; (n))</span></span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; m; k++) {</span><br><span class="line">            dp[k][<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> t = <span class="number">0</span>; t &lt; n; t++) {</span><br><span class="line">            dp[<span class="number">0</span>][t] = <span class="number">1</span>;        </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; m; i++) {</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>; j &lt; n; j++){</span><br><span class="line">                dp[i][j] = dp[i<span class="number">-1</span>][j] + dp[i][j<span class="number">-1</span>];</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> dp[m<span class="number">-1</span>][n<span class="number">-1</span>];</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-63-Unique-Paths-II"><a href="#Leetcode-63-Unique-Paths-II" class="headerlink" title="Leetcode[63]-Unique Paths II"></a>Leetcode[63]-Unique Paths II</h1><p>Link: <a href="https://leetcode.com/problems/unique-paths-ii/" target="_blank" rel="noopener">https://leetcode.com/problems/unique-paths-ii/</a></p><p>Follow up for “Unique Paths”:</p><p>Now consider if some obstacles are added to the grids. How many unique paths would there be?</p><p>An obstacle and empty space is marked as 1 and 0 respectively in the grid.</p><p>For example,<br>There is one obstacle in the middle of a 3x3 grid as illustrated below.</p><pre><code>[  [0,0,0],  [0,1,0],  [0,0,0]]</code></pre><p>The total number of unique paths is 2.</p><p>题意：在上题的基础上增加了点限制条件，不过大体上还是差不多的，还是采用动态规划思想，找到初始值和递推关系，和上体相比较，只是初始化和到达dp[i][j]时要加点判断语句，</p><ul><li>第0列，从上到下，如果碰到一个1，则设置该位置和后面的位置都不可到达，即dp[i to n][0]；</li><li>第0行，从左到右，如果碰到一个1，则设置该位置和右方的位置都不可到达，即dp[0][i to n];</li><li>其它位置，如果该位置不为1，则到达该位置的方式共有 dp[i][j] = dp[i-1][j] + dp[i][j-1],如果为1，则dp[i][j] = 0；</li></ul><p>代码如下：</p><p>Code(c++):</p><figure class="highlight matlab"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int uniquePathsWithObstacles(vector&lt;vector&lt;int&gt;&gt;&amp; obstacleGrid) {</span><br><span class="line">        </span><br><span class="line">        int m = obstacleGrid.<span class="built_in">size</span>(),n = obstacleGrid[<span class="number">0</span>].<span class="built_in">size</span>();</span><br><span class="line">        vector&lt;vector&lt;int&gt; &gt; dp(m, vector&lt;int&gt;(n));</span><br><span class="line">        </span><br><span class="line">        bool flag = <span class="built_in">false</span>;</span><br><span class="line">        <span class="keyword">for</span>(int <span class="built_in">i</span> = <span class="number">0</span>; <span class="built_in">i</span> &lt; m; <span class="built_in">i</span>++) {</span><br><span class="line">            <span class="keyword">if</span>(obstacleGrid[<span class="built_in">i</span>][<span class="number">0</span>] == <span class="number">1</span>) flag = <span class="built_in">true</span>;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span>(flag == <span class="built_in">false</span> )dp[<span class="built_in">i</span>][<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span> dp[<span class="built_in">i</span>][<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">        }  </span><br><span class="line">        </span><br><span class="line">        flag = <span class="built_in">false</span>;</span><br><span class="line">        <span class="keyword">for</span>(int <span class="built_in">j</span> = <span class="number">0</span>; <span class="built_in">j</span> &lt; n; <span class="built_in">j</span>++) {</span><br><span class="line">            <span class="keyword">if</span>(obstacleGrid[<span class="number">0</span>][<span class="built_in">j</span>] == <span class="number">1</span>) flag = <span class="built_in">true</span>;</span><br><span class="line">            <span class="keyword">if</span>(flag == <span class="built_in">false</span> )dp[<span class="number">0</span>][<span class="built_in">j</span>] = <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span> dp[<span class="number">0</span>][<span class="built_in">j</span>] = <span class="number">0</span>;</span><br><span class="line">        }    </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(int <span class="built_in">i</span> = <span class="number">1</span>; <span class="built_in">i</span> &lt; m; <span class="built_in">i</span>++) {</span><br><span class="line">            <span class="keyword">for</span>(int <span class="built_in">j</span> = <span class="number">1</span>; <span class="built_in">j</span> &lt; n; <span class="built_in">j</span>++){</span><br><span class="line">                <span class="keyword">if</span>(obstacleGrid[<span class="built_in">i</span>][<span class="built_in">j</span>] == <span class="number">1</span>) obstacleGrid[<span class="built_in">i</span>][<span class="built_in">j</span>] = <span class="number">0</span>; </span><br><span class="line">                <span class="keyword">else</span> dp[<span class="built_in">i</span>][<span class="built_in">j</span>] = dp[<span class="built_in">i</span><span class="number">-1</span>][<span class="built_in">j</span>] + dp[<span class="built_in">i</span>][<span class="built_in">j</span><span class="number">-1</span>];</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> dp[m<span class="number">-1</span>][n<span class="number">-1</span>];</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-66-Plus-One"><a href="#Leetcode-66-Plus-One" class="headerlink" title="Leetcode[66]-Plus One"></a>Leetcode[66]-Plus One</h1><p>Link:<a href="https://leetcode.com/problems/plus-one/" target="_blank" rel="noopener">https://leetcode.com/problems/plus-one/</a></p><p>Given a non-negative number represented as an array of digits, plus one to the number.</p><p>The digits are stored such that the most significant digit is at the head of the list.</p><hr><p>题意：给定一个数组，表示的是非负数的各个位的数，现在将该数加一，求加一后得到的数组。</p><p>分析：由于加以后数组的长度可能发生变化，说以不能单纯的直接在数组后面加一。可以先将数组翻转，个位转到前面来，然后从前往后依次加一，最后判断如果在最后一位相加超过十了，就将数组长度加一，代码如下：</p><p>Code(c++):</p><figure class="highlight fortran"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> Solution {</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;<span class="built_in">int</span>&gt; plusOne(vector&lt;<span class="built_in">int</span>&gt;&amp; <span class="built_in">digits</span>) {</span><br><span class="line">        <span class="built_in">int</span> n = <span class="built_in">digits</span>.<span class="built_in">size</span>();</span><br><span class="line">        reverse(<span class="built_in">digits</span>.begin(),<span class="built_in">digits</span>.<span class="keyword">end</span>());</span><br><span class="line">        <span class="built_in">int</span> temp = <span class="number">0</span>,flag = false;</span><br><span class="line">        for(<span class="built_in">int</span> i = <span class="number">0</span>; i&lt;n ; i++) {</span><br><span class="line">            <span class="keyword">if</span>(i==<span class="number">0</span>) temp =<span class="number">1</span>;</span><br><span class="line">            <span class="built_in">int</span> <span class="built_in">sum</span> = <span class="built_in">digits</span>[i] + temp;</span><br><span class="line">            <span class="built_in">digits</span>[i] = <span class="built_in">sum</span> %<span class="number">10</span>;</span><br><span class="line">            temp = <span class="built_in">sum</span>/<span class="number">10</span>;</span><br><span class="line">            <span class="keyword">if</span>(i == n-<span class="number">1</span> &amp;&amp; <span class="built_in">sum</span> &gt;= <span class="number">10</span>)</span><br><span class="line">                flag = true;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span>(flag){</span><br><span class="line">            <span class="built_in">digits</span>.resize(n+<span class="number">1</span>);</span><br><span class="line">            <span class="built_in">digits</span>[n] = temp;</span><br><span class="line">        }</span><br><span class="line">        reverse(<span class="built_in">digits</span>.begin(),<span class="built_in">digits</span>.<span class="keyword">end</span>());</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">digits</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-70-Climbing-Stairs"><a href="#Leetcode-70-Climbing-Stairs" class="headerlink" title="Leetcode[70]-Climbing Stairs"></a>Leetcode[70]-Climbing Stairs</h1><p>Link: <a href="https://leetcode.com/problems/climbing-stairs/" target="_blank" rel="noopener">https://leetcode.com/problems/climbing-stairs/</a></p><p>You are climbing a stair case. It takes n steps to reach to the top.</p><p>Each time you can either climb 1 or 2 steps. In how many distinct ways can you climb to the top?</p><hr><p>题意：给你一个n阶的台阶，你一次最多只能上2个台阶，请问一共有多少个走法？</p><p>分析：典型的斐波那契数列题目，可以使用递归求解，也可以使用DP方法求解；</p><p>i表示阶梯数，f(i)表示有多少种走法；</p><ul><li>当i = 1时，f(1) = 1,</li><li>当i = 2时，f(2) = 2;</li><li>当i &gt; 3时，f(i) = f(i-1) + f(i-2)。</li></ul><p>其实很容易理解，当阶梯数大于2时，它的走法可以是从n-1阶梯走一步，或是从n-2阶梯处一次走两步到达，即f(i) = f(i-1) + f(i-2)。</p><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">climbStairs</span><span class="params">(<span class="keyword">int</span> n)</span> </span>{</span><br><span class="line">        <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">dp</span><span class="params">(n)</span></span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++){</span><br><span class="line">            <span class="keyword">if</span>(i &lt; <span class="number">2</span>) dp[i] = i + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span> dp[i] = dp[i<span class="number">-1</span>] + dp[i<span class="number">-2</span>];</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> dp[n<span class="number">-1</span>];</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-74-Search-a-2D-Matrix"><a href="#Leetcode-74-Search-a-2D-Matrix" class="headerlink" title="Leetcode[74]-Search a 2D Matrix"></a>Leetcode[74]-Search a 2D Matrix</h1><p>Link: <a href="https://leetcode.com/problems/search-a-2d-matrix/" target="_blank" rel="noopener">https://leetcode.com/problems/search-a-2d-matrix/</a></p><p>Write an efficient algorithm that searches for a value in an m x n matrix. This matrix has the following properties:</p><p>Integers in each row are sorted from left to right.<br>The first integer of each row is greater than the last integer of the previous row.<br>For example,</p><p>Consider the following matrix:</p><figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">  [<span class="number">1</span>,   <span class="number">3</span>,  <span class="number">5</span>,  <span class="number">7</span>],</span><br><span class="line">  [<span class="number">10</span>, <span class="number">11</span>, <span class="number">16</span>, <span class="number">20</span>],</span><br><span class="line">  [<span class="number">23</span>, <span class="number">30</span>, <span class="number">34</span>, <span class="number">50</span>]</span><br><span class="line">]</span><br></pre></td></tr></tbody></table></figure><p>Given target = 3, return true.</p><hr><p>这道题之前做过：<a href="http://blog.csdn.net/dream_angel_z/article/details/46413705" target="_blank" rel="noopener">查找特殊矩阵中的一个数</a></p><p>算法思路：</p><p>起始从右上角开始查找，a[i][j]初试值为a[0][n-1]，循环下列<br>while( i &lt; n &amp;&amp; j &gt;= 0)<br>如果key &lt; a[i][j],往左走，j–，<br>如果key &gt; a[i][j],则往下走，执行i++<br>如果key == a[i][j],表示找到了</p><p>C++代码：</p><figure class="highlight stan"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    bool searchMatrix(<span class="keyword">vector</span>&lt;<span class="keyword">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; <span class="keyword">matrix</span>, <span class="keyword">int</span> <span class="built_in">target</span>) {</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> m = <span class="keyword">matrix</span>.<span class="built_in">size</span>(), n = <span class="keyword">matrix</span>[<span class="number">0</span>].<span class="built_in">size</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> i=<span class="number">0</span>,j = n-<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>( i &lt; m &amp;&amp; j &gt;= <span class="number">0</span>){</span><br><span class="line">            <span class="keyword">if</span>( <span class="built_in">target</span> &lt; <span class="keyword">matrix</span>[i][j] ) j--;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>( <span class="built_in">target</span> &gt; <span class="keyword">matrix</span>[i][j] ) i++;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">return</span> true;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> false;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-81-Search-for-a-Range"><a href="#Leetcode-81-Search-for-a-Range" class="headerlink" title="Leetcode[81]-Search for a Range"></a>Leetcode[81]-Search for a Range</h1><p>Link: <a href="https://leetcode.com/problems/search-in-rotated-sorted-array-ii/" target="_blank" rel="noopener">https://leetcode.com/problems/search-in-rotated-sorted-array-ii/</a></p><p>Given a sorted array of integers, find the starting and ending position of a given target value.</p><p>Your algorithm’s runtime complexity must be in the order of O(log n).</p><p>If the target is not found in the array, return [-1, -1].</p><p>For example,<br>Given [5, 7, 7, 8, 8, 10] and target value 8,<br>return [3, 4].</p><hr><p>思路：首先初始化一个2列的数组，值为-1，然后一次遍历数组，设置一个变量作为标识，记录出现target值的下标，并保存到数组中，如果标识值等于=了，就不增加它的值，保证数组第二个元素是最后一个出现target的下标。</p><p>C++:</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">searchRange</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span> </span>{</span><br><span class="line">        <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">res</span><span class="params">(<span class="number">2</span>)</span></span>;</span><br><span class="line">        res[<span class="number">0</span>]=<span class="number">-1</span>,res[<span class="number">1</span>]=<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> temp = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++){</span><br><span class="line">            <span class="keyword">if</span>(target == nums[i]){</span><br><span class="line">                <span class="keyword">if</span>(temp == <span class="number">2</span>)</span><br><span class="line">                    res[temp<span class="number">-1</span>] = i;</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    res[temp++] = i;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span>(temp ==<span class="number">1</span>) {</span><br><span class="line">            res[temp] = res[<span class="number">0</span>];</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-82-Remove-Duplicates-from-Sorted-List-II"><a href="#Leetcode-82-Remove-Duplicates-from-Sorted-List-II" class="headerlink" title="Leetcode[82]-Remove Duplicates from Sorted List II"></a>Leetcode[82]-Remove Duplicates from Sorted List II</h1><p>Link: <a href="https://leetcode.com/problems/remove-duplicates-from-sorted-list-ii/" target="_blank" rel="noopener">https://leetcode.com/problems/remove-duplicates-from-sorted-list-ii/</a></p><p>Given a sorted linked list, delete all nodes that have duplicate numbers, leaving only distinct numbers from the original list.</p><p>For example,<br>Given <code>1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5</code>, return<code>1-&gt;2-&gt;5</code>.<br>Given <code>1-&gt;1-&gt;1-&gt;2-&gt;3</code>, return <code>2-&gt;3</code>.</p><hr><p>思路：跟上道题<a href="http://blog.csdn.net/dream_angel_z/article/details/46446067" target="_blank" rel="noopener">Leetcode[83]-Remove Duplicates from Sorted List</a>算法有点区别，这道题需要设置一个标示符，如果某一趟比较的时候两个元素相等了，就设flag等于true，接着下一趟循环如果两个元素不相等，但此时的flag为true，就需要将两个元素前面的那个删掉。</p><p>最后，必定第二个元素为空而终止，此时还需要判断flag是否为true，如果为true，则末尾的元素还需要删掉；</p><p>代码如下：<br>Code(c++):</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * struct ListNode {</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode *next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) : val(x), next(NULL) {}</span></span><br><span class="line"><span class="comment"> * };</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">deleteDuplicates</span><span class="params">(ListNode* head)</span> </span>{</span><br><span class="line">       ListNode * newList = <span class="keyword">new</span> ListNode(<span class="number">-1</span>);</span><br><span class="line">        newList-&gt;next = head;</span><br><span class="line">        ListNode *pre = newList;</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">bool</span> flag = <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">while</span>(pre-&gt;next &amp;&amp; pre-&gt;next-&gt;next){</span><br><span class="line">            <span class="keyword">if</span>(pre-&gt;next-&gt;val == pre-&gt;next-&gt;next-&gt;val){</span><br><span class="line">                pre-&gt;next = pre-&gt;next-&gt;next;</span><br><span class="line">                flag = <span class="literal">true</span>;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            }</span><br><span class="line">            <span class="keyword">if</span>(flag == <span class="literal">true</span>){</span><br><span class="line">                pre-&gt;next = pre-&gt;next-&gt;next;</span><br><span class="line">                flag = <span class="literal">false</span>;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            }</span><br><span class="line">            pre = pre-&gt;next;</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">//最后还需要判断是否上次判断时元素重复</span></span><br><span class="line">        <span class="keyword">if</span>(flag == <span class="literal">true</span>){</span><br><span class="line">            pre-&gt;next = pre-&gt;next-&gt;next;</span><br><span class="line">        }</span><br><span class="line">        head = newList-&gt;next;</span><br><span class="line">        <span class="keyword">return</span> head;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-83-Remove-Duplicates-from-Sorted-List"><a href="#Leetcode-83-Remove-Duplicates-from-Sorted-List" class="headerlink" title="Leetcode[83]-Remove Duplicates from Sorted List"></a>Leetcode[83]-Remove Duplicates from Sorted List</h1><p>Link: <a href="https://leetcode.com/problems/remove-duplicates-from-sorted-list/" target="_blank" rel="noopener">https://leetcode.com/problems/remove-duplicates-from-sorted-list/</a></p><p>Given a sorted linked list, delete all duplicates such that each element appear only once.</p><p>For example,</p><pre><code>Given 1-&gt;1-&gt;2, return 1-&gt;2.Given 1-&gt;1-&gt;2-&gt;3-&gt;3, return 1-&gt;2-&gt;3.</code></pre><hr><p>比较简单，直接贴代码了！</p><p>C++:</p><figure class="highlight ocaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * <span class="type">Definition</span> <span class="keyword">for</span> singly-linked <span class="built_in">list</span>.</span><br><span class="line"> * <span class="keyword">struct</span> <span class="type">ListNode</span> {</span><br><span class="line"> *     <span class="built_in">int</span> <span class="keyword">val</span>;</span><br><span class="line"> *     <span class="type">ListNode</span> *next;</span><br><span class="line"> *     <span class="type">ListNode</span>(<span class="built_in">int</span> x) : <span class="keyword">val</span>(x), next(<span class="type">NULL</span>) {}</span><br><span class="line"> * };</span><br><span class="line"> */</span><br><span class="line"><span class="keyword">class</span> <span class="type">Solution</span> {</span><br><span class="line">public:</span><br><span class="line">    <span class="type">ListNode</span>* deleteDuplicates(<span class="type">ListNode</span>* head) {</span><br><span class="line">        <span class="type">ListNode</span> * pre = head;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span>(pre &amp;&amp; pre-&gt;next){</span><br><span class="line">            <span class="keyword">if</span>(pre-&gt;<span class="keyword">val</span> == pre-&gt;next-&gt;<span class="keyword">val</span>){</span><br><span class="line">                pre-&gt;next = pre-&gt;next-&gt;next;</span><br><span class="line">                continue;</span><br><span class="line">            }</span><br><span class="line">            pre = pre-&gt;next;            </span><br><span class="line">        }</span><br><span class="line">        return head;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p><strong>注意while循环的时候也要判断pre-&gt;next是否为空，如果为空就不用做判断了！</strong></p><hr><h1 id="Leetcode-86-Partition-List"><a href="#Leetcode-86-Partition-List" class="headerlink" title="Leetcode[86]-Partition List"></a>Leetcode[86]-Partition List</h1><p>Link： <a href="https://leetcode.com/problems/partition-list/" target="_blank" rel="noopener">https://leetcode.com/problems/partition-list/</a></p><p>Given a linked list and a value x, partition it such that all nodes less than x come before nodes greater than or equal to x.</p><p>You should preserve the original relative order of the nodes in each of the two partitions.</p><p>For example,<br>Given 1-&gt;4-&gt;3-&gt;2-&gt;5-&gt;2 and x = 3,<br>return 1-&gt;2-&gt;2-&gt;4-&gt;3-&gt;5.</p><hr><p>思路：设置两个临时单链表，一个存放小于x的链表，一个存放大于x的链表，然后遍历head，一次存入两个链表中，最后合并两个链表。</p><p>Code(c++):</p><figure class="highlight coq"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * <span class="keyword">Definition</span> <span class="keyword">for</span> singly-linked list.</span><br><span class="line"> * struct ListNode {</span><br><span class="line"> *     int val;</span><br><span class="line"> *     ListNode *next;</span><br><span class="line"> *     ListNode(int x) : val(x), next(NULL) {}</span><br><span class="line"> * };</span><br><span class="line"> */</span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    ListNode* partition(ListNode* head, int x) {</span><br><span class="line">        <span class="keyword">if</span>(head == NULL |<span class="type">| head</span>-&gt;next==NULL) <span class="keyword">return</span> head;</span><br><span class="line">        ListNode *<span class="built_in">left</span> = new ListNode(<span class="number">-1</span>),*<span class="built_in">right</span> = new ListNode(<span class="number">-1</span>);</span><br><span class="line">        ListNode *ltail = <span class="built_in">left</span>,* rtail = <span class="built_in">right</span>;</span><br><span class="line">        ListNode *pre = head;</span><br><span class="line">        while(pre){</span><br><span class="line">            <span class="keyword">if</span>(pre-&gt;val &lt; x) {</span><br><span class="line">                ltail-&gt;next = pre;</span><br><span class="line">                ltail = ltail-&gt;next;</span><br><span class="line">            }<span class="keyword">else</span>{</span><br><span class="line">                rtail-&gt;next = pre;</span><br><span class="line">                rtail = rtail-&gt;next;</span><br><span class="line">            }</span><br><span class="line">            pre = pre-&gt;next;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">right</span>-&gt;next){</span><br><span class="line">            ltail-&gt;next = <span class="built_in">right</span>-&gt;next;</span><br><span class="line">            rtail-&gt;next = NULL;//<span class="built_in">set</span> rtail <span class="built_in">as</span> NULL, otherwise <span class="built_in">time</span> limited error</span><br><span class="line">        }</span><br><span class="line">        <span class="built_in">left</span> = <span class="built_in">left</span>-&gt;next;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">left</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-88-Merge-Sorted-Array"><a href="#Leetcode-88-Merge-Sorted-Array" class="headerlink" title="Leetcode[88]-Merge Sorted Array"></a>Leetcode[88]-Merge Sorted Array</h1><p>Link:<a href="https://leetcode.com/problems/merge-sorted-array/" target="_blank" rel="noopener">https://leetcode.com/problems/merge-sorted-array/</a></p><p>Given two sorted integer arrays nums1 and nums2, merge nums2 into nums1 as one sorted array.</p><p>Note:<br>You may assume that nums1 has enough space (size that is greater or equal to m + n) to hold additional elements from nums2. The number of elements initialized in nums1 and nums2 are m and n respectively.</p><hr><p>分析：首先将nums1数组容量扩大到m+n,然后进行m+n-1次迭代，从后往前比较nums1和nums2的大小。</p><ul><li>如果nums1的值大于nums2的值，就将nums1的值放到nums1的最后一个；</li><li>如果nums2的值大于nums1的值，就将nums2的值放到nums1的最后一个；</li><li>……</li><li>依次迭代</li><li>……</li></ul><p>最后会必定有一个数组放完了，然后判断，哪个数组没放完，就接着放。</p><p>Code(c++):</p><figure class="highlight matlab"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    void merge(vector&lt;int&gt;&amp; nums1, int m, vector&lt;int&gt;&amp; nums2, int n) {</span><br><span class="line">        nums1.resize(m+n);</span><br><span class="line">        int <span class="built_in">j</span> = m<span class="number">-1</span>, k = n<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">for</span>(int <span class="built_in">i</span> = m+n<span class="number">-1</span>; <span class="built_in">i</span> &gt;= <span class="number">0</span>; --<span class="built_in">i</span>) {</span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">j</span> &gt;=<span class="number">0</span> &amp;&amp; k &gt;= <span class="number">0</span>){</span><br><span class="line">                <span class="keyword">if</span>(nums1[<span class="built_in">j</span>] &gt;= nums2[k]){</span><br><span class="line">                    nums1[<span class="built_in">i</span>] = nums1[<span class="built_in">j</span>--];</span><br><span class="line">                }<span class="keyword">else</span> <span class="keyword">if</span>(nums1[<span class="built_in">j</span>] &lt; nums2[k]){</span><br><span class="line">                    nums1[<span class="built_in">i</span>] = nums2[k--];</span><br><span class="line">                }</span><br><span class="line">            }<span class="keyword">else</span> <span class="keyword">if</span>(k&gt;=<span class="number">0</span>){</span><br><span class="line">                nums1[<span class="built_in">i</span>] = nums2[k--];</span><br><span class="line">            }<span class="keyword">else</span> <span class="keyword">if</span>(<span class="built_in">j</span>&gt;=<span class="number">0</span>){</span><br><span class="line">                nums1[<span class="built_in">i</span>] = nums1[<span class="built_in">j</span>--];</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p>方法二：</p><figure class="highlight matlab"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    void merge(vector&lt;int&gt;&amp; nums1, int m, vector&lt;int&gt;&amp; nums2, int n) {</span><br><span class="line">        int s = m+n<span class="number">-1</span>;</span><br><span class="line">        nums1.resize(m+n);</span><br><span class="line">        int <span class="built_in">i</span> = m<span class="number">-1</span>,<span class="built_in">j</span> = n<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">while</span>(<span class="built_in">i</span>&gt;=<span class="number">0</span> &amp;&amp; <span class="built_in">j</span>&gt;=<span class="number">0</span>){</span><br><span class="line">            <span class="keyword">if</span> (nums1[<span class="built_in">i</span>] &gt;= nums2[<span class="built_in">j</span>]){</span><br><span class="line">                nums1[s--] = nums1[<span class="built_in">i</span>--];</span><br><span class="line">            }<span class="keyword">else</span> <span class="keyword">if</span>(nums1[<span class="built_in">i</span>] &lt;nums2[<span class="built_in">j</span>]){</span><br><span class="line">                nums1[s--] = nums2[<span class="built_in">j</span>--];</span><br><span class="line">            }</span><br><span class="line">        }  </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span>(<span class="built_in">j</span>&gt;=<span class="number">0</span>){</span><br><span class="line">            nums1[s--] = nums2[<span class="built_in">j</span>--];</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">while</span>(<span class="built_in">i</span>&gt;=<span class="number">0</span>){</span><br><span class="line">            nums1[s--] = nums1[<span class="built_in">i</span>--];</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-92-Reverse-Linked-List-II"><a href="#Leetcode-92-Reverse-Linked-List-II" class="headerlink" title="Leetcode[92]-Reverse Linked List II"></a>Leetcode[92]-Reverse Linked List II</h1><p>Link: <a href="https://leetcode.com/problems/reverse-linked-list-ii/" target="_blank" rel="noopener">https://leetcode.com/problems/reverse-linked-list-ii/</a></p><p>Reverse a linked list from position m to n. Do it in-place and in one-pass.</p><p>For example:<br>Given 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL, m = 2 and n = 4,</p><p>return 1-&gt;4-&gt;3-&gt;2-&gt;5-&gt;NULL.</p><p>Note:<br>Given m, n satisfy the following condition:<br>1 ≤ m ≤ n ≤ length of list.</p><hr><p><strong>思路</strong>：分别找到m节点和m的前节点，n节点和n的后节点，然后翻转m到n的部分，最后链接三部分成一个整体；代码如下</p><p><strong>Code(c++):</strong></p><figure class="highlight xquery"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Definition <span class="keyword">for</span> singly-linked list.</span><br><span class="line"> * struct ListNode {</span><br><span class="line"> *     int val;</span><br><span class="line"> *     ListNode *<span class="keyword">next</span>;</span><br><span class="line"> *     ListNode(int x) : val(x), <span class="keyword">next</span>(NULL) {}</span><br><span class="line"> * };</span><br><span class="line"> */</span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    ListNode* reverseBetween(ListNode*<span class="built_in"> head</span>, int m, int n) {</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span><span class="built_in">(head</span> == NULL) <span class="keyword">return</span><span class="built_in"> head</span>;</span><br><span class="line"></span><br><span class="line">        ListNode *newList = new ListNode(-<span class="number">1</span>);</span><br><span class="line">        newList-&gt;<span class="keyword">next</span> =<span class="built_in"> head</span>;</span><br><span class="line"></span><br><span class="line">        ListNode *prebegin = newList;</span><br><span class="line">        ListNode *begin =<span class="built_in"> head</span>;</span><br><span class="line"></span><br><span class="line">        ListNode *<span class="keyword">end</span> = newList;</span><br><span class="line">        ListNode *postend =<span class="built_in"> head</span>;</span><br><span class="line">        </span><br><span class="line">        //begin <span class="keyword">as</span> center <span class="keyword">start</span> <span class="type">node</span></span><br><span class="line">        while(--m){</span><br><span class="line">            prebegin = prebegin-&gt;<span class="keyword">next</span>;</span><br><span class="line">            begin = begin-&gt;<span class="keyword">next</span>;</span><br><span class="line">        }</span><br><span class="line">        //<span class="keyword">end</span> <span class="keyword">as</span> center <span class="keyword">end</span> <span class="type">node</span></span><br><span class="line">        while(n--){</span><br><span class="line">            <span class="keyword">end</span> = end-&gt;<span class="keyword">next</span>;</span><br><span class="line">            postend = postend-&gt;<span class="keyword">next</span>;</span><br><span class="line">        }</span><br><span class="line">        </span><br><span class="line">        //reverse center part</span><br><span class="line">       <span class="built_in"> reverse</span>(begin, <span class="keyword">end</span>);</span><br><span class="line">        //link three part <span class="keyword">as</span> one list</span><br><span class="line">        prebegin-&gt;<span class="keyword">next</span> = begin;</span><br><span class="line">        end-&gt;<span class="keyword">next</span> = postend;</span><br><span class="line">        </span><br><span class="line">       <span class="built_in"> head</span> = newList-&gt;<span class="keyword">next</span>;</span><br><span class="line">        <span class="keyword">return</span><span class="built_in"> head</span>;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    void<span class="built_in"> reverse</span>(ListNode*&amp; begin, ListNode*&amp; <span class="keyword">end</span>){</span><br><span class="line">        <span class="keyword">if</span>(begin == <span class="keyword">end</span>)</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        <span class="keyword">if</span>(begin-&gt;<span class="keyword">next</span> == <span class="keyword">end</span>){</span><br><span class="line">            end-&gt;<span class="keyword">next</span> = begin;</span><br><span class="line">        } <span class="keyword">else</span> {</span><br><span class="line">            //<span class="keyword">at</span> <span class="keyword">least</span> <span class="number">3</span> nodes</span><br><span class="line">            ListNode* pre = begin;</span><br><span class="line">            ListNode* cur = pre-&gt;<span class="keyword">next</span>;</span><br><span class="line">            ListNode* post = cur-&gt;<span class="keyword">next</span>;</span><br><span class="line">            while(post != end-&gt;<span class="keyword">next</span>){</span><br><span class="line">                cur-&gt;<span class="keyword">next</span> = pre;</span><br><span class="line">                pre = cur;</span><br><span class="line">                cur = post;</span><br><span class="line">                post = post-&gt;<span class="keyword">next</span>;</span><br><span class="line">            }</span><br><span class="line">            cur-&gt;<span class="keyword">next</span> = pre;</span><br><span class="line">        }</span><br><span class="line">        //swap begin <span class="keyword">and</span> <span class="keyword">end</span></span><br><span class="line">        ListNode* temp = begin;</span><br><span class="line">        begin = <span class="keyword">end</span>;</span><br><span class="line">        <span class="keyword">end</span> = temp;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-94-Binary-Tree-Inorder-Traversal"><a href="#Leetcode-94-Binary-Tree-Inorder-Traversal" class="headerlink" title="Leetcode[94]-Binary Tree Inorder Traversal"></a>Leetcode[94]-Binary Tree Inorder Traversal</h1><p>Link: <a href="https://leetcode.com/problems/binary-tree-inorder-traversal/" target="_blank" rel="noopener">https://leetcode.com/problems/binary-tree-inorder-traversal/</a></p><p>Given a binary tree, return the inorder traversal of its nodes’ values.</p><p>For example:<br>Given binary tree <code>{1,#,2,3}</code>,</p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span></span><br><span class="line"> \</span><br><span class="line">  <span class="number">2</span></span><br><span class="line"> /</span><br><span class="line"><span class="number">3</span></span><br></pre></td></tr></tbody></table></figure><p>return<code>[1,3,2]</code>.</p><hr><p>递归遍历法C++：</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * struct TreeNode {</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode *left;</span></span><br><span class="line"><span class="comment"> *     TreeNode *right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span></span><br><span class="line"><span class="comment"> * };</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; result;</span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">inorderTraversal</span><span class="params">(TreeNode *root)</span> </span>{</span><br><span class="line">        result.<span class="built_in">clear</span>();</span><br><span class="line">        inorder(root);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    }</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">inorder</span><span class="params">(TreeNode* root)</span></span>{</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="literal">NULL</span>) <span class="keyword">return</span>;</span><br><span class="line">        inorder(root-&gt;left);</span><br><span class="line">        result.push_back(root-&gt;val);</span><br><span class="line">        inorder(root-&gt;right);</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p>非递归算法1：</p><figure class="highlight vbscript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Definition <span class="keyword">for</span> a binary tree node.</span><br><span class="line"> * struct TreeNode {</span><br><span class="line"> *     <span class="built_in">int</span> val;</span><br><span class="line"> *     TreeNode *<span class="built_in">left</span>;</span><br><span class="line"> *     TreeNode *<span class="built_in">right</span>;</span><br><span class="line"> *     TreeNode(<span class="built_in">int</span> x) : val(x), <span class="built_in">left</span>(<span class="literal">NULL</span>), <span class="built_in">right</span>(<span class="literal">NULL</span>) {}</span><br><span class="line"> * };</span><br><span class="line"> */</span><br><span class="line"><span class="keyword">class</span> Solution {</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;<span class="built_in">int</span>&gt; inorderTraversal(TreeNode* root) {</span><br><span class="line">        vector&lt;<span class="built_in">int</span>&gt; result;  </span><br><span class="line">        stack&lt;TreeNode *&gt; myStack;  </span><br><span class="line">        <span class="keyword">if</span> (root == <span class="literal">NULL</span>)  </span><br><span class="line">            return result;  </span><br><span class="line">        TreeNode *p = root;  </span><br><span class="line">        <span class="keyword">while</span> (p!=<span class="literal">NULL</span> || !myStack.<span class="literal">empty</span>()) {  </span><br><span class="line">            <span class="keyword">while</span> (p != <span class="literal">NULL</span>) {  </span><br><span class="line">                myStack.push(p);  </span><br><span class="line">                p = p-&gt;<span class="built_in">left</span>;  </span><br><span class="line">            }  </span><br><span class="line">            <span class="keyword">if</span> (!myStack.<span class="literal">empty</span>())  {  </span><br><span class="line">                p = myStack.top();  </span><br><span class="line">                myStack.pop();  </span><br><span class="line">                result.push_back(p-&gt;val);  </span><br><span class="line">                p = p-&gt;<span class="built_in">right</span>;  </span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return result;  </span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p>非递归遍历方法二：(递归条件只需要判断栈是否为空)<br>在递归条件中，</p><ul><li>首先取出栈顶节点，如果不为空的话，就把它的左节点进栈，然后再取栈顶元素，如果不为空，则再让它的左节点进栈，直到栈顶元素是空的节点为止；</li><li>然后让栈顶的空指针退栈</li><li>接着判断栈是否为空，如果不为空，则栈顶节点出栈，并将栈顶元素的值加入到数组中，然后把该节点的右节点入栈（右节点是否是空的，此处不做判断，内部的while循环会判断，因为内while循环后的栈顶节点必定是空指针）</li></ul><p>最后，返回数组即可。</p><figure class="highlight vbscript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"> /**</span><br><span class="line"> * Definition <span class="keyword">for</span> a binary tree node.</span><br><span class="line"> * struct TreeNode {</span><br><span class="line"> *     <span class="built_in">int</span> val;</span><br><span class="line"> *     TreeNode *<span class="built_in">left</span>;</span><br><span class="line"> *     TreeNode *<span class="built_in">right</span>;</span><br><span class="line"> *     TreeNode(<span class="built_in">int</span> x) : val(x), <span class="built_in">left</span>(<span class="literal">NULL</span>), <span class="built_in">right</span>(<span class="literal">NULL</span>) {}</span><br><span class="line"> * };</span><br><span class="line"> */</span><br><span class="line"><span class="keyword">class</span> Solution {</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;<span class="built_in">int</span>&gt; inorderTraversal(TreeNode* root) {</span><br><span class="line">        vector&lt;<span class="built_in">int</span>&gt; result;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="literal">NULL</span>) return result; </span><br><span class="line">        </span><br><span class="line">        stack&lt;TreeNode *&gt; stk;</span><br><span class="line">        TreeNode* p = root;</span><br><span class="line">        stk.push(root);</span><br><span class="line">        <span class="keyword">while</span>(!stk.<span class="literal">empty</span>()){</span><br><span class="line">            <span class="keyword">while</span>((p = stk.top()) &amp;&amp; p){</span><br><span class="line">                stk.push(p-&gt;<span class="built_in">left</span>);</span><br><span class="line">            }</span><br><span class="line">            stk.pop();</span><br><span class="line">            <span class="keyword">if</span>(!stk.<span class="literal">empty</span>()){</span><br><span class="line">                p = stk.top();</span><br><span class="line">                result.push_back(p-&gt;val);</span><br><span class="line">                stk.pop();</span><br><span class="line">                p = p-&gt;<span class="built_in">right</span>;</span><br><span class="line">                stk.push(p);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return result;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-96-Unique-Binary-Search-Trees"><a href="#Leetcode-96-Unique-Binary-Search-Trees" class="headerlink" title="Leetcode[96]-Unique Binary Search Trees"></a>Leetcode[96]-Unique Binary Search Trees</h1><p>Link: <a href="https://leetcode.com/problems/unique-binary-search-trees/" target="_blank" rel="noopener">https://leetcode.com/problems/unique-binary-search-trees/</a></p><p>Given n, how many structurally unique BST’s (binary search trees) that store values 1…n?</p><p>For example,<br>Given n = 3, there are a total of 5 unique BST’s.</p><pre><code>1         3     3      2      1 \       /     /      / \      \  3     2     1      1   3      2 /     /       \                 \2     1         2                 3</code></pre><p><strong>思路：</strong> 动态规划解题，dp[n]表示n个节点可以有dp[n]种不同的树，不管n为多少，先固定一个节点，剩余n-1个节点，分配给左右字数，然后把左子树个数乘以右子树的个数，</p><ul><li>初始值dp[0] = 1,dp[1] = 1,</li><li>dp[n] = dp[0] * dp[n-1] + dp[1] * dp[n-2] + …+ dp[i] * dp[n-1-i] +… + dp[n-1] * dp[0]，也就是左边i个节点，右边n-1-i个节点。代码如下：</li></ul><p><strong>Code(c++):</strong></p><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">numTrees</span><span class="params">(<span class="keyword">int</span> n)</span> </span>{</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; dp;</span><br><span class="line">        dp.resize(n+<span class="number">1</span>);<span class="comment">//set  the length of vector to n+1</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt;= n; i++) {</span><br><span class="line">        <span class="comment">//dp[0] = 1 , dp[1] =1</span></span><br><span class="line">            <span class="keyword">if</span>(i&lt;<span class="number">2</span>){</span><br><span class="line">                dp[i] = <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            }</span><br><span class="line">            <span class="comment">//dp[n] = dp[0]*dp[n-1]+dp[1]*dp[n-2]+...+dp[n-1]*dp[0]</span></span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>; j&lt;=i; j++) {</span><br><span class="line">                dp[i] += dp[j<span class="number">-1</span>]*dp[i-j];</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> dp[n];</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-98-Validate-Binary-Search-Tree"><a href="#Leetcode-98-Validate-Binary-Search-Tree" class="headerlink" title="Leetcode[98]-Validate Binary Search Tree"></a>Leetcode[98]-Validate Binary Search Tree</h1><p>Link: <a href="https://leetcode.com/problems/validate-binary-search-tree/" target="_blank" rel="noopener">https://leetcode.com/problems/validate-binary-search-tree/</a></p><p>Given a binary tree, determine if it is a valid binary search tree (BST).</p><p>Assume a BST is defined as follows:</p><p>The left subtree of a node contains only nodes with keys less than the node’s key.<br>The right subtree of a node contains only nodes with keys greater than the node’s key.<br>Both the left and right subtrees must also be binary search trees.<br>confused what “{1,#,2,3}” means? &gt; read more on how binary tree is serialized on OJ.</p><hr><p>思路：递归方法，对于根结点</p><ul><li>如果有左子树，比较根结点与左子树的最大值，如果小于等于则返回false；</li><li>如果有右子树，比较根结点与右子树的最小值 ，如果大于等于则返回false；</li><li>接着判断左子树和右子树是否也是合法的二叉搜索树；</li></ul><p>Code(c++):</p><figure class="highlight zephir"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * struct TreeNode {</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode *left;</span></span><br><span class="line"><span class="comment"> *     TreeNode *right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span></span><br><span class="line"><span class="comment"> * };</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>{</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">bool</span> isValidBST(TreeNode* root) {</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">NULL</span>) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">if</span>(root-&gt;left &amp;&amp; root-&gt;val &lt;= leftMax(root-&gt;left)) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">if</span>(root-&gt;right &amp;&amp; root-&gt;val &gt;= rightMin(root-&gt;right)) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> isValidBST(root-&gt;left) &amp;&amp; isValidBST(root-&gt;right);</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">//get the left tree max value</span></span><br><span class="line">    <span class="keyword">int</span> leftMax(TreeNode *root){</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">NULL</span>) <span class="keyword">return</span> INT_MIN;</span><br><span class="line">        <span class="keyword">int</span> max = root-&gt;val;</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">int</span> lmax = leftMax(root-&gt;left);</span><br><span class="line">        <span class="keyword">int</span> rmax = leftMax(root-&gt;right);</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">int</span> max1 = lmax&gt;rmax?lmax:rmax;</span><br><span class="line">        <span class="keyword">return</span> max&gt;max1?max:max1;</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">//get the right tree minimum value</span></span><br><span class="line">    <span class="keyword">int</span> rightMin(TreeNode *root){</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">NULL</span>) <span class="keyword">return</span> INT_MAX;</span><br><span class="line">        <span class="keyword">int</span> max = root-&gt;val;</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">int</span> lmin = rightMin(root-&gt;left);</span><br><span class="line">        <span class="keyword">int</span> rmin = rightMin(root-&gt;right);</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">int</span> max1 = lmin&gt;rmin? rmin:lmin;</span><br><span class="line">        <span class="keyword">return</span> max&gt;max1?max1:max;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-100-Same-Tree"><a href="#Leetcode-100-Same-Tree" class="headerlink" title="Leetcode[100]-Same Tree"></a>Leetcode[100]-Same Tree</h1><p>Link: <a href="https://leetcode.com/problems/same-tree/" target="_blank" rel="noopener">https://leetcode.com/problems/same-tree/</a></p><p>Given two binary trees, write a function to check if they are equal or not.</p><p>Two binary trees are considered equal if they are structurally identical and the nodes have the same value.</p><hr><p>思路：递归法判断<br>假设两棵树根结点为p和q</p><ul><li>如果p和q都为空，则返回true；否则，</li><li>如果p和q都非空，并且他们的值都相等，则判断其左右子树是否是相似树；否则</li><li>返回false；</li></ul><p>代码如下(C++)：</p><figure class="highlight coq"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * <span class="keyword">Definition</span> <span class="keyword">for</span> a binary tree node.</span><br><span class="line"> * struct TreeNode {</span><br><span class="line"> *     int val;</span><br><span class="line"> *     TreeNode *<span class="built_in">left</span>;</span><br><span class="line"> *     TreeNode *<span class="built_in">right</span>;</span><br><span class="line"> *     TreeNode(int x) : val(x), <span class="built_in">left</span>(NULL), <span class="built_in">right</span>(NULL) {}</span><br><span class="line"> * };</span><br><span class="line"> */</span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    bool isSameTree(TreeNode* p, TreeNode* q) {</span><br><span class="line">        <span class="keyword">if</span>(!p &amp;&amp; !q) <span class="keyword">return</span> true;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(p &amp;&amp; q &amp;&amp; (p-&gt;val == q-&gt;val)){</span><br><span class="line">            <span class="keyword">return</span> isSameTree(p-&gt;<span class="built_in">left</span>,q-&gt;<span class="built_in">left</span>) &amp;&amp; isSameTree(p-&gt;<span class="built_in">right</span>,q-&gt;<span class="built_in">right</span>);</span><br><span class="line">        }<span class="keyword">else</span>{</span><br><span class="line">            <span class="keyword">return</span> false;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-101-Symmetric-Tree"><a href="#Leetcode-101-Symmetric-Tree" class="headerlink" title="Leetcode[101]-Symmetric Tree"></a>Leetcode[101]-Symmetric Tree</h1><p>Link: <a href="https://leetcode.com/problems/symmetric-tree/" target="_blank" rel="noopener">https://leetcode.com/problems/symmetric-tree/</a></p><p>Given a binary tree, check whether it is a mirror of itself (ie, symmetric around its center).</p><p>For example, this binary tree is symmetric:</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">    <span class="number">1</span></span><br><span class="line">   <span class="string">/</span> <span class="string">\</span></span><br><span class="line">  <span class="number">2</span>   <span class="number">2</span></span><br><span class="line"> <span class="string">/</span> <span class="string">\</span> <span class="string">/</span> <span class="string">\</span></span><br><span class="line"><span class="number">3</span>  <span class="number">4</span> <span class="number">4</span>  <span class="number">3</span></span><br><span class="line"><span class="attr">But the following is not:</span></span><br><span class="line">    <span class="number">1</span></span><br><span class="line">   <span class="string">/</span> <span class="string">\</span></span><br><span class="line">  <span class="number">2</span>   <span class="number">2</span></span><br><span class="line">   <span class="string">\</span>   <span class="string">\</span></span><br><span class="line">   <span class="number">3</span>    <span class="number">3</span></span><br></pre></td></tr></tbody></table></figure><p>Note:<br>Bonus points if you could solve it both recursively and iteratively.</p><hr><p>思路：从左右两边同时执行DFS，同步进栈出栈，如果发现不匹配，则返回false,最后如果匹配后，栈中还剩有节点，则也返回false，否则返回true。</p><p>Code（c++）：</p><figure class="highlight zephir"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * struct TreeNode {</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode *left;</span></span><br><span class="line"><span class="comment"> *     TreeNode *right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span></span><br><span class="line"><span class="comment"> * };</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>{</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">bool</span> isSymmetric(TreeNode* root) {</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="keyword">NULL</span>) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        </span><br><span class="line">        TreeNode* p = root,*q = root;</span><br><span class="line">        stack&lt;TreeNode *&gt; stk,stk2;<span class="comment">//define two stack to save node</span></span><br><span class="line">        stk.push(p);</span><br><span class="line">        stk2.push(q);</span><br><span class="line">        <span class="comment">//if both of stk and stk2 is not empty </span></span><br><span class="line">        <span class="keyword">while</span>(!stk.<span class="keyword">empty</span>() &amp;&amp; !stk2.<span class="keyword">empty</span>() ){</span><br><span class="line">        <span class="comment">//p go left,q go right</span></span><br><span class="line">            <span class="keyword">while</span>(p-&gt;left &amp;&amp; q-&gt;right){</span><br><span class="line">                p = p-&gt;left;</span><br><span class="line">                stk.push(p);</span><br><span class="line">                q = q-&gt;right;</span><br><span class="line">                stk2.push(q);</span><br><span class="line">            }</span><br><span class="line">            <span class="comment">//next line is very important to this method </span></span><br><span class="line">            <span class="keyword">if</span>(p-&gt;left || q-&gt;right) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">//both of stk and stk2 is not empty,pop from  stack and judge p's right node and q's left node</span></span><br><span class="line">            <span class="keyword">if</span>(!stk.<span class="keyword">empty</span>() &amp;&amp; !stk2.<span class="keyword">empty</span>()){</span><br><span class="line">                p = stk.top();</span><br><span class="line">                q = stk2.top();</span><br><span class="line">                stk.pop();</span><br><span class="line">                stk2.pop();</span><br><span class="line">                <span class="keyword">if</span>(p-&gt;val != q-&gt;val) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span>(p-&gt;right) stk.push(p-&gt;right);</span><br><span class="line">                <span class="keyword">if</span>(q-&gt;left) stk2.push(q-&gt;left);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span>(!stk.<span class="keyword">empty</span>() || !stk2.<span class="keyword">empty</span>()) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-102-Binary-Tree-Level-Order-Traversal"><a href="#Leetcode-102-Binary-Tree-Level-Order-Traversal" class="headerlink" title="Leetcode[102]-Binary Tree Level Order Traversal"></a>Leetcode[102]-Binary Tree Level Order Traversal</h1><p>Link: <a href="https://leetcode.com/problems/binary-tree-level-order-traversal/" target="_blank" rel="noopener">https://leetcode.com/problems/binary-tree-level-order-traversal/</a></p><p>Given a binary tree, return the level order traversal of its nodes’ values. (ie, from left to right, level by level).</p><p>For example:<br>Given binary tree {3,9,20,#,#,15,7},</p><pre><code>  3 / \9  20  /  \ 15   7</code></pre><p>return its level order traversal as:</p><pre><code>[  [3],  [9,20],  [15,7]]</code></pre><hr><p><strong>思路</strong>： 使用层序遍历，一层一层的出队，并将节点值放入数组中；</p><p>代码C++：</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * struct TreeNode {</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode *left;</span></span><br><span class="line"><span class="comment"> *     TreeNode *right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span></span><br><span class="line"><span class="comment"> * };</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; <span class="title">levelOrder</span><span class="params">(TreeNode* root)</span> </span>{</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; res;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; nums;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="literal">NULL</span>) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="built_in">queue</span>&lt;TreeNode *&gt; que;</span><br><span class="line">        TreeNode *p = root;</span><br><span class="line">        que.push(p);</span><br><span class="line">        <span class="keyword">while</span>(!que.empty()){</span><br><span class="line">            <span class="keyword">int</span> queSize = que.<span class="built_in">size</span>();</span><br><span class="line">            nums.resize(<span class="number">0</span>);</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; queSize; i++){</span><br><span class="line">                p = que.front();</span><br><span class="line">                nums.push_back(p-&gt;val);</span><br><span class="line">                <span class="keyword">if</span>(p-&gt;left) que.push(p-&gt;left);</span><br><span class="line">                <span class="keyword">if</span>(p-&gt;right) que.push(p-&gt;right);</span><br><span class="line">                que.pop();</span><br><span class="line">            }</span><br><span class="line">            res.push_back(nums);</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p>有问题，来一起讨论吧!</p><hr><h1 id="Leetcode-103-Binary-Tree-Zigzag-Level-Order-Traversal"><a href="#Leetcode-103-Binary-Tree-Zigzag-Level-Order-Traversal" class="headerlink" title="Leetcode[103]-Binary Tree Zigzag Level Order Traversal"></a>Leetcode[103]-Binary Tree Zigzag Level Order Traversal</h1><p>Link: <a href="https://leetcode.com/problems/binary-tree-zigzag-level-order-traversal/" target="_blank" rel="noopener">https://leetcode.com/problems/binary-tree-zigzag-level-order-traversal/</a></p><p>Given a binary tree, return the zigzag level order traversal of its nodes’ values. (ie, from left to right, then right to left for the next level and alternate between).</p><p>For example:<br>Given binary tree {3,9,20,#,#,15,7},</p><pre><code>  3 / \9  20  /  \ 15   7</code></pre><p>return its zigzag level order traversal as:</p><pre><code>[  [3],  [20,9],  [15,7]]</code></pre><hr><p>思路：使用层序遍历，借助队列，依次遍历每层，如果层数为偶数，则将该层的数字翻转，使用vector的reverse函数即可。</p><p>代码Code （C++）：</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * struct TreeNode {</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode *left;</span></span><br><span class="line"><span class="comment"> *     TreeNode *right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span></span><br><span class="line"><span class="comment"> * };</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; <span class="title">zigzagLevelOrder</span><span class="params">(TreeNode* root)</span> </span>{</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; res;</span><br><span class="line">        <span class="keyword">if</span>(!root) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; nums;</span><br><span class="line">        <span class="built_in">queue</span>&lt;TreeNode *&gt; que;</span><br><span class="line">        TreeNode *p = root;</span><br><span class="line">        que.push(p);       </span><br><span class="line">        <span class="keyword">int</span> level  = <span class="number">0</span>; <span class="comment">// curent level</span></span><br><span class="line">        <span class="keyword">while</span>(!que.empty()){</span><br><span class="line">            nums.resize(<span class="number">0</span>);</span><br><span class="line">            level += <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">int</span> queSize = que.<span class="built_in">size</span>();</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; queSize; i++ ) {</span><br><span class="line">                p = que.front();</span><br><span class="line">                nums.push_back(p-&gt;val);</span><br><span class="line">                que.pop();</span><br><span class="line">                <span class="keyword">if</span>(p-&gt;left) que.push(p-&gt;left);</span><br><span class="line">                <span class="keyword">if</span>(p-&gt;right) que.push(p-&gt;right);</span><br><span class="line">            }</span><br><span class="line">            <span class="keyword">if</span>(level % <span class="number">2</span> == <span class="number">0</span>) reverse(nums.<span class="built_in">begin</span>(),nums.<span class="built_in">end</span>());</span><br><span class="line">            res.push_back(nums);</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span>  res;         </span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-104-Maximum-Depth-of-Binary-Tree"><a href="#Leetcode-104-Maximum-Depth-of-Binary-Tree" class="headerlink" title="Leetcode[104]-Maximum Depth of Binary Tree"></a>Leetcode[104]-Maximum Depth of Binary Tree</h1><p>Link: <a href="https://leetcode.com/problems/maximum-depth-of-binary-tree/" target="_blank" rel="noopener">https://leetcode.com/problems/maximum-depth-of-binary-tree/</a></p><p>Given a binary tree, find its maximum depth.</p><p>The maximum depth is the number of nodes along the longest path from the root node down to the farthest leaf node.</p><hr><p>求最大深度，用递归的方法</p><p>C++:</p><figure class="highlight vbscript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Definition <span class="keyword">for</span> a binary tree node.</span><br><span class="line"> * struct TreeNode {</span><br><span class="line"> *     <span class="built_in">int</span> val;</span><br><span class="line"> *     TreeNode *<span class="built_in">left</span>;</span><br><span class="line"> *     TreeNode *<span class="built_in">right</span>;</span><br><span class="line"> *     TreeNode(<span class="built_in">int</span> x) : val(x), <span class="built_in">left</span>(<span class="literal">NULL</span>), <span class="built_in">right</span>(<span class="literal">NULL</span>) {}</span><br><span class="line"> * };</span><br><span class="line"> */</span><br><span class="line"><span class="keyword">class</span> Solution {</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">int</span> maxDepth(TreeNode* root) {</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(root==<span class="literal">NULL</span>) return <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">int</span> ldepth = <span class="number">0</span>,rdepth = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(root-&gt;<span class="built_in">left</span>!=<span class="literal">NULL</span>){</span><br><span class="line">            ldepth = maxDepth(root-&gt;<span class="built_in">left</span>);</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span>(root-&gt;<span class="built_in">right</span>!=<span class="literal">NULL</span>){</span><br><span class="line">            rdepth = maxDepth(root-&gt;<span class="built_in">right</span>);</span><br><span class="line">        }</span><br><span class="line">        return ldepth&gt;rdepth?ldepth+<span class="number">1</span>:rdepth+<span class="number">1</span>;   </span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-107-Binary-Tree-Level-Order-Traversal-II"><a href="#Leetcode-107-Binary-Tree-Level-Order-Traversal-II" class="headerlink" title="Leetcode[107]-Binary Tree Level Order Traversal II"></a>Leetcode[107]-Binary Tree Level Order Traversal II</h1><p>Link: <a href="https://leetcode.com/problems/binary-tree-level-order-traversal-ii/" target="_blank" rel="noopener">https://leetcode.com/problems/binary-tree-level-order-traversal-ii/</a></p><p>Given a binary tree, return the bottom-up level order traversal of its nodes’ values. (ie, from left to right, level by level from leaf to root).</p><p>For example:<br>Given binary tree {3,9,20,#,#,15,7},</p><pre><code>  3 / \9  20  /  \ 15   7</code></pre><p>return its bottom-up level order traversal as:</p><pre><code>[  [15,7],  [9,20],  [3]]</code></pre><hr><p>使用BFS层序遍历，然后得到的vector数组使用reverse反转即可。</p><p>Code(c++):</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * struct TreeNode {</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode *left;</span></span><br><span class="line"><span class="comment"> *     TreeNode *right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span></span><br><span class="line"><span class="comment"> * };</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; <span class="title">levelOrderBottom</span><span class="params">(TreeNode* root)</span> </span>{</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; res;</span><br><span class="line">        <span class="keyword">if</span>(!root) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; nums;</span><br><span class="line">        <span class="built_in">queue</span>&lt;TreeNode *&gt; que;</span><br><span class="line">        </span><br><span class="line">        TreeNode *p = root;</span><br><span class="line">        que.push(p);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span>(!que.empty()){ </span><br><span class="line">            <span class="keyword">int</span> queSize = que.<span class="built_in">size</span>();</span><br><span class="line">            nums.resize(<span class="number">0</span>);</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; queSize; i++) {</span><br><span class="line">                p = que.front();</span><br><span class="line">                nums.push_back(p-&gt;val);</span><br><span class="line">                <span class="keyword">if</span>(p-&gt;left) que.push(p-&gt;left);</span><br><span class="line">                <span class="keyword">if</span>(p-&gt;right) que.push(p-&gt;right);</span><br><span class="line">                que.pop();</span><br><span class="line">            }</span><br><span class="line">            res.push_back(nums);</span><br><span class="line">        }</span><br><span class="line">        reverse(res.<span class="built_in">begin</span>(),res.<span class="built_in">end</span>());</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">        </span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-110-Balanced-Binary-Tree"><a href="#Leetcode-110-Balanced-Binary-Tree" class="headerlink" title="Leetcode[110]-Balanced Binary Tree"></a>Leetcode[110]-Balanced Binary Tree</h1><p>Link: <a href="https://leetcode.com/problems/balanced-binary-tree/" target="_blank" rel="noopener">https://leetcode.com/problems/balanced-binary-tree/</a></p><p>Given a binary tree, determine if it is height-balanced.</p><p>For this problem, a height-balanced binary tree is defined as a binary tree in which the depth of the two subtrees of every node never differ by more than 1.</p><hr><p>判断一棵树是否属于平衡二叉树</p><p>判断主节点的左右节点深度大小差，如果不在【-1,1】内，返回false，否则，继续判断其左右节点是否属于平衡二叉树；</p><p>只要有不满足的，就返回false</p><p>Code(C++):</p><figure class="highlight zephir"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * struct TreeNode {</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode *left;</span></span><br><span class="line"><span class="comment"> *     TreeNode *right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span></span><br><span class="line"><span class="comment"> * };</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>{</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">bool</span> isBalanced(TreeNode* root) {</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">NULL</span>) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> ldepth = getDepth(root-&gt;left);</span><br><span class="line">        <span class="keyword">int</span> rdepth = getDepth(root-&gt;right);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(ldepth - rdepth &gt; <span class="number">1</span> || ldepth - rdepth &lt; <span class="number">-1</span>) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> isBalanced(root-&gt;left) &amp;&amp; isBalanced(root-&gt;right);</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//get node's depth</span></span><br><span class="line">    <span class="keyword">int</span> getDepth(TreeNode *root){</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="keyword">NULL</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">int</span> ldepth=<span class="number">0</span>,rdepth=<span class="number">0</span>;</span><br><span class="line">        ldepth = getDepth(root-&gt;left);</span><br><span class="line">        rdepth = getDepth(root-&gt;right);</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> ldepth &gt; rdepth ? ldepth+<span class="number">1</span>:rdepth+<span class="number">1</span>;</span><br><span class="line">        </span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-111-Minimum-Depth-of-Binary-Tree"><a href="#Leetcode-111-Minimum-Depth-of-Binary-Tree" class="headerlink" title="Leetcode[111]-Minimum Depth of Binary Tree"></a>Leetcode[111]-Minimum Depth of Binary Tree</h1><p>Link: <a href="https://leetcode.com/problems/minimum-depth-of-binary-tree/" target="_blank" rel="noopener">https://leetcode.com/problems/minimum-depth-of-binary-tree/</a></p><p>Given a binary tree, find its minimum depth.</p><p>The minimum depth is the number of nodes along the shortest path from the root node down to the nearest leaf node.</p><hr><p>C++:</p><p>递归法</p><figure class="highlight coq"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * <span class="keyword">Definition</span> <span class="keyword">for</span> a binary tree node.</span><br><span class="line"> * struct TreeNode {</span><br><span class="line"> *     int val;</span><br><span class="line"> *     TreeNode *<span class="built_in">left</span>;</span><br><span class="line"> *     TreeNode *<span class="built_in">right</span>;</span><br><span class="line"> *     TreeNode(int x) : val(x), <span class="built_in">left</span>(NULL), <span class="built_in">right</span>(NULL) {}</span><br><span class="line"> * };</span><br><span class="line"> */</span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int minDepth(TreeNode* root) {</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(root == NULL) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(!root-&gt;<span class="built_in">left</span> &amp;&amp; !root-&gt;<span class="built_in">right</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        </span><br><span class="line">        int dleft=<span class="number">0</span>,dright=<span class="number">0</span>,dmin = <span class="number">0</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(root-&gt;<span class="built_in">left</span>) dleft = minDepth(root-&gt;<span class="built_in">left</span>) + <span class="number">1</span> ;</span><br><span class="line">        <span class="keyword">if</span>(root-&gt;<span class="built_in">right</span>) dright = minDepth(root-&gt;<span class="built_in">right</span>) + <span class="number">1</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(!root-&gt;<span class="built_in">left</span> &amp;&amp; root-&gt;<span class="built_in">right</span>) <span class="keyword">return</span> dright;</span><br><span class="line">        <span class="keyword">if</span>(!root-&gt;<span class="built_in">right</span> &amp;&amp; root-&gt;<span class="built_in">left</span>) <span class="keyword">return</span> dleft;</span><br><span class="line">        </span><br><span class="line">        dmin = dleft&gt;dright?dright:dleft; </span><br><span class="line">        <span class="keyword">return</span> dmin;</span><br><span class="line">        </span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-113-Path-Sum-II"><a href="#Leetcode-113-Path-Sum-II" class="headerlink" title="Leetcode[113]-Path Sum II"></a>Leetcode[113]-Path Sum II</h1><p>Link: <a href="https://leetcode.com/problems/path-sum-ii/" target="_blank" rel="noopener">https://leetcode.com/problems/path-sum-ii/</a></p><p>Given a binary tree and a sum, find all root-to-leaf paths where each path’s sum equals the given sum.</p><p>For example:<br>Given the below binary tree and sum = 22,</p><pre><code>      5     / \    4   8   /   / \  11  13  4 /  \    / \7    2  5   1</code></pre><p>return</p><pre><code>[   [5,4,11,2],   [5,8,4,5]]</code></pre><hr><p>思路：使用深度优先遍历，需要</p><ul><li>一个map，保存节点是否出栈过；</li><li>一个一维数组，保存根结点到当前节点的路径；</li><li>一个二维数组，保存根结点到当前叶节点的和等于给定sum的路径集合；</li><li>一个栈，用来辅助深度优先遍历；</li></ul><p>按照深度优先的遍历方式遍历，</p><ul><li>进栈的时候元素同时添加到一维数组中，并将该节点的map值设置为0,</li><li>当节点左右节点都为空的时候，判断一维数组里面的数据和是否等于给定sum，如果等于就把它丢到二维数组中，同时执行下一步出栈；</li><li>出栈的时候也同时缩小一维数组的长度，并将该节点的map值设置为1，表示该节点不能再次进栈了；</li></ul><p>Code（c++）：非递归算法：</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * struct TreeNode {</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode *left;</span></span><br><span class="line"><span class="comment"> *     TreeNode *right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span></span><br><span class="line"><span class="comment"> * };</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; <span class="title">pathSum</span><span class="params">(TreeNode* root, <span class="keyword">int</span> sum)</span> </span>{</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; res;</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="literal">NULL</span>) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; nums;</span><br><span class="line">        <span class="built_in">map</span>&lt;TreeNode *, <span class="keyword">int</span>&gt; visited;</span><br><span class="line">        <span class="built_in">stack</span>&lt;TreeNode *&gt; stk;</span><br><span class="line">        </span><br><span class="line">        TreeNode* p = root;</span><br><span class="line">        nums.push_back(p-&gt;val);</span><br><span class="line">        stk.push(p);</span><br><span class="line">        visited[p] = <span class="number">0</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span>(!stk.empty()){</span><br><span class="line">            p = stk.top();</span><br><span class="line">            <span class="keyword">while</span>(p-&gt;left &amp;&amp; visited[p] == <span class="number">0</span>){</span><br><span class="line">            <span class="comment">//this is very important to break this while</span></span><br><span class="line">                <span class="keyword">if</span>(visited[p-&gt;left]==<span class="number">1</span>) <span class="keyword">break</span>;</span><br><span class="line">                p = p-&gt;left;</span><br><span class="line">                nums.push_back(p-&gt;val);</span><br><span class="line">                stk.push(p);</span><br><span class="line">                visited[p] = <span class="number">0</span>;</span><br><span class="line">            }</span><br><span class="line">            <span class="keyword">if</span>(!stk.empty()){</span><br><span class="line">                p = stk.top();</span><br><span class="line">                <span class="keyword">if</span>(!p-&gt;left &amp;&amp; !p-&gt;right &amp;&amp; sumVector(nums) == sum){</span><br><span class="line">                    res.push_back(nums);</span><br><span class="line">                }</span><br><span class="line">                <span class="keyword">if</span>( p-&gt;right &amp;&amp; (visited.<span class="built_in">find</span>(p-&gt;right) == visited.<span class="built_in">end</span>() || visited[p-&gt;right] == <span class="number">0</span>)){</span><br><span class="line">                    p = p-&gt;right;</span><br><span class="line">                    stk.push(p);</span><br><span class="line">                    nums.push_back(p-&gt;val);</span><br><span class="line">                    visited[p] = <span class="number">0</span>;</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                }</span><br><span class="line">                visited[p] = <span class="number">1</span>;</span><br><span class="line">                stk.pop();</span><br><span class="line">                nums.resize(nums.<span class="built_in">size</span>()<span class="number">-1</span>);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">sumVector</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &amp; nums)</span></span>{</span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">if</span>( n == <span class="number">0</span> ) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) {</span><br><span class="line">            sum += nums[i];</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> sum;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p>递归方法：</p><figure class="highlight stan"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * struct TreeNode {</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode *left;</span></span><br><span class="line"><span class="comment"> *     TreeNode *right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span></span><br><span class="line"><span class="comment"> * };</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    <span class="keyword">vector</span>&lt;<span class="keyword">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; pathSum(TreeNode* root, <span class="keyword">int</span> <span class="built_in">sum</span>) {</span><br><span class="line">        <span class="keyword">vector</span>&lt;<span class="keyword">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; result;</span><br><span class="line">        <span class="keyword">vector</span>&lt;<span class="keyword">int</span>&gt; nums;</span><br><span class="line">        getPath(result,nums,<span class="built_in">sum</span>,<span class="number">0</span>,root);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line"></span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">void</span> getPath(<span class="keyword">vector</span>&lt;<span class="keyword">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; &amp;res, <span class="keyword">vector</span>&lt;<span class="keyword">int</span>&gt; &amp;nums, <span class="keyword">int</span> <span class="built_in">target</span>, <span class="keyword">int</span> <span class="built_in">sum</span>, TreeNode *root) {</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(root==NULL) <span class="keyword">return</span>;</span><br><span class="line">        <span class="built_in">sum</span> += root-&gt;val;</span><br><span class="line">        nums.push_back(root-&gt;val);</span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">sum</span> == <span class="built_in">target</span> &amp;&amp; !root-&gt;left &amp;&amp; !root-&gt;right){</span><br><span class="line">            res.push_back(nums);</span><br><span class="line">        }</span><br><span class="line">        </span><br><span class="line">        getPath(res, nums, <span class="built_in">target</span>, <span class="built_in">sum</span>, root-&gt;left);</span><br><span class="line">        getPath(res, nums, <span class="built_in">target</span>, <span class="built_in">sum</span>, root-&gt;right);</span><br><span class="line">        </span><br><span class="line">        nums.pop_back();</span><br><span class="line">        <span class="built_in">sum</span> -= root-&gt;val;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-114-Flatten-Binary-Tree-to-Linked-List"><a href="#Leetcode-114-Flatten-Binary-Tree-to-Linked-List" class="headerlink" title="Leetcode[114]-Flatten Binary Tree to Linked List"></a>Leetcode[114]-Flatten Binary Tree to Linked List</h1><p>Link: <a href="https://leetcode.com/problems/flatten-binary-tree-to-linked-list/" target="_blank" rel="noopener">https://leetcode.com/problems/flatten-binary-tree-to-linked-list/</a></p><p>Given a binary tree, flatten it to a linked list in-place.</p><p>For example,<br>Given</p><pre><code>   1   / \  2   5 / \   \3   4   6</code></pre><p>The flattened tree should look like:</p><pre><code>1 \  2   \    3     \      4       \        5         \          6</code></pre><hr><p>*<em>思路: *</em>  首先找到根节点左节点的最右子节点，然后把根节点的右子树移到左子树的最右端；接着把根结点的左子树移到右节点上，并将左子树置为空树，同时将根结点往右下移一个节点，依次递归即可。代码如下：</p><p>Code(c++):</p><figure class="highlight coq"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * <span class="keyword">Definition</span> <span class="keyword">for</span> a binary tree node.</span><br><span class="line"> * struct TreeNode {</span><br><span class="line"> *     int val;</span><br><span class="line"> *     TreeNode *<span class="built_in">left</span>;</span><br><span class="line"> *     TreeNode *<span class="built_in">right</span>;</span><br><span class="line"> *     TreeNode(int x) : val(x), <span class="built_in">left</span>(NULL), <span class="built_in">right</span>(NULL) {}</span><br><span class="line"> * };</span><br><span class="line"> */</span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    </span><br><span class="line">    void flatten(TreeNode* root) {</span><br><span class="line">        <span class="keyword">if</span>(!root) <span class="keyword">return</span>;</span><br><span class="line">        while(root){</span><br><span class="line">            <span class="keyword">if</span>(root-&gt;<span class="built_in">left</span> &amp;&amp; root-&gt;<span class="built_in">right</span>){</span><br><span class="line">                TreeNode *p = root-&gt;<span class="built_in">left</span>;</span><br><span class="line">                while(p-&gt;<span class="built_in">right</span>) </span><br><span class="line">                    p =p-&gt;<span class="built_in">right</span>;</span><br><span class="line">                p-&gt;<span class="built_in">right</span> = root-&gt;<span class="built_in">right</span>;</span><br><span class="line">            }</span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span>(root-&gt;<span class="built_in">left</span>)</span><br><span class="line">                root-&gt;<span class="built_in">right</span> = root-&gt;<span class="built_in">left</span>;</span><br><span class="line">            root-&gt;<span class="built_in">left</span> = NULL;</span><br><span class="line">            root = root-&gt;<span class="built_in">right</span>;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-118-Pascal’s-Triangle"><a href="#Leetcode-118-Pascal’s-Triangle" class="headerlink" title="Leetcode[118]-Pascal’s Triangle"></a>Leetcode[118]-Pascal’s Triangle</h1><p>Link: <a href="https://leetcode.com/problems/pascals-triangle/" target="_blank" rel="noopener">https://leetcode.com/problems/pascals-triangle/</a></p><p>Given numRows, generate the first numRows of Pascal’s triangle.</p><p>For example, given numRows = 5,<br>Return</p><figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">     [<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">   [<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>],</span><br><span class="line">  [<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">1</span>],</span><br><span class="line"> [<span class="number">1</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">4</span>,<span class="number">1</span>]</span><br><span class="line">]</span><br></pre></td></tr></tbody></table></figure><hr><p>分析：</p><ul><li>第j=0列全为1，第j==i列时，都为1</li><li>其它列<ul><li>a[2][1] = a[1][0]+a[1][1]</li><li>a[3][1] = a[2][0]+a[2][1]</li><li>a[3][2] = a[2][1]+a[2][2]</li><li>……</li><li>推算得出</li><li>……</li><li>a[i][j] = a[i-1][j-1]+a[i-1][j]</li></ul></li></ul><p><strong>代码（c++）：</strong></p><figure class="highlight matlab"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;vector&lt;int&gt;&gt; generate(int numRows) {</span><br><span class="line">        vector &lt;vector&lt;int&gt; &gt; vec(numRows);</span><br><span class="line">        <span class="keyword">for</span>(int <span class="built_in">i</span> = <span class="number">0</span>; <span class="built_in">i</span> &lt; numRows; <span class="built_in">i</span>++) {</span><br><span class="line">            vec[<span class="built_in">i</span>].resize(<span class="built_in">i</span>+<span class="number">1</span>);</span><br><span class="line">            <span class="keyword">for</span>(int <span class="built_in">j</span> = <span class="number">0</span>; <span class="built_in">j</span> &lt;= <span class="built_in">i</span> ; <span class="built_in">j</span>++){</span><br><span class="line">                <span class="keyword">if</span>(<span class="built_in">j</span>==<span class="built_in">i</span> || <span class="built_in">j</span>==<span class="number">0</span>)</span><br><span class="line">                    vec[<span class="built_in">i</span>][<span class="built_in">j</span>] = <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">else</span>{</span><br><span class="line">                    vec[<span class="built_in">i</span>][<span class="built_in">j</span>] = vec[<span class="built_in">i</span><span class="number">-1</span>][<span class="built_in">j</span><span class="number">-1</span>] + vec[<span class="built_in">i</span><span class="number">-1</span>][<span class="built_in">j</span>];</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> vec;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p><strong>代码（Python）：</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generate</span><span class="params">(self, numRows)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type numRows: int</span></span><br><span class="line"><span class="string">        :rtype: List[List[int]]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        b=[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(numRows):</span><br><span class="line">            temp = []</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> j==<span class="number">0</span>:</span><br><span class="line">                    temp.append(<span class="number">1</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> j &lt; i:</span><br><span class="line">                        temp.append(b[i<span class="number">-1</span>][j<span class="number">-1</span>]+b[i<span class="number">-1</span>][j])</span><br><span class="line">                    <span class="keyword">elif</span> j==i:</span><br><span class="line">                        temp.append(<span class="number">1</span>)</span><br><span class="line">            b.append(temp)</span><br><span class="line">        <span class="keyword">return</span> b</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-119-Pascal’s-Triangle-II"><a href="#Leetcode-119-Pascal’s-Triangle-II" class="headerlink" title="Leetcode[119]-Pascal’s Triangle II"></a>Leetcode[119]-Pascal’s Triangle II</h1><p>Link: <a href="https://leetcode.com/problems/pascals-triangle-ii/" target="_blank" rel="noopener">https://leetcode.com/problems/pascals-triangle-ii/</a></p><p>Given an index k, return the kth row of the Pascal’s triangle.</p><p>For example, given k = 3,<br>Return [1,3,3,1].</p><p>Note:<br>Could you optimize your algorithm to use only O(k) extra space?</p><hr><p>分析：通过递归设置vector的值，变量i表示当前行数，同时根据行数可以得到当前的vector元素个数。如果我们从前往后遍历，当i增加的时候，我们的num[j] = num[j] + num[j-1]就会出问题，因为num[j+1]=num[j+1]+num[j],而num[j]已经更新了。</p><p>所以这里采用的是从后往前遍历，num[j] = num[j] + num[j-1],这样num[j-1] = num[j-1] + num[j-2]，不会受到前面的num[j]的变化而变化。</p><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">getRow</span><span class="params">(<span class="keyword">int</span> rowIndex)</span> </span>{</span><br><span class="line">        <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">nums</span><span class="params">(rowIndex+<span class="number">1</span>)</span></span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt;= rowIndex; i++){</span><br><span class="line">            nums[i] =<span class="number">1</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = i<span class="number">-1</span>; j &gt;= <span class="number">1</span>; j--){</span><br><span class="line">                nums[j] = nums[j] + nums[j<span class="number">-1</span>];</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> nums;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p><strong>Python代码</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getRow</span><span class="params">(self, rowIndex)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type rowIndex: int</span></span><br><span class="line"><span class="string">        :rtype: List[int]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> rowIndex &lt; <span class="number">0</span>: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        nums = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(rowIndex+<span class="number">1</span>):</span><br><span class="line">            a = []</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> j==<span class="number">0</span>:</span><br><span class="line">                    a.append(<span class="number">1</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> j &lt; i:</span><br><span class="line">                        a.append(nums[i<span class="number">-1</span>][j<span class="number">-1</span>]+nums[i<span class="number">-1</span>][j])</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        a.append(<span class="number">1</span>)</span><br><span class="line">            nums.append(a)</span><br><span class="line">        <span class="keyword">return</span> nums[<span class="number">-1</span>]</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-125-Valid-Palindrome"><a href="#Leetcode-125-Valid-Palindrome" class="headerlink" title="Leetcode[125]-Valid Palindrome"></a>Leetcode[125]-Valid Palindrome</h1><p>Link: <a href="https://leetcode.com/problems/valid-palindrome/" target="_blank" rel="noopener">https://leetcode.com/problems/valid-palindrome/</a></p><p>Given a string, determine if it is a palindrome, considering only alphanumeric characters and ignoring cases.</p><figure class="highlight maxima"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">For <span class="built_in">example</span>,</span><br><span class="line"><span class="string">"A man, a plan, a canal: Panama"</span> <span class="built_in">is</span> a palindrome.</span><br><span class="line"><span class="string">"race a car"</span> <span class="built_in">is</span> <span class="keyword">not</span> a palindrome.</span><br></pre></td></tr></tbody></table></figure><p>Note:<br>Have you consider that the string might be empty? This is a good question to ask during an interview.</p><p>For the purpose of this problem, we define empty string as valid palindrome.</p><hr><p> 思路：定义两个标示符，一个指向字符串前面，一个指向字符串末尾，如果前后位置的字符不是字母或是数字，则直接跳过该字符，如果是大写，则转换成小写再比较，如果碰到不匹配的直接返回false。</p><p>Code(C++):</p><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isPalindrome</span><span class="params">(<span class="built_in">string</span> s)</span> </span>{</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> length = s.length();</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(length == <span class="number">0</span>){  </span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;  </span><br><span class="line">        }  </span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>, j = length<span class="number">-1</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span>(i &lt;= j){</span><br><span class="line">            <span class="keyword">if</span>(!isStr(s[i])) i++;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(!isStr(s[j])) j--;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(s[i++] != s[j--]) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isStr</span><span class="params">(<span class="keyword">char</span> &amp;a)</span></span>{</span><br><span class="line">        <span class="keyword">if</span>(a &gt;= <span class="string">'0'</span> &amp;&amp; a &lt;= <span class="string">'9'</span> ) {</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        }<span class="keyword">else</span> <span class="keyword">if</span>(a &gt;= <span class="string">'a'</span> &amp;&amp; a &lt;= <span class="string">'z'</span> ) {</span><br><span class="line">            a -= <span class="number">32</span>;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        } <span class="keyword">else</span> <span class="keyword">if</span>(a &gt;= <span class="string">'A'</span> &amp;&amp; a &lt;= <span class="string">'Z'</span> ) {</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        } </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    }</span><br><span class="line">   </span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-128-Longest-Consecutive-Sequence"><a href="#Leetcode-128-Longest-Consecutive-Sequence" class="headerlink" title="Leetcode[128]-Longest Consecutive Sequence"></a>Leetcode[128]-Longest Consecutive Sequence</h1><p>Link:<a href="https://leetcode.com/problems/longest-consecutive-sequence/" target="_blank" rel="noopener">https://leetcode.com/problems/longest-consecutive-sequence/</a></p><p>Given an unsorted array of integers, find the length of the longest consecutive elements sequence.</p><p>For example,<br>Given [100, 4, 200, 1, 3, 2],<br>The longest consecutive elements sequence is [1, 2, 3, 4]. Return its length: 4.</p><p>Your algorithm should run in O(n) complexity.</p><hr><p>思路：跟最大连续子序列和的思路类似，采用DP思想。设置一个长度为n的数组dp[n]，dp[i]表示在下标为i的时候，当前最大连续序列的长度为dp[i]，最后找到dp[i]中最大的那个值即可。</p><p>C++:</p><figure class="highlight matlab"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int longestConsecutive(vector&lt;int&gt;&amp; nums) {</span><br><span class="line">        int n=nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="built_in">sort</span>(nums.begin(),nums.<span class="keyword">end</span>());</span><br><span class="line">        vector&lt;int&gt; dp(n);</span><br><span class="line">        dp[<span class="number">0</span>]=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(int <span class="built_in">i</span>=<span class="number">1</span>; <span class="built_in">i</span>&lt;n; <span class="built_in">i</span>++){</span><br><span class="line">            <span class="keyword">if</span>(nums[<span class="built_in">i</span>]==(nums[<span class="built_in">i</span><span class="number">-1</span>]+<span class="number">1</span>))dp[<span class="built_in">i</span>]=dp[<span class="built_in">i</span><span class="number">-1</span>]+<span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (nums[<span class="built_in">i</span>] == nums[<span class="built_in">i</span><span class="number">-1</span>]){</span><br><span class="line">                dp[<span class="built_in">i</span>] = dp[<span class="built_in">i</span><span class="number">-1</span>];</span><br><span class="line">            }<span class="keyword">else</span>{</span><br><span class="line">                dp[<span class="built_in">i</span>]=<span class="number">1</span>;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        int maxl=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(int <span class="built_in">j</span>=<span class="number">0</span>; <span class="built_in">j</span>&lt;n;<span class="built_in">j</span>++){</span><br><span class="line">            maxl = <span class="built_in">max</span>(maxl,dp[<span class="built_in">j</span>]);</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> maxl;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-129-Sum-Root-to-Leaf-Numbers"><a href="#Leetcode-129-Sum-Root-to-Leaf-Numbers" class="headerlink" title="Leetcode[129]-Sum Root to Leaf Numbers"></a>Leetcode[129]-Sum Root to Leaf Numbers</h1><p>Link: <a href="https://leetcode.com/problems/sum-root-to-leaf-numbers/" target="_blank" rel="noopener">https://leetcode.com/problems/sum-root-to-leaf-numbers/</a></p><p>Given a binary tree containing digits from 0-9 only, each root-to-leaf path could represent a number.</p><p>An example is the root-to-leaf path 1-&gt;2-&gt;3 which represents the number 123.</p><p>Find the total sum of all root-to-leaf numbers.</p><p>For example,</p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">  <span class="number">1</span></span><br><span class="line"> / \</span><br><span class="line"><span class="number">2</span>   <span class="number">3</span></span><br></pre></td></tr></tbody></table></figure><p>The root-to-leaf path 1-&gt;2 represents the number 12.<br>The root-to-leaf path 1-&gt;3 represents the number 13.</p><p>Return the sum = 12 + 13 = 25.</p><hr><p>这道题让我真的醉了，先说下思路吧。</p><p>先求出每个叶子节点的值，然后将这些值相加。求叶子节点的值可以通过深度优先遍历，一遍往下，一遍增加各个节点的值，如果是叶子节点就将数组值的和加入到一个只有叶子节点的数组中，最后求这个只有叶子节点的数组的值得和。从头到尾自己写的代码，可以AC了，还没有进行优化，先做到这里吧。</p><p>代码（C++）：</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * struct TreeNode {</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode *left;</span></span><br><span class="line"><span class="comment"> *     TreeNode *right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span></span><br><span class="line"><span class="comment"> * };</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"><span class="comment">//return sum of newleafValue</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">sumNumbers</span><span class="params">(TreeNode* root)</span> </span>{</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="literal">NULL</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(!root-&gt;left &amp;&amp; !root-&gt;right) <span class="keyword">return</span> root-&gt;val;</span><br><span class="line">    </span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; nums = saveLeafNums(root);</span><br><span class="line">        <span class="keyword">return</span> sumV(nums);</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">//save leftnode to vector</span></span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">saveLeafNums</span><span class="params">(TreeNode * root)</span></span>{</span><br><span class="line">    </span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; nums,nodeValue;</span><br><span class="line">        <span class="keyword">int</span> eachSum = <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">stack</span>&lt;TreeNode *&gt; stk;</span><br><span class="line">        <span class="built_in">map</span>&lt;TreeNode *, <span class="keyword">int</span>&gt; visited;</span><br><span class="line">    </span><br><span class="line">        TreeNode *p = root;</span><br><span class="line">    </span><br><span class="line">        stk.push(p);</span><br><span class="line">        visited[p] = <span class="number">0</span>;</span><br><span class="line">        nodeValue.push_back(p-&gt;val);</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">while</span>(!stk.empty()){</span><br><span class="line">            <span class="keyword">while</span>(p-&gt;left &amp;&amp; visited[p]==<span class="number">0</span> ){</span><br><span class="line">            <span class="comment">//if this node is visited,break </span></span><br><span class="line">                <span class="keyword">if</span>(visited[p-&gt;left]==<span class="number">1</span>) <span class="keyword">break</span>;</span><br><span class="line">                p = p-&gt;left;</span><br><span class="line">                stk.push(p);</span><br><span class="line">                visited[p] = <span class="number">0</span>;</span><br><span class="line">                tenMutilVector(nodeValue);<span class="comment">//enlarge vector element's value</span></span><br><span class="line">                nodeValue.push_back(p-&gt;val);</span><br><span class="line">            }</span><br><span class="line">            <span class="keyword">if</span>(!stk.empty()) {</span><br><span class="line">                p = stk.top();</span><br><span class="line">                <span class="keyword">if</span>(!p-&gt;left &amp;&amp; !p-&gt;right){</span><br><span class="line">                    nums.push_back(sumV(nodeValue));</span><br><span class="line">                }</span><br><span class="line">                <span class="keyword">if</span>(p-&gt;right &amp;&amp; (visited.<span class="built_in">find</span>(p-&gt;right)==visited.<span class="built_in">end</span>() || visited[p-&gt;right]==<span class="number">0</span>)){</span><br><span class="line">                    p = p-&gt;right;</span><br><span class="line">                    stk.push(p);</span><br><span class="line">                    visited[p] = <span class="number">0</span>;</span><br><span class="line">                    tenMutilVector(nodeValue);</span><br><span class="line">                    nodeValue.push_back(p-&gt;val);</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                }</span><br><span class="line">                visited[p] = <span class="number">1</span>;</span><br><span class="line">                stk.pop();</span><br><span class="line">                tenDivideVector(nodeValue);</span><br><span class="line">                nodeValue.resize(nodeValue.<span class="built_in">size</span>()<span class="number">-1</span>);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> nums;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">tenMutilVector</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &amp;nums)</span> </span>{</span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++){</span><br><span class="line">            nums[i] *= <span class="number">10</span>;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">tenDivideVector</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &amp;nums)</span> </span>{</span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++){</span><br><span class="line">            nums[i] /= <span class="number">10</span>;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">sumV</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &amp;nums)</span></span>{</span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">int</span> sumValue = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++){</span><br><span class="line">            sumValue += nums[i];</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> sumValue;</span><br><span class="line">    }   </span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p>附加一个求深度的代码：</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getDepth</span><span class="params">(TreeNode* root)</span> </span>{</span><br><span class="line">    <span class="keyword">if</span>(root == <span class="literal">NULL</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> ldepth = <span class="number">0</span>,rdepth = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    ldepth = getDepth(root-&gt;left);</span><br><span class="line">    rdepth = getDepth(root-&gt;right);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ldepth&gt;rdepth?ldepth+<span class="number">1</span>:rdepth+<span class="number">1</span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>方法二：（递归法）</p><figure class="highlight coq"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int sumNumbers(TreeNode* root) {</span><br><span class="line">        <span class="built_in">sum</span> = <span class="number">0</span>;</span><br><span class="line">        sumStep(root, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>;</span><br><span class="line">    }</span><br><span class="line">private:</span><br><span class="line">    int <span class="built_in">sum</span>;</span><br><span class="line">    void sumStep(TreeNode *root, int num){</span><br><span class="line">        <span class="keyword">if</span>(!root) <span class="keyword">return</span>;</span><br><span class="line">        <span class="keyword">if</span>(!root-&gt;<span class="built_in">left</span> &amp;&amp; !root-&gt;<span class="built_in">right</span>) {</span><br><span class="line">            <span class="built_in">sum</span> = <span class="built_in">sum</span> + num*<span class="number">10</span> + root-&gt;val;</span><br><span class="line">        }<span class="keyword">else</span>{</span><br><span class="line">            sumStep(root-&gt;<span class="built_in">left</span>, num*<span class="number">10</span> + root-&gt;val);</span><br><span class="line">            sumStep(root-&gt;<span class="built_in">right</span>, num*<span class="number">10</span> + root-&gt;val);</span><br><span class="line">        }</span><br><span class="line">        </span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-136-Single-Number"><a href="#Leetcode-136-Single-Number" class="headerlink" title="Leetcode[136]-Single Number"></a>Leetcode[136]-Single Number</h1><p>Lind:<a href="https://leetcode.com/problems/single-number/" target="_blank" rel="noopener">https://leetcode.com/problems/single-number/</a></p><p>Given an array of integers, every element appears twice except for one. Find that single one.</p><p>Note:<br>Your algorithm should have a linear runtime complexity. Could you implement it without using extra memory?</p><hr><p>分析：首先对数组进行排序，然后从开始进行两两比较，如果两个相等，则以步长为2往后比较，如果不相等，则返回第一个值。代码如下：</p><p>Code(c++)</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">singleNumber</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>{</span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        </span><br><span class="line">        sort(nums.<span class="built_in">begin</span>(),nums.<span class="built_in">end</span>());</span><br><span class="line">        <span class="keyword">if</span>(n==<span class="number">1</span>) <span class="keyword">return</span> nums[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(i&lt;n) {</span><br><span class="line">            <span class="keyword">if</span>(nums[i] == nums[i+<span class="number">1</span>])</span><br><span class="line">                i = i+<span class="number">2</span>;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                <span class="keyword">return</span> nums[i];</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-137-Single-Number-II"><a href="#Leetcode-137-Single-Number-II" class="headerlink" title="Leetcode[137]-Single Number II"></a>Leetcode[137]-Single Number II</h1><p>Link:<a href="https://leetcode.com/problems/single-number-ii/" target="_blank" rel="noopener">https://leetcode.com/problems/single-number-ii/</a></p><p>Given an array of integers, every element appears three times except for one. Find that single one.</p><p>Note:</p><p>Your algorithm should have a linear runtime complexity. Could you implement it without using extra memory?</p><hr><p>思路：先排序，然后一对一对的进行比较.</p><p>C++</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">singleNumber</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>{</span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">if</span>(n==<span class="number">1</span>) <span class="keyword">return</span> nums[<span class="number">0</span>];</span><br><span class="line">        sort(nums.<span class="built_in">begin</span>(),nums.<span class="built_in">end</span>());</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(i&lt;n<span class="number">-2</span>){</span><br><span class="line">            <span class="keyword">if</span>(nums[i]!=nums[i+<span class="number">1</span>]){</span><br><span class="line">                <span class="keyword">return</span> nums[i];</span><br><span class="line">            }<span class="keyword">else</span>{</span><br><span class="line">                i = i + <span class="number">3</span>;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> nums[n<span class="number">-1</span>];</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-141-Linked-List-Cycle"><a href="#Leetcode-141-Linked-List-Cycle" class="headerlink" title="Leetcode[141]-Linked List Cycle"></a>Leetcode[141]-Linked List Cycle</h1><p>Link:<a href="https://leetcode.com/problems/linked-list-cycle/" target="_blank" rel="noopener">https://leetcode.com/problems/linked-list-cycle/</a></p><p>Given a linked list, determine if it has a cycle in it.</p><p>Follow up:<br>Can you solve it without using extra space?</p><hr><p><strong>分析：</strong>设置两个临时指针，一个一次走一步，一个一次走两步，如果再次相遇，表示有环。</p><p><strong>Code(c++):</strong></p><figure class="highlight vbscript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Definition <span class="keyword">for</span> singly-linked list.</span><br><span class="line"> * struct ListNode {</span><br><span class="line"> *     <span class="built_in">int</span> val;</span><br><span class="line"> *     ListNode *<span class="keyword">next</span>;</span><br><span class="line"> *     ListNode(<span class="built_in">int</span> x) : val(x), <span class="keyword">next</span>(<span class="literal">NULL</span>) {}</span><br><span class="line"> * };</span><br><span class="line"> */</span><br><span class="line"><span class="keyword">class</span> Solution {</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    bool hasCycle(ListNode *head) {</span><br><span class="line">        <span class="keyword">if</span>(head==<span class="literal">NULL</span> || head-&gt;<span class="keyword">next</span>==<span class="literal">NULL</span>) return <span class="literal">false</span>;</span><br><span class="line">        </span><br><span class="line">        ListNode *first = head,*<span class="built_in">second</span> = head;</span><br><span class="line">        <span class="keyword">while</span>(<span class="built_in">second</span>!=<span class="literal">NULL</span> &amp;&amp; <span class="built_in">second</span>-&gt;<span class="keyword">next</span>!=<span class="literal">NULL</span>){</span><br><span class="line">            <span class="built_in">second</span> = <span class="built_in">second</span>-&gt;<span class="keyword">next</span>-&gt;<span class="keyword">next</span>;  </span><br><span class="line">            first = first-&gt;<span class="keyword">next</span>;</span><br><span class="line">            <span class="keyword">if</span>(first == <span class="built_in">second</span>)</span><br><span class="line">                return <span class="literal">true</span>;</span><br><span class="line">        }</span><br><span class="line">        return <span class="literal">false</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-143-Reorder-List"><a href="#Leetcode-143-Reorder-List" class="headerlink" title="Leetcode[143]-Reorder List"></a>Leetcode[143]-Reorder List</h1><p>Link: <a href="https://leetcode.com/problems/reorder-list/" target="_blank" rel="noopener">https://leetcode.com/problems/reorder-list/</a></p><p>Given a singly linked list L: L0→L1→…→Ln-1→Ln,<br>reorder it to: L0→Ln→L1→Ln-1→L2→Ln-2→…</p><p>You must do this in-place without altering the nodes’ values.</p><p>For example,<br>Given {1,2,3,4}, reorder it to {1,4,2,3}.</p><hr><p>思路：将列表分成两半，然后把后一半翻转，最后一个一个构成新链表。</p><p>C++:</p><figure class="highlight haxe"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * struct ListNode {</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode *next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) : val(x), next(NULL) {}</span></span><br><span class="line"><span class="comment"> * };</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>{</span><br><span class="line"><span class="keyword">public</span>:<span class="type"></span></span><br><span class="line"><span class="type"></span></span><br><span class="line"><span class="type">    void reorderList</span>(ListNode* head) {</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(head==NULL || head-&gt;next==NULL) <span class="keyword">return</span>;</span><br><span class="line">        </span><br><span class="line">        ListNode *mid = getMid(head);</span><br><span class="line">        ListNode *left = head,*right = reverseList(mid-&gt;next);</span><br><span class="line">        </span><br><span class="line">        mid-&gt;next = NULL;</span><br><span class="line">        </span><br><span class="line">        ListNode* <span class="keyword">new</span><span class="type">Head</span> = <span class="keyword">new</span> <span class="type">ListNode</span>(<span class="number">-1</span>);</span><br><span class="line">        ListNode* <span class="keyword">new</span><span class="type">Tail</span> = <span class="keyword">new</span><span class="type">Head</span>;</span><br><span class="line">        <span class="keyword">while</span>(left &amp;&amp; right){</span><br><span class="line">            ListNode *temp = left-&gt;next;</span><br><span class="line">            left-&gt;next = <span class="keyword">new</span><span class="type">Tail</span>-&gt;next;</span><br><span class="line">            <span class="keyword">new</span><span class="type">Tail</span>-&gt;next = left;</span><br><span class="line">            <span class="keyword">new</span><span class="type">Tail</span> = <span class="keyword">new</span><span class="type">Tail</span>-&gt;next;</span><br><span class="line">            left = temp;</span><br><span class="line">    </span><br><span class="line">            temp = right-&gt;next;</span><br><span class="line">            right-&gt;next = <span class="keyword">new</span><span class="type">Tail</span>-&gt;next;</span><br><span class="line">            <span class="keyword">new</span><span class="type">Tail</span>-&gt;next = right;</span><br><span class="line">            <span class="keyword">new</span><span class="type">Tail</span> = <span class="keyword">new</span><span class="type">Tail</span>-&gt;next;</span><br><span class="line">            right = temp;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span>(left) <span class="keyword">new</span><span class="type">Tail</span>-&gt;next = left;</span><br><span class="line">        <span class="keyword">if</span>(right) <span class="keyword">new</span><span class="type">Tail</span>-&gt;next = right;</span><br><span class="line">        <span class="keyword">new</span><span class="type">Head</span> = <span class="keyword">new</span><span class="type">Head</span>-&gt;next;</span><br><span class="line">        head = <span class="keyword">new</span><span class="type">Head</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">//reverse list</span></span><br><span class="line">    ListNode* reverseList(ListNode* head){</span><br><span class="line">        <span class="keyword">if</span>(head==NULL || head-&gt;next==NULL) <span class="keyword">return</span> head;</span><br><span class="line">        </span><br><span class="line">        ListNode *pre = head;</span><br><span class="line">        ListNode *<span class="keyword">new</span><span class="type">List</span> = <span class="keyword">new</span> <span class="type">ListNode</span>(<span class="number">-1</span>);</span><br><span class="line">        <span class="keyword">while</span>(pre!=NULL){</span><br><span class="line">            ListNode* temp = pre-&gt;next;</span><br><span class="line">            pre-&gt;next = <span class="keyword">new</span><span class="type">List</span>-&gt;next;</span><br><span class="line">            <span class="keyword">new</span><span class="type">List</span>-&gt;next = pre;</span><br><span class="line">            pre = temp;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">new</span><span class="type">List</span> = <span class="keyword">new</span><span class="type">List</span>-&gt;next;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span><span class="type">List</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">//get the middle element</span></span><br><span class="line">    ListNode* getMid(ListNode* head){</span><br><span class="line">        <span class="keyword">if</span>(head==NULL ||head-&gt;next ==NULL)<span class="keyword">return</span> head;</span><br><span class="line">        </span><br><span class="line">        ListNode *first=head,*second=head-&gt;next;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span>(second &amp;&amp; second-&gt;next){</span><br><span class="line">            first = first-&gt;next;</span><br><span class="line">            second = second-&gt;next-&gt;next;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> first;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-144-Binary-Tree-Preorder-Traversal"><a href="#Leetcode-144-Binary-Tree-Preorder-Traversal" class="headerlink" title="Leetcode[144]-Binary Tree Preorder Traversal"></a>Leetcode[144]-Binary Tree Preorder Traversal</h1><p>Link: <a href="https://leetcode.com/problems/binary-tree-preorder-traversal/" target="_blank" rel="noopener">https://leetcode.com/problems/binary-tree-preorder-traversal/</a></p><p>Given a binary tree, return the preorder traversal of its nodes’ values.</p><p>For example:<br>Given binary tree<code>{1,#,2,3}</code>,</p><pre><code>1 \  2 /3</code></pre><p>return [1,2,3].</p><hr><h2 id="C-递归遍历："><a href="#C-递归遍历：" class="headerlink" title="C++递归遍历："></a>C++递归遍历：</h2><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**C++</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * struct TreeNode {</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode *left;</span></span><br><span class="line"><span class="comment"> *     TreeNode *right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span></span><br><span class="line"><span class="comment"> * };</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; nums;</span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">preorderTraversal</span><span class="params">(TreeNode* root)</span> </span>{</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="literal">NULL</span>) <span class="keyword">return</span> nums;</span><br><span class="line">        preOrder(root);</span><br><span class="line">        <span class="keyword">return</span> nums;</span><br><span class="line">    }</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">preOrder</span><span class="params">(TreeNode * root)</span></span>{</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="literal">NULL</span>) <span class="keyword">return</span>;</span><br><span class="line">        nums.push_back(root-&gt;val);</span><br><span class="line">        <span class="keyword">if</span>(root-&gt;left)  preOrder(root-&gt;left);</span><br><span class="line">        <span class="keyword">if</span>(root-&gt;right) preOrder(root-&gt;right);</span><br><span class="line">    }   </span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><h2 id="C-递归遍历二"><a href="#C-递归遍历二" class="headerlink" title="C++递归遍历二:"></a>C++递归遍历二:</h2><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * struct TreeNode {</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode *left;</span></span><br><span class="line"><span class="comment"> *     TreeNode *right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span></span><br><span class="line"><span class="comment"> * };</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">preorderTraversal</span><span class="params">(TreeNode* root)</span> </span>{</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; ves;</span><br><span class="line">        preorder(root, ves);</span><br><span class="line">        <span class="keyword">return</span> ves;</span><br><span class="line">    }</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">preorder</span><span class="params">(TreeNode* root, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &amp;nums)</span></span>{</span><br><span class="line">        <span class="keyword">if</span>(!root) <span class="keyword">return</span>;</span><br><span class="line">        nums.push_back(root-&gt;val);</span><br><span class="line">        preorder(root-&gt;left, nums);</span><br><span class="line">        preorder(root-&gt;right, nums);</span><br><span class="line">    }   </span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><h2 id="非递归遍历C-："><a href="#非递归遍历C-：" class="headerlink" title="非递归遍历C++："></a>非递归遍历C++：</h2><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">preorderTraversal</span><span class="params">(TreeNode* root)</span> </span>{</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span> &gt; nums;</span><br><span class="line">    <span class="built_in">stack</span>&lt;TreeNode* &gt; stk;</span><br><span class="line">    <span class="keyword">if</span>(root == <span class="literal">NULL</span>) <span class="keyword">return</span> nums;</span><br><span class="line">    TreeNode * p = root;</span><br><span class="line">    stk.push(p);   </span><br><span class="line">    <span class="keyword">while</span>(!stk.empty()){</span><br><span class="line">        p = stk.top();</span><br><span class="line">        nums.push_back(p-&gt;val);</span><br><span class="line">        stk.pop();</span><br><span class="line">        <span class="keyword">if</span>(p-&gt;right) stk.push(p-&gt;right);</span><br><span class="line">        <span class="keyword">if</span>(p-&gt;left) stk.push(p-&gt;left);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-145-Binary-Tree-Postorder-Traversal"><a href="#Leetcode-145-Binary-Tree-Postorder-Traversal" class="headerlink" title="Leetcode[145]-Binary Tree Postorder Traversal"></a>Leetcode[145]-Binary Tree Postorder Traversal</h1><p>Link: <a href="https://leetcode.com/problems/binary-tree-postorder-traversal/" target="_blank" rel="noopener">https://leetcode.com/problems/binary-tree-postorder-traversal/</a></p><p>Given a binary tree, return the postorder traversal of its nodes’ values.</p><p>For example:<br>Given binary tree <code>{1,#,2,3}</code>,</p><pre><code>1 \  2 /3</code></pre><p>return <code>[3,2,1]</code>.</p><p>Note: Recursive solution is trivial, could you do it iteratively?</p><hr><p>方法一：递归遍历</p><figure class="highlight vbscript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Definition <span class="keyword">for</span> a binary tree node.</span><br><span class="line"> * struct TreeNode {</span><br><span class="line"> *     <span class="built_in">int</span> val;</span><br><span class="line"> *     TreeNode *<span class="built_in">left</span>;</span><br><span class="line"> *     TreeNode *<span class="built_in">right</span>;</span><br><span class="line"> *     TreeNode(<span class="built_in">int</span> x) : val(x), <span class="built_in">left</span>(<span class="literal">NULL</span>), <span class="built_in">right</span>(<span class="literal">NULL</span>) {}</span><br><span class="line"> * };</span><br><span class="line"> */</span><br><span class="line"><span class="keyword">class</span> Solution {</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">    vector&lt;<span class="built_in">int</span>&gt; nums;</span><br><span class="line">    vector&lt;<span class="built_in">int</span>&gt; postorderTraversal(TreeNode* root) {</span><br><span class="line">        postorder(root);</span><br><span class="line">        return nums;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    void postorder(TreeNode * root){</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="literal">NULL</span>) return;</span><br><span class="line">        <span class="keyword">if</span>(root-&gt;<span class="built_in">left</span>) postorder(root-&gt;<span class="built_in">left</span>);</span><br><span class="line">        <span class="keyword">if</span>(root-&gt;<span class="built_in">right</span>) postorder(root-&gt;<span class="built_in">right</span>);</span><br><span class="line">        nums.push_back(root-&gt;val);</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-147-Insertion-Sort-List"><a href="#Leetcode-147-Insertion-Sort-List" class="headerlink" title="Leetcode[147]-Insertion Sort List"></a>Leetcode[147]-Insertion Sort List</h1><p>Link: <a href="https://leetcode.com/problems/insertion-sort-list/" target="_blank" rel="noopener">https://leetcode.com/problems/insertion-sort-list/</a></p><p>Sort a linked list using insertion sort.</p><hr><p>链表的插入排序</p><p>思路：新开辟一个链表空间，用来作为插入排序的目标链。循环遍历原链表，对每个节点，让其从头到尾的在已经排好序的链表中找到插入位置（此处记录的是插入位置的前一个位置），然后将其插入进去即可。</p><p>代码Code(c++)：</p><figure class="highlight xl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * struct ListNode {</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode *next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) : val(x), next(NULL) {}</span></span><br><span class="line"><span class="comment"> * };</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    ListNode* insertionSortList(ListNode* head) {</span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="title">if</span>(head == NULL || head-&gt;</span>next ==NULL) return head;</span><br><span class="line">        ListNode *pre = new ListNode(-<span class="number">1</span>);</span><br><span class="line">    </span><br><span class="line">        <span class="function"><span class="title">pre</span>-&gt;</span>next = head;</span><br><span class="line">        <span class="function"><span class="title">head</span> = head-&gt;</span>next;</span><br><span class="line">        <span class="function"><span class="title">pre</span>-&gt;</span><span class="function"><span class="title">next</span>-&gt;</span>next = NULL;</span><br><span class="line">        ListNode *temp,*headNext;</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">while</span>(head!=NULL){</span><br><span class="line">            ListNode *prior = pre;</span><br><span class="line">            <span class="function"><span class="title">temp</span> = pre-&gt;</span>next;</span><br><span class="line">            <span class="keyword">while</span>(temp){</span><br><span class="line">                <span class="function"><span class="title">if</span>(head-&gt;</span><span class="function"><span class="title">val</span> &gt; temp-&gt;</span>val){</span><br><span class="line">                    prior = temp;</span><br><span class="line">                    <span class="function"><span class="title">temp</span> = temp-&gt;</span>next;</span><br><span class="line">                }</span><br><span class="line">                <span class="keyword">else</span> break;</span><br><span class="line">            }</span><br><span class="line">            <span class="function"><span class="title">headNext</span> = head-&gt;</span>next;</span><br><span class="line">            <span class="function"><span class="title">head</span>-&gt;</span><span class="function"><span class="title">next</span> = prior-&gt;</span>next;</span><br><span class="line">            <span class="function"><span class="title">prior</span>-&gt;</span>next = head;</span><br><span class="line">            head = headNext;</span><br><span class="line">        }</span><br><span class="line">        <span class="function"><span class="title">head</span>= pre-&gt;</span>next;</span><br><span class="line">        return head;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-148-Sort-List"><a href="#Leetcode-148-Sort-List" class="headerlink" title="Leetcode[148]-Sort List"></a>Leetcode[148]-Sort List</h1><p>Link: <a href="https://leetcode.com/problems/sort-list/" target="_blank" rel="noopener">https://leetcode.com/problems/sort-list/</a></p><p>Sort a linked list in O(n log n) time using constant space complexity.</p><hr><p><strong>分析：</strong>题目要求时间复杂度为O(nlogn)，所以一开始想到的就是快速排序，但是快速排序一直AC不了，然后就想到用归并排序，没想到归并排序竟然可以。下面给出详细代码：</p><p>归并排序需要做的</p><ul><li>找到中间点</li><li>合并两个排好序的链表</li><li>递归实现归并排序</li></ul><p>Code(c++):</p><figure class="highlight coq"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * <span class="keyword">Definition</span> <span class="keyword">for</span> singly-linked list.</span><br><span class="line"> * struct ListNode {</span><br><span class="line"> *     int val;</span><br><span class="line"> *     ListNode *next;</span><br><span class="line"> *     ListNode(int x) : val(x), next(NULL) {}</span><br><span class="line"> * };</span><br><span class="line"> */</span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    //mergeSort</span><br><span class="line">    ListNode* sortList(ListNode* head) {</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">if</span>(head == NULL |<span class="type">| head</span>-&gt;next==NULL) <span class="keyword">return</span> head;</span><br><span class="line">    </span><br><span class="line">        ListNode *mid = getMid(head);</span><br><span class="line">        ListNode *<span class="built_in">left</span> = head,*<span class="built_in">right</span>;</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">if</span>(mid){</span><br><span class="line">            cout&lt;&lt;mid-&gt;val&lt;&lt;endl;</span><br><span class="line">            <span class="built_in">right</span> = mid-&gt;next;</span><br><span class="line">            mid-&gt;next = NULL;</span><br><span class="line">        }</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> mergeLinkedList(sortList(<span class="built_in">left</span>),sortList(<span class="built_in">right</span>));</span><br><span class="line">    </span><br><span class="line">    }</span><br><span class="line">    //get middle point from ListNode</span><br><span class="line">    ListNode* getMid(ListNode* head){</span><br><span class="line">        <span class="keyword">if</span>(head==NULL |<span class="type">| head</span>-&gt;next==NULL ) <span class="keyword">return</span> head;</span><br><span class="line">    </span><br><span class="line">        ListNode* <span class="built_in">first</span> = head,* second = head-&gt;next;</span><br><span class="line">    </span><br><span class="line">        while(second &amp;&amp; second-&gt;next){</span><br><span class="line">            <span class="built_in">first</span> = <span class="built_in">first</span>-&gt;next;</span><br><span class="line">            second = second-&gt;next-&gt;next;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">first</span>;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    //merge two sorted Linked List</span><br><span class="line">    ListNode* mergeLinkedList(ListNode* <span class="built_in">first</span>,ListNode* second){</span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">first</span>==NULL) <span class="keyword">return</span> second;</span><br><span class="line">        <span class="keyword">if</span>(second==NULL) <span class="keyword">return</span> <span class="built_in">first</span>;</span><br><span class="line">    </span><br><span class="line">        ListNode* tail,* front;</span><br><span class="line">        front = new ListNode(<span class="number">-1</span>);</span><br><span class="line">        tail = front;</span><br><span class="line">        while(<span class="built_in">first</span> &amp;&amp; second){</span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">first</span>-&gt;val &lt; second-&gt;val){</span><br><span class="line">                tail-&gt;next = <span class="built_in">first</span>;</span><br><span class="line">                <span class="built_in">first</span> = <span class="built_in">first</span>-&gt;next;</span><br><span class="line">                tail = tail-&gt;next;</span><br><span class="line">            }<span class="keyword">else</span>{</span><br><span class="line">                tail-&gt;next = second;</span><br><span class="line">                second = second-&gt;next;</span><br><span class="line">                tail = tail-&gt;next;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">first</span>){</span><br><span class="line">            tail-&gt;next =<span class="built_in">first</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span>(second){</span><br><span class="line">            tail-&gt;next = second;</span><br><span class="line">        }</span><br><span class="line">        front = front-&gt;next;</span><br><span class="line">        <span class="keyword">return</span> front;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-153-Find-Minimum-in-Rotated-Sorted-Array"><a href="#Leetcode-153-Find-Minimum-in-Rotated-Sorted-Array" class="headerlink" title="Leetcode[153]-Find Minimum in Rotated Sorted Array"></a>Leetcode[153]-Find Minimum in Rotated Sorted Array</h1><p>Link: <a href="https://leetcode.com/problems/find-minimum-in-rotated-sorted-array/" target="_blank" rel="noopener">https://leetcode.com/problems/find-minimum-in-rotated-sorted-array/</a></p><p>Suppose a sorted array is rotated at some pivot unknown to you beforehand.</p><p>(i.e., 0 1 2 4 5 6 7 might become 4 5 6 7 0 1 2).</p><p>Find the minimum element.</p><p>You may assume no duplicate exists in the array.</p><hr><p>C++:</p><p>方法一：直接遍历，暴力求解</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">findMin</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>{</span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">int</span> <span class="built_in">min</span> = nums[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span>  i = <span class="number">1</span>; i &lt; n; i++) {</span><br><span class="line">            <span class="keyword">if</span>(nums[i]&lt;<span class="built_in">min</span>){</span><br><span class="line">                <span class="built_in">min</span> = nums[i];</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">min</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-154-Find-Minimum-in-Rotated-Sorted-Array-II"><a href="#Leetcode-154-Find-Minimum-in-Rotated-Sorted-Array-II" class="headerlink" title="Leetcode[154]-Find Minimum in Rotated Sorted Array II"></a>Leetcode[154]-Find Minimum in Rotated Sorted Array II</h1><p>Link：　<a href="https://leetcode.com/problems/find-minimum-in-rotated-sorted-array-ii/" target="_blank" rel="noopener">https://leetcode.com/problems/find-minimum-in-rotated-sorted-array-ii/</a></p><pre><code>Follow up for "Find Minimum in Rotated Sorted Array":What if duplicates are allowed?Would this affect the run-time complexity? How and why?</code></pre><p>Suppose a sorted array is rotated at some pivot unknown to you beforehand.</p><p>(i.e., 0 1 2 4 5 6 7 might become 4 5 6 7 0 1 2).</p><p>Find the minimum element.</p><p>The array may contain duplicates.</p><hr><p>Ｃ++：</p><p>方法一：直接遍历求解</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">findMin</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>{</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">int</span> <span class="built_in">min</span> = nums[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span>  i = <span class="number">1</span>; i &lt; n; i++) {</span><br><span class="line">            <span class="keyword">if</span>(nums[i]&lt;<span class="built_in">min</span>){</span><br><span class="line">                <span class="built_in">min</span> = nums[i];</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">min</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="LeetCode-155-Min-Stack"><a href="#LeetCode-155-Min-Stack" class="headerlink" title="LeetCode[155]-Min Stack"></a>LeetCode[155]-Min Stack</h1><p>Link: <a href="https://leetcode.com/problems/min-stack/" target="_blank" rel="noopener">https://leetcode.com/problems/min-stack/</a></p><p>Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.</p><p>push(x) – Push element x onto stack.<br>pop() – Removes the element on top of the stack.<br>top() – Get the top element.<br>getMin() – Retrieve the minimum element in the stack.</p><hr><p>思路：需要两个栈，一个用来作为一般的栈，另一个用来存放进栈到某一位置的当前站内最小元素，代码如下：</p><p>Code（c++）:</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MinStack</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; stk;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; <span class="built_in">min</span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">push</span><span class="params">(<span class="keyword">int</span> x)</span> </span>{</span><br><span class="line">        stk.push(x);</span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">min</span>.empty() || (!<span class="built_in">min</span>.empty() &amp;&amp; x &lt;= <span class="built_in">min</span>.top())){</span><br><span class="line">            <span class="built_in">min</span>.push(x);</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">pop</span><span class="params">()</span> </span>{</span><br><span class="line">        <span class="keyword">if</span>(!stk.empty()){</span><br><span class="line">            <span class="keyword">if</span>(stk.top() == <span class="built_in">min</span>.top())<span class="built_in">min</span>.pop();</span><br><span class="line">            stk.pop();</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">top</span><span class="params">()</span> </span>{</span><br><span class="line">        <span class="keyword">if</span>(!stk.empty())</span><br><span class="line">            <span class="keyword">return</span> stk.top();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">getMin</span><span class="params">()</span> </span>{</span><br><span class="line">        <span class="keyword">if</span>(!stk.empty()) <span class="keyword">return</span> <span class="built_in">min</span>.top();</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-162-Find-Peak-Element"><a href="#Leetcode-162-Find-Peak-Element" class="headerlink" title="Leetcode[162]-Find Peak Element"></a>Leetcode[162]-Find Peak Element</h1><p>Link: <a href="https://leetcode.com/problems/find-peak-element/" target="_blank" rel="noopener">https://leetcode.com/problems/find-peak-element/</a></p><p>A peak element is an element that is greater than its neighbors.</p><p>Given an input array where num[i] ≠ num[i+1], find a peak element and return its index.</p><p>The array may contain multiple peaks, in that case return the index to any one of the peaks is fine.</p><p>You may imagine that num[-1] = num[n] = -∞.</p><p>For example, in array [1, 2, 3, 1], 3 is a peak element and your function should return the index number 2.</p><p>click to show spoilers.</p><hr><p>分析：</p><ul><li>如果只有一个元素，直接返回0；</li><li>如果元素个数&gt;=2，判断首尾是否大于它的附近元素，大于则返回下标；</li><li>循环遍历，下标从&gt;=1到 &lt; n-1，判断nums[i]是否同时大于它的附近元素，如果大于则返回该下标；</li></ul><p>否则，返回-1；</p><p>Code(c++)</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">findPeakElement</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>{</span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">if</span>(n==<span class="number">1</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(nums[<span class="number">0</span>] &gt; nums[<span class="number">1</span>]) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(nums[n<span class="number">-1</span>] &gt; nums[n<span class="number">-2</span>]) <span class="keyword">return</span> n<span class="number">-1</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;n<span class="number">-1</span>; i++){</span><br><span class="line">            <span class="keyword">if</span>(nums[i]&gt;nums[i<span class="number">-1</span>] &amp;&amp; nums[i]&gt;nums[i+<span class="number">1</span>]){</span><br><span class="line">                <span class="keyword">return</span> i;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-169-Majority-Element"><a href="#Leetcode-169-Majority-Element" class="headerlink" title="Leetcode[169]-Majority Element"></a>Leetcode[169]-Majority Element</h1><p>Given an array of size n, find the majority element. The majority element is the element that appears more than ⌊ n/2 ⌋ times.</p><p>You may assume that the array is non-empty and the majority element always exist in the array.</p><p>Credits:<br>Special thanks to @ts for adding this problem and creating all test cases.</p><hr><p>思路一：将数组排好序，中间的那个数一定就是我们需要的majority element。时间复杂度O(nlogn)</p><p>思路二：Moore voting algorithm–每找出两个不同的element，就成对删除即count–，最终剩下的一定就是所求的。时间复杂度：O(n)</p><p>Code1(C++):</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">majorityElement1</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>{</span><br><span class="line">    <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">    sort(nums.<span class="built_in">begin</span>(),nums.<span class="built_in">end</span>());</span><br><span class="line">    <span class="keyword">return</span> nums[n/<span class="number">2</span>];</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>Code2(C++)</p><figure class="highlight fortran"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> Solution {</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">int</span> majorityElement(vector&lt;<span class="built_in">int</span>&gt;&amp; nums) {</span><br><span class="line">        <span class="built_in">int</span> n = nums.<span class="built_in">size</span>();  </span><br><span class="line">        <span class="built_in">int</span> <span class="built_in">count</span> = <span class="number">0</span>,<span class="keyword">number</span>;</span><br><span class="line">        for(<span class="built_in">int</span> i=<span class="number">0</span>;i &lt; n; i++){</span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">count</span> == <span class="number">0</span>) {</span><br><span class="line">                <span class="keyword">number</span> = nums[i];</span><br><span class="line">                <span class="built_in">count</span>++;</span><br><span class="line">            } <span class="keyword">else</span> {</span><br><span class="line">                <span class="keyword">number</span> == nums[i] ? <span class="built_in">count</span>++: <span class="built_in">count</span>--;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">number</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-173-Binary-Search-Tree-Iterator"><a href="#Leetcode-173-Binary-Search-Tree-Iterator" class="headerlink" title="Leetcode[173]-Binary Search Tree Iterator"></a>Leetcode[173]-Binary Search Tree Iterator</h1><p>Link: <a href="https://leetcode.com/problems/binary-search-tree-iterator/" target="_blank" rel="noopener">https://leetcode.com/problems/binary-search-tree-iterator/</a></p><p>Implement an iterator over a binary search tree (BST). Your iterator will be initialized with the root node of a BST.</p><p>Calling next() will return the next smallest number in the BST.</p><p>Note: next() and hasNext() should run in average O(1) time and uses O(h) memory, where h is the height of the tree.</p><hr><p><strong>思路：</strong> 遍历一遍，然后从小到大的放到队列里去，然后判断队列是否非空，不非空则前面的就是最小的，出队即可！</p><p>C++:</p><figure class="highlight zephir"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for binary tree</span></span><br><span class="line"><span class="comment"> * struct TreeNode {</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode *left;</span></span><br><span class="line"><span class="comment"> *     TreeNode *right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span></span><br><span class="line"><span class="comment"> * };</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BSTIterator</span> </span>{</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    queue&lt;<span class="keyword">int</span>&gt; que;</span><br><span class="line">    BSTIterator(TreeNode *root) {</span><br><span class="line">        stack&lt;TreeNode *&gt; stk;</span><br><span class="line">        map&lt;TreeNode *, <span class="keyword">int</span>&gt; visited;</span><br><span class="line">        TreeNode *p;</span><br><span class="line">        <span class="keyword">if</span>(root) { </span><br><span class="line">            stk.push(root);</span><br><span class="line">            visited[root] = <span class="number">0</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">while</span>(!stk.<span class="keyword">empty</span>()){</span><br><span class="line">            p = stk.top();</span><br><span class="line">            <span class="keyword">while</span>(p-&gt;left &amp;&amp; visited[p] == <span class="number">0</span>){</span><br><span class="line">                <span class="keyword">if</span>(visited[p-&gt;left] == <span class="number">1</span>) <span class="keyword">break</span>;</span><br><span class="line">                p = p-&gt;left;</span><br><span class="line">                stk.push(p);</span><br><span class="line">                visited[p]=<span class="number">0</span>;</span><br><span class="line">            }</span><br><span class="line">            visited[p]=<span class="number">1</span>;</span><br><span class="line">            que.push(p-&gt;val);</span><br><span class="line">            stk.pop();</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span>(p-&gt;right &amp;&amp; (visited.find(p-&gt;right)==visited.end() || visited[p-&gt;right]==<span class="number">0</span>)){</span><br><span class="line">                stk.push(p-&gt;right);</span><br><span class="line">                visited[p-&gt;right] = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line"><span class="comment">/* another way     </span></span><br><span class="line"><span class="comment">stack&lt;TreeNode*&gt; stk;</span></span><br><span class="line"><span class="comment">        while(root || !stk.empty() ) {</span></span><br><span class="line"><span class="comment">            if(root){</span></span><br><span class="line"><span class="comment">                stk.push(root);</span></span><br><span class="line"><span class="comment">                root = root-&gt;left;</span></span><br><span class="line"><span class="comment">            }else {</span></span><br><span class="line"><span class="comment">                root = stk.top();</span></span><br><span class="line"><span class="comment">                stk.pop();</span></span><br><span class="line"><span class="comment">                que.push(root-&gt;val);</span></span><br><span class="line"><span class="comment">                root = root-&gt;right;</span></span><br><span class="line"><span class="comment">            }   </span></span><br><span class="line"><span class="comment">        } */</span> </span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line"><span class="comment">/** <span class="doctag">@return</span> whether we have a next smallest number */</span></span><br><span class="line">    <span class="keyword">bool</span> hasNext() {</span><br><span class="line">        <span class="keyword">if</span>(!que.<span class="keyword">empty</span>()) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    }</span><br><span class="line"><span class="comment">/** <span class="doctag">@return</span> the next smallest number */</span></span><br><span class="line">    <span class="keyword">int</span> next() {</span><br><span class="line">        <span class="keyword">int</span> val = que.front();</span><br><span class="line">        que.pop();</span><br><span class="line">        <span class="keyword">return</span> val;</span><br><span class="line">    }</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Your BSTIterator will be called like this:</span></span><br><span class="line"><span class="comment"> * BSTIterator i = BSTIterator(root);</span></span><br><span class="line"><span class="comment"> * while (i.hasNext()) cout &lt;&lt; i.next();</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-189-Rotate-Array"><a href="#Leetcode-189-Rotate-Array" class="headerlink" title="Leetcode[189]-Rotate Array"></a>Leetcode[189]-Rotate Array</h1><p>Link: <a href="https://leetcode.com/problems/rotate-array/" target="_blank" rel="noopener">https://leetcode.com/problems/rotate-array/</a></p><p>Rotate an array of n elements to the right by k steps.</p><p>For example, with n = 7 and k = 3, the array [1,2,3,4,5,6,7] is rotated to [5,6,7,1,2,3,4].</p><p>Note:<br>Try to come up as many solutions as you can, there are at least 3 different ways to solve this problem.</p><p>[show hint]</p><p>Related problem: Reverse Words in a String II</p><p>Credits:<br>Special thanks to @Freezen for adding this problem and creating all test cases.</p><hr><p>分析： (使用三次反转)利用</p><p>$$ba=(b^{r})^{r}(a^{r})^{r}=(a^{r}b^{r})^{r}$$</p><p>先分别反转a、b，最后再对所有元素进行一次反转。此算法读写内存各约2*n次。</p><p>结论：将数组按照k值分成左右两部分，右边k个，左边n-k个，然后先将左右两部分各自翻转，再将整个数组整体翻转，即可得到结果。</p><p>Code（c++）：</p><figure class="highlight matlab"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">class Solution</span><br><span class="line">{</span><br><span class="line">public:</span><br><span class="line">void swap(int * s1,int * s2)</span><br><span class="line">{</span><br><span class="line">int temp = *s1;</span><br><span class="line">*s1 = *s2;</span><br><span class="line">*s2 = temp;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">void rotate(vector&lt;int&gt; &amp; nums,int k)</span><br><span class="line">{</span><br><span class="line">int n = nums.<span class="built_in">size</span>();</span><br><span class="line">int left = n - (k <span class="comment">% n);</span></span><br><span class="line"><span class="keyword">for</span>(int <span class="built_in">i</span> = <span class="number">0</span>,<span class="built_in">j</span> = left - <span class="number">1</span>;<span class="built_in">i</span> &lt; <span class="built_in">j</span>;<span class="built_in">i</span>++,<span class="built_in">j</span>--)</span><br><span class="line">swap(&amp;nums[<span class="built_in">i</span>],&amp;nums[<span class="built_in">j</span>]);</span><br><span class="line"><span class="keyword">for</span>(int <span class="built_in">i</span> = left,<span class="built_in">j</span> = n - <span class="number">1</span>;<span class="built_in">i</span> &lt; <span class="built_in">j</span>;<span class="built_in">i</span>++,<span class="built_in">j</span>--)</span><br><span class="line">swap(&amp;nums[<span class="built_in">i</span>],&amp;nums[<span class="built_in">j</span>]);</span><br><span class="line"><span class="keyword">for</span>(int <span class="built_in">i</span> = <span class="number">0</span>,<span class="built_in">j</span> = n - <span class="number">1</span>;<span class="built_in">i</span> &lt; <span class="built_in">j</span>;<span class="built_in">i</span>++,<span class="built_in">j</span>--)</span><br><span class="line">swap(&amp;nums[<span class="built_in">i</span>],&amp;nums[<span class="built_in">j</span>]);</span><br><span class="line">}</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-191-Number-of-Bits"><a href="#Leetcode-191-Number-of-Bits" class="headerlink" title="Leetcode[191]-Number of Bits"></a>Leetcode[191]-Number of Bits</h1><p>Link:<a href="https://leetcode.com/problems/number-of-1-bits/" target="_blank" rel="noopener">https://leetcode.com/problems/number-of-1-bits/</a></p><p>Write a function that takes an unsigned integer and returns the number of ’1’ bits it has (also known as the Hamming weight).</p><p>For example, the 32-bit integer ’11’ has binary representation 00000000000000000000000000001011, so the function should return 3.</p><hr><p>分析：<strong>在十进制转换为二进制时，如果n%2=1，则在二进制中有1</strong>.根据这条规则，可以循环判断n，每判断一次，n=n/2，代码如下：</p><p>C++:</p><figure class="highlight axapta"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>{</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> hammingWeight(uint32_t n) {</span><br><span class="line">        <span class="keyword">int</span> <span class="keyword">count</span> = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(n&gt;<span class="number">0</span>){</span><br><span class="line">            <span class="keyword">if</span>(n%<span class="number">2</span>==<span class="number">1</span>){</span><br><span class="line">                <span class="keyword">count</span>++;</span><br><span class="line">            }</span><br><span class="line">            n=n/<span class="number">2</span>; </span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">count</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p>Python:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hammingWeight</span><span class="params">(self, n)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type n: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> n&gt;<span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> n%<span class="number">2</span>==<span class="number">1</span>:</span><br><span class="line">                count=count+<span class="number">1</span></span><br><span class="line">            n=n/<span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> count</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-198-House-Robber"><a href="#Leetcode-198-House-Robber" class="headerlink" title="Leetcode[198]-House Robber"></a>Leetcode[198]-House Robber</h1><p>Link: <a href="https://leetcode.com/problems/house-robber/" target="_blank" rel="noopener">https://leetcode.com/problems/house-robber/</a></p><p>You are a professional robber planning to rob houses along a street. Each house has a certain amount of money stashed, the only constraint stopping you from robbing each of them is that adjacent houses have security system connected and it will automatically contact the police if two adjacent houses were broken into on the same night.</p><p>Given a list of non-negative integers representing the amount of money of each house, determine the maximum amount of money you can rob tonight without alerting the police.</p><hr><p>题目意思：假如现在你是一个强盗，一个武功超群，足智多谋的江洋大盗，现在你要去一条街上抢劫，这条街全是贪官污吏，一共有N家，每家都有一定数量的金子，如果相邻的两家在同一个晚上都被打劫了，那么就会有一个类似触发器的东西自动调动兵马来街上抓你。</p><p>请问，在不触发这个警报器的前提下，你能抢劫到多少money？</p><p><strong>动态规划思想解题</strong></p><p><strong>分析：</strong>，有N家贪官，假设是从左到右，第i家贪官家里的钱数为m[i]，i从0到N-1，根据题意可知，肯定不能在今晚打劫两个相邻的贪官，也就是假如打劫了第i家，就不能打劫第i-1家和i+1家。</p><p>设dp[i]表示我从第1家到达第i家能强盗的最大money数；</p><ul><li>当你打劫第一家的时候，i = 0，可以得到的钱dp[i] = m[0]；</li><li>当你到达第二家的时候，i = 1，此时能得到的钱数为max(m[0],m[1]),因为不能同时打劫第一家和第二家；</li><li>当到达第i家的时候，i＞＝２，此时能够得到的钱数应该为max{dp[i-1],dp[i-2]+m[i]},即要么是到达上一家时的最大money数，要么是到达上上家时的最大money+这一家的money数，两者中较大的那个；</li></ul><p>所以最后我们要得到的就是dp[N-1]，即到达最后一家时的最大money数。</p><hr><p>Code(c++):</p><figure class="highlight matlab"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int rob(vector&lt;int&gt;&amp; nums) {</span><br><span class="line">        int n = nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">if</span>(n == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        vector&lt;int&gt; dp(n);</span><br><span class="line">        <span class="keyword">for</span>(int <span class="built_in">i</span> = <span class="number">0</span>; <span class="built_in">i</span> &lt; n; <span class="built_in">i</span>++) {</span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">i</span> == <span class="number">0</span>) dp[<span class="built_in">i</span>] = nums[<span class="built_in">i</span>];</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(<span class="built_in">i</span> == <span class="number">1</span>) dp[<span class="built_in">i</span>] = <span class="built_in">max</span>(nums[<span class="built_in">i</span>],nums[<span class="built_in">i</span><span class="number">-1</span>]);</span><br><span class="line">            <span class="keyword">else</span>{</span><br><span class="line">                dp[<span class="built_in">i</span>] = <span class="built_in">max</span>(dp[<span class="built_in">i</span><span class="number">-1</span>], dp[<span class="built_in">i</span><span class="number">-2</span>] + nums[<span class="built_in">i</span>]);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span>  dp[n<span class="number">-1</span>];</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-202-Happy-Number"><a href="#Leetcode-202-Happy-Number" class="headerlink" title="Leetcode[202]-Happy Number"></a>Leetcode[202]-Happy Number</h1><p>Link:<a href="https://leetcode.com/problems/happy-number/" target="_blank" rel="noopener">https://leetcode.com/problems/happy-number/</a></p><p>Write an algorithm to determine if a number is “happy”.</p><p>A happy number is a number defined by the following process: Starting with any positive integer, replace the number by the sum of the squares of its digits, and repeat the process until the number equals 1 (where it will stay), or it loops endlessly in a cycle which does not include 1. Those numbers for which this process ends in 1 are happy numbers.</p><p>Example: 19 is a happy number</p><p>$1^2 + 9^2 = 82$<br>$8^2 + 2^2 = 68$<br>$6^2 + 8^2 = 100$<br>$1^2 + 0^2 + 0^2 = 1$</p><p>Credits:<br>Special thanks to @mithmatt and @ts for adding this problem and creating all test cases.</p><hr><p><strong>分析</strong>：题目说的是对任意一个正整数，不断各个数位上数字的平方和，若最终收敛为1，则该数字为happy number，否则程序可能从某个数开始陷入循环。</p><p>这里我们使用一个哈希map表存储已经出现过的数字，如果下次还出现，则返回false。</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isHappy</span><span class="params">(<span class="keyword">int</span> n)</span> </span>{</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(n==<span class="number">1</span>) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="built_in">map</span>&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; nums;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>(n&gt;<span class="number">0</span>){</span><br><span class="line">            <span class="keyword">int</span> number = <span class="number">0</span>;</span><br><span class="line">            # 计算一个数各个位的平方和</span><br><span class="line">            <span class="keyword">while</span>(n){</span><br><span class="line">                number += (n % <span class="number">10</span>) * (n % <span class="number">10</span>);</span><br><span class="line">                n/=<span class="number">10</span>;</span><br><span class="line">            }</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span>(number == <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(nums.<span class="built_in">find</span>(number)!=nums.<span class="built_in">end</span>())</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            n = number;</span><br><span class="line">            nums[n] = <span class="number">1</span>;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p>另外还有一种简单的算法：</p><hr><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isHappy</span><span class="params">(<span class="keyword">int</span> n)</span> </span>{</span><br><span class="line">        <span class="keyword">while</span>(n&gt;<span class="number">6</span>){  </span><br><span class="line">            <span class="keyword">int</span> next = <span class="number">0</span>;  </span><br><span class="line">            <span class="keyword">while</span>(n){</span><br><span class="line">                next+=(n%<span class="number">10</span>)*(n%<span class="number">10</span>); </span><br><span class="line">                n/=<span class="number">10</span>;</span><br><span class="line">            }  </span><br><span class="line">            n = next;  </span><br><span class="line">        }  </span><br><span class="line">        <span class="keyword">return</span> n==<span class="number">1</span>;  </span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-203-Remove-Linked-List-Elements"><a href="#Leetcode-203-Remove-Linked-List-Elements" class="headerlink" title="Leetcode[203]-Remove Linked List Elements"></a>Leetcode[203]-Remove Linked List Elements</h1><p>Remove all elements from a linked list of integers that have value val.</p><p>Example<br>Given: 1 –&gt; 2 –&gt; 6 –&gt; 3 –&gt; 4 –&gt; 5 –&gt; 6, val = 6<br>Return: 1 –&gt; 2 –&gt; 3 –&gt; 4 –&gt; 5</p><p>Credits:<br>Special thanks to @mithmatt for adding this problem and creating all test cases.</p><hr><p><strong>分析：</strong></p><ul><li><p>如果链表不为空，保证第一个节点不等于val，如果等于，直接跳到下一个节点；</p></li><li><p>如果此时链表为空，返回该链表；</p></li><li><p>将头结点赋值给一个临时节点，如果该节点的下一个节点不为空，递归遍历；</p><ul><li>如果下一个节点的值等于给定值，直接跳到下下个节点；</li><li>如果下一个节点的值不等于给定值，则让跳到下个节点再来循环；</li></ul></li><li><p>最后返回链表的头结点即可。</p></li></ul><p>Code（c++）：</p><figure class="highlight ocaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * <span class="type">Definition</span> <span class="keyword">for</span> singly-linked <span class="built_in">list</span>.</span><br><span class="line"> * <span class="keyword">struct</span> <span class="type">ListNode</span> {</span><br><span class="line"> *     <span class="built_in">int</span> <span class="keyword">val</span>;</span><br><span class="line"> *     <span class="type">ListNode</span> *next;</span><br><span class="line"> *     <span class="type">ListNode</span>(<span class="built_in">int</span> x) : <span class="keyword">val</span>(x), next(<span class="type">NULL</span>) {}</span><br><span class="line"> * };</span><br><span class="line"> */</span><br><span class="line"><span class="keyword">class</span> <span class="type">Solution</span> {</span><br><span class="line">public:</span><br><span class="line">    <span class="type">ListNode</span>* removeElements(<span class="type">ListNode</span>* head, <span class="built_in">int</span> <span class="keyword">val</span>) {</span><br><span class="line">        <span class="keyword">while</span>(head !=<span class="type">NULL</span> &amp;&amp; head-&gt;<span class="keyword">val</span> == <span class="keyword">val</span>) {</span><br><span class="line">            head = head-&gt;next;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span>(head == <span class="type">NULL</span>) return head;</span><br><span class="line">        <span class="type">ListNode</span>* pre = <span class="type">NULL</span>;</span><br><span class="line">        pre = head;</span><br><span class="line">        <span class="keyword">while</span>(pre-&gt;next!=<span class="type">NULL</span>){</span><br><span class="line">            <span class="keyword">if</span>(pre-&gt;next-&gt;<span class="keyword">val</span> == <span class="keyword">val</span>){</span><br><span class="line">                pre-&gt;next = pre-&gt;next-&gt;next;</span><br><span class="line">            } <span class="keyword">else</span>{</span><br><span class="line">                pre = pre-&gt;next;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return head;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-206-Reverse-Linked-List"><a href="#Leetcode-206-Reverse-Linked-List" class="headerlink" title="Leetcode[206]-Reverse Linked List"></a>Leetcode[206]-Reverse Linked List</h1><p>Link:<a href="https://leetcode.com/problems/reverse-linked-list/" target="_blank" rel="noopener">https://leetcode.com/problems/reverse-linked-list/</a></p><p>Reverse a singly linked list.Reverse a singly linked list.</p><p>Hint:<br>A linked list can be reversed either iteratively or recursively. Could you implement both?</p><hr><p>分析：<br><img src="http://img.blog.csdn.net/20150610095309420" alt="这里写图片描述"></p><figure class="highlight xquery"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Definition <span class="keyword">for</span> singly-linked list.</span><br><span class="line"> * struct ListNode {</span><br><span class="line"> *     int val;</span><br><span class="line"> *     ListNode *<span class="keyword">next</span>;</span><br><span class="line"> *     ListNode(int x) : val(x), <span class="keyword">next</span>(NULL) {}</span><br><span class="line"> * };</span><br><span class="line"> */</span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    ListNode* reverseList(ListNode*<span class="built_in"> head</span>) {</span><br><span class="line">        ListNode* pre = NULL;</span><br><span class="line">        <span class="keyword">if</span><span class="built_in">(head</span> == NULL ||<span class="built_in"> head</span>-&gt;<span class="keyword">next</span>==NULL) <span class="keyword">return</span><span class="built_in"> head</span>;</span><br><span class="line">    </span><br><span class="line">        pre=<span class="built_in"> head</span>-&gt;<span class="keyword">next</span>;</span><br><span class="line">    </span><br><span class="line">       <span class="built_in"> head</span>-&gt;<span class="keyword">next</span> = NULL;</span><br><span class="line">        while(pre!=NULL){</span><br><span class="line">            ListNode * nextNode = NULL;</span><br><span class="line">            nextNode = pre-&gt;<span class="keyword">next</span>;</span><br><span class="line">            pre-&gt;<span class="keyword">next</span> =<span class="built_in"> head</span>;</span><br><span class="line">           <span class="built_in"> head</span> = pre;</span><br><span class="line">            pre = nextNode;</span><br><span class="line">            <span class="keyword">delete</span> nextNode;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">delete</span> pre;</span><br><span class="line">        <span class="keyword">return</span><span class="built_in"> head</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-215-Kth-Largest-Element-in-an-Array"><a href="#Leetcode-215-Kth-Largest-Element-in-an-Array" class="headerlink" title="Leetcode[215]-Kth Largest Element in an Array"></a>Leetcode[215]-Kth Largest Element in an Array</h1><p>Link: <a href="https://leetcode.com/problems/kth-largest-element-in-an-array/" target="_blank" rel="noopener">https://leetcode.com/problems/kth-largest-element-in-an-array/</a></p><p>Find the kth largest element in an unsorted array. Note that it is the kth largest element in the sorted order, not the kth distinct element.</p><p>For example,<br>Given<code>[3,2,1,5,6,4]</code>and <code>k = 2</code>, return <code>5</code>.</p><p>Note:<br>You may assume k is always valid, 1 ≤ k ≤ array’s length.</p><p>Credits:<br>Special thanks to @mithmatt for adding this problem and creating all test cases.</p><hr><p>法一：使用STL的sort排序O(NlogN)</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">findKthLargest</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> k)</span> </span>{</span><br><span class="line">    sort(nums.<span class="built_in">begin</span>(),nums.<span class="built_in">end</span>());</span><br><span class="line">    <span class="keyword">return</span> nums[nums.<span class="built_in">size</span>()-k];</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>法二：自己写快速排序O（NlogN）</p><figure class="highlight matlab"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">int findKthLargest(vector&lt;int&gt;&amp; nums, int k){</span><br><span class="line">   </span><br><span class="line">quickSort(nums, <span class="number">0</span> ,nums.<span class="built_in">size</span>());</span><br><span class="line"><span class="keyword">return</span> nums[nums.<span class="built_in">size</span>()-k];</span><br><span class="line">   </span><br><span class="line">}</span><br><span class="line">void quickSort(vector&lt;int&gt; &amp;nums, int left, int right){</span><br><span class="line">    int <span class="built_in">i</span> = left, <span class="built_in">j</span> = right - <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">i</span> &lt; <span class="built_in">j</span>){</span><br><span class="line">        int po = nums[<span class="built_in">i</span>];</span><br><span class="line">        <span class="keyword">while</span>(<span class="built_in">i</span> &lt; <span class="built_in">j</span>){</span><br><span class="line">            <span class="keyword">while</span>(<span class="built_in">i</span> &lt; <span class="built_in">j</span> &amp;&amp; nums[<span class="built_in">j</span>] &gt;= po) <span class="built_in">j</span>--;</span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">i</span> &lt; <span class="built_in">j</span>) {</span><br><span class="line">                nums[<span class="built_in">i</span>++] = nums[<span class="built_in">j</span>];</span><br><span class="line">            }</span><br><span class="line">            <span class="keyword">while</span>(<span class="built_in">i</span> &lt; <span class="built_in">j</span> &amp;&amp; nums[<span class="built_in">i</span>] &lt;= po ) <span class="built_in">i</span>++;</span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">i</span> &lt; <span class="built_in">j</span>){</span><br><span class="line">                nums[<span class="built_in">j</span>--] = nums[<span class="built_in">i</span>];</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        nums[<span class="built_in">i</span>] = po;</span><br><span class="line">        quickSort(nums, left, <span class="built_in">i</span>);</span><br><span class="line">        quickSort(nums, <span class="built_in">i</span>+<span class="number">1</span>, right);</span><br><span class="line">        </span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>法三：使用建堆法  时间复杂度O(klogN)</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">findKthLargest</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> k)</span></span>{</span><br><span class="line">    make_heap(nums.<span class="built_in">begin</span>(), nums.<span class="built_in">end</span>());</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> i=<span class="number">0</span>; i&lt;k<span class="number">-1</span>;i++){</span><br><span class="line">        pop_heap(nums.<span class="built_in">begin</span>(), nums.<span class="built_in">end</span>());</span><br><span class="line">        nums.pop_back();</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> nums.front();</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>方法四：此方法是论坛看到的，O（N）</p><figure class="highlight stan"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> findKthLargest(<span class="keyword">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> k){</span><br><span class="line">     <span class="keyword">int</span> i, m, n, pivot, <span class="built_in">head</span> =<span class="number">0</span>, <span class="built_in">tail</span> = nums.<span class="built_in">size</span>()-<span class="number">1</span>, maxV;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>){</span><br><span class="line">        m = <span class="built_in">head</span>, n= <span class="built_in">tail</span>;</span><br><span class="line">        pivot = nums[m++];</span><br><span class="line">        <span class="keyword">while</span>(m &lt;= n) {</span><br><span class="line">            <span class="keyword">if</span>(nums[m] &gt;= pivot) m++;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(nums[n] &lt; pivot) n--;</span><br><span class="line">            <span class="keyword">else</span> {</span><br><span class="line">                swap(nums[m++], nums[n--]);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span>(m-<span class="built_in">head</span> == k) </span><br><span class="line">            <span class="keyword">return</span> pivot;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(m-<span class="built_in">head</span> &lt; k) {</span><br><span class="line">            k -= (m-<span class="built_in">head</span>); </span><br><span class="line">            <span class="built_in">head</span> = m;  </span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">else</span> {</span><br><span class="line">            <span class="built_in">tail</span> = m-<span class="number">1</span>;</span><br><span class="line">            <span class="built_in">head</span> = <span class="built_in">head</span>+<span class="number">1</span>;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-217-Contains-Duplicate"><a href="#Leetcode-217-Contains-Duplicate" class="headerlink" title="Leetcode[217]-Contains Duplicate"></a>Leetcode[217]-Contains Duplicate</h1><p>Link：<a href="https://leetcode.com/problems/contains-duplicate/" target="_blank" rel="noopener">https://leetcode.com/problems/contains-duplicate/</a></p><p>Given an array of integers, find if the array contains any duplicates. Your function should return true if any value appears at least twice in the array, and it should return false if every element is distinct.</p><hr><p>思路：先将数组排序，然后从第二个开始遍历，如果和前一个值相等，则返回true，终止；此方法时间复杂度为O（nlogn），空间复杂度为O（1）</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">containsDuplicate</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>{</span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">int</span> flag = <span class="literal">false</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">std</span>::sort(nums.<span class="built_in">begin</span>(), nums.<span class="built_in">end</span>());</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(i &lt; n){</span><br><span class="line">            <span class="keyword">if</span>(nums[i] == nums[i<span class="number">-1</span>])</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">            i++;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> flag;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p><strong>小记</strong>：自己做的时候，开始使用两个for循环遍历，结果超时了，后来使用自己写的快速排序，也超时了。最后使用了std::sort(nums.begin(), nums.end())自带的sort，结果成功了！不知道是快速排序哪里出了问题。</p><p><br><br><br>拓展：快速排序算法</p><figure class="highlight matlab"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">void quickSort(vector&lt;int&gt; &amp;nums,int low,int high){</span><br><span class="line">    int <span class="built_in">i</span>=low,<span class="built_in">j</span>=high;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">i</span> &lt; <span class="built_in">j</span>){</span><br><span class="line">        int po = nums[low];</span><br><span class="line">        <span class="keyword">while</span>(<span class="built_in">i</span> &lt; <span class="built_in">j</span>){</span><br><span class="line">            <span class="keyword">while</span>(nums[<span class="built_in">i</span>]&lt;nums[<span class="built_in">j</span>] &amp;&amp; po &lt; nums[<span class="built_in">j</span>]) <span class="built_in">j</span>--;</span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">i</span>&lt;<span class="built_in">j</span>){</span><br><span class="line">                int temp = nums[<span class="built_in">i</span>];</span><br><span class="line">                nums[<span class="built_in">i</span>] = nums[<span class="built_in">j</span>];</span><br><span class="line">                nums[<span class="built_in">j</span>] = temp;</span><br><span class="line">                <span class="built_in">i</span>++;</span><br><span class="line">            }</span><br><span class="line">            <span class="keyword">while</span>(nums[<span class="built_in">i</span>]&lt;nums[<span class="built_in">j</span>] &amp;&amp; nums[<span class="built_in">i</span>] &lt; po) <span class="built_in">i</span>++;</span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">i</span>&lt;<span class="built_in">j</span>){</span><br><span class="line">                int temp = nums[<span class="built_in">i</span>];</span><br><span class="line">                nums[<span class="built_in">i</span>] = nums[<span class="built_in">j</span>];</span><br><span class="line">                nums[<span class="built_in">j</span>] = temp;</span><br><span class="line">                <span class="built_in">j</span>--;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        quickSort(nums,low,<span class="built_in">j</span><span class="number">-1</span>);</span><br><span class="line">        quickSort(nums,<span class="built_in">j</span>+<span class="number">1</span>,high);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p><strong>Python代码</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">containsDuplicate</span><span class="params">(self, nums)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        n = len(nums)</span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">0</span> <span class="keyword">or</span> n ==<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        nums.sort()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,n):</span><br><span class="line">            <span class="keyword">if</span> nums[i] == nums[i<span class="number">-1</span>]:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-219-Contains-Duplicate-II"><a href="#Leetcode-219-Contains-Duplicate-II" class="headerlink" title="Leetcode[219]-Contains Duplicate II"></a>Leetcode[219]-Contains Duplicate II</h1><p>Link:<a href="https://leetcode.com/problems/contains-duplicate-ii/" target="_blank" rel="noopener">https://leetcode.com/problems/contains-duplicate-ii/</a></p><p>Given an array of integers and an integer k, find out whether there there are two distinct indices i and j in the array such that nums[i] = nums[j] and the difference between i and j is at most k.</p><hr><p><strong>分析</strong>：用C++中的map记录num和下标value，key值为数值，value为值在nums数组中的下标。首先遍历数组，如果在map中存在<br>【mapv.find(number) != mapv.end()】并且当前位置和map中找到的位置差小于等于k【i-mapv[number] &lt;= k】，就返回true，不然就将该值加入到map中。依次循环…</p><p>Code(c++)</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span>  </span><br><span class="line"><span class="keyword">public</span>:  </span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">containsNearbyDuplicate</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> k)</span> </span>{</span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="built_in">map</span>&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt; mapv;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++){</span><br><span class="line">            <span class="keyword">int</span> number = nums[i];</span><br><span class="line">            <span class="keyword">if</span> (mapv.<span class="built_in">find</span>(number) != mapv.<span class="built_in">end</span>() &amp;&amp; i-mapv[number] &lt;= k){</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">            }<span class="keyword">else</span>{</span><br><span class="line">                mapv[number] = i;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-222-Count-Complete-Tree-Nodes"><a href="#Leetcode-222-Count-Complete-Tree-Nodes" class="headerlink" title="Leetcode[222]-Count Complete Tree Nodes"></a>Leetcode[222]-Count Complete Tree Nodes</h1><p>Link: <a href="https://leetcode.com/problems/count-complete-tree-nodes/" target="_blank" rel="noopener">https://leetcode.com/problems/count-complete-tree-nodes/</a></p><p>Given a complete binary tree, count the number of nodes.</p><p>Definition of a complete binary tree from Wikipedia:<br>In a complete binary tree every level, except possibly the last, is completely filled, and all nodes in the last level are as far left as possible. It can have between 1 and 2h nodes inclusive at the last level h.</p><hr><p>思路：分别计算左右子树，然后返回左右字数节点个数加一</p><p>递归法：（超时了）</p><figure class="highlight zephir"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>{</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> countNodes(TreeNode* root) {</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">NULL</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> lcount=<span class="number">0</span>,rcount=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(root-&gt;left != <span class="keyword">NULL</span>){</span><br><span class="line">            lcount = countNodes(root-&gt;left);</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span>(root-&gt;right != <span class="keyword">NULL</span>){</span><br><span class="line">            rcount = countNodes(root-&gt;right);</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> lcount+rcount+<span class="number">1</span>;  </span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p>方法二：<br>先计算左右的深度是否相等，相等则为满二叉树，满二叉树的节点个数为深度的平方减一,即depth^2-1；如果不相等，则递归以同样的方式计算左子树和右子树，并返回两者个数之和加一。</p><p><strong>Code(c++):</strong></p><figure class="highlight dart"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"><span class="markdown">/**</span></span></span><br><span class="line"><span class="comment"><span class="markdown"><span class="bullet"> * </span>Definition for </span>a<span class="markdown"> binary tree node.</span></span></span><br><span class="line"><span class="comment"><span class="markdown"><span class="bullet"> * </span>struct TreeNode {</span></span></span><br><span class="line"><span class="comment"><span class="markdown"><span class="bullet"> *     </span>int val;</span></span></span><br><span class="line"><span class="comment"><span class="markdown"><span class="bullet"> *     </span>TreeNode *left;</span></span></span><br><span class="line"><span class="comment"><span class="markdown"><span class="bullet"> *     </span>TreeNode *right;</span></span></span><br><span class="line"><span class="comment"><span class="markdown"><span class="bullet"> *     </span>TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span></span></span><br><span class="line"><span class="comment"><span class="markdown"><span class="bullet"> * </span>};</span></span></span><br><span class="line"><span class="comment"><span class="markdown"> */</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>{</span><br><span class="line">public:</span><br><span class="line">    <span class="built_in">int</span> countNodes(TreeNode* root) {</span><br><span class="line">        <span class="keyword">if</span>(root == NULL) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">int</span> ldepth = getLeftDepth(root);</span><br><span class="line">        <span class="built_in">int</span> rdepth = getRightDepth(root);</span><br><span class="line">        <span class="comment">//return the square of leftdepth -1</span></span><br><span class="line">        <span class="keyword">if</span>(ldepth == rdepth) <span class="keyword">return</span> (<span class="number">1</span> &lt;&lt; ldepth) - <span class="number">1</span>;</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> countNodes(root-&gt;left)+countNodes(root-&gt;right)+<span class="number">1</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">//compute the depth of left tree</span></span><br><span class="line">    <span class="built_in">int</span> getLeftDepth(TreeNode *root){</span><br><span class="line">        <span class="built_in">int</span> depth = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(root){</span><br><span class="line">            depth++;</span><br><span class="line">            root = root-&gt;left;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> depth;</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">//compute the depth of right tree</span></span><br><span class="line">    <span class="built_in">int</span> getRightDepth(TreeNode *root){</span><br><span class="line">        <span class="built_in">int</span> depth = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(root){</span><br><span class="line">            depth++;</span><br><span class="line">            root = root-&gt;right;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> depth;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-226-Invert-Binary-Tree"><a href="#Leetcode-226-Invert-Binary-Tree" class="headerlink" title="Leetcode[226]-Invert Binary Tree"></a>Leetcode[226]-Invert Binary Tree</h1><p>Link: <a href="https://leetcode.com/problems/invert-binary-tree/" target="_blank" rel="noopener">https://leetcode.com/problems/invert-binary-tree/</a></p><p>Invert a binary tree.</p><pre><code>     4   /   \  2     7 / \   / \1   3 6   9</code></pre><p>to</p><pre><code>     4   /   \  7     2 / \   / \9   6 3   1</code></pre><p>Trivia:<br>This problem was inspired by this original tweet by Max Howell:<br>Google: 90% of our engineers use the software you wrote (Homebrew), but you can’t invert a binary tree on a whiteboard so fuck off.</p><hr><p>C++递归法求解：</p><figure class="highlight coq"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * <span class="keyword">Definition</span> <span class="keyword">for</span> a binary tree node.</span><br><span class="line"> * struct TreeNode {</span><br><span class="line"> *     int val;</span><br><span class="line"> *     TreeNode *<span class="built_in">left</span>;</span><br><span class="line"> *     TreeNode *<span class="built_in">right</span>;</span><br><span class="line"> *     TreeNode(int x) : val(x), <span class="built_in">left</span>(NULL), <span class="built_in">right</span>(NULL) {}</span><br><span class="line"> * };</span><br><span class="line"> */</span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    TreeNode* invertTree(TreeNode* root) {</span><br><span class="line">        <span class="keyword">if</span>(!root) <span class="keyword">return</span> NULL;</span><br><span class="line">        </span><br><span class="line">        invertNode(root);</span><br><span class="line">        <span class="keyword">return</span> root;</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    void invertNode(TreeNode *root){</span><br><span class="line">        <span class="keyword">if</span>(root == NULL) <span class="keyword">return</span>;</span><br><span class="line">        <span class="keyword">if</span>(!root-&gt;<span class="built_in">left</span> &amp;&amp; !root-&gt;<span class="built_in">right</span>) <span class="keyword">return</span>;</span><br><span class="line">    </span><br><span class="line">        TreeNode *tempNode=NULL;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(root-&gt;<span class="built_in">right</span>) tempNode = root-&gt;<span class="built_in">right</span>;</span><br><span class="line">        <span class="keyword">if</span>(root-&gt;<span class="built_in">left</span>){</span><br><span class="line">            root-&gt;<span class="built_in">right</span> = root-&gt;<span class="built_in">left</span>;</span><br><span class="line">            root-&gt;<span class="built_in">left</span> = tempNode;</span><br><span class="line">        }<span class="keyword">else</span>{</span><br><span class="line">            root-&gt;<span class="built_in">left</span> = tempNode;</span><br><span class="line">            root-&gt;<span class="built_in">right</span> = NULL;</span><br><span class="line">        }</span><br><span class="line">        invertNode(root-&gt;<span class="built_in">left</span>);</span><br><span class="line">        invertNode(root-&gt;<span class="built_in">right</span>);</span><br><span class="line">    </span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-231-Power-of-Two"><a href="#Leetcode-231-Power-of-Two" class="headerlink" title="Leetcode[231]-Power of Two"></a>Leetcode[231]-Power of Two</h1><p>Link:<a href="https://leetcode.com/problems/power-of-two/" target="_blank" rel="noopener">https://leetcode.com/problems/power-of-two/</a></p><p>Given an integer, write a function to determine if it is a power of two.</p><hr><p>分析：</p><ul><li>如果n小于0，返回false；</li><li>如果n等于1或者等于2，返回true；</li><li>当n大于2时，根据n大于2的条件进行递归，，如果n%2不为0则直接返回false，否则将n/2赋值给n<ul><li>如果循环结束后还没有返回false，则返回true。</li></ul></li></ul><p>C++:</p><figure class="highlight kotlin"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>{</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    bool isPowerOfTwo(int n) {</span><br><span class="line">        <span class="keyword">if</span>(n&lt;=<span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">if</span> (n==<span class="number">2</span>||n==<span class="number">1</span>) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">while</span>(n&gt;<span class="number">2</span>){</span><br><span class="line">            <span class="keyword">if</span>(n%<span class="number">2</span>!=<span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            n/=<span class="number">2</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-237-Delete-Node-in-a-Linked-List"><a href="#Leetcode-237-Delete-Node-in-a-Linked-List" class="headerlink" title="Leetcode[237]-Delete Node in a Linked List"></a>Leetcode[237]-Delete Node in a Linked List</h1><p>Link:<a href="https://leetcode.com/problems/delete-node-in-a-linked-list/" target="_blank" rel="noopener">https://leetcode.com/problems/delete-node-in-a-linked-list/</a></p><p>Write a function to delete a node (except the tail) in a singly linked list, given only access to that node.</p><p>Supposed the linked list is 1 -&gt; 2 -&gt; 3 -&gt; 4 and you are given the third node with value 3, the linked list should become 1 -&gt; 2 -&gt; 4 after calling your function.</p><p>Subscribe to see which companies asked this question</p><hr><p>比较简单，直接给出答案</p><figure class="highlight crmsh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Definition for singly-linked list.</span><br><span class="line"> * struct ListNode {</span><br><span class="line"> *     int val;</span><br><span class="line"> *     ListNode *next;</span><br><span class="line"> *     ListNode(int x) : val(x), next(NULL) {}</span><br><span class="line"> * };</span><br><span class="line"> */</span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    void deleteNode(ListNode* <span class="keyword">node</span><span class="title">) {</span></span><br><span class="line"><span class="title">        if</span>(<span class="keyword">node</span> <span class="title">== NULL</span>) return;</span><br><span class="line">        ListNode *tmp = <span class="keyword">node</span><span class="title">-&gt;next</span>;</span><br><span class="line">        <span class="keyword">node</span><span class="title">-&gt;val</span> = tmp-&gt;val;</span><br><span class="line">        <span class="keyword">node</span><span class="title">-&gt;next</span> = tmp-&gt;next;</span><br><span class="line">        delete tmp;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-242-Valid-Anagram"><a href="#Leetcode-242-Valid-Anagram" class="headerlink" title="Leetcode[242]-Valid Anagram"></a>Leetcode[242]-Valid Anagram</h1><p>Link:<a href="https://leetcode.com/problems/valid-anagram/" target="_blank" rel="noopener">https://leetcode.com/problems/valid-anagram/</a></p><p>Given two strings s and t, write a function to determine if t is an anagram of s.</p><p>For example,<br>s = “anagram”, t = “nagaram”, return true.<br>s = “rat”, t = “car”, return false.</p><p>Note:<br>You may assume the string contains only lowercase alphabets.</p><hr><p>思路：这道题，思路比较简单，将s中字符串的单词个数映射到26个子母中，然后遍历t，出现一个字母，就将该字母数减1，最后判断是否全为0即可。</p><p>Python代码比较简单，就给出Python代码吧：</p><p>Python：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isAnagram</span><span class="params">(self, s, t)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type s: str</span></span><br><span class="line"><span class="string">        :type t: str</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> len(s) != len(t):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        word = [<span class="number">0</span>]*<span class="number">26</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(s)):</span><br><span class="line">            index1 = ord(s[i])<span class="number">-97</span></span><br><span class="line">            index2 = ord(t[i])<span class="number">-97</span></span><br><span class="line">            word[index1] += <span class="number">1</span></span><br><span class="line">            word[index2] -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">not</span> any(word)</span><br></pre></td></tr></tbody></table></figure><p>附加C++:</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isAnagram</span><span class="params">(<span class="built_in">string</span> s, <span class="built_in">string</span> t)</span> </span>{</span><br><span class="line">        <span class="keyword">if</span>(s.length()!=t.length())<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">int</span> <span class="keyword">word</span>[<span class="number">26</span>];</span><br><span class="line">        <span class="built_in">memset</span>(<span class="keyword">word</span>, <span class="number">0</span>, <span class="keyword">sizeof</span>(<span class="keyword">word</span>));</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;s.length();i++){</span><br><span class="line">            <span class="keyword">int</span> index1 = s[i]-<span class="string">'a'</span>;</span><br><span class="line">            <span class="keyword">int</span> index2 = t[i]-<span class="string">'a'</span>;</span><br><span class="line">            <span class="keyword">word</span>[index1]+=<span class="number">1</span>;</span><br><span class="line">            <span class="keyword">word</span>[index2]-=<span class="number">1</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">int</span> c=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(c&lt;<span class="number">26</span>){</span><br><span class="line">            <span class="keyword">if</span>(<span class="keyword">word</span>[c++]!=<span class="number">0</span>)<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p>学习心得：有关字符串的题目，可以考虑将其映射到字母表中。</p><hr><h1 id="Leetcode-258-Add-Digits"><a href="#Leetcode-258-Add-Digits" class="headerlink" title="Leetcode[258]-Add Digits"></a>Leetcode[258]-Add Digits</h1><p>Link: <a href="https://leetcode.com/problems/add-digits/" target="_blank" rel="noopener">https://leetcode.com/problems/add-digits/</a></p><p>Given a non-negative integer num, repeatedly add all its digits until the result has only one digit.</p><p>For example:</p><p>Given num = 38, the process is like: 3 + 8 = 11, 1 + 1 = 2. Since 2 has only one digit, return it.</p><p>Follow up:<br>Could you do it without any loop/recursion in O(1) runtime?</p><hr><p>思路：此题和202题有点类似，可以参考。主要是在各个位数的想加上，有点技巧。</p><p>C++</p><figure class="highlight excel"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">publ<span class="symbol">ic:</span></span><br><span class="line">    <span class="built_in">int</span> addDigits(<span class="built_in">int</span> num) {</span><br><span class="line">        <span class="built_in">int</span> <span class="built_in">n</span>=num;</span><br><span class="line">        while(<span class="built_in">n</span>&gt;=<span class="number">10</span>){</span><br><span class="line">            <span class="built_in">int</span> i = <span class="number">0</span>;</span><br><span class="line">            while(<span class="built_in">n</span>&gt;<span class="number">0</span>){</span><br><span class="line">                i += <span class="built_in">n</span>%<span class="number">10</span>;</span><br><span class="line">                <span class="built_in">n</span> = <span class="built_in">n</span>/<span class="number">10</span>;</span><br><span class="line">            };</span><br><span class="line">            <span class="built_in">n</span> = i;</span><br><span class="line">        }</span><br><span class="line">        return <span class="built_in">n</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-260-Single-Number-III"><a href="#Leetcode-260-Single-Number-III" class="headerlink" title="Leetcode[260]-Single Number III"></a>Leetcode[260]-Single Number III</h1><p>Link: <a href="https://leetcode.com/problems/single-number-iii/" target="_blank" rel="noopener">https://leetcode.com/problems/single-number-iii/</a></p><p>Given an array of numbers nums, in which exactly two elements appear only once and all the other elements appear exactly twice. Find the two elements that appear only once.</p><p>For example:</p><p>Given nums = [1, 2, 1, 3, 2, 5], return [3, 5].</p><p>Note:<br>The order of the result is not important. So in the above example, [5, 3] is also correct.<br>Your algorithm should run in linear runtime complexity. Could you implement it using only constant space complexity?</p><hr><p>思路：首先对数组进行排序，然后一对一对的进行比较，如果两个相等，则以步长为2往后移动，如果不相等，则将当前的值加入到返回变量中，然后以步长为1往后移动。</p><p>C++:</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">singleNumber</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>{</span><br><span class="line">        sort(nums.<span class="built_in">begin</span>(),nums.<span class="built_in">end</span>());</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; res;</span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(i&lt;n<span class="number">-1</span>){</span><br><span class="line">            <span class="keyword">if</span>(nums[i]==nums[i+<span class="number">1</span>]){</span><br><span class="line">                i+=<span class="number">2</span>;</span><br><span class="line">            }<span class="keyword">else</span>{</span><br><span class="line">                res.push_back(nums[i]);</span><br><span class="line">                i+=<span class="number">1</span>;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span>(nums[n<span class="number">-1</span>]!=nums[n<span class="number">-2</span>]){</span><br><span class="line">            res.push_back(nums[n<span class="number">-1</span>]);</span><br><span class="line">        }</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-263-Ugly-Number"><a href="#Leetcode-263-Ugly-Number" class="headerlink" title="Leetcode[263]-Ugly Number++"></a>Leetcode[263]-Ugly Number++</h1><p>Link:<a href="https://leetcode.com/problems/ugly-number/" target="_blank" rel="noopener">https://leetcode.com/problems/ugly-number/</a></p><p>Write a program to check whether a given number is an ugly number.</p><p>Ugly numbers are positive numbers whose prime factors only include 2, 3, 5. For example, 6, 8 are ugly while 14 is not ugly since it includes another prime factor 7.</p><p>Note that 1 is typically treated as an ugly number.</p><hr><figure class="highlight dart"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>{</span><br><span class="line">public:</span><br><span class="line">    <span class="built_in">bool</span> isUgly(<span class="built_in">int</span> <span class="built_in">num</span>) {</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">num</span> == <span class="number">0</span>) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">num</span> == <span class="number">1</span>) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">int</span> pfactor[] = { <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span> };</span><br><span class="line">        <span class="keyword">for</span> (auto val : pfactor) {</span><br><span class="line">            <span class="keyword">while</span> (<span class="built_in">num</span> % val == <span class="number">0</span>) { <span class="built_in">num</span> /= val; }</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">num</span> == <span class="number">1</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-283-Move-Zeroes"><a href="#Leetcode-283-Move-Zeroes" class="headerlink" title="Leetcode[283]-Move Zeroes"></a>Leetcode[283]-Move Zeroes</h1><p>Link:<a href="https://leetcode.com/problems/move-zeroes/" target="_blank" rel="noopener">https://leetcode.com/problems/move-zeroes/</a></p><p>Given an array nums, write a function to move all 0’s to the end of it while maintaining the relative order of the non-zero elements.</p><p>For example, given nums = [0, 1, 0, 3, 12], after calling your function, nums should be [1, 3, 12, 0, 0].</p><p>Note:</p><ul><li>You must do this in-place without making a copy of the array.</li><li>Minimize the total number of operations.</li></ul><hr><p>C++代码：</p><figure class="highlight matlab"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    void moveZeroes(vector&lt;int&gt;&amp; nums) {</span><br><span class="line">        int n=nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">if</span> (n==<span class="number">0</span> || n==<span class="number">1</span>) <span class="keyword">return</span>;</span><br><span class="line">        int <span class="built_in">i</span>=<span class="number">0</span>,s = n<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">while</span>(<span class="built_in">i</span>&lt;=s){</span><br><span class="line">            <span class="keyword">if</span>(nums[<span class="built_in">i</span>]==<span class="number">0</span>){</span><br><span class="line">                <span class="keyword">for</span>(int <span class="built_in">j</span> = <span class="built_in">i</span>; <span class="built_in">j</span>&lt;s; <span class="built_in">j</span>++){</span><br><span class="line">                    nums[<span class="built_in">j</span>] = nums[<span class="built_in">j</span>+<span class="number">1</span>];</span><br><span class="line">                }</span><br><span class="line">                nums[s]=<span class="number">0</span>;</span><br><span class="line">                s = s<span class="number">-1</span>;</span><br><span class="line">            }<span class="keyword">else</span>{</span><br><span class="line">                <span class="built_in">i</span>=<span class="built_in">i</span>+<span class="number">1</span>;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-292-Nim-Game"><a href="#Leetcode-292-Nim-Game" class="headerlink" title="Leetcode[292]-Nim Game"></a>Leetcode[292]-Nim Game</h1><p>Link:<a href="https://leetcode.com/problems/nim-game/" target="_blank" rel="noopener">https://leetcode.com/problems/nim-game/</a></p><p>You are playing the following Nim Game with your friend: There is a heap of stones on the table, each time one of you take turns to remove 1 to 3 stones. The one who removes the last stone will be the winner. You will take the first turn to remove the stones.</p><p>Both of you are very clever and have optimal strategies for the game. Write a function to determine whether you can win the game given the number of stones in the heap.</p><p>For example, if there are 4 stones in the heap, then you will never win the game: no matter 1, 2, or 3 stones you remove, the last stone will always be removed by your friend.</p><hr><p>分析：经过分析之后发现，有以下规律：</p><ul><li>如果n小于4，返回true；</li><li>如果n%4==0，返回false；</li><li>否则，返回true。</li></ul><p>C++:</p><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">canWinNim</span><span class="params">(<span class="keyword">int</span> n)</span> </span>{</span><br><span class="line">        <span class="keyword">if</span>(n&lt;=<span class="number">3</span>) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">if</span>(n%<span class="number">4</span>==<span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p>Python：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">canWinNim</span><span class="params">(self, n)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type n: int</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> n&lt;<span class="number">4</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span>;</span><br><span class="line">        <span class="keyword">if</span> n%<span class="number">4</span>==<span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span>;</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="Leetcode-300-Longest-Increasing-Subsequence"><a href="#Leetcode-300-Longest-Increasing-Subsequence" class="headerlink" title="Leetcode[300]-Longest Increasing Subsequence"></a>Leetcode[300]-Longest Increasing Subsequence</h1><p>Link：<a href="https://leetcode.com/problems/longest-increasing-subsequence/" target="_blank" rel="noopener">https://leetcode.com/problems/longest-increasing-subsequence/</a></p><p>Given an unsorted array of integers, find the length of longest increasing subsequence.</p><p>For example,<br>Given <code>[10, 9, 2, 5, 3, 7, 101, 18]</code>,<br>The longest increasing subsequence is <code>[2, 3, 7, 101]</code>, therefore the length is <code>4</code>. Note that there may be more than one LIS combination, it is only necessary for you to return the length.</p><p>Your algorithm should run in O(n2) complexity.</p><p>Follow up: Could you improve it to O(n log n) time complexity?</p><hr><p>这道题和最长连续子序列有些区别，它不限制【连续】这个条件，只要递增即可。</p><p>思路：定义一个长度为n的int类型一维数组dp[n]，dp[i]用来表示第i个位置上的最长递增子序列长度。dp[i]的计算过程如下：</p><ul><li>初始化dp[0]=1；</li><li>当i&gt;0时，设置一个变量max_dp，初始值为1,记录的是以当前位置结尾时的最长递增子序列长度。通过循环遍历前面的i-1个数，如果位置i的数大于前面位置j的数，就比较max_dp和dp[j]+1,将大的值赋值给max_dp，最后将max_dp赋值给dp[i]；</li><li>最后，遍历dp[n]，找出最大的值，即为最长递增子序列的长度。</li></ul><p>C++代码：</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> {</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">lengthOfLIS</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>{</span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">if</span>(n==<span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">dp</span><span class="params">(n)</span></span>;</span><br><span class="line">        dp[<span class="number">0</span>]=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;n; i++){</span><br><span class="line">            <span class="keyword">int</span> j=i<span class="number">-1</span>,max_dp=<span class="number">1</span>;            </span><br><span class="line">            <span class="keyword">while</span>(j&gt;=<span class="number">0</span>){</span><br><span class="line">                <span class="keyword">if</span>(nums[j]&lt;nums[i]){</span><br><span class="line">                    max_dp=(max_dp&gt;(dp[j]+<span class="number">1</span>)?max_dp:(dp[j]+<span class="number">1</span>));</span><br><span class="line">                }</span><br><span class="line">                --j;</span><br><span class="line">            }</span><br><span class="line">            dp[i]=max_dp;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">int</span> <span class="built_in">max</span>=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> k=<span class="number">0</span>;k&lt;n;k++){</span><br><span class="line">            <span class="built_in">max</span>=(<span class="built_in">max</span>&gt;dp[k]?<span class="built_in">max</span>:dp[k]);</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是先前做LeetCode时的部分题解，有的题目既包含C++代码，也有Python代码，为方便查阅，决定将这些思路合并到一文之中。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/assets/articleImg/2015-12-12-leetcode.png&quot; alt=&quot;leetcode&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="算法与数据结构" scheme="https://www.csuldw.com/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
      <category term="数据结构" scheme="https://www.csuldw.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
      <category term="LeetCode" scheme="https://www.csuldw.com/tags/LeetCode/"/>
    
  </entry>
  
  <entry>
    <title>Python笔记-几种取整方式</title>
    <link href="https://www.csuldw.com/2015/12/04/2015-12-04-Python-Round/"/>
    <id>https://www.csuldw.com/2015/12/04/2015-12-04-Python-Round/</id>
    <published>2015-12-04T04:12:00.000Z</published>
    <updated>2016-03-08T09:02:36.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>　　在处理数据的时候，碰到了一个问题，就是取整方式！比如给定一个数值型列表，我需要分别获取它位置为长度的0%,25%,50%,75%,100%处的几个数字。但Python自带的<code>int</code>是向下取整，如果数字长度是5，理论上这五个数字分别对应0%,25%,50%,75%,100%的位置，但使用<code>int</code>，结果却并不是入次。比如当<code>5*0.75</code>时,如果加上<code>int(5*0.75)</code>，就等于<code>3</code>，而我想要的应该是4，显然不是我想要的，所以这里需要用到向上取整方式。因此，顺便总结了一下Python的几种取整方式。</p><a id="more"></a><h2 id="取整方式"><a href="#取整方式" class="headerlink" title="取整方式"></a>取整方式</h2><p>　　下面介绍几种常用的取整方法，包括向下取整、四舍五入、向上取整。</p><h3 id="（1）向下取整"><a href="#（1）向下取整" class="headerlink" title="（1）向下取整"></a>（1）向下取整</h3><p>　　向下取整很简单，直接使用int()函数即可，如下代码(Python 2.7.5 IDLE)</p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; a = <span class="number">3.75</span></span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; int(a)</span><br><span class="line"><span class="number">3</span></span><br></pre></td></tr></tbody></table></figure><h3 id="（2）四舍五入"><a href="#（2）四舍五入" class="headerlink" title="（2）四舍五入"></a>（2）四舍五入</h3><p>　　第二种就是对数字进行四舍五入，具体的看下面的代码：</p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; a=<span class="number">3.25</span>;b=<span class="number">3.75</span></span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; round(a);round(b)</span><br><span class="line"><span class="number">3.0</span></span><br><span class="line"><span class="number">4.0</span></span><br></pre></td></tr></tbody></table></figure><h2 id="（3-向上取整"><a href="#（3-向上取整" class="headerlink" title="（3)向上取整"></a>（3)向上取整</h2><p>　　但三种，就是向上取整，也就是我这次数据处理中需要的，由于之前没在Python中用到过，所以不太熟悉，其实Python的math中就带了向上取整的函数，即<code>ceil</code>方法，专门用于向上取整，实例如下：</p><figure class="highlight css"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; <span class="selector-tag">import</span> <span class="selector-tag">math</span></span><br><span class="line">&gt;&gt;&gt; <span class="selector-tag">math</span><span class="selector-class">.ceil</span>(3<span class="selector-class">.25</span>)</span><br><span class="line">4<span class="selector-class">.0</span></span><br><span class="line">&gt;&gt;&gt; <span class="selector-tag">math</span><span class="selector-class">.ceil</span>(3<span class="selector-class">.75</span>)</span><br><span class="line">4<span class="selector-class">.0</span></span><br></pre></td></tr></tbody></table></figure><p>好了，取整方式，大概就是这三种，介绍到此吧！</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;　　在处理数据的时候，碰到了一个问题，就是取整方式！比如给定一个数值型列表，我需要分别获取它位置为长度的0%,25%,50%,75%,100%处的几个数字。但Python自带的&lt;code&gt;int&lt;/code&gt;是向下取整，如果数字长度是5，理论上这五个数字分别对应0%,25%,50%,75%,100%的位置，但使用&lt;code&gt;int&lt;/code&gt;，结果却并不是入次。比如当&lt;code&gt;5*0.75&lt;/code&gt;时,如果加上&lt;code&gt;int(5*0.75)&lt;/code&gt;，就等于&lt;code&gt;3&lt;/code&gt;，而我想要的应该是4，显然不是我想要的，所以这里需要用到向上取整方式。因此，顺便总结了一下Python的几种取整方式。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://www.csuldw.com/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.csuldw.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python笔记-均值列表</title>
    <link href="https://www.csuldw.com/2015/12/04/2015-12-04-Python-two-list-add-item-add-item/"/>
    <id>https://www.csuldw.com/2015/12/04/2015-12-04-Python-two-list-add-item-add-item/</id>
    <published>2015-12-04T01:03:00.000Z</published>
    <updated>2016-03-13T05:54:06.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>一个小小的实例，做个小笔记！</p><p>比如有三个列表，列表元素均为数值型，三个列表的长度都一样，现在我想要求这三个列表的均值，即求一个均值列表，对应元素为上述三个列表对应元素的均值。</p><a id="more"></a><p>代码实现如下：</p><figure class="highlight livecodeserver"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def meanMethod(<span class="literal">one</span>,<span class="literal">two</span>,<span class="literal">three</span>):</span><br><span class="line">    comb = zip(<span class="literal">one</span>,<span class="literal">two</span>,<span class="literal">three</span>)</span><br><span class="line">    <span class="literal">return</span> [float(i+j+k)/<span class="number">3</span> <span class="keyword">for</span> i,j,k <span class="keyword">in</span> comb]</span><br></pre></td></tr></tbody></table></figure><p>第二行使用的是zip函数，先将三个列表合并起来，zip函数返回的是一个列表，但里面的元素是一个元组。</p><p>第三行是列表推导式，计算comb每个元组的均值。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一个小小的实例，做个小笔记！&lt;/p&gt;
&lt;p&gt;比如有三个列表，列表元素均为数值型，三个列表的长度都一样，现在我想要求这三个列表的均值，即求一个均值列表，对应元素为上述三个列表对应元素的均值。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://www.csuldw.com/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.csuldw.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>EM-最大期望算法</title>
    <link href="https://www.csuldw.com/2015/12/02/2015-12-02-EM-algorithms/"/>
    <id>https://www.csuldw.com/2015/12/02/2015-12-02-EM-algorithms/</id>
    <published>2015-12-02T02:24:00.000Z</published>
    <updated>2019-04-11T15:44:02.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>对于EM算法，一直都是云里雾里。所以，今天索性就下个决定，不搞懂它，决不罢休。通过今天的学习，加上之前的基础，EM算法终于算是理清思绪了。回头想想，果真是如何做事不下定决心，真的很难有结果。下面，打算将EM算法的整个推导过程总结一遍，达到理解并掌握的目的。</p><a id="more"></a><p>首先来看一张EM算法的聚类图，来自wikipedia，效果比较直观。</p><p><img src="http://www.csuldw.com/assets/articleImg/2015-12-02-EM_Clustering_of_Old_Faithful_data.gif" alt=""></p><p>期望最大算法是一种从不完全数据或有数据丢失的数据集（存在隐含变量）中求解概率模型参数的最大似然估计方法。EM算法是机器学习十大算法之一，或许确实是因它在实际中的效果很好吧。下面先来说说它的定义。</p><h2 id="一、定义"><a href="#一、定义" class="headerlink" title="一、定义"></a>一、定义</h2><p>EM算法，全称Expectation Maximization Algorithm，译作最大期望化算法或期望最大算法，它是一种迭代算法，用于含有隐变量（hidden variable）的概率参数模型的最大似然估计或极大后验概率估计。</p><h2 id="二、Jensen不等式"><a href="#二、Jensen不等式" class="headerlink" title="二、Jensen不等式"></a>二、Jensen不等式</h2><p>在完善EM算法之前，首先来了解下Jensen不等式，因为在EM算法的推导过程中会用到。</p><p>Jensen不等式在优化理论中大量用到，首先来回顾下凸函数和凹函数的定义。假设f是定义域为实数的函数，如果对于所有的x，f(x)的二阶导数大于等于0，那么f是凸函数。当x是向量时，如果hessian矩阵H是半正定（即H&gt;=0），那么f是凸函数。如果，f(x)的二阶导数小于0或者H&gt;0，那么f就是凹函数。</p><p>Jensen不等式描述如下：</p><ul><li>如果$f$是凸函数，$X$是随机变量，则$E[f(X)]&gt;=f(E[X])$，当$f$是严格凸函数时，则$E[f(X)]&gt;f(E[X])$；</li><li>如果$f$是凹函数，$X$是随机变量，则$f(E[X])&lt;=E[f(X)]$，当$f$是（严格）凹函数当且仅当$-f$是（严格）凸函数。</li></ul><p>通过下面这张图，可以加深印象：</p><p><img src="http://www.csuldw.com/assets/articleImg/2015-12-02-Jensen-inequality.png" alt=""></p><p>上图中，函数$f$是凸函数，$X$是随机变量，有0.5的概率是$a$，有0.5的概率是$b$。X的期望值$E(x)$就是a和b的中值$\frac{a+b}{2}$了，图中可以看到E[f(X)]&gt;=f(E[X])成立。</p><h2 id="三、EM思想"><a href="#三、EM思想" class="headerlink" title="三、EM思想"></a>三、EM思想</h2><p>EM算法推导过程中，会使用到极大似然估计法估计参数，所以，首先给出一个求最大似然函数估计值的一般步骤：</p><ul><li>（1）写出似然函数；</li><li>（2）对似然函数取对数，并整理；</li><li>（3）求导数，令导数为0，得到似然方程；</li><li>（4）解似然方程，得到的参数即为所求；</li></ul><p>关于极大似然估计的实例，这里就不再提及了，下面介绍EM算法。</p><p>给定m个训练样本{$x^{(1)},…,x^{(m)}$},假设样本间相互独立，我们想要拟合模型$p(x ,z)$到数据的参数。根据分布，我们可以得到如下这个似然函数：</p><p><img src="http://www.csuldw.com/assets/articleImg/2015-12-02-gs1.png" alt=""></p><p>第一步是对极大似然函数取对数，第二步是对每个样本实例的每个可能的类别$z$求联合分布概率之和。然而，直接求这个参数$\theta$会比较困难，因为上式存在一个隐含随机变量（latent random variable）$z$。如果$z$是个已知的数，那么使用极大似然估计来估算会很容易。在这种$z$不确定的情形下，EM算法就派上用场了。</p><p>EM算法是常用的估计参数隐变量的利器。对于上述情况，由于存在隐含变量，不能直接最大化$l(\theta)$，所以只能不断地建立$l$的下界（E-step），再优化下界（M-step），依次迭代，直至算法收敛到局部最优解。这就是EM算法的核心思想，简单的归纳一下：</p><blockquote><p><strong>EM算法通过引入隐含变量,使用MLE（极大似然估计）进行迭代求解参数</strong>。通常引入隐含变量后会有两个参数，EM算法首先会固定其中的第一个参数，然后使用MLE计算第二个变量值；接着通过固定第二个变量，再使用MLE估测第一个变量值，依次迭代，直至收敛到局部最优解。</p></blockquote><p>E-Step和M-Step。</p><ul><li>E-Step：通过observed data和现有模型估计参数估计值 missing data；</li><li>M-Step：假设missing data已知的情况下，最大化似然函数。</li></ul><p>是否会收敛：<strong>由于算法保证了每次迭代之后，似然函数都会增加，所以函数最终会收敛(最后有推到)</strong>。</p><h2 id="四、EM推导"><a href="#四、EM推导" class="headerlink" title="四、EM推导"></a>四、EM推导</h2><p>下面来推导EM算法：</p><p>对于每个实例$i$,用$Q_{i}$表示样本实例隐含变量$z$的某种分布，且$Q_i$满足条件（$\sum_zQ_i(z)=1,Q_i(z)&gt;=0$） ,如果$Q_i$是连续性的，则$Q_i$表示概率密度函数，需要将求和符号换成积分符号。</p><p>对于上面的式子，做如下变换：</p><p><img src="http://www.csuldw.com/assets/articleImg/2015-12-02-gs2.png" alt=""></p><p>上面三个式子中，式（1）是根据联合概率密度下某个变量的边缘密度函数求解的（这里把z当作是随机变量）。对每一个样本i的所有可能类别$z$求等式右边的联合概率密度函数和，也就得到等式左边为随机变量x的边缘概率密度。由于对式（1）直接求导非常困难，所以将其分子分母都乘以一个相等的函数$Q_{i}(z^{(i)})$，转换为式（2）。而在式（2）变为式（3）的过程，采用的是上面提到的<strong><a href="http://www.csuldw.com/2015/12/02/2015-12-02-EM-algorithms/#二、Jensen不等式">Jensen不等式</a></strong>。分析过程如下：</p><p>首先，把（1）式中的log函数体看成是一个整体，由于log(x)的二阶导数为$-\frac{1}{x^2}$,小于0，为凹函数。所以使用Jensen不等式时，应用第二条准则：<strong>f(E[X])&gt;=E[f(x)]</strong>。</p><p>到这里，问题简化为如何求解随机变量的期望。还记得当年读大学的时候，概率论中的随机变量的期望计算方法么，不记得也没关系，下面这张图比较详细：</p><p><img src="http://www.csuldw.com/assets/articleImg/2015-12-02-p2.png" alt=""></p><p>因此，结合上面的知识点，我们可以把(2)式当中的$Q_i(z^{(i)})$看成相应的概率$p_i$，把$\frac{p(x^{i},z^{(i)};\theta)}{Q_i(z^{(i)})}$看作是$z^{(i)}$的函数$g(z)$，类似地，根据期望公式$E(x)=\sum x*p(x)$可以得到：</p><p><img src="http://www.csuldw.com/assets/articleImg/2015-12-02-gs3.png" alt=""></p><p>其实就是$\frac{p(x^{i},z^{(i)};\theta)}{Q_i(z^{(i)})}$的期望，再根据凹函数对应的Jensen不等式性质：</p><p><img src="http://www.csuldw.com/assets/articleImg/2015-12-02-gs4.png" alt=""></p><p>因此便得到了公式（3）。OK，现在我们知道上面的式（2）和式（3）两个不等式可以写成：似然函数$L(θ)&gt;=J(z,Q)$的形式（$z$为隐含变量），那么我们可以通过不断的最大化$J$的下界，来使得$L(θ)$不断提高，最终达到它的最大值。使用下图会比较形象：</p><p><img src="http://www.csuldw.com/assets/articleImg/2015-12-02-p3.png" alt=""></p><p>这里来说说上图的内在含义：<font color="#1986c7"><strong>首先我们固定θ，调整Q(z)使下界J(z,Q)上升至与L(θ)在此点θ处相等（绿色曲线到蓝色曲线），然后固定Q(z)，调整θ使下界J(z,Q)达到最大值（θt到θt+1），然后再固定θ，调整Q(z)……直到收敛到似然函数L(θ)的最大值处的θ</strong></font>。</p><p>这里有两个问题：</p><ol><li>什么时候下界J(z,Q)与L(θ)在此点θ处相等？</li><li>为什么一定会收敛？</li></ol><p>首先来解释下第一个问题（<del><font color="red">1.什么时候下界J(z,Q)与L(θ)在此点θ处相等？</font></del>）。在Jensen不等式中说到，当自变量X=E(X)时，即为常数的时候，等式成立。而在这里，为：</p><p><img src="http://www.csuldw.com/assets/articleImg/2015-12-02-gs5.png" alt=""></p><p>对该式做个变换，并对所有的$z$求和，得到</p><p>$$\sum_z{p(x^{i},z^{(i)};\theta)}=\sum_z{Q_i(z^{(i)})}c$$</p><p>因为前面提到$\sum_zQ_i(z)=1$（概率之和为1），所以可以推导出：</p><p>$$\sum_z{p(x^{i},z^{(i)};\theta)}=c$$</p><p>因此也就可以得到下面的式子：</p><p><img src="http://www.csuldw.com/assets/articleImg/2015-12-02-gs6.png" alt=""></p><p>至此，我们推出了在固定参数$\theta$后，使下界拉升的$Q(z)$的计算公式就是后验概率（条件概率），一并解决了$Q(z)$如何选择的问题。此步就是EM算法的E-step，目的是建立$L(\theta)$的下界。接下来的M-step，目的是在给定$Q(z)$后，调整$\theta$，从而极大化$L(\theta)$的下界$J$（在固定$Q(z)$后，下界还可以调整的更大）。到此，可以说是完美的展现了EM算法的E-step &amp; M-step，完整的流程如下：</p><p>第一步，初始化分布参数$\theta$；<br>第二步，重复E-step 和 M-step直到收敛：</p><ul><li>E步骤：根据参数的初始值或上一次迭代的模型参数来计算出的隐性变量的后验概率（条件概率），其实就是隐性变量的期望值。作为隐藏变量的现有估计值：</li></ul><p><img src="http://www.csuldw.com/assets/articleImg/2015-12-02-gs7.png" alt=""></p><ul><li>M步骤：最大化似然函数从而获得新的参数值：</li></ul><p><img src="http://www.csuldw.com/assets/articleImg/2015-12-02-gs8.png" alt=""></p><p>通过不断的迭代，然后就可以得到使似然函数L(θ)最大化的参数θ了。</p><p>上面多次说到直至函数收敛，那么该怎么确保EM收敛呢？(<font color="red"><del>②为什么一定会收敛？</del></font>)，下面进入证明阶段.</p><p>假定$\theta^{(t)}$和$\theta^{(t+1)}$是EM第t次和t+1次迭代后的结果。如果我们证明了$l(\theta^{(t)})&lt;=l(\theta^{(t+1)})$，也就是说极大似然估计单调增加，那么最终我们就会得到极大似然估计的最大值。下面来证明，选定$\theta^{(t)}$之后，我们得到E步：</p><p><img src="http://www.csuldw.com/assets/articleImg/2015-12-02-gs9.png" alt=""></p><p>这一步保证了在给定$\theta^{(t)}$时，Jensen不等式中的等式成立，也就是</p><p><img src="http://www.csuldw.com/assets/articleImg/2015-12-02-gs10.png" alt=""></p><p>然后进行M步，固定$Q_i^{(t)}(z^{(i)})$,并将$\theta^{(t)}$试作变量，对上面的式子求导，得到$\theta^{(t+1)}$,这样经过一些推导会有以下式子成立：</p><p><img src="http://www.csuldw.com/assets/articleImg/2015-12-02-gs11.png" alt=""></p><p>在公式（4）中，得到$\theta^{(t+1)}$,只是最大化$l(\theta^{(t)})$，也就是$l(\theta^{(t+1)})$的下界，并没有使等式成立，等式成立只有在固定$\theta$，并按E步得到$Q_i$时才能成立。</p><p>这样就证明了$l(\theta)$会单调增加。如果要判断收敛情况，可以这样来做：<font color="#1986C7"><strong>一种收敛方法是$l(\theta)$不再变化，还有一种就是变化幅度很小,即根据$l(\theta)^{(t+1)}-l(\theta)^{(t)}$的值来决定</strong></font>。</p><p>EM算法类似于坐标上生法（coordinate ascent）：E步：固定θ，优化Q；M步：固定Q，优化θ；交替将极值推向最大。</p><h2 id="五、应用"><a href="#五、应用" class="headerlink" title="五、应用"></a>五、应用</h2><ul><li><a href="http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006924.html" target="_blank" rel="noopener">混合高斯模型（Mixtures of Gaussians）</a></li><li><a href="http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006910.html" target="_blank" rel="noopener">K-means聚类算法</a></li></ul><h2 id="六、References"><a href="#六、References" class="headerlink" title="六、References"></a>六、References</h2><ul><li><a href="http://cs229.stanford.edu/notes/cs229-notes8.pdf" target="_blank" rel="noopener">http://cs229.stanford.edu/notes/cs229-notes8.pdf</a></li><li><a href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm" target="_blank" rel="noopener">wikipedia维基百科:https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm</a></li><li><a href="http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006936.html" target="_blank" rel="noopener">JerryLead博客-（EM算法）The EM Algorithm</a></li><li><a href="http://blog.csdn.net/zouxy09/article/details/8537620" target="_blank" rel="noopener">从最大似然到EM算法浅解</a></li><li><a href="http://blog.csdn.net/abcjennifer/article/details/8170378" target="_blank" rel="noopener">Rachel Zhang-EM算法原理</a></li></ul><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对于EM算法，一直都是云里雾里。所以，今天索性就下个决定，不搞懂它，决不罢休。通过今天的学习，加上之前的基础，EM算法终于算是理清思绪了。回头想想，果真是如何做事不下定决心，真的很难有结果。下面，打算将EM算法的整个推导过程总结一遍，达到理解并掌握的目的。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="EM" scheme="https://www.csuldw.com/tags/EM/"/>
    
      <category term="Optimization" scheme="https://www.csuldw.com/tags/Optimization/"/>
    
  </entry>
  
  <entry>
    <title>机器学习算法代码汇总</title>
    <link href="https://www.csuldw.com/2015/11/21/2015-11-21-machine-learning-algorithms/"/>
    <id>https://www.csuldw.com/2015/11/21/2015-11-21-machine-learning-algorithms/</id>
    <published>2015-11-21T02:24:00.000Z</published>
    <updated>2017-03-10T06:29:18.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><br><p>【机器学习算法代码汇总-Python&amp;R】- &lt;a link=”<a href="http://www.csuldw.com/assets/pdf/Full-CheatSheet-on-Machine-Learning-Algorithms(Python-and-R-Codes).pdf&quot;target=&quot;_black&quot;>PDF文件下载">http://www.csuldw.com/assets/pdf/Full-CheatSheet-on-Machine-Learning-Algorithms(Python-and-R-Codes).pdf"target="_black"&gt;PDF文件下载</a>.</p><p><img src="http://ww3.sinaimg.cn/large/637f3c58gw1ey8lm4rhn5j20s40fp466.jpg" alt="机器学习算法代码汇总1"></p><a id="more"></a><p><img src="http://ww3.sinaimg.cn/large/637f3c58gw1ey8lkrdcwlj20s93kl4qq.jpg" alt="机器学习算法代码汇总2"></p><p>原文链接：<a href="http://www.analyticsvidhya.com/blog/2015/09/full-cheatsheet-machine-learning-algorithms/" target="_blank" rel="noopener">点击这里</a>.</p><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;br&gt;


&lt;p&gt;【机器学习算法代码汇总-Python&amp;amp;R】- &amp;lt;a link=”&lt;a href=&quot;http://www.csuldw.com/assets/pdf/Full-CheatSheet-on-Machine-Learning-Algorithms(Python-and-R-Codes).pdf&amp;quot;target=&amp;quot;_black&amp;quot;&gt;PDF文件下载&quot;&gt;http://www.csuldw.com/assets/pdf/Full-CheatSheet-on-Machine-Learning-Algorithms(Python-and-R-Codes).pdf&quot;target=&quot;_black&quot;&amp;gt;PDF文件下载&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ww3.sinaimg.cn/large/637f3c58gw1ey8lm4rhn5j20s40fp466.jpg&quot; alt=&quot;机器学习算法代码汇总1&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Python" scheme="https://www.csuldw.com/tags/Python/"/>
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>实验笔记[1]-DSSP文件提取序列</title>
    <link href="https://www.csuldw.com/2015/11/18/2015-11-18%20ExpNotes%5B1%5D-Extract%20protein%20sequences%20from%20a%20fasta%20file/"/>
    <id>https://www.csuldw.com/2015/11/18/2015-11-18 ExpNotes[1]-Extract protein sequences from a fasta file/</id>
    <published>2015-11-18T04:24:00.000Z</published>
    <updated>2016-03-08T08:54:38.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>提示：以下内容乃个人实验笔记！</strong></p><h3 id="功能描述"><a href="#功能描述" class="headerlink" title="功能描述"></a>功能描述</h3><p>从格式化后的dssp文件<code>DSSP</code>（单一文件）中提取序列信息，要求输出的序列不含有<code>X</code>残基，并且序列最短长度<code>minlen</code>可人为指定，一般设置为<code>40</code>。</p><a id="more"></a><p><code>DSSP</code>文件格式Top10:</p><pre><code class="markdown">1A12        1       21     A     K                      0   0  172        0      172          0, 0.0         2,-1.9         0, 0.0         0, 0.0       0.000     360.0     360.0     360.0     129.7        9.7      -11.3       33.71A12        2       22     A     K            -         0   0  164        0      164          1,-0.1         2,-0.2         0, 0.0         0, 0.0      -0.433     360.0    -153.3     -64.1      85.0       10.1      -13.4       30.51A12        3       23     A     V            -         0   0   42        0       42         -2,-1.9         2,-0.2       114,-0.1       768,-0.1      -0.429       8.7    -128.1     -66.5     129.9       11.5      -10.5       28.41A12        4       24     A     K            -         0   0  130        0      130         -2,-0.2         2,-0.3       765,-0.1       113,-0.3      -0.476      21.9    -164.8     -79.9     149.3       10.9      -10.9       24.71A12        5       25     A     V            -         0   0   13        0       13        111,-2.8         2,-0.2        -2,-0.2       113,-0.2      -0.942       6.3    -177.4    -126.4     157.4       13.6      -10.6       22.11A12        6       26     A     S            -         0   0   20        0       20        719,-1.4         2,-0.3        -2,-0.3       720,-0.1      -0.694       8.2    -153.8    -133.2    -164.5       13.4      -10.1       18.31A12        7       27     A     H        &gt;   -         0   0    2        0        2         -2,-0.2         3,-1.6       718,-0.1       721,-0.3      -0.944      32.3    -112.1    -169.7     155.9       15.9       -9.9       15.41A12        8       28     A     R      T 3  S+         0   0   53        0       53        718,-0.4       720,-0.3       716,-0.3       717,-0.1       0.690     115.2      60.4     -69.3     -20.9       16.0       -8.3       12.01A12        9       29     A     S      T 3  S+         0   0   34        0       34        146,-0.2        -1,-0.3       718,-0.1         2,-0.2       0.548      78.3     108.7     -77.8     -13.9       15.9      -11.8       10.51A12       10       30     A     H        &lt;   -         0   0   22        0       22         -3,-1.6         2,-0.3       145,-0.1        93,-0.1      -0.516      67.8    -130.5     -73.7     135.3       12.6      -12.8       12.0</code></pre><hr><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p><code>generateSeqFromDSSP.py</code>文件如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment">#-*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> os </span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Parameters：</span></span><br><span class="line"><span class="string">    - dsspfile:为格式过的DSSP文件</span></span><br><span class="line"><span class="string">    - foseq: 为输出的序列文件</span></span><br><span class="line"><span class="string">    - fochain: 输出的蛋白链文件</span></span><br><span class="line"><span class="string">    - minLen:  最短的序列长度</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getSeqFromDSSP</span><span class="params">(dsspfile, foseq, fochain, minLen)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(dsspfile, <span class="string">'r'</span>) <span class="keyword">as</span> inputfile:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> foseq.strip():</span><br><span class="line">            foseq = <span class="string">'protein'</span>+ str(minLen) + <span class="string">'.dssp.seq'</span></span><br><span class="line">        outchain = open(fochain, <span class="string">'w'</span>)</span><br><span class="line">        <span class="keyword">with</span> open(foseq, <span class="string">'w'</span>) <span class="keyword">as</span> outputfile:</span><br><span class="line">            residue=[];Ntype=[]</span><br><span class="line">            preType=[];preRes=[]</span><br><span class="line">            firstline=[];secondline=[];content=<span class="string">''</span></span><br><span class="line">            <span class="keyword">for</span> eachline <span class="keyword">in</span> inputfile:</span><br><span class="line">                oneline = eachline.split(<span class="string">'\t'</span>) </span><br><span class="line">                residue = oneline[<span class="number">0</span>]</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> residue.strip(): </span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                Ntype = oneline[<span class="number">3</span>].strip()</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> Ntype.strip():</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">if</span> preRes!=residue:</span><br><span class="line">                    content = <span class="string">''</span>.join(firstline)+<span class="string">'\n'</span>+<span class="string">''</span>.join(secondline) +<span class="string">'\n'</span></span><br><span class="line">                    <span class="keyword">if</span> len(secondline)&gt;=int(minLen) <span class="keyword">and</span> <span class="keyword">not</span> <span class="string">'X'</span> <span class="keyword">in</span> secondline:</span><br><span class="line">                        outchain.write(<span class="string">''</span>.join(firstline) + <span class="string">'\n'</span>)</span><br><span class="line">                        outputfile.write(content)</span><br><span class="line">                    firstline=[]</span><br><span class="line">                    firstline.append(<span class="string">'&gt;'</span> + residue + <span class="string">':'</span> + Ntype)</span><br><span class="line">                    secondline=[];secondline.append(oneline[<span class="number">4</span>].strip())</span><br><span class="line">                    preRes = residue;preType = Ntype</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">if</span> Ntype != preType:</span><br><span class="line">                    content = <span class="string">''</span>.join(firstline)+<span class="string">'\n'</span>+<span class="string">''</span>.join(secondline)+<span class="string">'\n'</span></span><br><span class="line">                    <span class="keyword">if</span> len(secondline)&gt;=int(minLen) <span class="keyword">and</span>  <span class="keyword">not</span> <span class="string">'X'</span> <span class="keyword">in</span> secondline:</span><br><span class="line">                        outchain.write(<span class="string">''</span>.join(firstline) + <span class="string">'\n'</span>)</span><br><span class="line">                        outputfile.write(content)</span><br><span class="line">                    firstline=[]</span><br><span class="line">                    firstline.append(<span class="string">'&gt;'</span> + residue + <span class="string">':'</span> + Ntype)</span><br><span class="line">                    secondline=[];secondline.append(oneline[<span class="number">4</span>].strip())</span><br><span class="line">                    preRes = residue;preType = Ntype</span><br><span class="line">                <span class="keyword">else</span>: <span class="comment">#如果Ntype不为空，且等于preType</span></span><br><span class="line">                    secondline.append(oneline[<span class="number">4</span>].strip())</span><br><span class="line">            content = <span class="string">''</span>.join(firstline)+<span class="string">'\n'</span> + <span class="string">''</span>.join(secondline) +<span class="string">'\n'</span></span><br><span class="line">            <span class="comment">#选择长度大于40而且序列中不存在‘X’残基的序列</span></span><br><span class="line">            <span class="keyword">if</span> len(secondline) &gt;= int(minLen) <span class="keyword">and</span> <span class="keyword">not</span> <span class="string">'X'</span> <span class="keyword">in</span> secondline:  </span><br><span class="line">                outchain.write(<span class="string">''</span>.join(firstline) + <span class="string">'\n'</span>)</span><br><span class="line">                outputfile.write(content)</span><br><span class="line">        outchain.close()</span><br><span class="line"><span class="comment">###############################################################################</span></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    os.chdir(<span class="string">"/ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/"</span>)</span><br><span class="line">    dsspfile = os.sys.argv[<span class="number">1</span>]</span><br><span class="line">    foseq = os.sys.argv[<span class="number">2</span>]</span><br><span class="line">    fochain = os.sys.argv[<span class="number">3</span>]</span><br><span class="line">    minlen = os.sys.argv[<span class="number">4</span>]</span><br><span class="line">    getSeqFromDSSP(dsspfile, foseq, fochain, minlen)</span><br></pre></td></tr></tbody></table></figure><hr><h3 id="Test-sample"><a href="#Test-sample" class="headerlink" title="Test sample"></a>Test sample</h3><p>在Linux控制台中输入下面命令：</p><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python generateSeqFromDSSP.py \</span><br><span class="line"><span class="regexp">/ifs/</span>home<span class="regexp">/liudiwei/</span>DNA_BP<span class="regexp">/_data/</span>Exp_DBPI<span class="regexp">/dssp_testset/</span>DSSP \</span><br><span class="line"><span class="regexp">/ifs/</span>home<span class="regexp">/liudiwei/</span>DNA_BP<span class="regexp">/_data/</span>Exp_DBPI<span class="regexp">/protein_test.seq \</span></span><br><span class="line"><span class="regexp">/i</span>fs<span class="regexp">/home/</span>liudiwei<span class="regexp">/DNA_BP/</span>_data<span class="regexp">/Exp_DBPI/</span>protein_test.chain \</span><br><span class="line"><span class="number">40</span></span><br></pre></td></tr></tbody></table></figure><p>输出文件：</p><p><code>protein_test.seq</code>格式Top10：</p><pre><code class="markdown">&gt;1A12:AKKVKVSHRSHSTEPGLVLTLGQGDVGQLGLGENVMERKKPALVSIPEDVVQAEAGGMHTVCLSKSGQVYSFGCNDEGALGRDTSVEGSEMVPGKVELQEKVVQVSAGDSHTAALTDDGRVFLWGSFRDNNGVIGLLEPMKKSMVPVQVQLDVPVVKVASGNDHLVMLTADGDLYTLGCGEQGQLGRVPELFANRGGRQGLERLLVPKCVMLKSRGSRGHVRFQDAFCGAYFTFAISHEGHVYGFGLSNYHQLGTPGTESCFIPQNLTSFKNSTKSWVGFSGGQHHTVCMDSEGKAYSLGRAEYGRLGLGEGAEEKSIPTLISRLPAVSSVACGASVGYAVTKDGRVFAWGMGTNYQLGTGQDEDAWSPVEMMGKQLENRVVLSVSSGGQHTVLLVKDKEQS&gt;1A12:BKKVKVSHRSHSTEPGLVLTLGQGDVGQLGLGENVMERKKPALVSIPEDVVQAEAGGMHTVCLSKSGQVYSFGCNDEGALGRDTSVEGSEMVPGKVELQEKVVQVSAGDSHTAALTDDGRVFLWGSFRDNNGVIGLLEPMKKSMVPVQVQLDVPVVKVASGNDHLVMLTADGDLYTLGCGEQGQLGRVPELFANRGGRQGLERLLVPKCVMLKSRGSRGHVRFQDAFCGAYFTFAISHEGHVYGFGLSNYHQLGTPGTESCFIPQNLTSFKNSTKSWVGFSGGQHHTVCMDSEGKAYSLGRAEYGRLGLGEGAEEKSIPTLISRLPAVSSVACGASVGYAVTKDGRVFAWGMGTNYQLGTGQDEDAWSPVEMMGKQLENRVVLSVSSGGQHTVLLVKDKEQS&gt;1A12:CKKVKVSHRSHSTEPGLVLTLGQGDVGQLGLGENVMERKKPALVSIPEDVVQAEAGGMHTVCLSKSGQVYSFGCNDEGALGRDTSVEGSEMVPGKVELQEKVVQVSAGDSHTAALTDDGRVFLWGSFRDNNGVIGLLEPMKKSMVPVQVQLDVPVVKVASGNDHLVMLTADGDLYTLGCGEQGQLGRVPELFANRGGRQGLERLLVPKCVMLKSRGSRGHVRFQDAFCGAYFTFAISHEGHVYGFGLSNYHQLGTPGTESCFIPQNLTSFKNSTKSWVGFSGGQHHTVCMDSEGKAYSLGRAEYGRLGLGEGAEEKSIPTLISRLPAVSSVACGASVGYAVTKDGRVFAWGMGTNYQLGTGQDEDAWSPVEMMGKQLENRVVLSVSSGGQHTVLLVKDKEQS&gt;1BCH:1AIEVKLANMEAEINTLKSKLELTNKLHAFSMGKKSGKKFFVTNHERMPFSKVKALaSELRGTVAIPRNAEENKAIQEVAKTSAFLGITDEVTEGQFMYVTGGRLTYSNWKKDQPDDWYGHGLGGGEDbVHIVDNGLWNDISbQASHTAVaEFPA&gt;1BCH:2AIEVKLANMEAEINTLKSKLELTNKLHAFSMGKKSGKKFFVTNHERMPFSKVKALcSELRGTVAIPRNAEENKAIQEVAKTSAFLGITDEVTEGQFMYVTGGRLTYSNWKKDQPDDWYGHGLGGGEDdVHIVDNGLWNDISdQASHTAVcEFPA</code></pre><p><code>protein_test.chain</code>文件格式Top10:</p><pre><code class="markdown">&gt;1A12:A&gt;1A12:B&gt;1A12:C&gt;1BCH:1&gt;1BCH:2&gt;1BCH:3&gt;1BF6:B&gt;1BYP:A&gt;1C7J:A&gt;1CHM:A<code></code></code></pre><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;提示：以下内容乃个人实验笔记！&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;功能描述&quot;&gt;&lt;a href=&quot;#功能描述&quot; class=&quot;headerlink&quot; title=&quot;功能描述&quot;&gt;&lt;/a&gt;功能描述&lt;/h3&gt;&lt;p&gt;从格式化后的dssp文件&lt;code&gt;DSSP&lt;/code&gt;（单一文件）中提取序列信息，要求输出的序列不含有&lt;code&gt;X&lt;/code&gt;残基，并且序列最短长度&lt;code&gt;minlen&lt;/code&gt;可人为指定，一般设置为&lt;code&gt;40&lt;/code&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="BioInfo" scheme="https://www.csuldw.com/categories/BioInfo/"/>
    
    
      <category term="BioInfo" scheme="https://www.csuldw.com/tags/BioInfo/"/>
    
      <category term="预处理" scheme="https://www.csuldw.com/tags/%E9%A2%84%E5%A4%84%E7%90%86/"/>
    
      <category term="DSSP" scheme="https://www.csuldw.com/tags/DSSP/"/>
    
  </entry>
  
  <entry>
    <title>补集计算: B=U-A</title>
    <link href="https://www.csuldw.com/2015/11/17/2015-11-17%20B=U-A/"/>
    <id>https://www.csuldw.com/2015/11/17/2015-11-17 B=U-A/</id>
    <published>2015-11-17T07:11:00.000Z</published>
    <updated>2015-11-22T05:12:26.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>在做数据处理的时候，根据原论文的蛋白质链下载蛋白质PDB文件，大体上还算正常。但是有的protein的PDB文件在PDB数据库已经不存在了，所以下载后的PDB文件理论上只属于原论文提到的PDB文件的一个子集。由于数据比较大，手动去找会耗费大量的时间，所以为了找出这些不存在的PDB文件，下面写一段代码来实现。</p><h2 id="问题转换与实现"><a href="#问题转换与实现" class="headerlink" title="问题转换与实现"></a>问题转换与实现</h2><p>首先，将问题转化成一个数学问题。</p><a id="more"></a><p>问题转化：原论文提及的数据集（一个大集合U），现在下载到的只是一个子集合A，目的是求出U中不包含A的子集合（补集）：<code>B=U-A</code>.</p><p>最终转化为：根据集合U和子集A，计算A的补集B=U-A.</p><p>参数：</p><ul><li>file1：大集合文件U</li><li>file2: 下载后的一个子集合A</li><li>outfile：输出文件</li></ul><p>代码如下：</p><p>compareTwoFile.py</p><figure class="highlight livecodeserver"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment">#-*- coding: utf-8 -*-</span></span><br><span class="line">import os</span><br><span class="line">def compareTwoFile(file1,file2,outfile):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(outfile,<span class="string">'w'</span>) <span class="keyword">as</span> fo: </span><br><span class="line">        fw = []</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(file1,<span class="string">'r'</span>) <span class="keyword">as</span> fr1:</span><br><span class="line">            fr1_con = [<span class="keyword">each</span>.strip() <span class="keyword">for</span> <span class="keyword">each</span> <span class="keyword">in</span> fr1.readlines()] </span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(file2,<span class="string">'r'</span>) <span class="keyword">as</span> fr2:</span><br><span class="line">                fr2_con =[<span class="keyword">each</span>.strip() <span class="keyword">for</span> <span class="keyword">each</span> <span class="keyword">in</span> fr2.readlines()]</span><br><span class="line">                <span class="keyword">for</span> eachline <span class="keyword">in</span> fr1_con:</span><br><span class="line">                    <span class="keyword">if</span> eachline <span class="keyword">not</span> <span class="keyword">in</span> fr2_con:</span><br><span class="line">                        fw.append(eachline)</span><br><span class="line">        fo.<span class="built_in">write</span>(<span class="string">''</span>.join(fw))</span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>: </span><br><span class="line">    file1 = os.sys.argv[<span class="number">1</span>]</span><br><span class="line">    file2 = os.sys.argv[<span class="number">2</span>]</span><br><span class="line">    outfile = os.sys.argv[<span class="number">3</span>]</span><br><span class="line">    compareTwoFile(file1,file2,outfile)</span><br></pre></td></tr></tbody></table></figure><p>Test sample:</p><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python compareTwoFile.py \</span><br><span class="line"><span class="regexp">/ifs/</span>home<span class="regexp">/liudiwei/</span>DNA_BP<span class="regexp">/_data/</span>Exp_DBPI<span class="regexp">/train_set.protein  \</span></span><br><span class="line"><span class="regexp">/i</span>fs<span class="regexp">/home/</span>liudiwei<span class="regexp">/DNA_BP/</span>_data<span class="regexp">/Exp_DBPI/</span>pdb_trainset.txt \</span><br><span class="line"><span class="regexp">/ifs/</span>home<span class="regexp">/liudiwei/</span>DNA_BP<span class="regexp">/_data/</span>Exp_DBPI<span class="regexp">/compare.result</span></span><br></pre></td></tr></tbody></table></figure><p>file1和file2的top10格式：</p><pre><code>1A021A0A1A3Q1A531A8E1A8P1A8Y1AAC    1ABE1AC5</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a&gt;问题描述&lt;/h2&gt;&lt;p&gt;在做数据处理的时候，根据原论文的蛋白质链下载蛋白质PDB文件，大体上还算正常。但是有的protein的PDB文件在PDB数据库已经不存在了，所以下载后的PDB文件理论上只属于原论文提到的PDB文件的一个子集。由于数据比较大，手动去找会耗费大量的时间，所以为了找出这些不存在的PDB文件，下面写一段代码来实现。&lt;/p&gt;
&lt;h2 id=&quot;问题转换与实现&quot;&gt;&lt;a href=&quot;#问题转换与实现&quot; class=&quot;headerlink&quot; title=&quot;问题转换与实现&quot;&gt;&lt;/a&gt;问题转换与实现&lt;/h2&gt;&lt;p&gt;首先，将问题转化成一个数学问题。&lt;/p&gt;
    
    </summary>
    
      <category term="BioInfo" scheme="https://www.csuldw.com/categories/BioInfo/"/>
    
    
      <category term="Python" scheme="https://www.csuldw.com/tags/Python/"/>
    
      <category term="BioInfo" scheme="https://www.csuldw.com/tags/BioInfo/"/>
    
  </entry>
  
  <entry>
    <title>Download PDB file with wget command</title>
    <link href="https://www.csuldw.com/2015/11/16/2015-11-16%20Download%20PDB%20file%20with%20wget%20command/"/>
    <id>https://www.csuldw.com/2015/11/16/2015-11-16 Download PDB file with wget command/</id>
    <published>2015-11-16T02:24:00.000Z</published>
    <updated>2017-03-10T06:28:58.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在Linux服务器下，使用<code>wget</code>命令下载PDB文件，即蛋白质文件。</p><ul><li>输入文件格式：一个存有<code>protein chain</code>的单独文件，每行的格式为：<code>1A34A</code></li><li>输出文件：多个蛋白质文件，买一行下载一个蛋白质，格式：1A34.pdb<a id="more"></a>download.py文件</li></ul><figure class="highlight vim"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/<span class="keyword">python</span></span><br><span class="line"># -*- codin<span class="variable">g:</span> utf-<span class="number">8</span> -*-</span><br><span class="line">import os</span><br><span class="line">def downloadPDB(namefile,outpath):</span><br><span class="line">    <span class="keyword">if</span> not os.path.<span class="built_in">exists</span>(outpath):</span><br><span class="line">        os.<span class="built_in">mkdir</span>(outpath)</span><br><span class="line">    os.<span class="keyword">chdir</span>(outpath)</span><br><span class="line">    inputfile = <span class="keyword">open</span>(namefile,<span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">for</span> eachline in inputfile:</span><br><span class="line">        pdbname = eachline.lower().strip()[<span class="number">0</span>:<span class="number">4</span>]</span><br><span class="line">        os.<span class="built_in">system</span>(<span class="string">"wget http://ftp.wwpdb.org/pub/pdb/data/structures/all/pdb/pdb"</span> + pdbname + <span class="string">".ent.gz"</span>)</span><br><span class="line">        os.<span class="built_in">system</span>(<span class="string">"gzip -d pdb"</span> + pdbname + <span class="string">'.ent.gz'</span>)</span><br><span class="line">        os.<span class="built_in">system</span>(<span class="string">"mv pdb"</span> + pdbname + <span class="string">".ent "</span> + pdbname.upper() + <span class="string">'.pdb'</span>)</span><br><span class="line">    inputfile.<span class="keyword">close</span>()</span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    chainfile = os.sys.<span class="built_in">argv</span>[<span class="number">1</span>] </span><br><span class="line">    outpath = os.sys.<span class="built_in">argv</span>[<span class="number">2</span>]</span><br><span class="line">    proteinList = downloadPDB(chainfile,outpath)</span><br><span class="line"><span class="string">""</span><span class="comment">"</span></span><br><span class="line">test sample</span><br><span class="line"><span class="keyword">python</span> download.<span class="keyword">py</span> /ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/train_set.txt /ifs/home/liudiwei/DNA_BP/_data/Exp_DBPI/pdb_trainset   </span><br><span class="line"><span class="string">""</span><span class="comment">"</span></span><br></pre></td></tr></tbody></table></figure><p>命令解释：首先打开文件，然后逐行读取蛋白链，根据蛋白链的前四个字符，得到蛋白质的名字，然后使用<code>wget</code>命令下载<code>.ent.gz</code>文件，最后使用<code>gzip</code>解压文件即可。</p><p>命令行输入：</p><figure class="highlight jboss-cli"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python download.py <span class="string">../filepath</span>  <span class="string">../dirpath</span></span><br></pre></td></tr></tbody></table></figure><p>其中<code>filepath</code>表示的是一个存有多行，每行表示一个蛋白链的单独文件。</p><p>Top10格式如下：</p><pre><code>1A12A1BCH11BF6A1BYPA1C7JA1CHMA1CMNA1CUHA1CZYA1D7EA</code></pre><p>最后的输出文件Top5：</p><pre><code>1A12.pdb1BCH.pdb1BF6.pdb1BYP.pdb1C7J.pdb</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在Linux服务器下，使用&lt;code&gt;wget&lt;/code&gt;命令下载PDB文件，即蛋白质文件。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入文件格式：一个存有&lt;code&gt;protein chain&lt;/code&gt;的单独文件，每行的格式为：&lt;code&gt;1A34A&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;输出文件：多个蛋白质文件，买一行下载一个蛋白质，格式：1A34.pdb&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
      <category term="BioInfo" scheme="https://www.csuldw.com/categories/BioInfo/"/>
    
    
      <category term="BioInfo" scheme="https://www.csuldw.com/tags/BioInfo/"/>
    
      <category term="PDB" scheme="https://www.csuldw.com/tags/PDB/"/>
    
  </entry>
  
  <entry>
    <title>Machine Learning-Normalization</title>
    <link href="https://www.csuldw.com/2015/11/15/2015-11-15%20normalization/"/>
    <id>https://www.csuldw.com/2015/11/15/2015-11-15 normalization/</id>
    <published>2015-11-15T02:24:00.000Z</published>
    <updated>2016-07-11T15:36:42.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文主要介绍两种基本的数据归一化方法。</p><ul><li>min-max标准化（Min-Max Normalization）</li><li>Z-score标准化方法</li></ul><p>数据标准化（归一化）处理是数据挖掘的一项基础工作，不同评价指标往往具有不同的量纲和量纲单位，这样的情况会影响到数据分析的结果，为了消除指标之间的量纲影响，需要进行数据标准化处理，以解决数据指标之间的可比性。原始数据经过数据标准化处理后，各指标处于同一数量级，适合进行综合对比评价。归一化方法主要有两种形式，一种是把数变为（0，1）之间的小数，一种是把有量纲表达式变为无量纲表达式。</p><a id="more"></a><p>下面是归一化和没有归一化的比较：</p><p>没有经过归一化，寻找最优解过程如下：</p><p><img src="/assets/images/2015111501.png" alt="2015111501"></p><p>经过归一化，把各个特征的尺度控制在相同的范围内：</p><p><img src="/assets/images/2015111502.png" alt="2015111502"></p><p>从经验上说，归一化是让不同维度之间的特征在数值上有一定比较性，可以大大提高分类器的准确性。</p><p>以下是两种常用的归一化方法：</p><h2 id="1-min-max标准化（Min-Max-Normalization）"><a href="#1-min-max标准化（Min-Max-Normalization）" class="headerlink" title="1.min-max标准化（Min-Max Normalization）"></a>1.min-max标准化（Min-Max Normalization）</h2><p>也称为离差标准化，是对原始数据的线性变换，使结果值映射到[0 - 1]之间。转换函数如下：</p><p>$$x^{*}=\frac{x-x_{min}}{x_{max}-x_{min}}$$</p><p>x_min表示样本数据的最小值，x_max表示样本数据的最大值。</p><p><strong>Python代码实现：</strong></p><figure class="highlight llvm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def Normalization(<span class="keyword">x</span>):</span><br><span class="line">return [(float(i)-<span class="keyword">min</span>(<span class="keyword">x</span>))/float(<span class="keyword">max</span>(<span class="keyword">x</span>)-<span class="keyword">min</span>(<span class="keyword">x</span>)) for i in <span class="keyword">x</span>]</span><br></pre></td></tr></tbody></table></figure><p>测试：</p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">2</span>,<span class="number">7</span>]</span><br><span class="line">b=Normalization(x)</span><br></pre></td></tr></tbody></table></figure><p>Output：</p><figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">0.0</span>, <span class="number">0.16666666666666666</span>, <span class="number">0.0</span>, <span class="number">0.5</span>, <span class="number">0.3333333333333333</span>, <span class="number">0.16666666666666666</span>, <span class="number">0.6666666666666666</span>, <span class="number">0.8333333333333334</span>, <span class="number">0.16666666666666666</span>, <span class="number">1.0</span>]</span><br></pre></td></tr></tbody></table></figure><p>如果想要将数据映射到[-1,1]，则将公式换成：</p><p>$$x^{*}=\frac{x-x_{mean}}{x_{max}-x_{min}}$$</p><p>x_mean表示数据的均值</p><p><strong>Python代码实现：</strong></p><figure class="highlight llvm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">def Normalization<span class="number">2</span>(<span class="keyword">x</span>):</span><br><span class="line">return [(float(i)-np.mean(<span class="keyword">x</span>))/(<span class="keyword">max</span>(<span class="keyword">x</span>)-<span class="keyword">min</span>(<span class="keyword">x</span>)) for i in <span class="keyword">x</span>]</span><br></pre></td></tr></tbody></table></figure><p>测试：</p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">2</span>,<span class="number">7</span>]</span><br><span class="line">b=Normalization2(x)</span><br></pre></td></tr></tbody></table></figure><p>Output：</p><figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">-0.3833333333333333</span>, <span class="number">-0.21666666666666665</span>, <span class="number">-0.3833333333333333</span>, <span class="number">0.1166666666666667</span>, <span class="number">-0.049999999999999968</span>, <span class="number">-0.21666666666666665</span>, <span class="number">0.28333333333333338</span>, <span class="number">0.45000000000000001</span>, <span class="number">-0.21666666666666665</span>, <span class="number">0.6166666666666667</span>]</span><br></pre></td></tr></tbody></table></figure><p>注意：上面的Normalization是处理单个列表的。</p><h2 id="2-z-score标准化方法"><a href="#2-z-score标准化方法" class="headerlink" title="2.z-score标准化方法"></a>2.z-score标准化方法</h2><p>这种方法给予原始数据的均值（mean）和标准差（standard deviation）进行数据的标准化。经过处理的数据符合标准正态分布，即均值为0，标准差为1，转化函数为：</p><p>$$x^{*}=\frac{x-\mu}{\sigma}$$</p><p>其中，μ表示所有样本数据的均值，σ表示所有样本的标准差。</p><p><strong>Python代码实现：</strong></p><figure class="highlight matlab"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">def z_score(x):</span><br><span class="line">    x_mean=np.<span class="built_in">mean</span>(x)</span><br><span class="line">    s2=sum([(<span class="built_in">i</span>-np.<span class="built_in">mean</span>(x))*(<span class="built_in">i</span>-np.<span class="built_in">mean</span>(x)) <span class="keyword">for</span> <span class="built_in">i</span> in x])/len(x)</span><br><span class="line">    <span class="keyword">return</span> [(<span class="built_in">i</span>-x_mean)/s2 <span class="keyword">for</span> <span class="built_in">i</span> in x]</span><br></pre></td></tr></tbody></table></figure><p>测试：</p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">2</span>,<span class="number">7</span>]</span><br><span class="line">print z_score(x)</span><br></pre></td></tr></tbody></table></figure><p>Output:</p><figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">-0.57356608478802995</span>, <span class="number">-0.32418952618453861</span>, <span class="number">-0.57356608478802995</span>, <span class="number">0.17456359102244395</span>, <span class="number">-0.074812967581047343</span>, <span class="number">-0.32418952618453861</span>, <span class="number">0.42394014962593524</span>, <span class="number">0.67331670822942646</span>, <span class="number">-0.32418952618453861</span>, <span class="number">0.92269326683291775</span>]</span><br></pre></td></tr></tbody></table></figure><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要介绍两种基本的数据归一化方法。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;min-max标准化（Min-Max Normalization）&lt;/li&gt;
&lt;li&gt;Z-score标准化方法&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;数据标准化（归一化）处理是数据挖掘的一项基础工作，不同评价指标往往具有不同的量纲和量纲单位，这样的情况会影响到数据分析的结果，为了消除指标之间的量纲影响，需要进行数据标准化处理，以解决数据指标之间的可比性。原始数据经过数据标准化处理后，各指标处于同一数量级，适合进行综合对比评价。归一化方法主要有两种形式，一种是把数变为（0，1）之间的小数，一种是把有量纲表达式变为无量纲表达式。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="预处理" scheme="https://www.csuldw.com/tags/%E9%A2%84%E5%A4%84%E7%90%86/"/>
    
      <category term="normalization" scheme="https://www.csuldw.com/tags/normalization/"/>
    
      <category term="标准化" scheme="https://www.csuldw.com/tags/%E6%A0%87%E5%87%86%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Add header and footer to some file</title>
    <link href="https://www.csuldw.com/2015/11/03/2015-11-03%20Add%20header%20and%20footer%20to%20some%20file/"/>
    <id>https://www.csuldw.com/2015/11/03/2015-11-03 Add header and footer to some file/</id>
    <published>2015-11-03T08:24:00.000Z</published>
    <updated>2016-07-28T16:11:26.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>今天整理资料的时候，发现要在很多文件中的头部和尾部添加相同的文本，于是自己使用Python做了一个简单的文件拼接功能，也可以说是文件追加功能，给一个文件批量追加头尾内容，达到省事的效果，顺便还可以练习下Python。下面来介绍下这个功能的代码。</p><a id="more"></a><p>现在有三个文件，如下：</p><ul><li>content.txt 位于一个叫path的文件中；</li><li>header.txt用于添加到content.txt头部的文件；</li><li>footer.txt用于添加到content.txt尾部的文件。</li></ul><p>现在要实现的功能就是，将header和footer分别添加到content的头部和尾部。 </p><p>函数说明：</p><ul><li>add_footer(infile, outfile)：用于将footer内容添加到content中，第一个参数表示的添加到尾部的文件，如输入footer.txt，第二个为内容文件。如content.txt文件</li><li>add_header(infile, outfile, auto=True): 用于将一个文件放入好另一个文件的头部，如果auto=Ture，则不对内容做修改，auto为False的话，这里添加了部分需要的东西，如文件的创建时间、标题等信息。</li><li>addHeadAndFooter(path, header, footer, auto=False)：核心函数，调用头尾两个方法，此处的path为文件夹名称，该函数的功能是将path文件夹下的所有文件都添加头和尾的内容，auto默认为False，功能和上面的相同。</li><li>getStdTime(seconds):将时间戳格式的日期转换为标准格式，如：2015-11-03 10:24</li></ul><p>代码（AddHeader.py）：</p><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line">"""</span><br><span class="line">Created on Tue Nov 03 10:32:26 2015</span><br><span class="line">@author: liudiwei</span><br><span class="line">"""</span><br><span class="line">import os,time</span><br><span class="line">def add_footer(infile, outfile):</span><br><span class="line">    <span class="keyword">with</span> <span class="keyword">open</span>(<span class="keyword">infile</span>,<span class="string">'r'</span>) <span class="keyword">as</span> inputfile:</span><br><span class="line">        <span class="keyword">with</span> <span class="keyword">open</span>(<span class="keyword">outfile</span>,<span class="string">'a'</span>) <span class="keyword">as</span> <span class="keyword">outfile</span>:</span><br><span class="line">            outfile.write(<span class="string">"\n\n"</span>+<span class="string">''</span>.join(inputfile.readlines()))</span><br><span class="line"><span class="comment">#如果auto==True，直接将文件内容加入到当前文件</span></span><br><span class="line"><span class="keyword">def</span> add_header(<span class="keyword">infile</span>, <span class="keyword">outfile</span>, <span class="keyword">auto</span>=<span class="literal">True</span>): </span><br><span class="line">    inf=<span class="keyword">open</span>(<span class="keyword">infile</span>,<span class="string">'r'</span>)</span><br><span class="line">    outf = <span class="keyword">open</span>(<span class="keyword">outfile</span>,<span class="string">'r'</span>)</span><br><span class="line">    header = inf.readlines()</span><br><span class="line">    <span class="keyword">content</span>=outf.readlines()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">auto</span>==<span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">with</span> <span class="keyword">open</span>(<span class="keyword">outfile</span>,<span class="string">'w'</span>) <span class="keyword">as</span> <span class="keyword">output</span>:</span><br><span class="line">            output.write(<span class="string">''</span>.join(header)+ <span class="string">"\n\n"</span> \</span><br><span class="line">                            +<span class="string">''</span>.join(<span class="keyword">content</span>))  </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ctime=getStdTime(os.path.getctime(<span class="keyword">outfile</span>))</span><br><span class="line">        title=<span class="string">"title: "</span> + outfile.split(<span class="string">'/'</span>)[<span class="number">1</span>].split(<span class="string">'.'</span>)[<span class="number">0</span>]</span><br><span class="line">        print title</span><br><span class="line">        add_content=<span class="string">"---\n"</span></span><br><span class="line">        add_content=add_content+title+<span class="string">'\n'</span>  <span class="comment">#add title</span></span><br><span class="line">        add_content=add_content+ctime +<span class="string">'\n'</span> <span class="comment">#add date</span></span><br><span class="line">        add_content=add_content+<span class="string">''</span>.join(header)</span><br><span class="line">        <span class="keyword">with</span> <span class="keyword">open</span>(<span class="keyword">outfile</span>,<span class="string">'w'</span>) <span class="keyword">as</span> <span class="keyword">output</span>:</span><br><span class="line">            output.write(<span class="string">''</span>.join(add_content)+ <span class="string">"\n\n"</span> \</span><br><span class="line">                        +<span class="string">''</span>.join(<span class="keyword">content</span>))  </span><br><span class="line">    outf.close()</span><br><span class="line">    inf.close()</span><br><span class="line"><span class="keyword">def</span> addHeadAndFooter(<span class="keyword">path</span>, header, footer, <span class="keyword">auto</span>=<span class="literal">False</span>):</span><br><span class="line">    filelist=os.listdir(<span class="keyword">path</span>)</span><br><span class="line">    <span class="keyword">for</span> eachfile <span class="keyword">in</span> filelist:</span><br><span class="line">        add_header(header,<span class="keyword">path</span> + <span class="string">"/"</span> + eachfile, <span class="keyword">auto</span>)</span><br><span class="line">        add_footer(footer,<span class="keyword">path</span> + <span class="string">"/"</span> + eachfile)       </span><br><span class="line"><span class="keyword">def</span> getStdTime(<span class="keyword">seconds</span>):</span><br><span class="line">    x = time.localtime(<span class="keyword">seconds</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">"date: "</span>+ time.strftime(<span class="string">'%Y-%m-%d %H:%M:%S'</span>,x)        </span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">len</span>(os.sys.argv)&lt;<span class="number">4</span>):</span><br><span class="line">        <span class="keyword">raise</span> TypeError()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print <span class="string">"os.sys.arg"</span></span><br><span class="line">    <span class="comment">#path="path"</span></span><br><span class="line">    <span class="comment">#header="head.md"</span></span><br><span class="line">    <span class="comment">#footer="footer.md"</span></span><br><span class="line">    os.chdir(<span class="string">"."</span>)</span><br><span class="line">    <span class="keyword">path</span>=os.sys.argv[<span class="number">1</span>]</span><br><span class="line">    print <span class="keyword">path</span></span><br><span class="line">    header=os.sys.argv[<span class="number">2</span>]</span><br><span class="line">    footer=os.sys.argv[<span class="number">3</span>]</span><br><span class="line">    filelist=os.listdir(<span class="keyword">path</span>)</span><br><span class="line">    addHeadAndFooter(<span class="keyword">path</span>,header,footer)</span><br><span class="line">    print <span class="string">"Success added!"</span>    </span><br><span class="line"><span class="comment">#----------------    </span></span><br><span class="line"><span class="comment"># command </span></span><br><span class="line"><span class="comment"># python AddHead.py "path" "header.txt" "footer.txt"</span></span><br><span class="line"><span class="comment">#----------------</span></span><br></pre></td></tr></tbody></table></figure><p>直接在console控制台上运行下列代码即可 </p><figure class="highlight vim"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">python</span> AddHeader.<span class="keyword">py</span> <span class="string">"path"</span> <span class="string">"header.txt"</span> <span class="string">"footer.txt"</span></span><br></pre></td></tr></tbody></table></figure><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天整理资料的时候，发现要在很多文件中的头部和尾部添加相同的文本，于是自己使用Python做了一个简单的文件拼接功能，也可以说是文件追加功能，给一个文件批量追加头尾内容，达到省事的效果，顺便还可以练习下Python。下面来介绍下这个功能的代码。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://www.csuldw.com/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.csuldw.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python-RegEx（正则表达式）</title>
    <link href="https://www.csuldw.com/2015/10/29/2015-10-29%20Python%20RegEx/"/>
    <id>https://www.csuldw.com/2015/10/29/2015-10-29 Python RegEx/</id>
    <published>2015-10-29T12:24:00.000Z</published>
    <updated>2016-03-23T12:25:48.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>关于Python的正则表达式，初步学习了下，感觉跟shell脚本的正则表达式大体相同，先来做个小结吧！</p><h2 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h2><p>正则表达式在实际的文本文件处理中，经常用到，其实正则表达式并不是Python的一部分，其它语言中都有。正则表达式是用于处理字符串的强大工具，拥有自己独特的语法以及一个独立的处理引擎，效率上可能不如str自带的方法，但功能真的十分强大。得益于这一点，在提供了正则表达式的语言里，正则表达式的语法都是一样的，区别只在于不同的编程语言实现支持的语法数量不同；但不用担心，不被支持的语法通常是不常用的部分。如果已经在其他语言里使用过正则表达式，只需要简单看一看就可以上手了。</p><p>下图展示了使用正则表达式进行匹配的流程： </p><p><img src="http://ww4.sinaimg.cn/large/637f3c58gw1exic0q7k4ej20cj055t9e.jpg" alt=""></p><a id="more"></a><p>从上图我们可以看出，正则表达式的大致匹配过程是：依次拿出表达式和文本中的字符比较，如果每一个字符都能匹配，则匹配成功；一旦有匹配不成功的字符则匹配失败。如果表达式中有量词或边界，这个过程会稍微有一些不同，但也是很好理解的，来看看下面的这个正则表达式模式。</p><table><thead><tr><th>ID</th><th align="right">模式</th><th>描述</th></tr></thead><tbody><tr><td>1</td><td align="right">^</td><td>匹配字符串的开头</td></tr><tr><td>2</td><td align="right">$</td><td>匹配字符串的末尾。</td></tr><tr><td>3</td><td align="right">.</td><td>匹配任意字符，除了换行符，当re.DOTALL标记被指定时，则可以匹配包括换行符的任意字符。</td></tr><tr><td>4</td><td align="right">[…]</td><td>用来表示一组字符,单独列出：[amk] 匹配 ‘a’，’m’或’k’</td></tr><tr><td>5</td><td align="right">[^…]</td><td>不在[]中的字符：[^abc] 匹配除了a,b,c之外的字符。</td></tr><tr><td>6</td><td align="right">*</td><td>匹配0个或多个的表达式。</td></tr><tr><td>7</td><td align="right">+</td><td>匹配1个或多个的表达式。</td></tr><tr><td>8</td><td align="right">?</td><td>匹配0个或1个由前面的正则表达式定义的片段，非贪婪方式</td></tr><tr><td>9</td><td align="right">{ n,}</td><td>精确匹配n个前面表达式。</td></tr><tr><td>10</td><td align="right">{n,m}</td><td>匹配 n 到 m 次由前面的正则表达式定义的片段，贪婪方式</td></tr><tr><td>11</td><td align="right">(re)</td><td>G匹配括号内的表达式，也表示一个组</td></tr><tr><td>12</td><td align="right">(?imx)</td><td>正则表达式包含三种可选标志：i, m, 或 x 。只影响括号中的区域。</td></tr><tr><td>13</td><td align="right">(?-imx)</td><td>正则表达式关闭 i, m, 或 x 可选标志。只影响括号中的区域。</td></tr><tr><td>14</td><td align="right">(?:re)</td><td>类似 (…), 但是不表示一个组</td></tr><tr><td>15</td><td align="right">(?imx:re)</td><td>在括号中使用i, m, 或 x 可选标志</td></tr><tr><td>16</td><td align="right">(?-imx:re)</td><td>在括号中不使用i, m, 或 x 可选标志</td></tr><tr><td>17</td><td align="right">(?#…)</td><td>注释.</td></tr><tr><td>18</td><td align="right">(?=re)</td><td>前向肯定界定符。如果所含正则表达式，以 … 表示，在当前位置成功匹配时成功，否则失败。但一旦所含表达式已经尝试，匹配引擎根本没有提高；模式的剩余部分还要尝试界定符的右边。</td></tr><tr><td>19</td><td align="right">(?!re)</td><td>前向否定界定符。与肯定界定符相反；当所含表达式不能在字符串当前位置匹配时成功</td></tr><tr><td>20</td><td align="right">(?&gt;re)</td><td>匹配的独立模式，省去回溯。</td></tr><tr><td>21</td><td align="right">\w</td><td>匹配字母数字,等价于’[A-Za-z0-9_]’</td></tr><tr><td>22</td><td align="right">\W</td><td>匹配非字母数字, [^A-Za-z0-9_]’</td></tr><tr><td>23</td><td align="right">\s</td><td>匹配任意空白字符，等价于[\t\n\r\f].</td></tr><tr><td>24</td><td align="right">\S</td><td>匹配任意非空字符,等价于[^ \f\n\r\t\v]</td></tr><tr><td>25</td><td align="right">\d</td><td>匹配任意数字，等价于[0-9].</td></tr><tr><td>26</td><td align="right">\D</td><td>匹配任意非数字,等价于[^0-9]。</td></tr><tr><td>27</td><td align="right">\A</td><td>匹配字符串开始</td></tr><tr><td>28</td><td align="right">\Z</td><td>匹配字符串结束，如果是存在换行，只匹配到换行前的结束字符串。c</td></tr><tr><td>29</td><td align="right">\z</td><td>匹配字符串结束</td></tr><tr><td>30</td><td align="right">\G</td><td>匹配最后匹配完成的位置。</td></tr><tr><td>31</td><td align="right">\b</td><td>匹配一个单词边界，也就是指单词和空格间的位置。例如， ‘er\b’ 可以匹配”never” 中的 ‘er’，但不能匹配 “verb” 中的 ‘er’。</td></tr><tr><td>32</td><td align="right">\B</td><td>匹配非单词边界。’er\B’ 能匹配 “verb” 中的 ‘er’，但不能匹配 “never” 中的 ‘er’。</td></tr><tr><td>33</td><td align="right">\n, \t, 等.</td><td>匹配一个换行符。匹配一个制表符。等</td></tr><tr><td>34</td><td align="right">\1…\9</td><td>匹配第n个分组的子表达式。</td></tr><tr><td>35</td><td align="right">\10</td><td>匹配第n个分组的子表达式，如果它经匹配。否则指的是八进制字符码的表达式。</td></tr></tbody></table><p>下面从正则表达式的几个函数/方法来简单介绍下正则表达式的用法。</p><hr><h2 id="re-match-函数"><a href="#re-match-函数" class="headerlink" title="re.match()函数"></a>re.match()函数</h2><p>re.match 尝试<font color="#007FFF"><strong>从字符串的开头匹配一个模式</strong></font>，如：下面的例子匹配第一个单词。 </p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">text = <span class="string">"This is a very beautiful girl, I like her very much."</span></span><br><span class="line">m = re.match(<span class="string">r"(\w+)\s"</span>, text)</span><br><span class="line"><span class="keyword">if</span> m:</span><br><span class="line"><span class="keyword">print</span> m.group(<span class="number">0</span>), <span class="string">'\n'</span>, m.group(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">print</span> <span class="string">'not match'</span></span><br></pre></td></tr></tbody></table></figure><p>输出:</p><pre><code class="markdown">ThisThis</code></pre><p>re.match的函数原型为：re.match(pattern, string, flags)</p><ul><li>第一个参数是正则表达式，这里为”(\w+)\s”，如果匹配成功，则返回一个Match，否则返回一个None；</li><li>第二个参数表示要匹配的字符串；</li><li>第三个参数是标致位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。</li></ul><hr><h2 id="re-search-函数"><a href="#re-search-函数" class="headerlink" title="re.search()函数"></a>re.search()函数</h2><p>re.search函数会在字符串内查找模式匹配,只到找到第一个匹配然后返回，如果字符串没有匹配，则返回None。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">text = <span class="string">"This is a very beautiful girl, I like her very much."</span></span><br><span class="line">m = re.search(<span class="string">r'\sbeaut(i)ful\s'</span>, text)</span><br><span class="line"><span class="keyword">if</span> m:</span><br><span class="line"><span class="keyword">print</span> m.group(<span class="number">0</span>), m.group(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">print</span> <span class="string">'not search'</span></span><br></pre></td></tr></tbody></table></figure><p>输出结果：</p><pre><code class="markdown">beautiful i</code></pre><p>re.search的函数原型为： re.search(pattern, string, flags)</p><p>每个参数的含意与re.match一样。 </p><hr><h2 id="re-match-与re-search-的区别"><a href="#re-match-与re-search-的区别" class="headerlink" title="re.match()与re.search()的区别"></a>re.match()与re.search()的区别</h2><p><font color="#007FFF"><strong>re.match只匹配字符串的开始，如果字符串从一开始就不符合正则表达式，则匹配失败，函数返回None；而re.search匹配整个字符串，直到找到一个匹配。</strong></font></p><p>请看下面这个实例：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">line = <span class="string">"This is a very beautiful girl, I like her very much."</span>;</span><br><span class="line">m = re.match( <span class="string">r'girl'</span>, line, re.M|re.I)</span><br><span class="line"><span class="keyword">if</span> m:</span><br><span class="line">   <span class="keyword">print</span> <span class="string">"match --&gt; m.group() : "</span>, m.group()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">   <span class="keyword">print</span> <span class="string">"No match!!"</span></span><br></pre></td></tr></tbody></table></figure><p>match会从字符串起始出进行模式匹配，即模式中的其实字母‘g’匹配‘This’中的‘T’，所以，匹配失败。</p><pre><code class="markdown">No match!!</code></pre><p>如果使用的是search，来看看结果：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">m = re.search( <span class="string">r'girl'</span>, line, re.M|re.I)</span><br><span class="line"><span class="keyword">if</span> m:</span><br><span class="line">   <span class="keyword">print</span> <span class="string">"search --&gt; m.group() : "</span>, m.group()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">   <span class="keyword">print</span> <span class="string">"No match!"</span></span><br></pre></td></tr></tbody></table></figure><p>以上实例运行结果如下：</p><pre><code class="markdown">search --&gt; m.group() :  girl</code></pre><hr><h2 id="re-sub-amp-re-subn-函数"><a href="#re-sub-amp-re-subn-函数" class="headerlink" title="re.sub() &amp; re.subn()函数"></a>re.sub() &amp; re.subn()函数</h2><p>re.sub用于替换字符串中的匹配项。下面一个例子将字符串中的空格 ‘ ‘ 替换成 ‘-‘ : </p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">text = <span class="string">"I like Cats more than dogs!"</span></span><br><span class="line"><span class="keyword">print</span> re.sub(<span class="string">r'\s+'</span>, <span class="string">'-'</span>, text)</span><br></pre></td></tr></tbody></table></figure><p>输出：</p><pre><code class="markdown">I-like-Cats-more-than-dogs!</code></pre><p>re.sub的函数原型为：<font color="#007FFF"><strong>re.sub(pattern, repl, string, count)</strong></font></p><p>其中第二个函数是替换后的字符串；本例中为’-‘</p><p>第四个参数指替换个数。默认为0，表示每个匹配项都替换。</p><p>re.sub还允许使用函数对匹配项的替换进行复杂的处理。如：re.sub(r’\s’, lambda m: ‘[‘ + m.group(0) + ‘]’, text, 0)；将字符串中的空格’ ‘替换为’[ ]’。</p><p>注：re.subn和re.sub大体相似，唯一不同的就是返回结果，subn会将匹配的个数也显示出来。</p><p>如：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="keyword">import</span> re</span><br><span class="line">&gt;&gt;&gt;text = <span class="string">"I like Cats more than dogs!"</span></span><br><span class="line">&gt;&gt;&gt;<span class="keyword">print</span> re.subn(<span class="string">r'\s+'</span>, <span class="string">'-'</span>, text)</span><br><span class="line"></span><br><span class="line">(<span class="string">'I-like-Cats-more-than-dogs!'</span>, <span class="number">5</span>)</span><br></pre></td></tr></tbody></table></figure><hr><h2 id="re-split-函数"><a href="#re-split-函数" class="headerlink" title="re.split()函数"></a>re.split()函数</h2><p>可以使用re.split来分割字符串，如：re.split(r’-‘, text)；将字符串按’-‘符号分割成一个单词列表。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">text=<span class="string">"I-really-like-this-girl!"</span></span><br><span class="line">re.split(<span class="string">r'-'</span>,text)</span><br></pre></td></tr></tbody></table></figure><p>输出：</p><pre><code class="markdown">['I', 'really', 'like', 'this', 'girl!']</code></pre><hr><h2 id="re-findall-函数"><a href="#re-findall-函数" class="headerlink" title="re.findall()函数"></a>re.findall()函数</h2><p>re.findall可以获取字符串中所有匹配的字符串。如：re.findall(r’\w*i\w*‘, text)；获取字符串中，包含’oo’的所有单词。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">text=<span class="string">"I-really-like-this-girl!"</span></span><br><span class="line">re.findall(<span class="string">r'girl'</span>,text)</span><br></pre></td></tr></tbody></table></figure><p>输出结果：</p><pre><code class="markdown">['like', 'this', 'girl']</code></pre><hr><h2 id="re-compile-函数"><a href="#re-compile-函数" class="headerlink" title="re.compile()函数"></a>re.compile()函数</h2><p>可以把正则表达式编译成一个正则表达式对象。可以把那些经常使用的正则表达式编译成正则表达式对象，这样可以提高一定的效率。下面是一个正则表达式对象的一个例子：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">regex = re.compile(<span class="string">r'\w*er\w*'</span>) <span class="comment"># 将正则表达式编译成Pattern对象</span></span><br><span class="line">text = <span class="string">"This is a very beautiful girl, I like her very much."</span></span><br><span class="line">m = regex.search(text) <span class="comment">#使用regex来匹配text字符串</span></span><br><span class="line"><span class="keyword">if</span> m:</span><br><span class="line">    <span class="keyword">print</span> m.group() <span class="comment"># 使用Match获得分组信息</span></span><br><span class="line"><span class="keyword">print</span> regex.findall(text)   <span class="comment">#查找所有包含'oo'的单词</span></span><br><span class="line"><span class="keyword">print</span> regex.sub(<span class="keyword">lambda</span> m: <span class="string">'['</span> + m.group(<span class="number">0</span>) + <span class="string">']'</span>, text) <span class="comment">#将字符串中含有'oo'的单词用[]括起来。</span></span><br></pre></td></tr></tbody></table></figure><p>分别输出下列信息：</p><pre><code class="markdown">'very'['very', 'her', 'very']This is a [very] beautiful girl, I like [her] [very] much.</code></pre><hr><h2 id="邮箱验证"><a href="#邮箱验证" class="headerlink" title="邮箱验证"></a>邮箱验证</h2><p>使用Python写一个简单的邮箱验证的正则表达式：</p><p>根据<a href="mailto:csu.ldw@csu.edu.cn" target="_blank" rel="noopener">csu.ldw@csu.edu.cn</a>来填写规则</p><p>规则：</p><ul><li>@前面可以有’.’, ‘_’, ‘-‘, 但不能出现在头尾，而且不能连续出现</li><li>@后面到结尾之间，可以有多个子域名</li><li>邮箱的结尾为2~5个字母，比如cn、com、name等</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Thu Oct 29 20:28:57 2015</span></span><br><span class="line"><span class="string">@author: liudiwei</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">regex = re.compile(<span class="string">'^[A-Za-z0-9]+(([\.\_\-])?[A-Za-z0-9]+)+@([A-Za-z]+.)+[A-Za-z]{2,5}$'</span>)</span><br><span class="line">m = regex.match(<span class="string">"csu.ldw@csu.edu.cn"</span>)</span><br><span class="line"><span class="keyword">if</span> m:</span><br><span class="line">    <span class="keyword">print</span> m.group()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"no match!"</span></span><br></pre></td></tr></tbody></table></figure><p>测试输出：</p><pre><code class="markdown">csu.ldw@csu.edu.cn</code></pre><p>当m = regex.match(“<a href="mailto:_csu.ldw@csu.edu.cn" target="_blank" rel="noopener">_csu.ldw@csu.edu.cn</a>“)<br>当邮箱为：</p><pre><code class="markdown">_csu.ldw@csu.edu.cn  csu.ldw_@csu.edu.cncsu.ldw@csu_.edu.cn_csu.ldw@csu.edu.cn1</code></pre><p>都不会匹配</p><p>提示：合法邮箱的规则可能不够完善，这里就简单的匹配这三个规则吧！</p><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于Python的正则表达式，初步学习了下，感觉跟shell脚本的正则表达式大体相同，先来做个小结吧！&lt;/p&gt;
&lt;h2 id=&quot;正则表达式&quot;&gt;&lt;a href=&quot;#正则表达式&quot; class=&quot;headerlink&quot; title=&quot;正则表达式&quot;&gt;&lt;/a&gt;正则表达式&lt;/h2&gt;&lt;p&gt;正则表达式在实际的文本文件处理中，经常用到，其实正则表达式并不是Python的一部分，其它语言中都有。正则表达式是用于处理字符串的强大工具，拥有自己独特的语法以及一个独立的处理引擎，效率上可能不如str自带的方法，但功能真的十分强大。得益于这一点，在提供了正则表达式的语言里，正则表达式的语法都是一样的，区别只在于不同的编程语言实现支持的语法数量不同；但不用担心，不被支持的语法通常是不常用的部分。如果已经在其他语言里使用过正则表达式，只需要简单看一看就可以上手了。&lt;/p&gt;
&lt;p&gt;下图展示了使用正则表达式进行匹配的流程： &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ww4.sinaimg.cn/large/637f3c58gw1exic0q7k4ej20cj055t9e.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://www.csuldw.com/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.csuldw.com/tags/Python/"/>
    
      <category term="正则表达式" scheme="https://www.csuldw.com/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    
      <category term="RegEx" scheme="https://www.csuldw.com/tags/RegEx/"/>
    
  </entry>
  
  <entry>
    <title>scikit-learn Preprocessing</title>
    <link href="https://www.csuldw.com/2015/10/25/2015-10-25%20scikit-learn%20preprocessing/"/>
    <id>https://www.csuldw.com/2015/10/25/2015-10-25 scikit-learn preprocessing/</id>
    <published>2015-10-25T02:24:00.000Z</published>
    <updated>2016-03-13T05:55:40.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文主要是对照<a href="http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing" target="_blank" rel="noopener">scikit-learn的preprocessing</a>章节结合代码简单的回顾下预处理技术的几种方法，主要包括标准化、数据最大最小缩放处理、正则化、特征二值化和数据缺失值处理。内容比较简单，仅供参考！</p><p>首先来回顾一下下面要用到的基本知识。</p><a id="more"></a><h2 id="一、知识回顾"><a href="#一、知识回顾" class="headerlink" title="一、知识回顾"></a><strong>一、知识回顾</strong></h2><p>均值公式：</p><p>$$\bar{x}=\frac{1}{n}\sum_{i=1}^{n}x_{i}$$</p><p>方差公式：</p><p>$$s^{2}=\frac{1}{n}\sum_{i=1}^{n}(x_{i}-\bar{x})^{2}$$</p><p>0-范数，向量中非零元素的个数。</p><p>1-范数：</p><p>$$||X||= \sum_{i=1}^{n} |x_{i}|$$</p><p>2-范数：</p><p>$$||X||_{2} =  (\sum_{i=1}^{n} x_{i}^{2})^{\frac{1}{2}}$$</p><p>p-范数的计算公式：</p><p>$$||X||_{p}=(|x1|^{p}+|x2|^{p}+…+|xn|^{p})^{\frac{1}{p}}$$</p><hr><p>数据标准化：当单个特征的样本取值相差甚大或明显不遵从高斯正态分布时，标准化表现的效果较差。实际操作中，经常忽略特征数据的分布形状，移除每个特征均值，划分离散特征的标准差，从而等级化，进而实现数据中心化。</p><h2 id="二、标准化-Standardization-，或者去除均值和方差进行缩放"><a href="#二、标准化-Standardization-，或者去除均值和方差进行缩放" class="headerlink" title="二、标准化(Standardization)，或者去除均值和方差进行缩放"></a><strong>二、标准化(Standardization)，或者去除均值和方差进行缩放</strong></h2><p>公式为：(X-X_mean)/X_std 计算时对每个属性/每列分别进行.</p><p>将数据按其属性(按列进行)减去其均值，然后除以其方差。最后得到的结果是，对每个属性/每列来说所有数据都聚集在0附近，方差值为1。</p><p>首先说明下sklearn中preprocessing库里面的scale函数使用方法：</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.preprocessing.scale(X, <span class="attribute">axis</span>=0, <span class="attribute">with_mean</span>=<span class="literal">True</span>,with_std=True,copy=True)</span><br></pre></td></tr></tbody></table></figure><p>根据参数的不同，可以沿任意轴标准化数据集。</p><p>参数解释：</p><ul><li>X：数组或者矩阵</li><li>axis：int类型，初始值为0，axis用来计算均值 means 和标准方差 standard deviations. 如果是0，则单独的标准化每个特征（列），如果是1，则标准化每个观测样本（行）。</li><li>with_mean: boolean类型，默认为True，表示将数据均值规范到0</li><li>with_std: boolean类型，默认为True，表示将数据方差规范到1</li></ul><p><strong>一个简单的例子</strong></p><p>假设现在我构造一个数据集X，然后想要将其标准化。下面使用不同的方法来标准化X：</p><p><strong>方法一：使用sklearn.preprocessing.scale()函数</strong></p><p><strong>方法说明：</strong></p><ul><li>X.mean(axis=0)用来计算数据X每个特征的均值；</li><li>X.std(axis=0)用来计算数据X每个特征的方差；</li><li>preprocessing.scale(X)直接标准化数据X。</li></ul><p>将代码整理到一个文件中：</p><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from sklearn <span class="built_in">import</span> preprocessing </span><br><span class="line"><span class="built_in">import</span> numpy as np</span><br><span class="line"><span class="attr">X</span> = np.array([[ <span class="number">1</span>., -<span class="number">1</span>.,  <span class="number">2</span>.],</span><br><span class="line">              [ <span class="number">2</span>.,  <span class="number">0</span>.,  <span class="number">0</span>.],</span><br><span class="line">              [ <span class="number">0</span>.,  <span class="number">1</span>., -<span class="number">1</span>.]])</span><br><span class="line"><span class="comment"># calculate mean</span></span><br><span class="line"><span class="attr">X_mean</span> = X.mean(<span class="attr">axis=0)</span></span><br><span class="line"><span class="comment"># calculate variance </span></span><br><span class="line"><span class="attr">X_std</span> = X.std(<span class="attr">axis=0)</span></span><br><span class="line"><span class="comment"># standardize X</span></span><br><span class="line"><span class="attr">X1</span> = (X-X_mean)/X_std</span><br><span class="line"><span class="comment"># use function preprocessing.scale to standardize X</span></span><br><span class="line"><span class="attr">X_scale</span> = preprocessing.scale(X)</span><br></pre></td></tr></tbody></table></figure><p>最后X_scale的值和X1的值是一样的，前面是单独的使用数学公式来计算，主要是为了形成一个对比，能够更好的理解scale()方法。</p><p><strong>方法2：sklearn.preprocessing.StandardScaler类</strong></p><p>该方法也可以对数据X进行标准化处理，实例如下：</p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import preprocessing </span><br><span class="line">import numpy as np</span><br><span class="line">X = np.array([[ <span class="number">1.</span>, <span class="number">-1.</span>,  <span class="number">2.</span>],</span><br><span class="line">              [ <span class="number">2.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">              [ <span class="number">0.</span>,  <span class="number">1.</span>, <span class="number">-1.</span>]])</span><br><span class="line">scaler = preprocessing.StandardScaler()</span><br><span class="line">X_scaled = scaler.fit_transform(X)</span><br></pre></td></tr></tbody></table></figure><p>这两个方法得到最后的结果都是一样的。</p><hr><h2 id="三、将特征的取值缩小到一个范围（如0到1）"><a href="#三、将特征的取值缩小到一个范围（如0到1）" class="headerlink" title="三、将特征的取值缩小到一个范围（如0到1）"></a><strong>三、将特征的取值缩小到一个范围（如0到1）</strong></h2><p>除了上述介绍的方法之外，另一种常用的方法是将属性缩放到一个指定的最大值和最小值(通常是1-0)之间，这可以通过preprocessing.MinMaxScaler类来实现。</p><p>使用这种方法的目的包括：</p><ul><li>1、对于方差非常小的属性可以增强其稳定性；</li><li>2、维持稀疏矩阵中为0的条目。</li></ul><p>下面将数据缩至0-1之间，采用MinMaxScaler函数</p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import preprocessing </span><br><span class="line">import numpy as np</span><br><span class="line">X = np.array([[ <span class="number">1.</span>, <span class="number">-1.</span>,  <span class="number">2.</span>],</span><br><span class="line">              [ <span class="number">2.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">              [ <span class="number">0.</span>,  <span class="number">1.</span>, <span class="number">-1.</span>]])</span><br><span class="line">min_max_scaler = preprocessing.MinMaxScaler()</span><br><span class="line">X_minMax = min_max_scaler.fit_transform(X)</span><br></pre></td></tr></tbody></table></figure><p>最后输出：</p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[ <span class="number">0.5</span>       ,  <span class="number">0.</span>        ,  <span class="number">1.</span>        ],</span><br><span class="line">       [ <span class="number">1.</span>        ,  <span class="number">0.5</span>       ,  <span class="number">0.33333333</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">1.</span>        ,  <span class="number">0.</span>        ]])</span><br></pre></td></tr></tbody></table></figure><p>测试用例：</p><figure class="highlight lua"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; X_test = np.array(<span class="string">[[ -3., -1.,  4.]]</span>)</span><br><span class="line">&gt;&gt;&gt; X_test_minmax = min_max_scaler.transform(X_test)</span><br><span class="line">&gt;&gt;&gt; X_test_minmax</span><br><span class="line">array(<span class="string">[[-1.5       ,  0.        ,  1.66666667]]</span>)</span><br></pre></td></tr></tbody></table></figure><p>注意：这些变换都是对列进行处理。</p><p>当然，在构造类对象的时候也可以直接指定最大最小值的范围：feature_range=(min, max)，此时应用的公式变为：</p><figure class="highlight tp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_std=(<span class="keyword">X</span>-<span class="keyword">X</span>.min(axis=<span class="number">0</span>))/(<span class="keyword">X</span>.max(axis=<span class="number">0</span>)-<span class="keyword">X</span>.min(axis=<span class="number">0</span>))</span><br><span class="line">X_minmax=X_std/(<span class="keyword">X</span>.max(axis=<span class="number">0</span>)-<span class="keyword">X</span>.min(axis=<span class="number">0</span>))+<span class="keyword">X</span>.min(axis=<span class="number">0</span>))</span><br></pre></td></tr></tbody></table></figure><hr><h2 id="四、正则化-Normalization"><a href="#四、正则化-Normalization" class="headerlink" title="四、正则化(Normalization)"></a><strong>四、正则化(Normalization)</strong></h2><p>正则化的过程是将每个样本缩放到单位范数(每个样本的范数为1)，如果要使用如二次型(点积)或者其它核方法计算两个样本之间的相似性这个方法会很有用。</p><p>该方法是文本分类和聚类分析中经常使用的向量空间模型（Vector Space Model)的基础.</p><p>Normalization主要思想是对每个样本计算其p-范数，然后对该样本中每个元素除以该范数，这样处理的结果是使得每个处理后样本的p-范数(l1-norm,l2-norm)等于1。</p><p><strong>方法1：使用sklearn.preprocessing.normalize()函数</strong></p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; X = [[ <span class="number">1.</span>, <span class="number">-1.</span>,  <span class="number">2.</span>],</span><br><span class="line">...      [ <span class="number">2.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">...      [ <span class="number">0.</span>,  <span class="number">1.</span>, <span class="number">-1.</span>]]</span><br><span class="line">&gt;&gt;&gt; X_normalized = preprocessing.normalize(X, norm='l2')</span><br><span class="line">&gt;&gt;&gt; X_normalized                                      </span><br><span class="line">array([[ <span class="number">0.40</span>..., <span class="number">-0.40</span>...,  <span class="number">0.81</span>...],</span><br><span class="line">       [ <span class="number">1.</span>  ...,  <span class="number">0.</span>  ...,  <span class="number">0.</span>  ...],</span><br><span class="line">       [ <span class="number">0.</span>  ...,  <span class="number">0.70</span>..., <span class="number">-0.70</span>...]])</span><br></pre></td></tr></tbody></table></figure><p><strong>方法2：sklearn.preprocessing.StandardScaler类</strong></p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; normalizer = preprocessing.Normalizer().fit(X)  # fit does <span class="literal">nothing</span></span><br><span class="line">&gt;&gt;&gt; normalizer</span><br><span class="line">Normalizer(<span class="attribute">copy</span>=<span class="literal">True</span>, <span class="attribute">norm</span>=<span class="string">'l2'</span>)</span><br></pre></td></tr></tbody></table></figure><p>然后使用正则化实例来转换样本向量：</p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; normalizer.transform(X)                            </span><br><span class="line">array([[ <span class="number">0.40</span>..., <span class="number">-0.40</span>...,  <span class="number">0.81</span>...],</span><br><span class="line">       [ <span class="number">1.</span>  ...,  <span class="number">0.</span>  ...,  <span class="number">0.</span>  ...],</span><br><span class="line">       [ <span class="number">0.</span>  ...,  <span class="number">0.70</span>..., <span class="number">-0.70</span>...]])</span><br><span class="line">&gt;&gt;&gt; normalizer.transform([[<span class="number">-1.</span>,  <span class="number">1.</span>, <span class="number">0.</span>]])             </span><br><span class="line">array([[<span class="number">-0.70</span>...,  <span class="number">0.70</span>...,  <span class="number">0.</span>  ...]])</span><br></pre></td></tr></tbody></table></figure><p>两种方法都可以，效果是一样的。</p><hr><h2 id="五、二值化-Binarization"><a href="#五、二值化-Binarization" class="headerlink" title="五、二值化(Binarization)"></a><strong>五、二值化(Binarization)</strong></h2><p>特征的二值化主要是为了将数据特征转变成boolean变量。在sklearn中，sklearn.preprocessing.Binarizer函数可以实现这一功能。实例如下：</p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; X = [[ <span class="number">1.</span>, <span class="number">-1.</span>,  <span class="number">2.</span>],</span><br><span class="line">...      [ <span class="number">2.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">...      [ <span class="number">0.</span>,  <span class="number">1.</span>, <span class="number">-1.</span>]]</span><br><span class="line">&gt;&gt;&gt; binarizer = preprocessing.Binarizer().fit(X)  # fit does nothing</span><br><span class="line">&gt;&gt;&gt; binarizer</span><br><span class="line">Binarizer(copy=True, threshold=<span class="number">0.0</span>)</span><br><span class="line">&gt;&gt;&gt; binarizer.transform(X)</span><br><span class="line">array([[ <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>],</span><br><span class="line">       [ <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>]])</span><br></pre></td></tr></tbody></table></figure><p>Binarizer函数也可以设定一个阈值，结果数据值大于阈值的为1，小于阈值的为0，实例代码如下：</p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; binarizer = preprocessing.Binarizer(threshold=<span class="number">1.1</span>)</span><br><span class="line">&gt;&gt;&gt; binarizer.transform(X)</span><br><span class="line">array([[ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>],</span><br><span class="line">       [ <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>]])</span><br></pre></td></tr></tbody></table></figure><hr><h2 id="六、缺失值处理"><a href="#六、缺失值处理" class="headerlink" title="六、缺失值处理"></a><strong>六、缺失值处理</strong></h2><p>由于不同的原因，许多现实中的数据集都包含有缺失值，要么是空白的，要么使用NaNs或者其它的符号替代。这些数据无法直接使用scikit-learn分类器直接训练，所以需要进行处理。幸运地是，sklearn中的<strong>Imputer</strong>类提供了一些基本的方法来处理缺失值，如使用均值、中位值或者缺失值所在列中频繁出现的值来替换。</p><p>下面是使用均值来处理的实例：</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import numpy as np</span><br><span class="line">&gt;&gt;&gt; <span class="keyword">from</span> sklearn.preprocessing import Imputer</span><br><span class="line">&gt;&gt;&gt; imp = Imputer(<span class="attribute">missing_values</span>=<span class="string">'NaN'</span>, <span class="attribute">strategy</span>=<span class="string">'mean'</span>, <span class="attribute">axis</span>=0)</span><br><span class="line">&gt;&gt;&gt; imp.fit([[1, 2], [np.nan, 3], [7, 6]])</span><br><span class="line">Imputer(<span class="attribute">axis</span>=0, <span class="attribute">copy</span>=<span class="literal">True</span>, <span class="attribute">missing_values</span>=<span class="string">'NaN'</span>, <span class="attribute">strategy</span>=<span class="string">'mean'</span>, <span class="attribute">verbose</span>=0)</span><br><span class="line">&gt;&gt;&gt; X = [[np.nan, 2], [6, np.nan], [7, 6]]</span><br><span class="line">&gt;&gt;&gt; <span class="builtin-name">print</span>(imp.transform(X))                           </span><br><span class="line">[[ 4.          2.        ]</span><br><span class="line"> [ 6.          3.666<span class="built_in">..</span>.]</span><br><span class="line"> [ 7.          6.        ]]</span><br></pre></td></tr></tbody></table></figure><p>Imputer类同样支持稀疏矩阵：</p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import scipy.sparse as sp</span><br><span class="line">&gt;&gt;&gt; X = sp.csc_matrix([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">3</span>], [<span class="number">7</span>, <span class="number">6</span>]])</span><br><span class="line">&gt;&gt;&gt; imp = Imputer(missing_values=<span class="number">0</span>, strategy='mean', axis=<span class="number">0</span>)</span><br><span class="line">&gt;&gt;&gt; imp.fit(X)</span><br><span class="line">Imputer(axis=<span class="number">0</span>, copy=True, missing_values=<span class="number">0</span>, strategy='mean', verbose=<span class="number">0</span>)</span><br><span class="line">&gt;&gt;&gt; X_test = sp.csc_matrix([[<span class="number">0</span>, <span class="number">2</span>], [<span class="number">6</span>, <span class="number">0</span>], [<span class="number">7</span>, <span class="number">6</span>]])</span><br><span class="line">&gt;&gt;&gt; print(imp.transform(X_test))                      </span><br><span class="line">[[ <span class="number">4.</span>          <span class="number">2.</span>        ]</span><br><span class="line"> [ <span class="number">6.</span>          <span class="number">3.666</span>...]</span><br><span class="line"> [ <span class="number">7.</span>          <span class="number">6.</span>        ]]</span><br></pre></td></tr></tbody></table></figure><p>本文讲解的比较接单，如果对这些不是很理解的话，请到scikit-learn的官网中查看英文版本：<a href="http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing" target="_blank" rel="noopener">preprocessing</a>.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a><strong>References</strong></h2><ul><li><a href="http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing" target="_blank" rel="noopener">Scikit-learn preprocessing</a>.</li></ul><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要是对照&lt;a href=&quot;http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;scikit-learn的preprocessing&lt;/a&gt;章节结合代码简单的回顾下预处理技术的几种方法，主要包括标准化、数据最大最小缩放处理、正则化、特征二值化和数据缺失值处理。内容比较简单，仅供参考！&lt;/p&gt;
&lt;p&gt;首先来回顾一下下面要用到的基本知识。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="scikit-learn" scheme="https://www.csuldw.com/tags/scikit-learn/"/>
    
      <category term="预处理" scheme="https://www.csuldw.com/tags/%E9%A2%84%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>机器学习之特征工程</title>
    <link href="https://www.csuldw.com/2015/10/24/2015-10-24%20feature%20engineering/"/>
    <id>https://www.csuldw.com/2015/10/24/2015-10-24 feature engineering/</id>
    <published>2015-10-24T02:24:00.000Z</published>
    <updated>2019-11-23T06:17:00.496Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在这个振奋人心的程序员节日里，我决定认真地写一篇文章来纪念一下自己这长达六年程序员史。o(╯□╰)o</p><p>本文是一篇关于特征工程的总结类文章，如有不足之处或理解有偏差的地方，还望多多指教。</p><a id="more"></a><p>首先，给一张特征工程的思维导图吧：</p><p><img src="/assets/articleImg/feature-enginering.png" alt="特征工程"></p><center><font color="green">**【如果要浏览图片，建议将其下载到本地，使用图片浏览软件查看】**</font></center><p>关于特征工程（Feature Engineering），已经是很古老很常见的话题了，坊间常说：“数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已”。由此可见，特征工程在机器学习中占有相当重要的地位。在实际应用当中，可以说特征工程是机器学习成功的关键。纵观Kaggle、KDD等国内外大大小小的比赛，每个竞赛的冠军其实并没有用到很高深的算法，大多数都是在特征工程这个环节做出了出色的工作，然后使用一些常见的算法，比如LR，就能得到出色的性能。遗憾的是，在很多的书籍中并没有直接提到Feature Engineering，更多的是Feature selection。这也并不，很多ML书籍都是以讲解算法为主，他们的目的是从理论到实践来理解算法，所以用到的数据要么是使用代码生成的，要么是已经处理好的数据，并没有提到特征工程。在这篇文章，我打算自我总结下特征工程，让自己对特征工程有个全面的认识。在这我要说明一下，我并不是说那些书写的不好，其实都很有不错，主要是因为它们的目的是理解算法，所以直接给出数据相对而言对于学习和理解算法效果更佳。</p><p>这篇文章主要从以下三个问题出发来理解特征工程：</p><ul><li>特征工程是什么？</li><li>为什么要做特征工程？</li><li>应该如何做特征工程？</li></ul><p>对于第一个问题，我会通过特征工程的目的来解释什么是特征工程。对于第二个问题，主要从特征工程的重要性来阐述。对于第三个问题，我会从特征工程的子问题以及简单的处理方法来进一步说明。下面来看看详细内容！</p><hr><h2 id="1、特征工程是什么"><a href="#1、特征工程是什么" class="headerlink" title="1、特征工程是什么"></a><strong>1、特征工程是什么</strong></h2><p>首先来解释下什么是特征工程？</p><p>当你想要你的预测模型性能达到最佳时，你要做的不仅是要选取最好的算法，还要尽可能的从原始数据中获取更多的信息。那么问题来了，<font color="red">你应该如何为你的预测模型得到更好的数据呢？</font></p><p>想必到了这里你也应该猜到了，是的，这就是特征工程要做的事，它的目的就是<font color="red">获取更好的训练数据</font>。</p><p>关于特征工程的定义，Wikipedia上是这样说的：</p><pre><code>Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. ”</code></pre><p>我的理解：</p><pre><code>特征工程是利用数据领域的相关知识来创建能够使机器学习算法达到最佳性能的特征的过程。</code></pre><p>简而言之，特征工程就是一个把原始数据转变成特征的过程，这些特征可以很好的描述这些数据，并且利用它们建立的模型在未知数据上的表现性能可以达到最优（或者接近最佳性能）。从数学的角度来看，特征工程就是人工地去设计输入变量X。</p><p>特征工程更是一门艺术，跟编程一样。导致许多机器学习项目成功和失败的主要因素就是使用了不同的特征。说了这么多，想必你也大概知道了为什么要做特征工程，下面来说说特征工程的重要性。</p><hr><h2 id="2、特征工程的重要性"><a href="#2、特征工程的重要性" class="headerlink" title="2、特征工程的重要性"></a><strong>2、特征工程的重要性</strong></h2><p>OK！知道了特征工程是什么，那么我们必须要来了解下特征工程的重要性，为什么在实际工作中都要有特征工程这个过程，下面从不同的角度来分析一下。</p><p>首先，我们大家都知道，数据特征会直接影响我们模型的预测性能。你可以这么说：“选择的特征越好，最终得到的性能也就越好”。这句话说得没错，但也会给我们造成误解。事实上，<font color="green">你得到的实验结果取决于你选择的模型、获取的数据以及使用的特征，甚至你问题的形式和你用来评估精度的客观方法也扮演了一部分</font>。此外，你的实验结果还受到许多相互依赖的属性的影响，你需要的是能够很好地描述你数据内部结构的好特征。</p><p><strong>（1）特征越好，灵活性越强</strong></p><p>只要特征选得好，即使是一般的模型（或算法）也能获得很好的性能，因为大多数模型（或算法）在好的数据特征下表现的性能都还不错。<font color="red">好特征的灵活性在于它允许你选择不复杂的模型，同时运行速度也更快，也更容易理解和维护</font>。</p><p><strong>（2）特征越好，构建的模型越简单</strong></p><p>有了好的特征，即便你的参数不是最优的，你的模型性能也能仍然会表现的很nice，所以你就不需要花太多的时间去寻找最有参数，这大大的降低了模型的复杂度，使模型趋于简单。</p><p><strong>（3）特征越好，模型的性能越出色</strong></p><p>显然，这一点是毫无争议的，我们进行特征工程的最终目的就是提升模型的性能。</p><p>下面从特征的子问题来分析下特征工程。</p><hr><h2 id="3、特征工程子问题"><a href="#3、特征工程子问题" class="headerlink" title="3、特征工程子问题"></a><strong>3、特征工程子问题</strong></h2><p>大家通常会把特征工程看做是一个问题。事实上，在特征工程下面，还有许多的子问题，主要包括：Feature Selection（特征选择）、Feature Extraction（特征提取）和Feature construction（特征构造）.下面从这三个子问题来详细介绍。</p><h3 id="3-1-特征选择Feature-Selection"><a href="#3-1-特征选择Feature-Selection" class="headerlink" title="3.1 特征选择Feature Selection"></a><strong>3.1 特征选择Feature Selection</strong></h3><p>首先，从特征开始说起，假设你现在有一个标准的Excel表格数据，它的每一行表示的是一个观测样本数据，表格数据中的每一列就是一个特征。在这些特征中，有的特征携带的信息量丰富，有的（或许很少）则属于无关数据（irrelevant data），我们可以通过特征项和类别项之间的相关性（特征重要性）来衡量。比如，在实际应用中，常用的方法就是使用一些评价指标单独地计算出单个特征跟类别变量之间的关系。如Pearson相关系数，Gini-index（基尼指数），IG（信息增益）等，下面举Pearson指数为例，它的计算方式如下：</p><p>$$r_{xy}^2=(\frac{con(x,y)}{\sqrt{var(x)var(y)}})$$</p><p>其中，x属于X，X表一个特征的多个观测值，y表示这个特征观测值对应的类别列表。</p><p>Pearson相关系数的取值在0到1之间，如果你使用这个评价指标来计算所有特征和类别标号的相关性，那么得到这些相关性之后，你可以将它们从高到低进行排名，然后选择一个子集作为特征子集（比如top 10%），接着用这些特征进行训练，看看性能如何。此外，你还可以画出不同子集的一个精度图，根据绘制的图形来找出性能最好的一组特征。</p><p>这就是特征工程的子问题之一——特征选择，它的目的是<font color="red"><strong>从特征集合中挑选一组最具统计意义的特征子集，从而达到降维的效果</strong></font>。</p><p>做特征选择的原因是因为这些特征对于目标类别的作用并不是相等的，一些无关的数据需要删掉。做特征选择的方法有多种，上面提到的这种特征子集选择的方法属于filter（刷选器）方法，它主要侧重于单个特征跟目标变量的相关性。优点是计算时间上较高效,对于过拟合问题也具有较高的鲁棒性。缺点就是倾向于选择冗余的特征,因为他们不考虑特征之间的相关性,有可能某一个特征的分类能力很差，但是它和某些其它特征组合起来会得到不错的效果。另外做特征子集选取的方法还有wrapper（封装器）和Embeded(集成方法)。wrapper方法实质上是一个分类器，封装器用选取的特征子集对样本集进行分类，分类的精度作为衡量特征子集好坏的标准,经过比较选出最好的特征子集。常用的有逐步回归（Stepwise regression）、向前选择（Forward selection）和向后选择（Backward selection）。它的优点是考虑了特征与特征之间的关联性，缺点是：当观测数据较少时容易过拟合，而当特征数量较多时,计算时间又会增长。对于Embeded集成方法，它是学习器自身自主选择特征，如使用Regularization做特征选择，或者使用决策树思想，细节这里就不做介绍了。这里还提一下，在做实验的时候，我们有时候会用Random Forest和Gradient boosting做特征选择，本质上都是基于决策树来做的特征选择，只是细节上有些区别。</p><p>综上所述，特征选择过程一般包括产生过程，评价函数，停止准则，验证过程，这4个部分。如下图所示：</p><center> ![feature selection](/assets/images/feature selection.png)</center><p>(1) <strong>产生过程( Generation Procedure )</strong>：产生过程是搜索特征子集的过程，负责为评价函数提供特征子集。搜索特征子集的过程有多种，将在2.2小节展开介绍。<br>(2) <strong>评价函数( Evaluation Function )</strong>：评价函数是评价一个特征子集好坏程度的一个准则。<br>(3) <strong>停止准则( Stopping Criterion )</strong>：停止准则是与评价函数相关的，一般是一个阈值，当评价函数值达到这个阈值后就可停止搜索。<br>(4) <strong>验证过程( Validation Procedure )</strong> ：在验证数据集上验证选出来的特征子集的有效性。</p><h3 id="3-2-特征提取"><a href="#3-2-特征提取" class="headerlink" title="3.2 特征提取"></a><strong>3.2 特征提取</strong></h3><p>特征提取的子问题之二——特征提取。</p><p>原则上来讲，特征提取应该在特征选择之前。特征提取的对象是原始数据（raw data），它的目的是<font color="red"><strong>自动地构建新的特征，将原始特征转换为一组具有明显物理意义（Gabor、几何特征[角点、不变量]、纹理[LBP HOG]）或者统计意义或核的特征</strong></font>。比如通过变换特征取值来减少原始数据中某个特征的取值个数等。对于表格数据，你可以在你设计的特征矩阵上使用主要成分分析（Principal Component Analysis，PCA)来进行特征提取从而创建新的特征。对于图像数据，可能还包括了线或边缘检测。</p><p>常用的方法有：</p><ul><li>PCA (Principal component analysis，主成分分析)</li><li>ICA (Independent component analysis，独立成分分析)</li><li>LDA （Linear Discriminant Analysis，线性判别分析）</li></ul><p>对于图像识别中，还有SIFT方法。</p><h3 id="3-3-特征构建-Feature-Construction"><a href="#3-3-特征构建-Feature-Construction" class="headerlink" title="3.3 特征构建 Feature Construction"></a><strong>3.3 特征构建 Feature Construction</strong></h3><p>特征提取的子问题之二——特征构建。</p><p>在上面的特征选择部分，我们提到了对特征重要性进行排名。那么，这些特征是如何得到的呢？在实际应用中，显然是不可能凭空而来的，需要我们手工去构建特征。关于特征构建的定义，可以这么说：<font color="green"><strong>特征构建指的是从原始数据中人工的构建新的特征</strong></font>。我们需要人工的创建它们。这需要我们花大量的时间去研究真实的数据样本，思考问题的潜在形式和数据结构，同时能够更好地应用到预测模型中。</p><p>特征构建需要很强的洞察力和分析能力，要求我们能够从原始数据中找出一些具有物理意义的特征。假设原始数据是表格数据，一般你可以使用混合属性或者组合属性来创建新的特征，或是分解或切分原有的特征来创建新的特征。</p><hr><h2 id="4、特征工程处理过程"><a href="#4、特征工程处理过程" class="headerlink" title="4、特征工程处理过程"></a><strong>4、特征工程处理过程</strong></h2><p>那么问题来了，特征工程具体是在哪个步骤做呢？</p><p>具体的机器学习过程是这样的一个过程：</p><ul><li>1.Task before here</li><li>2.选择数据(Select Data): 整合数据，将数据规范化成一个数据集，收集起来.</li><li>3.数据预处理（Preprocess Data）: 数据格式化，数据清理，采样等.</li><li>4.数据转换（Transform Data）: <font color="red"><strong>这个阶段做特征工程</strong></font>.</li><li>5.数据建模（Model Data）: 建立模型，评估模型并逐步优化.</li><li>Tasks after here…</li></ul><p>我们发现，特征工程和数据转换其实是等价的。<font color="red"><strong>事实上，特征工程是一个迭代过程，我们需要不断的设计特征、选择特征、建立模型、评估模型，然后才能得到最终的model</strong></font>。下面是特征工程的一个迭代过程：</p><ul><li>1.头脑风暴式特征：意思就是进你可能的从原始数据中提取特征，暂时不考虑其重要性，对应于特征构建；</li><li>2.设计特征：根据你的问题，你可以使用自动地特征提取，或者是手工构造特征，或者两者混合使用；</li><li>3.选择特征：使用不同的特征重要性评分和特征选择方法进行特征选择；</li><li>4.评估模型：使用你选择的特征进行建模，同时使用未知的数据来评估你的模型精度。</li></ul><p>By the way, 在做feature selection的时候，会涉及到特征学习（Feature Learning），这里说下特征学习的概念，一般而言，特征学习（Feature Learning）是指学习输入特征和一个训练实例真是类别之间的关系。</p><p>下面举个例子来简单了解下特征工程的处理。</p><p>首先是来说下特征提取，假设你的数据里现在有一个颜色类别的属性，比如是“item_Color”,它的取值有三个，分别是：<em>red，blue，unknown</em>。从特征提取的角度来看，你可以将其转化成一个二值特征“<em>has_color</em>”，取值为1或0。其中1表示有颜色，0表示没颜色。你还可以将其转换成三个二值属性：<em>Is_Red, Is_Blue and Is_Unknown</em>。这样构建特征之后，你就可以使用简单的线性模型进行训练了。</p><p>另外再举一个例子，假设你有一个日期时间 (i.e. 2014-09-20T20:45:40Z)，这个该如何转换呢？</p><p>对于这种时间的数据，我们可以根据需求提取出多种属性。比如，如果你想知道某一天的时间段跟其它属性的关系，你可以创建一个数字特征“<strong>Hour_Of_Day</strong>”来帮你建立一个回归模型，或者你可以建立一个序数特征，“Part_Of_Day”,取值“<em>Morning,Midday,Afternoon,Night</em>”来关联你的数据。</p><p>此外，你还可以按星期或季度来构建属性，等等等等……</p><p>关于特征构建，主要是尽可能的从原始数据中构建特征，而特征选择，经过上面的分析，想必大家也知道了，其实就是达到一个降维的效果。</p><p>只要分析能力和实践能力够强，那么特征构建和特征提取对你而言就会显得相对比较简单，所以抓紧时间好好实践吧！</p><hr><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a><strong>Conclusion</strong></h2><p>恩。说了这么多，大家可能对特征工程、特征选择、特征提取和特征构建有点混乱了，下面来简单的做个总结：</p><p>首先来说说这几个术语：</p><ul><li>特征工程：利用数据领域的相关知识来创建能够使机器学习算法达到最佳性能的特征的过程。</li><li>特征构建：是原始数据中人工的构建新的特征。</li><li>特征提取：自动地构建新的特征，将原始特征转换为一组具有明显物理意义或者统计意义或核的特征。</li><li>特征选择：从特征集合中挑选一组最具统计意义的特征子集，从而达到降维的效果</li></ul><p>了解这几个术语的意思后，我们来看看他们之间的关系。</p><p>在Quora中有人这么说：</p><p>Feature engineering is a super-set of  activities which include feature extraction, feature construction and feature selection. Each of the three are important steps and none should be ignored. We could make a generalization of the importance though, from my experience the relative importance of the steps would be feature construction &gt; feature extraction &gt; feature selection.</p><p>用中文来说就是：<font color="green"><strong>特征工程是一个超集，它包括特征提取、特征构建和特征选择这三个子模块。在实践当中，每一个子模块都非常重要，忽略不得。根据答主的经验，他将这三个子模块的重要性进行了一个排名，即：特征构建&gt;特征提取&gt;特征选择。</strong></font></p><p>事实上，真的是这样，<font color="red"><strong>如果特征构建做的不好，那么它会直接影响特征提取，进而影响了特征选择，最终影响模型的性能</strong></font>。</p><p>OK！关于特征工程就到此为止吧，如果有纰漏的地方，还望多多指导！作为一枚行走在ML界的程序员，就让我们快乐的建模，快乐的做特征工程吧^_^！Happy coding, happy modeling！</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a><strong>References</strong></h2><ul><li><a href="https://www.quora.com/What-are-some-general-tips-on-feature-selection-and-engineering-that-every-data-scientist-should-know" target="_blank" rel="noopener">Neglected machine learning ideas</a></li><li><a href="http://blog.kaggle.com/2013/04/10/qa-with-xavier-conort/" target="_blank" rel="noopener">Q&amp;A with Xavier Conort</a></li><li><a href="https://www.quora.com/What-is-feature-engineering" target="_blank" rel="noopener">https://www.quora.com/What-is-feature-engineering</a></li><li><a href="https://en.wikipedia.org/wiki/Feature_engineering" target="_blank" rel="noopener">Feature_engineering-wikipedia</a></li><li><a href="http://machinelearningmastery.com/an-introduction-to-feature-selection/" target="_blank" rel="noopener">An Introduction to Feature Selection</a></li><li><a href="http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/" target="_blank" rel="noopener">Discover Feature Engineering, How to Engineer Features and How to Get Good at It</a></li><li><a href="https://www.quora.com/How-valuable-do-you-think-feature-selection-is-in-machine-learning-Which-do-you-think-improves-accuracy-more-feature-selection-or-feature-engineering" target="_blank" rel="noopener">How valuable do you think feature selection is in machine learning? Which do you think improves accuracy more, feature selection or feature engineering?</a></li></ul><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在这个振奋人心的程序员节日里，我决定认真地写一篇文章来纪念一下自己这长达六年程序员史。o(╯□╰)o&lt;/p&gt;
&lt;p&gt;本文是一篇关于特征工程的总结类文章，如有不足之处或理解有偏差的地方，还望多多指教。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="特征工程" scheme="https://www.csuldw.com/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>Windows下使用 git push 命令的无密码设置</title>
    <link href="https://www.csuldw.com/2015/10/21/2015-10-21%20Windows%20git%20push%20no%20password/"/>
    <id>https://www.csuldw.com/2015/10/21/2015-10-21 Windows git push no password/</id>
    <published>2015-10-21T08:45:44.000Z</published>
    <updated>2016-07-28T16:10:46.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在使用git时，每次进行git push时都需要输入用户名和密码，简直让人抓狂呀。下面介绍一种方法，可以避免用户名和密码输入，节省大量时间。</p><a id="more"></a><h2 id="1-添加环境变量"><a href="#1-添加环境变量" class="headerlink" title="1.添加环境变量"></a>1.添加环境变量</h2><p>首先在系统变量中添加一个环境变量HOME，内容为</p><figure class="highlight gcode"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HOME<span class="meta">%</span>USERPROFILE<span class="meta">%</span></span><br></pre></td></tr></tbody></table></figure><center>![配置环境变量](http://ww4.sinaimg.cn/large/637f3c58gw1exbx3roqvcj20bo0cadgy.jpg)</center><h2 id="2-新建配置文件"><a href="#2-新建配置文件" class="headerlink" title="2.新建配置文件"></a>2.新建配置文件</h2><p>由于使用的是Windows，所以进入%HOME%目录（如我的:C:\Users\username），新建一个名为”_netrc”的文件，文件中内容格式如下：</p><figure class="highlight css"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">machine</span> <span class="selector-tag">github</span><span class="selector-class">.com</span></span><br><span class="line"><span class="selector-tag">login</span> <span class="selector-tag">your-username</span></span><br><span class="line"><span class="selector-tag">password</span> <span class="selector-tag">your-password</span></span><br></pre></td></tr></tbody></table></figure><p>接着，打开git bash后，输入git push 命令就无需再输入用户名和密码了。</p><p>爽歪歪啦~</p><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在使用git时，每次进行git push时都需要输入用户名和密码，简直让人抓狂呀。下面介绍一种方法，可以避免用户名和密码输入，节省大量时间。&lt;/p&gt;
    
    </summary>
    
      <category term="GitHub" scheme="https://www.csuldw.com/categories/GitHub/"/>
    
    
      <category term="GitHub" scheme="https://www.csuldw.com/tags/GitHub/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-个人资料整理</title>
    <link href="https://www.csuldw.com/2015/09/23/2015-09-23%20Machine%20learning%20materials/"/>
    <id>https://www.csuldw.com/2015/09/23/2015-09-23 Machine learning materials/</id>
    <published>2015-09-23T14:22:22.000Z</published>
    <updated>2016-03-13T05:56:18.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>学习Machine Learning也有很长一段时间了，前段时间在paper中应用了GTB（Gradient Tree Boosting）算法。在我的数据集上GTB的performance比Random Forest要稍微强一点，整个experiment做完之后，有许多东西都来不及及时整理，很多都遗忘了。打算接下来的时间里，好好整理下自己的学习资料，这份资料绝对不是一时半会就整理得完的，先开个头吧，以后会间断性更新该blog的。</p><p>下面来做个资料整理吧。</p><a id="more"></a><h2 id="书籍推荐"><a href="#书籍推荐" class="headerlink" title="书籍推荐"></a><strong>书籍推荐</strong></h2><p>机器学习的书籍很多，下面推荐几本本人用过而且觉得还不错的书籍。优于机器学习是一门跨领域的学科，所以在书籍上并非全是机器学习的书籍:</p><ul><li>1.《机器学习实战》<strong>Machine Learning in Action [美] Peter Harington 著</strong>。该书贯穿了10个最受欢迎的机器学习算法，提供了案例研究问题并用Python代码实例来解决。我本人比较喜欢这本书，因为里面的代码给了我很大的帮助，自己在学习机器学习算法的时候，理论上很多东西不太理解透，通过该书实践之后，在算法层面又有了进一步的提高。</li><li>2.《统计学习方法》 李航著。该书比较详细地介绍了算法的原理，只从理论层面来研究算法。通过这本书和《机器学习实战》两本书相结合，一本讲理论，一本着手实践，加在一起会有事半功倍的效果。</li><li>3.《数据挖掘概念与技术》 韩家炜著。该书介绍了数据挖掘的常用技术，比较详实，但本人觉得不太适合初学者，当时自己初学的时候看的就是这本书，结果最后很多地方理解的不是很好，后来通过《统计学习方法》和算法实践之后，再回头看《数据挖掘概念与技术》，感觉就轻松多了。</li><li>4.《数学之美》 吴军著。本书可以当做业余书籍来看，可以在无聊的时候看看，不过里面讲的东西还是挺有用的。</li><li>5.《Python科学计算》该书可以当做Python编程参考书籍，但前提是你喜欢使用Python，并爱上了它，不然这本书还是蛮贵的，我自己也是通过“研究生自由探索项目”才买的这本书，因为可以报销嘛。</li></ul><h2 id="学习工具"><a href="#学习工具" class="headerlink" title="学习工具"></a><strong>学习工具</strong></h2><p>机器学习的tools很多，这里只列出几个参考工具。</p><ul><li><a href="http://scikit-learn.org/stable/user_guide.html" target="_blank" rel="noopener">Scikit-learn</a>.基于Python语言的<a href="http://scikit-learn.org/stable/user_guide.html" target="_blank" rel="noopener">scikit-learn</a>库，里面涵盖了分类、聚类、回归的大部分算法，并且有常用的评估指标以及预处理数据的方法，是一个不错的学习库，强力推荐。附一篇博文：<a href="http://www.erogol.com/broad-view-machine-learning-libraries/" target="_blank" rel="noopener">SOME USEFUL MACHINE LEARNING LIBRARIES</a>.</li><li><a href="http://www.r-project.org/" target="_blank" rel="noopener">R</a>语言，语言就是一门工具，R语言现在在商业界是用的最多的，在统计方面功能强大，而且也有封装好的算法库可以直接使用。附：<a href="https://cran.r-project.org/doc/contrib/Liu-R-refcard.pdf" target="_blank" rel="noopener">R语言参考卡片</a>.</li><li><a href="http://www.cs.waikato.ac.nz/ml/weka/" target="_blank" rel="noopener">Weka</a>，是一个基于java开发的数据挖掘工具，可以尝试一下。它为用户提供了一系列据挖掘API、命令行和图形化用户接口。你可以准备数据、可视化、建立分类、进行回归分析、建立聚类模型，同时可以通过第三方插件执行其他算法。除了WEKA之外， <a href="http://mahout.apache.org/" target="_blank" rel="noopener">Mahout</a>是Hadoop中为机器学习提供的一个很好的JAVA框架，你可以自行学习。如果你是机器学习和大数据学习的新手，那么坚持学习WEKA，并且全心全意地学习一个库。</li><li>Matlab，里面有很多的工具包，不过本人不怎么用过。参考：<a href="http://www.cad.zju.edu.cn/home/dengcai/Data/data.html" target="_blank" rel="noopener">Matlab Codes and Datasets for Feature Learning</a>和<a href="http://cn.mathworks.com/products/statistics/" target="_blank" rel="noopener">Statistics and Machine Learning Toolbox</a>。此外matlab中的<a href="http://www.gnu.org/software/octave/" target="_blank" rel="noopener">Octave</a>可以很方便地解决线性和非线性问题，比如机器学习算法底层涉及的问题。如果你有工程背景，那么你可以由此入手。</li><li><a href="https://bigml.com/" target="_blank" rel="noopener">BigML</a>:可能你并不想进行编程工作。你完全可以不通过代码，来使用 WEKA那样的工具。你通过使用BigMLS的服务来进行更加深入的工作。BigML通过Web页面，提供了机器学习的接口，因此你可以通过浏览器来建立模型。</li><li>如果你使用Python，这里推荐一个IDE，<a href="http://sourceforge.net/projects/winpython/files/WinPython_2.7/2.7.10.1/" target="_blank" rel="noopener">WinPython</a>,IDE版本就是Python的版本，自行选择！</li></ul><p>下面给出一个比较图，具体想要学什么，还需自己抉择。</p><center>![这里写图片描述](http://img.blog.csdn.net/20150918075645450)</center><h2 id="学习视频"><a href="#学习视频" class="headerlink" title="学习视频"></a><strong>学习视频</strong></h2><p>由于本人比较崇拜Andrew Ng，所以关于视频，首先推荐的便是Andrew Ng的斯坦福大学的机器学习课程。这套视频在网上有两个网址，国外和国内的都有，全程英语教学，内容很好，有时间建议你去听听：</p><ul><li>一个是国外的Coursera公开课，该课程在机器学习领域很火，是很多入门学者的首选。地址：<a href="https://www.coursera.org/；讲义地址：[Stanford" target="_blank" rel="noopener">https://www.coursera.org/；讲义地址：[Stanford</a> CS229 course下载讲义和笔记](<a href="http://cs229.stanford.edu/)；" target="_blank" rel="noopener">http://cs229.stanford.edu/)；</a></li><li>一个是国内的网易公开课，链接地址：<a href="http://open.163.com/movie/2008/1/U/O/M6SGF6VB4_M6SGJURUO.html" target="_blank" rel="noopener">http://open.163.com/movie/2008/1/U/O/M6SGF6VB4_M6SGJURUO.html</a></li></ul><p>下面是一个机器学习视频库，由加州理工学院（Caltech）出品。</p><ul><li>机器学习视频库，地址：<a href="http://work.caltech.edu/library/" target="_blank" rel="noopener">http://work.caltech.edu/library/</a></li></ul><p>其它的视频库</p><ul><li><a href="http://videolectures.net/Top/Computer_Science/Machine_Learning/" target="_blank" rel="noopener">Machine Learning Category on VideoLectures</a>，这个网站的视频比较多。你可以找出比较感兴趣的资源，然后深入学习。</li></ul><p><font color="#008B00">机器学习最近在国内比较火，许多培训机构都相应的开了该门课程，如果想要听中文教程的，可以去网上搜索下，这里就不给培训机构打广告了。</font></p><h2 id="博客和文章推荐"><a href="#博客和文章推荐" class="headerlink" title="博客和文章推荐"></a><strong>博客和文章推荐</strong></h2><p>大牛们的博客，会让你感到兴奋，让你觉得你不是一个人在奋斗，让你时刻记住你的前方已经有很多的学者正在等着你，你要加油。他们的经验会让我们少走些冤枉路，能让我们在他们的基础上进一步理解。下面推荐几个我所知道的或者说我了解到的几位牛人博客和几篇文章：</p><ul><li><strong>pluskid</strong>，真名张弛原，一位技术大牛，毕业于浙江大学，后来出国深造。他的博文质量非常高，深入浅出，其SVM三层境界的讲解让人茅塞顿开，应该给了很多人启发吧，很值得学习。现在的博客网址：<a href="http://pluskid.org/about.html" target="_blank" rel="noopener">Chiyuan Zhang</a>，原博客网址：<a href="http://blog.pluskid.org/" target="_blank" rel="noopener">Chiyuan Zhang</a></li><li><strong>Rachel Zhang</strong>，真名张睿卿，很有气质的一位软妹纸，目前是百度深度学习实验室研发工程师，在CSDN中的博客人气绝对屈指可数，算是IT界的一位女中豪杰。博客网址：<a href="http://blog.csdn.net/abcjennifer" target="_blank" rel="noopener">CSDN博客-Rachel Zhang</a></li><li><strong>July</strong>，对算法研究独具一格，目前是七月在线科技创始人兼CEO。博客网址：<a href="http://blog.csdn.net/v_JULY_v" target="_blank" rel="noopener">July</a></li><li><strong>Jason</strong>，一位国外机器学习爱好者，其博客内容详实，多篇文章被国内机器学习者翻译。博客网址：<a href="http://machinelearningmastery.com/blog/" target="_blank" rel="noopener">http://machinelearningmastery.com/blog/</a></li><li>一个国外很好的机器学习博客，里面介绍了详细的算法知识，很全面，从感知机、神经网络、决策树、SVM、Adaboost到随机森林、Deep Learning.网址：<a href="http://www.erogol.com/machine-learning/" target="_blank" rel="noopener">A Blog From a Human-engineer-being</a></li><li>一篇涵盖许多机器学习资料的文章：<a href="http://www.open-open.com/lib/view/open1428112201271.html" target="_blank" rel="noopener">机器学习(Machine Learning)&amp;深度学习(Deep Learning)资料</a></li><li><strong>Edwin Chen</strong>    ，机器学习爱好者，博客内容涵盖数学、机器学习和数据科学。分享其中一篇博文：<a href="http://blog.echen.me/2011/04/27/choosing-a-machine-learning-classifier/" target="_blank" rel="noopener">Choosing a Machine Learning Classifier</a>    </li><li>一篇以前的博文：<a href="http://conductrics.com/data-science-resources/" target="_blank" rel="noopener">A List of Data Science and Machine Learning Resources</a>，有时间好好阅读阅读，对你绝对有帮助。</li><li><a href="http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf" target="_blank" rel="noopener">A Few Useful Things to Know about Machine Learning</a>,一篇很有帮助的机器学习文章，里面包括了特征选择与模型的简化。</li><li><a href="http://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf" target="_blank" rel="noopener">The Discipline of Machine Learning</a>机器学习规则。该文章比较老，2006年发布的，作者是Tom Mitchell，但很有参考价值，其中定义了机器学习的规则。Mitchell在说服CMU总裁为一个百年内都存在的问题建立一个独立的机器学习部门时，也用到了这本书中的观点。希望能对你也有所帮助。</li><li>分享一个网站：<a href="http://www.jianshu.com/" target="_blank" rel="noopener">简书</a>。</li></ul><h2 id="国外网站"><a href="#国外网站" class="headerlink" title="国外网站"></a><strong>国外网站</strong></h2><p>如果你想搜索比较新颖的机器学习资料或是文章，可以到以下网站中搜索，里面不仅包括了机器学习的内容，还有许多其它相关领域内容，如数据科学和云计算等。</p><ul><li>InfoWord：<a href="http://www.infoworld.com/reviews/" target="_blank" rel="noopener">http://www.infoworld.com/reviews/</a></li><li>Kdnuggets：<a href="http://www.kdnuggets.com" target="_blank" rel="noopener">http://www.kdnuggets.com</a></li><li>Datasciencecentral：<a href="http://www.datasciencecentral.com/" target="_blank" rel="noopener">http://www.datasciencecentral.com/</a></li><li>Datascienceplus：<a href="http://datascienceplus.com" target="_blank" rel="noopener">http://datascienceplus.com</a></li></ul><h2 id="数据科学竞赛"><a href="#数据科学竞赛" class="headerlink" title="数据科学竞赛"></a><strong>数据科学竞赛</strong></h2><p>关于数据分析的竞赛，国内国外都有，下面推荐几个比较火的竞赛网站 ：</p><ul><li>Kaggle比赛，网址：<a href="https://www.kaggle.com/" target="_blank" rel="noopener">https://www.kaggle.com/</a></li><li>DataCastle比赛，网站：<a href="http://www.pkbigdata.com/" target="_blank" rel="noopener">http://www.pkbigdata.com/</a></li><li>阿里大数据竞赛，目前没有消息了，2015年有个【2015天池大数据竞赛】</li></ul><h2 id="ML相关算法参考"><a href="#ML相关算法参考" class="headerlink" title="ML相关算法参考"></a><strong>ML相关算法参考</strong></h2><ul><li>决策树-参考：<a href="http://blog.csdn.net/dream_angel_z/article/details/45965463" target="_blank" rel="noopener">decision Tree（Python实现）</a></li><li>SVM支持向量机-参考：<a href="http://blog.pluskid.org/?page_id=683" target="_blank" rel="noopener">pluskid支持向量机三重境界</a></li><li>Adaboost-参考：<a href="http://www.csuldw.com/2015/07/05/2015-07-12-Adaboost/">组合算法-Adaboost</a></li><li>Random Forest-参考：<a href="http://www.cnblogs.com/wentingtu/archive/2011/12/22/2297405.html" target="_blank" rel="noopener">随机森林算法</a></li><li>朴素贝叶斯算法-参考：<a href="http://blog.csdn.net/dream_angel_z/article/details/46120867" target="_blank" rel="noopener">Naive Bayes算法实现</a></li><li>人工神经网络-参考：<a href="http://www.cnblogs.com/luxiaoxun/archive/2012/12/10/2811309.html" target="_blank" rel="noopener">http://www.cnblogs.com/luxiaoxun/archive/2012/12/10/2811309.html</a></li><li>Apriori算法-参考地址：<a href="http://www.csuldw.com/2015/06/04/2015-06-04-Apriori/">Apriori关联分析</a></li><li>K最近邻算法-参考：<a href="http://blog.csdn.net/dream_angel_z/article/details/45896449" target="_blank" rel="noopener">KNN从原理到实现</a></li><li>梯度树提升GTB算法-参考：<a href="http://blog.csdn.net/dream_angel_z/article/details/48085889" target="_blank" rel="noopener">Gradient Tree Boosting（或GBRT）</a></li><li>K-means聚类-参考：<a href="http://blog.csdn.net/dream_angel_z/article/details/46343597" target="_blank" rel="noopener">K-means cluster</a></li><li>组合算法总结-参考：<a href="http://www.csuldw.com/2015/07/22/2015-07-22%20%20ensemble/">Ensemble算法总结</a></li><li>EM期望最大算法-参考：<a href="http://blog.csdn.net/zouxy09/article/details/8537620" target="_blank" rel="noopener">EM算法</a></li><li>Logistic回归-参考：<a href="http://blog.csdn.net/wangran51/article/details/8892923" target="_blank" rel="noopener">逻辑回归</a></li><li>HMM隐马尔可夫模型，参考:<a href="http://blog.csdn.net/likelet/article/details/7056068" target="_blank" rel="noopener">HMM</a></li><li>条件随机场，参考：<a href="http://www.tanghuangwhu.com/archives/162" target="_blank" rel="noopener">CRF</a></li><li>随机森林和GBDT，参考：<a href="http://www.cnblogs.com/LeftNotEasy/archive/2011/03/07/1976562.html" target="_blank" rel="noopener">决策树模型组合之随机森林与GBDT</a></li><li>特征选择和特征提取，参考：<a href="http://blog.csdn.net/lanbing510/article/details/40488787" target="_blank" rel="noopener">特征提取与特征选择</a></li><li>梯度下降法，参考:<a href="http://blog.csdn.net/woxincd/article/details/7040944" target="_blank" rel="noopener">gradient descent</a></li><li>牛顿法，参考：<a href="http://blog.csdn.net/luoleicn/article/details/6527049" target="_blank" rel="noopener">牛顿法</a></li><li>线性判别分析，参考：<a href="http://www.cnblogs.com/jerrylead/archive/2011/04/21/2024384.html" target="_blank" rel="noopener">线性判别</a></li><li>深度学习-<a href="http://www.cnblogs.com/xiaowanyer/p/3701944.html" target="_blank" rel="noopener">深度学习概述：从感知机到深度网络</a></li></ul><h2 id="个人译文"><a href="#个人译文" class="headerlink" title="个人译文"></a><strong>个人译文</strong></h2><p>下面是本人在CSDN云计算栏目发布的翻译文章，如有翻译不准确的地方，还望多多包涵，希望能给大家带来点帮助，译文列表如下：</p><ul><li>2015-09-14 <a href="http://www.csdn.net/article/2015-09-14/2825693" target="_blank" rel="noopener">LSTM实现详解</a></li><li>2015-09-10 <a href="http://www.csdn.net/article/2015-09-08/2825646" target="_blank" rel="noopener">从零实现来理解机器学习算法：书籍推荐及障碍的克服</a></li><li>2015-08-31  <a href="http://www.csdn.net/article/2015-08-27/2825551" target="_blank" rel="noopener">机器学习开发者的现代化路径：不需要从统计学微积分开始</a></li><li>2015-08-27 <a href="http://www.csdn.net/article/2015-08-27/2825549" target="_blank" rel="noopener">基于Python的卷积神经网络和特征提取</a></li><li>2015-08-20 <a href="http://www.csdn.net/article/2015-08-19/2825492" target="_blank" rel="noopener">你应该掌握的七种回归技术</a></li><li>2015-08-11 <a href="http://www.csdn.net/article/2015-08-10/2825430" target="_blank" rel="noopener">机器学习API Top 10：AT&amp;T Speech、IBM Watson和Google Prediction</a></li><li>2015-08-03 <a href="http://www.csdn.net/article/2015-08-01/2825362" target="_blank" rel="noopener">从Theano到Lasagne：基于Python的深度学习的框架和库</a></li><li>2015-07-15 <a href="http://www.csdn.net/article/2015-07-13/2825188" target="_blank" rel="noopener">Airbnb欺诈预测机器学习模型设计：准确率和召回率的故事</a></li><li>2015-07-13 <a href="http://www.csdn.net/article/2015-07-13/2825187" target="_blank" rel="noopener">开发者成功使用机器学习的十大诀窍</a></li></ul><p>下面是相关译者的译文，仅供参考：</p><ul><li>2015-09-16 <a href="http://www.csdn.net/article/2015-09-15/2825714" target="_blank" rel="noopener">各种编程语言的深度学习库整理</a></li><li>2015-09-11 <a href="http://www.csdn.net/article/2015-09-08/2825647" target="_blank" rel="noopener">机器学习温和指南</a></li><li>2015-09-10 <a href="http://www.csdn.net/article/2015-09-10/2825668" target="_blank" rel="noopener">关于数据科学，书上不曾提及的三点经验</a></li></ul><hr><p><font color="#CD3333">从这些牛人的博客中，你能学到很多。慢慢地你会体会到，不是你一个人在战斗，还有很多人，所以你不用害怕孤独。</font></p><p>最后，关于机器学习资料的整理，先到此为止吧，如果你有什么好的资料，欢迎在评论中给出推荐或网址链接。</p><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;学习Machine Learning也有很长一段时间了，前段时间在paper中应用了GTB（Gradient Tree Boosting）算法。在我的数据集上GTB的performance比Random Forest要稍微强一点，整个experiment做完之后，有许多东西都来不及及时整理，很多都遗忘了。打算接下来的时间里，好好整理下自己的学习资料，这份资料绝对不是一时半会就整理得完的，先开个头吧，以后会间断性更新该blog的。&lt;/p&gt;
&lt;p&gt;下面来做个资料整理吧。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Gradient Tree Boosting Algorithm</title>
    <link href="https://www.csuldw.com/2015/08/19/2015-08-19%20GBDT/"/>
    <id>https://www.csuldw.com/2015/08/19/2015-08-19 GBDT/</id>
    <published>2015-08-19T02:54:00.000Z</published>
    <updated>2017-05-13T02:35:22.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在机器学习各大算法中，决策树这种算法有着很多良好的特性，其现有的特点就有训练的时间复杂度$Omega$较低，对新样本预测的过程比较快，同时模型容易展示（容易将得到的决策树做成图片展示出来）等。但与此同时，单决策树又有一些不好的地方，比如说容易over-fitting。虽然目前有一些方法，比如剪枝可以减少这种over-fitting的程度，但结果还是不太理想。</p><a id="more"></a><p>与决策树相关的ensemble model（比如说有Boosting，Bagging等）算法比较多，比如RandomForest、Adaboost、GBRT等，这些算法最终的结果是生成$N$($N$的取值有可能成百上千）棵树，这样得到的最终模型可以大大减少单个决策树带来的缺陷。换言之，集成算法有点类似于“三个臭皮匠赛过一个诸葛亮”的做法。虽然这几百棵决策树中的每一棵都很简单（相对于C4.5这种单决策树而言），但将他们组合起来之后就能达到非常不错的模型。另外，值得注意的是，虽然这些算法都是由决策树演变而来，但不同的集成模型在训练的细节上伴有一些差异，在文章后面会对这些算法做一个本质的对比。下面先来讲解下本文的核心内容——Gradient Tree Boosting。</p><h2 id="Introduction-to-Gradient-Tree-Boosting"><a href="#Introduction-to-Gradient-Tree-Boosting" class="headerlink" title="Introduction to Gradient Tree Boosting"></a><strong>Introduction to Gradient Tree Boosting</strong></h2><p>Gradient Tree Boosting 算法最初是FreidMan在2000年提出来的，是一种集成算法（或是组合算法）。该算法的名字可以说是千奇百态，有叫GBRT（gradient boosting regression tree），也有说成GBM、GBDT的。它的base learners是决策树，既可以用来训练regression model，也可以用做classification。在分类性能上，能够和random forest媲美，甚至在有的dataset上表现的有过之而无不及。如今，Gradient Tree Boosting模型还广泛地运用在Web搜索排行榜以及生态学上，所以值得我们去花点时间认真学习。根据scikit-learn官网的介绍，GTB的优势有以下三大点：</p><ul><li>自然而然地处理混合类型的数据；</li><li>预测能力强；</li><li>在输出空间对于异常值的鲁棒性强（通过强大的损失函数）。</li></ul><p>然而，也存在一些劣势：</p><ul><li>可扩展性方面，由于提升的时序性，不能进行并行处理。</li></ul><p>尽管如此，由于gradient tree boosting algorithm的表现性能很好，所以受到广大业界人士的青睐。下面来介绍下梯度提升树的算法原理。</p><h2 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a><strong>算法原理</strong></h2><p>gradient tree boosting 算法的核心在于，它的每棵树都是从上一次训练的所有树的残差中进行学习，进而拟合一棵回归（分类）树。<br>。在训练的时候，残差近似等于当前模型中损失函数的负梯度值，公式如下：</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24%20r_%7Bmi%7D%20%3D%20-%20%5CBigg%20%5B%20%5Cfrac%20%7B%5Cpartial%20L%28y_i%2C%20f%20%28x_i%29%29%7D%7B%5Cpartial%20f%20%28x_i%29%7D%5CBigg%20%5D%20_%7Bf%20%28x%29%20%3D%20f%20_%7Bm-1%7D%28x%29%7D%24%24" alt=""></p><p>gradient boosting是boosting算法的一种，也可以说是Boosting算法的一种改进，原始的Boosting算法（Adaboost）是：在算法初始化阶段，为每一个样本赋予一个相等的weight，换言之，每个样本在开始都是一样重要的。接下来，每一次训练后得到的模型，对数据点的估计会有所差异，所以在每一步结束后，我们需要对weight进行处理，而处理的方式就是通过增加错分类的样本点的weight，同时减少分类正确的样本点的weight。这样能够确保，如果某些点经常被分错，那么就会被“严重关注”，也就会被赋予一个很高的weight。然后等进行了$N$次迭代（迭代次数由用户指定），将会得到$N$个简单的base learner，最后将它们组合起来，可以对它们进行加权（错误率越大的base learner 其权重值越小，错误率越小的基分类器权重值越大）、或者让它们进行投票等得到一个最终的模型。</p><p>gradient boosting与传统的boosting有着很大的区别，它的每一次计算都是为了减少上一次的 residual，而为了减少这些residual，它会在residual减少的gradient方向上建立一个新的 model。所以说，在gradient boosting algorithm中，新model建立的目的是为了使先前模型的残差往梯度方向减少，与传统的boosting算法对正错样本赋予不同加权的做法有着极大的区别。</p><p>gtb算法理论的核心包括三大点：</p><ol><li>regression tree</li><li>gradient descent</li><li>boosting - Shrinkage</li></ol><h3 id="gradient-tree-boosting-algorithm-Regression"><a href="#gradient-tree-boosting-algorithm-Regression" class="headerlink" title="gradient tree boosting algorithm - Regression"></a><strong>gradient tree boosting algorithm - Regression</strong></h3><p>对于给定的输入：训练数据集 $T={(x_1,y_1),(x_2,y_2),…,(x_n,y_n)},损失函数$L(y,f(x))$;<br>输出结果：一棵回归树$\tilde{f}(x)$</p><p>（1）首先初始化</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24f_0%28x%29%3D%5Carg%20%5C%20%5Cmin_c%20%5Csum_%7Bi%3D1%7D%5E%7BN%7DL%28y_i%2C%20c%29%24%24" alt="$$f_0(x)=\arg \ \min_c \sum_{i=1}^{N}L(y_i, c)$$"></p><p>建立一个model，估计一个使loss function 极小化的常数值，此时的model是一个只有一个节点的树；</p><p>（2）迭代的建立M棵boosting tree</p><p>$for m=1 to M:$（第一层循环开始）<br>$for i=1 to N:$（第二层循环1） 计算loss function 的negative gradient在当前model的值，并将它作为residual的估计值。</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24%20r_%7Bmi%7D%20%3D%20-%20%5CBigg%20%5B%20%5Cfrac%20%7B%5Cpartial%20L%28y_i%2C%20f%20%28x_i%29%29%7D%7B%5Cpartial%20f%20%28x_i%29%7D%5CBigg%20%5D%20_%7Bf%20%28x%29%20%3D%20f%20_%7Bm-1%7D%28x%29%7D%24%24" alt=""></p><p>接着，对于$r_{mi}$拟合一棵回归树，得到第$m$棵树的叶节点区域 $c_{mj} ,j=1,2,…,J$</p><p>$for j=1 to J:$（第二层循环2）,计算：</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24c_%7Bmj%7D%20%3D%20arg%20min_c%20%5Csum_%7Bx_i%5Cepsilon%20R_%7Bmj%7D%7DL%28y_i%2Cf_%7Bm-1%7D%28x_i%29+c%29%24%24" alt=""></p><p>利用线性搜索估计叶节点区域的值，使损失函数极小化；</p><p>然后，更新</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24f_%7Bm%7D%28x%29%20%3D%20f_%7Bm-1%7D%28x%29%20+%20%5Csum_%7Bj%3D1%7D%5EJc_%7Bmj%7DI%28x%20%5Cepsilon%20R_%7Bmj%7D%29%24%24" alt=""></p><p>（3）最后得到的$f_{m}(x)$就是我们最终的模型</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24%5Ctilde%7Bf%7D%28x%29%3Df_M%28x%29%3D%5Csum_%7Bm%3D1%7D%5EM%5Csum_%7Bj%3D1%7D%5EJc_%7Bmj%7DI%28x%20%5Cepsilon%20R_%7Bmj%7D%29%24%24" alt=""></p><p>从式子中可以看出，gradient tree boosting algorithm 本质上是一个加和模型，并在推导中结合了前向分步算法。</p><hr><h2 id="scikit-learn中的GTB"><a href="#scikit-learn中的GTB" class="headerlink" title="scikit-learn中的GTB"></a><strong>scikit-learn中的GTB</strong></h2><p>在scikit-learn中对GTB算法有了很好的封装，对于分类可以选择的损失函数有逻辑回归和指数函数，对于回归的损失函数相对比较多，有最小二乘法、最小绝对偏差函数、huber以及分位数等。</p><p>下面是sklearn中的一个分类原例：</p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; from sklearn.datasets import make_hastie_10_2</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; from sklearn.ensemble import GradientBoostingClassifier</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; X, y = make_hastie_10_2(random_state=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; X_train, X_test = X[<span class="symbol">:</span><span class="number">2000</span>], X[<span class="number">2000</span><span class="symbol">:</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; y_train, y_test = y[<span class="symbol">:</span><span class="number">2000</span>], y[<span class="number">2000</span><span class="symbol">:</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; clf = GradientBoostingClassifier(n_estimators=<span class="number">100</span>, learning_rate=<span class="number">1.0</span>,</span><br><span class="line">...     max_depth=<span class="number">1</span>, random_state=<span class="number">0</span>).fit(X_train, y_train)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; clf.score(X_test, y_test)                 </span><br><span class="line"><span class="number">0</span>.<span class="number">913</span>...</span><br></pre></td></tr></tbody></table></figure><p>其中$n_estimators$表示弱分类器的个数，$learning_rate$表示学习率，$max_depth$表示树的最大深度等。GTB的参数比较多，在实际应用中需要自己去调整合适的参数。</p><h2 id="A-comparison-of-ensemble-algorithms"><a href="#A-comparison-of-ensemble-algorithms" class="headerlink" title="A comparison of ensemble algorithms"></a><strong>A comparison of ensemble algorithms</strong></h2><p>基于决策树的组合算法常用的有三个，分别是Adaboost、RandomFrest以及本文的GBRT。</p><p>Adaboost是通过迭代的学习每一个基分类器，每次迭代中，把上一次错分类的数据权值增大，正确分类的数据权值减小，然后将基分类器的线性组合作为一个强分类器，同时给分类误差率较小的基本分类器以大的权值，给分类误差率较大的基分类器以小的权重值。Adaboost使用的是自适应的方法，其中概率分布式变化的，关注的是难分类的样本。详细内容请参考之前的文章：<a href="http://www.csuldw.com/2015/07/05/2015-07-05-ML-algorithm-Adaboost/">机器学习算法-Adaboost</a>。</p><p>Random Forest与adaboost有些区别，可以说一种改进的bagging算法。Random Forest不仅对样本进行sampling，还对feature进行sampling。它通过随机的方式建立一个森林，森林里面有许多棵决策树，并且每一棵树之间是没有联系的。在得到森林之后，当有一个新的input sample进来的时候，就让森林中的每一棵决策树分别对其进行判断，看这个样本应该属于哪一类（就分类算法而言），然后看看哪一类选择最多（随机森林使用到的是 vote方式），就预测这个样本为该class。在建立每一棵决策树的过程中，有两点需要注意，即<strong>采样</strong>与<strong>完全分裂</strong>。首先是两个随机采样的过程，random forest对输入的数据要进<strong>行采样</strong>和<strong>列采样</strong>。对于行采样，是采用有放回的方式，即bootstrap sampling，也就是在采样得到的样本集合中，可能有重复的样本。举个例子，假设输入样本为$N$个，那么采样的样本也为$N$个。这样使得在训练的时候，每一棵树的输入样本都不是全部的样本，从某种程度上讲，相对不容易出现over-fitting。其次就是列采样，这个过程是从$M$个feature中，选择$m$个($m &lt;&lt; M$)。之后就是对采样之后的数据使用<strong>完全分裂</strong>的方式建立决策树模型。最后得到的决策树，它的某一个叶子节点要么是无法继续分裂的，要么里面的所有样本的都是指向的同一类别。一般很多的决策树算法都一个重要的步骤-Pruning（剪枝），但是random forest并不这样干，由于之前的两个随机采样的过程保证了样本的随机性，所以替代了Pruning这个工作，也不太容易出现over-fitting。按照这种算法得到的random forest中的每一棵决策树都是非常弱的，但是当你把它们组合在一起的时候，就得对它刮目相看了。random forest可以这样来形容：每一棵决策树就是一个精通于某一领域的专家（因为我们从$M$个feature set中选择$m$个sub set让每一棵决策树进行学习），这样在random forest中就有了很多个精通不同领域的专家，对一个新的问题（input data），可以用不同的角度去看待它，最终由各个专家投票得到结果。random forest的分类准确率可以与adaboost媲美，但它对<a href="http://sci2s.ugr.es/noisydata" target="_blank" rel="noopener">noise data</a>更加鲁棒，运行速度比adaboost也快得多。</p><p>另外，random forest是可以实现并行化的，而adaboost无法并行。同时，random forest等bagging算法其本质是降variance的，而adaboost等boosting算法其实降的是bias。</p><p>最后，<strong>对于gradient tree boosting algorithm，它的每一次计算都是为了减少上一次训练模型的residual，而为了减少这些残差，可以在残差减少的梯度(Gradient)方向上建立一个新模型。</strong>这与adaboost和随机森林还是有很大区别的。</p><h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><ul><li><a href="https://statweb.stanford.edu/~jhf/ftp/trebst.pdf" target="_blank" rel="noopener">Greedy Function Approximation: A Gradient Boosting Machine</a></li><li><a href="http://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting" target="_blank" rel="noopener">Scikit-learn - GRADIENT BOOSTING</a></li><li><a href="https://www.quora.com/What-is-the-basic-difference-between-noise-and-outliers-in-Data-mining" target="_blank" rel="noopener">What-is-the-basic-difference-between-noise-and-outliers-in-Data-mining</a></li><li><a href="http://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/slides/gradient_boosting.pdf" target="_blank" rel="noopener">PPT - A Gentle Introduction to Gradient Boosting</a></li><li><a href="https://www.cs.princeton.edu/courses/archive/spring12/cos598A/slides/intro.pdf" target="_blank" rel="noopener">PPT - Boosting: Foundations and Algorithms</a></li><li><a href="http://people.csail.mit.edu/torralba/courses/6.869/lectures/lecture6/boosting.pdf" target="_blank" rel="noopener">Additive Logistic Regression: a Statistical View of<br>Boosting</a></li></ul><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在机器学习各大算法中，决策树这种算法有着很多良好的特性，其现有的特点就有训练的时间复杂度$Omega$较低，对新样本预测的过程比较快，同时模型容易展示（容易将得到的决策树做成图片展示出来）等。但与此同时，单决策树又有一些不好的地方，比如说容易over-fitting。虽然目前有一些方法，比如剪枝可以减少这种over-fitting的程度，但结果还是不太理想。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="组合算法" scheme="https://www.csuldw.com/tags/%E7%BB%84%E5%90%88%E7%AE%97%E6%B3%95/"/>
    
      <category term="GBDT" scheme="https://www.csuldw.com/tags/GBDT/"/>
    
  </entry>
  
  <entry>
    <title>从Theano到Lasagne：基于Python的深度学习的框架和库（译文）</title>
    <link href="https://www.csuldw.com/2015/08/12/2015-08-12-theano-to-lasagne/"/>
    <id>https://www.csuldw.com/2015/08/12/2015-08-12-theano-to-lasagne/</id>
    <published>2015-08-12T12:24:00.000Z</published>
    <updated>2017-03-10T06:28:30.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>英文链接：<a href="http://creative-punch.net/2015/07/frameworks-and-libraries-for-deep-learning/" target="_blank" rel="noopener">http://creative-punch.net/2015/07/frameworks-and-libraries-for-deep-learning/</a></p><p>深度学习是机器学习和人工智能的一种形式，利用堆积在彼此顶部的神经网络的多个隐藏层来尝试形成对数据更深层次的“理解”。</p><p>最近，深度神经网络以“Deep Dreams”形式在网站中如雨后春笋般出现，或是像谷歌研究原创论文中描述的那样：Inceptionism。</p><p>在这篇文章中，我们将讨论几个不同的深度学习框架，库以及工具。</p><a id="more"></a><h2 id="Python深度学习"><a href="#Python深度学习" class="headerlink" title="Python深度学习"></a>Python深度学习</h2><h3 id="Theano"><a href="#Theano" class="headerlink" title="Theano"></a>Theano</h3><p>主页：<a href="http://deeplearning.net/software/theano/" target="_blank" rel="noopener">http://deeplearning.net/software/theano/</a></p><p>Github网址：<a href="https://github.com/Theano/Theano" target="_blank" rel="noopener">https://github.com/Theano/Theano</a></p><p>Theano不仅是这篇文章中将要讨论的其他框架的核心库，于其自身而言，它也是一个强大的库，几乎能在任何情况下使用，从简单的logistic回归到建模并生成音乐和弦序列或是使用长短期记忆人工神经网络对电影收视率进行分类。</p><p>Theano大部分代码是使用Cython编写，Cython是一个可编译为本地可执行代码的Python方言，与仅仅使用解释性Python语言相比，它能够使运行速度快速提升。最重要的是，很多优化程序已经集成到Theano库中，它能够优化你的计算量并让你的运行时间保持最低。</p><p>如果速度的提升还不能满足你，它还内置支持使用CUDA在GPU上执行那些所有耗时的计算。所有的这一切仅仅只需要修改配置文件中的标志位即可。在CPU上运行一个脚本，然后切换到GPU，而对于你的代码，则不需要做任何变化。</p><p>同时我们应该注意到，尽管Theano使用Cython和CUDA对其性能大大提升，但你仍然可以仅仅使用Python语言来创建几乎任何类型的神经网络结构。</p><h3 id="Pylearn2"><a href="#Pylearn2" class="headerlink" title="Pylearn2"></a>Pylearn2</h3><p>主页：<a href="http://deeplearning.net/software/pylearn2/" target="_blank" rel="noopener">http://deeplearning.net/software/pylearn2/</a></p><p>Github网址：<a href="https://github.com/lisa-lab/pylearn2" target="_blank" rel="noopener">https://github.com/lisa-lab/pylearn2</a></p><p>Pylearn2和Theano由同一个开发团队开发，Pylearn2是一个机器学习库，它把深度学习和人工智能研究许多常用的模型以及训练算法封装成一个单一的实验包，如随机梯度下降。</p><p>你也可以很轻松的围绕你的类和算法编写一个封装程序，为了能让它在Pylearn2上运行，你需要在一个单独的YAML格式的配置文件中配置你整个神经网络模型的参数。</p><p>除此之外，它还有很多数据集及其预编译好的软件包，所以，你现在就可以直接使用MNIST数据集开始做实验了！</p><h3 id="Blocks"><a href="#Blocks" class="headerlink" title="Blocks"></a>Blocks</h3><p>Github网址：<a href="https://github.com/mila-udem/blocks" target="_blank" rel="noopener">https://github.com/mila-udem/blocks</a></p><p>Blocks是一个非常模块化的框架，有助于你在Theano上建立神经网络。目前它支持并提供的功能有：</p><p>构建参数化Theano运算，称之为“bricks”。<br>在大型模型中使用模式匹配来选择变量以及“bricks”。<br>使用算法优化模型。<br>训练模型的保存和恢复。<br>在训练过程中检测和分析值（训练集以及测试集）。<br>图形变换的应用，如dropout。</p><h3 id="Keras"><a href="#Keras" class="headerlink" title="Keras"></a>Keras</h3><p>主页：<a href="http://keras.io/" target="_blank" rel="noopener">http://keras.io/</a></p><p>Github网址：<a href="https://github.com/fchollet/keras" target="_blank" rel="noopener">https://github.com/fchollet/keras</a></p><p>Keras是一个简约的、高度模块化的神经网络库，设计参考了Torch，基于Theano和Python语言编写，支持GPU和CPU。它的开发侧重于实现快速试验和创造新的深度学习模型。</p><p>如果你需要具有以下功能的深度学习库，采用Keras就恰到好处：</p><p>可以很容易地、快速地建立原型（通过总体模块化，极简化并且可扩展化）。<br>支持卷积网络和递归网络，以及两者的组合。<br>支持任意连接方式（包括多输入多输出训练）。<br>Keras库与其他采用Theano库的区别是Keras的编码风格非常简约、清晰。它把所有的要点使用小类封装起来，能够很容易地组合在一起并创造出一种全新的模型。</p><h3 id="Lasagne"><a href="#Lasagne" class="headerlink" title="Lasagne"></a>Lasagne</h3><p>Github网址：<a href="https://github.com/Lasagne/Lasagne" target="_blank" rel="noopener">https://github.com/Lasagne/Lasagne</a></p><p>Lasagne不只是一个美味的意大利菜，也是一个与Blocks和Keras有着相似功能的深度学习库，但其在设计上与它们有些不同。</p><p>下面是Lasagne的一些设计目的：</p><p>简单化：它应该是易于使用和扩展的机器学习库。每添加一个特征，就应该考虑其对易用性和扩展性的影响。每一个抽象概念的加入都应该仔细检查，以确定增加的复杂性是否合理。<br>小接口：尽可能少的类和方法。尽可能依赖Theano的功能和数据类型，遵循Theano的规定。如果没有严格的必要，不要在类中封装东西。这会使它更容易使用库并且扩展它（不需要有太多的认知）。<br>不碍事：未使用的功能应该是不可见的，用户不会考虑他们不使用的功能。尽可能单独的使用库文件中的组件。<br>透明性：不要试图掩盖Theano，尽量以Python或NumPy数据类型的形式将函数和方法返回给Theano表达式。<br>重点：遵循Unix哲学“做一件事，并把它做好”，重点集中在前馈神经网络。<br>实用主义：使普通用例更易于使用，这要比支持每一个可能的用例更为重要。</p><p>译者简介： <a href="https://www.csuldw.com">刘帝伟</a>，中南大学软件学院在读研究生，关注机器学习、数据挖掘及生物信息领域。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;英文链接：&lt;a href=&quot;http://creative-punch.net/2015/07/frameworks-and-libraries-for-deep-learning/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://creative-punch.net/2015/07/frameworks-and-libraries-for-deep-learning/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;深度学习是机器学习和人工智能的一种形式，利用堆积在彼此顶部的神经网络的多个隐藏层来尝试形成对数据更深层次的“理解”。&lt;/p&gt;
&lt;p&gt;最近，深度神经网络以“Deep Dreams”形式在网站中如雨后春笋般出现，或是像谷歌研究原创论文中描述的那样：Inceptionism。&lt;/p&gt;
&lt;p&gt;在这篇文章中，我们将讨论几个不同的深度学习框架，库以及工具。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="译文" scheme="https://www.csuldw.com/tags/%E8%AF%91%E6%96%87/"/>
    
      <category term="框架&amp;库" scheme="https://www.csuldw.com/tags/%E6%A1%86%E6%9E%B6-%E5%BA%93/"/>
    
      <category term="Theano" scheme="https://www.csuldw.com/tags/Theano/"/>
    
      <category term="Lasagne" scheme="https://www.csuldw.com/tags/Lasagne/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-Cross Validation交叉验证Python实现</title>
    <link href="https://www.csuldw.com/2015/07/28/2015-07-28%20crossvalidation/"/>
    <id>https://www.csuldw.com/2015/07/28/2015-07-28 crossvalidation/</id>
    <published>2015-07-28T07:40:00.000Z</published>
    <updated>2016-03-13T10:22:16.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="1-原理"><a href="#1-原理" class="headerlink" title="1.原理"></a><strong>1.原理</strong></h2><h3 id="1-1-概念"><a href="#1-1-概念" class="headerlink" title="1.1 概念"></a><strong>1.1 概念</strong></h3><p>交叉验证(Cross-validation)主要用于模型训练或建模应用中，如分类预测、PCR、PLS回归建模等。在给定的样本空间中，拿出大部分样本作为训练集来训练模型，剩余的小部分样本使用刚建立的模型进行预测，并求这小部分样本的预测误差或者预测精度，同时记录它们的加和平均值。这个过程迭代K次，即K折交叉。其中，把每个样本的预测误差平方加和，称为PRESS(predicted Error Sum of Squares)。</p><a id="more"></a><h3 id="1-2-目的"><a href="#1-2-目的" class="headerlink" title="1.2 目的"></a><strong>1.2 目的</strong></h3><p>用交叉验证的目的是为了得到可靠稳定的模型。在分类，建立PC 或PLS模型时，一个很重要的因素是取多少个主成分的问题。用cross validation校验每个主成分下的PRESS值，选择PRESS值小的主成分数。或PRESS值不再变小时的主成分数。</p><p>常用的精度测试方法主要是交叉验证，例如10折交叉验证(10-fold cross validation)，将数据集分成十份，轮流将其中9份做训练1份做验证，10次的结果的均值作为对算法精度的估计，一般还需要进行多次10折交叉验证求均值，例如：10次10折交叉验证，以求更精确一点。<br>交叉验证有时也称为交叉比对，如：10折交叉比对</p><h3 id="1-3-常见的交叉验证形式："><a href="#1-3-常见的交叉验证形式：" class="headerlink" title="1.3 常见的交叉验证形式："></a><strong>1.3 常见的交叉验证形式</strong>：</h3><p><strong>Holdout 验证</strong></p><blockquote><p>方法：将原始数据随机分为两组,一组做为训练集,一组做为验证集,利用训练集训练分类器,然后利用验证集验证模型,记录最后的分类准确率为此Hold-OutMethod下分类器的性能指标.。Hold-OutMethod相对于K-fold Cross Validation 又称Double cross-validation ，或相对K-CV称 2-fold cross-validation(2-CV)</p></blockquote><blockquote><p>一般来说，Holdout 验证并非一种交叉验证，因为数据并没有交叉使用。 随机从最初的样本中选出部分，形成交叉验证数据，而剩余的就当做训练数据。 一般来说，少于原本样本三分之一的数据被选做验证数据。</p></blockquote><ul><li>优点：好处的处理简单,只需随机把原始数据分为两组即可</li><li>缺点：严格意义来说Hold-Out Method并不能算是CV,因为这种方法没有达到交叉的思想,由于是随机的将原始数据分组,所以最后验证集分类准确率的高低与原始数据的分组有很大的关系,所以这种方法得到的结果其实并不具有说服性.(主要原因是 训练集样本数太少，通常不足以代表母体样本的分布，导致 test 阶段辨识率容易出现明显落差。此外，2-CV 中一分为二的分子集方法的变异度大，往往无法达到「实验过程必须可以被复制」的要求。)</li></ul><p><strong>K-fold cross-validation</strong></p><blockquote><p>K折交叉验证，初始采样分割成K个子样本，一个单独的子样本被保留作为验证模型的数据，其他K-1个样本用来训练。交叉验证重复K次，每个子样本验证一次，平均K次的结果或者使用其它结合方式，最终得到一个单一估测。这个方法的优势在于，同时重复运用随机产生的子样本进行训练和验证，每次的结果验证一次，10折交叉验证是最常用的。</p></blockquote><ul><li>优点：K-CV可以有效的避免过学习以及欠学习状态的发生,最后得到的结果也比较具有说服性.  </li><li>缺点：K值选取上</li></ul><p><strong>留一验证</strong></p><blockquote><p>正如名称所建议， 留一验证（LOOCV）意指只使用原本样本中的一项来当做验证资料， 而剩余的则留下来当做训练资料。 这个步骤一直持续到每个样本都被当做一次验证资料。 事实上，这等同于 K-fold 交叉验证是一样的，其中K为原本样本个数。 在某些情况下是存在有效率的演算法，如使用kernel regression 和Tikhonov regularization。</p></blockquote><h2 id="2-深入"><a href="#2-深入" class="headerlink" title="2.深入"></a><strong>2.深入</strong></h2><p>使用交叉验证方法的目的主要有3个： </p><ul><li>（1）从有限的学习数据中获取尽可能多的有效信息； </li><li>（2）交叉验证从多个方向开始学习样本的，可以有效的避免陷入局部最小值； </li><li>（3）可以在一定程度上避免过拟合问题。</li></ul><p>采用交叉验证方法时需要将学习数据样本分为两部分：训练数据样本和验证数据样本。并且为了得到更好的学习效果，无论训练样本还是验证样本都要尽可能参与学习。一般选取10重交叉验证即可达到好的学习效果。下面在上述原则基础上设计算法，主要描述下算法步骤，如下所示。</p><h2 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm  "></a>Algorithm  </h2><figure class="highlight matlab"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Step1: 将学习样本空间 C 分为大小相等的 K 份  </span><br><span class="line">Step2: <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> to K ：</span><br><span class="line">取第<span class="built_in">i</span>份作为测试集</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span> to K:</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">i</span> != <span class="built_in">j</span>:</span><br><span class="line">将第<span class="built_in">j</span>份加到训练集中，作为训练集的一部分</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">if</span></span><br><span class="line"><span class="keyword">end</span> <span class="keyword">for</span></span><br><span class="line"><span class="keyword">end</span> <span class="keyword">for</span></span><br><span class="line">Step3: <span class="keyword">for</span> <span class="built_in">i</span> in (K<span class="number">-1</span>训练集)：</span><br><span class="line">训练第<span class="built_in">i</span>个训练集，得到一个分类模型</span><br><span class="line">使用该模型在第N个数据集上测试，计算并保存模型评估指标</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">for</span></span><br><span class="line">Step4: 计算模型的平均性能</span><br><span class="line">Step5: 用这K个模型在最终验证集的分类准确率平均值作为此K-CV下分类器的性能指标.</span><br></pre></td></tr></tbody></table></figure><h2 id="3-实现"><a href="#3-实现" class="headerlink" title="3.实现"></a><strong>3.实现</strong></h2><h3 id="3-1-scikit-learn交叉验证"><a href="#3-1-scikit-learn交叉验证" class="headerlink" title="3.1 scikit-learn交叉验证"></a><strong>3.1 scikit-learn交叉验证</strong></h3><p>在scikit-learn中有CrossValidation的实现代码，地址： <a href="http://scikit-learn.org/dev/modules/cross_validation.html#cross-validation" target="_blank" rel="noopener">scikit-learn官网crossvalidation文档</a></p><p>使用方法：</p><p>首先加载数据集</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn <span class="keyword">import</span> cross_validation</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>iris = datasets.load_iris()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>iris.data.shape, iris.target.shape</span><br><span class="line">((<span class="number">150</span>, <span class="number">4</span>), (<span class="number">150</span>,))</span><br></pre></td></tr></tbody></table></figure><p>通过上面代码，数据集特征和类标签分别为iris.data, iris.target，接着进行交叉验证</p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; X_train, X_test, y_train, y_test = cross_validation.train_test_split(</span><br><span class="line">...     iris.data, iris.target, test_size=<span class="number">0</span>.<span class="number">4</span>, random_state=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; X_train.shape, y_train.shape</span><br><span class="line">((<span class="number">90</span>, <span class="number">4</span>), (<span class="number">90</span>,))</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; X_test.shape, y_test.shape</span><br><span class="line">((<span class="number">60</span>, <span class="number">4</span>), (<span class="number">60</span>,))</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; clf = svm.SVC(kernel=<span class="string">'linear'</span>, C=<span class="number">1</span>).fit(X_train, y_train)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; clf.score(X_test, y_test)                           </span><br><span class="line"><span class="number">0</span>.<span class="number">96</span>...</span><br></pre></td></tr></tbody></table></figure><p>上面的clf是分类器，可以自己替换，比如我可以使用RandomForest</p><figure class="highlight ini"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">clf</span> = RandomForestClassifier(n_estimators=<span class="number">400</span>)</span><br></pre></td></tr></tbody></table></figure><p>一个比较有用的函数是train_test_split。功能是从样本中随机的按比例选取train data和test data。形式为</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = cross_validation.train_test_split(train_data,train_target, <span class="attribute">test_size</span>=0.4, <span class="attribute">random_state</span>=0)</span><br></pre></td></tr></tbody></table></figure><p>test_size是样本占比。如果是整数的话就是样本的数量。random_state是随机数的种子。</p><p>当然，也可以换成别的，具体算法可以参考 <a href="http://scikit-learn.org/dev/supervised_learning.html#supervised-learning" target="_blank" rel="noopener">scikit-learn官方文档</a></p><hr><h3 id="3-2-抽样与CV结合"><a href="#3-2-抽样与CV结合" class="headerlink" title="3.2 抽样与CV结合"></a><strong>3.2 抽样与CV结合</strong></h3><blockquote><p>由于我跑的实验，数据是非均衡数据，不能直接套用，所以这里自己写了一个交叉验证的代码，仅供参考，如有问题，欢迎交流。</p></blockquote><p>首先有一个自适应的数据加载函数，主要用于加载本地文本数据，同时文本每行数据以”\t”隔开，最后一列为类标号，数据样例如下：</p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A1001<span class="number">708</span>K<span class="number">-4</span><span class="number">-3</span><span class="number">6</span><span class="number">2</span><span class="number">-13</span><span class="number">0</span><span class="number">2</span><span class="number">-4</span><span class="number">-4</span><span class="number">-10</span><span class="number">-9</span><span class="number">1</span></span><br><span class="line">A1002<span class="number">709</span>L<span class="number">-4</span><span class="number">-4</span><span class="number">-1</span><span class="number">-2</span><span class="number">-11</span><span class="number">-1</span><span class="number">0</span><span class="number">-12</span><span class="number">-7</span><span class="number">-5</span><span class="number">-1</span><span class="number">-1</span></span><br><span class="line">A1003<span class="number">710</span>G<span class="number">0</span><span class="number">-6</span><span class="number">-2</span><span class="number">-6</span><span class="number">-8</span><span class="number">-4</span><span class="number">-6</span><span class="number">-6</span><span class="number">-9</span><span class="number">-4</span><span class="number">0</span><span class="number">-1</span></span><br><span class="line">A1004<span class="number">711</span>R<span class="number">0</span><span class="number">0</span><span class="number">1</span><span class="number">-3</span><span class="number">-10</span><span class="number">-1</span><span class="number">-3</span><span class="number">-4</span><span class="number">-6</span><span class="number">-9</span><span class="number">-6</span><span class="number">1</span></span><br></pre></td></tr></tbody></table></figure><p><strong>说明</strong>：前面三个不是特征，所以在加载数据集的时候，特征部分起始位置修改了下，loadDataSet函数如下：</p><figure class="highlight gradle"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> loadDataSet(fileName):</span><br><span class="line">    fr = open(fileName)</span><br><span class="line">    dataMat = []; labelMat = []</span><br><span class="line">    <span class="keyword">for</span> <span class="keyword">eachline</span> in fr:</span><br><span class="line">        lineArr = []</span><br><span class="line">        curLine = <span class="keyword">eachline</span>.strip().split(<span class="string">'\t'</span>) #remove <span class="string">'\n'</span></span><br><span class="line">        <span class="keyword">for</span> i in range(<span class="number">3</span>, len(curLine)-<span class="number">1</span>):</span><br><span class="line">            lineArr.<span class="keyword">append</span>(<span class="keyword">float</span>(curLine[i])) #get all feature <span class="keyword">from</span> inpurfile</span><br><span class="line">        dataMat.<span class="keyword">append</span>(lineArr)</span><br><span class="line">        labelMat.<span class="keyword">append</span>(<span class="keyword">int</span>(curLine[-<span class="number">1</span>])) #last one is <span class="keyword">class</span> lable</span><br><span class="line">    fr.close()</span><br><span class="line">    <span class="keyword">return</span> dataMat,labelMat</span><br></pre></td></tr></tbody></table></figure><p>返回的dataMat为纯特征矩阵，labelMat为类别标号。</p><p>下面的<strong>splitDataSet</strong>用来切分数据集，如果是十折交叉，则split_size取10，filename为整个数据集文件，outdir则是切分的数据集的存放路径。</p><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">def splitDataSet(fileName, split_size,outdir):</span><br><span class="line">    <span class="keyword">if</span> not os.path.exists(outdir): <span class="comment">#if not outdir,makrdir</span></span><br><span class="line">        os.makedirs(outdir)</span><br><span class="line">    <span class="attr">fr</span> = open(fileName,'r')<span class="comment">#open fileName to read</span></span><br><span class="line">    <span class="attr">num_line</span> = <span class="number">0</span></span><br><span class="line">    <span class="attr">onefile</span> = fr.readlines()</span><br><span class="line">    <span class="attr">num_line</span> = len(onefile)        </span><br><span class="line">    <span class="attr">arr</span> = np.arange(num_line) <span class="comment">#get a seq and set len=numLine</span></span><br><span class="line">    np.random.shuffle(arr) <span class="comment">#generate a random seq from arr</span></span><br><span class="line">    <span class="attr">list_all</span> = arr.tolist()</span><br><span class="line">    <span class="attr">each_size</span> = (num_line+<span class="number">1</span>) / split_size <span class="comment">#size of each split sets</span></span><br><span class="line">    <span class="attr">split_all</span> = []; <span class="attr">each_split</span> = []</span><br><span class="line">    <span class="attr">count_num</span> = <span class="number">0</span>; <span class="attr">count_split</span> = <span class="number">0</span>  <span class="comment">#count_num 统计每次遍历的当前个数</span></span><br><span class="line">                                    <span class="comment">#count_split 统计切分次数</span></span><br><span class="line">    for i <span class="keyword">in</span> range(len(list_all)): <span class="comment">#遍历整个数字序列</span></span><br><span class="line">        each_split.append(onefile[int(list_all[i])].strip()) </span><br><span class="line">        count_num += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> <span class="attr">count_num</span> == each_size:</span><br><span class="line">            count_split += <span class="number">1</span> </span><br><span class="line">            <span class="attr">array_</span> = np.array(each_split)</span><br><span class="line">            np.savetxt(outdir + <span class="string">"/split_"</span> + str(count_split) + '.txt',\</span><br><span class="line">                        array_,<span class="attr">fmt="%s",</span> <span class="attr">delimiter='\t')</span>  <span class="comment">#输出每一份数据</span></span><br><span class="line">            split_all.append(each_split) <span class="comment">#将每一份数据加入到一个list中</span></span><br><span class="line">            <span class="attr">each_split</span> = []</span><br><span class="line">            <span class="attr">count_num</span> = <span class="number">0</span></span><br><span class="line">    return split_all</span><br></pre></td></tr></tbody></table></figure><p>underSample(datafile)方法为抽样函数，强正负样本比例固定为1:1，返回的是一个正负样本比例均等的数据集合。</p><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def underSample(datafile): <span class="comment">#只针对一个数据集的下采样</span></span><br><span class="line">    dataMat,<span class="attr">labelMat</span> = loadDataSet(datafile) <span class="comment">#加载数据</span></span><br><span class="line">    <span class="attr">pos_num</span> = <span class="number">0</span>; <span class="attr">pos_indexs</span> = []; <span class="attr">neg_indexs</span> = []   </span><br><span class="line">    for i <span class="keyword">in</span> range(len(labelMat)):<span class="comment">#统计正负样本的下标    </span></span><br><span class="line">        <span class="keyword">if</span> labelMat[i] == <span class="number">1</span>:</span><br><span class="line">            pos_num +=<span class="number">1</span></span><br><span class="line">            pos_indexs.append(i)</span><br><span class="line">            continue</span><br><span class="line">        neg_indexs.append(i)</span><br><span class="line">    np.random.shuffle(neg_indexs)</span><br><span class="line">    <span class="attr">neg_indexs</span> = neg_indexs[<span class="number">0</span>:pos_num]</span><br><span class="line">    <span class="attr">fr</span> = open(datafile, 'r')</span><br><span class="line">    <span class="attr">onefile</span> = fr.readlines()</span><br><span class="line">    <span class="attr">outfile</span> = []</span><br><span class="line">    for i <span class="keyword">in</span> range(pos_num):</span><br><span class="line">        <span class="attr">pos_line</span> = onefile[pos_indexs[i]]    </span><br><span class="line">        outfile.append(pos_line)</span><br><span class="line">        <span class="attr">neg_line=</span> onefile[neg_indexs[i]]      </span><br><span class="line">        outfile.append(neg_line)</span><br><span class="line">    return outfile <span class="comment">#输出单个数据集采样结果</span></span><br></pre></td></tr></tbody></table></figure><p>下面的generateDataset(datadir,outdir)方法是从切分的数据集中留出一份作为测试集（无需抽样），对其余的进行抽样然后合并为一个作为训练集，代码如下：</p><figure class="highlight livecodeserver"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">def generateDataset(datadir,outdir): <span class="comment">#从切分的数据集中，对其中九份抽样汇成一个,\</span></span><br><span class="line">    <span class="comment">#剩余一个做为测试集,将最后的结果按照训练集和测试集输出到outdir中</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(outdir): <span class="comment">#if not outdir,makrdir</span></span><br><span class="line">        os.makedirs(outdir)</span><br><span class="line">    listfile = os.listdir(datadir)</span><br><span class="line">    train_all = []; test_all = [];cross_now = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> eachfile1 <span class="keyword">in</span> listfile:</span><br><span class="line">        train_sets = []; test_sets = []; </span><br><span class="line">        cross_now += <span class="number">1</span> <span class="comment">#记录当前的交叉次数</span></span><br><span class="line">        <span class="keyword">for</span> eachfile2 <span class="keyword">in</span> listfile:</span><br><span class="line">            <span class="keyword">if</span> eachfile2 != eachfile1:<span class="comment">#对其余九份欠抽样构成训练集</span></span><br><span class="line">                one_sample = underSample(datadir + <span class="string">'/'</span> + eachfile2)</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="built_in">len</span>(one_sample)):</span><br><span class="line">                    train_sets.append(one_sample[i])</span><br><span class="line">        <span class="comment">#将训练集和测试集文件单独保存起来</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(outdir +<span class="string">"/test_"</span>+str(cross_now)+<span class="string">".datasets"</span>,<span class="string">'w'</span>) <span class="keyword">as</span> fw_test:</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(datadir + <span class="string">'/'</span> + eachfile1, <span class="string">'r'</span>) <span class="keyword">as</span> fr_testsets:</span><br><span class="line">                <span class="keyword">for</span> each_testline <span class="keyword">in</span> fr_testsets:                </span><br><span class="line">                    test_sets.append(each_testline) </span><br><span class="line">            <span class="keyword">for</span> oneline_test <span class="keyword">in</span> test_sets:</span><br><span class="line">                fw_test.<span class="built_in">write</span>(oneline_test) <span class="comment">#输出测试集</span></span><br><span class="line">            test_all.append(test_sets)<span class="comment">#保存训练集</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(outdir+<span class="string">"/train_"</span>+str(cross_now)+<span class="string">".datasets"</span>,<span class="string">'w'</span>) <span class="keyword">as</span> fw_train:</span><br><span class="line">            <span class="keyword">for</span> oneline_train <span class="keyword">in</span> train_sets:   </span><br><span class="line">                oneline_train = oneline_train</span><br><span class="line">                fw_train.<span class="built_in">write</span>(oneline_train)<span class="comment">#输出训练集</span></span><br><span class="line">            train_all.append(train_sets)<span class="comment">#保存训练集</span></span><br><span class="line">    <span class="literal">return</span> train_all,test_all</span><br></pre></td></tr></tbody></table></figure><p>因为需要评估交叉验证，所以我写了一个performance方法根据真实类标签纸和预测值来计算SN和SP，当然如果需要其他的评估标准，继续添加即可。</p><figure class="highlight armasm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">def</span> performance(labelArr, predictArr):#类标签为int类型</span><br><span class="line">    <span class="symbol">#labelArr</span>[i] is actual value,predictArr[i] is predict value</span><br><span class="line">    TP = <span class="number">0</span>.<span class="comment">; TN = 0.; FP = 0.; FN = 0.   </span></span><br><span class="line">    for i in range(len(labelArr)):</span><br><span class="line">        <span class="meta">if</span> labelArr[i] == <span class="number">1</span> <span class="keyword">and </span>predictArr[i] == <span class="number">1</span>:</span><br><span class="line">            TP += <span class="number">1</span>.</span><br><span class="line">        <span class="meta">if</span> labelArr[i] == <span class="number">1</span> <span class="keyword">and </span>predictArr[i] == -<span class="number">1</span>:</span><br><span class="line">            <span class="meta">FN</span> += <span class="number">1</span>.</span><br><span class="line">        <span class="meta">if</span> labelArr[i] == -<span class="number">1</span> <span class="keyword">and </span>predictArr[i] == <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">FP</span> += <span class="number">1</span>.</span><br><span class="line">        <span class="meta">if</span> labelArr[i] == -<span class="number">1</span> <span class="keyword">and </span>predictArr[i] == -<span class="number">1</span>:</span><br><span class="line">            TN += <span class="number">1</span>.</span><br><span class="line">    <span class="meta">SN</span> = TP/(TP + <span class="meta">FN</span>) <span class="symbol">#Sensitivity</span> = TP/P  <span class="keyword">and </span>P = TP + <span class="meta">FN</span> </span><br><span class="line">    <span class="built_in">SP</span> = TN/(<span class="built_in">FP</span> + TN) <span class="symbol">#Specificity</span> = TN/N  <span class="keyword">and </span>N = TN + <span class="built_in">FP</span></span><br><span class="line">    <span class="symbol">#MCC</span> = (TP*TN-<span class="built_in">FP</span>*<span class="meta">FN</span>)/math.sqrt((TP+<span class="built_in">FP</span>)*(TP+<span class="meta">FN</span>)*(TN+<span class="built_in">FP</span>)*(TN+<span class="meta">FN</span>))</span><br><span class="line">    return <span class="meta">SN</span>,<span class="built_in">SP</span></span><br></pre></td></tr></tbody></table></figure><p> classifier(clf,train_X, train_y, test_X, test_y)方法是交叉验证中每次用的分类器训练过程以及测试过程，里面使用的分类器是scikit-learn自带的。该方法会将一些训练结果写入到文件中并保存到本地，同时在最后会返回ACC,SP,SN。</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">def classifier(clf,train_X, train_y, test_X, test_y):#X:训练特征，y:训练标号</span><br><span class="line">    # train with randomForest </span><br><span class="line">    <span class="builtin-name">print</span> <span class="string">" training begin..."</span></span><br><span class="line">    clf = clf.fit(train_X,train_y)</span><br><span class="line">    <span class="builtin-name">print</span> <span class="string">" training end."</span></span><br><span class="line">    #==========================================================================</span><br><span class="line">    # test randomForestClassifier with testsets</span><br><span class="line">    <span class="builtin-name">print</span> <span class="string">" test begin."</span></span><br><span class="line">    predict_ = clf.predict(test_X) #return<span class="built_in"> type </span>is float64</span><br><span class="line">    proba = clf.predict_proba(test_X) #return<span class="built_in"> type </span>is float64</span><br><span class="line">    score_ = clf.score(test_X,test_y)</span><br><span class="line">    <span class="builtin-name">print</span> <span class="string">" test end."</span></span><br><span class="line">    #==========================================================================</span><br><span class="line">    # Modeal Evaluation</span><br><span class="line">    ACC = accuracy_score(test_y, predict_)</span><br><span class="line">    SN,SP = performance(test_y, predict_)</span><br><span class="line">    MCC = matthews_corrcoef(test_y, predict_)</span><br><span class="line">    #AUC = roc_auc_score(test_labelMat, proba)</span><br><span class="line">    #==========================================================================</span><br><span class="line">    #save output </span><br><span class="line">    eval_output = []</span><br><span class="line">    eval_output.append(ACC);eval_output.append(SN)  #eval_output.append(AUC)</span><br><span class="line">    eval_output.append(SP);eval_output.append(MCC)</span><br><span class="line">    eval_output.append(score_)</span><br><span class="line">    eval_output = np.array(eval_output,<span class="attribute">dtype</span>=float)</span><br><span class="line">    np.savetxt(<span class="string">"proba.data"</span>,proba,<span class="attribute">fmt</span>=<span class="string">"%f"</span>,delimiter="\t")</span><br><span class="line">    np.savetxt(<span class="string">"test_y.data"</span>,test_y,<span class="attribute">fmt</span>=<span class="string">"%f"</span>,delimiter="\t")</span><br><span class="line">    np.savetxt(<span class="string">"predict.data"</span>,predict_,<span class="attribute">fmt</span>=<span class="string">"%f"</span>,delimiter="\t") </span><br><span class="line">    np.savetxt(<span class="string">"eval_output.data"</span>,eval_output,<span class="attribute">fmt</span>=<span class="string">"%f"</span>,delimiter="\t")</span><br><span class="line">    <span class="builtin-name">print</span> <span class="string">"Wrote results to output.data...EOF..."</span></span><br><span class="line">    return ACC,SN,SP</span><br></pre></td></tr></tbody></table></figure><p>下面的mean_fun用于求列表list中数值的平均值，主要是求ACC_mean,SP_mean,SN_mean，用来评估模型好坏。</p><figure class="highlight gradle"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> mean_fun(onelist):</span><br><span class="line">    <span class="keyword">count</span> = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i in onelist:</span><br><span class="line">        <span class="keyword">count</span> += i</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">float</span>(<span class="keyword">count</span><span class="regexp">/len(onelist))</span></span><br></pre></td></tr></tbody></table></figure><p>交叉验证代码</p><figure class="highlight maxima"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">def crossValidation(clf, clfname, curdir,train_all, test_all):</span><br><span class="line">    os.<span class="built_in">chdir</span>(curdir)</span><br><span class="line">    #构造出纯数据型样本集</span><br><span class="line">    cur_path = curdir</span><br><span class="line">    ACCs = [];SNs = []; SPs =[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(len(train_all)):</span><br><span class="line">        os.<span class="built_in">chdir</span>(cur_path)</span><br><span class="line">        train_data = train_all[i];train_X = [];train_y = []</span><br><span class="line">        test_data = test_all[i];test_X = [];test_y = []</span><br><span class="line">        <span class="keyword">for</span> eachline_train <span class="keyword">in</span> train_data:</span><br><span class="line">            one_train = eachline_train.<span class="built_in">split</span>('\t') </span><br><span class="line">            one_train_format = []</span><br><span class="line">            <span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>,len(one_train)-<span class="number">1</span>):</span><br><span class="line">                one_train_format.<span class="built_in">append</span>(<span class="built_in">float</span>(one_train[index]))</span><br><span class="line">            train_X.<span class="built_in">append</span>(one_train_format)</span><br><span class="line">            train_y.<span class="built_in">append</span>(int(one_train[-<span class="number">1</span>].strip()))</span><br><span class="line">        <span class="keyword">for</span> eachline_test <span class="keyword">in</span> test_data:</span><br><span class="line">            one_test = eachline_test.<span class="built_in">split</span>('\t')</span><br><span class="line">            one_test_format = []</span><br><span class="line">            <span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>,len(one_test)-<span class="number">1</span>):</span><br><span class="line">                one_test_format.<span class="built_in">append</span>(<span class="built_in">float</span>(one_test[index]))</span><br><span class="line">            test_X.<span class="built_in">append</span>(one_test_format)</span><br><span class="line">            test_y.<span class="built_in">append</span>(int(one_test[-<span class="number">1</span>].strip()))</span><br><span class="line">        #======================================================================</span><br><span class="line">        #classifier start here</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(clfname):#使用的分类器</span><br><span class="line">            os.<span class="built_in">mkdir</span>(clfname)</span><br><span class="line">        out_path = clfname + <span class="string">"/"</span> + clfname + <span class="string">"_00"</span> + str(i)#计算结果文件夹</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(out_path):</span><br><span class="line">            os.<span class="built_in">mkdir</span>(out_path)</span><br><span class="line">        os.<span class="built_in">chdir</span>(out_path)</span><br><span class="line">        ACC, SN, SP = classifier(clf, train_X, train_y, test_X, test_y)</span><br><span class="line">        ACCs.<span class="built_in">append</span>(ACC);SNs.<span class="built_in">append</span>(SN);SPs.<span class="built_in">append</span>(SP)</span><br><span class="line">        #======================================================================</span><br><span class="line">    ACC_mean = mean_fun(ACCs)</span><br><span class="line">    SN_mean = mean_fun(SNs)</span><br><span class="line">    SP_mean = mean_fun(SPs)</span><br><span class="line">    #==========================================================================</span><br><span class="line">    #output experiment result</span><br><span class="line">    os.<span class="built_in">chdir</span>(<span class="string">"../"</span>)</span><br><span class="line">    os.<span class="built_in">system</span>(<span class="string">"echo `date` '"</span> + str(clf) + <span class="string">"' &gt;&gt; log.out"</span>)</span><br><span class="line">    os.<span class="built_in">system</span>(<span class="string">"echo ACC_mean="</span> + str(ACC_mean) + <span class="string">" &gt;&gt; log.out"</span>)</span><br><span class="line">    os.<span class="built_in">system</span>(<span class="string">"echo SN_mean="</span> + str(SN_mean) + <span class="string">" &gt;&gt; log.out"</span>)</span><br><span class="line">    os.<span class="built_in">system</span>(<span class="string">"echo SP_mean="</span> + str(SP_mean) + <span class="string">" &gt;&gt; log.out"</span>)</span><br><span class="line">    <span class="built_in">return</span> ACC_mean, SN_mean, SP_mean</span><br></pre></td></tr></tbody></table></figure><p><strong>测试：</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">os.chdir(<span class="string">"your workhome"</span>) <span class="comment">#你的数据存放目录</span></span><br><span class="line">    datadir = <span class="string">"split10_1"</span> <span class="comment">#切分后的文件输出目录</span></span><br><span class="line">    splitDataSet(<span class="string">'datasets'</span>,<span class="number">10</span>,datadir)<span class="comment">#将数据集datasets切为十个保存到datadir目录中</span></span><br><span class="line"><span class="comment">#==========================================================================</span></span><br><span class="line">    outdir = <span class="string">"sample_data1"</span><span class="comment">#抽样的数据集存放目录</span></span><br><span class="line">    train_all,test_all = generateDataset(datadir,outdir) <span class="comment">#抽样后返回训练集和测试集</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">"generateDataset end and cross validation start"</span></span><br><span class="line">    <span class="comment">#==========================================================================</span></span><br><span class="line">    <span class="comment">#分类器部分</span></span><br><span class="line">    <span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line">    clf = RandomForestClassifier(n_estimators=<span class="number">500</span>) <span class="comment">#使用随机森林分类器来训练</span></span><br><span class="line">    clfname = <span class="string">"RF_1"</span></span><br><span class="line">    <span class="comment">#==========================================================================</span></span><br><span class="line">    curdir = <span class="string">"experimentdir"</span> <span class="comment">#工作目录</span></span><br><span class="line"><span class="comment">#clf:分类器,clfname:分类器名称,curdir:当前路径,train_all:训练集,test_all:测试集</span></span><br><span class="line">    ACC_mean, SN_mean, SP_mean = crossValidation(clf, clfname, curdir, train_all,test_all)</span><br><span class="line">    <span class="keyword">print</span> ACC_mean,SN_mean,SP_mean<span class="comment">#将ACC均值，SP均值，SN均值都输出到控制台</span></span><br></pre></td></tr></tbody></table></figure><p>上面的代码主要用于抽样后的十倍交叉验证，该怎么设置参数，还得具体分析。</p><p>总之，交叉验证在一定程度上能够避免陷入局部最小值。一般实际操作中使用的是十折交叉验证，单具体情况还得具体分析，并没有一个统一的标准固定十倍交叉的参数或者是算法的选择以及算法参数的选择。不同的数据使用不同的算法往往会的得到不同的最优分类器。So,just try it!Happy coding!</p><hr><br><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-原理&quot;&gt;&lt;a href=&quot;#1-原理&quot; class=&quot;headerlink&quot; title=&quot;1.原理&quot;&gt;&lt;/a&gt;&lt;strong&gt;1.原理&lt;/strong&gt;&lt;/h2&gt;&lt;h3 id=&quot;1-1-概念&quot;&gt;&lt;a href=&quot;#1-1-概念&quot; class=&quot;headerlink&quot; title=&quot;1.1 概念&quot;&gt;&lt;/a&gt;&lt;strong&gt;1.1 概念&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;交叉验证(Cross-validation)主要用于模型训练或建模应用中，如分类预测、PCR、PLS回归建模等。在给定的样本空间中，拿出大部分样本作为训练集来训练模型，剩余的小部分样本使用刚建立的模型进行预测，并求这小部分样本的预测误差或者预测精度，同时记录它们的加和平均值。这个过程迭代K次，即K折交叉。其中，把每个样本的预测误差平方加和，称为PRESS(predicted Error Sum of Squares)。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="交叉验证" scheme="https://www.csuldw.com/tags/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/"/>
    
      <category term="Cross-Validation" scheme="https://www.csuldw.com/tags/Cross-Validation/"/>
    
  </entry>
  
  <entry>
    <title>scikit-klean交叉验证</title>
    <link href="https://www.csuldw.com/2015/07/23/2015-07-23%20machine%20learning%20tips/"/>
    <id>https://www.csuldw.com/2015/07/23/2015-07-23 machine learning tips/</id>
    <published>2015-07-23T04:53:00.000Z</published>
    <updated>2016-03-13T10:23:04.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>一个Windows操作系统能够使用的pythonIDE</strong></p><blockquote><p>winPython下载地址：<a href="http://sourceforge.net/projects/winpython/files/WinPython_2.7/2.7.10.1/" target="_blank" rel="noopener">WinPython_2.7</a></p></blockquote><p>传统的F-measure或平衡的F-score (F1 score)是精度和召回的调和平均值：</p><p>$$F_1 = 2 \times \dfrac{precision \times recall}{precision + recall}$$</p><a id="more"></a><h3 id="1-Cross-Validation-（交叉验证）"><a href="#1-Cross-Validation-（交叉验证）" class="headerlink" title="1.Cross Validation （交叉验证）"></a><strong>1.Cross Validation （交叉验证）</strong></h3><p>cross validation大概的意思是：对于原始数据我们要将其一部分分为train_data，一部分分为test_data。train_data用于训练，test_data用于测试准确率。在test_data上测试的结果叫做validation_error。将一个算法作用于一个原始数据，我们不可能只做出随机的划分一次train和test_data，然后得到一个validation_error，就作为衡量这个算法好坏的标准。因为这样存在偶然性。我们必须好多次的随机的划分train_data和test_data，分别在其上面算出各自的validation_error。这样就有一组validation_error，根据这一组validation_error，就可以较好的准确的衡量算法的好坏。</p><p>cross validation是在数据量有限的情况下的非常好的一个evaluate performance的方法。而对原始数据划分出train data和test data的方法有很多种，这也就造成了cross validation的方法有很多种。</p><p>sklearn中的cross validation模块，最主要的函数是如下函数：<br>sklearn.cross_validation.cross_val_score:他的调用形式是scores = cross_validation.cross_val_score(clf, raw_data, raw_target, cv=5, score_func=None)</p><p><strong>参数解释：</strong></p><p><strong>clf</strong>:表示的是不同的分类器，可以是任何的分类器。比如支持向量机分类器。clf = svm.SVC(kernel=’linear’, C=1)；<br><strong>raw_data</strong>：原始数据；<br><strong>raw_target</strong>:原始类别标号；<br><strong>cv</strong>：代表的就是不同的cross validation的方法了。引用scikit-learn上的一句话（When the cv argument is an integer, cross_val_score uses the KFold or StratifiedKFold strategies by default, the latter being used if the estimator derives from ClassifierMixin.）如果cv是一个int数字的话，那么默认使用的是KFold或者StratifiedKFold交叉，如果如果指定了类别标签则使用的是StratifiedKFold。<br><strong>cross_val_score</strong>:这个函数的返回值就是对于每次不同的的划分raw_data时，在test_data上得到的分类的<strong>准确率</strong>。至于准确率的算法可以通过score_func参数指定，如果不指定的话，是用clf默认自带的准确率算法。  </p><p>scikit-learn的cross-validation交叉验证代码：</p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; from sklearn import cross_validation</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; from sklearn import svm</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; clf = svm.SVC(kernel=<span class="string">'linear'</span>, C=<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; scores = cross_validation.cross_val_score(clf, iris.data, iris.target, cv=<span class="number">5</span>)<span class="comment">#5-fold cv</span></span><br><span class="line"><span class="comment"># change metrics</span></span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; from sklearn import metrics</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; cross_validation.cross_val_score(clf, iris.data, iris.target, cv=<span class="number">5</span>, score_func=metrics.f1_score)</span><br><span class="line"><span class="comment">#f1 score: http://en.wikipedia.org/wiki/F1_score</span></span><br></pre></td></tr></tbody></table></figure><p>Note: if using LR, clf = LogisticRegression().</p><p><strong>生成一个数据集做为交叉验证</strong></p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import numpy as np</span><br><span class="line">&gt;&gt;&gt; from sklearn.cross_validation import train_test_split</span><br><span class="line">&gt;&gt;&gt; X, y = np.arange(<span class="number">10</span>).reshape((<span class="number">5</span>, <span class="number">2</span>)), range(<span class="number">5</span>)</span><br><span class="line">&gt;&gt;&gt; X</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">7</span>],</span><br><span class="line">       [<span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line">&gt;&gt;&gt; <span class="type">list</span>(y)</span><br><span class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br></pre></td></tr></tbody></table></figure><p><strong>将数据切分为训练集和测试集</strong></p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(</span><br><span class="line">...     X, y, test_size=<span class="number">0.33</span>, random_state=<span class="number">42</span>)</span><br><span class="line">...</span><br><span class="line">&gt;&gt;&gt; X_train</span><br><span class="line">array([[<span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">7</span>]])</span><br><span class="line">&gt;&gt;&gt; y_train</span><br><span class="line">[<span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>]</span><br><span class="line">&gt;&gt;&gt; X_test</span><br><span class="line">array([[<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line">&gt;&gt;&gt; y_test</span><br><span class="line">[<span class="number">1</span>, <span class="number">4</span>]</span><br></pre></td></tr></tbody></table></figure><p><strong>交叉验证的使用</strong></p><p>下面是手动划分训练集和测试集，控制台中输入下列代码进行测试：</p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; import numpy as np</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; from sklearn import cross_validation</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; from sklearn import datasets</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; from sklearn import svm</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; iris = datasets.load_iris()</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; iris.data.shape, iris.target.shape</span><br><span class="line">((<span class="number">150</span>, <span class="number">4</span>), (<span class="number">150</span>,))</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; X_train, X_test, y_train, y_test = cross_validation.train_test_split(</span><br><span class="line">...     iris.data, iris.target, test_size=<span class="number">0</span>.<span class="number">4</span>, random_state=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; X_train.shape, y_train.shape</span><br><span class="line">((<span class="number">90</span>, <span class="number">4</span>), (<span class="number">90</span>,))</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; X_test.shape, y_test.shape</span><br><span class="line">((<span class="number">60</span>, <span class="number">4</span>), (<span class="number">60</span>,))</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; clf = svm.SVC(kernel=<span class="string">'linear'</span>, C=<span class="number">1</span>).fit(X_train, y_train)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; clf.score(X_test, y_test)                           </span><br><span class="line"><span class="number">0</span>.<span class="number">96</span>...</span><br></pre></td></tr></tbody></table></figure><p>下面是交叉验证的实例：</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; clf = svm.SVC(<span class="attribute">kernel</span>=<span class="string">'linear'</span>, <span class="attribute">C</span>=1)</span><br><span class="line">&gt;&gt;&gt; scores = cross_validation.cross_val_score(</span><br><span class="line"><span class="built_in">..</span>.    clf, iris.data, iris.target, <span class="attribute">cv</span>=5)</span><br><span class="line"><span class="built_in">..</span>.</span><br><span class="line">&gt;&gt;&gt; scores                                              </span><br><span class="line">array([ 0.96<span class="built_in">..</span>.,  1.  <span class="built_in">..</span>.,  0.96<span class="built_in">..</span>.,  0.96<span class="built_in">..</span>.,  1.        ])</span><br></pre></td></tr></tbody></table></figure><p>通过cross_validation，设置cv=5，进行5倍交叉验证，最后得到一个scores的预测准确率数组，表示每次交叉验证得到的准确率。</p><figure class="highlight lisp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; print(<span class="string">"Accuracy: %0.2f (+/- %0.2f)"</span> % (<span class="name">scores</span>.mean(), scores.std() * 2))</span><br><span class="line">Accuracy: 0.98 (+/- 0.03)</span><br></pre></td></tr></tbody></table></figure><p>通过scores.mean()求出平均值，得到平均精度。还可以通过指定scoring来设置准确率算法</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; <span class="keyword">from</span> sklearn import metrics</span><br><span class="line">&gt;&gt;&gt; scores = cross_validation.cross_val_score(clf, iris.data, iris.target,</span><br><span class="line"><span class="built_in">..</span>.     <span class="attribute">cv</span>=5, <span class="attribute">scoring</span>=<span class="string">'f1_weighted'</span>)</span><br><span class="line">&gt;&gt;&gt; scores                                              </span><br><span class="line">array([ 0.96<span class="built_in">..</span>.,  1.  <span class="built_in">..</span>.,  0.96<span class="built_in">..</span>.,  0.96<span class="built_in">..</span>.,  1.        ])</span><br></pre></td></tr></tbody></table></figure><p><strong>libsvm格式的数据导入：</strong></p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; from sklearn.datasets import load_svmlight_file</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; X_train, y_train = load_svmlight_file(<span class="string">"/path/to/train_dataset.txt"</span>)</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt;X_train.todense()<span class="comment">#将稀疏矩阵转化为完整特征矩阵</span></span><br></pre></td></tr></tbody></table></figure><hr><h3 id="2-处理非均衡问题"><a href="#2-处理非均衡问题" class="headerlink" title="2.处理非均衡问题"></a><strong>2.处理非均衡问题</strong></h3><p>对于正负样本比例相差较大的非均衡问题，一种调节分类器的方法就是对分类器的训练数据进行改造。一种是<strong>欠抽样</strong>，一种是<strong>过抽样</strong>。过抽样意味着赋值样例，而欠抽样意味着删除样例。对于过抽样，最后可能导致过拟合问题；而对于欠抽样，则删掉的样本中可能包含某些重要的信息，会导致欠拟合。对于正例样本较少的情况下，通常采取的方式是<strong>使用反例类别的欠抽样和正例类别的过抽样相混合的方法</strong></p><hr><h3 id="3-scikit-learn学习SVM"><a href="#3-scikit-learn学习SVM" class="headerlink" title="3.scikit-learn学习SVM"></a><strong>3.scikit-learn学习SVM</strong></h3><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&gt;&gt;&gt;</span> <span class="string">from</span> <span class="string">sklearn</span> <span class="string">import</span> <span class="string">datasets</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;</span> <span class="string">iris</span> <span class="string">=</span> <span class="string">datasets.load_iris()</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;</span> <span class="string">digits</span> <span class="string">=</span> <span class="string">datasets.load_digits()</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;</span> <span class="string">print</span> <span class="string">digits.data</span></span><br><span class="line"><span class="string">[[</span>  <span class="number">0</span><span class="string">.</span>   <span class="number">0</span><span class="string">.</span>   <span class="number">5</span><span class="string">.</span> <span class="string">...,</span>   <span class="number">0</span><span class="string">.</span>   <span class="number">0</span><span class="string">.</span>   <span class="number">0</span><span class="string">.]</span></span><br><span class="line"> <span class="string">[</span>  <span class="number">0</span><span class="string">.</span>   <span class="number">0</span><span class="string">.</span>   <span class="number">0</span><span class="string">.</span> <span class="string">...,</span>  <span class="number">10</span><span class="string">.</span>   <span class="number">0</span><span class="string">.</span>   <span class="number">0</span><span class="string">.]</span></span><br><span class="line"> <span class="string">[</span>  <span class="number">0</span><span class="string">.</span>   <span class="number">0</span><span class="string">.</span>   <span class="number">0</span><span class="string">.</span> <span class="string">...,</span>  <span class="number">16</span><span class="string">.</span>   <span class="number">9</span><span class="string">.</span>   <span class="number">0</span><span class="string">.]</span></span><br><span class="line"> <span class="string">...,</span> </span><br><span class="line"> <span class="string">[</span>  <span class="number">0</span><span class="string">.</span>   <span class="number">0</span><span class="string">.</span>   <span class="number">1</span><span class="string">.</span> <span class="string">...,</span>   <span class="number">6</span><span class="string">.</span>   <span class="number">0</span><span class="string">.</span>   <span class="number">0</span><span class="string">.]</span></span><br><span class="line"> <span class="string">[</span>  <span class="number">0</span><span class="string">.</span>   <span class="number">0</span><span class="string">.</span>   <span class="number">2</span><span class="string">.</span> <span class="string">...,</span>  <span class="number">12</span><span class="string">.</span>   <span class="number">0</span><span class="string">.</span>   <span class="number">0</span><span class="string">.]</span></span><br><span class="line"> <span class="string">[</span>  <span class="number">0</span><span class="string">.</span>   <span class="number">0</span><span class="string">.</span>  <span class="number">10</span><span class="string">.</span> <span class="string">...,</span>  <span class="number">12</span><span class="string">.</span>   <span class="number">1</span><span class="string">.</span>   <span class="number">0</span><span class="string">.]]</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;</span> <span class="string">digits.target</span></span><br><span class="line"><span class="string">array([0,</span> <span class="number">1</span><span class="string">,</span> <span class="number">2</span><span class="string">,</span> <span class="string">...,</span> <span class="number">8</span><span class="string">,</span> <span class="number">9</span><span class="string">,</span> <span class="number">8</span><span class="string">])</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;</span> <span class="string">digits.images[0]</span></span><br><span class="line"><span class="string">array([[</span>  <span class="number">0</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.,</span>   <span class="number">5</span><span class="string">.,</span>  <span class="number">13</span><span class="string">.,</span>   <span class="number">9</span><span class="string">.,</span>   <span class="number">1</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.],</span></span><br><span class="line">       <span class="string">[</span>  <span class="number">0</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.,</span>  <span class="number">13</span><span class="string">.,</span>  <span class="number">15</span><span class="string">.,</span>  <span class="number">10</span><span class="string">.,</span>  <span class="number">15</span><span class="string">.,</span>   <span class="number">5</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.],</span></span><br><span class="line">       <span class="string">[</span>  <span class="number">0</span><span class="string">.,</span>   <span class="number">3</span><span class="string">.,</span>  <span class="number">15</span><span class="string">.,</span>   <span class="number">2</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.,</span>  <span class="number">11</span><span class="string">.,</span>   <span class="number">8</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.],</span></span><br><span class="line">       <span class="string">[</span>  <span class="number">0</span><span class="string">.,</span>   <span class="number">4</span><span class="string">.,</span>  <span class="number">12</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.,</span>   <span class="number">8</span><span class="string">.,</span>   <span class="number">8</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.],</span></span><br><span class="line">       <span class="string">[</span>  <span class="number">0</span><span class="string">.,</span>   <span class="number">5</span><span class="string">.,</span>   <span class="number">8</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.,</span>   <span class="number">9</span><span class="string">.,</span>   <span class="number">8</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.],</span></span><br><span class="line">       <span class="string">[</span>  <span class="number">0</span><span class="string">.,</span>   <span class="number">4</span><span class="string">.,</span>  <span class="number">11</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.,</span>   <span class="number">1</span><span class="string">.,</span>  <span class="number">12</span><span class="string">.,</span>   <span class="number">7</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.],</span></span><br><span class="line">       <span class="string">[</span>  <span class="number">0</span><span class="string">.,</span>   <span class="number">2</span><span class="string">.,</span>  <span class="number">14</span><span class="string">.,</span>   <span class="number">5</span><span class="string">.,</span>  <span class="number">10</span><span class="string">.,</span>  <span class="number">12</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.],</span></span><br><span class="line">       <span class="string">[</span>  <span class="number">0</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.,</span>   <span class="number">6</span><span class="string">.,</span>  <span class="number">13</span><span class="string">.,</span>  <span class="number">10</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.,</span>   <span class="number">0</span><span class="string">.]])</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;</span> <span class="string">from</span> <span class="string">sklearn</span> <span class="string">import</span> <span class="string">svm</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;</span> <span class="string">clf</span> <span class="string">=</span> <span class="string">svm.SVC(gamma=0.001,</span> <span class="string">C=100.)</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;</span> <span class="string">clf.fit(digits.data[:-1],digits.target[:-1])</span></span><br><span class="line"><span class="string">SVC(C=100.0,</span> <span class="string">cache_size=200,</span> <span class="string">class_weight=None,</span> <span class="string">coef0=0.0,</span> <span class="string">degree=3,</span></span><br><span class="line">  <span class="string">gamma=0.001,</span> <span class="string">kernel='rbf',</span> <span class="string">max_iter=-1,</span> <span class="string">probability=False,</span></span><br><span class="line">  <span class="string">random_state=None,</span> <span class="string">shrinking=True,</span> <span class="string">tol=0.001,</span> <span class="string">verbose=False)</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;</span> <span class="string">clf.predict(digits.data[-1])</span></span><br><span class="line"><span class="string">array([8])</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;</span></span><br></pre></td></tr></tbody></table></figure><hr><h3 id="4-scikit-learn学习RandomForest"><a href="#4-scikit-learn学习RandomForest" class="headerlink" title="4.scikit-learn学习RandomForest"></a><strong>4.scikit-learn学习RandomForest</strong></h3><p>使用例子</p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; from sklearn.ensemble import RandomForestClassifier</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; X = [[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; Y = [<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; clf = RandomForestClassifier(n_estimators=<span class="number">10</span>)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; clf = clf.fit(X, Y)</span><br></pre></td></tr></tbody></table></figure><p><strong>Method</strong></p><p>![](/assets/articleImg/2015-07-21 randomForest分类器的方法png.png)</p><p>randomForestClassifier分类器的初始值</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">def __init__(self,</span><br><span class="line"> <span class="attribute">n_estimators</span>=10,</span><br><span class="line"> <span class="attribute">criterion</span>=<span class="string">"gini"</span>,</span><br><span class="line"> <span class="attribute">max_depth</span>=None,</span><br><span class="line"> <span class="attribute">min_samples_split</span>=2,</span><br><span class="line"> <span class="attribute">min_samples_leaf</span>=1,</span><br><span class="line"> <span class="attribute">min_weight_fraction_leaf</span>=0.,</span><br><span class="line"> <span class="attribute">max_features</span>=<span class="string">"auto"</span>,</span><br><span class="line"> <span class="attribute">max_leaf_nodes</span>=None,</span><br><span class="line"> <span class="attribute">bootstrap</span>=<span class="literal">True</span>,</span><br><span class="line"> <span class="attribute">oob_score</span>=<span class="literal">False</span>,</span><br><span class="line"> <span class="attribute">n_jobs</span>=1,</span><br><span class="line"> <span class="attribute">random_state</span>=None,</span><br><span class="line"> <span class="attribute">verbose</span>=0,</span><br><span class="line"> <span class="attribute">warm_start</span>=<span class="literal">False</span>,</span><br><span class="line"> <span class="attribute">class_weight</span>=None):</span><br></pre></td></tr></tbody></table></figure><hr><br><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;一个Windows操作系统能够使用的pythonIDE&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;winPython下载地址：&lt;a href=&quot;http://sourceforge.net/projects/winpython/files/WinPython_2.7/2.7.10.1/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;WinPython_2.7&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;传统的F-measure或平衡的F-score (F1 score)是精度和召回的调和平均值：&lt;/p&gt;
&lt;p&gt;$$F_1 = 2 \times \dfrac{precision \times recall}{precision + recall}$$&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="交叉验证" scheme="https://www.csuldw.com/tags/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/"/>
    
      <category term="Cross-Validation" scheme="https://www.csuldw.com/tags/Cross-Validation/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-组合算法总结</title>
    <link href="https://www.csuldw.com/2015/07/22/2015-07-22%20%20ensemble/"/>
    <id>https://www.csuldw.com/2015/07/22/2015-07-22  ensemble/</id>
    <published>2015-07-21T22:53:00.000Z</published>
    <updated>2016-03-13T05:58:30.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="组合模型"><a href="#组合模型" class="headerlink" title="组合模型"></a><strong>组合模型</strong></h2><p>下面简单的介绍下Bootstraping, Bagging, Boosting, AdaBoost, RandomForest 和Gradient boosting这些组合型算法.</p><h3 id="1-Bootstraping"><a href="#1-Bootstraping" class="headerlink" title="1.Bootstraping"></a><strong>1.Bootstraping</strong></h3><p><strong>Bootstraping</strong>: 名字来自成语“pull up by your own bootstraps”，意思就是依靠你自己的资源，称为自助法，它是一种有放回的抽样方法，它是非参数统计中一种重要的估计统计量方差进而进行区间估计的统计方法。其核心思想和基本步骤如下：<br> <a id="more"></a></p><blockquote><p>（1）采用重抽样技术从原始样本中抽取一定数量（自己给定）的样本，此过程允许重复抽样。<br>（2）根据抽出的样本计算给定的统计量T。<br>（3）重复上述N次（一般大于1000），得到N个统计量T。<br>（4）计算上述N个统计量T的样本方差，得到统计量的方差。 </p></blockquote><p>应该说Bootstrap是现代统计学较为流行的一种统计方法，在小样本时效果很好。通过方差的估计可以构造置信区间等，其运用范围得到进一步延伸。</p><hr><h3 id="2-装袋bagging"><a href="#2-装袋bagging" class="headerlink" title="2.装袋bagging"></a><strong>2.装袋bagging</strong></h3><p>装袋算法相当于多个专家投票表决，对于多次测试，每个样本返回的是多次预测结果较多的那个。</p><p>装袋算法描述</p><figure class="highlight excel"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">模型生成</span><br><span class="line">令<span class="built_in">n</span>为训练数据的实例数量</span><br><span class="line">对于<span class="built_in">t</span>次循环中的每一次</span><br><span class="line">从训练数据中采样<span class="built_in">n</span>个实例</span><br><span class="line">将学习应用于所采样本</span><br><span class="line">保存结果模型</span><br><span class="line">分类</span><br><span class="line">对于<span class="built_in">t</span>个模型的每一个</span><br><span class="line">使用模型对实例进行预测</span><br><span class="line">返回被预测次数最多的一个</span><br></pre></td></tr></tbody></table></figure><p>bagging：bootstrap aggregating的缩写。让该学习算法训练多轮，每轮的训练集由从初始的训练集中随机取出的n个训练样本组成，某个初始训练样本在某轮训练集中可以出现多次或根本不出现，训练之后可得到一个预测函数序列</p><p>$$h_1，⋯ ⋯h_n$$ </p><p>最终的预测函数H对分类问题采用<strong>投票方式</strong>，对回归问题采用<strong>简单平均方法</strong>对新示例进行判别。</p><p>[训练R个分类器f_i，分类器之间其他相同就是参数不同。其中f_i是通过从训练集合中(N篇文档)随机取(取后放回)N次文档构成的训练集合训练得到的。对于新文档d，用这R个分类器去分类，得到的最多的那个类别作为d的最终类别。]</p><p>使用scikit-learn测试bagging方法</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> BaggingClassifier</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bagging = BaggingClassifier(KNeighborsClassifier(),</span><br><span class="line"><span class="meta">... </span>                            max_samples=<span class="number">0.5</span>, max_features=<span class="number">0.5</span>)</span><br></pre></td></tr></tbody></table></figure><hr><h3 id="3-提升Boosting与Adaboost"><a href="#3-提升Boosting与Adaboost" class="headerlink" title="3.提升Boosting与Adaboost"></a><strong>3.提升Boosting与Adaboost</strong></h3><p><strong>提升算法描述</strong></p><figure class="highlight stan"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">模型生成</span><br><span class="line">赋予每个训练实例相同的权值</span><br><span class="line">t次循环中的每一次：</span><br><span class="line">将学习算法应用于加了权的数据集上并保存结果模型</span><br><span class="line">计算模型在加了权的数据上的误差<span class="built_in">e</span>并保存这个误差</span><br><span class="line">结果<span class="built_in">e</span>等于<span class="number">0</span>或者大于等于<span class="number">0.5</span>：</span><br><span class="line">终止模型</span><br><span class="line">对于数据集中的每个实例：</span><br><span class="line">如果模型将实例正确分类</span><br><span class="line">将实例的权值乘以<span class="built_in">e</span>/(<span class="number">1</span>-<span class="built_in">e</span>)</span><br><span class="line">将所有的实例权重进行正常化</span><br><span class="line">分类</span><br><span class="line">赋予所有类权重为<span class="number">0</span></span><br><span class="line">对于t（或小于t）个模型中的每一个：</span><br><span class="line">给模型预测的类加权 -<span class="built_in">log</span>(<span class="built_in">e</span>/(<span class="number">1</span>-<span class="built_in">e</span>))</span><br><span class="line">返回权重最高的类</span><br></pre></td></tr></tbody></table></figure><p>这个模型提供了一种巧妙的方法生成一系列互补型的专家。</p><p><strong>boosting</strong>: 其中主要的是<strong>AdaBoost</strong>（Adaptive boosting，自适应boosting）。初始化时对每一个训练例赋相等的权重1／N，然后用该学算法对训练集训练t轮，每次训练后，对训练失败的训练例赋以较大的权重，也就是让学习算法在后续的学习中集中对比较难的训练例进行学习，从而得到一个预测函数序列$h_1,⋯, h_m$ , 其中h_i也有一定的权重，预测效果好的预测函数权重较大，反之较小。最终的预测函数H对分类问题采用有权重的投票方式，对回归问题采用加权平均的方法对新示例进行判别。</p><p>提升算法理想状态是这些模型对于其他模型来说是一个补充，每个模型是这个领域的一个专家，而其他模型在这部分却不能表现很好，就像执行官一样要寻觅那些技能和经验互补的顾问，而不是重复的。这与装袋算法有所区分。</p><p>Adaboost算法描述</p><figure class="highlight excel"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">模型生成</span><br><span class="line">训练数据中的每个样本，并赋予一个权重，构成权重向量D，初始值为<span class="number">1</span>/<span class="built_in">N</span></span><br><span class="line"><span class="built_in">t</span>次循环中的每一次：</span><br><span class="line">在训练数据上训练弱分类器并计算分类器的错误率e</span><br><span class="line">如果e等于<span class="number">0</span>或者大于等于用户指定的阈值：</span><br><span class="line">终止模型，break</span><br><span class="line">重新调整每个样本的权重，其中alpha=<span class="number">0.5</span>*<span class="built_in">ln</span>((<span class="number">1</span>-e)/e)</span><br><span class="line">对权重向量D进行更新，正确分类的样本的权重降低而错误分类的样本权重值升高</span><br><span class="line">对于数据集中的每个样例：</span><br><span class="line">如果某个样本正确分类：</span><br><span class="line">权重改为D^(<span class="built_in">t</span>+<span class="number">1</span>)_i = D^(<span class="built_in">t</span>)_i * e^(-a)/<span class="built_in">Sum</span>(D)</span><br><span class="line">如果某个样本错误分类：</span><br><span class="line">权重改为D^(<span class="built_in">t</span>+<span class="number">1</span>)_i = D^(<span class="built_in">t</span>)_i * e^(a)/<span class="built_in">Sum</span>(D)</span><br><span class="line">分类</span><br><span class="line">赋予所有类权重为<span class="number">0</span></span><br><span class="line">对于<span class="built_in">t</span>（或小于<span class="built_in">t</span>）个模型（基分类器）中的每一个：</span><br><span class="line">给模型预测的类加权 -<span class="built_in">log</span>(e/(<span class="number">1</span>-e))</span><br><span class="line">返回权重最高的类</span><br></pre></td></tr></tbody></table></figure><p>（类似Bagging方法，但是训练是串行进行的，第k个分类器训练时关注对前k-1分类器中错分的文档，即不是随机取，而是加大取这些文档的概率。)</p><p><strong>bagging与boosting的区别</strong>：</p><p>二者的主要区别是<strong>取样方式不同</strong>。bagging采用<strong>均匀取样</strong>，而Boosting根据<strong>错误率来取样</strong>，因此boosting的分类精度要优于Bagging。bagging的训练集的选择是随机的，各轮训练集之间相互独立，而boostlng的各轮训练集的选择与前面各轮的学习结果有关；bagging的各个预测函数没有权重，而boosting是有权重的；bagging的各个预测函数可以并行生成，而boosting的各个预测函数只能顺序生成。对于象神经网络这样极为耗时的学习方法。bagging可通过并行训练节省大量时间开销。</p><p>bagging和boosting都可以有效地提高分类的准确性。在大多数数据集中，boosting的准确性比bagging高。在有些数据集中，boosting会引起退化— Overfit。  </p><p>Boosting思想的一种改进型AdaBoost方法在邮件过滤、文本分类方面都有很好的性能。 </p><p><strong>Gradient boosting（又叫Mart, Treenet)</strong>：Boosting是一种思想，Gradient Boosting是一种实现Boosting的方法，它主要的思想是，每一次建立模型是在之前建立模型<strong>损失函数的梯度下降方向</strong>。<strong>损失函数(loss function)描述的是模型的不靠谱程度，损失函数越大，则说明模型越容易出错。</strong>如果我们的模型能够让损失函数持续的下降，则说明我们的模型在不停的改进，而最好的方式就是<strong>让损失函数在其梯度（Gradient)的方向上下降</strong>。  </p><p>使用scikit-learn测试adaboost算法</p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; from sklearn.cross_validation import cross_val_score</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; from sklearn.datasets import load_iris</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; from sklearn.ensemble import AdaBoostClassifier</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; iris = load_iris()</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; clf = AdaBoostClassifier(n_estimators=<span class="number">100</span>)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; scores = cross_val_score(clf, iris.data, iris.target)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; scores.mean()                             </span><br><span class="line"><span class="number">0</span>.<span class="number">9</span>...</span><br></pre></td></tr></tbody></table></figure><hr><h3 id="4-Random-Forest"><a href="#4-Random-Forest" class="headerlink" title="4.Random Forest"></a><strong>4.Random Forest</strong></h3><p><strong>Random Forest</strong>： 随机森林，顾名思义，是用随机的方式建立一个森林，森林里面有很多的决策树组成，随机森林的每一棵决策树之间是没有关联的。在得到森林之后，当有一个新的输入样本进入的时候，就让森林中的每一棵决策树分别进行一下判断，看看这个样本应该属于哪一类（对于分类算法），然后看看哪一类被选择最多，就预测这个样本为那一类。 在建立每一棵决策树的过程中，有两点需要注意——<strong>采样</strong>与<strong>完全分裂</strong>。首先是两个随机采样的过程，random forest对输入的数据要进行行和列的采样。对于行采样，采用有放回的方式，也就是在采样得到的样本集合中，可能有重复的样本。假设输入样本为N个，那么采样的样本也为N个。这样使得在训练的时候，每一棵树的输入样本都不是全部的样本，使得相对不容易出现over-fitting。然后进行列采样，从M个feature中，选择m个(m &lt;&lt; M)。之后就是对采样之后的数据使用完全分裂的方式建立出决策树，这样决策树的某一个叶子节点要么是无法继续分裂的，要么里面的所有样本的都是指向的同一个分类。<strong>一般很多的决策树算法都一个重要的步骤——剪枝，但随机森林不这样做，由于之前的两个随机采样的过程保证了随机性，所以就算不剪枝，也不会出现over-fitting。</strong> 按这种算法得到的随机森林中的每一棵都是很弱的，但是大家组合起来就很厉害了。可以这样比喻随机森林算法：每一棵决策树就是一个精通于某一个窄领域的专家（因为我们从M个feature中选择m让每一棵决策树进行学习），这样在随机森林中就有了很多个精通不同领域的专家，对一个新的问题（新的输入数据），可以用不同的角度去看待它，最终由各个专家，投票得到结果。  </p><p><strong>Random forest与bagging的区别</strong>：</p><p>(1)Random forest是选与输入样本的数目相同多的次数（可能一个样本会被选取多次，同时也会造成一些样本不会被选取到），而bagging一般选取比输入样本的数目少的样本；<br>(2)bagging是用全部特征来得到分类器，而Random forest是需要从全部特征中选取其中的一部分来训练得到分类器； <strong>一般Random forest效果比bagging效果好！</strong></p><p>使用scikit-learn测试随机森林算法</p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; from sklearn.ensemble import RandomForestClassifier</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; X = [[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; Y = [<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; clf = RandomForestClassifier(n_estimators=<span class="number">10</span>)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; clf = clf.fit(X, Y)</span><br></pre></td></tr></tbody></table></figure><h3 id="5-Gradient-boosting"><a href="#5-Gradient-boosting" class="headerlink" title="5.Gradient boosting"></a><strong>5.Gradient boosting</strong></h3><p>梯度提升树或者梯度提升回归树(GBRT)是任意一个不同损失函数的泛化。GBRT是一个灵敏的并且高效程序，可以用在回归和分类中。梯度提升树模型在许多领域中都有使用，如web搜索排行榜和社会生态学中。它主要的思想是，每一次建立模型是在之前建立模型损失函数的梯度下降方向。这句话有一点拗口，损失函数(loss function)描述的是模型的不靠谱程度，损失函数越大，则说明模型越容易出错（其实这里有一个方差、偏差均衡的问题，但是这里就假设损失函数越大，模型越容易出错）。如果我们的模型能够让损失函数持续的下降，则说明我们的模型在不停的改进，而最好的方式就是让损失函数在其梯度（Gradient)的方向上下降。</p><p>GRBT的优势：</p><ul><li>混合数据类型的自然处理</li><li>预测力强</li><li>健壮的输出空间</li></ul><p>Boosting主要是一种思想，表示“知错就改”。而Gradient Boosting是在这个思想下的一种函数（也可以说是模型）的优化的方法，首先将函数分解为可加的形式（其实所有的函数都是可加的，只是是否好放在这个框架中，以及最终的效果如何）。然后进行m次迭代，通过使得损失函数在梯度方向上减少，最终得到一个优秀的模型。值得一提的是，每次模型在梯度方向上的减少的部分，可以认为是一个“小”的或者“弱”的模型，最终我们会通过加权(也就是每次在梯度方向上下降的距离）的方式将这些“弱”的模型合并起来，形成一个更好的模型。</p><hr><br><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;组合模型&quot;&gt;&lt;a href=&quot;#组合模型&quot; class=&quot;headerlink&quot; title=&quot;组合模型&quot;&gt;&lt;/a&gt;&lt;strong&gt;组合模型&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;下面简单的介绍下Bootstraping, Bagging, Boosting, AdaBoost, RandomForest 和Gradient boosting这些组合型算法.&lt;/p&gt;
&lt;h3 id=&quot;1-Bootstraping&quot;&gt;&lt;a href=&quot;#1-Bootstraping&quot; class=&quot;headerlink&quot; title=&quot;1.Bootstraping&quot;&gt;&lt;/a&gt;&lt;strong&gt;1.Bootstraping&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Bootstraping&lt;/strong&gt;: 名字来自成语“pull up by your own bootstraps”，意思就是依靠你自己的资源，称为自助法，它是一种有放回的抽样方法，它是非参数统计中一种重要的估计统计量方差进而进行区间估计的统计方法。其核心思想和基本步骤如下：&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="组合算法" scheme="https://www.csuldw.com/tags/%E7%BB%84%E5%90%88%E7%AE%97%E6%B3%95/"/>
    
      <category term="ensemble" scheme="https://www.csuldw.com/tags/ensemble/"/>
    
  </entry>
  
  <entry>
    <title>机器学习scikit-learn入门教程（译）</title>
    <link href="https://www.csuldw.com/2015/07/21/2015-07-21-An-introduction-to-machine-learning-with-scikit-learn/"/>
    <id>https://www.csuldw.com/2015/07/21/2015-07-21-An-introduction-to-machine-learning-with-scikit-learn/</id>
    <published>2015-07-21T13:31:00.000Z</published>
    <updated>2016-03-08T08:57:48.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>原文链接：<a href="http://scikit-learn.github.io/dev/tutorial/basic/tutorial.html" target="_blank" rel="noopener">http://scikit-learn.github.io/dev/tutorial/basic/tutorial.html</a></p><p><strong>章节内容</strong></p><p>在这个章节中，我们主要介绍关于scikit-learn机器学习词库，并且将给出一个学习样例。</p><h2 id="机器学习：问题设置"><a href="#机器学习：问题设置" class="headerlink" title="机器学习：问题设置"></a><strong>机器学习：问题设置</strong></h2><p>通常，一个学习问题是通过一系列的n个样本数据来学习然后尝试预测未知数据的属性。如果每一个样本超过一个单一的数值，例如多维输入（也叫做多维数据），那么它就拥有了多个特征。</p><a id="more"></a><p>我们可以把学习问题划分为几个大的来别：</p><ul><li>监督学习: 在监督学习中，这些数据自带了我们想要预测的附加属性（<a href="http://scikit-learn.github.io/dev/supervised_learning.html#supervised-learning" target="_blank" rel="noopener">scikit-learn监督学习链接</a>），这个问题包括：<ul><li>分类：样本属于属于两类或者多类，我们想从已经被标记的数据中来预测未知数据的类别。一个分类问题的例子就是手写字识别。这个例子的目的是从有些的类别中识别出输入向量的类别。对于分类的另一种想法是作为监督学习的一种分离的表格(不是连续的)，在这个表格中，一个是被限制的类别数量，而且对于每个类别都有N个样例被提供；一个是尝试用正确的类别或者类来标记他们。</li><li>回归：如果期望的输出是由一个或者更多的连续的变量组成，那么就叫做回归。回归问题的例子将通过一条鲑鱼的年龄和重量预测它的长度。</li></ul></li><li>无监督学习：在无监督学习里面，训练数据是由一组没有任何类别标签值的一系列输入向量组成。这种问题的目的是可能可以在这些数据里发现相似的样例组，这些相似的样例被称作聚类。或者在输入空间里决定数据分布，称之为密度估算；或者将数据从高维空间映射到二维或三维空间中，称之为数据可视化问题。（<a href="http://scikit-learn.github.io/dev/unsupervised_learning.html#unsupervised-learning" target="_blank" rel="noopener">无监督学习链接</a>）</li></ul><p><strong>训练集和测试集</strong></p><p>机器学习是关于学习数据集的一些属性然后将它们应用到新的数据上。这就是为什么在机器学习中评价一个算法的通常惯例是把数据集切分为两个数据集，其中一个叫做训练集，用来学习数据的属性；另一个叫做测试集，在测试集上测试那些属性。</p><h2 id="加载样本数据集"><a href="#加载样本数据集" class="headerlink" title="加载样本数据集"></a><strong>加载样本数据集</strong></h2><p>scikit-learn带有一些标准的数据集，例如用于分类的<a href="http://en.wikipedia.org/wiki/Iris_flower_data_set" target="_blank" rel="noopener">iris</a>和<a href="http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits" target="_blank" rel="noopener">digit</a>数据集和用于回归的<a href="http://archive.ics.uci.edu/ml/datasets/Housing" target="_blank" rel="noopener"> boston house prices dataset </a>.</p><p>下面，我们打开Python编译器，然后载入<strong>iris</strong>和digits数据集。我们的符号’$’表示shell提示，’&gt;&gt;&gt;’表示Python编译器提示</p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ python</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; from sklearn import datasets</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; iris = datasets.load_iris()</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; digits = datasets.load_digits()</span><br></pre></td></tr></tbody></table></figure><p> 数据集是一个类似字典的对象，包含所有的数据和一些和数据有关的元数据。数据存储在.data中，是个n_samples,n_features的数组。在监督问题的情况下，一个或多个类别变量存储在.target成员中。更多有关的不同数据集的细节可以在<a href="http://scikit-learn.github.io/dev/datasets/index.html#datasets" target="_blank" rel="noopener">dedicated section</a>查找。</p><p> 例如，在digits数据集情况下，digits.data 提供了可用于分类数字样本。</p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; print(digits.data)  </span><br><span class="line">[[  <span class="number">0.</span>   <span class="number">0.</span>   <span class="number">5.</span> ...,   <span class="number">0.</span>   <span class="number">0.</span>   <span class="number">0.</span>]</span><br><span class="line"> [  <span class="number">0.</span>   <span class="number">0.</span>   <span class="number">0.</span> ...,  <span class="number">10.</span>   <span class="number">0.</span>   <span class="number">0.</span>]</span><br><span class="line"> [  <span class="number">0.</span>   <span class="number">0.</span>   <span class="number">0.</span> ...,  <span class="number">16.</span>   <span class="number">9.</span>   <span class="number">0.</span>]</span><br><span class="line"> ...,</span><br><span class="line"> [  <span class="number">0.</span>   <span class="number">0.</span>   <span class="number">1.</span> ...,   <span class="number">6.</span>   <span class="number">0.</span>   <span class="number">0.</span>]</span><br><span class="line"> [  <span class="number">0.</span>   <span class="number">0.</span>   <span class="number">2.</span> ...,  <span class="number">12.</span>   <span class="number">0.</span>   <span class="number">0.</span>]</span><br><span class="line"> [  <span class="number">0.</span>   <span class="number">0.</span>  <span class="number">10.</span> ...,  <span class="number">12.</span>   <span class="number">1.</span>   <span class="number">0.</span>]]</span><br></pre></td></tr></tbody></table></figure><p>并且digits.target给出了digit数据集的真实结果，这些数字是和我们正在学习的每个数字图像相关的数字。</p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; digits.target</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, ..., <span class="number">8</span>, <span class="number">9</span>, <span class="number">8</span>])</span><br></pre></td></tr></tbody></table></figure><p><strong>数组的形状</strong></p><p>数据总是一些2D数组，shape(n_samples,n_features),尽管原始数据也许有一个不同的形状，就这个digits而言，每一个原始样例是一个shape(8,8)的图像，并且能被访问使用:</p><figure class="highlight lsl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; digits.images[<span class="number">0</span>]</span><br><span class="line">array([[  <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">5.</span>,  <span class="number">13.</span>,   <span class="number">9.</span>,   <span class="number">1.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>],</span><br><span class="line">       [  <span class="number">0.</span>,   <span class="number">0.</span>,  <span class="number">13.</span>,  <span class="number">15.</span>,  <span class="number">10.</span>,  <span class="number">15.</span>,   <span class="number">5.</span>,   <span class="number">0.</span>],</span><br><span class="line">       [  <span class="number">0.</span>,   <span class="number">3.</span>,  <span class="number">15.</span>,   <span class="number">2.</span>,   <span class="number">0.</span>,  <span class="number">11.</span>,   <span class="number">8.</span>,   <span class="number">0.</span>],</span><br><span class="line">       [  <span class="number">0.</span>,   <span class="number">4.</span>,  <span class="number">12.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">8.</span>,   <span class="number">8.</span>,   <span class="number">0.</span>],</span><br><span class="line">       [  <span class="number">0.</span>,   <span class="number">5.</span>,   <span class="number">8.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">9.</span>,   <span class="number">8.</span>,   <span class="number">0.</span>],</span><br><span class="line">       [  <span class="number">0.</span>,   <span class="number">4.</span>,  <span class="number">11.</span>,   <span class="number">0.</span>,   <span class="number">1.</span>,  <span class="number">12.</span>,   <span class="number">7.</span>,   <span class="number">0.</span>],</span><br><span class="line">       [  <span class="number">0.</span>,   <span class="number">2.</span>,  <span class="number">14.</span>,   <span class="number">5.</span>,  <span class="number">10.</span>,  <span class="number">12.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>],</span><br><span class="line">       [  <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">6.</span>,  <span class="number">13.</span>,  <span class="number">10.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>]])</span><br></pre></td></tr></tbody></table></figure><p><a href="http://scikit-learn.github.io/dev/auto_examples/classification/plot_digits_classification.html#example-classification-plot-digits-classification-py" target="_blank" rel="noopener">simple example on this dataset </a>这个数据集表明了在scikit-learn中怎样从原始问题开始着手制作数据。</p><h2 id="学习和预测"><a href="#学习和预测" class="headerlink" title="学习和预测"></a><strong>学习和预测</strong></h2><p>在digits数据集中，给定一幅手写数字的数字图像，任务是预测结果。我们给定的样本有10种类别（是数字0到9），基于此我们建立一个估计方法能够预测我们没有见过的样本属于哪一类。</p><p>在scikit-learn中，用于分类的估计模型是一个实现了fit(x,y)方法和predict(T)方法的Python对象。</p><p>估计模型的例子是在实现了<a href="http://en.wikipedia.org/wiki/Support_vector_machine" target="_blank" rel="noopener">support vector classification支持向量机</a>的类 sklearn.svm.SVC。估计模型的构造函数带有模型参数，但是目前，我们将估计模型当做一个黑盒子。</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; <span class="keyword">from</span> sklearn import svm  </span><br><span class="line">&gt;&gt;&gt; clf = svm.SVC(<span class="attribute">gamma</span>=0.001, <span class="attribute">C</span>=100.)</span><br></pre></td></tr></tbody></table></figure><p><strong>选择模型参数</strong></p><p>在这个例子中，我们这设定了gamma值。可以通过使用<a href="http://scikit-learn.github.io/dev/modules/grid_search.html#grid-search" target="_blank" rel="noopener">网格搜索</a>和<a href="http://scikit-learn.github.io/dev/modules/cross_validation.html#cross-validation" target="_blank" rel="noopener">交叉验证</a>自动的找出最好的参数值</p><p>我们把我们的评估模型命名为clf，作为一个分类器，它现在必须拟合这个模型，也就是它必须从这个模型学习。我们通过将数据集传递给fit函数完成。作为训练集，除了最后一个样本，我们选择其余的所有样本。通过python语句[:-1]选择样本，这条语句将从digits.data中产生一个除了最后一个样本的新数组。</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">clf.fit(digits.data[:-1], digits.target[:-1])    </span><br><span class="line">SVC(<span class="attribute">C</span>=100.0, <span class="attribute">cache_size</span>=200, <span class="attribute">class_weight</span>=None, <span class="attribute">coef0</span>=0.0, <span class="attribute">degree</span>=3,  </span><br><span class="line">  <span class="attribute">gamma</span>=0.001, <span class="attribute">kernel</span>=<span class="string">'rbf'</span>, <span class="attribute">max_iter</span>=-1, <span class="attribute">probability</span>=<span class="literal">False</span>,  </span><br><span class="line">  <span class="attribute">random_state</span>=None, <span class="attribute">shrinking</span>=<span class="literal">True</span>, <span class="attribute">tol</span>=0.001, <span class="attribute">verbose</span>=<span class="literal">False</span>)</span><br></pre></td></tr></tbody></table></figure><p>现在，我们可以预测新值，尤其是我们可以问分类器在digits数据集中的用来训练分类器时没有使用的最后一个数据是数字几：</p><p>相应的图像如下所示:</p><center>![这里写图片描述](http://img.blog.csdn.net/20150720185355481)</center><p>正如你看到的，这是一个具有挑战性的任务：图象的分辨率很低。你认同这个分类器吗？</p><p>一个完整的分类问题实例可以通过下面的链接下载，用来作为你运行并且学习的例子 <a href="http://scikit-learn.github.io/dev/auto_examples/classification/plot_digits_classification.html#example-classification-plot-digits-classification-py" target="_blank" rel="noopener">Recognizing hand-written digits</a></p><h2 id="模型持久化"><a href="#模型持久化" class="headerlink" title="模型持久化"></a><strong>模型持久化</strong></h2><p>可以通过使用python的built-in持久化模型在scikit中保存一个模型，命名<a href="http://docs.python.org/library/pickle.html" target="_blank" rel="noopener">pickle</a>:</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; <span class="keyword">from</span> sklearn import svm</span><br><span class="line">&gt;&gt;&gt; <span class="keyword">from</span> sklearn import datasets</span><br><span class="line">&gt;&gt;&gt; clf = svm.SVC()</span><br><span class="line">&gt;&gt;&gt; iris = datasets.load_iris()</span><br><span class="line">&gt;&gt;&gt; X, y = iris.data, iris.target</span><br><span class="line">&gt;&gt;&gt; clf.fit(X, y)  </span><br><span class="line">SVC(<span class="attribute">C</span>=1.0, <span class="attribute">cache_size</span>=200, <span class="attribute">class_weight</span>=None, <span class="attribute">coef0</span>=0.0,</span><br><span class="line">  <span class="attribute">decision_function_shape</span>=None, <span class="attribute">degree</span>=3, <span class="attribute">gamma</span>=<span class="string">'auto'</span>, <span class="attribute">kernel</span>=<span class="string">'rbf'</span>,</span><br><span class="line">  <span class="attribute">max_iter</span>=-1, <span class="attribute">probability</span>=<span class="literal">False</span>, <span class="attribute">random_state</span>=None, <span class="attribute">shrinking</span>=<span class="literal">True</span>,</span><br><span class="line">  <span class="attribute">tol</span>=0.001, <span class="attribute">verbose</span>=<span class="literal">False</span>)</span><br><span class="line">&gt;&gt;&gt; import pickle</span><br><span class="line">&gt;&gt;&gt; s = pickle.dumps(clf)</span><br><span class="line">&gt;&gt;&gt; clf2 = pickle.loads(s)</span><br><span class="line">&gt;&gt;&gt; clf2.predict(X[0])</span><br><span class="line">array([0])</span><br><span class="line">&gt;&gt;&gt; y[0]</span><br><span class="line">0</span><br></pre></td></tr></tbody></table></figure><p>在scikit的特别情况下，使用joblib替换pickle(joblib.dump &amp; joblib.load)会更有趣,它在大数据上是更有效的，但是仅仅只能存入的是字典而不是字符串。</p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; from sklearn.externals import joblib</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; joblib.dump(clf, <span class="string">'filename.pkl'</span>)</span><br></pre></td></tr></tbody></table></figure><p>然后你就可以读取上面的pickled模型使用了（通常是在其它的Python程序中）：</p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; clf = joblib.load(<span class="string">'filename.pkl'</span>)</span><br></pre></td></tr></tbody></table></figure><h2 id="惯例"><a href="#惯例" class="headerlink" title="惯例"></a><strong>惯例</strong></h2><p>scikit-learn估计量有一些特定的规则是的分类器更具有预测性</p><p><strong>Type casting 类型转换</strong></p><p>除非特别指定，否则输入格式是float64</p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; import numpy as np</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; from sklearn import random_projection</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; rng = np.random.RandomState(<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; X = rng.rand(<span class="number">10</span>, <span class="number">2000</span>)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; X = np.array(X, dtype=<span class="string">'float32'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; X.dtype</span><br><span class="line">dtype(<span class="string">'float32'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; transformer = random_projection.GaussianRandomProjection()</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; X_new = transformer.fit_transform(X)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; X_new.dtype</span><br><span class="line">dtype(<span class="string">'float64'</span>)</span><br></pre></td></tr></tbody></table></figure><p>在这个例子中，X是float32，通过fit_transform(X)把它转为float64</p><p>回归的输出值是float64，分类的也是：</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; <span class="keyword">from</span> sklearn import datasets</span><br><span class="line">&gt;&gt;&gt; <span class="keyword">from</span> sklearn.svm import SVC</span><br><span class="line">&gt;&gt;&gt; iris = datasets.load_iris()</span><br><span class="line">&gt;&gt;&gt; clf = SVC()</span><br><span class="line">&gt;&gt;&gt; clf.fit(iris.data, iris.target)  </span><br><span class="line">SVC(<span class="attribute">C</span>=1.0, <span class="attribute">cache_size</span>=200, <span class="attribute">class_weight</span>=None, <span class="attribute">coef0</span>=0.0,</span><br><span class="line">  <span class="attribute">decision_function_shape</span>=None, <span class="attribute">degree</span>=3, <span class="attribute">gamma</span>=<span class="string">'auto'</span>, <span class="attribute">kernel</span>=<span class="string">'rbf'</span>,</span><br><span class="line">  <span class="attribute">max_iter</span>=-1, <span class="attribute">probability</span>=<span class="literal">False</span>, <span class="attribute">random_state</span>=None, <span class="attribute">shrinking</span>=<span class="literal">True</span>,</span><br><span class="line">  <span class="attribute">tol</span>=0.001, <span class="attribute">verbose</span>=<span class="literal">False</span>)</span><br><span class="line">&gt;&gt;&gt; list(clf.predict(iris.data[:3]))</span><br><span class="line">[0, 0, 0]</span><br><span class="line">&gt;&gt;&gt; clf.fit(iris.data, iris.target_names[iris.target])  </span><br><span class="line">SVC(<span class="attribute">C</span>=1.0, <span class="attribute">cache_size</span>=200, <span class="attribute">class_weight</span>=None, <span class="attribute">coef0</span>=0.0,</span><br><span class="line">  <span class="attribute">decision_function_shape</span>=None, <span class="attribute">degree</span>=3, <span class="attribute">gamma</span>=<span class="string">'auto'</span>, <span class="attribute">kernel</span>=<span class="string">'rbf'</span>,</span><br><span class="line">  <span class="attribute">max_iter</span>=-1, <span class="attribute">probability</span>=<span class="literal">False</span>, <span class="attribute">random_state</span>=None, <span class="attribute">shrinking</span>=<span class="literal">True</span>,</span><br><span class="line">  <span class="attribute">tol</span>=0.001, <span class="attribute">verbose</span>=<span class="literal">False</span>)</span><br><span class="line">&gt;&gt;&gt; list(clf.predict(iris.data[:3]))  </span><br><span class="line">[<span class="string">'setosa'</span>, <span class="string">'setosa'</span>, <span class="string">'setosa'</span>]</span><br></pre></td></tr></tbody></table></figure><p>这里，第一次predict()返回的是一个整数数组，因为在拟合中用到了iris.target（一个整数数组），第二个predict返回的是一个字符串数组，因为用来拟合的是iris.target_names。</p><h2 id="Supplementary"><a href="#Supplementary" class="headerlink" title="Supplementary"></a>Supplementary</h2><p>推介一个好用的python IDE：</p><blockquote><p>winPython下载地址：<a href="http://sourceforge.net/projects/winpython/files/WinPython_2.7/2.7.10.1/" target="_blank" rel="noopener">WinPython_2.7</a></p></blockquote><hr><br><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;原文链接：&lt;a href=&quot;http://scikit-learn.github.io/dev/tutorial/basic/tutorial.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://scikit-learn.github.io/dev/tutorial/basic/tutorial.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;章节内容&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在这个章节中，我们主要介绍关于scikit-learn机器学习词库，并且将给出一个学习样例。&lt;/p&gt;
&lt;h2 id=&quot;机器学习：问题设置&quot;&gt;&lt;a href=&quot;#机器学习：问题设置&quot; class=&quot;headerlink&quot; title=&quot;机器学习：问题设置&quot;&gt;&lt;/a&gt;&lt;strong&gt;机器学习：问题设置&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;通常，一个学习问题是通过一系列的n个样本数据来学习然后尝试预测未知数据的属性。如果每一个样本超过一个单一的数值，例如多维输入（也叫做多维数据），那么它就拥有了多个特征。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="scikit-learn" scheme="https://www.csuldw.com/tags/scikit-learn/"/>
    
      <category term="译文" scheme="https://www.csuldw.com/tags/%E8%AF%91%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>一个简单的Python函数运行时间计时器</title>
    <link href="https://www.csuldw.com/2015/07/16/2015-07-16%20Python%20timer/"/>
    <id>https://www.csuldw.com/2015/07/16/2015-07-16 Python timer/</id>
    <published>2015-07-16T12:24:25.000Z</published>
    <updated>2016-03-13T05:58:44.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在实际开发中，往往想要计算一段代码运行多长时间，下面我将该功能写入到一个函数里面，只要在每个函数前面调用该函数即可，见下面代码：</p><a id="more"></a><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#--------------------------------</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> wraps  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun_timer</span><span class="params">(function)</span>:</span></span><br><span class="line"><span class="meta">    @wraps(function)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">function_timer</span><span class="params">(*args, **kwargs)</span>:</span></span><br><span class="line">        t0 = time.time()</span><br><span class="line">        result = function(*args, **kwargs)</span><br><span class="line">        t1 = time.time()</span><br><span class="line">        os.system(<span class="string">" echo Total time running %s: %s seconds"</span> % (function.func_name, str(t1-t0)) + <span class="string">" &gt;&gt; timecount.log"</span>)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    <span class="keyword">return</span> function_timer</span><br><span class="line"><span class="comment">#-----------------------------------</span></span><br></pre></td></tr></tbody></table></figure><p>说明：<font color="green"><strong>一个记时器，只要在函数前面写上@fun_timer即可</strong></font>.</p><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在实际开发中，往往想要计算一段代码运行多长时间，下面我将该功能写入到一个函数里面，只要在每个函数前面调用该函数即可，见下面代码：&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://www.csuldw.com/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.csuldw.com/tags/Python/"/>
    
      <category term="计时器" scheme="https://www.csuldw.com/tags/%E8%AE%A1%E6%97%B6%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>开发者成功使用机器学习的十大诀窍(译)</title>
    <link href="https://www.csuldw.com/2015/07/13/2015-07-13-10%20keys%20to%20successful%20machine%20learning%20for%20developers/"/>
    <id>https://www.csuldw.com/2015/07/13/2015-07-13-10 keys to successful machine learning for developers/</id>
    <published>2015-07-13T13:53:12.000Z</published>
    <updated>2016-03-13T05:58:58.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><div style="text-align:right;padding-bottom:7px;">译者：<a href="http://blog.csdn.net/dream_angel_z" target="_blank" rel="noopener">刘帝伟</a>   审校：刘翔宇 朱正贵   责编：周建丁</div><p>在提供发现埋藏数据深层的模式的能力上，机器学习有着潜在的能力使得应用程序更加的强大并且更能响应用户的需求。精心调校好的算法能够从巨大的并且互不相同的数据源中提取价值，同时没有人类思考和分析的限制。对于开发者而言，机器学习为应用业务的关键分析提供了希望，从而实现从改善客户体验到提供产品推荐上升至超个性化内容服务的任何应用程序。</p><a id="more"></a><p>像Amazon和Micorosoft这样的云供应商提供云功能的机器学习解决方案，承诺为开发者提供一个简单的方法，使得机器学习的能力能够融入到他们的应用程序当中，这也算是最近的头条新闻了。承诺似乎很好，但开发者还需谨慎。</p><p>对于开发人员而言，基于云的机器学习工具带来了使用机器学习创造和提供新的功能的可能性。然而，当我们使用不当时，这些工具会输出不好的结果，用户可能会因此而感到不安。测试过<a href="http://how-old.net/" target="_blank" rel="noopener">微软年龄检测机器学习工具</a>的人都会发现，伴随即插即用的易用性而来的是主要的精度问题——对于关键应用程序或者是重大决策，它应该不值得信赖。</p><p>想要在应用程序中成功地融入机器学习的开发者，需要注意以下的一些关键要点：</p><p><strong>1.算法使用的数据越多，它的精度会更加准确，所以如果可能要尽量避免抽样。</strong>机器学习理论在预测误差上有着非常直观的描述。简而言之，在机器学习模型和最优预测（在理论上达到最佳可能的误差）之间的预测误差的差距可以被分解为三个部分：</p><ul><li>由于没有找到正确函数形式的模型的误差</li><li>由于没有找到最佳参数的模型的误差</li><li>由于没用使用足够数据的模型的误差</li><li>如果训练集有限，它可能无法支撑解决这个问题所需的模型复杂性。统计学的基本规律告诉我们，如果我们可以的话，应该利用所有的数据而不是抽样。</li></ul><p><strong>2.对给定的问题选择效果最好的机器学习算法是决定成败的关键。</strong>例如，梯度提升树（GBT）是一个非常受欢迎的监督学习算法，由于其精度而被业内开发人员广泛使用。然而，尽管其高度受欢迎，我们也不能盲目的把这种算法应用于任何问题上。相反，我们使用的算法应该是能够最佳地拟合数据特征同时能够保证精度的算法。</p><p>为了证明这个观点，尝试做这样一个实验，在数据集 <a href="http://www.daviddlewis.com/resources/testcollections/rcv1/" target="_blank" rel="noopener">the popular text categorization dataset rcv1</a>上测试GBT算法和线性支持向量机（SVM）算法，并比较两者的精度。我们观察到在这个问题上，就错误率而言，线性SVM要优于GBT算法。这是因为在文本领域当中，数据通常是高维的。一个线性分类器能够在N-1维当中完美的分离出N个样本，所以，一个样本模型在这种数据上通常表现的更好。此外，模型越简单，通过利用有限的训练样本来避免过拟合的方式学习参数，并且提供一个精确的模型，产生的问题也会随之越少。</p><p>另一方面，GBT是高度非线性的并且更加强大，但是在这种环境中却更难学习并且更容易发生过拟合，往往结果精度也较低。</p><p><strong>3.为了得到一个更好的模型，必须选择最佳的的算法和相关的参数。</strong>这对于非数据科学家而言可能不容易。现代的机器学习算法有许多的参数可以调整。例如，对于流行的GBT算法单独的就有十二个参数可以设置，其中包括如何控制树的大小，学习率，行或列的采样方法，损失函数，正则化选项等等。一个特有的项目需要在给定的数据集上为每一个参数找到其最优值并且达到最精准的精度，这确实不是一件容易的事。但是为了得到最佳的结果，数据科学家需要训练大量的模型，而直觉和经验会帮助他们根据交叉验证的得分，然后决定使用什么参数再次尝试。</p><p><strong>4.机器学习模型会随着好的数据而变得更好，错误的数据收集和数据处理会降低你建立预测和归纳的机器学习模型的能力。</strong>根据经验，建议仔细审查与主题相关的数据，从而深入了解数据和幕后数据的生成过程。通常这个过程可以识别与记录、特征、值或采样相关的数据质量问题。</p><p><strong>5.理解数据特征并改进它们（通过创造新的特征或者去掉某个特征）对预测能力有着高度的影响。</strong>机器学习的一个基本任务就是找到能够被机器学习算法充分利用的丰富特征空间来替代原始数据。例如，特征转换是一种流行的方法，可以通过在原始数据的基础上使用数学上的转换提取新的特征来实现。最后的特征空间（也就是最后用来描述数据的特征）要能更好的捕获数据的多复杂性（如非线性和多种特征之间的相互作用），这对于成功的学习过程至关重要。</p><p><strong>6.在应用中，选择合适的灵感来自商业价值的目标函数/损失函数对于最后的成功至关重要。</strong>几乎所有的机器学习算法最后都被当成是一种优化问题。根据业务的性质，合理设置或调整优化的目标函数，是机器学习成功的关键。</p><p>以支持向量机为例，通过假设所有错误类型的权重相等，对一个二分类问题的泛化误差进行了优化。这对损失敏感的问题并不合适，如故障检测，其中某些类型的错误比重可能比其它类型的要高。在这种情况下，建议通过在特定的错误类型上，增加更多的惩罚来解释它们的权重，从而调整SVM的损失函数。</p><p><strong>7.确保正确地处理训练数据和测试数据，如此当在生产中部署该模型时，测试数据能够模拟输入数据。</strong>例如，我们可以看到，这对于时间依赖性数据是多么的重要。在这种情况下，使用标准的交叉验证方法进行训练，调整，那么测试模型的结果可能会有偏差，甚至会不准确。这是因为在实施平台上它不能准确的模拟输入数据的性质。为了纠正这一点，在部署时我们必须仿照模型来部署使用。我们应该使用一个基于时间的交叉验证，用时间较新的数据来验证训练模型。</p><p><strong>8.部署前理解模型的泛化误差。泛化误差衡量模型在未知数据上的性能好坏。</strong>因为一个模型在训练数据上的性能好并不意味着它在未知的数据上的表现也好。一个精心设计的模拟实际部署使用的模型评估过程，是估计模型泛化误差所需要的。</p><p>一不留心就很容易违反交叉验证的规则，并且也没有一种显而易见的方法来表现交叉验证的非正确性，通常在你试图寻找快捷方式计算时发生。在任何模型部署之前，有必要仔细注意交叉验证的正确性，以获得部署性能的科学评估。</p><p><strong>9.知道如何处理非结构化和半结构化数据，如文本、时间序列、空间、图形或者图像数据。</strong>大多数机器学习算法在处理特征空间中的数据时，一个特征集代表一个对象，特征集的每一个元素都描述对象的一个特点。在实际当中，数据引进时并不是这种格式化的形式，往往来自于最原始的格式，并且最后都必须被改造成机器学习算法能够识别的理想格式。比如，我们必须知道如何使用各种计算机视觉技术从图像中提取特征或者如何将自然语言处理技术应用于影片文本。</p><p><strong>10.学会将商业问题转换成机器学习算法。</strong>一些重要的商业问题，比如欺诈检测、产品推荐、广告精准投放，都有“标准”的机器学习表达形式并且在实践当中取得了合理的成就。即使对于这些众所周知的问题，也还有鲜为人知但功能更强大的表达形式，从而带来更高的预测精度。对于一般在博客和论坛中讨论的小实例的商业问题，适当的机器学习方法则不太明显。</p><p>如果你是一个开发者，学习这十个通往成功的诀窍可能似乎是一个艰难的任务，但是不要气馁。事实上，开发者不是数据科学家。认为开发人员可以充分利用所有的机学习工具是不公平的。但是这并不意味着开发人员没有机会去学习一些有水准的数据科学从而改进他们的应用。随着适当的企业解决方案和自动化程度的提高，开发人员可以做模型构建到实施部署的一切事情，使用机器学习最佳实践来保持高精度。</p><p>自动化是在应用程序中扩展机器学习的关键。即使你能够供得起一批小的数据科学家团队和开发者携手合作，也没有足够的人才。像Skytree的AutoModel（自动化模型）能够帮助开发者自动地确定最佳的参数并且使得算法得到最大的模型精度。一个易于使用的接口可以引导开发人员通过训练加工，调整并且测试模型来防止统计上的错误。</p><p>自动化机器学习过程，有许多方式，包括数据科学家或开发者的人工智能原理，允许算法去思考，学习并且承受更多的建模重任。也就是说，认为数据科学家能够从机器学习中解耦是错误的，特别是在关键任务模型上。谨防这种能够简单使用机器学习功能的承诺，即能够在不需要正确复杂的思考下或者可扩展的应用技术下就使用机器学习——这通常并不会得到高预测精度和机器学习提供的高商业价值结果。更糟糕的是，在应用程序中使用不好的模型实际上可能会适得其反，并迅速在其用户之间建立不信任的产品或服务。</p><p>英文原文： <a href="http://www.infoworld.com/article/2943862/application-development/what-developers-need-to-know-about-machine-learning.html" target="_blank" rel="noopener">10 keys to successful machine learning for developers</a> （译者/<a href="http://blog.csdn.net/dream_angel_z" target="_blank" rel="noopener">刘帝伟</a> 审校/刘翔宇、朱正贵 责编/周建丁）</p><p>作者简介：Alexander Gray，Skytree首席技术官，佐治亚理工学院计算机学院副教授，主要致力于大规模数据集的机器学习算法技术研发，1993年开始在NASA喷气推进实验室机器学习系统小组从事大规模科学数据的工作。</p><p>译者简介： <a href="http://blog.csdn.net/dream_angel_z" target="_blank" rel="noopener">刘帝伟</a>，中南大学软件学院在读研究生，关注机器学习、数据挖掘及生物信息领域。</p><p>【预告】<a href="http://ccai2015.csdn.net/" target="_blank" rel="noopener">首届中国人工智能大会（CCAI 2015）</a>将于7月26-27日在北京友谊宾馆召开。机器学习与模式识别、大数据的机遇与挑战、人工智能与认知科学、智能机器人四个主题专家云集。人工智能产品库将同步上线，预约咨询：QQ：1192936057。欢迎关注。</p><p>本文为CSDN编译整理，未经允许不得转载，如需转载请联系market#csdn.net(#换成@)</p><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;div style=&quot;text-align:right;padding-bottom:7px;&quot;&gt;译者：&lt;a href=&quot;http://blog.csdn.net/dream_angel_z&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;刘帝伟&lt;/a&gt;   审校：刘翔宇 朱正贵   责编：周建丁&lt;/div&gt;

&lt;p&gt;在提供发现埋藏数据深层的模式的能力上，机器学习有着潜在的能力使得应用程序更加的强大并且更能响应用户的需求。精心调校好的算法能够从巨大的并且互不相同的数据源中提取价值，同时没有人类思考和分析的限制。对于开发者而言，机器学习为应用业务的关键分析提供了希望，从而实现从改善客户体验到提供产品推荐上升至超个性化内容服务的任何应用程序。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="译文" scheme="https://www.csuldw.com/tags/%E8%AF%91%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>数据预处理-PDB文件</title>
    <link href="https://www.csuldw.com/2015/07/07/2015-07-07-PDB/"/>
    <id>https://www.csuldw.com/2015/07/07/2015-07-07-PDB/</id>
    <published>2015-07-07T15:23:23.000Z</published>
    <updated>2016-03-08T08:48:56.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>以下代码为个人原创，python实现，是处理PDB文件的部分常用代码，仅供参考！</p><h3 id="1-下载PDB文件"><a href="#1-下载PDB文件" class="headerlink" title="1.下载PDB文件"></a>1.下载PDB文件</h3><p>下面是一个下载PDB文件的函数，传入的参数是一个写有pdb名字的namefile文件，函数的核心部分是三个系统命令，先通过wget下载，然后解压，最后替换名字。</p><a id="more"></a><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">downloadpdb</span><span class="params">(namefile)</span>:</span></span><br><span class="line">    inputfile = open(namefile, <span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">for</span> eachline <span class="keyword">in</span> inputfile:</span><br><span class="line">        pdbname = eachline.lower().strip()</span><br><span class="line">        os.system(<span class="string">"wget http://ftp.wwpdb.org/pub/pdb/data/structures/all/pdb/pdb"</span> + pdbname + <span class="string">".ent.gz"</span>)</span><br><span class="line">        os.system(<span class="string">"gzip -d pdb"</span> + pdbname + <span class="string">'.ent.gz'</span>)</span><br><span class="line">        os.system(<span class="string">"mv pdb"</span> + pdbname + <span class="string">".ent "</span> + pdbname.upper() + <span class="string">'.pdb'</span>)</span><br></pre></td></tr></tbody></table></figure><p>测试用例</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">os.chdir(<span class="string">'/ifs/home/liudiwei/datasets/RPdatas'</span>)</span><br><span class="line">downloadpdb(<span class="string">'protein.name'</span>)</span><br></pre></td></tr></tbody></table></figure><h3 id="2-PDB转DSSP"><a href="#2-PDB转DSSP" class="headerlink" title="2.PDB转DSSP"></a>2.PDB转DSSP</h3><p>将下载的PDB文件转成DSSP文件</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 处理一行dssp数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">formatdsspline</span><span class="params">(dsspline)</span>:</span></span><br><span class="line">    eachline  = dsspline</span><br><span class="line">    col = <span class="string">'\t'</span> + eachline[<span class="number">0</span>:<span class="number">5</span>]</span><br><span class="line">    col += <span class="string">'\t'</span> + eachline[<span class="number">5</span>:<span class="number">10</span>]</span><br><span class="line">    col += <span class="string">'\t'</span> + eachline[<span class="number">10</span>:<span class="number">12</span>]</span><br><span class="line">    col += <span class="string">'\t'</span> + eachline[<span class="number">12</span>:<span class="number">15</span>]</span><br><span class="line">    col += <span class="string">'\t'</span> + eachline[<span class="number">15</span>:<span class="number">25</span>]</span><br><span class="line">    col += <span class="string">'\t'</span> + eachline[<span class="number">25</span>:<span class="number">39</span>]</span><br><span class="line">    col += <span class="string">'\t'</span> + eachline[<span class="number">29</span>:<span class="number">34</span>]</span><br><span class="line">    col += <span class="string">'\t'</span> + eachline[<span class="number">34</span>:<span class="number">38</span>]</span><br><span class="line">    col += <span class="string">'\t'</span> + eachline[<span class="number">38</span>:<span class="number">50</span>]</span><br><span class="line">    col += <span class="string">'\t'</span> + eachline[<span class="number">50</span>:<span class="number">61</span>]</span><br><span class="line">    col += <span class="string">'\t'</span> + eachline[<span class="number">61</span>:<span class="number">72</span>]</span><br><span class="line">    col += <span class="string">'\t'</span> + eachline[<span class="number">72</span>:<span class="number">83</span>]</span><br><span class="line">    col += <span class="string">'\t'</span> + eachline[<span class="number">83</span>:<span class="number">92</span>]</span><br><span class="line">    col += <span class="string">'\t'</span> + eachline[<span class="number">92</span>:<span class="number">97</span>]</span><br><span class="line">    col += <span class="string">'\t'</span> + eachline[<span class="number">97</span>:<span class="number">103</span>]</span><br><span class="line">    col += <span class="string">'\t'</span> + eachline[<span class="number">103</span>:<span class="number">109</span>]</span><br><span class="line">    col += <span class="string">'\t'</span> + eachline[<span class="number">109</span>:<span class="number">115</span>]</span><br><span class="line">    col += <span class="string">'\t'</span> + eachline[<span class="number">115</span>:<span class="number">122</span>]</span><br><span class="line">    col += <span class="string">'\t'</span> + eachline[<span class="number">122</span>:<span class="number">129</span>]</span><br><span class="line">    col += <span class="string">'\t'</span> + eachline[<span class="number">129</span>:<span class="number">136</span>]</span><br><span class="line">    <span class="keyword">return</span> col</span><br></pre></td></tr></tbody></table></figure><p>PDB转DSSP格式，需要DSSP软件</p><p>参数：</p><ul><li>pdbdir: pdb文件目录   </li><li>dsspdir: 生成的dssp文件目录（需创建）</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pdbToDSSP</span><span class="params">(pdbnamefile,pdbdir, dsspdir)</span>:</span>    </span><br><span class="line">    pdbfiles = os.listdir(pdbdir)</span><br><span class="line">    <span class="comment">#对于每个pdb文件，生成对应的dssp文件，并保存在dssp目录下</span></span><br><span class="line">    <span class="keyword">for</span> pdb_file <span class="keyword">in</span> pdbfiles:</span><br><span class="line">        pdb_name = pdb_file.split(<span class="string">'.'</span>)[<span class="number">0</span>].upper()</span><br><span class="line">        command = <span class="string">'DSSPCMBI.EXE -x '</span> + pdbdir +<span class="string">'/'</span>+ pdb_file + <span class="string">'  '</span>+ dsspdir +<span class="string">"/"</span>+ pdb_name +<span class="string">'.dssp'</span></span><br><span class="line">        os.system(command) </span><br><span class="line">    dsspfiles = os.listdir(dsspdir)</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(dsspdir + <span class="string">"/DSSP"</span>):      <span class="comment">#判断DSSP文件是否存在，存在则删除</span></span><br><span class="line">        dsspfiles.remove(<span class="string">"DSSP"</span>)</span><br><span class="line">    output=open(dsspdir + <span class="string">'/DSSP'</span>,<span class="string">'w'</span>)</span><br><span class="line">    <span class="comment">#循环读取dssp文件，将其合并成一个整的DSSP</span></span><br><span class="line">    <span class="keyword">with</span> open(pdbnamefile, <span class="string">'r'</span>) <span class="keyword">as</span> namefile:</span><br><span class="line">        <span class="keyword">for</span> eachline <span class="keyword">in</span> namefile:</span><br><span class="line">            pdb_name = eachline.strip() </span><br><span class="line">            dssp_file = pdb_name + <span class="string">'.dssp'</span></span><br><span class="line">        <span class="comment">#for dssp_file in dsspfiles:</span></span><br><span class="line">            <span class="comment">#pdb_name = dssp_file.split('.')[0]</span></span><br><span class="line">            <span class="keyword">with</span> open(dsspdir + <span class="string">'/'</span> + dssp_file,<span class="string">"r"</span>) <span class="keyword">as</span> f:</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(dsspdir + <span class="string">'/format'</span>):</span><br><span class="line">                    os.mkdir(dsspdir + <span class="string">'/format'</span>)</span><br><span class="line">                <span class="keyword">with</span> open(dsspdir + <span class="string">'/format/'</span> + pdb_name + <span class="string">'.dssp.format'</span>,<span class="string">'w'</span>) <span class="keyword">as</span> singleOut:</span><br><span class="line">                    count = <span class="number">0</span>; preRes=[]</span><br><span class="line">                    sets = set(<span class="string">''</span>);content=<span class="string">''</span>   </span><br><span class="line">                    <span class="keyword">for</span> eachline <span class="keyword">in</span> f.readlines():</span><br><span class="line">                        list1=[];oneline=[]</span><br><span class="line">                        count+=<span class="number">1</span></span><br><span class="line">                        list1.append(pdb_name)                             </span><br><span class="line">                        <span class="keyword">if</span> count &gt;= <span class="number">29</span>:</span><br><span class="line">                            eachline = formatdsspline(eachline)</span><br><span class="line">                            oneline = eachline.split(<span class="string">'\t'</span>)</span><br><span class="line"></span><br><span class="line">                            <span class="keyword">if</span> oneline[<span class="number">3</span>].strip():</span><br><span class="line">                                preRes = oneline[<span class="number">3</span>].strip()                        </span><br><span class="line">                            </span><br><span class="line">                            list1.append(eachline)</span><br><span class="line">                            content += <span class="string">""</span>.join(list1)+<span class="string">'\n'</span>                            </span><br><span class="line">                            </span><br><span class="line">                            <span class="keyword">if</span> <span class="string">'!'</span> == oneline[<span class="number">4</span>].strip():</span><br><span class="line">                                <span class="keyword">continue</span></span><br><span class="line">                            </span><br><span class="line">                            <span class="keyword">if</span> <span class="string">'!*'</span> <span class="keyword">in</span> eachline <span class="keyword">or</span> <span class="keyword">not</span> oneline[<span class="number">3</span>].strip():</span><br><span class="line">                                <span class="keyword">if</span> preRes <span class="keyword">in</span> sets <span class="keyword">and</span> len(sets):</span><br><span class="line">                                    content=<span class="string">''</span></span><br><span class="line">                                    preRes=[]</span><br><span class="line">                                    <span class="keyword">continue</span></span><br><span class="line">                                sets.add(preRes)</span><br><span class="line">                                output.write(content)</span><br><span class="line">                                singleOut.write(content)</span><br><span class="line">                                content=<span class="string">''</span></span><br><span class="line">                    <span class="keyword">if</span> preRes <span class="keyword">and</span> preRes <span class="keyword">not</span> <span class="keyword">in</span> sets:</span><br><span class="line">                        output.write(content)</span><br><span class="line">                        singleOut.write(content)</span><br><span class="line">    output.close()</span><br></pre></td></tr></tbody></table></figure><p>测试</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#test</span></span><br><span class="line">pdbdir = <span class="string">'z:/datasets/protein/pdb'</span></span><br><span class="line">dsspdir = <span class="string">'Z:/datasets/protein/DSSPdir'</span> </span><br><span class="line">proname = <span class="string">'Z:/datasets/protein/protein.name'</span></span><br><span class="line">pdbToDSSP(proname,pdbdir, dsspdir)</span><br></pre></td></tr></tbody></table></figure><h3 id="3-DSSP抽取序列"><a href="#3-DSSP抽取序列" class="headerlink" title="3.DSSP抽取序列"></a>3.DSSP抽取序列</h3><p>从一个整合的DSSP文件中抽取序列文件 </p><p>从格式化后的dssp文件获取序列信息</p><p>参数：dsspfile为格式过的DSSP文件,seqfile为输出的序列文件,同时输出序列文件</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getSeqFromDSSP</span><span class="params">(dsspfile, seqfile, minLen)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(dsspfile, <span class="string">'r'</span>) <span class="keyword">as</span> inputfile:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> seqfile.strip():</span><br><span class="line">            seqfile = <span class="string">'protein'</span>+minLen + <span class="string">'.dssp.seq'</span></span><br><span class="line">        outchain = open(<span class="string">'protein40.chain.all'</span>, <span class="string">'w'</span>)</span><br><span class="line">        <span class="keyword">with</span> open(seqfile, <span class="string">'w'</span>) <span class="keyword">as</span> outputfile:</span><br><span class="line">            residue=[];Ntype=[]</span><br><span class="line">            preType=[];preRes=[]</span><br><span class="line">            firstline=[];secondline=[];content=<span class="string">''</span></span><br><span class="line">            <span class="keyword">for</span> eachline <span class="keyword">in</span> inputfile:</span><br><span class="line">                oneline = eachline.split(<span class="string">'\t'</span>)</span><br><span class="line">                residue = oneline[<span class="number">0</span>]</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> residue.strip(): </span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                Ntype = oneline[<span class="number">3</span>].strip()</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> Ntype.strip():</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">if</span> preRes!=residue:</span><br><span class="line">                    content = <span class="string">''</span>.join(firstline)+<span class="string">'\n'</span> + <span class="string">''</span>.join(secondline) +<span class="string">'\n'</span></span><br><span class="line">                    <span class="keyword">if</span> len(secondline) &gt;=minLen <span class="keyword">and</span> <span class="keyword">not</span> <span class="string">'X'</span> <span class="keyword">in</span> secondline:</span><br><span class="line">                        outchain.write(<span class="string">''</span>.join(firstline) + <span class="string">'\n'</span>)</span><br><span class="line">                        outputfile.write(content)</span><br><span class="line">                    firstline=[]</span><br><span class="line">                    firstline.append(<span class="string">'&gt;'</span> + residue + <span class="string">':'</span> + Ntype)</span><br><span class="line">                    secondline=[];secondline.append(oneline[<span class="number">4</span>].strip())</span><br><span class="line">                    preRes = residue;preType = Ntype</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">if</span> Ntype != preType:</span><br><span class="line">                    content = <span class="string">''</span>.join(firstline)+<span class="string">'\n'</span> + <span class="string">''</span>.join(secondline) +<span class="string">'\n'</span></span><br><span class="line">                    <span class="keyword">if</span> len(secondline) &gt;=minLen <span class="keyword">and</span>  <span class="keyword">not</span> <span class="string">'X'</span> <span class="keyword">in</span> secondline:</span><br><span class="line">                        outchain.write(<span class="string">''</span>.join(firstline) + <span class="string">'\n'</span>)</span><br><span class="line">                        outputfile.write(content)</span><br><span class="line">                    firstline=[]</span><br><span class="line">                    firstline.append(<span class="string">'&gt;'</span> + residue + <span class="string">':'</span> + Ntype)</span><br><span class="line">                    secondline=[];secondline.append(oneline[<span class="number">4</span>].strip())</span><br><span class="line">                    preRes = residue;preType = Ntype</span><br><span class="line">                <span class="keyword">else</span>: <span class="comment">#如果Ntype不为空，且等于preType</span></span><br><span class="line">                    secondline.append(oneline[<span class="number">4</span>].strip())</span><br><span class="line">            content = <span class="string">''</span>.join(firstline)+<span class="string">'\n'</span> + <span class="string">''</span>.join(secondline) +<span class="string">'\n'</span></span><br><span class="line">            <span class="keyword">if</span> len(secondline) &gt;=minLen <span class="keyword">and</span> <span class="keyword">not</span> <span class="string">'X'</span> <span class="keyword">in</span> secondline:  <span class="comment">#选择长度大于40</span></span><br><span class="line">                outchain.write(<span class="string">''</span>.join(firstline) + <span class="string">'\n'</span>)</span><br><span class="line">                outputfile.write(content)</span><br><span class="line">        outchain.close()</span><br></pre></td></tr></tbody></table></figure><p>测试：</p><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">os.chdir(<span class="string">r"E:\3-CSU\Academic\_Oriented\analysis\experiment\Datasets\ptest.dssp"</span>)</span><br><span class="line">pdbfile = <span class="string">'DSSP'</span></span><br><span class="line">outfile = <span class="string">'protein.seq'</span></span><br><span class="line">getSeqFromDSSP(pdbfile,outfile)</span><br></pre></td></tr></tbody></table></figure><h3 id="4-对序列做blast聚类"><a href="#4-对序列做blast聚类" class="headerlink" title="4.对序列做blast聚类"></a>4.对序列做blast聚类</h3><p>设置相应的参数，在服务器上跑blast，代码如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifs/share/lib/cd-hit-v4<span class="number">.5</span><span class="number">.4</span>/cd-hit -i /ifs/home/liudiwei/datasets/protein40.seq -o /ifs/home/liudiwei/experiment/cdhit/fasta<span class="number">.40</span> -c <span class="number">0.4</span> -n <span class="number">2</span> -M <span class="number">2000</span></span><br></pre></td></tr></tbody></table></figure><h3 id="5-生成聚类后的DSSP，得到protein-name、protein-seq、protein-chain三个文件"><a href="#5-生成聚类后的DSSP，得到protein-name、protein-seq、protein-chain三个文件" class="headerlink" title="5.生成聚类后的DSSP，得到protein.name、protein.seq、protein.chain三个文件"></a>5.生成聚类后的DSSP，得到protein.name、protein.seq、protein.chain三个文件</h3><p>从原来的DSSP文件中，根据聚类后的链名抽取新的DSSP文件</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># extract dssp from old dssp file</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extractDSSP</span><span class="params">(dsspfile, chainname, outfile)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(outfile, <span class="string">'w'</span>) <span class="keyword">as</span> outdssp:</span><br><span class="line">        <span class="keyword">with</span> open(dsspfile, <span class="string">'r'</span>) <span class="keyword">as</span> inputdssp:</span><br><span class="line">            <span class="keyword">for</span> eachline <span class="keyword">in</span> inputdssp:</span><br><span class="line">                oneline = eachline.split(<span class="string">'\t'</span>)</span><br><span class="line">                <span class="comment">#preNum = oneline[2].strip()     </span></span><br><span class="line">                <span class="keyword">with</span> open(chainname,<span class="string">'r'</span>) <span class="keyword">as</span> chainfile:       </span><br><span class="line">                    <span class="keyword">for</span> eachchain <span class="keyword">in</span> chainfile:</span><br><span class="line">                        protein_ame = eachchain[<span class="number">1</span>:<span class="number">5</span>]</span><br><span class="line">                        chain_id = eachchain[<span class="number">6</span>:<span class="number">7</span>]</span><br><span class="line">                        <span class="keyword">if</span> oneline[<span class="number">0</span>].strip() == protein_ame <span class="keyword">and</span> oneline[<span class="number">3</span>].strip() == chain_id:</span><br><span class="line">                            outdssp.write(eachline)</span><br><span class="line">                            <span class="keyword">break</span></span><br></pre></td></tr></tbody></table></figure><p>测试实例：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dsspfile = <span class="string">'/ifs/home/liudiwei/datasets/832.protein/DSSPdir1/DSSP'</span></span><br><span class="line">chainname = <span class="string">'/ifs/home/liudiwei/experiment/step1/832p.cluster/cdhit/protein.chain'</span></span><br><span class="line">outfile = <span class="string">'/ifs/home/liudiwei/experiment/step1/832p.cluster/cdhit/DSSP'</span></span><br><span class="line">extractDSSP(dsspfile, chainname, outfile )</span><br></pre></td></tr></tbody></table></figure><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;以下代码为个人原创，python实现，是处理PDB文件的部分常用代码，仅供参考！&lt;/p&gt;
&lt;h3 id=&quot;1-下载PDB文件&quot;&gt;&lt;a href=&quot;#1-下载PDB文件&quot; class=&quot;headerlink&quot; title=&quot;1.下载PDB文件&quot;&gt;&lt;/a&gt;1.下载PDB文件&lt;/h3&gt;&lt;p&gt;下面是一个下载PDB文件的函数，传入的参数是一个写有pdb名字的namefile文件，函数的核心部分是三个系统命令，先通过wget下载，然后解压，最后替换名字。&lt;/p&gt;
    
    </summary>
    
      <category term="BioInfo" scheme="https://www.csuldw.com/categories/BioInfo/"/>
    
    
      <category term="BioInfo" scheme="https://www.csuldw.com/tags/BioInfo/"/>
    
      <category term="PDB" scheme="https://www.csuldw.com/tags/PDB/"/>
    
      <category term="预处理" scheme="https://www.csuldw.com/tags/%E9%A2%84%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>Machine Learning algorithm - Adaboost </title>
    <link href="https://www.csuldw.com/2015/07/05/2015-07-05-ML-algorithm-Adaboost/"/>
    <id>https://www.csuldw.com/2015/07/05/2015-07-05-ML-algorithm-Adaboost/</id>
    <published>2015-07-05T14:53:12.000Z</published>
    <updated>2016-08-30T00:29:30.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Github源码实现：<a href="https://github.com/csuldw/MachineLearning/tree/master/Adaboost" target="_blank" rel="noopener">https://github.com/csuldw/MachineLearning/tree/master/Adaboost</a></p><p>本文主要介绍的是Adaboost算法，<strong>利用AdaBoost元算法来提高分类器的性能</strong>，主要参考《机器学习实战》来学习Adaboost，同时结合Wikipedia以及各位同道人士的经验等，希望可以通过总结达到学习效果。</p><a id="more"></a><h2 id="基于数据集多重抽样的分类器"><a href="#基于数据集多重抽样的分类器" class="headerlink" title="基于数据集多重抽样的分类器"></a>基于数据集多重抽样的分类器</h2><p>先来看看Adaboost的优缺点。</p><table><thead><tr><th>Feature</th><th>AdaBoost</th></tr></thead><tbody><tr><td>优点</td><td>泛化错误率低，易编码，可以应用在大部分分类器上，无需参数调整</td></tr><tr><td>缺点</td><td>对离群点敏感</td></tr><tr><td>数据</td><td>数值型和标称型数据</td></tr></tbody></table><p>下面，来看看bagging和boosting的不同：</p><ul><li><p>bagging: 一种基于数据随机重抽样的分类器构建方法。自举汇聚法(bootstrap aggregating),也叫做bagging方法，是从原始数据集选择$S$次（有放回的抽取）后得到$S$个新数据集的一种技术。新数据集和原始数据集的大小相等（<font color="#007FFF"><strong>维数和列数都相等</strong></font>）。每个数据集都是通过在原始数据集中随机选择一个来进行替换而得到的。在S个数据集建好之后，将某个机器学习算法分别作用域每个数据集就可以得到S个分类器。当我们对新数据进行分类时，就可以应用S个分类器进行分类。与此同时，选择分类器<font color="#007fff"><strong>投票结果最多的类别作为最后的分类结果</strong></font>。目前，有一种改进的bagging方法，如<strong>随机森林</strong>（RF,随机森林不同的是，它对列也进行采样），它在一定程度上可以防止过拟合，也是对决策树的一种改进。</p></li><li><p>boosting则是一种与bagging很类似的技术。不论是boosting还是bagging当中，使用的多个分类器的类型都是一致的。但是在前者当中，不同的分类器是通过串行训练而得到，每个新分类器都根据已训练出的分类器的性能来进行训练。boosting则是通过训练集中关注被已有分类器错分的那些数据来获得新的分类器。</p></li></ul><p>boosting方法有多个版本，当前最流行便是<strong>AdaBoost</strong>。Adaboost 学习的一般流程如下：</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">收集数据：可以使用任何方法；  </span><br><span class="line">准备数据：依赖于所使用的弱分类器类型；  </span><br><span class="line">分析数据：可以使用任意方法  </span><br><span class="line">训练算法：AdaBoost的大部分时间都用在训练上，分类器将多次在同一数据集上训练弱分类器；  </span><br><span class="line">测试算法：计算分类的错误率；  </span><br><span class="line">使用算法：同SVM一样，AdaBoost预测的两个类别中的一个，如果是多类，也可使用与SVM一样的方法。</span><br></pre></td></tr></tbody></table></figure><h2 id="训练算法：基于错误率提升分类器性能"><a href="#训练算法：基于错误率提升分类器性能" class="headerlink" title="训练算法：基于错误率提升分类器性能"></a>训练算法：基于错误率提升分类器性能</h2><p>AdaBoost是adaptive boosting（自适应 boosting）的缩写，其运行过程如下：</p><blockquote><p>训练集中的每个样本，赋予其一个权重，这些权重构成向量$D$。一开始，这些权重都初试化成相等值$\frac{1}{N}$，其中$N$为样本个数。首先在训练数据上训练出一个弱分类器并计算该分类器的错误率，然后在同一数据集上再次训练弱分类器。接着，在分类器的第二次训练当中，将会重新调整每个样本的weight，其中第一次正确分类的样本的weight将会降低，而第一次错误分类的样本的weight将会提高。为了从所有分类器中得到最终的分类结果，AdaBoost会为每个分类器都赋予一个权重值$\alpha$，这些$\alpha$则是基于每个分类器的错误率进行计算的。</p></blockquote><p>在模型训练时，错误率定义为：</p><p>$$\epsilon=\dfrac{未正确分类的样本数目}{所有样本数目}$$</p><p>系数$\alpha$的计算公式为:</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24%5Calpha%3D%5Cdfrac%7B1%7D%7B2%7Dln%28%5Cdfrac%7B1-%5Cepsilon%7D%7B%5Cepsilon%7D%29%24%24" alt="$$\alpha=\dfrac{1}{2}ln(\dfrac{1-\epsilon}{\epsilon})$$"></p><p>从上面两个式子可以看出，$\alpha$和$\epsilon$是成反比的，$\epsilon$越大，$\alpha$就越小，也就是说建立的这个模型应该赋予更少的weight。计算出$\alpha$值之后，可以对weight向量$D$进行更新，使得正确分类的样本weight降低而错分类的样本weight值升高，$D$的计算方法如下<br>如果某个样本被正确分类，更新该样本权重值为：</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24D%5E%7B%28t+1%29%7D_i%3D%5Cdfrac%7BD_i%5E%7B%28t%29%7D%20e%5E%7B-%5Calpha%7D%7D%7BSum%28D%29%7D%24%24" alt="$$D^{(t+1)}_i=\dfrac{D_i^{(t)} e^{-\alpha}}{Sum(D)}$$"></p><p>如果某个样本被错误分类，更新该样本的权重值为：</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24D%5E%7B%28t+1%29%7D_i%3D%5Cdfrac%7BD_i%5E%7B%28t%29%7D%20e%5E%7B%5Calpha%7D%7D%7BSum%28D%29%7D%24%24" alt="$$D^{(t+1)}_i=\dfrac{D_i^{(t)} e^{\alpha}}{Sum(D)}$$"></p><p>计算出$D$后，AdaBoost会继续下一轮迭代，不断地重复训练和调整weight的过程，直到训练error ratio为0或者weak classifier的数目达到用户指定的特定值为止。Adaboost算法也是一种加和模型，最终的到的classifier可以表示成如下形式：</p><p><img src="https://upload.wikimedia.org/math/5/4/a/54a5bff707b9188fd81d1a725d63643a.png" alt=""></p><p>在建立完整的AdaBoost算法之前，需要通过一些代码建立<code>weak classifier</code>并保存数据集的<code>weight</code>。</p><h2 id="基于单层决策树构建弱分类器"><a href="#基于单层决策树构建弱分类器" class="headerlink" title="基于单层决策树构建弱分类器"></a>基于单层决策树构建弱分类器</h2><p>单层决策树是一种简单的决策树。首先构建一个简单的数据集,建立一个<code>adaboost.py</code>文件并加入下列代码：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadSimpData</span><span class="params">()</span>:</span></span><br><span class="line">    datMat = matrix([[ <span class="number">1.</span> ,  <span class="number">2.1</span>],</span><br><span class="line">        [ <span class="number">2.</span> ,  <span class="number">1.1</span>],</span><br><span class="line">        [ <span class="number">1.3</span>,  <span class="number">1.</span> ],</span><br><span class="line">        [ <span class="number">1.</span> ,  <span class="number">1.</span> ],</span><br><span class="line">        [ <span class="number">2.</span> ,  <span class="number">1.</span> ]])</span><br><span class="line">    classLabels = [<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>]</span><br><span class="line">    <span class="keyword">return</span> datMat,classLabels</span><br></pre></td></tr></tbody></table></figure><p>导入数据</p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; import adaboost</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; datMat,classLabels=adaboost.loadSimpData()</span><br></pre></td></tr></tbody></table></figure><p>下面两个函数，一个用于测试是否某个值小于或者大于我们正在测试的阈值，一个会在一个加权数据集中循环，并找到具有最低错误率的单层决策树。</p><p>伪代码如下：<br></p><pre><code>将最小错误率minError设为无穷大对数据及中的每一个特征（第一层循环）：    对每个步长（第二层循环）：        对每个不等号（第三层循环）：            建立一颗单层决策树并利用加权数据集对它进行测试            如果错误率低于minError，则将当前单层决策树设置为最佳单层决策树返回最佳单层决策树</code></pre><p>单层决策树生成函数代码：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stumpClassify</span><span class="params">(dataMatrix,dimen,threshVal,threshIneq)</span>:</span><span class="comment">#just classify the data</span></span><br><span class="line">    retArray = ones((shape(dataMatrix)[<span class="number">0</span>],<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">if</span> threshIneq == <span class="string">'lt'</span>:</span><br><span class="line">        retArray[dataMatrix[:,dimen] &lt;= threshVal] = <span class="number">-1.0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        retArray[dataMatrix[:,dimen] &gt; threshVal] = <span class="number">-1.0</span></span><br><span class="line">    <span class="keyword">return</span> retArray</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">buildStump</span><span class="params">(dataArr,classLabels,D)</span>:</span></span><br><span class="line">    dataMatrix = mat(dataArr); labelMat = mat(classLabels).T</span><br><span class="line">    m,n = shape(dataMatrix)</span><br><span class="line">    numSteps = <span class="number">10.0</span>; bestStump = {}; bestClasEst = mat(zeros((m,<span class="number">1</span>)))</span><br><span class="line">    minError = inf <span class="comment">#init error sum, to +infinity</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):<span class="comment">#loop over all dimensions</span></span><br><span class="line">        rangeMin = dataMatrix[:,i].min(); rangeMax = dataMatrix[:,i].max();</span><br><span class="line">        stepSize = (rangeMax-rangeMin)/numSteps</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">-1</span>,int(numSteps)+<span class="number">1</span>):<span class="comment">#loop over all range in current dimension</span></span><br><span class="line">            <span class="keyword">for</span> inequal <span class="keyword">in</span> [<span class="string">'lt'</span>, <span class="string">'gt'</span>]: <span class="comment">#go over less than and greater than</span></span><br><span class="line">                threshVal = (rangeMin + float(j) * stepSize)</span><br><span class="line">                predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)<span class="comment">#call stump classify with i, j, lessThan</span></span><br><span class="line">                errArr = mat(ones((m,<span class="number">1</span>)))</span><br><span class="line">                errArr[predictedVals == labelMat] = <span class="number">0</span></span><br><span class="line">                weightedError = D.T*errArr  <span class="comment">#calc total error multiplied by D</span></span><br><span class="line">                <span class="comment">#print "split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f" % (i, threshVal, inequal, weightedError)</span></span><br><span class="line">                <span class="keyword">if</span> weightedError &lt; minError:</span><br><span class="line">                    minError = weightedError</span><br><span class="line">                    bestClasEst = predictedVals.copy()</span><br><span class="line">                    bestStump[<span class="string">'dim'</span>] = i</span><br><span class="line">                    bestStump[<span class="string">'thresh'</span>] = threshVal</span><br><span class="line">                    bestStump[<span class="string">'ineq'</span>] = inequal</span><br><span class="line">    <span class="keyword">return</span> bestStump,minError,bestClasEst</span><br></pre></td></tr></tbody></table></figure><h2 id="AdaBoost算法的实现"><a href="#AdaBoost算法的实现" class="headerlink" title="AdaBoost算法的实现"></a>AdaBoost算法的实现</h2><p>整个实现的伪代码如下：</p><pre><code>对每次迭代：    利用buildStump()函数找到最佳的单层决策树    将最佳单层决策树加入到单层决策树数据中    计算alpha    计算心的权重向量D    更新累计类别估计值    如果错误率低于0.0 则退出循环</code></pre><p>基于单层决策树的AdaBoost训练过程</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">adaBoostTrainDS</span><span class="params">(dataArr,classLabels,numIt=<span class="number">40</span>)</span>:</span></span><br><span class="line">    weakClassArr = []</span><br><span class="line">    m = shape(dataArr)[<span class="number">0</span>]</span><br><span class="line">    D = mat(ones((m,<span class="number">1</span>))/m)   <span class="comment">#init D to all equal</span></span><br><span class="line">    aggClassEst = mat(zeros((m,<span class="number">1</span>)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numIt):</span><br><span class="line">        bestStump,error,classEst = buildStump(dataArr,classLabels,D)<span class="comment">#build Stump</span></span><br><span class="line">        <span class="comment">#print "D:",D.T</span></span><br><span class="line">        alpha = float(<span class="number">0.5</span>*log((<span class="number">1.0</span>-error)/max(error,<span class="number">1e-16</span>)))<span class="comment">#calc alpha, throw in max(error,eps) to account for error=0</span></span><br><span class="line">        bestStump[<span class="string">'alpha'</span>] = alpha  </span><br><span class="line">        weakClassArr.append(bestStump)                  <span class="comment">#store Stump Params in Array</span></span><br><span class="line">        <span class="comment">#print "classEst: ",classEst.T</span></span><br><span class="line">        expon = multiply(<span class="number">-1</span>*alpha*mat(classLabels).T,classEst) <span class="comment">#exponent for D calc, getting messy</span></span><br><span class="line">        D = multiply(D,exp(expon))                              <span class="comment">#Calc New D for next iteration</span></span><br><span class="line">        D = D/D.sum()</span><br><span class="line">        <span class="comment">#calc training error of all classifiers, if this is 0 quit for loop early (use break)</span></span><br><span class="line">        aggClassEst += alpha*classEst</span><br><span class="line">        <span class="comment">#print "aggClassEst: ",aggClassEst.T</span></span><br><span class="line">        aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T,ones((m,<span class="number">1</span>)))</span><br><span class="line">        errorRate = aggErrors.sum()/m</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"total error: "</span>,errorRate</span><br><span class="line">        <span class="keyword">if</span> errorRate == <span class="number">0.0</span>: <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> weakClassArr,aggClassEst</span><br></pre></td></tr></tbody></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>拥有了多个弱分类器以及其对应的$alpha$值，进行测试就方便了。</p><p>AdaBoost分类函数:利用训练处的多个弱分类器进行分类的函数。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">adaClassify</span><span class="params">(datToClass,classifierArr)</span>:</span></span><br><span class="line">    dataMatrix = mat(datToClass)<span class="comment">#do stuff similar to last aggClassEst in adaBoostTrainDS</span></span><br><span class="line">    m = shape(dataMatrix)[<span class="number">0</span>]</span><br><span class="line">    aggClassEst = mat(zeros((m,<span class="number">1</span>)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(classifierArr)):</span><br><span class="line">        classEst = stumpClassify(dataMatrix,classifierArr[i][<span class="string">'dim'</span>],\</span><br><span class="line">                                 classifierArr[i][<span class="string">'thresh'</span>],\</span><br><span class="line">                                 classifierArr[i][<span class="string">'ineq'</span>])<span class="comment">#call stump classify</span></span><br><span class="line">        aggClassEst += classifierArr[i][<span class="string">'alpha'</span>]*classEst</span><br><span class="line">        <span class="keyword">print</span> aggClassEst</span><br><span class="line">    <span class="keyword">return</span> sign(aggClassEst)</span><br></pre></td></tr></tbody></table></figure><p>OK，文章粗略地的讲解了下Adaboost，主要从实现中讲解，如果要知道原理，请看文献<a href="https://en.wikipedia.org/wiki/AdaBoost" target="_blank" rel="noopener">Wiki-AdaBoost</a>，Wikipedia中讲解的比较清楚，由于能力有限，以后再回头补充吧。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://www.cs.princeton.edu/courses/archive/spring12/cos598A/slides/intro.pdf" target="_blank" rel="noopener">PPT - Boosting: Foundations and Algorithms</a></li><li><a href="https://en.wikipedia.org/wiki/AdaBoost" target="_blank" rel="noopener">Wiki-AdaBoost</a></li><li>Machine Learning in Action 机器学习实战 第七章</li></ul><hr><br><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Github源码实现：&lt;a href=&quot;https://github.com/csuldw/MachineLearning/tree/master/Adaboost&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/csuldw/MachineLearning/tree/master/Adaboost&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文主要介绍的是Adaboost算法，&lt;strong&gt;利用AdaBoost元算法来提高分类器的性能&lt;/strong&gt;，主要参考《机器学习实战》来学习Adaboost，同时结合Wikipedia以及各位同道人士的经验等，希望可以通过总结达到学习效果。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="Adaboost" scheme="https://www.csuldw.com/tags/Adaboost/"/>
    
      <category term="组合算法" scheme="https://www.csuldw.com/tags/%E7%BB%84%E5%90%88%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Python模拟ls命令</title>
    <link href="https://www.csuldw.com/2015/06/10/2015-06-10%20Python-simulate-command/"/>
    <id>https://www.csuldw.com/2015/06/10/2015-06-10 Python-simulate-command/</id>
    <published>2015-06-10T12:03:00.000Z</published>
    <updated>2016-07-28T16:04:20.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>模拟控制台命令</p><p>写一个程序 lsrm 要求如下:</p><pre><code>模拟linux的命令ls部分功能当使用命令lsrm -ll显示目录下所有 py 结尾的文件增加难度 (1.使用递归 显示所有目录里的 py 结尾文件)</code></pre><a id="more"></a><p>首先定义一个outputFile函数，参数只设置一个infile，表示的是文件名或者目录名，然后进行判断，如果是文件，而且以py结尾，则输出；否则，如果是目录，则循环遍历每个每个文件。代码如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Wed Oct 28 19:25:20 2015</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: liudiwei</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">outputFile</span><span class="params">(infile)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> os.path.isdir(infile):</span><br><span class="line">        filelist = getFileList(infile)</span><br><span class="line">        <span class="keyword">for</span> eachfile <span class="keyword">in</span> filelist:</span><br><span class="line">            os.chdir(infile)</span><br><span class="line">            outputFile(eachfile)</span><br><span class="line">            os.chdir(<span class="string">".."</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="string">".py"</span> <span class="keyword">in</span> infile:</span><br><span class="line">            <span class="keyword">print</span> infile</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    filepath = <span class="string">r"F:\CSU\Academic\analysis\experiment\code"</span>; </span><br><span class="line">    filelist = getFileList(filepath)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        command = raw_input(<span class="string">'# '</span> )</span><br><span class="line">        <span class="keyword">if</span> command == <span class="string">'lsrm -ll'</span>:    </span><br><span class="line">            outputFile(filepath)</span><br><span class="line">        <span class="keyword">elif</span> command == <span class="string">"stop"</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></tbody></table></figure><p>运行结果如下图所示：</p><center>![output](/assets/images/20151029094653.png)</center><p>注意：在寻找子目录的文件时，需将工作目切换到子目录，档子目录遍历完毕后，再前换到上一层目录os.chdir(“..”).</p><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;模拟控制台命令&lt;/p&gt;
&lt;p&gt;写一个程序 lsrm 要求如下:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;模拟linux的命令ls部分功能
当使用命令
lsrm -ll
显示目录下所有 py 结尾的文件
增加难度 (1.使用递归 显示所有目录里的 py 结尾文件)&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="Python" scheme="https://www.csuldw.com/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.csuldw.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>机器学习算法-Apriori关联分析</title>
    <link href="https://www.csuldw.com/2015/06/04/2015-06-04-Apriori/"/>
    <id>https://www.csuldw.com/2015/06/04/2015-06-04-Apriori/</id>
    <published>2015-06-04T13:53:12.000Z</published>
    <updated>2016-03-13T05:59:48.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>引文：</strong> 学习一个算法，我们最关心的并不是算法本身，而是一个算法能够干什么，能应用到什么地方。很多的时候，我们都需要从大量数据中提取出有用的信息，从大规模数据中寻找物品间的隐含关系叫做关联分析(association analysis)或者关联规则学习(association rule learning)。比如在平时的购物中，那些商品一起捆绑购买销量会比较好，又比如购物商城中的那些推荐信息，都是根据用户平时的搜索或者是购买情况来生成的。如果是蛮力搜索的话代价太高了，所以Apriori就出现了，就是为了解决这类问题的。</p><a id="more"></a><p><strong>内容纲要</strong></p><ul><li><p>关联分析</p></li><li><p>Apriori算法理论</p></li><li><p>Apriori实现</p><ul><li>频繁项集生成</li><li>关联规则生成</li></ul></li><li><p>reference</p></li></ul><p><strong>Apriori算法</strong></p><ul><li>优点：易编码实现</li><li>缺点：在大数据集上可能较慢</li><li>适合数据类型：数值型或者标称型数据</li></ul><h3 id="1-关联分析"><a href="#1-关联分析" class="headerlink" title="1 关联分析"></a><strong>1 关联分析</strong></h3><p>说到关联分析，顾名思义的就可以联想到，所谓关联就是两个东西之间存在的某种联系。关联分析最有名的例子是“尿布和啤酒”，以前在美国西部的一家连锁店，店家发现男人们在周四购买尿布后还会购买啤酒。于是他便得出一个推理，尿布和啤酒存在某种关联。但是具体怎么来评判呢？</p><p>那么，这里用的是<strong>支持度</strong>和<strong>可信度</strong>来评判!</p><p>一个项集的支持度（support）被定义为数据集中包含该数据集的记录所占的比例。可信度或置信度（confidence）是正对一条关联规则来定义的，比如{尿布}-&gt;{啤酒}，这条规则的可信度定义为“支持度{尿布，啤酒}/支持度{尿布}”</p><p>比如有规则X=&gt;Y，它的<strong>支持度</strong>可以计算为包含XUY所有商品的交易量相对所有交易量的比例（也就是X和Y同时出现一次交易的概率）。<strong>可信度</strong>定义为包含XUY所有物品的交易量相对仅包含X的交易量的比值，也就是说可信度对应给定X时的条件概率。关联规则挖掘，其目的是自动发起这样的规则，同时计算这些规则的质量。</p><p>计算公式如下：</p><p>$$支持度=\frac{交易量包含XUY}{交易量}$$</p><p>$$可信度=\frac{交易量包含XUY}{交易量包含X}$$</p><p>支持度和可信度是用来量化关联分析是否成功的方法。关联分析的目的包括两个：发现频繁项集和发现关联规则。首先我们要找到频繁项集，然后根据频繁项集找出关联规则。下面使用apriori算法来发现频繁项集。</p><h3 id="2-Apriori理论"><a href="#2-Apriori理论" class="headerlink" title="2 Apriori理论"></a><strong>2 Apriori理论</strong></h3><p><strong>算法的一般过程：</strong></p><ul><li>收集数据：使用任何方法</li><li>准备数据：任意数据类型都可以，因为我们只保存集合</li><li>分析数据：使用任何方法</li><li>训练算法：使用Apriori算法来找到频繁项集</li><li>测试算法：不需要测试过程</li><li>使用算法：用于发现频繁项集以及物品之间的关联规则</li></ul><p><strong>使用Apriori算法，首先计算出单个元素的支持度，然后选出单个元素置信度大于我们要求的数值，比如0.5或是0.7等。然后增加单个元素组合的个数，只要组合项的支持度大于我们要求的数值就把它加到我们的频繁项集中，依次递归。</strong></p><p>然后根据计算的支持度选出来的频繁项集来生成关联规则。</p><h3 id="3-Apriori实现"><a href="#3-Apriori实现" class="headerlink" title="3 Apriori实现"></a><strong>3 Apriori实现</strong></h3><p>首先定义一些算法的辅助函数<br>加载数据集的</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">from</span> <span class="string">numpy</span> <span class="string">import</span> <span class="string">*</span></span><br><span class="line"></span><br><span class="line"><span class="string">def</span> <span class="string">loadDataSet():</span></span><br><span class="line">    <span class="string">list</span> <span class="string">=</span> <span class="string">[[1,</span> <span class="number">3</span><span class="string">,</span> <span class="number">4</span><span class="string">],</span> <span class="string">[2,</span> <span class="number">3</span><span class="string">,</span> <span class="number">5</span><span class="string">],</span> <span class="string">[1,</span> <span class="number">2</span><span class="string">,</span> <span class="number">3</span><span class="string">,</span> <span class="number">5</span><span class="string">],</span> <span class="string">[2,</span> <span class="number">5</span><span class="string">]]</span></span><br><span class="line">    <span class="string">return</span> <span class="string">list</span></span><br></pre></td></tr></tbody></table></figure><p>根据数据集构建集合C1，该集合是大小为1的所有候选集的集合。</p><figure class="highlight applescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def createC1(dataSet):</span><br><span class="line">    C1 = [] <span class="comment">#C1是大小为1的所有候选项集的集合</span></span><br><span class="line">    <span class="keyword">for</span> <span class="keyword">transaction</span> <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">item</span> <span class="keyword">in</span> <span class="keyword">transaction</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> [<span class="built_in">item</span>] <span class="keyword">in</span> C1:</span><br><span class="line">                C1.append([<span class="built_in">item</span>])             </span><br><span class="line">    C1.sort()</span><br><span class="line"><span class="built_in">    return</span> map(frozenset, C1)<span class="comment">#use frozen set so we can use it as a key in a dict</span></span><br></pre></td></tr></tbody></table></figure><p>根据构建出来的频繁项集，选出满足我们需要的大于我们给定的支持度的项集</p><figure class="highlight elm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">#<span class="type">D</span>表示数据集，<span class="type">CK</span>表示候选项集，minSup<span class="keyword">port</span>表示最小的支持度，自己设定</span><br><span class="line"><span class="title">def</span> scanD(<span class="type">D</span>, <span class="type">Ck</span>, minSup<span class="keyword">port</span>):</span><br><span class="line">    ssCnt = {}</span><br><span class="line">    for tid <span class="keyword">in</span> <span class="type">D</span>:</span><br><span class="line">        for can <span class="keyword">in</span> <span class="type">Ck</span>:</span><br><span class="line">            <span class="keyword">if</span> can.issubset(tid):</span><br><span class="line">                <span class="keyword">if</span> not ssCnt.has_key(can): ssCnt[can]=<span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>: ssCnt[can] += <span class="number">1</span></span><br><span class="line">    numItems = float(len(<span class="type">D</span>))</span><br><span class="line">    retList = [] #存储满足最小支持度要求的项集</span><br><span class="line">    supportData = {} #每个项集的支持度字典</span><br><span class="line">    for key <span class="keyword">in</span> ssCnt:  #计算所有项集的支持度</span><br><span class="line">        sup<span class="keyword">port</span> = ssCnt[key]/numItems</span><br><span class="line">        <span class="keyword">if</span> sup<span class="keyword">port</span> &gt;= minSupport:</span><br><span class="line">            retList.insert(<span class="number">0</span>,key)</span><br><span class="line">        supportData[key] = support</span><br><span class="line">    return retList, supportData</span><br></pre></td></tr></tbody></table></figure><h4 id="3-1-频繁项集"><a href="#3-1-频繁项集" class="headerlink" title="3.1 频繁项集"></a><strong>3.1 频繁项集</strong></h4><p>关于频繁项集的产生，我们单独的抽取出来<br>首先需要一个生成合并项集的函数，将两个子集合并的函数</p><figure class="highlight elixir"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#LK是频繁项集列表，K表示接下来合并的项集中的单个想的个数{1,2,3}表示k=3</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">aprioriGen</span></span>(Lk, k): <span class="comment">#creates Ck</span></span><br><span class="line">    retList = []</span><br><span class="line">    lenLk = len(Lk)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(lenLk)<span class="symbol">:</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>, lenLk): </span><br><span class="line">            L1 = list(Lk[i])[<span class="symbol">:k-</span><span class="number">2</span>]; L2 = list(Lk[j])[<span class="symbol">:k-</span><span class="number">2</span>] <span class="comment">#前k-2个项相同时，将两个集合合并</span></span><br><span class="line">            L1.sort(); L2.sort()</span><br><span class="line">            if L1==<span class="symbol">L2:</span> <span class="comment">#if first k-2 elements are equal</span></span><br><span class="line">                retList.append(Lk[i] | Lk[j]) <span class="comment">#set union</span></span><br><span class="line">    <span class="keyword">return</span> retList</span><br></pre></td></tr></tbody></table></figure><p>接着定义生成频繁项集的函数</p><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#只需要输入数据集和支持度即可</span></span><br><span class="line">def apriori(dataSet, <span class="attr">minSupport</span> = <span class="number">0.5</span>):</span><br><span class="line">    <span class="attr">C1</span> = createC1(dataSet)</span><br><span class="line">    <span class="attr">D</span> = <span class="built_in">map</span>(set, dataSet)</span><br><span class="line">    L1, <span class="attr">supportData</span> = scanD(D, C1, minSupport)</span><br><span class="line">    <span class="attr">L</span> = [L1]</span><br><span class="line">    <span class="attr">k</span> = <span class="number">2</span></span><br><span class="line">    while (len(L[k-<span class="number">2</span>]) &gt; <span class="number">0</span>):</span><br><span class="line">        <span class="attr">Ck</span> = aprioriGen(L[k-<span class="number">2</span>], k)</span><br><span class="line">        Lk, <span class="attr">supK</span> = scanD(D, Ck, minSupport)<span class="comment">#scan DB to get Lk</span></span><br><span class="line">        supportData.update(supK)</span><br><span class="line">        L.append(Lk)</span><br><span class="line">        k += <span class="number">1</span></span><br><span class="line">    return L, supportData<span class="comment">#返回频繁项集和每个项集的支持度值</span></span><br></pre></td></tr></tbody></table></figure><h4 id="3-2-关联规则生成"><a href="#3-2-关联规则生成" class="headerlink" title="3.2 关联规则生成"></a><strong>3.2 关联规则生成</strong></h4><p>通过频繁项集，我们可以得到相应的规则，但是具体规则怎么得出来的呢？下面给出一个规则生成函数，具体原理参考注释</p><figure class="highlight perl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#输入的参数分别为：频繁项集、支持度数据字典、自定义的最小支持度，返回的是可信度规则列表</span></span><br><span class="line">def generateRules(L, supportData, minConf=<span class="number">0</span>.<span class="number">7</span>):  <span class="comment">#支持度是通过scanD得到的字典</span></span><br><span class="line">    bigRuleList = []</span><br><span class="line">    <span class="keyword">for</span> i in range(<span class="number">1</span>, len(L)):<span class="comment">#只去频繁项集中元素个数大于2的子集，如{1,2}{1,2,3}，不取{2}{3},etc...</span></span><br><span class="line">        <span class="keyword">for</span> freqSet in L[i]:</span><br><span class="line">            H1 = [frozenset([item]) <span class="keyword">for</span> item in freqSet]</span><br><span class="line">            <span class="keyword">if</span> (i &gt; <span class="number">1</span>):</span><br><span class="line">                rulesFromConse<span class="string">q(freqSet, H1, supportData, bigRuleList, minConf)</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                calcConf(freqSet, H1, supportData, bigRuleList, minConf)</span><br><span class="line">    <span class="keyword">return</span> bigRuleList</span><br></pre></td></tr></tbody></table></figure><p>下面定义一个用来计算置信度的函数，通过该函数抽取出符合我们要求的规则，如freqSet为{1,2}，H为{1}，{2}，可以计算出{1}–&gt;{2}和{2}–&gt;{1}的质心度，即下面的conf变量，然后用if语句判断是否符合我们的要求。代码如下：</p><figure class="highlight vim"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#计算可信度，找到满足最小可信度的要求规则</span><br><span class="line">def calcConf(freqSet, H, supportData, brl, minConf=<span class="number">0.7</span>):</span><br><span class="line">    prunedH = [] #create <span class="keyword">new</span> <span class="keyword">list</span> <span class="keyword">to</span> <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">for</span> conseq in H:</span><br><span class="line">        <span class="keyword">conf</span> = supportData[freqSet]/supportData[freqSet-conseq] #calc confidence</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">conf</span> &gt;= minConf: </span><br><span class="line">            <span class="keyword">print</span> freqSet-conseq,<span class="string">'--&gt;'</span>,conseq,<span class="string">'conf:'</span>,<span class="keyword">conf</span></span><br><span class="line">            brl.<span class="keyword">append</span>((freqSet-conseq, conseq, <span class="keyword">conf</span>))</span><br><span class="line">            prunedH.<span class="keyword">append</span>(conseq)</span><br><span class="line">    <span class="keyword">return</span> prunedH</span><br></pre></td></tr></tbody></table></figure><p>下面的函数是用来合并子集的，比如我现在的频繁项集是{2,3,5},它的构造元素是{2},{3},{5}，所以需要将{2},{3},{5}两两合并然后再根据上面的calcConf函数计算置信度。代码如下：</p><figure class="highlight perl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#从最初的项集中生成更多的规则</span></span><br><span class="line">def rulesFromConse<span class="string">q(freqSet, H, supportData, brl, minConf=0.7)</span>:</span><br><span class="line">    <span class="keyword">m</span> = len(H[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">if</span> (len(freqSet) &gt; (<span class="keyword">m</span> + <span class="number">1</span>)): <span class="comment">#进一步合并项集</span></span><br><span class="line">        Hmp1 = aprioriGen(H, <span class="keyword">m</span>+<span class="number">1</span>)<span class="comment">#create Hm+1 new candidates</span></span><br><span class="line">        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)</span><br><span class="line">        <span class="keyword">if</span> (len(Hmp1) &gt; <span class="number">1</span>):    <span class="comment">#need at least two sets to merge</span></span><br><span class="line">            rulesFromConse<span class="string">q(freqSet, Hmp1, supportData, brl, minConf)</span></span><br></pre></td></tr></tbody></table></figure><h4 id="3-3-测试"><a href="#3-3-测试" class="headerlink" title="3.3 测试"></a><strong>3.3 测试</strong></h4><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">dataSet</span> = loadDataSet() <span class="comment">#加载数据集</span></span><br><span class="line">L,<span class="attr">suppoData</span> = apriori(dataSet)<span class="comment">#计算频繁项集</span></span><br><span class="line"><span class="attr">rules</span> = generateRules(L,suppoData,<span class="attr">minConf=0.7)</span> <span class="comment">#抽取规则</span></span><br></pre></td></tr></tbody></table></figure><p>得到的结果为：<br><img src="http://img.blog.csdn.net/20150604094036589" alt="这里写图片描述"></p><p>L表示的是符合条件的频繁项集，rules表示最后抽取出来的符合条件的规则；还可以查看各个项集的支持度，如下所示。<br><img src="http://img.blog.csdn.net/20150604094213762" alt="这里写图片描述"></p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a><strong>Reference</strong></h3><p>[1]<strong>《机器学习实战》</strong>书籍第11章</p><br><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;引文：&lt;/strong&gt; 学习一个算法，我们最关心的并不是算法本身，而是一个算法能够干什么，能应用到什么地方。很多的时候，我们都需要从大量数据中提取出有用的信息，从大规模数据中寻找物品间的隐含关系叫做关联分析(association analysis)或者关联规则学习(association rule learning)。比如在平时的购物中，那些商品一起捆绑购买销量会比较好，又比如购物商城中的那些推荐信息，都是根据用户平时的搜索或者是购买情况来生成的。如果是蛮力搜索的话代价太高了，所以Apriori就出现了，就是为了解决这类问题的。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="Apriori" scheme="https://www.csuldw.com/tags/Apriori/"/>
    
      <category term="关联分析" scheme="https://www.csuldw.com/tags/%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>机器学习算法-K-means聚类</title>
    <link href="https://www.csuldw.com/2015/06/03/2015-06-03-ml-algorithm-K-means/"/>
    <id>https://www.csuldw.com/2015/06/03/2015-06-03-ml-algorithm-K-means/</id>
    <published>2015-06-03T04:30:00.000Z</published>
    <updated>2016-07-30T14:54:24.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Github源码:<a href="https://github.com/csuldw/MachineLearning/tree/master/Kmeans" target="_blank" rel="noopener">https://github.com/csuldw/MachineLearning/tree/master/Kmeans</a></p><p>k-Means算法是一种聚类算法，它是一种无监督学习算法，目的是将相似的对象归到同一个蔟中。蔟内的对象越相似，聚类的效果就越好。聚类和分类最大的不同在于，分类的目标事先已知，而聚类则不一样。其产生的结果和分类相同，而只是类别没有预先定义。</p><a id="more"></a><h2 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h2><p>设计的目的：<font color="#1986C7"><strong>使各个样本与所在簇的质心的均值的误差平方和达到最小</strong></font>（这也是评价K-means算法最后聚类效果的评价标准）。</p><p><img src="http://latex.codecogs.com/gif.latex?%24%24SSE%20%3D%20%5Csum_%7Bi%3D1%7D%5Ek%20%5Csum_%7Bx%20%5Cepsilon%20C_%7Bi%7D%20%7D%20%7C%7Cx-%5Cmu_i%7C%7C_%7B2%7D%5E2%24%24" alt="$$SSE = \sum_{i=1}^k  \sum_{x \epsilon C_{i} } ||x-\mu_i||_{2}^2$$"></p><p><strong>K-均值聚类</strong></p><ul><li>优点：容易实现</li><li>缺点：可能收敛到局部最小值，在大规模数据上收敛较慢</li><li>适合数据类型：数值型数据</li></ul><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ol><li>创建k个点作为k个簇的起始质心（经常随机选择）。</li><li>分别计算剩下的元素到k个簇中心的相异度（距离），将这些元素分别划归到相异度最低的簇。</li><li>根据聚类结果，重新计算k个簇各自的中心，计算方法是取簇中所有元素各自维度的算术平均值。</li><li>将D中全部元素按照新的中心重新聚类。</li><li>重复第4步，直到聚类结果不再变化。</li><li>最后，输出聚类结果。</li></ol><h2 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h2><p><strong>伪代码</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">创建k个点作为K个簇的起始质心（经常随机选择）</span><br><span class="line">当任意一个点的蔟分配结果发生变化时（初始化为<span class="literal">True</span>）</span><br><span class="line">对数据集中的每个数据点，重新分配质心</span><br><span class="line">对每个质心</span><br><span class="line">计算质心到数据点之间的距离</span><br><span class="line">将数据点分配到距其最近的蔟</span><br><span class="line">对每个蔟，计算蔟中所有点的均值并将均值作为新的质心</span><br></pre></td></tr></tbody></table></figure><p><strong>实现</strong></p><p>因为我们用到的是数值类型数据，这里需要编写一个加载数据集的函数，其返回值是一个矩阵。下面代码应写在一个py文件里，我这里写在kMeans.py文件中。</p><p>首先引入相关的头文件：numpy</p><figure class="highlight capnproto"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br></pre></td></tr></tbody></table></figure><p><strong>数据集加载代码</strong></p><figure class="highlight processing"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 加载数据集文件，没有返回类标号的函数</span><br><span class="line">def loadDataSet(fileName):</span><br><span class="line">    dataMat = []</span><br><span class="line">    openfile = <span class="built_in">open</span>(fileName)    </span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">line</span> in openfile.readlines():</span><br><span class="line">        curLine = <span class="built_in">line</span>.strip().<span class="built_in">split</span>(<span class="string">'\t'</span>)</span><br><span class="line">        floatLine = <span class="built_in">map</span>(<span class="built_in">float</span>,curLine)</span><br><span class="line">        dataMat.<span class="built_in">append</span>(floatLine)</span><br><span class="line">    <span class="keyword">return</span> dataMat</span><br></pre></td></tr></tbody></table></figure><p>因为在k均值算法中要计算点到质心的距离，所以这里将距离计算写成一个函数，计算欧几里得距离公式：</p><p>$$d=\sqrt{(x_1-z_1)^2+…+(x_n-z_n)^2}$$</p><p><strong>函数代码如下：</strong></p><figure class="highlight ruby"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算两个向量的欧氏距离</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distEclud</span><span class="params">(vecA,vecB)</span></span><span class="symbol">:</span></span><br><span class="line">    <span class="keyword">return</span> sqrt(sum(power(vecA-vecB,<span class="number">2</span>)))</span><br></pre></td></tr></tbody></table></figure><p><strong>接下来初始化k个蔟的质心函数centroid</strong></p><figure class="highlight mipsasm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 传入的数据时numpy的矩阵格式</span></span><br><span class="line">def randCent(dataMat, k):</span><br><span class="line">    n = <span class="keyword">shape(dataMat)[1]</span></span><br><span class="line"><span class="keyword"> </span>   centroids = mat(zeros((k,n)))  </span><br><span class="line">    for <span class="keyword">j </span>in range(n):</span><br><span class="line">        minJ = min(dataMat[:,<span class="keyword">j]) </span><span class="comment"># 找出矩阵dataMat第j列最小值</span></span><br><span class="line">        rangeJ = float(max(dataMat[:,<span class="keyword">j]) </span>- minJ) <span class="comment">#计算第j列最大值和最小值的差</span></span><br><span class="line">        <span class="comment">#赋予一个随机质心，它的值在整个数据集的边界之内</span></span><br><span class="line">        centroids[:,<span class="keyword">j] </span>= minJ + rangeJ * <span class="built_in">random</span>.rand(k,<span class="number">1</span>) </span><br><span class="line">    return centroids <span class="comment">#返回一个随机的质心矩阵</span></span><br></pre></td></tr></tbody></table></figure><p><strong>K-means算法实现</strong></p><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#返回的第一个变量时质心，第二个是各个簇的分布情况</span></span><br><span class="line">def kMeans(dataMat,k,<span class="attr">distE</span> = distEclud , <span class="attr">createCent=randCent):</span></span><br><span class="line">    <span class="attr">m</span> = shape(dataMat)[<span class="number">0</span>]    <span class="comment"># 获得行数m</span></span><br><span class="line">    <span class="attr">clusterAssment</span> = mat(zeros((m,<span class="number">2</span>))) <span class="comment"># 初试化一个矩阵，用来记录簇索引和存储误差                               </span></span><br><span class="line">    <span class="attr">centroids</span> = createCent(dataMat,k) <span class="comment"># 随机的得到一个质心矩阵蔟</span></span><br><span class="line">    <span class="attr">clusterChanged</span> = True</span><br><span class="line">    while clusterChanged:</span><br><span class="line">        <span class="attr">clusterChanged</span> = False</span><br><span class="line">        for i <span class="keyword">in</span> range(m):    <span class="comment">#对每个数据点寻找最近的质心</span></span><br><span class="line">            <span class="attr">minDist</span> = inf; <span class="attr">minIndex</span> = -<span class="number">1</span></span><br><span class="line">            for j <span class="keyword">in</span> range(k): <span class="comment"># 遍历质心蔟，寻找最近的质心    </span></span><br><span class="line">                <span class="attr">distJ1</span> = distE(centroids[j,:],dataMat[i,:]) <span class="comment">#计算数据点和质心的欧式距离</span></span><br><span class="line">                <span class="keyword">if</span> distJ1 &lt; minDist: </span><br><span class="line">                    <span class="attr">minDist</span> = distJ1</span><br><span class="line">                    <span class="attr">minIndex</span> = j</span><br><span class="line">            <span class="keyword">if</span> clusterAssment[i,<span class="number">0</span>] != minIndex:</span><br><span class="line">                <span class="attr">clusterChanged</span> = True</span><br><span class="line">            clusterAssment[i,:] = minIndex, minDist**<span class="number">2</span></span><br><span class="line">        print centroids</span><br><span class="line">        for ci <span class="keyword">in</span> range(k):   <span class="comment">#更新质心，将每个族中的点的均值作为质心</span></span><br><span class="line">            <span class="attr">index_all</span> = clusterAssment[:,<span class="number">0</span>].A   <span class="comment">#取出样本所属簇的索引值</span></span><br><span class="line">            <span class="attr">value</span> = nonzero(<span class="attr">index_all==ci)</span>    <span class="comment">#取出所有属于第ci个簇的索引值</span></span><br><span class="line">            <span class="attr">sampleInClust</span> = dataMat[value[<span class="number">0</span>]]     <span class="comment">#取出属于第i个簇的所有样本点</span></span><br><span class="line">            centroids[cent,:] = mean(sampleInClust, <span class="attr">axis=0)</span> </span><br><span class="line">    return centroids, clusterAssment</span><br></pre></td></tr></tbody></table></figure><p>虽然K-Means算法原理简单，但是也有自身的缺陷：</p><ul><li>首先，聚类的簇数K值需要事先给定，但在实际中这个 K 值的选定是非常难以估计的，很多时候，事先并不知道给定的数据集应该分成多少个类别才最合适。</li><li>Kmeans需要人为地确定初始聚类中心，不同的初始聚类中心可能导致完全不同的聚类结果，不能保证Ｋ-Means算法收敛于全局最优解。<ul><li>针对此问题，在K-Means的基础上提出了二分K-means算法。该算法首先将所有点看做是一个簇，然后一分为二，找到最小SSE的聚类质心。接着选择其中一个簇继续一分为二，此处哪一个簇需要根据划分后的SSE值来判断。</li></ul></li><li>对离群点敏感。</li><li>结果不稳定 （受输入顺序影响）。</li><li>时间复杂度高O(nkt)，其中n是对象总数，k是簇数，t是迭代次数。</li></ul><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>在控制台调用上述函数，执行下列命令：</p><figure class="highlight lisp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataMat = mat(<span class="name">loadDataSet</span>('testSet.txt'))</span><br><span class="line">kMeans(<span class="name">dataMat</span>, <span class="number">4</span>)</span><br></pre></td></tr></tbody></table></figure><p>运行上面代码后，可以看到<code>print</code>处输出的结果：</p><pre><code class="markdown">[[-3.66087851  2.30869657] [ 3.24377288  3.04700412] [ 2.52577861 -3.12485493] [-2.79672694  3.19201596]][[-3.78710372 -1.66790611] [ 2.6265299   3.10868015] [ 1.62908469 -2.92689085] [-2.18799937  3.01824781]][[-3.53973889 -2.89384326] [ 2.6265299   3.10868015] [ 2.65077367 -2.79019029] [-2.46154315  2.78737555]]</code></pre><p>测试的时候取的k值为4，即簇的个数为4，所以经过3次迭代之后K-均值算法就收敛了。质心会保存在第一个返回值中，第二个是每个点的簇分布情况。k=4是，聚类结果如下：</p><p><img src="/assets/articleImg/k_clusters4.png" alt=""></p><p>附数据集：<a href="https://github.com/csuldw/MachineLearning/blob/master/Kmeans/data/testSet.txt" target="_blank" rel="noopener">https://github.com/csuldw/MachineLearning/blob/master/Kmeans/data/testSet.txt</a></p><h2 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h2><h3 id="1-K-Means算法K值如何选择？"><a href="#1-K-Means算法K值如何选择？" class="headerlink" title="1.K-Means算法K值如何选择？"></a>1.K-Means算法K值如何选择？</h3><p>《大数据》中提到：给定一个合适的类簇指标，比如平均半径或直径，只要我们假设的类簇的数目等于或者高于真实的类簇的数目时，该指标上升会很缓慢，而一旦试图得到少于真实数目的类簇时，该指标会急剧上升。</p><ul><li>簇的直径是指簇内任意两点之间的最大距离。</li><li>簇的半径是指簇内所有点到簇中心距离的最大值。</li></ul><h3 id="2-如何优化K-Means算法搜索的时间复杂度？"><a href="#2-如何优化K-Means算法搜索的时间复杂度？" class="headerlink" title="2. 如何优化K-Means算法搜索的时间复杂度？"></a>2. 如何优化K-Means算法搜索的时间复杂度？</h3><p>可以使用K-D树来缩短最近邻的搜索时间（NN算法都可以使用K-D树来优化时间复杂度）。</p><h3 id="3-如何确定K个簇的初始质心？"><a href="#3-如何确定K个簇的初始质心？" class="headerlink" title="3. 如何确定K个簇的初始质心？"></a>3. 如何确定K个簇的初始质心？</h3><p>1) 选择批次距离尽可能远的K个点</p><p>首先随机选择一个点作为第一个初始类簇中心点，然后选择距离该点最远的那个点作为第二个初始类簇中心点，然后再选择距离前两个点的最近距离最大的点作为第三个初始类簇的中心点，以此类推，直至选出K个初始类簇中心点。</p><p>2) 选用层次聚类或者Canopy算法进行初始聚类，然后利用这些类簇的中心点作为KMeans算法初始类簇中心点。</p><p>聚类扩展：密度聚类、层次聚类。</p><p>##　参考文献</p><ul><li><a href="http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006910.html" target="_blank" rel="noopener">http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006910.html</a></li><li><a href="http://www.cs.cmu.edu/~guestrin/Class/10701-S07/Slides/clustering.pdf" target="_blank" rel="noopener">http://www.cs.cmu.edu/~guestrin/Class/10701-S07/Slides/clustering.pdf</a></li></ul><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Github源码:&lt;a href=&quot;https://github.com/csuldw/MachineLearning/tree/master/Kmeans&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/csuldw/MachineLearning/tree/master/Kmeans&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;k-Means算法是一种聚类算法，它是一种无监督学习算法，目的是将相似的对象归到同一个蔟中。蔟内的对象越相似，聚类的效果就越好。聚类和分类最大的不同在于，分类的目标事先已知，而聚类则不一样。其产生的结果和分类相同，而只是类别没有预先定义。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="K-Means" scheme="https://www.csuldw.com/tags/K-Means/"/>
    
      <category term="聚类" scheme="https://www.csuldw.com/tags/%E8%81%9A%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>sklearn训练模型的保存与恢复（Python）</title>
    <link href="https://www.csuldw.com/2015/05/31/2015-05-31%20scikit-learn%20training%20model&#39;s%20save%20and%20reused/"/>
    <id>https://www.csuldw.com/2015/05/31/2015-05-31 scikit-learn training model&#39;s save and reused/</id>
    <published>2015-05-31T12:52:00.000Z</published>
    <updated>2016-07-28T15:43:04.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在做模型训练的时候，尤其是在训练集上做交叉验证，通常想要将模型保存下来，然后放到独立的测试集上测试，下面介绍的是Python中训练模型的保存和再使用。</p><a id="more"></a><p>在scikit-learn这个库里，已经有了模型持久化的操作，只需导入joblib即可</p><figure class="highlight capnproto"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</span><br></pre></td></tr></tbody></table></figure><hr><h3 id="模型保存"><a href="#模型保存" class="headerlink" title="模型保存"></a><strong>模型保存</strong></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>os.chdir(<span class="string">"workspace/model_save"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X = [[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = [<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>clf = svm.SVC()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>clf.fit(X, y)  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>clf.fit(train_X,train_y)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>joblib.dump(clf, <span class="string">"train_model.m"</span>)</span><br></pre></td></tr></tbody></table></figure><p>通过joblib的dump可以将模型保存到本地，clf是训练的分类器</p><h3 id="模型从本地调回"><a href="#模型从本地调回" class="headerlink" title="模型从本地调回"></a><strong>模型从本地调回</strong></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>clf = joblib.load(<span class="string">"train_model.m"</span>)</span><br></pre></td></tr></tbody></table></figure><p>通过joblib的load方法，加载保存的模型。</p><p>然后就可以在测试集上测试了</p><figure class="highlight css"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">clf</span><span class="selector-class">.predit</span>(<span class="selector-tag">test_X</span>，<span class="selector-tag">test_y</span>)</span><br></pre></td></tr></tbody></table></figure><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在做模型训练的时候，尤其是在训练集上做交叉验证，通常想要将模型保存下来，然后放到独立的测试集上测试，下面介绍的是Python中训练模型的保存和再使用。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://www.csuldw.com/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.csuldw.com/tags/Python/"/>
    
      <category term="scikit-learn" scheme="https://www.csuldw.com/tags/scikit-learn/"/>
    
      <category term="持久化" scheme="https://www.csuldw.com/tags/%E6%8C%81%E4%B9%85%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>机器学习算法-朴素贝叶斯Python实现</title>
    <link href="https://www.csuldw.com/2015/05/28/2015-05-28-NB/"/>
    <id>https://www.csuldw.com/2015/05/28/2015-05-28-NB/</id>
    <published>2015-05-28T04:59:00.000Z</published>
    <updated>2016-07-28T15:42:18.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>源码：<a href="https://github.com/csuldw/MachineLearning/tree/master/NaiveBayes" target="_blank" rel="noopener">https://github.com/csuldw/MachineLearning/tree/master/NaiveBayes</a></p><p>前面提到的KNN和决策树DT算法，数据实例最终被明确的划分到某个分类中，下面介绍一种不能完全确定数据实例应该划分到哪个类别，或者说只能给数据实例属于给定分类的概率。</p><a id="more"></a><h3 id="基于贝叶斯决策理论的分类方法之朴素贝叶斯"><a href="#基于贝叶斯决策理论的分类方法之朴素贝叶斯" class="headerlink" title="基于贝叶斯决策理论的分类方法之朴素贝叶斯"></a><strong>基于贝叶斯决策理论的分类方法之朴素贝叶斯</strong></h3><ul><li>优点：在数据较少的情况下仍然有效，可以处理多类别问题</li><li>缺点：对于输入数据的准备方式较为敏感 </li><li>适用数据类型：标称型数据。</li></ul><h3 id="朴素贝叶斯的一般过程"><a href="#朴素贝叶斯的一般过程" class="headerlink" title="朴素贝叶斯的一般过程"></a><strong>朴素贝叶斯的一般过程</strong></h3><ul><li>收集数据：可以使用任何方式</li><li>准备数据：需要数据型或是布尔型数据</li><li>分类数据：有大量特征时，绘制特征作用不大，此时使用直方图效果更好</li><li>训练算法：计算不同的独立特征的条件概率</li><li>测试算法：计算错误率</li><li>使用算法：文档分类</li></ul><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a><strong>原理</strong></h3><p>主要是运用<strong>贝叶斯定理</strong></p><p>$$ P(H|X) = \dfrac{P(X|H) p(H)}{P(X)} $$</p><h3 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a><strong>算法实现</strong></h3><p>下面做一个简单的留言板分类，自动判别留言类别：侮辱类和非侮辱类，分别使用1和0表示。下面来做一下这个实验。以下函数全部写在一个叫bayes.py文件中，后面的实验室通过导入bayes.py，调用里面的函数来做的。</p><p>导入numpy包</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br></pre></td></tr></tbody></table></figure><h4 id="1-加载数据集"><a href="#1-加载数据集" class="headerlink" title="1.加载数据集"></a><strong>1.加载数据集</strong></h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    postingList=[[<span class="string">'my'</span>, <span class="string">'dog'</span>, <span class="string">'has'</span>, <span class="string">'flea'</span>, <span class="string">'problems'</span>, <span class="string">'help'</span>, <span class="string">'please'</span>],</span><br><span class="line">                 [<span class="string">'maybe'</span>, <span class="string">'not'</span>, <span class="string">'take'</span>, <span class="string">'him'</span>, <span class="string">'to'</span>, <span class="string">'dog'</span>, <span class="string">'park'</span>, <span class="string">'stupid'</span>],</span><br><span class="line">                 [<span class="string">'my'</span>, <span class="string">'dalmation'</span>, <span class="string">'is'</span>, <span class="string">'so'</span>, <span class="string">'cute'</span>, <span class="string">'I'</span>, <span class="string">'love'</span>, <span class="string">'him'</span>],</span><br><span class="line">                 [<span class="string">'stop'</span>, <span class="string">'posting'</span>, <span class="string">'stupid'</span>, <span class="string">'worthless'</span>, <span class="string">'garbage'</span>],</span><br><span class="line">                 [<span class="string">'mr'</span>, <span class="string">'licks'</span>, <span class="string">'ate'</span>, <span class="string">'my'</span>, <span class="string">'steak'</span>, <span class="string">'how'</span>, <span class="string">'to'</span>, <span class="string">'stop'</span>, <span class="string">'him'</span>],</span><br><span class="line">                 [<span class="string">'quit'</span>, <span class="string">'buying'</span>, <span class="string">'worthless'</span>, <span class="string">'dog'</span>, <span class="string">'food'</span>, <span class="string">'stupid'</span>]]</span><br><span class="line">    classVec = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>]    <span class="comment">#1 is abusive, 0 not</span></span><br><span class="line">    <span class="keyword">return</span> postingList,classVec</span><br></pre></td></tr></tbody></table></figure><p>该函数返回的是<strong>词条切分集合</strong>和<strong>类标签</strong>。</p><p>####<strong>2.根据样本创建一个词库</strong></p><p>下面的函数是根据上面给出来的样本数据所创建出来的一个词库。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createVocabList</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    vocabSet = set([])  <span class="comment">#create empty set</span></span><br><span class="line">    <span class="keyword">for</span> document <span class="keyword">in</span> dataSet:</span><br><span class="line">        vocabSet = vocabSet | set(document) <span class="comment">#union of the two sets</span></span><br><span class="line">    <span class="keyword">return</span> list(vocabSet)</span><br></pre></td></tr></tbody></table></figure><h4 id="3-统计每个样本在词库中的出现情况"><a href="#3-统计每个样本在词库中的出现情况" class="headerlink" title="3.统计每个样本在词库中的出现情况"></a><strong>3.统计每个样本在词库中的出现情况</strong></h4><p>下面的函数功能是把单个样本映射到词库中去，统计单个样本在词库中的出现情况，1表示出现过，0表示没有出现，函数如下：</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">setOfWords2Vec</span><span class="params">(vocabList, inputSet)</span>:</span></span><br><span class="line"><span class="function">    returnVec </span>= [<span class="number">0</span>]*len(vocabList)</span><br><span class="line">    <span class="keyword">for</span> <span class="keyword">word</span> in inputSet:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">word</span> in vocabList:</span><br><span class="line">            returnVec[vocabList.index(<span class="keyword">word</span>)] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>: <span class="built_in">print</span> <span class="string">"the word: %s is not in my Vocabulary!"</span> % <span class="keyword">word</span></span><br><span class="line">    <span class="keyword">return</span> returnVec</span><br></pre></td></tr></tbody></table></figure><h4 id="4-计算条件概率和类标签概率"><a href="#4-计算条件概率和类标签概率" class="headerlink" title="4.计算条件概率和类标签概率"></a><strong>4.计算条件概率和类标签概率</strong></h4><figure class="highlight smali"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">def trainNB0(trainMatrix,trainCategory):</span><br><span class="line">    numTrainDocs = len(trainMatrix)</span><br><span class="line">    numWords = len(trainMatrix[0])</span><br><span class="line">    pAbusive = sum(trainCategory)/float(numTrainDocs) <span class="comment">#计算某个类发生的概率</span></span><br><span class="line">    p0Num = ones(numWords); p1Num = ones(numWords) <span class="comment">#初始样本个数为1，防止条件概率为0，影响结果       </span></span><br><span class="line">    p0Denom = 2.0; p1Denom = 2.0  <span class="comment">#作用同上                      </span></span><br><span class="line">    for i in range(numTrainDocs):</span><br><span class="line">       <span class="built_in"> if </span>trainCategory[i] == 1:</span><br><span class="line">            p1Num += trainMatrix[i]</span><br><span class="line">            p1Denom += sum(trainMatrix[i])</span><br><span class="line">        else:</span><br><span class="line">            p0Num += trainMatrix[i]</span><br><span class="line">            p0Denom += sum(trainMatrix[i])</span><br><span class="line">    p1Vect = log(p1Num/p1Denom)         <span class="comment">#计算类标签为1时的其它属性发生的条件概率</span></span><br><span class="line">    p0Vect = log(p0Num/p0Denom)         <span class="comment">#计算标签为0时的其它属性发生的条件概率</span></span><br><span class="line">   <span class="built_in"> return </span>p0Vect,p1Vect,pAbusive       <span class="comment">#返回条件概率和类标签为1的概率</span></span><br></pre></td></tr></tbody></table></figure><p>说明：</p><h4 id="5-训练贝叶斯分类算法"><a href="#5-训练贝叶斯分类算法" class="headerlink" title="5.训练贝叶斯分类算法"></a><strong>5.训练贝叶斯分类算法</strong></h4><p>该算法包含四个输入，vec2Classify表示待分类的样本在词库中的映射集合，p0Vec表示条件概率$P(w_i|c=0)$，p1Vec表示条件概率$P(w_i|c=1)$，pClass1表示类标签为1时的概率$P(c=1)$。</p><figure class="highlight smali"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):</span><br><span class="line">    p1 = sum(vec2Classify * p1Vec) + log(pClass1)    <span class="comment">#element-wise mult</span></span><br><span class="line">    p0 = sum(vec2Classify * p0Vec) + log(1.0 - pClass1)</span><br><span class="line">   <span class="built_in"> if </span>p1 &gt; p0:</span><br><span class="line">       <span class="built_in"> return </span>1</span><br><span class="line">    else: </span><br><span class="line">       <span class="built_in"> return </span>0</span><br></pre></td></tr></tbody></table></figure><p>其中p1和p0表示的是</p><p>$$lnp(w_1|c=1)p(w_2|c=1)…p(w_n|c=1)*p(c=1)$$</p><p>和</p><p>$$lnp(w_1|c=0)p(w_2|c=0)…p(w_n|c=0)*p(c=0)$$</p><p>取对数是因为防止p(w_1|c=1)p(w_2|c=1)p(w_3|c=1)…p(w_n|c=1)多个小于1的数相乘结果值下溢。</p><h4 id="6-文档词袋模型-修改函数setOfWords2Vec"><a href="#6-文档词袋模型-修改函数setOfWords2Vec" class="headerlink" title="6.文档词袋模型,修改函数setOfWords2Vec"></a><strong>6.文档词袋模型,修改函数setOfWords2Vec</strong></h4><p>词袋模型主要修改上面的第三个步骤，因为有的词可能出现多次，所以在单个样本映射到词库的时候需要多次统计。</p><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">bagOfWords2VecMN</span><span class="params">(vocabList, inputSet)</span>:</span></span><br><span class="line"><span class="function">    returnVec </span>= [<span class="number">0</span>]*len(vocabList)</span><br><span class="line">    <span class="keyword">for</span> <span class="keyword">word</span> in inputSet:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">word</span> in vocabList:</span><br><span class="line">            returnVec[vocabList.index(<span class="keyword">word</span>)] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> returnVec</span><br></pre></td></tr></tbody></table></figure><h4 id="7-测试函数"><a href="#7-测试函数" class="headerlink" title="7.测试函数"></a><strong>7.测试函数</strong></h4><p>下面给出一个测试函数，直接调用该测试函数就可以实现简单的分类，测试结果看下个部分。</p><figure class="highlight php"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def testingNB():</span><br><span class="line"><span class="comment">#step1：加载数据集和类标号</span></span><br><span class="line">    listOPosts,listClasses = loadDataSet()</span><br><span class="line">    <span class="comment">#step2：创建词库</span></span><br><span class="line">    myVocabList = createVocabList(listOPosts)</span><br><span class="line">    <span class="comment"># step3：计算每个样本在词库中的出现情况</span></span><br><span class="line">    trainMat=[]</span><br><span class="line">    <span class="keyword">for</span> postinDoc in listOPosts:</span><br><span class="line">        trainMat.append(setOfWords2Vec(myVocabList, postinDoc))</span><br><span class="line">    <span class="comment">#step4：调用第四步函数，计算条件概率</span></span><br><span class="line">    p0V,p1V,pAb = trainNB0(<span class="keyword">array</span>(trainMat),<span class="keyword">array</span>(listClasses))</span><br><span class="line">    <span class="comment"># step5</span></span><br><span class="line">    <span class="comment"># 测试1 </span></span><br><span class="line">    testEntry = [<span class="string">'love'</span>, <span class="string">'my'</span>, <span class="string">'dalmation'</span>]</span><br><span class="line">    thisDoc = <span class="keyword">array</span>(setOfWords2Vec(myVocabList, testEntry))</span><br><span class="line">    <span class="keyword">print</span> testEntry,<span class="string">'classified as: '</span>,classifyNB(thisDoc,p0V,p1V,pAb)</span><br><span class="line">    <span class="comment"># 测试2</span></span><br><span class="line">    testEntry = [<span class="string">'stupid'</span>, <span class="string">'garbage'</span>]</span><br><span class="line">    thisDoc = <span class="keyword">array</span>(setOfWords2Vec(myVocabList, testEntry))</span><br><span class="line">    <span class="keyword">print</span> testEntry,<span class="string">'classified as: '</span>,classifyNB(thisDoc,p0V,p1V,pAb)</span><br></pre></td></tr></tbody></table></figure><h4 id="8-实验"><a href="#8-实验" class="headerlink" title="8.实验"></a><strong>8.实验</strong></h4><p>首先导入库，然后导入bayes.py文件</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.chdir(<span class="string">r"E:\3-CSU\Academic\Machine Leaning\机器学习实战\src\machinelearninginaction\Ch04"</span>)</span><br><span class="line"><span class="keyword">import</span> bayes</span><br></pre></td></tr></tbody></table></figure><p><img src="http://img.blog.csdn.net/20150528122404620" alt="这里写图片描述"></p><p>可以看出，贝叶斯算法将[‘love’, ‘my’, ‘dalmation’]分为“无侮辱”一类，将[‘stupid’, ‘garbage’]分为“侮辱”性质的一类。</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a><strong>Reference</strong></h3><p><strong>[1]《Machine Learning in Action 》机器学习实战</strong></p><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;源码：&lt;a href=&quot;https://github.com/csuldw/MachineLearning/tree/master/NaiveBayes&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/csuldw/MachineLearning/tree/master/NaiveBayes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;前面提到的KNN和决策树DT算法，数据实例最终被明确的划分到某个分类中，下面介绍一种不能完全确定数据实例应该划分到哪个类别，或者说只能给数据实例属于给定分类的概率。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Python" scheme="https://www.csuldw.com/tags/Python/"/>
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="Naive Bayes" scheme="https://www.csuldw.com/tags/Naive-Bayes/"/>
    
  </entry>
  
  <entry>
    <title>机器学习算法-K最近邻从原理到实现</title>
    <link href="https://www.csuldw.com/2015/05/21/2015-05-21-KNN/"/>
    <id>https://www.csuldw.com/2015/05/21/2015-05-21-KNN/</id>
    <published>2015-05-21T12:34:00.000Z</published>
    <updated>2016-07-28T15:41:14.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>源码：<a href="https://github.com/csuldw/MachineLearning/tree/master/KNN" target="_blank" rel="noopener">https://github.com/csuldw/MachineLearning/tree/master/KNN</a></p><p>决策树和基于规则的分类器都是<strong>积极学习方法</strong>（eager learner）的例子，因为一旦训练数据可用，他们就开始学习从输入属性到类标号的映射模型。一个相反的策略是推迟对训练数据的建模，直到需要分类测试样例时再进行。采用这种策略的技术被称为<strong>消极学习法</strong>（lazy learner）。<strong>最近邻分类器</strong>就是这样的一种方法。</p><a id="more"></a><h3 id="KNN原理"><a href="#KNN原理" class="headerlink" title="KNN原理"></a><strong>KNN原理</strong></h3><p>首先给出一张图，根据这张图来理解最近邻分类器，如下：</p><center>![这里写图片描述](http://img.blog.csdn.net/20150521201557111)</center><p>根据上图所示，有两类不同的样本数据，分别用<strong>蓝色的小正方形</strong>和<strong>红色的小三角形</strong>表示，而图正中间的那个<strong>绿色的圆</strong>所标示的数据则是待分类的数据。也就是说，现在， 我们不知道中间那个绿色的数据是从属于哪一类（蓝色小正方形or红色小三角形），下面，我们就要解决这个问题：给这个绿色的圆分类。</p><p>　　我们常说，物以类聚，人以群分，判别一个人是一个什么样品质特征的人，常常可以从他or她身边的朋友入手，所谓观其友，而识其人。我们不是要判别上图中那个绿色的圆是属于哪一类数据么，好说，从它的邻居下手。但一次性看多少个邻居呢？从上图中，你还能看到：</p><ul><li>如果K=3，绿色圆点的最近的3个邻居是2个红色小三角形和1个蓝色小正方形，少数从属于多数，基于统计的方法，判定绿色的这个待分类点属于红色的三角形一类。</li><li>如果K=5，绿色圆点的最近的5个邻居是2个红色三角形和3个蓝色的正方形，还是少数从属于多数，基于统计的方法，判定绿色的这个待分类点属于蓝色的正方形一类。</li></ul><p>于此我们看到，当无法判定当前待分类点是从属于已知分类中的哪一类时，我们可以依据统计学的理论看它所处的位置特征，衡量它周围邻居的权重，而把它归为(或分配)到权重更大的那一类。这就是K近邻算法的核心思想。</p><p>KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。</p><p>KNN 算法本身简单有效，它是一种 lazy-learning 算法，分类器不需要使用训练集进行训练，训练时间复杂度为0。KNN 分类的计算复杂度和训练集中的文档数目成正比，也就是说，如果训练集中文档总数为 n，那么 KNN 的分类时间复杂度为O(n)。</p><p>前面的例子中强调了选择合适的K值的重要性。如果太小，则最近邻分类器容易受到训练数据的噪声而产生的过分拟合的影响；相反，如果K太大，最近分类器可能会误会分类测试样例，因为最近邻列表中可能包含远离其近邻的数据点。（如下图所示）</p><center>![这里写图片描述](http://img.blog.csdn.net/20150521203027253) <p><strong>K较大时的最近邻分类</strong></p></center><p>可见，K值的选取还是非常关键。</p><hr><h3 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a><strong>算法描述</strong></h3><p>算法步骤如下所示：</p><center>![这里写图片描述](http://img.blog.csdn.net/20150521203212596)</center><p>对每个测试样例$z = (x’,y’)$，算法计算它和所有训练样例$（x,y）属于D$之间的距离（或相似度），以确定其最近邻列表$D_z$。如果训练样例的数目很大，那么这种计算的开销就会很大。不过，可以使索引技术降低为测试样例找最近邻是的计算量。</p><p>一旦得到最近邻列表，测试样例就可以根据最近邻的多数类进行分类，使用多数表决方法。</p><h3 id="算法实现（Python）"><a href="#算法实现（Python）" class="headerlink" title="算法实现（Python）"></a><strong>算法实现（Python）</strong></h3><p>KNN.py</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KNN</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">createDataset</span><span class="params">(self)</span>:</span></span><br><span class="line">        group = array([[<span class="number">1.0</span>,<span class="number">1.1</span>],[<span class="number">1.0</span>,<span class="number">1.0</span>],[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0.1</span>]])</span><br><span class="line">        labels = [<span class="string">'A'</span>,<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'B'</span>]</span><br><span class="line">        <span class="keyword">return</span> group,labels</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">KnnClassify</span><span class="params">(self,testX,trainX,labels,K)</span>:</span></span><br><span class="line">        [N,M]=trainX.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#calculate the distance between testX and other training samples</span></span><br><span class="line">        difference = tile(testX,(N,<span class="number">1</span>)) - trainX <span class="comment"># tile for array and repeat for matrix in Python, == repmat in Matlab</span></span><br><span class="line">        difference = difference ** <span class="number">2</span> <span class="comment"># take pow(difference,2)</span></span><br><span class="line">        distance = difference.sum(<span class="number">1</span>) <span class="comment"># take the sum of difference from all dimensions</span></span><br><span class="line">        distance = distance ** <span class="number">0.5</span></span><br><span class="line">        sortdiffidx = distance.argsort()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># find the k nearest neighbours</span></span><br><span class="line">        vote = {} <span class="comment">#create the dictionary</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(K):</span><br><span class="line">            ith_label = labels[sortdiffidx[i]];</span><br><span class="line">            vote[ith_label] = vote.get(ith_label,<span class="number">0</span>)+<span class="number">1</span> <span class="comment">#get(ith_label,0) : if dictionary 'vote' exist key 'ith_label', return vote[ith_label]; else return 0</span></span><br><span class="line">        sortedvote = sorted(vote.iteritems(),key = <span class="keyword">lambda</span> x:x[<span class="number">1</span>], reverse = <span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># 'key = lambda x: x[1]' can be substituted by operator.itemgetter(1)</span></span><br><span class="line">        <span class="keyword">return</span> sortedvote[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">k = KNN() <span class="comment">#create KNN object</span></span><br><span class="line">group,labels = k.createDataset()</span><br><span class="line">cls = k.KnnClassify([<span class="number">0</span>,<span class="number">0</span>],group,labels,<span class="number">3</span>)</span><br><span class="line"><span class="keyword">print</span> cls</span><br></pre></td></tr></tbody></table></figure><p>运行：</p><ol><li>在Python Shell 中可以运行KNN.py</li></ol><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="keyword">import</span> os</span><br><span class="line">&gt;&gt;&gt;os.chdir(<span class="string">"/home/liudiwei/code/data_miningKNN/"</span>)</span><br><span class="line">&gt;&gt;&gt;execfile(<span class="string">"KNN.py"</span>)</span><br></pre></td></tr></tbody></table></figure><p>输出:B<br>（B表示类别）</p><p>2.或者terminal中直接运行</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python KNN.py</span><br></pre></td></tr></tbody></table></figure><p>3.也可以不在KNN.py中写输出，而选择在Shell中获得结果，i.e.,</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="keyword">import</span> KNN</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>KNN.k.KnnClassify([<span class="number">0</span>,<span class="number">0</span>],KNN.group,KNN.labels,<span class="number">3</span>)</span><br></pre></td></tr></tbody></table></figure><h3 id="References"><a href="#References" class="headerlink" title="References"></a><strong>References</strong></h3><p>【1】Introduction to Data Mining <a href="http://vdisk.weibo.com/s/akTUdytgliZM8" target="_blank" rel="noopener">数据挖掘导论</a><br>【2】<a href="http://blog.csdn.net/abcjennifer/article/details/19757987" target="_blank" rel="noopener">Rachel Zhang-K近邻分类算法实现 in Python</a></p><hr><p>附件（两张自己的计算过程图）：</p><center>![这里写图片描述](http://img.blog.csdn.net/20150524192410343)**图1 KNN算法核心部分**</center><center>![这里写图片描述](http://img.blog.csdn.net/20150524192640924)**图2 简易计算过程**</center>说明：上述图片仅供参考，看不懂就自己测试一组数据如[0,1]慢慢推导一下吧<hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;源码：&lt;a href=&quot;https://github.com/csuldw/MachineLearning/tree/master/KNN&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/csuldw/MachineLearning/tree/master/KNN&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;决策树和基于规则的分类器都是&lt;strong&gt;积极学习方法&lt;/strong&gt;（eager learner）的例子，因为一旦训练数据可用，他们就开始学习从输入属性到类标号的映射模型。一个相反的策略是推迟对训练数据的建模，直到需要分类测试样例时再进行。采用这种策略的技术被称为&lt;strong&gt;消极学习法&lt;/strong&gt;（lazy learner）。&lt;strong&gt;最近邻分类器&lt;/strong&gt;就是这样的一种方法。&lt;/p&gt;
    
    </summary>
    
      <category term="ML" scheme="https://www.csuldw.com/categories/ML/"/>
    
    
      <category term="Machine Learning" scheme="https://www.csuldw.com/tags/Machine-Learning/"/>
    
      <category term="KNN" scheme="https://www.csuldw.com/tags/KNN/"/>
    
      <category term="最近邻" scheme="https://www.csuldw.com/tags/%E6%9C%80%E8%BF%91%E9%82%BB/"/>
    
  </entry>
  
</feed>
